{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks for different implementations of Muon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "import torch.utils.benchmark as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = [\n",
    "    *[torch.rand(768, 4*768, dtype=torch.float32, device=\"cuda\") for _ in range(12)],\n",
    "    *[torch.rand(4*768, 768, dtype=torch.float32, device=\"cuda\") for _ in range(12)],\n",
    "    *[torch.rand(768, 768, dtype=torch.float32, device=\"cuda\") for _ in range(4*12)],\n",
    "]\n",
    "\n",
    "s1 = torch.cuda.Stream()\n",
    "s2 = torch.cuda.Stream()\n",
    "s3 = torch.cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_in_us(f, *args, **kwargs):\n",
    "    t0 = benchmark.Timer(\n",
    "        stmt=\"f(*args, **kwargs)\", globals={\"args\": args, \"kwargs\": kwargs, \"f\": f}\n",
    "    )\n",
    "    return t0.blocked_autorange().mean * 1e3\n",
    "\n",
    "\n",
    "def single(f: Callable[[torch.Tensor, int], torch.Tensor], gs: list[torch.Tensor], steps: int):\n",
    "    g = gs[0]\n",
    "    f(g, steps)\n",
    "\n",
    "\n",
    "def multiple(f: Callable[[torch.Tensor, int], torch.Tensor], gs: list[torch.Tensor], steps: int):\n",
    "    for g in gs:\n",
    "        f(g, steps)\n",
    "\n",
    "\n",
    "def multiplexed_2_streams(f: Callable[[torch.Tensor, int], torch.Tensor], gs: list[torch.Tensor], steps: int):\n",
    "    with torch.cuda.stream(s1):\n",
    "        for g in gs[:9]:\n",
    "            f(g, steps)\n",
    "    with torch.cuda.stream(s2):\n",
    "        for g in gs[9:]:\n",
    "            f(g, steps)\n",
    "\n",
    "\n",
    "def multiplexed_3_streams(f: Callable[[torch.Tensor, int], torch.Tensor], gs: list[torch.Tensor], steps: int):\n",
    "    with torch.cuda.stream(s1):\n",
    "        for g in gs[:6]:\n",
    "            f(g, steps)\n",
    "    with torch.cuda.stream(s2):\n",
    "        for g in gs[6:12]:\n",
    "            f(g, steps)\n",
    "    with torch.cuda.stream(s3):\n",
    "        for g in gs[12:]:\n",
    "            f(g, steps)\n",
    "\n",
    "\n",
    "def run_benchmarks(f: Callable[[torch.Tensor, int], torch.Tensor]):\n",
    "    # Warmup\n",
    "    benchmark_in_us(single, f, gs, 4)\n",
    "    benchmark_in_us(single, f, gs, 5)\n",
    "\n",
    "    runtime_single_4_steps = benchmark_in_us(single, f, gs, 4)\n",
    "    runtime_single_5_steps = benchmark_in_us(single, f, gs, 5)\n",
    "    runtime_multiple_4_steps = benchmark_in_us(multiple, f, gs, 4) / len(gs)\n",
    "    runtime_multiple_5_steps = benchmark_in_us(multiple, f, gs, 5) / len(gs)\n",
    "    runtime_mux_2_streams_4_steps = benchmark_in_us(multiplexed_2_streams, f, gs, 4) / len(gs)\n",
    "    runtime_mux_2_streams_5_steps = benchmark_in_us(multiplexed_2_streams, f, gs, 5) / len(gs)\n",
    "    runtime_mux_3_streams_4_steps = benchmark_in_us(multiplexed_3_streams, f, gs, 4) / len(gs)\n",
    "    runtime_mux_3_streams_5_steps = benchmark_in_us(multiplexed_3_streams, f, gs, 5) / len(gs)\n",
    "    print(f\"Single, 4 steps: {runtime_single_4_steps} ms\")\n",
    "    print(f\"Single, 5 steps: {runtime_single_5_steps} ms\")\n",
    "    print(f\"Multiple, 4 steps: {runtime_multiple_4_steps} ms\")\n",
    "    print(f\"Multiple, 5 steps: {runtime_multiple_5_steps} ms\")\n",
    "    print(f\"Multiplexed 2 streams, 4 steps: {runtime_mux_2_streams_4_steps} ms\")\n",
    "    print(f\"Multiplexed 2 streams, 5 steps: {runtime_mux_2_streams_5_steps} ms\")\n",
    "    print(f\"Multiplexed 3 streams, 4 steps: {runtime_mux_3_streams_4_steps} ms\")\n",
    "    print(f\"Multiplexed 3 streams, 5 steps: {runtime_mux_3_streams_5_steps} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-step Muon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, n: int):\n",
    "    assert len(G.shape) == 2\n",
    "    a, b, c = (3.4445, -4.7750, 2.0315)\n",
    "    X = G.bfloat16()\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    for _ in range(n):\n",
    "        A = X @ X.T\n",
    "        B = A @ X\n",
    "        X = a * X + b * B + c * A @ B\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"Original - naive compile\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-overhead is slower\n",
    "# @torch.compile\n",
    "@torch.compile(mode=\"max-autotune-no-cudagraphs\")\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, n: int):\n",
    "    assert len(G.shape) == 2\n",
    "    a, b, c = (3.4445, -4.7750, 2.0315)\n",
    "    X = G.bfloat16()\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    for _ in range(n):\n",
    "        A = X @ X.T\n",
    "        B = A @ X\n",
    "        X = a * X + b * B + c * A @ B\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"Original\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-overhead is slower\n",
    "# @torch.compile\n",
    "@torch.compile(mode=\"max-autotune-no-cudagraphs\")\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, steps: int):\n",
    "    a, b, c = (3.4445, -4.7750, 2.0315)\n",
    "    n, m = G.size()\n",
    "    X = G.bfloat16()\n",
    "    I = torch.eye(min(n, m), dtype=X.dtype, device=X.device)\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if n > m:\n",
    "        X = X.T\n",
    "    for _ in range(steps):\n",
    "        A = X @ X.T\n",
    "        X = a * X + (b * A + c * A @ A) @ X\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"X = a * X + (b * A + c * A @ A) @ X\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-overhead is slower\n",
    "# @torch.compile\n",
    "@torch.compile(mode=\"max-autotune-no-cudagraphs\")\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, steps: int):\n",
    "    a, b, c = (3.4445, -4.7750, 2.0315)\n",
    "    n, m = G.size()\n",
    "    X = G.bfloat16()\n",
    "    I = torch.eye(min(n, m), dtype=X.dtype, device=X.device)\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if n > m:\n",
    "        X = X.T\n",
    "    for _ in range(steps):\n",
    "        A = X @ X.T\n",
    "        X = (a * I + A @ (b * I + c * A)) @ X\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"X = (a * I + A @ (b * I + c * A)) @ X\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-overhead is slower\n",
    "# @torch.compile\n",
    "@torch.compile(mode=\"max-autotune-no-cudagraphs\")\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, steps: int):\n",
    "    a, b, c = (3.4445, -4.7750, 2.0315)\n",
    "    n, m = G.size()\n",
    "    X = G.bfloat16()\n",
    "    I = torch.eye(min(n, m), dtype=X.dtype, device=X.device)\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if n > m:\n",
    "        X = X.T\n",
    "    for _ in range(steps):\n",
    "        A = X @ X.T\n",
    "        S = A @ (b * I + c * A)\n",
    "        torch.diagonal(S).add_(a)\n",
    "        X = S @ X\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"w/ S\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Step Muon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-overhead is slower\n",
    "# @torch.compile\n",
    "@torch.compile(mode=\"max-autotune-no-cudagraphs\")\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, steps: int):\n",
    "    a, b, c = (3.4445, -4.7750, 2.0315)\n",
    "    n, m = G.size()\n",
    "    X = G.bfloat16()\n",
    "    I = torch.eye(min(n, m), dtype=X.dtype, device=X.device)\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if n > m:\n",
    "        X = X.T\n",
    "    for a, b, c in (\n",
    "        (4.8969, -14.0610, 10.1415),\n",
    "        (4.7285, -10.0664, 5.4487),\n",
    "        (4.0968, -5.9557, 2.3200),\n",
    "        (3.0319, -3.3993, 1.1814),\n",
    "    ):\n",
    "        A = X @ X.T\n",
    "        B = A @ X\n",
    "        X = a * X + b * B + c * A @ B\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"Original - 4-step\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-overhead is slower\n",
    "# @torch.compile\n",
    "@torch.compile(mode=\"max-autotune-no-cudagraphs\")\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, steps: int):\n",
    "    a, b, c = (3.4445, -4.7750, 2.0315)\n",
    "    n, m = G.size()\n",
    "    X = G.bfloat16()\n",
    "    I = torch.eye(min(n, m), dtype=X.dtype, device=X.device)\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if n > m:\n",
    "        X = X.T\n",
    "    for a, b, c in (\n",
    "        (4.8969, -14.0610, 10.1415),\n",
    "        (4.7285, -10.0664, 5.4487),\n",
    "        (4.0968, -5.9557, 2.3200),\n",
    "        (3.0319, -3.3993, 1.1814),\n",
    "    ):\n",
    "        A = X @ X.T\n",
    "        X = (a * I + b * A @ (I + c/b * A)) @ X\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"X = (a * I + b * A @ (I + c/b * A)) @ X - 4-step\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-overhead is slower\n",
    "# @torch.compile\n",
    "@torch.compile(mode=\"max-autotune-no-cudagraphs\")\n",
    "def zeropower_via_newtonschulz5(G: torch.Tensor, steps: int):\n",
    "    n, m = G.size()\n",
    "    X = G.bfloat16()\n",
    "    I = torch.eye(min(n, m), dtype=X.dtype, device=X.device)\n",
    "    X.div_(X.norm() + 1e-7)\n",
    "    if n > m:\n",
    "        X = X.T\n",
    "    for a, b, c in (\n",
    "        (4.8969, -14.0610, 10.1415),\n",
    "        (4.7285, -10.0664, 5.4487),\n",
    "        (4.0968, -5.9557, 2.3200),\n",
    "        (3.0319, -3.3993, 1.1814),\n",
    "    ):\n",
    "        A = X @ X.T\n",
    "        S = A @ (b * I + c * A)\n",
    "        torch.diagonal(S).add_(a)\n",
    "        X = S @ X\n",
    "    if G.size(0) > G.size(1):\n",
    "        X = X.T\n",
    "    return X\n",
    "\n",
    "\n",
    "print(\"w/ S - 4-step\")\n",
    "run_benchmarks(zeropower_via_newtonschulz5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
