import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging

with open('optimizer.py', 'r', encoding='utf-8') as f:
    source_code = f.read()
    code += source_code

with open('model.py', 'r', encoding='utf-8') as f:
    source_code = f.read()
    code += source_code

with open('utils.py', 'r', encoding='utf-8') as f:
    source_code = f.read()
    code += source_code

with open('dataloading.py', 'r', encoding='utf-8') as f:
    source_code = f.read()
    code += source_code

import argparse
import uuid
import time
import contextlib
import math
import numpy as np
import torch
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP
from pathlib import Path
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, matthews_corrcoef

from optimizer import Muon
from model import ModelConfig, ESM, CastedLinear
from dataloading import DistributedDataLoader


def get_args():
    parser = argparse.ArgumentParser(description='ESM2 training arguments')
    
    # Model hyperparams
    parser.add_argument('--vocab_size', type=int, default=33, help='vocabulary size')
    parser.add_argument('--num_hidden_layers', type=int, default=24, help='number of transformer layers')
    parser.add_argument('--num_attention_heads', type=int, default=6, help='number of attention heads (head dim 128 suggested by @Grad62304977)')
    parser.add_argument('--hidden_size', type=int, default=768, help='model hidden dimension size')
    
    # Data hyperparams
    parser.add_argument('--input_bin', type=str, default='data/omgprot50/omgprot50_train_*.bin', help='input .bins to train on')
    parser.add_argument('--input_valid_bin', type=str, default='data/omgprot50/omgprot50_valid_*.bin', help='input .bins to eval validation loss on')
    parser.add_argument('--input_test_bin', type=str, default='data/omgprot50/omgprot50_test_*.bin', help='input .bins to eval test loss on')   
    
    # Optimization hyperparams
    parser.add_argument('--batch_size', type=int, default=8*64*1024, help='batch size, in tokens, across all devices')
    parser.add_argument('--grad_accum', type=int, default=1, help='manually set number of gradient accumulation steps, else, will be ddp_world_size')
    parser.add_argument('--num_steps', type=int, default=25000, help='number of iterations to run')
    parser.add_argument('--warmup_steps', type=int, default=1000, help='number of warmup steps')
    parser.add_argument('--cooldown_steps', type=int, default=1000, help='number of cooldown steps')
    
    # Evaluation and logging hyperparams
    parser.add_argument('--valid_loss_every', type=int, default=1000, help='every how many steps to evaluate val loss? 0 for only at the end')
    parser.add_argument('--hf_model_name', type=str, default='Synthyra/esm_speedrun', help='huggingface model name')
    parser.add_argument('--token', type=str, default=None, help='huggingface token')
    parser.add_argument('--save_every', type=int, default=None, help='save every how many steps? None for no saving')
    args = parser.parse_args()
    return args


def get_param_count(model):
    total_params = 0
    for _, param in model.named_parameters():
        total_params += param.numel()
    return total_params


if __name__ == "__main__":
    args = get_args()
    if args.token:
        from huggingface_hub import login
        login(args.token)
        args.token = None
    model_config = ModelConfig(
        vocab_size=args.vocab_size,
        num_hidden_layers=args.num_hidden_layers,
        num_attention_heads=args.num_attention_heads,
        hidden_size=args.hidden_size,
    )

    # set up DDP (distributed data parallel) if available, otherwise single GPU
    if 'RANK' in os.environ:
        ddp_rank = int(os.environ['RANK'])
        ddp_local_rank = int(os.environ['LOCAL_RANK'])
        ddp_world_size = int(os.environ['WORLD_SIZE'])
        device = torch.device(f'cuda:{ddp_local_rank}')
        torch.cuda.set_device(device)
        dist.init_process_group(backend='nccl', device_id=device)
        dist.barrier()
        master_process = (ddp_rank == 0)
    else:
        ddp_rank = 0
        ddp_local_rank = 0 
        ddp_world_size = 1
        device = torch.device('cuda:0')
        torch.cuda.set_device(device)
        master_process = True

    print(f'using device: {device}')

    # begin logging
    logfile = None
    if master_process:
        run_id = uuid.uuid4()
        Path('logs').mkdir(exist_ok=True)
        # logdir = Path('logs') / f'{run_id}'
        # logdir.mkdir()
        logfile = Path('logs') / f'{run_id}.txt'
        print(logfile.stem)
        # create the log file
        with logfile.open('w') as f:
            # begin the log by printing this file (the Python code)
            print(code, file=f)
            print('=' * 100, file=f)

    def print0(s, logonly=False):
        if master_process:
            with logfile.open('a') as f:
                if not logonly:
                    print(s)
                print(s, file=f)

    # log information about the hardware/software environment this is running on
    # and print the full `nvidia-smi` to file
    print0(f'Running python {sys.version}')
    print0(f'Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:')
    import subprocess
    result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    print0(f'{result.stdout}', logonly=True)
    print0('='*100, logonly=True)

    print0(f'Model config: {model_config}')
    print0(f'Args: {args.__dict__}')

    # calculate the steps of gradient accumulation required to attain the desired global batch size
    # args.batch_size should refer to the total amount of tokens per backward pass
    train_accumulation_steps = 1
    batch_size = args.batch_size

    assert ddp_world_size == 1 or args.grad_accum == 1, "Cannot currently use both DDP and gradient accumulation"
    if ddp_world_size > 1:
        train_accumulation_steps = ddp_world_size
        batch_size = args.batch_size // ddp_world_size 
    elif args.grad_accum > 1:
        train_accumulation_steps *= args.grad_accum
        batch_size = args.batch_size // args.grad_accum

    print0(f'Train accumulation steps: {train_accumulation_steps}')
    print0(f'Adjusted local batch size: {batch_size} tokens')
    print0(f'Across {ddp_world_size} GPUs')
    print0(f'Total batch size: {args.batch_size} tokens')

    # load tokens
    train_loader = DistributedDataLoader(args.input_bin, batch_size, ddp_rank, ddp_world_size)
    valid_loader = DistributedDataLoader(args.input_valid_bin, batch_size, ddp_rank, ddp_world_size)
    test_loader = DistributedDataLoader(args.input_test_bin, batch_size, ddp_rank, ddp_world_size)
    print0(f"Training DataLoader: total number of tokens: {train_loader.total_num_tokens} across {len(train_loader.files)} files")
    print0(f"Validation DataLoader: total number of tokens: {valid_loader.total_num_tokens} across {len(valid_loader.files)} files")
    print0(f"Testing DataLoader: total number of tokens: {test_loader.total_num_tokens} across {len(test_loader.files)} files")
    print0('='*100, logonly=True)

    valid_steps = valid_loader.total_num_tokens // args.batch_size
    test_steps = test_loader.total_num_tokens // args.batch_size

    input_ids = train_loader.next_batch()

    model = ESM(model_config)
    model = model.cuda().bfloat16()
    for m in model.modules():
        if isinstance(m, CastedLinear):
            m.float()
    config.coordinate_descent_tuning = True # suggested by @Chillee
    model = torch.compile(model)

    # wrap model in DDP only if using distributed training
    if ddp_world_size > 1:
        model = DDP(model, device_ids=[ddp_local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)
        raw_model = model.module
    else:
        raw_model = model

    # init the optimizers
    embed_params = [*raw_model.embed.parameters(), *raw_model.value_embeds.parameters()]
    params = list(raw_model.blocks.parameters())
    matrix_params = [p for p in params if p.ndim == 2]
    scalar_params = [p for p in params if p.ndim < 2] + [raw_model.skip_weights]
    optimizer1 = torch.optim.Adam(embed_params, lr=0.6, betas=(0.8, 0.95), fused=True)
    optimizer2 = torch.optim.Adam([raw_model.lm_head.weight], lr=0.008, betas=(0.8, 0.95), fused=True)
    optimizer3 = Muon(matrix_params, lr=0.05, momentum=0.95)
    optimizer4 = torch.optim.Adam(scalar_params, lr=0.04, betas=(0.8, 0.95), fused=True)
    optimizers = [optimizer1, optimizer2, optimizer3, optimizer4]

    # learning rate decay scheduler (linear warmup and cooldown)
    def get_lr(it):
        assert it <= args.num_steps
        # 1) linear warmup for warmup_steps steps
        if it < args.warmup_steps:
            return (it+1) / args.warmup_steps
        # 2) constant lr for a while
        elif it < args.num_steps - args.cooldown_steps:
            return 1.0
        # 3) linear cooldown
        else:
            decay_ratio = (args.num_steps - it) / args.cooldown_steps
            return decay_ratio

    schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

    sliding_window_size = torch.tensor(1024 - 128, dtype=torch.int32, device="cuda")
    sw_prev = 1024 - 128
    # Start training loop
    training_time_ms = 0
    # start the clock
    torch.cuda.synchronize()
    t0 = time.perf_counter()

    ### BEGIN TRAINING LOOP ###
    for step in range(args.num_steps + 1):
        last_step = (step == args.num_steps)
        # This effectively ignores timing first 10 steps, which are slower for weird reasons.
        # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
        # steps with dummy data first, and then re-initialize the model and reset the loader.
        if step == 10:
            training_time_ms = 0
            t0 = time.perf_counter()
        timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

        # Linearly increase the sliding window size over training in chunks of 128 from 1024 -> 2048. By @fernbear.bsky.social
        frac_done = step / args.num_steps # training progress
        sw_size = int(((1 - frac_done) * 1023 + frac_done * 2048) // 128) * 128
        if sw_size != sw_prev:
            sliding_window_size.copy_(sw_size, non_blocking=True)
            sw_prev = sw_size

        # once in a while evaluate the validation dataset
        if args.valid_loss_every > 0 and step % args.valid_loss_every == 0 or last_step:
            # stop the clock
            torch.cuda.synchronize()
            training_time_ms += 1000 * (time.perf_counter() - t0)
            # run validation batches
            model.eval()
            valid_loader.reset()
            val_loss = 0.0
            with torch.no_grad():
                for _ in range(valid_steps):
                    input_ids = valid_loader.next_batch()
                    val_loss += model(input_ids, sliding_window_size)
            if ddp_world_size > 1:
                dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
            val_loss /= valid_steps
            # log val loss to console and to logfile
            print0(f'step:{step}/{args.num_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms perplexity:{(math.e**val_loss):.4f} param_count:{get_param_count(model):,}')
            # start the clock again
            torch.cuda.synchronize()
            t0 = time.perf_counter()

        # save checkpoint every `save_every` steps
        if master_process and args.save_every:
            if last_step or (step % args.save_every == 0):
                # stop the clock
                torch.cuda.synchronize()
                training_time_ms += 1000 * (time.perf_counter() - t0)
                # save the state of the training process
                log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
                torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
                # start the clock again
                torch.cuda.synchronize()
                t0 = time.perf_counter()

        if last_step:
            break

        # --------------- FORWARD AND BACKWARD PASS -----------------
        model.train()
        for i in range(1, train_accumulation_steps + 1):
            with contextlib.ExitStack() as stack:
                if ddp_world_size > 1 and i < train_accumulation_steps: # there's no need to sync gradients every accumulation step
                    stack.enter_context(model.no_sync())
                #if step >= 5:
                #    stack.enter_context(torch.compiler.set_stance(skip_guard_eval_unsafe=True))
                model(input_ids, sliding_window_size).backward()
                input_ids = train_loader.next_batch()
        if train_accumulation_steps != 1:
            for p in model.parameters():
                p.grad /= train_accumulation_steps
        # momentum warmup for Muon
        frac = min(step/300, 1)
        for group in optimizer3.param_groups:
            group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
        # step the optimizers and schedulers
        for opt, sched in zip(optimizers, schedulers):
            opt.step()
            sched.step()
        # null the gradients
        model.zero_grad(set_to_none=True)
        # --------------- FORWARD AND BACKWARD PASS END -------------------
        # everything that follows now is just eval, diagnostics, prints, logging, etc.
        if step % 100 == 0:
            approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
            print0(f"step:{step+1}/{args.num_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")

    print0(f"peak memory consumption training: {torch.cuda.max_memory_allocated() // 1024 // 1024 // 1024} GiB")

    # save the model to huggingface
    try:
        model.push_to_hub(args.hf_model_name)
    except Exception as e:
        print(e)

    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    torch.manual_seed(42)
    model.eval()
    test_loader.reset()
    test_loss = 0.0
    with torch.no_grad():
        for _ in range(test_steps):
            input_ids = test_loader.next_batch()
            test_loss += model(input_ids, sliding_window_size)

    test_loss /= test_steps
    print0(f"Test results | Loss: {test_loss:.4f} | Perplexity: {math.e**test_loss:.4f}")
    print0(f"Total train time (min): {training_time_ms / 60000:.2f}")
    print0(f"Total train time (hours): {training_time_ms / 3600000:.2f}")

    print0(f"peak memory consumption testing: {torch.cuda.max_memory_allocated() // 1024 // 1024 // 1024} GiB")
    # -------------------------------------------------------------------------
    # clean up nice
    if ddp_world_size > 1:
        dist.destroy_process_group()
import os
import torch
import torch.distributed as dist


### Muon optimizer
@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X

    if G.size(0) > G.size(1):
        X = X.T
    return X


class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ.get('WORLD_SIZE', '1'))
        self.rank = int(os.environ.get('RANK', '0'))
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params = list(params)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [
            {
                'params': [p for p in params if p.numel() == size],
                'update_buffer': [
                    torch.empty(size, device='cuda', dtype=torch.bfloat16)
                    for _ in range(self.world_size)
                ],
            }
            for size in sizes
        ]
        super().__init__(param_groups, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            assert len(params) % self.world_size == 0
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                if handle is not None:
                    handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                p = params[base_i + self.rank]
                g = p.grad
                assert g is not None
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.lerp_(g, 1 - momentum)
                g = g.lerp_(buf, momentum) if nesterov else buf
                g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                update_prev()
                if self.world_size > 1:
                    handle = dist.all_gather(update_buffers, g, async_op=True)
                else:
                    update_buffers[0].copy_(g)
                    handle = None
                params_world = params[base_i : base_i + self.world_size]
            update_prev()
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.attention.flex_attention import flex_attention, create_block_mask
from transformers import EsmTokenizer, PretrainedConfig, PreTrainedModel
from utils import ProteinMasker
from typing import Optional, Tuple, List, Any


class ModelConfig(PretrainedConfig):
    """
    33 tokens: https://huggingface.co/Synthyra/ESMplusplus_large/blob/main/modeling_esm_plusplus.py#L868-L874
    ESM2-8M has 6 layers, 20 heads, 320 hidden dim: https://huggingface.co/facebook/esm2_t6_8M_UR50D/blob/main/config.json
    ESM2-35M has 12 layers, 20 heads, 480 hidden dim: https://huggingface.co/facebook/esm2_t12_35M_UR50D/blob/main/config.json
    ESM2-150M has 30 layers, 20 heads, 640 hidden dim: https://huggingface.co/facebook/esm2_t30_150M_UR50D/blob/main/config.json
    ESM2-650M has 33 layers, 20 heads, 1280 hidden dim: https://huggingface.co/facebook/esm2_t33_650M_UR50D/blob/main/config.json
    """
    def __init__(
        self,
        vocab_size=33,
        hidden_size=768,
        num_hidden_layers=12,
        num_attention_heads=12,
        expansion_ratio=8/3,
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.vocab_size = vocab_size
        self.hidden_size = hidden_size
        self.num_hidden_layers = num_hidden_layers
        self.num_attention_heads = num_attention_heads
        self.expansion_ratio = expansion_ratio


def norm(x: torch.Tensor) -> torch.Tensor:
    return F.rms_norm(x, (x.size(-1),))


class CastedLinear(nn.Linear):
    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return F.linear(x, self.weight.to(x.dtype))


class Rotary(nn.Module):
    def __init__(self, dim, base=10000):
        super().__init__()
        self.register_buffer('inv_freq', (1 / base) ** (torch.arange(0, dim, 2) / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            t = torch.arange(seq_len, device=x.device)
            freqs = torch.outer(t, self.inv_freq)
            self.seq_len_cached = seq_len
            self.cos_cached = freqs.cos()
            self.sin_cached = freqs.sin()
        cos, sin = self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]
        # apply_rotary_emb(x, cos, sin)
        x1, x2 = x.chunk(2, dim=3)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)


class SelfAttention(nn.Module):
    """
    TODO
    Add F.spda option
    Add causal option (flex and sdpa)
    """
    def __init__(self, dim, num_attention_heads):
        super().__init__()
        assert dim % num_attention_heads == 0
        self.num_attention_heads = num_attention_heads
        self.qkv = CastedLinear(dim, 3 * dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_attention_heads) # dim // num_attention_heads = head_dim
        self.o_proj = CastedLinear(dim, dim)
        self.o_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward_sdpa(self, x: torch.Tensor, vi: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        TODO
        Question? Is this output actually different than flex attention output?
        Likely yes because of scoremod and / or soft capping
        Would be good to be able to do inference this way for typical PLM inference pipelines
        https://pytorch.org/blog/flexattention/
        """
        B, T = x.size(0), x.size(1) # batch size, sequence length
        qkv = self.qkv(x)
        q, k, v = qkv.chunk(3, dim=-1)
        q = q.view(B, T, self.num_attention_heads, -1)
        k = k.view(B, T, self.num_attention_heads, -1)
        v = v.view(B, T, self.num_attention_heads, -1)
        v = self.lambdas[0] * v + self.lambdas[1] * vi.view_as(v) # @KoszarskyB & @Grad62304977
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = F.scaled_dot_product_attention(
            q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2),
            attn_mask=attention_mask,
            dropout_p=0.0,
            is_causal=False,
            enable_gqa=True
        )
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.o_proj(y)
        return y

    def forward(self, x: torch.Tensor, vi: torch.Tensor, block_mask: torch.Tensor) -> torch.Tensor:
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        qkv = self.qkv(x)
        q, k, v = qkv.chunk(3, dim=-1)
        q = q.view(B, T, self.num_attention_heads, -1)
        k = k.view(B, T, self.num_attention_heads, -1)
        v = v.view(B, T, self.num_attention_heads, -1)
        v = self.lambdas[0] * v + self.lambdas[1] * vi.view_as(v) # @KoszarskyB & @Grad62304977
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, enable_gqa=True)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.o_proj(y)
        return y


def correction_fn(expansion_ratio: float, d_model: int) -> int:
    return int(((expansion_ratio * d_model) + 255) // 256 * 256)


class MLP(nn.Module):
    def __init__(self, dim, expansion_ratio):
        super().__init__()
        self.up   = CastedLinear(dim, correction_fn(expansion_ratio, dim))
        self.down = CastedLinear(correction_fn(expansion_ratio, dim), dim)
        self.down.weight.data.zero_() # zero init suggested by @Grad62304977
        self.relu = nn.ReLU()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # https://arxiv.org/abs/2109.08668v2
        # ReLU squared ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        return self.down(self.relu(self.up(x)).square())


class Block(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.attn = SelfAttention(config.hidden_size, config.num_attention_heads)
        self.mlp = MLP(config.hidden_size, config.expansion_ratio)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def sdpa_forward(self, x: torch.Tensor, vi: torch.Tensor, x0: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        x = x + self.attn.forward_sdpa(norm(x), vi, attention_mask)
        x = x + self.mlp(norm(x))
        return x

    def forward(self, x: torch.Tensor, vi: torch.Tensor, x0: torch.Tensor, block_mask: torch.Tensor) -> torch.Tensor:
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        x = x + self.attn(norm(x), vi, block_mask)
        x = x + self.mlp(norm(x))
        return x


class ValueEmbedding(nn.Module):
    def __init__(self, config: "ModelConfig"):
        super().__init__()
        self.embed = nn.ModuleList([
            nn.Embedding(config.vocab_size, config.hidden_size)
            for _ in range(config.num_hidden_layers // 2)
        ])

    def forward(self, inputs: torch.Tensor) -> List[torch.Tensor]:
        ve = [emb(inputs) for emb in self.embed]
        ve += reversed(ve)
        return ve


class ESM(PreTrainedModel):
    """
    TODO
    Add causal option (flex and sdpa)
    """
    config_class = ModelConfig
    def __init__(self, config: ModelConfig):
        super().__init__(config)
        self.config = config
        tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t6_8M_UR50D')
        self.masker = ProteinMasker(tokenizer, 0.20) # 20% masking rate https://arxiv.org/abs/2301.06568
        self.inference_masker = ProteinMasker(tokenizer, 0.15) # 15% masking rate for inference, ESM2
        self.cls_id = tokenizer.cls_token_id
        self.vocab_size = tokenizer.vocab_size
        self.num_hidden_layers = config.num_hidden_layers

        # U-net design by @brendanh0gan
        assert config.num_hidden_layers % 2 == 0, "Number of layers should be even for U-net design"
        self.num_encoder_layers = config.num_hidden_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = config.num_hidden_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

        self.embed = nn.Embedding(self.vocab_size, config.hidden_size)
        self.blocks = nn.ModuleList([Block(config) for _ in range(config.num_hidden_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(config)
        self.lm_head = CastedLinear(config.hidden_size, self.vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        self.cross_entropy = nn.CrossEntropyLoss()

    def embed_forward(self, input_ids: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:
        x = self.embed(input_ids[None])
        x = norm(x) # @Grad62304977
        x0 = x
        ve = self.value_embeds(input_ids)
        return x, x0, ve

    def get_logits(self, x: torch.Tensor) -> torch.Tensor:
        x = norm(x)
        logits = self.lm_head(x)
        logits = 30 * torch.tanh(logits / 30) # @Grad62304977
        logits = logits.float()
        return logits

    def sdpa_forward(self, input_ids: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        if attention_mask is not None:
            attention_mask = attention_mask[:, None, None, :].bool()
        
        x, x0, ve = self.embed_forward(input_ids)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        skip_connections = []
        for i in range(self.num_encoder_layers):
            x = self.blocks[i].sdpa_forward(x, ve_enc[i], x0, attention_mask)
            skip_connections.append(x)

        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            x = self.blocks[self.num_encoder_layers + i].sdpa_forward(x, ve_dec[i], x0, attention_mask)

        return self.get_logits(x)

    def flex_forward(self, input_ids: torch.Tensor, sliding_window_size: torch.Tensor) -> torch.Tensor:
        input_ids = input_ids.flatten() # flex_attention needs batch 1
        docs = (input_ids == self.cls_id).cumsum(0)

        def doc_mask_mod(b, h, q_idx, kv_idx):
            bidirectional_sliding_window_mask = torch.abs(q_idx - kv_idx) < sliding_window_size
            doc_mask = docs[q_idx] == docs[kv_idx]
            return bidirectional_sliding_window_mask & doc_mask

        S = len(input_ids)
        block_mask = create_block_mask(doc_mask_mod, None, None, S, S)

        x, x0, ve = self.embed_forward(input_ids)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        return self.get_logits(x)

    def inference(self, input_ids: torch.Tensor, sliding_window_size: torch.Tensor = None) -> Tuple[torch.Tensor, Any, Any]:
        input_ids, labels = self.inference_masker(input_ids)
        logits = self.flex_forward(input_ids, sliding_window_size)
        loss = None
        if labels is not None:
            loss = self.cross_entropy(logits.view(-1, self.vocab_size), labels.view(-1).long())
        return logits, loss, labels

    def forward(self, input_ids: torch.Tensor, sliding_window_size: torch.Tensor) -> torch.Tensor:
        input_ids, labels = self.masker(input_ids)
        logits = self.flex_forward(input_ids, sliding_window_size)
        return self.cross_entropy(logits.view(-1, self.vocab_size), labels.view(-1).long())


if __name__ == '__main__':
    """
    TODO
    look at MSE between flex attention outputs and sdpa outputs
    """


import torch
from typing import Tuple

"""
Standardized MLM masking approach for consistency
"""

class ProteinMasker:
    def __init__(self, tokenizer, mlm_probability=0.15):
        """
        Initialize the ProteinMasker with the given tokenizer and masking parameters.
        Of the masked tokens, 80% are replaced with [MASK], 10% are replaced with a random amino acid token, and 10% are unchanged.
        """
        self.tokenizer = tokenizer
        self.mlm_probability = mlm_probability
        self.mask_token_id = tokenizer.mask_token_id
        self.special_tokens = torch.tensor(tokenizer.all_special_ids)
        canonical_amino_acids = 'ACDEFGHIKLMNPQRSTVWY'
        canonical_amino_acids_ids = tokenizer.convert_tokens_to_ids(list(canonical_amino_acids))
        self.low_range = min(canonical_amino_acids_ids)
        self.high_range = max(canonical_amino_acids_ids)

    def __call__(self, input_ids: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        labels = input_ids.clone()
        
        # Create special tokens mask using broadcasting
        special_tokens = self.special_tokens.to(input_ids.device)
        special_tokens_mask = (input_ids[..., None] == special_tokens).any(-1)
        
        # Create probability matrix and mask special tokens
        probability_matrix = torch.full_like(labels, self.mlm_probability, dtype=torch.float)
        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)
        
        # Create masked indices
        masked_indices = torch.bernoulli(probability_matrix).bool()
        labels[~masked_indices] = -100  # We only compute loss on masked tokens
        
        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])
        indices_replaced = torch.bernoulli(torch.full_like(probability_matrix, 0.8)).bool() & masked_indices
        input_ids[indices_replaced] = self.mask_token_id
        
        # 10% of the time, we replace masked input tokens with random word
        indices_random = torch.bernoulli(torch.full_like(probability_matrix, 0.5)).bool() & masked_indices & ~indices_replaced
        random_words = torch.randint(low=self.low_range, high=self.high_range, size=labels.shape, dtype=input_ids.dtype, device=labels.device)
        input_ids[indices_random] = random_words[indices_random]
        
        # The rest of the time (10% of the time) we keep the masked input tokens unchanged
        return input_ids, labels


if __name__ == "__main__":
    from transformers import EsmTokenizer
    tokenizer = EsmTokenizer.from_pretrained("facebook/esm2_t6_8M_UR50D")
    test_seqs = [
        'MNFKYKLYSYITIFQIILILPTIVASNERCIALGGVCKDFSDCTGNYKPIDKHCDGSNNIKCCIRKIECPTSQNSNFTISGKNKEDEALPFIFKSEGGCQNDKNDNGNKINGKIGYTCAGITPMVGWKNKENYFSYAIKECTNDTNFTYCAYKLNENKFREGAKNIYIDKYAVAGKCNNLPQPAYYVCFDTSVNHGSGWSSKTITANPIGNMDGREYGLLLNKKSREKYINIVKNDSSQEKYLNGWLSRADDREKYCNNYCTSNCNCDNSASKASVSSNTNTTDIYNSVNTVDSDICNCDDNEPTDFLDDDYINNEEEIDEEIIDQEEY',
        'MYRTALYFTVCSIWLCQIITGVLSLKCKCDLCKDKNYTCITDGYCYTSATLKDGVILYNYRCLDLNFPMRNPMFCHKQIPIHHEFTLECCNDRDFCNIRLVPKLTPKDNATSDTSLGTIEIAVVIILPTLVICIIAMAIYLYYQNKRSTHHHLGLGDDSIEAPDHPILNGVSLKHMIEMTTSGSGSGLPLLVQRSIARQIQLVEIIGQGRYGEVWRGRWRGENVAVKIFSSREERSWFREAEIYQTVMLRHDNILGFIAADNKGVLSLKCKCDLCKDKNYTCITDGYCYTSATLKDGVILYNYRQLGASLNRFXVYALGLIFWEISRRCNVGGIYDEYQLPFYDAVPSDPTIEEMRRVVCVERQRPSIPNRWQSCEALHVMSKLMKECWYHNATARLTALRIKKTLANFRASEELKM'
    ]
    test_ids = tokenizer(test_seqs, return_tensors="pt", padding=True).input_ids
    masker = ProteinMasker(tokenizer, mlm_probability=0.5)
    print(masker.mask_token_id)
    print(masker.special_tokens)
    print(masker.low_range, masker.high_range)

    # First set of masking
    masked_ids1, labels1 = masker(test_ids.clone())
    masked_ids2, labels2 = masker(test_ids.clone())

    print("Before setting seed:")
    print("Original: ", test_ids[0][:20].tolist())
    print("Masking 1:", masked_ids1[0][:20].tolist()) 
    print("Masking 2:", masked_ids2[0][:20].tolist())
    print("Are they equal?", torch.equal(masked_ids1, masked_ids2))

    # Now with seed
    torch.manual_seed(42)
    masked_ids3, labels3 = masker(test_ids.clone())
    torch.manual_seed(42)
    masked_ids4, labels4 = masker(test_ids.clone())

    print("\nAfter setting seed:")
    print("Original: ", test_ids[0][:20].tolist())
    print("Masking 3:", masked_ids3[0][:20].tolist())
    print("Masking 4:", masked_ids4[0][:20].tolist()) 
    print("Are they equal?", torch.equal(masked_ids3, masked_ids4))
import torch
from pathlib import Path


def _peek_data_shard(file: Path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(f"{file}", False, 256, dtype=torch.int32)
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    return int(header[2]) # number of tokens (claimed)


def _load_data_shard(path: Path, num_tokens):
    with path.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint8, pin_memory=True)
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy())
        assert nbytes == num_tokens, "number of tokens read does not match header?"
    return tokens


class DistributedDataLoader:
    def __init__(self, filename_pattern, batch_size, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.batch_size = batch_size

        # glob files that match the pattern
        self.files = sorted(Path.cwd().glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        self.files_num_tokens = [_peek_data_shard(file) for file in self.files]
        self.total_num_tokens = sum(self.files_num_tokens)

        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.batch_size
        self.tokens = _load_data_shard(self.files[self.current_shard], self.files_num_tokens[self.current_shard])

    def next_batch(self):
        batch_size = self.batch_size * self.num_processes
        buf = self.tokens[self.current_position:self.current_position+self.batch_size]
        # host side async is sufficient;
        # no performance improvement was observed when introducing a separate stream.
        input_ids = buf.to(device="cuda", dtype=torch.int32, non_blocking=True) # inputs
        # advance current position and load next shard if necessary
        self.current_position += batch_size
        if self.current_position + batch_size >= len(self.tokens):
            self.advance()
        return input_ids

====================================================================================================
Running python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
Running pytorch 2.6.0.dev20241203+cu124 compiled for CUDA 12.4
nvidia-smi:
Sun Dec 29 05:43:28 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GH200 480GB             On  |   00000000:DD:00.0 Off |                    0 |
| N/A   36C    P0             83W /  700W |       4MiB /  97871MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

====================================================================================================
Model config: ModelConfig {
  "expansion_ratio": 2.6666666666666665,
  "hidden_size": 768,
  "num_attention_heads": 6,
  "num_hidden_layers": 24,
  "transformers_version": "4.47.1",
  "vocab_size": 33
}

Args: {'vocab_size': 33, 'num_hidden_layers': 24, 'num_attention_heads': 6, 'hidden_size': 768, 'input_bin': 'data/omgprot50/omgprot50_train_*.bin', 'input_valid_bin': 'data/omgprot50/omgprot50_valid_*.bin', 'input_test_bin': 'data/omgprot50/omgprot50_test_*.bin', 'batch_size': 524288, 'grad_accum': 8, 'num_steps': 20000, 'warmup_steps': 1000, 'cooldown_steps': 1000, 'valid_loss_every': 500, 'hf_model_name': 'Synthyra/esm_speedrun', 'token': None, 'save_every': None}
Train accumulation steps: 8
Adjusted local batch size: 65536 tokens
Across 1 GPUs
Total batch size: 524288 tokens
Training DataLoader: total number of tokens: 43956331596 across 440 files
Validation DataLoader: total number of tokens: 2097660 across 1 files
Testing DataLoader: total number of tokens: 3686279 across 1 files
====================================================================================================
step:0/20000 val_loss:3.4965 train_time:0ms step_avg:nanms perplexity:33.0000 param_count:132,475,500
step:1/20000 train_time:33852ms step_avg:nanms
step:101/20000 train_time:147342ms step_avg:1619.14ms
step:201/20000 train_time:310515ms step_avg:1625.73ms
step:301/20000 train_time:473666ms step_avg:1627.72ms
step:401/20000 train_time:636478ms step_avg:1627.82ms
step:500/20000 val_loss:2.5452 train_time:797436ms step_avg:1627.42ms perplexity:12.7455 param_count:132,475,500
step:501/20000 train_time:799068ms step_avg:1627.43ms
step:601/20000 train_time:961629ms step_avg:1627.12ms
step:701/20000 train_time:1124100ms step_avg:1626.77ms
step:801/20000 train_time:1287130ms step_avg:1627.22ms
step:901/20000 train_time:1449507ms step_avg:1626.83ms
step:1000/20000 val_loss:2.5012 train_time:1610347ms step_avg:1626.61ms perplexity:12.1976 param_count:132,475,500
step:1001/20000 train_time:1611974ms step_avg:1626.61ms
step:1101/20000 train_time:1774481ms step_avg:1626.47ms
step:1201/20000 train_time:1936703ms step_avg:1626.12ms
step:1301/20000 train_time:2099034ms step_avg:1625.90ms
step:1401/20000 train_time:2261421ms step_avg:1625.75ms
step:1500/20000 val_loss:2.4656 train_time:2422491ms step_avg:1625.83ms perplexity:11.7702 param_count:132,475,500
step:1501/20000 train_time:2424110ms step_avg:1625.83ms
step:1601/20000 train_time:2586399ms step_avg:1625.64ms
step:1701/20000 train_time:2748676ms step_avg:1625.47ms
step:1801/20000 train_time:2911071ms step_avg:1625.39ms
step:1901/20000 train_time:3073436ms step_avg:1625.30ms
step:2000/20000 val_loss:2.4370 train_time:3234021ms step_avg:1625.14ms perplexity:11.4382 param_count:132,475,500
step:2001/20000 train_time:3235638ms step_avg:1625.13ms
step:2101/20000 train_time:3397975ms step_avg:1625.05ms
step:2201/20000 train_time:3560302ms step_avg:1624.97ms
step:2301/20000 train_time:3722972ms step_avg:1625.04ms
step:2401/20000 train_time:3885147ms step_avg:1624.90ms
step:2500/20000 val_loss:2.4148 train_time:4045785ms step_avg:1624.81ms perplexity:11.1879 param_count:132,475,500
step:2501/20000 train_time:4047401ms step_avg:1624.81ms
step:2601/20000 train_time:4209840ms step_avg:1624.79ms
step:2701/20000 train_time:4372300ms step_avg:1624.79ms
step:2801/20000 train_time:4534759ms step_avg:1624.78ms
step:2901/20000 train_time:4697223ms step_avg:1624.77ms
step:3000/20000 val_loss:2.3958 train_time:4858082ms step_avg:1624.78ms perplexity:10.9768 param_count:132,475,500
step:3001/20000 train_time:4859706ms step_avg:1624.78ms
step:3101/20000 train_time:5022907ms step_avg:1625.01ms
step:3201/20000 train_time:5185488ms step_avg:1625.04ms
step:3301/20000 train_time:5348035ms step_avg:1625.05ms
step:3401/20000 train_time:5510463ms step_avg:1625.03ms
step:3500/20000 val_loss:2.3880 train_time:5671226ms step_avg:1624.99ms perplexity:10.8917 param_count:132,475,500
step:3501/20000 train_time:5672845ms step_avg:1624.99ms
step:3601/20000 train_time:5835308ms step_avg:1624.98ms
step:3701/20000 train_time:5997791ms step_avg:1624.98ms
step:3801/20000 train_time:6160164ms step_avg:1624.94ms
step:3901/20000 train_time:6323145ms step_avg:1625.07ms
step:4000/20000 val_loss:2.3730 train_time:6484149ms step_avg:1625.10ms perplexity:10.7293 param_count:132,475,500
step:4001/20000 train_time:6485779ms step_avg:1625.10ms
step:4101/20000 train_time:6648162ms step_avg:1625.07ms
step:4201/20000 train_time:6810401ms step_avg:1625.01ms
step:4301/20000 train_time:6972794ms step_avg:1624.98ms
step:4401/20000 train_time:7135184ms step_avg:1624.96ms
step:4500/20000 val_loss:2.3545 train_time:7295826ms step_avg:1624.91ms perplexity:10.5328 param_count:132,475,500
step:4501/20000 train_time:7297458ms step_avg:1624.91ms
step:4601/20000 train_time:7460437ms step_avg:1625.01ms
step:4701/20000 train_time:7622866ms step_avg:1625.00ms
step:4801/20000 train_time:7785244ms step_avg:1624.97ms
step:4901/20000 train_time:7947663ms step_avg:1624.96ms
step:5000/20000 val_loss:2.3454 train_time:8108295ms step_avg:1624.91ms perplexity:10.4378 param_count:132,475,500
step:5001/20000 train_time:8109921ms step_avg:1624.91ms
step:5101/20000 train_time:8272439ms step_avg:1624.91ms
step:5201/20000 train_time:8434806ms step_avg:1624.89ms
step:5301/20000 train_time:8597307ms step_avg:1624.89ms
step:5401/20000 train_time:8760162ms step_avg:1624.96ms
step:5500/20000 val_loss:2.3373 train_time:8920861ms step_avg:1624.93ms perplexity:10.3532 param_count:132,475,500
step:5501/20000 train_time:8922489ms step_avg:1624.93ms
step:5601/20000 train_time:9085018ms step_avg:1624.94ms
step:5701/20000 train_time:9247345ms step_avg:1624.91ms
step:5801/20000 train_time:9409611ms step_avg:1624.87ms
step:5901/20000 train_time:9571986ms step_avg:1624.85ms
step:6000/20000 val_loss:2.3282 train_time:9732864ms step_avg:1624.85ms perplexity:10.2592 param_count:132,475,500
step:6001/20000 train_time:9734504ms step_avg:1624.85ms
step:6101/20000 train_time:9896952ms step_avg:1624.85ms
step:6201/20000 train_time:10059572ms step_avg:1624.87ms
step:6301/20000 train_time:10221169ms step_avg:1624.73ms
step:6401/20000 train_time:10382628ms step_avg:1624.57ms
step:6500/20000 val_loss:2.3226 train_time:10542533ms step_avg:1624.43ms perplexity:10.2018 param_count:132,475,500
step:6501/20000 train_time:10544159ms step_avg:1624.43ms
step:6601/20000 train_time:10705794ms step_avg:1624.31ms
step:6701/20000 train_time:10867323ms step_avg:1624.17ms
step:6801/20000 train_time:11028894ms step_avg:1624.05ms
step:6901/20000 train_time:11191143ms step_avg:1624.02ms
step:7000/20000 val_loss:2.3140 train_time:11351040ms step_avg:1623.90ms perplexity:10.1145 param_count:132,475,500
step:7001/20000 train_time:11352658ms step_avg:1623.90ms
step:7101/20000 train_time:11514258ms step_avg:1623.78ms
step:7201/20000 train_time:11675903ms step_avg:1623.68ms
step:7301/20000 train_time:11837648ms step_avg:1623.60ms
step:7401/20000 train_time:11999370ms step_avg:1623.51ms
step:7500/20000 val_loss:2.3056 train_time:12159255ms step_avg:1623.40ms perplexity:10.0303 param_count:132,475,500
step:7501/20000 train_time:12160878ms step_avg:1623.40ms
step:7601/20000 train_time:12322548ms step_avg:1623.31ms
step:7701/20000 train_time:12484621ms step_avg:1623.28ms
step:7801/20000 train_time:12646079ms step_avg:1623.17ms
step:7901/20000 train_time:12807720ms step_avg:1623.08ms
step:8000/20000 val_loss:2.3072 train_time:12967683ms step_avg:1622.99ms perplexity:10.0464 param_count:132,475,500
step:8001/20000 train_time:12969300ms step_avg:1622.99ms
step:8101/20000 train_time:13131012ms step_avg:1622.92ms
step:8201/20000 train_time:13292644ms step_avg:1622.84ms
step:8301/20000 train_time:13454282ms step_avg:1622.76ms
step:8401/20000 train_time:13615989ms step_avg:1622.69ms
step:8500/20000 val_loss:2.2984 train_time:13776425ms step_avg:1622.66ms perplexity:9.9579 param_count:132,475,500
step:8501/20000 train_time:13778055ms step_avg:1622.67ms
step:8601/20000 train_time:13939657ms step_avg:1622.59ms
step:8701/20000 train_time:14101377ms step_avg:1622.53ms
step:8801/20000 train_time:14263238ms step_avg:1622.48ms
step:8901/20000 train_time:14424787ms step_avg:1622.40ms
step:9000/20000 val_loss:2.2847 train_time:14584718ms step_avg:1622.33ms perplexity:9.8231 param_count:132,475,500
step:9001/20000 train_time:14586343ms step_avg:1622.33ms
step:9101/20000 train_time:14748024ms step_avg:1622.27ms
step:9201/20000 train_time:14909378ms step_avg:1622.17ms
step:9301/20000 train_time:15071543ms step_avg:1622.17ms
step:9401/20000 train_time:15233303ms step_avg:1622.12ms
step:9500/20000 val_loss:2.2848 train_time:15393435ms step_avg:1622.07ms perplexity:9.8233 param_count:132,475,500
step:9501/20000 train_time:15395046ms step_avg:1622.07ms
step:9601/20000 train_time:15556646ms step_avg:1622.00ms
step:9701/20000 train_time:15718263ms step_avg:1621.94ms
step:9801/20000 train_time:15879854ms step_avg:1621.88ms
step:9901/20000 train_time:16041560ms step_avg:1621.83ms
step:10000/20000 val_loss:2.2755 train_time:16202104ms step_avg:1621.83ms perplexity:9.7327 param_count:132,475,500
step:10001/20000 train_time:16203725ms step_avg:1621.83ms
step:10101/20000 train_time:16365378ms step_avg:1621.78ms
step:10201/20000 train_time:16527156ms step_avg:1621.74ms
step:10301/20000 train_time:16689092ms step_avg:1621.72ms
step:10401/20000 train_time:16850905ms step_avg:1621.68ms
step:10500/20000 val_loss:2.2761 train_time:17011085ms step_avg:1621.65ms perplexity:9.7387 param_count:132,475,500
step:10501/20000 train_time:17012708ms step_avg:1621.65ms
step:10601/20000 train_time:17174380ms step_avg:1621.60ms
step:10701/20000 train_time:17336194ms step_avg:1621.57ms
step:10801/20000 train_time:17498650ms step_avg:1621.60ms
step:10901/20000 train_time:17660439ms step_avg:1621.56ms
step:11000/20000 val_loss:2.2742 train_time:17820759ms step_avg:1621.54ms perplexity:9.7204 param_count:132,475,500
step:11001/20000 train_time:17822384ms step_avg:1621.54ms
step:11101/20000 train_time:17984105ms step_avg:1621.50ms
step:11201/20000 train_time:18146023ms step_avg:1621.48ms
step:11301/20000 train_time:18307985ms step_avg:1621.47ms
step:11401/20000 train_time:18469755ms step_avg:1621.43ms
step:11500/20000 val_loss:2.2779 train_time:18629933ms step_avg:1621.40ms perplexity:9.7565 param_count:132,475,500
step:11501/20000 train_time:18631555ms step_avg:1621.40ms
step:11601/20000 train_time:18793981ms step_avg:1621.43ms
step:11701/20000 train_time:18955843ms step_avg:1621.40ms
step:11801/20000 train_time:19117525ms step_avg:1621.37ms
step:11901/20000 train_time:19279107ms step_avg:1621.32ms
step:12000/20000 val_loss:2.2660 train_time:19439270ms step_avg:1621.29ms perplexity:9.6412 param_count:132,475,500
step:12001/20000 train_time:19440910ms step_avg:1621.29ms
step:12101/20000 train_time:19602814ms step_avg:1621.27ms
step:12201/20000 train_time:19764702ms step_avg:1621.25ms
step:12301/20000 train_time:19926460ms step_avg:1621.22ms
step:12401/20000 train_time:20088684ms step_avg:1621.23ms
step:12500/20000 val_loss:2.2693 train_time:20248868ms step_avg:1621.21ms perplexity:9.6727 param_count:132,475,500
step:12501/20000 train_time:20250505ms step_avg:1621.21ms
step:12601/20000 train_time:20412240ms step_avg:1621.18ms
step:12701/20000 train_time:20574194ms step_avg:1621.16ms
step:12801/20000 train_time:20736042ms step_avg:1621.14ms
step:12901/20000 train_time:20897931ms step_avg:1621.13ms
step:13000/20000 val_loss:2.2511 train_time:21058237ms step_avg:1621.11ms perplexity:9.4978 param_count:132,475,500
step:13001/20000 train_time:21059859ms step_avg:1621.11ms
step:13101/20000 train_time:21222421ms step_avg:1621.15ms
step:13201/20000 train_time:21384348ms step_avg:1621.13ms
step:13301/20000 train_time:21546287ms step_avg:1621.12ms
step:13401/20000 train_time:21708415ms step_avg:1621.12ms
step:13500/20000 val_loss:2.2601 train_time:21868551ms step_avg:1621.09ms perplexity:9.5841 param_count:132,475,500
step:13501/20000 train_time:21870166ms step_avg:1621.09ms
step:13601/20000 train_time:22032072ms step_avg:1621.08ms
step:13701/20000 train_time:22194055ms step_avg:1621.07ms
step:13801/20000 train_time:22356077ms step_avg:1621.06ms
step:13901/20000 train_time:22518692ms step_avg:1621.10ms
step:14000/20000 val_loss:2.2587 train_time:22678967ms step_avg:1621.08ms perplexity:9.5711 param_count:132,475,500
step:14001/20000 train_time:22680592ms step_avg:1621.08ms
step:14101/20000 train_time:22842614ms step_avg:1621.08ms
step:14201/20000 train_time:23004506ms step_avg:1621.06ms
step:14301/20000 train_time:23166430ms step_avg:1621.05ms
step:14401/20000 train_time:23328362ms step_avg:1621.04ms
step:14500/20000 val_loss:2.2495 train_time:23488715ms step_avg:1621.03ms perplexity:9.4829 param_count:132,475,500
step:14501/20000 train_time:23490346ms step_avg:1621.03ms
step:14601/20000 train_time:23652268ms step_avg:1621.02ms
step:14701/20000 train_time:23814533ms step_avg:1621.03ms
step:14801/20000 train_time:23976471ms step_avg:1621.02ms
step:14901/20000 train_time:24138505ms step_avg:1621.01ms
step:15000/20000 val_loss:2.2499 train_time:24298763ms step_avg:1621.00ms perplexity:9.4867 param_count:132,475,500
step:15001/20000 train_time:24300372ms step_avg:1621.00ms
step:15101/20000 train_time:24462593ms step_avg:1621.01ms
step:15201/20000 train_time:24624615ms step_avg:1621.00ms
step:15301/20000 train_time:24786558ms step_avg:1620.99ms
step:15401/20000 train_time:24948758ms step_avg:1621.00ms
step:15500/20000 val_loss:2.2460 train_time:25109614ms step_avg:1621.02ms perplexity:9.4502 param_count:132,475,500
step:15501/20000 train_time:25111237ms step_avg:1621.02ms
step:15601/20000 train_time:25273382ms step_avg:1621.02ms
step:15701/20000 train_time:25435500ms step_avg:1621.02ms
step:15801/20000 train_time:25597629ms step_avg:1621.03ms
step:15901/20000 train_time:25759864ms step_avg:1621.03ms
step:16000/20000 val_loss:2.2268 train_time:25920519ms step_avg:1621.05ms perplexity:9.2706 param_count:132,475,500
step:16001/20000 train_time:25922152ms step_avg:1621.05ms
step:16101/20000 train_time:26084394ms step_avg:1621.05ms
step:16201/20000 train_time:26247000ms step_avg:1621.09ms
step:16301/20000 train_time:26409353ms step_avg:1621.10ms
step:16401/20000 train_time:26571336ms step_avg:1621.09ms
step:16500/20000 val_loss:2.2311 train_time:26731635ms step_avg:1621.08ms perplexity:9.3101 param_count:132,475,500
step:16501/20000 train_time:26733262ms step_avg:1621.08ms
step:16601/20000 train_time:26895432ms step_avg:1621.09ms
step:16701/20000 train_time:27057371ms step_avg:1621.08ms
step:16801/20000 train_time:27219432ms step_avg:1621.07ms
step:16901/20000 train_time:27381542ms step_avg:1621.07ms
step:17000/20000 val_loss:2.2349 train_time:27542405ms step_avg:1621.10ms perplexity:9.3455 param_count:132,475,500
step:17001/20000 train_time:27544041ms step_avg:1621.10ms
step:17101/20000 train_time:27706091ms step_avg:1621.09ms
step:17201/20000 train_time:27868329ms step_avg:1621.10ms
step:17301/20000 train_time:28030660ms step_avg:1621.11ms
step:17401/20000 train_time:28192844ms step_avg:1621.12ms
step:17500/20000 val_loss:2.2328 train_time:28353537ms step_avg:1621.13ms perplexity:9.3260 param_count:132,475,500
step:17501/20000 train_time:28355182ms step_avg:1621.13ms
step:17601/20000 train_time:28517423ms step_avg:1621.14ms
step:17701/20000 train_time:28679555ms step_avg:1621.14ms
step:17801/20000 train_time:28842326ms step_avg:1621.18ms
step:17901/20000 train_time:29004621ms step_avg:1621.19ms
step:18000/20000 val_loss:2.2263 train_time:29165526ms step_avg:1621.21ms perplexity:9.2656 param_count:132,475,500
step:18001/20000 train_time:29167164ms step_avg:1621.21ms
step:18101/20000 train_time:29329293ms step_avg:1621.21ms
step:18201/20000 train_time:29491678ms step_avg:1621.22ms
step:18301/20000 train_time:29653970ms step_avg:1621.23ms
step:18401/20000 train_time:29816314ms step_avg:1621.24ms
step:18500/20000 val_loss:2.2311 train_time:29977086ms step_avg:1621.26ms perplexity:9.3103 param_count:132,475,500
step:18501/20000 train_time:29978708ms step_avg:1621.26ms
step:18601/20000 train_time:30141332ms step_avg:1621.29ms
step:18701/20000 train_time:30303551ms step_avg:1621.29ms
step:18801/20000 train_time:30466007ms step_avg:1621.31ms
step:18901/20000 train_time:30628345ms step_avg:1621.32ms
step:19000/20000 val_loss:2.2328 train_time:30789160ms step_avg:1621.34ms perplexity:9.3259 param_count:132,475,500
step:19001/20000 train_time:30790789ms step_avg:1621.34ms
step:19101/20000 train_time:30953194ms step_avg:1621.35ms
step:19201/20000 train_time:31115625ms step_avg:1621.37ms
step:19301/20000 train_time:31278646ms step_avg:1621.41ms
step:19401/20000 train_time:31440973ms step_avg:1621.42ms
step:19500/20000 val_loss:2.2125 train_time:31601897ms step_avg:1621.44ms perplexity:9.1387 param_count:132,475,500
step:19501/20000 train_time:31603543ms step_avg:1621.44ms
step:19601/20000 train_time:31765993ms step_avg:1621.46ms
step:19701/20000 train_time:31928333ms step_avg:1621.47ms
step:19801/20000 train_time:32090808ms step_avg:1621.48ms
step:19901/20000 train_time:32253015ms step_avg:1621.49ms
step:20000/20000 val_loss:2.2137 train_time:32413832ms step_avg:1621.50ms perplexity:9.1496 param_count:132,475,500
peak memory consumption training: 42 GiB
Test results | Loss: 2.2093 | Perplexity: 9.1096
Total train time (min): 540.23
Total train time (hours): 9.00
peak memory consumption testing: 42 GiB
