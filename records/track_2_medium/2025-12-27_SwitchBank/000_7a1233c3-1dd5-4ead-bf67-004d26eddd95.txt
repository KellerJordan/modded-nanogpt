wandb logging enabled.
===== /home/ubuntu/switch-bank/train_switch_bank.py =====\n# ========== train_switch_bank.py ==========

import csv
import json
import os
import sys
from pathlib import Path

def _read_text(path: Path) -> str:
    try:
        return path.read_text()
    except Exception:
        return ""

def _build_code() -> str:
    code_paths = [
        Path(__file__).resolve(),
        Path("switch_bank/utils.py"),
        Path("switch_bank/optim/muon.py"),
        Path("switch_bank/model/components.py"),
        Path("switch_bank/model/gpt.py"),
        Path("switch_bank/data.py"),
        Path("switch_bank/trainer.py"),
    ]
    code_parts = []
    for p in code_paths:
        if p.exists():
            code_parts.append(f"===== {p} =====\\n{_read_text(p)}")
    return "\\n\\n".join(code_parts)

code = _build_code()
import uuid
import copy
from dataclasses import dataclass
from switch_bank.utils import compute_train_micro_len
from switch_bank.optim.muon import Muon
from switch_bank.model.components import CausalSelfAttention
from switch_bank.model.gpt import GPT
from switch_bank.data import summarize_router_metrics, summarize_expert_usage, summarize_expert_activity, \
    router_summary_str, distributed_data_generator
from switch_bank import trainer

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
import torch._functorch.config
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import nn
import torch.distributed as dist
torch._inductor.config.coordinate_descent_tuning = True   # allowed for medium track; false for rocm / single-GPU
torch._functorch.config.donated_buffer = False
torch._dynamo.config.compiled_autograd = False  # torch nightly build issue??


#
# -----------------------------------------------------------------------------
# The main model
# -----------------------------------------------------------------------------

# ----- Parameter accounting / logging -----
def _num_params(tensors_iter):
    return sum(p.numel() for p in tensors_iter)

def _unique_params(params):
    seen = set()
    unique = []
    for p in params:
        pid = id(p)
        if pid in seen:
            continue
        seen.add(pid)
        unique.append(p)
    return unique

def _fmt(n: int) -> str:
    return f"{n:,} ({n/1e6:.3f}M)"

@torch.no_grad()
def log_param_counts(model: nn.Module, args, print_fn) -> None:
    #if not args.enable_extra_logging:
    #    return
    # totals
    total = _num_params(model.parameters())

    # attention stack: merged QKV/out per block that has attention
    attn_params = []
    attn_layers = 0
    for b in model.blocks:
        if isinstance(b.attn, CausalSelfAttention):
            attn_params.append(b.attn.qkvo_w)
            attn_layers += 1
    attn_total = _num_params(_unique_params(attn_params))

    # FFN bank: experts + routers
    bank_expert_params = list(model.bank.W1) + list(model.bank.W2)
    bank_router_params = list(model.bank.router_w) + list(model.bank.router_b)
    bank_expert_total = _num_params(bank_expert_params)
    bank_router_total = _num_params(bank_router_params)
    bank_total = bank_expert_total + bank_router_total

    # embeddings: tied token embedding + N value-embedding tables
    tok_embed_total = _num_params(model.embed.parameters())
    ve_total = sum(_num_params(ve.parameters()) for ve in model.value_embeds)
    embeds_total = tok_embed_total + ve_total

    # lm head (if untied / instantiated)
    head_total = _num_params([model.lm_head]) if model.lm_head is not None else 0

    # scalars (skip lambdas / SA lambdas / skip weights)
    scalars_total = model.scalars.numel()

    adapter_total = 0
    if getattr(model.bank, "use_adapters", False):
        adapter_total = model.bank.adapter_scale.numel() + model.bank.adapter_bias.numel()

    # anything unaccounted (should be ~0; keeps us honest)
    accounted = attn_total + bank_total + embeds_total + head_total + scalars_total + adapter_total
    other_total = total - accounted

    # pretty print
    print_fn("=== Parameter counts ===", console=True)
    print_fn(f"model total:           {_fmt(total)}", console=True)
    print_fn(f"  attention stack ({attn_layers} of {args.num_layers} layers run attention): {_fmt(attn_total)}", console=True)
    print_fn(f"  FFN bank total:      {_fmt(bank_total)}", console=True)
    print_fn(f"    ├─ experts W1/W2:  {_fmt(bank_expert_total)}", console=True)
    print_fn(f"    └─ routers:        {_fmt(bank_router_total)}", console=True)
    print_fn(f"  embeddings (tok + {model.num_value_embeds}× value): {_fmt(embeds_total)}", console=True)
    print_fn(f"    └─ token embed:    {_fmt(tok_embed_total)}", console=True)
    print_fn(f"    └─ value embeds:   {_fmt(ve_total)}", console=True)
    if head_total:
        tied_state = "tied" if model._head_tied_runtime else "untied"
        print_fn(f"  lm head ({tied_state}):   {_fmt(head_total)}", console=True)
    if adapter_total:
        print_fn(f"  adapters:            {_fmt(adapter_total)}", console=True)
    print_fn(f"  scalars:             {_fmt(scalars_total)}", console=True)
    if other_total != 0:
        print_fn(f"  other (unclassified): {_fmt(other_total)}", console=True)
    print_fn("="*100, console=False)

# -----------------------------------------------------------------------------
# int main
# -----------------------------------------------------------------------------

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin"
    val_files = "data/fineweb10B/fineweb_val_*.bin"
    val_tokens = 10485760
    val_tokens_intermediate: int | None = 32768 * 7
    val_tokens_final: int | None = 10485760
    train_seq_len = 12*1024 #64*1024          # effective tokens per optimizer step per rank
    val_seq_len = 8192 #4*64*1024
    # minibatch / gradient accumulation
    grad_accum_steps = 1 # default=1 keeps original, multi-GPU behavior
    train_micro_seq_len: int | None = None  # if None, computed as train_seq_len // grad_accum_steps
    # optimization
    num_iterations = 1750
    early_stop_step: int | None = None
    cooldown_frac = 0.65  #0.7
    lr_final_mult = 0.0  # decay to this % of original lr at final iteration
    lr_freeze_last_steps = 0 # decay toward lr_final_mult at final step, but freeze lr at num_iterations-lr_freeze_last_steps
    lr_embed = 0.3
    lr_scalar = 0.015
    lr_head = 1/320
    lr_router = 0.095
    lr_adapter = 0.03
    lr_muon = 0.025
    router_grad_clip_norm = 0.0
    router_autoclip = True
    # Muon optimizer parameters (see switch_bank/optim/muon.py)
    muon_betas: tuple[float, float] = (0.8, 0.95)
    muon_eps: float = 1e-10
    muon_weight_decay: float = 0.0
    muon_momentum: float = 0.95
    muon_ns_iters: int = 4
    use_turbo_muon: bool = True
    turbo_muon_warmstart_smax_start_frac: float = -1 #0.725  # <0 disables; >=0 enables warm-started sigma-max (near end)
    # architecture
    vocab_size = 50257
    model_dim = 896
    num_layers = 28
    # Layer weight tying (attention + router adapters). Set to () to disable. Avoid tying layers with different attention types (short/long).
    layer_tie_groups: tuple[tuple[int, ...], ...] = (
        #(9, 10), (13, 14), (17, 18), (21, 22), (25, 26),  # Add 5,6 if need more. Remove from the beginning for fewer.
        #(17, 18), (21, 22), (25, 26),
    )
    head_dim = 128
    num_heads = model_dim // head_dim #7
    # value-embeddings integer count: 0, 1, 2, or 3 supported.
    num_value_embeds = 2
    tie_lm_head = False
    untie_lm_head_frac = -1.0
    # Bank / routing
    num_experts = 8 #9
    ffn_hidden = 1024
    topk = 1
    topk_val: int | None = None
    lb_coeff = 2.15e-3
    router_entropy_coeff = 2.5e-3  # coefficient for router entropy aux loss component
    use_router_adapters = True
    router_block_pos_bins = 8  # 4 / 8 / 16
    first_doc_tokens_N = 64
    router_enable_forward_ema = False
    router_enable_reverse_ema = True
    ema_alpha_fwd = 0.80
    ema_alpha_rev = 0.85
    ema_window_size_fwd = 128  # <=0 means full sequence
    ema_block_size_fwd = 128
    ema_window_size_rev = 384
    ema_block_size_rev = 384
    router_ema_layer_stride = -1  # How often to calculate fresh EMAs (which are then used by the next N-1 layers).  N < 0 -> num_layers (one shared EMA calculation for all layers).
    # Parameter freezing
    router_freeze_frac = 1.0
    router_freeze_adapters = False
    router_lr_reduce_start_frac = -1.0
    shared_ffn_freeze_frac = 1.0
    shared_ffn_lr_reduce_start_frac = -1.0
    # skip-attention layers (short-SWA) — exactly two
    skip_attn_layers = (11,)  # (7,)
    expert_activation_schedule: tuple[tuple[int, int], ...] = ((0, 1), (75, 2), (141, 3), (234, 4), (338, 5), (441, 6), (591, 7), (695, 8),)     #((0, 1), (200, 2), (375, 3), (625, 4), (900, 5), (1175, 6), (1575, 7), (1850, 8),) # (2175, 9))
    router_temp_init = 1.464
    router_temp_final = 0.93744
    router_temp_power = 1.5  # fallback if anchor disabled
    router_temp_anchor_delta_steps = 284 #756  # steps after 2nd expert activation to hit anchor ratio
    router_temp_anchor_ratio = 0.49  # temp curve hits this ratio at anchor delta
    router_logit_cap_initial = 1.166
    router_logit_cap_final = 13.757
    router_logit_cap_delta_steps = 237 #632  # ramp length after second expert activation
    # Optional Gumbel exploration (off by default)
    router_use_gumbel = True
    router_gumbel_schedule: tuple[tuple[int, int], ...] = ((75, 441), (459, 488), (534, 722), (900, 909), (1004, 1022), (1097, 1107), (1200, 1209), (1284, 1313), (1472, 1500))       #((200, 1175), (1225, 1300), (1425, 1925),) # (2400, 2425), (2675, 2725), (2925, 2950), (3200, 3225), ) #(3425, 3500), (3925, -1))
    # Layerwise router temp & lb boosts.
    router_boost_shape = "peak"  # options: peak (default), valley, linear_start, linear_end
    router_temp_boost = 0.2
    router_lb_boost = 0.5
    router_layer_peak_frac = 0.475  # only used for peak or valley shapes. boosts are calculated continuously
    # evaluation and logging
    val_loss_every = 50  # 0 for only at end
    save_final_checkpoint = True
    save_final_checkpoint_if_loss_below: bool = True
    save_final_checkpoint_max_loss: float = 2.92
    checkpoint_save_step: int = -1  # -1 disables mid-training save
    resume_checkpoint: str | None = None
    log_dir: str = "records/track_2_medium/2025-12-27_SwitchBank"
    use_wandb = True
    wandb_project = "switch-bank-final"
    wandb_run_name = ""
    wandb_log_every = 1
    enable_extra_logging = False
    enable_extra_wandb_logging = False
    do_model_warmup = True
    metrics_log_every = 25


def _coerce_override(value, current):
    if current is None:
        return value
    if isinstance(current, bool):
        return bool(value)
    if isinstance(current, int) and not isinstance(current, bool):
        return int(value)
    if isinstance(current, float):
        return float(value)
    if isinstance(current, tuple):
        if isinstance(value, (list, tuple)):
            return tuple(value)
    return value


def _apply_overrides(args, overrides: dict, source: str) -> None:
    for key, value in overrides.items():
        if not hasattr(args, key):
            raise KeyError(f"Unknown Hyperparameters override '{key}' from {source}")
        current = getattr(args, key)
        coerced = _coerce_override(value, current)
        setattr(args, key, coerced)


def _parse_overrides_env() -> dict:
    raw = os.environ.get("SWB_OVERRIDES_JSON") or os.environ.get("SWITCH_BANK_OVERRIDES_JSON")
    if not raw:
        return {}
    try:
        data = json.loads(raw)
    except json.JSONDecodeError as exc:
        raise ValueError(f"Failed to parse overrides JSON: {exc}") from exc
    if not isinstance(data, dict):
        raise ValueError("Overrides JSON must be an object/dict")
    return data


def _reset_runtime_state(model: nn.Module) -> None:
    base_model = getattr(model, "_orig_mod", model)
    for name, value in (
        ("_router_frozen_logged", False),
        ("_ffn_frozen_logged", False),
        ("_last_active_expert_count", None),
        ("_pending_active_count", None),
    ):
        if hasattr(base_model, name):
            setattr(base_model, name, value)


def _set_seed(seed: int | None) -> None:
    if seed is None:
        return
    import random
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def run_training(
    overrides: dict | None = None,
    single_gpu: bool = False,
    early_stop_step: int | None = None,
    early_stop_val_multiplier: int = 1,
    reuse_state: dict | None = None,
    results_path: str | None = None,
    destroy_process_group: bool = True,
    seed: int | None = None,
):
    args = Hyperparameters()
    env_overrides = _parse_overrides_env()
    if env_overrides:
        _apply_overrides(args, env_overrides, "env")
    if overrides:
        _apply_overrides(args, overrides, "call")
    if args.router_ema_layer_stride < 0:
        args.router_ema_layer_stride = args.num_layers
    _set_seed(seed)
    early_stop_is_final = False
    if early_stop_step is None:
        early_stop_step = getattr(args, "early_stop_step", None)
        if early_stop_step is not None:
            early_stop_is_final = True

    def hyperparams_to_config(h: Hyperparameters) -> dict:
        cfg: dict[str, object] = {}
        for name in dir(h):
            if name.startswith("_"):
                continue
            value = getattr(h, name)
            if callable(value):
                continue
            cfg[name] = value
        return cfg

    untie_lm_head_after = -1
    if args.tie_lm_head and args.untie_lm_head_frac is not None and args.untie_lm_head_frac >= 0:
        untie_lm_head_after = int(args.untie_lm_head_frac * args.num_iterations)
        untie_lm_head_after = min(max(untie_lm_head_after, 0), args.num_iterations)

    if single_gpu:
        os.environ.setdefault("RANK", "0")
        os.environ.setdefault("WORLD_SIZE", "1")
        os.environ.setdefault("LOCAL_RANK", "0")
        os.environ.setdefault("MASTER_ADDR", "127.0.0.1")
        os.environ.setdefault("MASTER_PORT", "29500")
    run_id = int(os.environ.get("RUN_ID", 0))
    import torch
    assert torch.cuda.is_available()
    if dist.is_initialized():
        rank = dist.get_rank()
        world_size = dist.get_world_size()
    else:
        rank = int(os.environ.get("RANK", "0"))
        world_size = int(os.environ.get("WORLD_SIZE", "1"))
        device = torch.device("cuda", int(os.environ.get("LOCAL_RANK", "0")))
        torch.cuda.set_device(device)
        dist.init_process_group(backend="nccl", device_id=device)
    device = torch.device("cuda", int(os.environ.get("LOCAL_RANK", "0")))
    torch.cuda.set_device(device)
    dist.barrier()
    master_process = (rank == 0)
    run_id_full: str | None = None

    if master_process:
        run_id_full = f"{run_id:03d}_{uuid.uuid4()}"
        log_dir = args.log_dir
        os.makedirs(log_dir, exist_ok=True)
        logfile = os.path.join(log_dir, f"{run_id_full}.txt")
        print(logfile)
    def print0(s, console=False):
        if master_process:
            with open(logfile, "a") as f:
                if console:
                    print(s)
                print(s, file=f)

    # --- Robust Inductor trace hook (compatible with callsites with/without metadata_fn) ---
    from torch._logging._internal import trace_structured as _orig_trace_structured  # keep original
    import torch._inductor.codecache  # noqa: E402
    import torch._inductor.graph      # noqa: E402

    def _patched_trace_structured(name, *args, **kwargs):
        """
        Torch Inductor sometimes calls trace_structured(name, metadata_fn, **kwargs),
        and other times as trace_structured(name, **kwargs) with metadata_fn omitted.
        Be permissive and forward both forms. Also print compiled filename when available.
        """
        metadata_fn = kwargs.get("metadata_fn", None)
        if metadata_fn is None and len(args) > 0 and callable(args[0]):
            # first positional could be metadata_fn
            metadata_fn = args[0]
        try:
            if name == "inductor_output_code" and callable(metadata_fn):
                md = metadata_fn()
                filename = (md.get("filename", "Unknown") if isinstance(md, dict) else "Unknown")
                print0(f"inductor_output_code: {filename}")
        except Exception:
            # never let logging break compilation
            pass
        return _orig_trace_structured(name, *args, **kwargs)

    torch._inductor.codecache.trace_structured = _patched_trace_structured
    torch._inductor.graph.trace_structured = _patched_trace_structured
    # --- end robust hook ---

    wandb_run = None
    if args.use_wandb and os.environ.get("WANDB_DISABLED", "0").lower() not in ("1", "true", "yes") and master_process:
        wandb_reinit = os.environ.get("WANDB_REINIT", "0").lower() in ("1", "true", "yes")
        try:
            import wandb  # type: ignore
            wandb_run = wandb.init(
                project=args.wandb_project,
                config=hyperparams_to_config(args),
                reinit=wandb_reinit,
                #name=args.wandb_run_name or run_id_full or f"rank{rank}",
            )
            print0("wandb logging enabled.", console=True)
        except Exception as err:
            print0(f"wandb init failed ({err}); disabling wandb.", console=True)
            wandb_run = None

    metrics_csv_file = None
    metrics_csv_writer = None
    expert_usage_headers: list[str] = []
    expert_active_headers: list[str] = []
    if master_process and run_id_full is not None and args.enable_extra_logging:
        metrics_csv_path = os.path.join(args.log_dir, f"{run_id_full}_metrics.csv")
        metrics_csv_file = open(metrics_csv_path, "w", newline="")
        metrics_csv_writer = csv.writer(metrics_csv_file)
        expert_usage_headers = [f"expert_usage_e{i}" for i in range(args.num_experts)]
        expert_active_headers = [f"expert_active_e{i}" for i in range(args.num_experts)]
        router_ema_headers: list[str] = []
        if args.router_enable_forward_ema:
            router_ema_headers.append("router_ema_alpha_forward")
        if args.router_enable_reverse_ema:
            router_ema_headers.append("router_ema_alpha_reverse")
        metrics_csv_writer.writerow([
            "step", "loss", "loss_main", "loss_aux",
            "router_imp_cv2", "router_load_cv2", "router_usage_frac",
            "router_topk_prob_mean", *router_ema_headers, "router_max_logit",
            "logit_cap", "router_temp", "window_blocks", *expert_usage_headers, *expert_active_headers
        ])

    def log_metrics_row(step_value: int, avg_loss: float, avg_main: float, avg_aux: float,
                        router_summary: dict[str, float], logit_cap_value: float | None,
                        router_temp_value: float, window_blocks_value: int,
                        expert_usage: torch.Tensor | None,
                        expert_active: torch.Tensor | None):
        if metrics_csv_writer is None:
            return
        expert_usage_list = []
        if expert_usage is not None:
            expert_usage_list = [float(x) for x in expert_usage.tolist()]
        else:
            expert_usage_list = [float("nan")] * len(expert_usage_headers)
        expert_active_list = []
        if expert_active is not None:
            expert_active_list = [float(x) for x in expert_active.tolist()]
        else:
            expert_active_list = [float("nan")] * len(expert_active_headers)
        row = [
            step_value,
            avg_loss,
            avg_main,
            avg_aux,
            router_summary.get("imp_cv2", float("nan")),
            router_summary.get("load_cv2", float("nan")),
            router_summary.get("usage_frac", float("nan")),
            router_summary.get("topk_prob_mean", float("nan")),
        ]
        if args.router_enable_forward_ema:
            row.append(router_summary.get("ema_alpha_forward", float("nan")))
        if args.router_enable_reverse_ema:
            row.append(router_summary.get("ema_alpha_reverse", float("nan")))
        row.extend([
            router_summary.get("max_logit", float("nan")),
            (logit_cap_value if logit_cap_value is not None else float("nan")),
            router_temp_value,
            window_blocks_value,
        ])
        row.extend(expert_usage_list)
        row.extend(expert_active_list)
        metrics_csv_writer.writerow(row)

    print0(code)
    print0("="*100)
    print0(f"Running Python {sys.version}")
    print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
    def nvidia_smi():
        import subprocess
        try:
            return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
        except FileNotFoundError:
            return "nvidia-smi not available."
    print0(nvidia_smi())
    print0("="*100)

    shared_state = reuse_state if reuse_state is not None else {}
    model: nn.Module | None = shared_state.get("model")
    optimizers: list[torch.optim.Optimizer] | None = shared_state.get("optimizers")
    opt2params: dict | None = shared_state.get("opt2params")
    using_cached = model is not None and optimizers is not None and opt2params is not None

    ########################################
    #    Construct model and optimizer     #
    ########################################

    if not using_cached:
        model: nn.Module = GPT(
            vocab_size=args.vocab_size,
            num_layers=args.num_layers,
            num_heads=args.num_heads,
            model_dim=args.model_dim,
            max_seq_len=max(args.train_seq_len, args.val_seq_len),
            skip_attn_layers=set(args.skip_attn_layers),
            layer_tie_groups=tuple(args.layer_tie_groups) if args.layer_tie_groups is not None else tuple(),
            E=args.num_experts,
            h=args.ffn_hidden,
            lb_coeff=args.lb_coeff,
            ent_coeff=args.router_entropy_coeff,
            k=args.topk,
            num_value_embeds=args.num_value_embeds,
            tie_lm_head=args.tie_lm_head,
            untie_lm_head_after=untie_lm_head_after,
            ema_alpha_fwd=args.ema_alpha_fwd,
            ema_alpha_rev=args.ema_alpha_rev,
            router_temp_init=args.router_temp_init,
            router_temp_final=args.router_temp_final,
            router_temp_power=args.router_temp_power,
            router_temp_anchor_delta_steps=args.router_temp_anchor_delta_steps,
            router_temp_anchor_ratio=args.router_temp_anchor_ratio,
            router_logit_cap_initial=args.router_logit_cap_initial,
            router_logit_cap_final=args.router_logit_cap_final,
            router_logit_cap_delta_steps=args.router_logit_cap_delta_steps,
            router_layer_peak_frac=args.router_layer_peak_frac,
            router_temp_boost=args.router_temp_boost,
            router_lb_boost=args.router_lb_boost,
            router_boost_shape=args.router_boost_shape,
            use_router_adapters=args.use_router_adapters,
            expert_activation_schedule=args.expert_activation_schedule,
            router_freeze_frac=args.router_freeze_frac,
            router_freeze_adapters=args.router_freeze_adapters,
            ema_block_size_fwd=args.ema_block_size_fwd,
            ema_block_size_rev=args.ema_block_size_rev,
            ema_window_size_fwd=args.ema_window_size_fwd,
            ema_window_size_rev=args.ema_window_size_rev,
            ema_layer_stride=args.router_ema_layer_stride,
            shared_ffn_freeze_frac=args.shared_ffn_freeze_frac,
            router_use_gumbel=args.router_use_gumbel,
            router_gumbel_schedule=args.router_gumbel_schedule,
            router_block_pos_bins=args.router_block_pos_bins,
            first_doc_tokens_N=args.first_doc_tokens_N,
            router_enable_forward_ema=args.router_enable_forward_ema,
            router_enable_reverse_ema=args.router_enable_reverse_ema,
            extra_console_logging=args.enable_extra_logging,
            extra_wandb_logging=args.enable_extra_wandb_logging,
            print_fn=print0,
        ).cuda()

        for m in model.modules():
            if isinstance(m, nn.Embedding):
                m.bfloat16()
        for param in model.parameters():
            dist.broadcast(param.detach(), 0)

        log_param_counts(model, args, print0)

        # collect the parameters to optimize
        # ### FFNBANK MOD: include bank expert matrices in Muon spectral groups;
        # non-spectral params (routers/embeds/scalars/head/adapters) use AdamW branch.
        def is_2d(p: nn.Parameter) -> bool:
            return p.ndim >= 2

        attn_2d_params = []
        for b in model.blocks:
            if isinstance(b.attn, CausalSelfAttention):
                attn_2d_params.append(b.attn.qkvo_w)
        attn_2d_params = _unique_params(attn_2d_params)
        ffn_matrix_params = [*model.bank.W1, *model.bank.W2]
        hidden_matrix_params = attn_2d_params + ffn_matrix_params

        embed_params = [*model.embed.parameters(), *model.value_embeds.parameters()]
        head_params: list[nn.Parameter] = [model.lm_head] if model.lm_head is not None else []
        adapter_params = []
        if model.bank.use_adapters:
            adapter_params.extend([model.bank.adapter_scale, model.bank.adapter_bias])
        scalar_params = [model.scalars]
        router_params = list(model.bank.router_w) + list(model.bank.router_b)

        # sanity / completeness checks
        params_collections = [hidden_matrix_params, embed_params, head_params, adapter_params, scalar_params, router_params]
        optimized_parameters_set = {p for params in params_collections for p in params}
        assert optimized_parameters_set == {*model.parameters()}
        assert len(optimized_parameters_set) == sum(len(lst) for lst in params_collections)

        # init the optimizer(s)
        muon_param_groups: list[dict] = [
            dict(params=embed_params, lr=args.lr_embed, component="embed", spectral=False),
            dict(params=scalar_params, lr=args.lr_scalar, component="scalar", spectral=False),
            dict(params=router_params, lr=args.lr_router, component="router", spectral=False),
        ]
        if adapter_params:
            muon_param_groups.append(dict(params=adapter_params, lr=args.lr_adapter, component="adapter", spectral=False))
        if head_params:
            muon_param_groups.append(dict(params=head_params, lr=args.lr_head, component="head", spectral=False))
        if attn_2d_params:
            muon_param_groups.append(dict(params=attn_2d_params, lr=args.lr_muon, component="attention", spectral=True))
        if ffn_matrix_params:
            muon_param_groups.append(dict(params=ffn_matrix_params, lr=args.lr_muon, component="shared_ffn", spectral=True))

        optimizer = Muon(
            muon_param_groups,
            lr=args.lr_muon,  # default lr for spectral groups; overridden per-group above
            betas=tuple(args.muon_betas),
            eps=float(args.muon_eps),
            weight_decay=float(args.muon_weight_decay),
            muon_momentum=float(args.muon_momentum),
            lr_spec=None,
            ns_iters=int(args.muon_ns_iters),
            rank=rank,
            world_size=world_size,
            enable_turbomuon=bool(args.use_turbo_muon),
        )
        optimizers: list[torch.optim.Optimizer] = [optimizer]
        def opt_params(opt: torch.optim.Optimizer) -> list[nn.Parameter]:
            return [p for group in opt.param_groups for p in group["params"]]
        opt2params = {opt: opt_params(opt) for opt in optimizers}
        for opt in optimizers:
            for group in opt.param_groups:
                group["initial_lr"] = group["lr"]

    if not using_cached and reuse_state is not None:
        shared_state["model"] = model
        shared_state["optimizers"] = optimizers
        shared_state["opt2params"] = opt2params
    if using_cached:
        model = shared_state["model"]
        optimizers = shared_state["optimizers"]
        opt2params = shared_state["opt2params"]
        base_model = getattr(model, "_orig_mod", model)
        for key in (
            "router_temp_init",
            "router_temp_final",
            "router_temp_power",
            "router_temp_anchor_delta_steps",
            "router_temp_anchor_ratio",
            "router_logit_cap_initial",
            "router_logit_cap_final",
            "router_logit_cap_delta_steps",
            "router_use_gumbel",
            "router_gumbel_schedule",
            "router_temp_boost",
            "router_lb_boost",
            "router_layer_peak_frac",
            "router_boost_shape",
        ):
            if hasattr(base_model, key):
                setattr(base_model, key, getattr(args, key))
        if hasattr(base_model, "extra_console_logging"):
            base_model.extra_console_logging = bool(args.enable_extra_logging)
        if hasattr(base_model, "extra_wandb_logging"):
            base_model.extra_wandb_logging = bool(args.enable_extra_wandb_logging)
        if hasattr(base_model, "_print0"):
            base_model._print0 = print0
        if hasattr(base_model, "bank") and hasattr(base_model.bank, "enable_extra_wandb_logging"):
            base_model.bank.enable_extra_wandb_logging = bool(args.enable_extra_wandb_logging)
        _reset_runtime_state(model)
    start_step = 0
    resume_path = args.resume_checkpoint
    if resume_path:
        print0(f"Loading checkpoint from {resume_path}", console=True)
        checkpoint = torch.load(resume_path, map_location="cuda")
        model_state = checkpoint.get("model", {})
        if all(k.startswith("_orig_mod.") for k in model_state.keys()):
            model_state = {k.removeprefix("_orig_mod."): v for k, v in model_state.items()}
        args.approx_step_time_ms = float(checkpoint.get("approx_step_time_ms", 0))
        meta = checkpoint.get("meta", {}) or {}
        meta_checks = {
            "model_dim": args.model_dim,
            "num_layers": args.num_layers,
            "num_heads": args.num_heads,
            "num_experts": args.num_experts,
            "ffn_hidden": args.ffn_hidden,
            "vocab_size": args.vocab_size,
        }
        for key, current_val in meta_checks.items():
            saved_val = meta.get(key, current_val)
            assert saved_val == current_val, f"Checkpoint {key}={saved_val} does not match current args ({current_val})"
        model.load_state_dict(model_state)
        ckpt_opts = checkpoint.get("optimizers", [])
        assert len(ckpt_opts) == len(optimizers), "Optimizer count mismatch in checkpoint."
        for opt, state in zip(optimizers, ckpt_opts):
            opt.load_state_dict(state)
            for group in opt.param_groups:
                group.setdefault("initial_lr", group.get("lr", 0.0))
            # ensure Muon state dtypes survive checkpoint reload
            if isinstance(opt, Muon):
                for p, st in opt.state.items():
                    if not st:
                        continue
                    if "mantissa" in st and st["mantissa"].dtype != torch.uint16:
                        st["mantissa"] = st["mantissa"].to(dtype=torch.uint16)
                    if "momentum_buffer" in st and st["momentum_buffer"].dtype != torch.float32:
                        st["momentum_buffer"] = st["momentum_buffer"].to(dtype=torch.float32)
        start_step = int(checkpoint.get("step", -1)) + 1
        assert start_step >= 0, "Invalid checkpoint step."
        assert start_step <= args.num_iterations, "Checkpoint step exceeds configured num_iterations."
        print0(f"Resumed from checkpoint at step {start_step - 1}. Continuing from step {start_step}.", console=True)
        dist.barrier()

    if using_cached and shared_state.get("base_state") is not None and not resume_path:
        base_state = shared_state["base_state"]
        model.load_state_dict(base_state["model"])
        for opt, opt_state in zip(optimizers, base_state["optimizers"]):
            opt.load_state_dict(opt_state)
        _reset_runtime_state(model)

    for param in model.parameters():
        dist.broadcast(param.detach(), 0)

    if not using_cached:
        if not shared_state.get("compiled", False):
            print0("Compiling model...", console=True)
            model = torch.compile(model, dynamic=False)
            print0("Compile complete.", console=True)
        if reuse_state is not None:
            shared_state["model"] = model
            shared_state["compiled"] = True

    ########################################
    #            Warmup kernels            #
    ########################################

    train_micro_len = compute_train_micro_len(args.train_seq_len, args.grad_accum_steps, args.train_micro_seq_len)
    effective_train_tokens = train_micro_len * args.grad_accum_steps
    if effective_train_tokens != args.train_seq_len:
        print0(
            f"Adjusted train_micro_seq_len to {train_micro_len} (block-aligned). "
            f"Effective tokens per step: {effective_train_tokens} (requested {args.train_seq_len}).",
            console=True)

    warmup_needed = bool(args.do_model_warmup) and not shared_state.get("warmup_done", False)
    if warmup_needed and not using_cached:
        print0("Warming up kernels...", console=True)
        warmup_steps = 10
        initial_state = copy.deepcopy(dict(model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers]))
        warmup_loader = distributed_data_generator(
            args.train_files,
            world_size * train_micro_len,
            rank,
            world_size,
        )
        for warm_step in range(warmup_steps):
            model.zero_grad(set_to_none=True)
            for micro in range(args.grad_accum_steps):
                if micro == 0:
                    inputs, targets = next(warmup_loader)
                else:
                    inputs = targets = torch.randint(0, args.vocab_size, size=(train_micro_len,), device="cuda")
                outputs = model(inputs.to(torch.int32), targets, trainer.get_window_size_blocks(args, 0), 0, args.num_iterations)
                if isinstance(outputs, tuple):
                    loss_main, loss_aux = outputs
                    loss_val = float((loss_main + loss_aux).detach().item())
                    main_loss = float(loss_main.detach().item())
                    aux_loss = float(loss_aux.detach().item())
                    loss_total = (loss_main + loss_aux) / args.grad_accum_steps
                    loss_total.backward()
                else:
                    loss = outputs
                    loss_val = float(loss.detach().item())
                    components = model.latest_loss_components
                    main_loss = float(components[0].item()) if components else float("nan")
                    aux_loss = float(components[1].item()) if components else float("nan")
                    (loss / args.grad_accum_steps).backward()
                router_summary = summarize_router_metrics(model.latest_router_metrics or [])
                if args.enable_extra_logging:
                    print0(
                        f"[warmup {warm_step + 1}/{warmup_steps} micro {micro + 1}/{args.grad_accum_steps}] "
                        f"loss={loss_val:.6f} main={main_loss:.6f} aux={aux_loss:.6f} "
                        f"{router_summary_str(router_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
                        console=True)
            opt2futures = {
                opt: [dist.all_reduce(p.grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
                      for p in params if (p.grad is not None)]
                for opt, params in opt2params.items()
            }
            for opt in optimizers:
                torch.futures.collect_all(opt2futures[opt]).wait()
                opt.step()
            model.zero_grad(set_to_none=True)

        with torch.no_grad():
            model.bank.compile_warm_all_experts(d=args.model_dim, T_warm=128)

        with torch.no_grad():
            model.eval()
            val_inputs = torch.randint(0, args.vocab_size, size=(args.val_seq_len,), device="cuda")
            val_targets = torch.randint(0, args.vocab_size, size=(args.val_seq_len,), device="cuda")
            model(val_inputs.to(torch.int32), val_targets, trainer.get_window_size_blocks(args, 0), 0, args.num_iterations)
            model.train()


        model.load_state_dict(initial_state["model"])
        for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
            opt.load_state_dict(opt_state)
        if reuse_state is not None:
            shared_state["base_state"] = initial_state
            shared_state["warmup_done"] = True
        else:
            del initial_state
        print0("Kernel warmup complete.", console=True)

    if reuse_state is not None and shared_state.get("base_state") is None and not resume_path:
        shared_state["base_state"] = copy.deepcopy(
            dict(model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        )

    ########################################
    #        Training and validation       #
    ########################################

    torch.cuda.reset_peak_memory_stats()
    result = trainer.run_training(
        args=args,
        model=model,
        optimizers=optimizers,
        opt2params=opt2params,
        train_micro_len=train_micro_len,
        untie_lm_head_after=untie_lm_head_after,
        run_id_full=run_id_full,
        master_process=master_process,
        print0=print0,
        code=code,
        wandb_run=wandb_run,
        metrics_csv_writer=metrics_csv_writer,
        expert_usage_headers=expert_usage_headers,
        expert_active_headers=expert_active_headers,
        world_size=world_size,
        rank=rank,
        log_param_counts_fn=(lambda m: log_param_counts(m, args, print0)),
        start_step=start_step,
        checkpoint_save_step=args.checkpoint_save_step,
        early_stop_step=early_stop_step,
        early_stop_val_multiplier=early_stop_val_multiplier,
        early_stop_as_final=early_stop_is_final,
    )

    print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
        f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
    if master_process and results_path:
        payload = {"run_id": run_id_full}
        if isinstance(result, dict):
            payload.update(result)
        try:
            with open(results_path, "w") as f:
                json.dump(payload, f, indent=2, sort_keys=True)
        except Exception as err:
            print0(f"Failed to write results to {results_path}: {err}", console=True)
    if destroy_process_group and dist.is_initialized():
        dist.destroy_process_group()
    if wandb_run is not None:
        wandb_run.finish()
    if metrics_csv_file is not None:
        metrics_csv_file.close()
    return result

if __name__ == '__main__':
    run_training()
\n\n===== switch_bank/utils.py =====\nimport math
from functools import lru_cache
from typing import Iterable

import torch
from torch import Tensor
import torch.nn.functional as F


def _sanitize(t: Tensor, *, value: float = 0.0) -> Tensor:
    if torch.isfinite(t).all():
        return t
    return torch.nan_to_num(t, nan=value, posinf=value, neginf=value)


def _safe_softmax(logits: Tensor, dim: int) -> Tensor:
    logits = torch.nan_to_num(logits, nan=0.0, posinf=0.0)
    probs = logits.softmax(dim=dim)
    probs = _sanitize(probs)
    denom = probs.sum(dim=dim, keepdim=True).clamp_min(1e-6)
    return probs / denom


def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)


def rampdown_multiplier(progress: float, start_frac: float, end_frac: float) -> float:
    if end_frac < 0:
        return 1.0
    if progress >= end_frac:
        return 0.0
    if start_frac < 0 or start_frac >= end_frac:
        return 1.0
    if progress <= start_frac:
        return 1.0
    span = max(end_frac - start_frac, 1e-6)
    frac = 1.0 - (progress - start_frac) / span
    return min(max(frac, 0.0), 1.0)


def compute_train_micro_len(train_seq_len: int, grad_accum_steps: int, train_micro_seq_len: int | None) -> int:
    if train_micro_seq_len is not None:
        micro = train_micro_seq_len
    else:
        approx = max(train_seq_len // grad_accum_steps, 128)
        approx = (approx // 128) * 128
        if approx == 0:
            approx = 128
        micro = approx
    assert micro % 128 == 0, "train_micro_seq_len must be a multiple of 128 tokens (block size)"
    return micro


def summarize(values: Iterable[Tensor | float], reducer) -> dict:
    # Placeholder utility for potential future reductions; kept for parity with planned structure.
    return {}
\n\n===== switch_bank/optim/muon.py =====\nimport math
from typing import Any, Dict, Iterable, List, Optional, Tuple

import torch
import torch.distributed as dist
from torch import Tensor
from torch.optim import Optimizer

# Optional torch.compile compatibility
if hasattr(torch, "compile"):
    _compile = torch.compile
else:  # pragma: no cover
    def _compile(f):
        return f


def _as_full_prec_tensor(val: float, device: torch.device) -> Tensor:
    """
    Helper that mimics torch._as_tensor_fullprec where available, but safely
    falls back to a standard float32 tensor otherwise.
    """
    if hasattr(torch, "_as_tensor_fullprec"):
        # type: ignore[attr-defined]
        return torch._as_tensor_fullprec(val)  # pragma: no cover
    return torch.tensor(val, dtype=torch.float32, device=device)


def zeropower_via_newtonschulz5(G: Tensor) -> Tensor:
    """
    Reference Muon Newton–Schulz quintic iteration (unchanged).
    """
    assert G.ndim >= 2
    X = G.bfloat16()
    transposed = False
    if G.size(-2) > G.size(-1):
        X = X.mT
        transposed = True

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)

    # Quintic NS iterations
    for a, b, c in [
        (4.0848, -6.8946, 2.9270),
        (3.9505, -6.3029, 2.6377),
        (3.7418, -5.5913, 2.3037),
        (2.8769, -3.1427, 1.2046),
        (2.8366, -3.0525, 1.2012),
    ]:
        A = X @ X.mT
        B = b * A + c * (A @ A)
        X = a * X + B @ X

    if transposed:
        X = X.mT
    return X


@_compile
def _muon_update_kernel(
    acc_bf16_view_u16: Tensor,
    mantissa: Tensor,
    momentum_buffer: Tensor,
    grad: Tensor,
    momentum: Tensor,
    eff_lr: Tensor,
    eff_weight_decay: Tensor,
) -> None:
    """
    Bit-for-bit equivalent to the reference Muon update (kept intact).
    """
    assert acc_bf16_view_u16.dtype == mantissa.dtype == torch.uint16
    grad = grad.float()
    # Same two-step use of momentum as in the reference implementation
    momentum_buffer.copy_(momentum * momentum_buffer + (1 - momentum) * grad)
    v = zeropower_via_newtonschulz5(momentum * momentum_buffer + (1 - momentum) * grad)

    acc_m_u32 = (acc_bf16_view_u16.to(torch.uint32) << 16) | mantissa.to(torch.uint32)
    acc_view_f32 = acc_m_u32.view(torch.float32)
    acc_view_f32.mul_(1 - eff_weight_decay)
    acc_view_f32.add_(other=v, alpha=-eff_lr)
    acc_m_u32 = acc_view_f32.view(torch.uint32)
    acc_bf16_view_u16.copy_((acc_m_u32 >> 16).to(torch.uint16))
    mantissa.copy_(acc_m_u32.to(torch.uint16))


def power_iteration_smax(
    A: Tensor,
    iters: int = 2,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Approximate largest singular value of a (batched) 2D tensor via power iteration.
    """
    A = A.float()
    if A.ndim == 2:
        m, n = A.shape
        if (
            v_buf is not None
            and (v_buf.shape != (n,) or v_buf.device != A.device or v_buf.dtype != A.dtype)
        ):
            v_buf = None

        if v_buf is None:
            v = torch.randn(n, device=A.device, dtype=A.dtype, generator=generator)
        else:
            v = v_buf

        v.div_(v.norm() + 1e-8)
        for _ in range(iters):
            u = A @ v
            u = u / (u.norm() + 1e-8)
            v_new = A.mT @ u
            v_new = v_new / (v_new.norm() + 1e-8)
            if v_buf is None:
                v = v_new
            else:
                v.copy_(v_new)
        sigma = (A @ v).norm()
        return sigma

    # Batched matrices: treat leading dims as batch.
    m, n = int(A.size(-2)), int(A.size(-1))
    lead_shape = A.shape[:-2]
    A_flat = A.reshape(-1, m, n)
    batch = A_flat.size(0)

    if (
        v_buf is not None
        and (
            v_buf.shape != (*lead_shape, n)
            or v_buf.device != A.device
            or v_buf.dtype != A.dtype
        )
    ):
        v_buf = None

    if v_buf is None:
        v = torch.randn(batch, n, device=A.device, dtype=A.dtype, generator=generator)
    else:
        v = v_buf.reshape(batch, n)

    v.div_(v.norm(dim=1, keepdim=True) + 1e-8)
    for _ in range(iters):
        u = torch.bmm(A_flat, v.unsqueeze(-1)).squeeze(-1)
        u = u / (u.norm(dim=1, keepdim=True) + 1e-8)
        v_new = torch.bmm(A_flat.mT, u.unsqueeze(-1)).squeeze(-1)
        v_new = v_new / (v_new.norm(dim=1, keepdim=True) + 1e-8)
        if v_buf is None:
            v = v_new
        else:
            v.copy_(v_new)
    sigma = torch.bmm(A_flat, v.unsqueeze(-1)).squeeze(-1).norm(dim=1)
    return sigma.view(*lead_shape)


# ---- Turbo-Muon-style polar approximations ----

_ADANEWTON_COEFF_TABLE: Dict[Tuple[int, int], Tuple[float, float, float]] = {
    (2048, 2048): (3.3, -4.6, 2.0),
    (4096, 4096): (3.37, -4.9, 2.31),
    (3072, 2048): (2.9, -3.8, 1.86),
    (4096, 2048): (2.78, -3.49, 1.70),
}


def _get_adanewton_coeffs(m: int, n: int) -> Tuple[float, float, float]:
    if (m, n) in _ADANEWTON_COEFF_TABLE:
        return _ADANEWTON_COEFF_TABLE[(m, n)]
    if (n, m) in _ADANEWTON_COEFF_TABLE:
        return _ADANEWTON_COEFF_TABLE[(n, m)]
    # Default Muon-like coefficients
    return (3.44, -4.78, 2.03)


def _turbo_muon_polar(B: Tensor, ns_iters: int = 4) -> Tensor:
    """
    Turbo-Muon-inspired polar approximation:
    - Column-wise RMS preconditioning + few NS steps.
    """
    X = B.float()
    transposed = False
    if X.size(-2) > X.size(-1):
        X = X.mT
        transposed = True

    # Column-wise RMS preconditioning (per matrix, no batch mixing)
    col_rms = X.pow(2).mean(dim=-2, keepdim=True).sqrt().clamp_min(1e-6)
    X = X / col_rms

    # Normalize spectral norm
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)

    m, n = int(X.size(-2)), int(X.size(-1))
    a, b, c = _get_adanewton_coeffs(m, n)
    for _ in range(ns_iters):
        A = X @ X.mT
        X = a * X + b * (A @ X) + c * (A @ (A @ X))

    if transposed:
        X = X.mT
    return X


def approx_polar(
    B: Tensor,
    backend: str = "baseline",
    ns_iters: int = 4,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Approximate polar factor U for B ≈ U H with ||U||_op ≈ 1.
    backend:
      - "baseline": Muon zeropower_via_newtonschulz5
      - "turbo":    Turbo-Muon-style preconditioned NS
    """
    if backend == "turbo":
        U = _turbo_muon_polar(B, ns_iters=ns_iters)
    elif backend == "baseline":
        U = zeropower_via_newtonschulz5(B)
    else:
        raise ValueError(f"Unknown polar backend: {backend}")

    U = U.float()
    sigma_max = power_iteration_smax(U, iters=1, generator=generator, v_buf=v_buf)
    U = U / (sigma_max[..., None, None] + 1e-8)
    return U


def muon_like_spectral_update(
    B: Tensor,
    lr_spec_base: float,
    backend: str = "baseline",
    ns_iters: int = 4,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Plain Muon-style spectral update.
    """
    U = approx_polar(B, backend=backend, ns_iters=ns_iters, generator=generator, v_buf=v_buf)
    m, n = int(U.size(-2)), int(U.size(-1))
    shape_scale = math.sqrt(max(1.0, float(m) / max(1.0, float(n))))
    return -lr_spec_base * shape_scale * U


def _adamw_update_param(
    p: Tensor,
    state: Dict[str, Any],
    lr: float,
    betas: Tuple[float, float],
    eps: float,
    weight_decay: float,
) -> None:
    """
    Full AdamW update for non-spectral (AdamW-only) parameters.
    """
    if p.grad is None:
        return
    g = p.grad
    if g.is_sparse:  # pragma: no cover
        raise RuntimeError("Muon does not support sparse gradients")

    g32 = g.detach().to(torch.float32)

    exp_avg = state.get("exp_avg")
    exp_avg_sq = state.get("exp_avg_sq")
    if exp_avg is None:
        exp_avg = torch.zeros_like(p, dtype=torch.float32)
        exp_avg_sq = torch.zeros_like(p, dtype=torch.float32)
        state["exp_avg"] = exp_avg
        state["exp_avg_sq"] = exp_avg_sq
        state["adam_step"] = 0

    beta1, beta2 = betas
    t = int(state.get("adam_step", 0)) + 1
    state["adam_step"] = t

    exp_avg.mul_(beta1).add_(g32, alpha=1.0 - beta1)
    exp_avg_sq.mul_(beta2).addcmul_(g32, g32, value=1.0 - beta2)

    bias_correction1 = 1.0 - beta1**t
    bias_correction2 = 1.0 - beta2**t

    m_hat = exp_avg / bias_correction1
    v_hat = exp_avg_sq / bias_correction2

    denom = v_hat.sqrt().add_(eps)
    step_dir = -lr * (m_hat / denom)

    # Decoupled weight decay
    if weight_decay != 0.0:
        p.mul_(1.0 - lr * weight_decay)

    p.add_(step_dir.to(p.dtype))


class Muon(Optimizer):
    """
    Muon: hybrid optimizer for switch-bank.

    - Muon mode is based on Keller Jordan's Muon (MomentUm Orthogonalized by Newton–Schulz):
      https://kellerjordan.github.io/posts/muon/
    - TurboMuon mode is a faster Muon-inspired approximate-polar update (see `_turbo_muon_polar`
      and `approx_polar`).

    Param groups:
      - spectral=True  (default): 2D+ bfloat16 matrices updated via Muon (Turbo off)
        or TurboMuon-style spectral updates (Turbo on).
      - spectral=False: AdamW-only parameters (embeddings, heads, biases, norms, etc).
    """

    def __init__(
        self,
        params: Iterable[Tensor] | Iterable[Dict[str, Any]],
        # AdamW / Euclidean hyperparams
        lr: float = 1e-3,
        betas: Tuple[float, float] = (0.9, 0.95),
        eps: float = 1e-8,
        weight_decay: float = 0.01,
        # Muon spectral hyperparams
        muon_momentum: float = 0.95,
        lr_spec: Optional[float] = None,
        ns_iters: int = 4,
        rank: int = 0,
        world_size: int = 1,
        enable_turbomuon: bool = True,
    ) -> None:
        if lr_spec is None:
            lr_spec = lr

        defaults: Dict[str, Any] = dict(
            lr=lr,
            betas=betas,
            eps=eps,
            weight_decay=weight_decay,
            momentum=muon_momentum,
            lr_spec=lr_spec,
            spectral=True,  # default; can be overridden per param-group
        )
        super().__init__(params, defaults)

        self.rank = int(rank)
        self.world_size = int(world_size)
        self.enable_turbomuon = bool(enable_turbomuon)
        self.ns_iters = int(ns_iters)

        self._step_count: int = 0
        self._turbo_rng: Optional[torch.Generator] = None
        self._turbo_rng_state: Optional[Tensor] = None
        self._turbomuon_warmstart_smax: bool = False

        # Muon constraint: spectral parameters must be bfloat16
        for group in self.param_groups:
            if group.get("spectral", True):
                for p in group["params"]:
                    if not isinstance(p, Tensor):
                        continue
                    # Only enforce for >=2D tensors; 0/1D will usually go to AdamW or be ignored.
                    if p.ndim >= 2 and p.dtype != torch.bfloat16:
                        raise ValueError(
                            "Muon spectral parameters (2D) must be torch.bfloat16 "
                            f"(got dtype={p.dtype} for param shape {tuple(p.shape)}). "
                            "Put non-bfloat16 or non-2D parameters into a param group "
                            "with spectral=False to use pure AdamW."
                        )

    def _get_turbo_rng(self, device: torch.device) -> torch.Generator:
        if self._turbo_rng is not None:
            return self._turbo_rng

        gen = torch.Generator(device=device)
        base_seed = int(torch.initial_seed())
        seed = (base_seed + 1000003 * int(self.rank)) & 0xFFFFFFFFFFFFFFFF
        gen.manual_seed(seed)

        if self._turbo_rng_state is not None:
            state_cpu = self._turbo_rng_state.detach().to(device="cpu")
            gen.set_state(state_cpu)
            self._turbo_rng_state = None

        self._turbo_rng = gen
        return gen

    def set_turbomuon_warmstart_smax(self, enabled: bool) -> None:
        self._turbomuon_warmstart_smax = bool(enabled)

    def state_dict(self) -> Dict[str, Any]:
        out = super().state_dict()
        if not out.get("param_groups"):
            return out

        turbo_state: Optional[Tensor] = None
        if self._turbo_rng is not None:
            turbo_state = self._turbo_rng.get_state()
        elif self._turbo_rng_state is not None:
            turbo_state = self._turbo_rng_state

        if turbo_state is not None:
            out["param_groups"][0]["turbo_rng_state"] = turbo_state.detach().to(device="cpu")

        return out

    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:
        turbo_state: Optional[Tensor] = None
        try:
            param_groups = state_dict.get("param_groups", [])
            if param_groups:
                turbo_state = param_groups[0].get("turbo_rng_state")
        except Exception:
            turbo_state = None

        super().load_state_dict(state_dict)
        self._turbo_rng = None
        self._turbo_rng_state = turbo_state

    @torch.no_grad()
    def step(self, closure: Optional[Any] = None) -> Optional[Tensor]:
        loss = None
        if closure is not None:
            with torch.enable_grad():
                loss = closure()

        self._step_count += 1
        global_step = self._step_count

        # 1) AdamW-only param groups (spectral=False) – always AdamW.
        for group in self.param_groups:
            if group.get("spectral", True):
                continue  # handled in spectral pass

            lr: float = float(group["lr"])
            betas: Tuple[float, float] = tuple(group["betas"])  # type: ignore[arg-type]
            eps: float = float(group["eps"])
            weight_decay: float = float(group["weight_decay"])

            for p in group["params"]:
                if not isinstance(p, Tensor):
                    continue
                if p.grad is None:
                    continue
                state = self.state[p]
                _adamw_update_param(p, state, lr, betas, eps, weight_decay)

        # If no spectral groups, we're done.
        has_spectral = any(group.get("spectral", True) for group in self.param_groups)
        if not has_spectral:
            return loss

        use_dist = (
            self.world_size > 1 and dist.is_available() and dist.is_initialized()
        )

        # 2) Spectral groups.
        if not self.enable_turbomuon:
            # --- Pure Muon mode for spectral groups (reference behaviour) ---
            futures: List[torch.futures.Future] = []

            for group in self.param_groups:
                if not group.get("spectral", True):
                    continue

                params: List[Tensor] = [p for p in group["params"] if isinstance(p, Tensor)]
                if not params:
                    continue

                if use_dist:
                    params_pad = params + [torch.empty_like(params[-1])] * self.world_size
                    momentum_t: Optional[Tensor] = None

                    for base_i in range(0, len(params), self.world_size):
                        idx = base_i + self.rank
                        if idx < len(params):
                            p = params[idx]
                            if p.grad is not None:
                                state = self.state[p]
                                if "mantissa" not in state:
                                    state["mantissa"] = torch.zeros_like(p, dtype=torch.uint16)
                                    state["momentum_buffer"] = torch.zeros_like(p, dtype=torch.float32)
                                if momentum_t is None:
                                    momentum_t = _as_full_prec_tensor(
                                        float(group["momentum"]), device=p.device
                                    )

                                eff_lr = float(group["lr"]) * math.sqrt(
                                    max(
                                        1.0,
                                        float(p.size(-2))
                                        / max(1.0, float(p.size(-1))),
                                    )
                                )
                                eff_lr_t = _as_full_prec_tensor(eff_lr, device=p.device)

                                eff_wd = float(group["lr"]) * float(group["weight_decay"]) * float(
                                    getattr(p, "wd_mul", 1.0)
                                )
                                eff_wd_t = _as_full_prec_tensor(eff_wd, device=p.device)

                                _muon_update_kernel(
                                    p.view(torch.uint16),
                                    state["mantissa"],
                                    state["momentum_buffer"],
                                    p.grad,
                                    momentum_t,
                                    eff_lr_t,
                                    eff_wd_t,
                                )
                            src = params_pad[idx]
                        else:
                            src = params_pad[-1]

                        out_list = params_pad[base_i : base_i + self.world_size]
                        work = dist.all_gather(out_list, src, async_op=True)
                        futures.append(work.get_future())

                    torch.futures.collect_all(futures).wait()

                else:
                    momentum_t: Optional[Tensor] = None
                    for p in params:
                        if p.grad is None:
                            continue
                        state = self.state[p]
                        if "mantissa" not in state:
                            state["mantissa"] = torch.zeros_like(p, dtype=torch.uint16)
                            state["momentum_buffer"] = torch.zeros_like(p, dtype=torch.float32)
                        if momentum_t is None:
                            momentum_t = _as_full_prec_tensor(
                                float(group["momentum"]), device=p.device
                            )

                        eff_lr = float(group["lr"]) * math.sqrt(
                            max(
                                1.0,
                                float(p.size(-2)) / max(1.0, float(p.size(-1))),
                            )
                        )
                        eff_lr_t = _as_full_prec_tensor(eff_lr, device=p.device)

                        eff_wd = float(group["lr"]) * float(group["weight_decay"]) * float(
                            getattr(p, "wd_mul", 1.0)
                        )
                        eff_wd_t = _as_full_prec_tensor(eff_wd, device=p.device)

                        _muon_update_kernel(
                            p.view(torch.uint16),
                            state["mantissa"],
                            state["momentum_buffer"],
                            p.grad,
                            momentum_t,
                            eff_lr_t,
                            eff_wd_t,
                        )

            return loss

        # --- TurboMuon mode for spectral groups ---
        for group in self.param_groups:
            if not group.get("spectral", True):
                continue

            params: List[Tensor] = [p for p in group["params"] if isinstance(p, Tensor)]
            if not params:
                continue

            lr: float = float(group["lr"])
            betas: Tuple[float, float] = tuple(group["betas"])  # type: ignore[arg-type]
            eps: float = float(group["eps"])
            weight_decay: float = float(group["weight_decay"])
            lr_spec: float = float(group.get("lr_spec", lr))

            if use_dist:
                params_pad = params + [torch.empty_like(params[-1])] * self.world_size

                for base_i in range(0, len(params), self.world_size):
                    idx = base_i + self.rank
                    if idx < len(params):
                        p = params[idx]
                        if p.grad is not None:
                            self._update_spectral_param_turbomuon(
                                p=p,
                                group_lr=lr,
                                lr_spec=lr_spec,
                                betas=betas,
                                eps=eps,
                                weight_decay=weight_decay,
                                global_step=global_step,
                            )
                        src = params_pad[idx]
                    else:
                        src = params_pad[-1]

                    out_list = params_pad[base_i : base_i + self.world_size]
                    dist.all_gather(out_list, src, async_op=False)

            else:
                for p in params:
                    if p.grad is None:
                        continue
                    self._update_spectral_param_turbomuon(
                        p=p,
                        group_lr=lr,
                        lr_spec=lr_spec,
                        betas=betas,
                        eps=eps,
                        weight_decay=weight_decay,
                        global_step=global_step,
                    )

        return loss

    @torch.no_grad()
    def _update_spectral_param_turbomuon(
        self,
        p: Tensor,
        group_lr: float,
        lr_spec: float,
        betas: Tuple[float, float],
        eps: float,
        weight_decay: float,
        global_step: int,
    ) -> None:
        state = self.state[p]
        g = p.grad
        if g is None:
            return

        # 0/1D in spectral groups → treat as AdamW for robustness.
        if p.ndim < 2:
            _adamw_update_param(p, state, group_lr, betas, eps, weight_decay)
            return

        g32 = g.detach().to(torch.float32)

        M = state.get("M")
        if M is None:
            M = torch.zeros_like(p, dtype=torch.float32)
        beta1_spec = betas[0]
        M.mul_(beta1_spec).add_(g32, alpha=1.0 - beta1_spec)
        state["M"] = M

        turbo_gen = self._get_turbo_rng(device=p.device)
        v_buf = None
        if self._turbomuon_warmstart_smax:
            v_buf = state.get("pi_v")
            if v_buf is None:
                v_shape = (*p.shape[:-2], int(p.size(-1)))
                v_buf = torch.randn(v_shape, device=p.device, dtype=torch.float32, generator=turbo_gen)
                state["pi_v"] = v_buf

        spec_dir = muon_like_spectral_update(
            M,
            lr_spec_base=lr_spec,
            backend="turbo",
            ns_iters=self.ns_iters,
            generator=turbo_gen,
            v_buf=v_buf,
        )

        if weight_decay != 0.0:
            p.mul_(1.0 - group_lr * weight_decay)

        p.add_(spec_dir.to(p.dtype))
\n\n===== switch_bank/model/components.py =====\nimport math
from collections import defaultdict
from typing import Any

import torch
from torch import Tensor, nn
import torch.nn.functional as F
from torch.nn.attention.flex_attention import BlockMask, flex_attention

from switch_bank.utils import _sanitize, _safe_softmax


def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))


@torch.no_grad()
def init_linear(w: Tensor):
    std = 0.5 * (w.size(-1) ** -0.5)
    bound = (3 ** 0.5) * std
    return w.uniform_(-bound, bound)


class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)


class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        self.qkvo_w = nn.Parameter(init_linear(torch.empty(4, hdim, dim)).bfloat16())
        self.qkvo_w.detach()[3].zero_()  # out zero init
        self.rotary = Rotary(head_dim, max_seq_len)
        self.attn_scale = 0.12

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask, lambdas: Tensor):
        B, T = x.size(0), x.size(1)
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        # Record input activations for Muon spectral gating.
        # This is a detached side-channel only; it does not affect numerics.
        self.qkvo_w._neomuon_last_activation = x.detach()
        q, k, v = F.linear(x, self.qkvo_w[:3].flatten(end_dim=1))\
                   .view(B, T, 3 * self.num_heads, self.head_dim)\
                   .chunk(3, dim=-2)
        q, k = norm(q), norm(k)
        q, k = self.rotary(q), self.rotary(k)
        v = norm(v)
        if ve is not None:
            v = lambdas[0] * v + lambdas[1] * ve.view_as(v)
        else:
            v = lambdas[0] * v
        q = _sanitize(q)
        k = _sanitize(k)
        v = _sanitize(v)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2),
                           block_mask=block_mask, scale=self.attn_scale).transpose(1, 2)
        y = _sanitize(y)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim)
        y = F.linear(y, self.qkvo_w[3])
        return _sanitize(y)


class SharedFFNBank(nn.Module):
    def __init__(self, d: int, h: int, E: int, L: int, flags_dim: int,
                 lb_coeff: float = 1e-3, ent_coeff: float = 0.0, k: int = 1,
                 use_adapters: bool = False,
                 ema_alpha_fwd: float = 0.80, ema_alpha_rev: float | None = None,
                 use_forward_ema: bool = True, use_reverse_ema: bool = False,
                 ema_block_size_fwd: int = 128, ema_block_size_rev: int = 128,
                 ema_window_size_fwd: int = -1, ema_window_size_rev: int = 128,
                 ema_layer_stride: int = 1,
                 extra_wandb_logging: bool = True,
                 adapter_layer_tie_map: list[int] | tuple[int, ...] | None = None):
        super().__init__()
        self.d, self.h, self.E, self.L = d, h, E, L
        self.flags_dim = flags_dim
        self.lb_coeff = lb_coeff
        self.ent_coeff = ent_coeff
        self.k = int(k)
        alpha_fwd_val = float(ema_alpha_fwd)
        alpha_rev_val = float(ema_alpha_rev if ema_alpha_rev is not None else ema_alpha_fwd)
        self.ema_alpha_min_fwd = alpha_fwd_val
        self.ema_alpha_max_fwd = alpha_fwd_val
        self.ema_alpha_min_rev = alpha_rev_val
        self.ema_alpha_max_rev = alpha_rev_val
        self.use_adapters = bool(use_adapters)
        self.use_forward_ema = bool(use_forward_ema)
        self.use_reverse_ema = bool(use_reverse_ema)
        self.enable_extra_wandb_logging = bool(extra_wandb_logging)
        self.ema_block_size_fwd = int(ema_block_size_fwd)
        self.ema_block_size_rev = int(ema_block_size_rev)
        self.ema_window_size_fwd = int(ema_window_size_fwd)
        self.ema_window_size_rev = int(ema_window_size_rev)
        self.ema_layer_stride = max(int(ema_layer_stride), 1)
        assert self.ema_layer_stride <= L, "ema_layer_stride must be <= number of layers"
        self._ema_cache_fwd: dict[int, Tensor] | None = None
        self._ema_cache_rev: dict[int, Tensor] | None = None
        if adapter_layer_tie_map is not None:
            if len(adapter_layer_tie_map) != L:
                raise ValueError("adapter_layer_tie_map must match number of layers")
            tie_map = [int(idx) for idx in adapter_layer_tie_map]
            for idx in tie_map:
                if idx < 0 or idx >= L:
                    raise ValueError("adapter_layer_tie_map contains out-of-range indices")
            self.adapter_layer_tie_map = tie_map
        else:
            self.adapter_layer_tie_map = None
        if self.use_adapters:
            self.adapter_scale = nn.Parameter(torch.ones(L, E, d).bfloat16())
            self.adapter_bias = nn.Parameter(torch.zeros(L, E, d).bfloat16())
            self.register_buffer("adapter_initialized", torch.zeros(L, E, dtype=torch.bool), persistent=False)
        else:
            self.adapter_scale = None
            self.adapter_bias = None
            self.adapter_initialized = None
        self.register_buffer("pruned_experts", torch.zeros(E, dtype=torch.bool), persistent=False)
        self.W1 = nn.ParameterList([nn.Parameter(init_linear(torch.empty(h, d)).bfloat16()) for _ in range(E)])
        self.W2 = nn.ParameterList([nn.Parameter(torch.zeros(d, h).bfloat16()) for _ in range(E)])
        for w in list(self.W1) + list(self.W2):
            w.wd_mul = 2.0
        feat_multiplier = 1 + int(self.use_forward_ema) + int(self.use_reverse_ema)
        in_dim = feat_multiplier * d + flags_dim
        self.router_w = nn.ParameterList([nn.Parameter(init_linear(torch.empty(E, in_dim)).bfloat16()) for _ in range(L)])
        self.router_b = nn.ParameterList([nn.Parameter(torch.zeros(E).bfloat16()) for _ in range(L)])
        if self.use_forward_ema:
            alpha_fwd = torch.full((L,), alpha_fwd_val, dtype=torch.bfloat16)
            self.register_buffer("ema_alpha", alpha_fwd)
        else:
            self.ema_alpha = None
        if self.use_reverse_ema:
            alpha_rev = torch.full((L,), alpha_rev_val, dtype=torch.bfloat16)
            self.register_buffer("ema_alpha_rev", alpha_rev)
        else:
            self.ema_alpha_rev = None
        self._router_metrics_buffer: list[dict[str, float] | None] | None = None

    def _adapter_layer_idx(self, layer_idx: int) -> int:
        if self.adapter_layer_tie_map is None:
            return layer_idx
        return int(self.adapter_layer_tie_map[layer_idx])

    @torch.no_grad()
    @torch._dynamo.disable
    def maybe_init_adapters(self, active_mask: torch.Tensor | None):
        if not (self.use_adapters and self.adapter_initialized is not None):
            return
        if active_mask is None:
            init_mask = torch.ones(self.E, dtype=torch.bool, device=self.adapter_initialized.device)
        else:
            init_mask = active_mask.to(device=self.adapter_initialized.device, dtype=torch.bool)
        if self.pruned_experts.any():
            init_mask = init_mask & (~self.pruned_experts.to(device=init_mask.device))
        if not init_mask.any():
            return
        seen_layers = set()
        for layer_idx in range(self.L):
            adapter_layer = self._adapter_layer_idx(layer_idx)
            if adapter_layer in seen_layers:
                continue
            seen_layers.add(adapter_layer)
            init_flags = self.adapter_initialized[adapter_layer]
            to_init = init_mask & (~init_flags)
            if not to_init.any():
                continue
            src_mask = init_mask & init_flags
            if src_mask.any():
                scale_mean = self.adapter_scale[adapter_layer, src_mask].mean(dim=0, keepdim=True)
                bias_mean = self.adapter_bias[adapter_layer, src_mask].mean(dim=0, keepdim=True)
            else:
                scale_mean = None
                bias_mean = None
            if scale_mean is not None:
                self.adapter_scale[adapter_layer, to_init] = scale_mean
                self.adapter_bias[adapter_layer, to_init] = bias_mean
            self.adapter_initialized[adapter_layer, to_init] = True

    @staticmethod
    def _ema_blockwise(x: Tensor, alpha: Tensor, block_size: int = 128) -> Tensor:
        B, T, D = x.shape
        assert B == 1
        a = _sanitize(alpha.float(), value=0.8).clamp(1e-4, 0.9999)
        one_minus = (1.0 - a)
        assert T % block_size == 0, "Sequence length must be a multiple of 128."
        nb = T // block_size
        x_blk = x.view(1, nb, block_size, D).float()
        ar = torch.arange(block_size, device=x.device, dtype=torch.float32)
        pow_a = a.pow(ar)
        pow_a_p1 = a.pow(ar + 1.0)
        pow_a_inv = a.pow(-ar)
        y = torch.empty_like(x_blk)
        carry = torch.zeros(1, 1, D, device=x.device, dtype=torch.float32)
        for b in range(nb):
            xb = x_blk[:, b]
            u = xb * pow_a_inv.view(1, -1, 1)
            prefix = torch.cumsum(u, dim=1)
            yb = pow_a_p1.view(1, -1, 1) * carry + (one_minus * (pow_a.view(1, -1, 1) * prefix))
            y[:, b] = yb
            carry = yb[:, -1:, :]
        out = y.view(1, T, D).to(dtype=x.dtype)
        return _sanitize(out)

    @staticmethod
    @torch._dynamo.disable
    def _ema_reverse_since_doc_start(x: Tensor, alpha: Tensor, doc_starts: torch.Tensor, window: int = 128, block_size: int = 128) -> Tensor:
        B, T, D = x.shape
        assert B == 1
        doc_starts = doc_starts.to(dtype=torch.bool, device=x.device)
        if not bool(doc_starts[0]):
            doc_starts[0] = True
        doc_bounds = torch.nonzero(doc_starts, as_tuple=True)[0]
        if doc_bounds.numel() == 0 or doc_bounds[0].item() != 0:
            doc_bounds = torch.cat([doc_bounds.new_tensor([0]), doc_bounds])
        doc_bounds = torch.cat([doc_bounds, doc_bounds.new_tensor([T])])
        out = torch.empty_like(x, dtype=torch.float32)
        a = _sanitize(alpha.float(), value=0.8).clamp(1e-4, 0.9999)
        for idx in range(doc_bounds.numel() - 1):
            start = int(doc_bounds[idx].item())
            end = int(doc_bounds[idx + 1].item())
            if end <= start:
                continue
            seg = x[:, start:end, :]
            length = end - start
            limit = min(window, length)
            if limit > 0:
                head = seg[:, :limit, :]
                rev = torch.flip(head, dims=(1,))
                pad = (-limit) % block_size
                if pad:
                    zero_pad = torch.zeros(1, pad, D, device=x.device, dtype=rev.dtype)
                    rev = torch.cat([rev, zero_pad], dim=1)
                ema = SharedFFNBank._ema_blockwise(rev, a, block_size=block_size)
                ema = ema[:, :limit]
                ema = torch.flip(ema, dims=(1,))
                out[:, start:start + limit] = ema
                if length > limit:
                    out[:, start + limit:end] = ema[:, -1:].expand(1, length - limit, D)
            else:
                out[:, start:end] = 0
        return _sanitize(out.to(dtype=x.dtype))

    def forward(self, x_norm: Tensor, layer_idx: int, flags: Tensor, temperature: float,
                logit_cap: float | None, freeze_ema_alpha: bool, use_gumbel: bool,
                lb_multiplier: float = 1.0, active_mask: Tensor | None = None,
                freeze_router_params: bool = False, freeze_adapter_params: bool = False,
                ema_limits_fwd: tuple[float, float] | None = None,
                ema_limits_rev: tuple[float, float] | None = None,
                freeze_ema_alpha_rev: bool = False) -> tuple[Tensor, Tensor]:
        assert x_norm.size(0) == 1
        deterministic_topk = False
        base_mask = torch.ones(self.E, dtype=torch.bool, device=x_norm.device)
        if active_mask is not None:
            base_mask &= active_mask.to(device=x_norm.device, dtype=torch.bool)
        if self.pruned_experts.any():
            base_mask &= (~self.pruned_experts.to(device=x_norm.device))
        if not base_mask.any():
            base_mask = torch.ones(self.E, dtype=torch.bool, device=x_norm.device)
        regular_active_count = int(base_mask.sum().item())
        if (regular_active_count == 1):
            deterministic_topk = True
            active_idx = int(base_mask.nonzero(as_tuple=True)[0].item())
        features: list[Tensor] = [x_norm]
        feat_names: list[str] = ["tok"]
        feat_sizes: list[int] = [self.d]
        alpha_use_rev = None
        alpha_use = None
        group_stride = max(self.ema_layer_stride, 1)
        base_layer = (layer_idx // group_stride) * group_stride
        if (not deterministic_topk) and self.use_forward_ema and self.ema_alpha is not None:
            min_alpha, max_alpha = (ema_limits_fwd if ema_limits_fwd is not None else (self.ema_alpha_min_fwd, self.ema_alpha_max_fwd))
            alpha_raw = self.ema_alpha[base_layer].float()
            alpha_clip = _sanitize(alpha_raw).clamp(min_alpha, max_alpha)
            alpha_use = alpha_clip.detach() if freeze_ema_alpha else alpha_clip
            cache_fwd = self._ema_cache_fwd if isinstance(self._ema_cache_fwd, dict) else None
            if cache_fwd is not None and base_layer in cache_fwd:
                ema_feat = cache_fwd[base_layer]
            else:
                if 0 < self.ema_window_size_fwd < x_norm.size(1):
                    head_len = min(self.ema_window_size_fwd, x_norm.size(1))
                    pad = (-head_len) % self.ema_block_size_fwd
                    head = x_norm[:, :head_len]
                    if pad:
                        head = torch.cat([head, torch.zeros(1, pad, self.d, device=head.device, dtype=head.dtype)], dim=1)
                    ema_head = self._ema_blockwise(head, alpha_use, block_size=self.ema_block_size_fwd)[:, :head_len]
                    ema_feat = x_norm.new_empty(x_norm.shape)
                    ema_feat[:, :head_len] = ema_head
                    ema_feat[:, head_len:] = ema_head[:, -1:].expand(1, x_norm.size(1) - head_len, self.d)
                else:
                    ema_feat = self._ema_blockwise(x_norm, alpha_use, block_size=self.ema_block_size_fwd)
                if cache_fwd is not None:
                    cache_fwd[base_layer] = ema_feat
            features.append(ema_feat)
            feat_names.append("ema_fwd")
            feat_sizes.append(self.d)
        if (not deterministic_topk) and self.use_reverse_ema and self.ema_alpha_rev is not None:
            min_alpha_rev, max_alpha_rev = (ema_limits_rev if ema_limits_rev is not None else (self.ema_alpha_min_rev, self.ema_alpha_max_rev))
            alpha_raw_rev = self.ema_alpha_rev[base_layer].float()
            alpha_clip_rev = _sanitize(alpha_raw_rev).clamp(min_alpha_rev, max_alpha_rev)
            alpha_use_rev = alpha_clip_rev.detach() if freeze_ema_alpha_rev else alpha_clip_rev
            cache_rev = self._ema_cache_rev if isinstance(self._ema_cache_rev, dict) else None
            if cache_rev is not None and base_layer in cache_rev:
                ema_rev = cache_rev[base_layer]
            else:
                doc_starts = (flags[0, :, 1].float() > 0.5)
                ema_rev = self._ema_reverse_since_doc_start(
                    x_norm, alpha_use_rev, doc_starts,
                    window=self.ema_window_size_rev, block_size=self.ema_block_size_rev,
                )
                if cache_rev is not None:
                    cache_rev[base_layer] = ema_rev
            features.append(ema_rev)
            feat_names.append("ema_rev")
            feat_sizes.append(self.d)
        feat_names.append("flags")
        feat_sizes.append(self.flags_dim)
        if deterministic_topk:
            effective_mask = base_mask
            probs = torch.zeros((1, x_norm.size(1), self.E), device=x_norm.device, dtype=x_norm.dtype)
            probs[..., active_idx] = 1.0
            topk_idx = torch.full((1, x_norm.size(1), 1), active_idx, device=x_norm.device, dtype=torch.int64)
            topk_prob = torch.ones_like(topk_idx, dtype=x_norm.dtype)
            max_logit = float("nan")
            imp = torch.zeros(self.E, device=x_norm.device, dtype=x_norm.dtype)
            imp[active_idx] = 1.0
            load = imp.clone()
            k = 1
        else:
            rin = _sanitize(torch.cat([*features, flags], dim=-1))
            logits = F.linear(rin, self.router_w[layer_idx], self.router_b[layer_idx]).float()
            if use_gumbel:
                u = torch.rand_like(logits).clamp_(1e-6, 1 - 1e-6)
                g = -torch.log(-torch.log(u))
                logits = logits + g
            logits = logits / max(temperature, 1e-6)
            if logit_cap is not None and logit_cap > 0:
                logits = logits.clamp(-logit_cap, logit_cap)
            logits = _sanitize(logits)
            if freeze_router_params:
                logits = logits.detach()
            effective_mask = None
            if base_mask is not None:
                effective_mask = base_mask.to(device=logits.device, dtype=torch.bool)
            if effective_mask is not None:
                if not effective_mask.any():
                    fallback = (~self.pruned_experts).to(device=logits.device)
                    if not fallback.any():
                        fallback = torch.ones(self.E, dtype=torch.bool, device=logits.device)
                    effective_mask = fallback
                logits = logits.masked_fill(~effective_mask.view(1, 1, -1), float("-inf"))
            probs = _safe_softmax(logits, dim=-1)
            max_logit = logits.max().item() if logits.numel() > 0 else float("nan")

            active_count = int(effective_mask.sum().item()) if effective_mask is not None else self.E
            k = max(1, min(self.k, active_count))
            topk_prob, topk_idx = probs.topk(k, dim=-1)
            if torch.isnan(topk_prob).any():
                probs = _safe_softmax(torch.zeros_like(logits), dim=-1)
                topk_prob, topk_idx = probs.topk(k, dim=-1)

            imp = _sanitize(probs.mean(dim=(0, 1)))
            top1 = topk_idx[..., 0]
            one_hot = F.one_hot(top1.view(-1), num_classes=self.E).float()
            load = _sanitize(one_hot.mean(dim=0))

        def cv2(v: Tensor):
            m = v.mean()
            return v.var(unbiased=False) / (m * m + 1e-6)

        imp_f = imp.float()
        load_f = load.float()
        single_active = (regular_active_count <= 1)

        imp_entropy = (-(imp_f + 1e-6).log().mul(imp_f)).sum()
        load_entropy = (-(load_f + 1e-6).log().mul(load_f)).sum()

        lb_term = (self.lb_coeff * lb_multiplier) * (cv2(imp_f) + cv2(load_f))
        #entropy_term = -self.ent_coeff * (load_entropy + imp_entropy)

        ############# Test
        expected_entropy = math.log(regular_active_count) if regular_active_count > 0 else float("nan")

        def _entropy_gap(val):
            if math.isnan(val) or math.isnan(expected_entropy) or expected_entropy <= 0:
                return float("nan")
            return max(0.0, abs(expected_entropy - val) / expected_entropy)

        load_entropy_gap = _entropy_gap(load_entropy)
        imp_entropy_gap = _entropy_gap(imp_entropy)
        entropy_term = self.ent_coeff * (load_entropy_gap + imp_entropy_gap)
        ############

        router_aux = lb_term + entropy_term

        if single_active:
            router_aux = router_aux.new_zeros(())

        other_aux = router_aux.new_zeros(())
        aux = router_aux + other_aux
        if freeze_router_params:
            if freeze_adapter_params:
                aux = x_norm.new_zeros(())
            else:
                aux = other_aux

        y = torch.zeros_like(x_norm)
        pruned_flags = self.pruned_experts.to(dtype=torch.bool, device=x_norm.device)
        for e in range(self.E):
            if pruned_flags[e]:
                continue
            union_mask = torch.zeros(topk_idx.size(1), dtype=torch.bool, device=x_norm.device)
            per_rank_masks = []
            for r in range(k):
                mr = (topk_idx[0, :, r] == e)
                per_rank_masks.append(mr)
                union_mask |= mr
            if not union_mask.any():
                continue
            x_e = x_norm[:, union_mask]
            if self.use_adapters:
                adapter_layer = self._adapter_layer_idx(layer_idx)
                scale = self.adapter_scale[adapter_layer, e]
                bias = self.adapter_bias[adapter_layer, e]
                if freeze_adapter_params:
                    scale = scale.detach()
                    bias = bias.detach()
                x_e = x_e * scale.to(x_e.dtype) + bias.to(x_e.dtype)
            # Record activations for Muon spectral gating.
            self.W1[e]._neomuon_last_activation = x_e.detach()
            h1 = F.linear(x_e, self.W1[e])
            h1 = F.relu(h1).square()
            self.W2[e]._neomuon_last_activation = h1.detach()
            out_e = F.linear(h1, self.W2[e])
            idx_union = union_mask.nonzero(as_tuple=True)[0]
            accum = torch.zeros_like(out_e)
            for r in range(k):
                mr = per_rank_masks[r]
                if not mr.any():
                    continue
                rel = torch.nonzero(mr[union_mask], as_tuple=True)[0]
                scales = topk_prob[0, mr, r].unsqueeze(-1)
                accum[:, rel] += scales * out_e[:, rel]
            y[:, idx_union] += accum

        stats: dict[str, Any] = dict(
            imp_cv2=float(cv2(_sanitize(imp_f)).item()),
            load_cv2=float(cv2(_sanitize(load_f)).item()),
            usage_frac=float(((load_f > 0).float().mean()).item()),
            topk_prob_mean=float(_sanitize(topk_prob).mean().item()),
            imp_entropy=float(imp_entropy.item()),
            load_entropy=float(load_entropy.item()),
        )
        if self.enable_extra_wandb_logging:
            if self.use_forward_ema and self.ema_alpha is not None and alpha_use is not None:
                stats["ema_alpha_forward"] = float(alpha_use.float().item())
            if self.use_reverse_ema and self.ema_alpha_rev is not None and alpha_use_rev is not None:
                stats["ema_alpha_reverse"] = float(alpha_use_rev.float().item())
            start_idx = 0
            for name, size in zip(feat_names, feat_sizes):
                end_idx = start_idx + size
                if end_idx > self.router_w[layer_idx].size(1):
                    break
                w_slice = self.router_w[layer_idx][:, start_idx:end_idx].float()
                stats[f"feat_w_{name}"] = float(w_slice.abs().mean().item())
                start_idx = end_idx
        stats["load_vector"] = _sanitize(load_f).detach().float().cpu()
        self._record_router_metrics(layer_idx, stats, max_logit)

        return y, aux

    @torch.no_grad()
    def compile_warm_all_experts(self, d: int, T_warm: int = 128):
        x = torch.randn(1, T_warm, d, device=self.W1[0].device, dtype=torch.bfloat16)
        for e in range(self.E):
            h1 = F.linear(x, self.W1[e]); h1 = F.relu(h1).square(); _ = F.linear(h1, self.W2[e])

    def begin_router_metrics(self):
        self._router_metrics_buffer = [None] * self.L
        self._ema_cache_fwd = {}
        self._ema_cache_rev = {}

    def _record_router_metrics(self, layer_idx: int, stats: dict[str, float], max_logit: float):
        if self._router_metrics_buffer is not None:
            stats = dict(stats)
            stats["max_logit"] = max_logit
            self._router_metrics_buffer[layer_idx] = stats

    def pop_router_metrics(self):
        metrics = self._router_metrics_buffer
        self._router_metrics_buffer = None
        return metrics or []

    @torch.no_grad()
    def prune_inactive_experts(self, activity: torch.Tensor, threshold: float) -> list[int]:
        if activity is None:
            return []
        if activity.numel() != self.E:
            return []
        device = self.pruned_experts.device
        activity = activity.to(device=device, dtype=torch.float32)
        available = (~self.pruned_experts)
        if not available.any():
            return []
        keep = (activity >= threshold) & available
        if not keep.any():
            masked_activity = activity.clone()
            masked_activity[~available] = float("-inf")
            best_idx = int(torch.argmax(masked_activity).item())
            keep[best_idx] = True
        pruned_mask = available & (~keep)
        new_pruned = pruned_mask.nonzero(as_tuple=True)[0].tolist()
        if not new_pruned:
            return []
        self.pruned_experts |= pruned_mask
        for idx in new_pruned:
            self.W1[idx].zero_()
            self.W2[idx].zero_()
        if self.use_adapters:
            mask = self.pruned_experts
            self.adapter_scale[:, mask] = 0
            self.adapter_bias[:, mask] = 0
        return new_pruned


class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int, skip_attn_layers: set[int],
                 peak_frac: float, temp_boost: float, lb_boost: float, boost_shape: str = "peak"):
        super().__init__()
        self.attn = None if layer_idx in skip_attn_layers else CausalSelfAttention(dim, num_heads, max_seq_len)
        self.layer_idx = layer_idx
        self.total_layers = None
        self.layer_peak_frac = float(peak_frac)
        self.temp_boost = float(temp_boost)
        self.lb_boost = float(lb_boost)
        self.boost_shape = (boost_shape or "peak").lower()

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask,
                lambdas: Tensor, sa_lambdas: Tensor, bank: SharedFFNBank, layer_idx: int,
                flags: Tensor, temperature: float, logit_cap: float | None,
                freeze_ema_alpha: bool, use_gumbel: bool, active_mask: Tensor | None,
                freeze_router_params: bool, freeze_adapter_params: bool,
                ema_limits_fwd: tuple[float, float] | None,
                ema_limits_rev: tuple[float, float] | None,
                freeze_ema_alpha_rev: bool, decay_scale: float) -> tuple[Tensor, Tensor]:
        if self.total_layers is None:
            self.total_layers = getattr(bank, "L", layer_idx + 1)
        layer_frac = layer_idx / max(self.total_layers - 1, 1)
        x = lambdas[0] * x + lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(x, ve, block_mask, sa_lambdas)
        peak = self.layer_peak_frac
        dist = abs(layer_frac - peak)
        denom = peak if layer_frac <= peak else max(1.0 - peak, 1e-6)
        shape_peak = max(0.0, 1.0 - dist / denom)
        if self.boost_shape == "valley":
            shape = 1.0 - shape_peak
        elif self.boost_shape == "linear_start":
            shape = max(0.0, min(1.0, 1.0 - layer_frac))
        elif self.boost_shape == "linear_end":
            shape = max(0.0, min(1.0, layer_frac))
        else:
            shape = shape_peak
        decay_scale = float(decay_scale)
        temp_multiplier = 1.0 + decay_scale * self.temp_boost * shape
        lb_multiplier = 1.0 + decay_scale * self.lb_boost * shape
        y, aux = bank(
            norm(x),
            layer_idx,
            flags,
            temperature * temp_multiplier,
            logit_cap,
            freeze_ema_alpha,
            use_gumbel,
            lb_multiplier,
            active_mask,
            freeze_router_params=freeze_router_params,
            freeze_adapter_params=freeze_adapter_params,
            ema_limits_fwd=ema_limits_fwd,
            ema_limits_rev=ema_limits_rev,
            freeze_ema_alpha_rev=freeze_ema_alpha_rev,
        )
        x = x + y
        return x, aux
\n\n===== switch_bank/model/gpt.py =====\nimport math
import os
from functools import lru_cache

import torch
from torch import Tensor, nn
import torch.nn.functional as F
from torch.nn.attention.flex_attention import BlockMask

from switch_bank.model.components import Block, SharedFFNBank, norm, init_linear
from switch_bank.utils import next_multiple_of_n


def _compute_router_temp(step: int, total_steps: int, t_init: float, t_final: float,
                         power: float, anchor_delta_steps: int, anchor_ratio: float | None,
                         start_step: int) -> float:
    if step <= start_step:
        return t_init
    effective_total = max(total_steps - start_step, 1)
    progress = (step - start_step) / effective_total
    power_use = power
    if anchor_delta_steps > 0 and anchor_ratio is not None and 0 < anchor_ratio < 1:
        anchor_progress = min(max(anchor_delta_steps / effective_total, 1e-6), 0.999999)
        power_use = math.log(anchor_ratio) / math.log(1.0 - anchor_progress)
    return t_final + (t_init - t_final) * (1.0 - progress) ** power_use


@lru_cache(None)
def _second_expert_step(expert_activation_schedule: tuple[tuple[int, int], ...]) -> int:
    if len(expert_activation_schedule) >= 2:
        return max(0, int(expert_activation_schedule[1][0]))
    if len(expert_activation_schedule) == 1:
        return max(0, int(expert_activation_schedule[0][0]))
    return 0


def _normalize_layer_tie_groups(
    tie_groups: tuple[tuple[int, ...], ...] | None,
    num_layers: int,
    skip_attn_layers: set[int],
) -> tuple[int, ...]:
    tie_map = list(range(num_layers))
    if not tie_groups:
        return tuple(tie_map)
    if not isinstance(tie_groups, (list, tuple)):
        raise ValueError("layer_tie_groups must be a sequence of layer index groups")
    tie_groups = tuple(tie_groups)
    if (
        len(tie_groups) == 1
        and isinstance(tie_groups[0], (list, tuple))
        and tie_groups[0]
        and all(isinstance(entry, (list, tuple)) for entry in tie_groups[0])
    ):
        tie_groups = tuple(tie_groups[0])
    used = set()
    for group in tie_groups:
        if not group:
            continue
        group_layers = []
        for idx in group:
            if isinstance(idx, (list, tuple)):
                raise ValueError("layer_tie_groups should be a sequence of layer indices; remove extra nesting")
            idx_i = int(idx)
            if idx_i < 0 or idx_i >= num_layers:
                raise ValueError(f"Layer tie index {idx_i} out of range for num_layers={num_layers}")
            if idx_i in used or idx_i in group_layers:
                raise ValueError(f"Layer {idx_i} appears multiple times in layer_tie_groups")
            if idx_i in skip_attn_layers:
                raise ValueError(f"Layer tie groups cannot include skip-attn layer {idx_i}")
            group_layers.append(idx_i)
        if len(group_layers) < 2:
            continue
        base = group_layers[0]
        for idx_i in group_layers:
            used.add(idx_i)
            tie_map[idx_i] = base
    return tuple(tie_map)


class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int,
                 skip_attn_layers: set[int], layer_tie_groups: tuple[tuple[int, ...], ...],
                 E: int, h: int, lb_coeff: float, ent_coeff: float, k: int,
                 num_value_embeds: int,
                 tie_lm_head: bool, untie_lm_head_after: int,
                 ema_alpha_fwd: float, ema_alpha_rev: float,
                 router_temp_init: float, router_temp_final: float, router_temp_power: float,
                 router_temp_anchor_delta_steps: int | None, router_temp_anchor_ratio: float | None,
                 router_logit_cap_initial: float, router_logit_cap_final: float, router_logit_cap_delta_steps: int,
                 router_layer_peak_frac: float, router_temp_boost: float, router_lb_boost: float, router_boost_shape: str,
                 use_router_adapters: bool, expert_activation_schedule: tuple[tuple[int, int], ...],
                 router_freeze_frac: float, router_freeze_adapters: bool,
                 ema_block_size_fwd: int, ema_block_size_rev: int,
                 ema_window_size_fwd: int, ema_window_size_rev: int,
                 ema_layer_stride: int,
                 shared_ffn_freeze_frac: float,
                 router_use_gumbel: bool, router_gumbel_schedule: tuple[tuple[int, int], ...],
                 router_block_pos_bins: int, first_doc_tokens_N: int,
                 router_enable_forward_ema: bool, router_enable_reverse_ema: bool,
                 extra_console_logging: bool, extra_wandb_logging: bool,
                 print_fn=None):
        super().__init__()
        self.vocab_size = vocab_size
        self.vocab_size_padded = next_multiple_of_n(vocab_size, n=128)
        self.embed = nn.Embedding(self.vocab_size_padded, model_dim)

        assert 0 <= num_value_embeds <= 3
        self.num_value_embeds = int(num_value_embeds)
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(self.num_value_embeds)])
        self.enable_forward_ema = bool(router_enable_forward_ema)
        self.enable_reverse_ema = bool(router_enable_reverse_ema)
        self.extra_console_logging = bool(extra_console_logging)
        self.extra_wandb_logging = bool(extra_wandb_logging)

        self.num_layers = num_layers
        self.layer_tie_map = _normalize_layer_tie_groups(layer_tie_groups, num_layers, skip_attn_layers)
        self.blocks = nn.ModuleList([
            Block(model_dim, num_heads, max_seq_len, i, skip_attn_layers,
                  router_layer_peak_frac, router_temp_boost, router_lb_boost, boost_shape=router_boost_shape)
            for i in range(num_layers)
        ])
        for idx, base in enumerate(self.layer_tie_map):
            if idx == base:
                continue
            base_attn = self.blocks[base].attn
            if base_attn is None:
                raise ValueError(f"Layer {base} has no attention but is used as a tie base")
            self.blocks[idx].attn = base_attn
        self.router_temp_boost = float(router_temp_boost)
        self.router_lb_boost = float(router_lb_boost)
        self.tie_lm_head = bool(tie_lm_head)
        self.untie_lm_head_after = int(untie_lm_head_after)
        needs_lm_head = (not self.tie_lm_head) or (self.untie_lm_head_after >= 0)
        self.lm_head = nn.Parameter(init_linear(torch.empty(self.vocab_size_padded, model_dim)).bfloat16()) if needs_lm_head else None
        self._head_tied_runtime = True
        if not self.tie_lm_head:
            self._head_tied_runtime = False

        assert 1 <= ema_layer_stride <= self.num_layers, "ema_layer_stride must be between 1 and num_layers"
        self.scalars = nn.Parameter(torch.cat([
            torch.ones(num_layers),
            *[torch.tensor([1.0, 0.0]) for _ in range(num_layers)],
            *[torch.tensor([0.5, 0.5]) for _ in range(num_layers)],
        ]))
        self.router_temp_init = float(router_temp_init)
        self.router_temp_final = float(router_temp_final)
        self.router_temp_power = float(router_temp_power)
        self.router_temp_anchor_delta_steps = (int(router_temp_anchor_delta_steps) if router_temp_anchor_delta_steps is not None else -1)
        self.router_temp_anchor_ratio = (float(router_temp_anchor_ratio) if router_temp_anchor_ratio is not None else None)
        self.router_logit_cap_delta_steps = int(router_logit_cap_delta_steps)
        self.router_logit_cap_initial = float(router_logit_cap_initial)
        self.router_logit_cap_final = float(router_logit_cap_final)
        self.router_use_gumbel = bool(router_use_gumbel)
        schedule: list[tuple[int, int]] = []
        for entry in router_gumbel_schedule:
            if len(entry) < 2:
                continue
            start, end = entry
            schedule.append((max(0, int(start)), int(end)))
        schedule.sort(key=lambda x: x[0])
        self.router_gumbel_schedule: tuple[tuple[int, int], ...] = tuple(schedule)
        self.second_expert_step_const = _second_expert_step(expert_activation_schedule)
        self.router_freeze_frac = float(router_freeze_frac)
        self.router_freeze_adapters = bool(router_freeze_adapters)
        self.shared_ffn_freeze_frac = float(shared_ffn_freeze_frac)
        self._router_frozen_logged = False
        self._ffn_frozen_logged = False

        assert router_block_pos_bins in (4, 8, 16), "router_block_pos_bins must be 4, 8, or 16"
        self.router_block_pos_bins = int(router_block_pos_bins)
        self.first_doc_tokens_N = int(first_doc_tokens_N)
        self.use_router_adapters = bool(use_router_adapters)
        self.num_experts = E
        schedule: list[tuple[int, int]] = []
        for entry in expert_activation_schedule:
            if len(entry) < 2:
                continue
            step_v, count = entry[0], entry[1]
            step_i = max(0, int(step_v))
            count_i = max(1, min(self.num_experts, int(count)))
            schedule.append((step_i, count_i))
        schedule.sort(key=lambda x: x[0])
        self.expert_activation_schedule: list[tuple[int, int]] = []
        for step_v, count in schedule:
            if self.expert_activation_schedule and step_v == self.expert_activation_schedule[-1][0]:
                self.expert_activation_schedule[-1] = (step_v, count)
            else:
                self.expert_activation_schedule.append((step_v, count))
        mask_needed = any(count < self.num_experts for _, count in self.expert_activation_schedule)
        if mask_needed:
            if not self.expert_activation_schedule:
                self.expert_activation_schedule = [(0, self.num_experts)]
            elif self.expert_activation_schedule[0][0] > 0:
                first = self.expert_activation_schedule[0][1]
                self.expert_activation_schedule.insert(0, (0, first))
            last_step, last_count = self.expert_activation_schedule[-1]
            if last_count < self.num_experts:
                self.expert_activation_schedule.append((last_step, self.num_experts))
        self._expert_schedule_requires_mask = mask_needed
        self._full_activation_step = self._compute_full_activation_step()
        self._full_activation_step = self._compute_full_activation_step()

        flags_dim = 3 + self.router_block_pos_bins

        self.bank = SharedFFNBank(
            d=model_dim, h=h, E=E, L=num_layers, flags_dim=flags_dim,
            lb_coeff=lb_coeff, ent_coeff=ent_coeff, k=k,
            use_adapters=use_router_adapters,
            ema_alpha_fwd=ema_alpha_fwd, ema_alpha_rev=ema_alpha_rev,
            use_forward_ema=self.enable_forward_ema, use_reverse_ema=self.enable_reverse_ema,
            ema_block_size_fwd=ema_block_size_fwd, ema_block_size_rev=ema_block_size_rev,
            ema_window_size_fwd=ema_window_size_fwd, ema_window_size_rev=ema_window_size_rev,
            ema_layer_stride=ema_layer_stride,
            extra_wandb_logging=self.extra_wandb_logging,
            adapter_layer_tie_map=self.layer_tie_map,
        )
        self.latest_router_metrics: list[dict[str, float] | None] | None = None
        self.latest_loss_components: tuple[Tensor, Tensor] | None = None
        self._last_active_expert_count: int | None = None
        self._current_base_active: int = self.num_experts
        self._pending_active_count: tuple[int, int] | None = None
        self._print0 = print_fn or (lambda *args, **kwargs: None)

    def _build_flags(self, input_seq: Tensor) -> Tensor:
        T = input_seq.size(0)
        device = input_seq.device
        is_eod_bool = (input_seq == 50256)
        is_eod = is_eod_bool.float().unsqueeze(0).unsqueeze(-1)
        start_flags = torch.zeros(T, dtype=torch.bool, device=device)
        start_flags[0] = True
        if T > 1:
            start_flags[1:] = is_eod_bool[:-1]
        is_after_eod = start_flags.float().unsqueeze(0).unsqueeze(-1)
        idx = torch.arange(T, device=device, dtype=torch.int64)
        start_idx = torch.where(start_flags, idx, torch.zeros_like(idx))
        last_start = torch.cummax(start_idx, dim=0)[0]
        dist_since_start = (idx - last_start).to(torch.int64)
        N = max(self.first_doc_tokens_N, 0)
        is_first_docN = (dist_since_start < N).float().unsqueeze(0).unsqueeze(-1)
        bins = self.router_block_pos_bins
        pos128 = idx % 128
        bin_idx = torch.clamp((pos128 * bins) // 128, max=bins - 1)
        onehot_bins = F.one_hot(bin_idx, num_classes=bins).float().unsqueeze(0)
        flags = torch.cat([is_eod, is_after_eod, is_first_docN, onehot_bins], dim=-1).to(dtype=torch.bfloat16)
        return flags

    def _ema_limits_for_progress(self, progress: float, reverse: bool = False) -> tuple[float, float]:
        if reverse:
            return (float(self.bank.ema_alpha_min_rev), float(self.bank.ema_alpha_max_rev))
        return (float(self.bank.ema_alpha_min_fwd), float(self.bank.ema_alpha_max_fwd))

    @torch._dynamo.disable
    def _active_expert_mask(self, step: int, device: torch.device) -> torch.Tensor | None:
        if not self._expert_schedule_requires_mask or not self.expert_activation_schedule:
            self._current_base_active = self.num_experts
            return None
        current = self.expert_activation_schedule[0]
        for stage in self.expert_activation_schedule:
            if step >= stage[0]:
                current = stage
            else:
                break
        active_count = max(1, min(self.num_experts, int(current[1])))
        self._current_base_active = active_count
        if active_count >= self.num_experts:
            self._expert_schedule_requires_mask = False
            self._mask_for_runtime = None
            return None
        mask = torch.zeros(self.num_experts, dtype=torch.bool, device=device)
        mask[:active_count] = True
        if mask.all():
            self._mask_for_runtime = None
            return None
        self._mask_for_runtime = mask
        return mask

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx

        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)

        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all

        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)

        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def compute_router_temp(self, step: int, total_steps: int) -> float:
        return _compute_router_temp(
            step, total_steps, self.router_temp_init, self.router_temp_final,
            self.router_temp_power, self.router_temp_anchor_delta_steps, self.router_temp_anchor_ratio,
            start_step=self.second_expert_step_const)

    def compute_logit_cap(self, step: int) -> float | None:
        start_step = self.second_expert_step_const
        delta = max(int(self.router_logit_cap_delta_steps), 0)
        start = self.router_logit_cap_initial
        end = self.router_logit_cap_final
        if delta <= 0:
            return end if end > 0 else None
        if step < start_step:
            return start if start > 0 else None
        frac = min(max((step - start_step) / max(delta, 1), 0.0), 1.0)
        if start <= 0 and end <= 0:
            return None
        if start <= 0:
            return end
        if end <= 0:
            return max(start * (1.0 - frac), 0.0)
        shaped = frac ** 4.0
        return start * math.exp(math.log(end / start) * shaped)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor,
                step: int, total_steps: int):
        assert input_seq.ndim == 1
        self.bank.begin_router_metrics()
        self.latest_loss_components = None
        head_should_be_tied = self._head_should_be_tied(step)
        if self.lm_head is not None and self._head_tied_runtime and not head_should_be_tied:
            self.lm_head.data.copy_(self.embed.weight.data)
        self._head_tied_runtime = head_should_be_tied

        progress = step / max(total_steps, 1)
        active_mask = self._active_expert_mask(step, input_seq.device)
        self.bank.maybe_init_adapters(active_mask)
        ema_limits_fwd = self._ema_limits_for_progress(progress, reverse=False)
        ema_limits_rev = self._ema_limits_for_progress(progress, reverse=True)
        freeze_router_params = (progress >= self.router_freeze_frac)
        freeze_adapter_params = (freeze_router_params and self.router_freeze_adapters)
        freeze_ffn = (progress >= self.shared_ffn_freeze_frac)
        base_active = getattr(self, "_current_base_active", self.num_experts if active_mask is None else int(active_mask.sum().item()))
        if self.training:
            last_logged = getattr(self, "_last_active_expert_count", None)
            if last_logged is None or base_active > last_logged:
                self._last_active_expert_count = base_active
                self._pending_active_count = (step, base_active)
        if freeze_router_params and not self._router_frozen_logged and self.extra_console_logging:
            self._print0(f"Routers frozen at step {step}", console=True)
            self._router_frozen_logged = True
        if freeze_ffn and not self._ffn_frozen_logged and self.extra_console_logging:
            self._print0(f"Shared FFN frozen at step {step}", console=True)
            self._ffn_frozen_logged = True
        T_cur = self.compute_router_temp(step, total_steps)
        logit_cap = self.compute_logit_cap(step)
        decay_scale = 1.0
        freeze_ema_alpha_fwd = True
        freeze_ema_alpha_rev = True
        use_gumbel_now = False
        if self.router_use_gumbel:
            for start, end in self.router_gumbel_schedule:
                end_eff = total_steps if end < 0 else end
                if start <= step < end_eff:
                    use_gumbel_now = True
                    break

        ve_tables = [value_embed(input_seq) for value_embed in self.value_embeds]
        L = len(self.blocks)
        if self.num_value_embeds == 3:
            ve = [ve_tables[0], ve_tables[1], ve_tables[2]] + [None] * max(L - 6, 0) + [ve_tables[0], ve_tables[1], ve_tables[2]]
        elif self.num_value_embeds == 2:
            ve = [ve_tables[0], ve_tables[1]] + [None] * max(L - 4, 0) + [ve_tables[0], ve_tables[1]]
        elif self.num_value_embeds == 1:
            ve = [ve_tables[0]] + [None] * max(L - 2, 0)
            if L >= 2:
                ve.append(ve_tables[0])
        else:
            ve = [None] * L
        if len(ve) < L:
            ve = ve + [None] * (L - len(ve))
        elif len(ve) > L:
            ve = ve[:L]

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        if L == 28:
            long_ids = {0, 4, 8, 12, 16, 20, 24}
        elif L == 32:
            long_ids = {0, 4, 8, 12, 16, 20, 24, 28}
        else:
            stride = max(L // 4, 1)
            long_ids = set(range(0, L, stride))
        block_masks = [long_bm if i in long_ids else short_bm for i in range(L)]

        x = x0 = norm(self.embed(input_seq)[None])
        flags = self._build_flags(input_seq)

        skip_connections = []
        skip_map = {9: 6, 10: 4, 11: 2}
        skip_weights = self.scalars[:L]
        lambdas = self.scalars[1 * L: 3 * L].view(-1, 2)
        sa_lambdas = self.scalars[3 * L: 5 * L].view(-1, 2)

        aux_loss = x.new_zeros(()).float()
        for i in range(L):
            if i in skip_map and skip_map[i] < len(skip_connections):
                x = x + skip_weights[skip_map[i]] * skip_connections[skip_map[i]]
            if freeze_ffn:
                with torch.no_grad():
                    y, aux = self.blocks[i](
                        x, ve[i], x0, block_masks[i], lambdas[i], sa_lambdas[i],
                        self.bank, i, flags, float(T_cur),
                        (float(logit_cap) if logit_cap is not None else None),
                        freeze_ema_alpha_fwd, use_gumbel_now, active_mask,
                        freeze_router_params=freeze_router_params,
                        freeze_adapter_params=freeze_adapter_params,
                        ema_limits_fwd=ema_limits_fwd,
                        ema_limits_rev=ema_limits_rev,
                        freeze_ema_alpha_rev=freeze_ema_alpha_rev,
                        decay_scale=decay_scale,
                    )
                y = y.detach()
                aux = aux.detach()
            else:
                y, aux = self.blocks[i](
                    x, ve[i], x0, block_masks[i], lambdas[i], sa_lambdas[i],
                    self.bank, i, flags, float(T_cur),
                    (float(logit_cap) if logit_cap is not None else None),
                    freeze_ema_alpha_fwd, use_gumbel_now, active_mask,
                    freeze_router_params=freeze_router_params,
                    freeze_adapter_params=freeze_adapter_params,
                    ema_limits_fwd=ema_limits_fwd,
                    ema_limits_rev=ema_limits_rev,
                    freeze_ema_alpha_rev=freeze_ema_alpha_rev,
                    decay_scale=decay_scale,
                )
            x = y
            aux_loss = aux_loss + aux
            skip_connections.append(x)

        x = norm(x)
        self.latest_router_metrics = self.bank.pop_router_metrics()
        if self.training:
            logits: Tensor = F.linear(x.flatten(end_dim=1), self._lm_head_weight()).float()
            loss_main = F.cross_entropy(15 * logits * torch.rsqrt(logits.square() + 225), target_seq)
            self.latest_loss_components = (loss_main.detach(), aux_loss.detach())
            return loss_main, aux_loss

        loss = 0
        for i in range(4):
            logits: Tensor = F.linear(x.flatten(end_dim=1).chunk(4)[i], self._lm_head_weight()).float()
            loss += F.cross_entropy(15 * logits * torch.rsqrt(logits.square() + 225), target_seq.chunk(4)[i]) / 4
        self.latest_loss_components = None
        return loss

    def _head_should_be_tied(self, step: int) -> bool:
        if not self.tie_lm_head:
            return False
        if self.untie_lm_head_after >= 0:
            return step < self.untie_lm_head_after
        return True

    def _lm_head_weight(self) -> Tensor:
        if self.lm_head is None or self._head_tied_runtime:
            return self.embed.weight.bfloat16()
        return self.lm_head.bfloat16()

    def _compute_full_activation_step(self) -> int:
        step_full = 0
        for step_v, count in self.expert_activation_schedule:
            if count >= self.num_experts:
                step_full = int(step_v)
                break
        return max(0, step_full)

    def _latest_activation(self, step: int) -> tuple[int, int]:
        last_step = 0
        last_count = 0
        for stage_step, count in self.expert_activation_schedule:
            if step >= stage_step:
                last_step = int(stage_step)
                last_count = int(count)
            else:
                break
        return last_step, last_count
\n\n===== switch_bank/data.py =====\nimport torch
from pathlib import Path
from torch import Tensor


def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32)
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2])
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True)
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy())
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens


def distributed_data_generator(filename_pattern: str, batch_size: int, rank: int, world_size: int, skip_batches: int = 0):
    files = sorted(Path.cwd().glob(filename_pattern))
    if not files:
        raise RuntimeError(f"No data files match pattern '{filename_pattern}' in {Path.cwd()}")
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files)
    try:
        tokens, pos = _load_data_shard(next(file_iter)), 0
    except StopIteration as exc:
        raise RuntimeError(f"No data files available for pattern '{filename_pattern}'") from exc
    # fast-forward if resuming
    while skip_batches > 0:
        if pos + batch_size + 1 >= len(tokens):
            try:
                tokens, pos = _load_data_shard(next(file_iter)), 0
            except StopIteration:
                raise RuntimeError(f"Ran out of data while skipping batches for '{filename_pattern}'")
        pos += batch_size
        skip_batches -= 1

    while True:
        if pos + batch_size + 1 >= len(tokens):
            try:
                tokens, pos = _load_data_shard(next(file_iter)), 0
            except StopIteration:
                return
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True)
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True)
        pos += batch_size
        yield inputs, targets


def summarize_router_metrics(metrics: list[dict[str, float] | None]) -> dict[str, float]:
    summary: dict[str, float] = {}
    counts: dict[str, int] = {}
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        for key, value in layer_stats.items():
            if isinstance(value, torch.Tensor):
                if value.numel() == 1:
                    value = float(value.item())
                else:
                    continue
            elif not isinstance(value, (int, float)):
                continue
            summary[key] = summary.get(key, 0.0) + float(value)
            counts[key] = counts.get(key, 0) + 1
    for key, total in list(summary.items()):
        summary[key] = total / max(counts.get(key, 1), 1)
    return summary


def summarize_expert_usage(metrics: list[dict[str, float] | None], num_experts: int) -> Tensor | None:
    accum: Tensor | None = None
    count = 0
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        load_vec = layer_stats.get("load_vector")
        if load_vec is None:
            continue
        load_vec = load_vec.to(torch.float32)
        if load_vec.numel() != num_experts:
            continue
        if accum is None:
            accum = load_vec.clone()
        else:
            accum += load_vec
        count += 1
    if accum is None or count == 0:
        return None
    return (accum / count).cpu()


def summarize_expert_activity(metrics: list[dict[str, float] | None], num_experts: int) -> Tensor | None:
    accum: Tensor | None = None
    count = 0
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        load_vec = layer_stats.get("load_vector")
        if load_vec is None:
            continue
        load_vec = load_vec.to(torch.float32)
        if load_vec.numel() != num_experts:
            continue
        active = (load_vec > 0).to(torch.float32)
        if accum is None:
            accum = active.clone()
        else:
            accum += active
        count += 1
    if accum is None or count == 0:
        return None
    return (accum / count).cpu()


def router_summary_str(summary: dict[str, float], enable_forward_ema: bool, enable_reverse_ema: bool) -> str:
    if not summary:
        return "router=NA"
    fragments = []
    extra_keys: list[str] = []
    if enable_forward_ema:
        extra_keys.append("ema_alpha_forward")
    if enable_reverse_ema:
        extra_keys.append("ema_alpha_reverse")
    keys = ("imp_cv2", "load_cv2", "usage_frac", "topk_prob_mean", *extra_keys, "max_logit")
    for key in keys:
        val = summary.get(key, float("nan"))
        fragments.append(f"{key}={val:.4f}")
    return " ".join(fragments)
\n\n===== switch_bank/trainer.py =====\nimport copy
import math
import time
import os
from functools import lru_cache
from collections import defaultdict, deque

import torch
import torch.distributed as dist
import torch.nn.functional as F
from torch import nn

from switch_bank.utils import next_multiple_of_n, rampdown_multiplier
from switch_bank.data import (
    distributed_data_generator,
    summarize_router_metrics,
    summarize_expert_usage,
    summarize_expert_activity,
    router_summary_str,
)
from switch_bank.model.gpt import _compute_router_temp, _second_expert_step
from switch_bank.model.components import CausalSelfAttention

def get_lr(args, step: int):
    freeze_last = max(int(getattr(args, "lr_freeze_last_steps", 0)), 0)
    schedule_step = min(step, max(args.num_iterations - freeze_last, 0))
    x = schedule_step / max(args.num_iterations, 1)
    x = min(max(x, 0.0), 1.0)
    if x < 1 - args.cooldown_frac:
        return 1.0
    cooldown = max(args.cooldown_frac, 1e-8)
    t = (x - (1 - cooldown)) / cooldown
    t = min(max(t, 0.0), 1.0)
    final_mult = float(getattr(args, "lr_final_mult", 0.0))
    return 1.0 - t * (1.0 - final_mult)


@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)


def get_window_size_blocks(args, step: int):
    x = step / args.num_iterations
    assert 0 <= x <= 1
    factor = 4 * x ** 3 - 6 * x ** 2 + 3 * x
    window_size = next_multiple_of_n(3456 * factor, n=128)
    return get_window_size_blocks_helper(window_size)


def get_router_temp(args, step: int):
    return _compute_router_temp(
        step, args.num_iterations, args.router_temp_init, args.router_temp_final,
        args.router_temp_power, args.router_temp_anchor_delta_steps, args.router_temp_anchor_ratio,
        start_step=_second_expert_step(tuple(args.expert_activation_schedule)))


def get_logit_cap(args, step: int):
    start_step = _second_expert_step(tuple(args.expert_activation_schedule))
    delta = max(int(args.router_logit_cap_delta_steps), 0)
    start = args.router_logit_cap_initial
    end = args.router_logit_cap_final
    if delta <= 0:
        return end if end > 0 else None
    if step < start_step:
        return start if start > 0 else None
    frac = min(max((step - start_step) / max(delta, 1), 0.0), 1.0)
    if start <= 0 and end <= 0:
        return None
    if start <= 0:
        return end
    if end <= 0:
        return max(start * (1.0 - frac), 0.0)
    shaped = frac ** 4.0
    return start * math.exp(math.log(end / start) * shaped)

def gumbel_active(args, step: int):
    if not args.router_use_gumbel:
        return False
    schedule = getattr(args, "router_gumbel_schedule", ())
    for start, end in schedule:
        end_eff = args.num_iterations if end < 0 else end
        if start <= step < end_eff:
            return True
    return False


def _update_logit_stats(logit_stats: dict[str, float], max_logit: float, logit_cap: float | None):
    if logit_cap is None or logit_cap <= 0 or math.isnan(logit_cap):
        return
    if math.isnan(max_logit) or math.isinf(max_logit):
        return
    ratio = max_logit / logit_cap if logit_cap > 0 else float("nan")
    if math.isnan(ratio) or math.isinf(ratio):
        return
    ratio = min(max(ratio, 0.0), 1.5)
    logit_stats["count"] += 1.0
    logit_stats["sum_ratio"] += ratio
    if ratio >= 0.98:
        logit_stats["cap_hits"] += 1.0
    if ratio > logit_stats["max_ratio"]:
        logit_stats["max_ratio"] = ratio


def _finalize_logit_stats(logit_stats: dict[str, float]) -> dict[str, float]:
    count = int(logit_stats.get("count", 0.0))
    if count <= 0:
        return {
            "logit_cap_steps": 0.0,
            "logit_cap_hit_rate": float("nan"),
            "logit_cap_ratio_mean": float("nan"),
            "logit_cap_ratio_max": float("nan"),
            "logit_headroom_mean": float("nan"),
            "logit_score": float("nan"),
        }
    mean_ratio = logit_stats.get("sum_ratio", 0.0) / max(count, 1)
    cap_hit_rate = logit_stats.get("cap_hits", 0.0) / max(count, 1)
    ratio_target = 0.85
    ratio_score = 1.0 - abs(mean_ratio - ratio_target) / max(ratio_target, 1e-8)
    ratio_score = min(max(ratio_score, 0.0), 1.0)
    logit_score = 0.7 * (1.0 - cap_hit_rate) + 0.3 * ratio_score
    logit_score = min(max(logit_score, 0.0), 1.0)
    return {
        "logit_cap_steps": float(count),
        "logit_cap_hit_rate": float(cap_hit_rate),
        "logit_cap_ratio_mean": float(mean_ratio),
        "logit_cap_ratio_max": float(logit_stats.get("max_ratio", 0.0)),
        "logit_headroom_mean": float(1.0 - mean_ratio),
        "logit_score": float(logit_score),
    }


def run_training(
    args,
    model: nn.Module,
    optimizers: list[torch.optim.Optimizer],
    opt2params: dict,
    train_micro_len: int,
    untie_lm_head_after: int,
    run_id_full: str | None,
    master_process: bool,
    print0,
    code: str,
    wandb_run,
    metrics_csv_writer,
    expert_usage_headers: list[str],
    expert_active_headers: list[str],
    world_size: int,
    rank: int,
    log_param_counts_fn=None,
    start_step: int = 0,
    checkpoint_save_step: int = -1,
    early_stop_step: int | None = None,
    early_stop_val_multiplier: int = 1,
    early_stop_as_final: bool = False,
):
    training_time_ms = 0
    log_dir = getattr(args, "log_dir", "logs")
    approx_step_time_ms_resume = getattr(args, "approx_step_time_ms", None)
    train_loader = distributed_data_generator(
        args.train_files,
        world_size * train_micro_len,
        rank,
        world_size,
        skip_batches=start_step * args.grad_accum_steps,
    )
    print0("Starting training.", console=True)
    dist.barrier()
    t0 = time.perf_counter()
    train_steps = args.num_iterations
    stop_step = train_steps if early_stop_step is None else min(train_steps, early_stop_step)
    last_val_loss: float | None = None
    gumbel_prev_state = gumbel_active(args, start_step - 1) if start_step > 0 else gumbel_active(args, 0)
    logit_cap_decay_logged = False
    lm_head_untie_step = untie_lm_head_after
    lm_head_untied_logged = lm_head_untie_step < 0
    turbo_muon_warmstart_prev: bool | None = None
    turbo_muon_warmstart_start_step: int | None = None
    warmstart_start_frac = float(getattr(args, "turbo_muon_warmstart_smax_start_frac", -1.0))
    if warmstart_start_frac >= 0:
        turbo_muon_warmstart_start_step = int(warmstart_start_frac * train_steps)
        turbo_muon_warmstart_start_step = min(max(turbo_muon_warmstart_start_step, 0), train_steps)

    logit_stats = {"count": 0.0, "sum_ratio": 0.0, "cap_hits": 0.0, "max_ratio": 0.0}

    def run_validation(val_steps_multiplier: float, log_val_loss: bool, extra_log: dict | None = None, log_to_wandb: bool = True):
        nonlocal training_time_ms, t0, last_val_loss
        dist.barrier()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        print0("Running validation...")
        model.eval()
        prev_k = model.bank.k
        model.bank.k = int(args.topk if args.topk_val is None else max(1, min(args.topk_val, args.num_experts)))
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        base_steps = args.val_tokens // val_batch_size
        val_steps = int(round(base_steps * float(val_steps_multiplier)))
        val_steps = max(val_steps, 1)
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, window_blocks, step, args.num_iterations)
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_scalar = float(val_loss.detach().item())
        last_val_loss = val_scalar
        print0(
            f"step:{step}/{train_steps} val_loss:{val_scalar:.6f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms / max(step, 1):.2f}ms",
            console=True)
        if wandb_run is not None and log_to_wandb:
            log_payload = {
                "val/step": step,
                "perf/approx_step_time_ms": training_time_ms,
            }
            if log_val_loss:
                log_payload["val/loss"] = val_scalar
            if extra_log:
                log_payload.update(extra_log)
            wandb_run.log(log_payload, step=step)
        model.train()
        model.bank.k = prev_k
        dist.barrier()
        t0 = time.perf_counter()
        return val_scalar

    if start_step == 0 and (early_stop_step is None or early_stop_step > 0):
        step = 0
        window_blocks = get_window_size_blocks(args, step)
        tokens_target = getattr(args, "val_tokens_intermediate", None)
        if tokens_target is None:
            tokens_target = args.val_tokens
        val_steps_multiplier = float(tokens_target) / float(args.val_tokens)
        run_validation(val_steps_multiplier, log_val_loss=True)

    router_clip_base = getattr(args, "router_grad_clip_norm", None)
    router_clip_base = float(router_clip_base) if router_clip_base is not None else None
    if router_clip_base is not None and router_clip_base <= 0:
        router_clip_base = None
    router_params_by_opt: dict[torch.optim.Optimizer, list[nn.Parameter]] = {}
    router_autoclip = bool(getattr(args, "router_autoclip", False))
    autoclip_window = 250
    router_autoclip_state: dict[torch.optim.Optimizer, dict[str, object]] = {}
    needs_router_clip = router_autoclip or (router_clip_base is not None)
    if needs_router_clip:
        for opt in optimizers:
            params = []
            for group in opt.param_groups:
                if group.get("component") == "router":
                    params.extend(group["params"])
            if params:
                router_params_by_opt[opt] = params
                if router_autoclip:
                    initial_clip = router_clip_base if router_clip_base is not None else None
                    router_autoclip_state[opt] = {
                        "history": deque(maxlen=autoclip_window),
                        "clip": (initial_clip if (initial_clip is not None and initial_clip > 0) else None),
                    }

    for step in range(start_step, train_steps + 1):
        final_step = (step == train_steps)
        last_step = (step == stop_step)
        finalize_now = final_step or (early_stop_as_final and last_step)
        turbo_muon_warmstart_now = (
            turbo_muon_warmstart_start_step is not None and step >= turbo_muon_warmstart_start_step
        )
        if turbo_muon_warmstart_prev is None or turbo_muon_warmstart_now != turbo_muon_warmstart_prev:
            for opt in optimizers:
                if hasattr(opt, "set_turbomuon_warmstart_smax"):
                    opt.set_turbomuon_warmstart_smax(turbo_muon_warmstart_now)
            turbo_muon_warmstart_prev = turbo_muon_warmstart_now
        window_blocks = get_window_size_blocks(args, step)
        progress = step / max(train_steps, 1)
        gumbel_now = gumbel_active(args, step)
        if args.enable_extra_logging and gumbel_now != gumbel_prev_state:
            status = "enabled" if gumbel_now else "disabled"
            print0(f"Gumbel router noise {status} at step {step}", console=True)
        gumbel_prev_state = gumbel_now
        current_logit_cap = get_logit_cap(args, step)
        cap_start_step = _second_expert_step(tuple(args.expert_activation_schedule))
        if not logit_cap_decay_logged and step >= cap_start_step:
            cap_str = f"{current_logit_cap:.4f}" if current_logit_cap is not None else "disabled"
            if args.enable_extra_logging:
                print0(f"Router logit cap entered ramp at step {step}: cap={cap_str}", console=True)
            logit_cap_decay_logged = True
        if (not lm_head_untied_logged) and lm_head_untie_step >= 0 and step >= lm_head_untie_step:
            if args.enable_extra_logging:
                print0(f"LM head untied at step {step}", console=True)
            if log_param_counts_fn:
                log_param_counts_fn(model)
            lm_head_untied_logged = True

        if last_step or (step > 0 and args.val_loss_every > 0 and step % args.val_loss_every == 0):
            extra_log = None
            if last_step:
                extra_log = _finalize_logit_stats(logit_stats)
            tokens_target = getattr(args, "val_tokens", None)
            if finalize_now:
                final_tokens = getattr(args, "val_tokens_final", None)
                if final_tokens is not None:
                    tokens_target = final_tokens
            else:
                intermediate_tokens = getattr(args, "val_tokens_intermediate", None)
                if intermediate_tokens is not None:
                    tokens_target = intermediate_tokens
            val_steps_multiplier = float(tokens_target) / float(args.val_tokens)
            run_validation(val_steps_multiplier, log_val_loss=True, extra_log=extra_log)
            if last_step and not finalize_now:
                result = {"val_loss": last_val_loss, "stop_step": step, "aborted": False}
                result.update(_finalize_logit_stats(logit_stats))
                return result

        if last_step and finalize_now:
            should_save = getattr(args, "save_final_checkpoint", getattr(args, "save_checkpoint", False))
            if should_save and getattr(args, "save_final_checkpoint_if_loss_below", False):
                max_loss = float(getattr(args, "save_final_checkpoint_max_loss", float("inf")))
                should_save = last_val_loss is not None and math.isfinite(last_val_loss) and last_val_loss < max_loss
            if master_process and should_save:
                model_to_save = getattr(model, "_orig_mod", model)
                log = dict(step=step, code=code, model=model_to_save.state_dict())
                run_dir = os.path.join(log_dir, run_id_full)
                os.makedirs(run_dir, exist_ok=True)
                torch.save(log, os.path.join(run_dir, f"final_model_step{step:06d}.pt"))
            break

        model.zero_grad(set_to_none=True)
        micro_losses: list[float] = []
        micro_main_losses: list[float] = []
        micro_aux_losses: list[float] = []
        router_metric_accum: list[dict[str, float]] = []
        router_layer_metric_sums = [defaultdict(float) for _ in range(model.num_layers)]
        router_layer_metric_counts = [defaultdict(int) for _ in range(model.num_layers)]
        expert_usage_accum: list[torch.Tensor] = []
        expert_active_accum: list[torch.Tensor] = []
        for micro in range(args.grad_accum_steps):
            inputs, targets = next(train_loader)
            outputs = model(inputs, targets, window_blocks, step, args.num_iterations)
            if isinstance(outputs, tuple):
                loss_main, loss_aux = outputs
                loss_main_v = float(loss_main.detach().item())
                loss_aux_v = float(loss_aux.detach().item())
                loss_val = loss_main_v + loss_aux_v
                micro_losses.append(loss_val)
                micro_main_losses.append(loss_main_v)
                micro_aux_losses.append(loss_aux_v)
                loss_total = (loss_main + loss_aux) / args.grad_accum_steps
                loss_total.backward()
                components = (loss_main.detach(), loss_aux.detach())
                main_loss = loss_main_v
                aux_loss = loss_aux_v
            else:
                loss = outputs
                loss_val = float(loss.detach().item())
                micro_losses.append(loss_val)
                (loss / args.grad_accum_steps).backward()
                components = model.latest_loss_components
                main_loss = float(components[0].item()) if components else float("nan")
                aux_loss = float(components[1].item()) if components else float("nan")
                if not math.isnan(main_loss):
                    micro_main_losses.append(main_loss)
                if not math.isnan(aux_loss):
                    micro_aux_losses.append(aux_loss)
            router_summary = summarize_router_metrics(model.latest_router_metrics or [])
            if router_summary:
                router_metric_accum.append(router_summary)
            layer_metrics = model.latest_router_metrics or []
            for layer_idx, stats in enumerate(layer_metrics):
                if not stats:
                    continue
                layer_sum = router_layer_metric_sums[layer_idx]
                layer_count = router_layer_metric_counts[layer_idx]
                for key, value in stats.items():
                    scalar_val = None
                    if isinstance(value, torch.Tensor):
                        if value.numel() == 1:
                            scalar_val = float(value.item())
                        else:
                            continue
                    elif isinstance(value, (int, float)):
                        scalar_val = float(value)
                    else:
                        continue
                    layer_sum[key] += scalar_val
                    layer_count[key] += 1
            usage = summarize_expert_usage(layer_metrics, args.num_experts)
            if usage is not None:
                expert_usage_accum.append(usage)
            active = summarize_expert_activity(layer_metrics, args.num_experts)
            if active is not None:
                expert_active_accum.append(active)
            if args.enable_extra_logging:
                print0(
                    f"[train step {step} micro {micro + 1}/{args.grad_accum_steps}] "
                    f"loss={loss_val:.6f} main={main_loss:.6f} aux={aux_loss:.6f} "
                    f"{router_summary_str(router_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
                    console=True)

        avg_loss = sum(micro_losses) / max(len(micro_losses), 1)
        avg_main_loss = sum(micro_main_losses) / max(len(micro_main_losses), 1) if micro_main_losses else float("nan")
        avg_aux_loss = sum(micro_aux_losses) / max(len(micro_aux_losses), 1) if micro_aux_losses else float("nan")
        router_step_summary = summarize_router_metrics(router_metric_accum)
        router_layer_avg: dict[int, dict[str, float]] = {}
        for layer_idx in range(model.num_layers):
            sums = router_layer_metric_sums[layer_idx]
            if not sums:
                continue
            counts = router_layer_metric_counts[layer_idx]
            router_layer_avg[layer_idx] = {key: sums[key] / max(counts[key], 1) for key in sums}
        expert_usage = torch.stack(expert_usage_accum).mean(0) if expert_usage_accum else None
        expert_active = torch.stack(expert_active_accum).mean(0) if expert_active_accum else None
        pending_event = getattr(model, "_pending_active_count", None)
        if pending_event is not None:
            event_step, active_count = pending_event
            if wandb_run is not None:
                wandb_run.log({"router/active_experts": active_count}, step=event_step)
                wandb_run.log({"router/active_total_ffn_dim": active_count * args.ffn_hidden}, step=event_step)
            model._pending_active_count = None

        abort_flag = False
        abort_reason = ""
        if math.isnan(avg_loss) or math.isinf(avg_loss):
            abort_flag = True
            abort_reason = "non-finite avg_loss"
        elif not math.isnan(avg_main_loss) and not math.isinf(avg_main_loss) and math.isnan(avg_main_loss):
            abort_flag = True
            abort_reason = "non-finite main loss"
        else:
            max_logit_val = router_step_summary.get("max_logit", float("nan")) if router_step_summary else float("nan")
            if (not math.isnan(max_logit_val)) and (max_logit_val == 0.0 or math.isinf(max_logit_val)):
                abort_flag = True
                abort_reason = f"router max_logit suspicious ({max_logit_val})"

        abort_tensor = torch.tensor(1 if abort_flag else 0, device="cuda", dtype=torch.int32)
        dist.all_reduce(abort_tensor, op=dist.ReduceOp.SUM)
        if abort_tensor.item() > 0:
            if abort_reason and master_process:
                print0(f"Aborting training at step {step} due to: {abort_reason}", console=True)
            result = {"val_loss": last_val_loss, "stop_step": step, "aborted": True, "abort_reason": abort_reason}
            result.update(_finalize_logit_stats(logit_stats))
            return result

        opt2futures = {
            opt: [dist.all_reduce(p.grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
                  for p in params if (p.grad is not None)]
            for opt, params in opt2params.items()
        }

        progress = step / max(args.num_iterations, 1)
        router_lr_mult = rampdown_multiplier(progress, args.router_lr_reduce_start_frac, model.router_freeze_frac)
        adapter_lr_mult = router_lr_mult if args.router_freeze_adapters else 1.0
        ffn_lr_mult = rampdown_multiplier(progress, args.shared_ffn_lr_reduce_start_frac, model.shared_ffn_freeze_frac)
        for opt in optimizers:
            for group in opt.param_groups:
                base_lr = group["initial_lr"] * get_lr(args, step)
                component = group.get("component")
                mult = 1.0
                if component == "router":
                    mult = router_lr_mult
                elif component == "adapter":
                    mult = adapter_lr_mult
                elif component == "shared_ffn":
                    mult = ffn_lr_mult
                group["lr"] = base_lr * mult
        # Muon-style momentum warmup for spectral groups.
        target_muon_momentum = float(getattr(args, "muon_momentum", getattr(args, "neomuon_muon_momentum", 0.95)))
        frac = min(step / 300, 1)
        warm_momentum = (1 - frac) * 0.85 + frac * target_muon_momentum
        for opt in optimizers:
            for group in opt.param_groups:
                if group.get("spectral", True):
                    group["momentum"] = warm_momentum
        for opt in optimizers:
            torch.futures.collect_all(opt2futures[opt]).wait()
            if opt in router_params_by_opt:
                state = router_autoclip_state.get(opt)
                clip_value = router_clip_base
                if state is not None and state.get("clip") is not None:
                    clip_value = float(state["clip"])
                max_norm = clip_value if (clip_value is not None and clip_value > 0) else float("inf")
                total_norm = float(torch.nn.utils.clip_grad_norm_(router_params_by_opt[opt], max_norm))
                if state is not None:
                    history: deque = state["history"]  # type: ignore[assignment]
                    history.append(total_norm)
                    if len(history) >= autoclip_window:
                        hist_tensor = torch.tensor(list(history), device="cpu")
                        new_clip = float(torch.quantile(hist_tensor, 0.10).item())
                        new_clip = max(new_clip, 1e-6)
                        if state.get("clip") is None or not math.isclose(state["clip"], new_clip):
                            state["clip"] = new_clip
                            if args.enable_extra_logging:
                                print0(
                                    f"[router grad clip auto] norm={total_norm:.4f} clip-> {new_clip:.4f}",
                                    console=True,
                                )
                elif clip_value is not None and clip_value > 0 and args.enable_extra_logging and total_norm > clip_value:
                    print0(
                        f"[router grad clip] norm={total_norm:.4f} clip={clip_value:.4f}",
                        console=True,
                    )
            # Feed last activations to Muon for spectral gating.
            if hasattr(opt, "set_last_activation") and bool(getattr(opt, "enable_spectral_gating", False)):
                for group in opt.param_groups:
                    if not group.get("spectral", True):
                        continue
                    for p in group.get("params", []):
                        act = getattr(p, "_neomuon_last_activation", None)
                        if act is not None:
                            opt.set_last_activation(p, act)
            opt.step()
        model.zero_grad(set_to_none=True)
        if args.enable_extra_logging and router_layer_avg:
            metric_keys = ["imp_cv2", "load_cv2", "usage_frac", "topk_prob_mean"]
            if args.router_enable_forward_ema:
                metric_keys.append("ema_alpha_forward")
            if args.router_enable_reverse_ema:
                metric_keys.append("ema_alpha_reverse")
            layer_fragments = []
            for layer_idx in sorted(router_layer_avg):
                stats = router_layer_avg[layer_idx]
                metrics = ", ".join(f"{key}={stats.get(key, float('nan')):.4f}" for key in metric_keys if key in stats)
                layer_fragments.append(f"L{layer_idx}: {metrics}")
            print0("[router layers] " + " | ".join(layer_fragments), console=True)
        print0(
            f"[train step {step}] avg_loss={avg_loss:.6f} main={avg_main_loss:.6f} aux={avg_aux_loss:.6f} "
            f"{router_summary_str(router_step_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
            console=True)
        approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
        if approx_step_time_ms_resume is not None:
            approx_training_time_ms = approx_step_time_ms_resume
            # reset base timer so subsequent steps are correct
            training_time_ms = approx_step_time_ms_resume
            t0 = time.perf_counter()
            approx_step_time_ms_resume = None
        print0(
            f"step:{step + 1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms / (step + 1):.2f}ms",
            console=True)
        current_logit_cap = get_logit_cap(args, step)
        current_router_temp = get_router_temp(args, step)
        max_logit_val = router_step_summary.get("max_logit", float("nan")) if router_step_summary else float("nan")
        _update_logit_stats(logit_stats, max_logit_val, current_logit_cap)
        active_count_val = None
        if expert_active is not None:
            active_count_val = float(expert_active.mean().item() * args.num_experts)
        if active_count_val is None or active_count_val <= 0:
            active_count_val = float(args.num_experts)
        active_count_val = max(active_count_val, 1.0)
        if wandb_run is not None and (step % max(args.wandb_log_every, 1) == 0):
            if args.enable_extra_wandb_logging:
                # Preserve historical lr keys by mapping to first non-spectral/spectral groups.
                adamw_lr = next(
                    (g["lr"] for g in optimizers[0].param_groups if not g.get("spectral", True)),
                    float("nan"),
                )
                muon_lr = next(
                    (g["lr"] for g in optimizers[0].param_groups if g.get("spectral", True)),
                    float("nan"),
                )
                log_data = {
                    "train/loss": avg_loss,
                    "train/loss_main": avg_main_loss,
                    "train/loss_aux": avg_aux_loss,
                    "perf/approx_step_time_ms": approx_training_time_ms,
                    "train/tokens_seen": float((step + 1) * args.train_seq_len * world_size),
                    "lr/adamw": adamw_lr,
                    "lr/muon": muon_lr,
                    "train/step": step,
                    "router/logit_cap": (current_logit_cap if current_logit_cap is not None else float("nan")),
                    "router/logit_cap_enabled": float(current_logit_cap is not None),
                    "router/temperature": current_router_temp,
                    "router/max_logit": router_step_summary.get("max_logit", float("nan")),
                }
                # feature weight percentages
                feat_keys_all = [k for k in router_step_summary.keys() if k.startswith("feat_w_")]
                feat_keys = [k for k in feat_keys_all if k in ("feat_w_tok", "feat_w_ema_fwd", "feat_w_ema_rev", "feat_w_flags")]
                if not feat_keys:
                    feat_keys = feat_keys_all
                feat_total = sum(router_step_summary[k] for k in feat_keys) if feat_keys else 0.0
                if feat_total and feat_total != 0:
                    for k in feat_keys:
                        pct = 100.0 * router_step_summary[k] / feat_total
                        log_data[f"router/feat_pct/{k.replace('feat_w_', '')}"] = pct
                # normalized CV metrics
                imp_cv2 = router_step_summary.get("imp_cv2", float("nan"))
                load_cv2 = router_step_summary.get("load_cv2", float("nan"))
                log_data["router/imp_cv2_norm"] = imp_cv2 / active_count_val if not math.isnan(imp_cv2) else float("nan")
                log_data["router/load_cv2_norm"] = load_cv2 / active_count_val if not math.isnan(load_cv2) else float("nan")
                # entropy gaps
                expected_entropy = math.log(active_count_val) if active_count_val > 0 else float("nan")
                load_entropy = router_step_summary.get("load_entropy", float("nan"))
                imp_entropy = router_step_summary.get("imp_entropy", float("nan"))
                def _entropy_gap(val):
                    if math.isnan(val) or math.isnan(expected_entropy) or expected_entropy <= 0:
                        return float("nan")
                    return max(0.0, abs(expected_entropy - val) / expected_entropy)
                load_entropy_gap = _entropy_gap(load_entropy)
                imp_entropy_gap = _entropy_gap(imp_entropy)
                log_data["router/load_entropy_gap"] = load_entropy_gap
                log_data["router/imp_entropy_gap"] = imp_entropy_gap
                # usage gap and health score
                usage_frac = router_step_summary.get("usage_frac", float("nan"))
                target_usage = min(1.0, active_count_val / max(args.num_experts, 1))
                usage_gap = abs(usage_frac - target_usage) if not math.isnan(usage_frac) else float("nan")
                weights = {
                    "imp_cv2_norm": 0.8,
                    "load_cv2_norm": 0.9,
                    "load_entropy_gap": 0.5,
                    "imp_entropy_gap": 0.2,
                    "usage_gap": 1.25,
                }
                components_weighted = []
                components_weighted.append(weights["imp_cv2_norm"] * log_data["router/imp_cv2_norm"] if not math.isnan(log_data["router/imp_cv2_norm"]) else float("nan"))
                components_weighted.append(weights["load_cv2_norm"] * log_data["router/load_cv2_norm"] if not math.isnan(log_data["router/load_cv2_norm"]) else float("nan"))
                components_weighted.append(weights["load_entropy_gap"] * load_entropy_gap if not math.isnan(load_entropy_gap) else float("nan"))
                components_weighted.append(weights["imp_entropy_gap"] * imp_entropy_gap if not math.isnan(imp_entropy_gap) else float("nan"))
                components_weighted.append(weights["usage_gap"] * usage_gap if not math.isnan(usage_gap) else float("nan"))
                health_terms = [v for v in components_weighted if not math.isnan(v)]
                if health_terms:
                    health_penalty = sum(health_terms)
                    log_data["router/health_score"] = 1.0 / (1.0 + health_penalty)
                    health_penalty = health_penalty
                    log_data["router/health_penalty"] = health_penalty
                # raw router stats (skip feat_w_*; percents already logged)
                for key, value in router_step_summary.items():
                    if key.startswith("feat_w_"):
                        continue
                    log_data[f"router/{key}"] = value
                for layer_idx, stats in router_layer_avg.items():
                    for key, value in stats.items():
                        log_data[f"router_layer/{layer_idx}/{key}"] = value
                if expert_usage is not None:
                    expert_list = expert_usage.tolist()
                    log_data["router_expert/min_usage"] = float(min(expert_list))
                    log_data["router_expert/max_usage"] = float(max(expert_list))
                    log_data["router_expert/mean_usage"] = float(sum(expert_list) / len(expert_list))
                    for idx, value in enumerate(expert_list):
                        log_data[f"router_expert/e{idx}"] = float(value)
                if expert_active is not None:
                    base_model = getattr(model, "_orig_mod", model)
                    scheduled_active = getattr(base_model, "_current_base_active", None)
                    active_count = args.num_experts
                    if isinstance(scheduled_active, int):
                        active_count = max(1, min(args.num_experts, scheduled_active))
                    inferred_active = expert_active.sum().item()
                    if inferred_active > 0:
                        active_count = max(1, min(active_count, int(round(inferred_active))))
                    source = expert_usage if expert_usage is not None else expert_active
                    active_list = source.tolist()
                    active_slice = active_list[:active_count] if active_list else []
                    if not active_slice:
                        active_slice = [0.0]
                    denom = sum(active_slice)
                    if denom > 0:
                        active_slice = [v / denom for v in active_slice]
                    log_data["router_expert_active/min"] = float(min(active_slice))
                    log_data["router_expert_active/max"] = float(max(active_slice))
                    log_data["router_expert_active/mean"] = float(sum(active_slice) / len(active_slice))
                    per_expert = []
                    for idx in range(args.num_experts):
                        if idx < active_count and idx < len(active_slice):
                            per_expert.append(float(active_slice[idx]))
                        else:
                            per_expert.append(0.0)
                    for idx, value in enumerate(per_expert):
                        log_data[f"router_expert_active/e{idx}"] = value
                wandb_run.log(log_data, step=step)
            else:
                wandb_run.log(
                    {
                        "train/loss": avg_loss,
                        "train/loss_main": avg_main_loss,
                        "train/loss_aux": avg_aux_loss,
                        "perf/approx_step_time_ms": approx_training_time_ms,
                        "train/tokens_seen": float((step + 1) * args.train_seq_len * world_size),
                        "train/step": step,
                        "router/logit_cap": (current_logit_cap if current_logit_cap is not None else float("nan")),
                        "router/temperature": current_router_temp,
                    },
                    step=step,
                )
        if master_process and metrics_csv_writer and (step % max(args.metrics_log_every, 1) == 0):
            expert_usage_list = []
            if expert_usage is not None:
                expert_usage_list = [float(x) for x in expert_usage.tolist()]
            else:
                expert_usage_list = [float("nan")] * len(expert_usage_headers)
            expert_active_list = []
            if expert_active is not None:
                expert_active_list = [float(x) for x in expert_active.tolist()]
            else:
                expert_active_list = [float("nan")] * len(expert_active_headers)
            router_ema_vals: list[float] = []
            if args.router_enable_forward_ema:
                router_ema_vals.append(router_step_summary.get("ema_alpha_forward", float("nan")))
            if args.router_enable_reverse_ema:
                router_ema_vals.append(router_step_summary.get("ema_alpha_reverse", float("nan")))
            row = [
                step,
                avg_loss,
                avg_main_loss,
                avg_aux_loss,
                router_step_summary.get("imp_cv2", float("nan")),
                router_step_summary.get("load_cv2", float("nan")),
                router_step_summary.get("usage_frac", float("nan")),
                router_step_summary.get("topk_prob_mean", float("nan")),
                *router_ema_vals,
                router_step_summary.get("max_logit", float("nan")),
                (current_logit_cap if current_logit_cap is not None else float("nan")),
                current_router_temp,
                int(window_blocks.item()),
                *expert_usage_list,
                *expert_active_list,
            ]
            metrics_csv_writer.writerow(row)
        if master_process and checkpoint_save_step >= 0 and step == checkpoint_save_step:
            run_dir = os.path.join(log_dir, run_id_full)
            os.makedirs(run_dir, exist_ok=True)
            model_to_save = getattr(model, "_orig_mod", model)
            checkpoint_payload = dict(
                step=step,
                code=code,
                model=model_to_save.state_dict(),
                optimizers=[opt.state_dict() for opt in optimizers],
                approx_step_time_ms=approx_training_time_ms,
                meta=dict(
                    model_dim=getattr(args, "model_dim", None),
                    num_layers=getattr(args, "num_layers", None),
                    num_heads=getattr(args, "num_heads", None),
                    num_experts=getattr(args, "num_experts", None),
                    ffn_hidden=getattr(args, "ffn_hidden", None),
                    vocab_size=getattr(args, "vocab_size", None),
                ),
            )
            torch.save(checkpoint_payload, os.path.join(run_dir, f"state_step{step:06d}.pt"))

    result = {"val_loss": last_val_loss, "stop_step": stop_step, "aborted": False}
    result.update(_finalize_logit_stats(logit_stats))
    return result

====================================================================================================
Running Python 3.10.12 (main, Nov  4 2025, 08:48:33) [GCC 11.4.0]
Running PyTorch 2.10.0.dev20251210+cu126 compiled for CUDA 12.6
Sat Dec 27 22:26:39 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          Off |   00000000:19:00.0 Off |                    0 |
| N/A   29C    P0            117W /  700W |    5858MiB /  81559MiB |      1%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          Off |   00000000:3B:00.0 Off |                    0 |
| N/A   26C    P0            118W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          Off |   00000000:4C:00.0 Off |                    0 |
| N/A   23C    P0            115W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          Off |   00000000:5D:00.0 Off |                    0 |
| N/A   27C    P0            116W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          Off |   00000000:9B:00.0 Off |                    0 |
| N/A   27C    P0            117W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          Off |   00000000:BB:00.0 Off |                    0 |
| N/A   26C    P0            121W /  700W |    2766MiB /  81559MiB |    100%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          Off |   00000000:CB:00.0 Off |                    0 |
| N/A   56C    P0            142W /  700W |    2766MiB /  81559MiB |     96%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          Off |   00000000:DB:00.0 Off |                    0 |
| N/A   23C    P0            115W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    163508      C   /usr/bin/python3                             1510MiB |
|    0   N/A  N/A    163509      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    163510      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    163511      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    163512      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    163513      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    163514      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    163515      C   /usr/bin/python3                              614MiB |
|    1   N/A  N/A    163509      C   /usr/bin/python3                             1510MiB |
|    2   N/A  N/A    163510      C   /usr/bin/python3                             1510MiB |
|    3   N/A  N/A    163511      C   /usr/bin/python3                             1510MiB |
|    4   N/A  N/A    163512      C   /usr/bin/python3                             1510MiB |
|    5   N/A  N/A    163513      C   /usr/bin/python3                             2756MiB |
|    6   N/A  N/A    163514      C   /usr/bin/python3                             2756MiB |
|    7   N/A  N/A    163515      C   /usr/bin/python3                             1510MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
=== Parameter counts ===
model total:           282,395,148 (282.395M)
  attention stack (27 of 28 layers run attention): 86,704,128 (86.704M)
  FFN bank total:      15,084,160 (15.084M)
    ├─ experts W1/W2:  14,680,064 (14.680M)
    └─ routers:        404,096 (0.404M)
  embeddings (tok + 2× value): 135,132,928 (135.133M)
    └─ token embed:    45,072,384 (45.072M)
    └─ value embeds:   90,060,544 (90.061M)
  lm head (untied):   45,072,384 (45.072M)
  adapters:            401,408 (0.401M)
  scalars:             140 (0.000M)
====================================================================================================
Compiling model...
Compile complete.
Warming up kernels...
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/fq/cfqixvmxmiuyvximhm5cxovwynazccyxrjgpoqksbci2miqaptdo.py
inductor_output_code: /tmp/torchinductor_ubuntu/4l/c4ljprwocn4kfjpeoxx76qdg4kx3ryurg2ybcvofnmnpknnprl3n.py
inductor_output_code: /tmp/torchinductor_ubuntu/hb/chb2bnc3t74wttigx46vmvyli2swsbmgb3swroqvtdxwqgno3gef.py
inductor_output_code: /tmp/torchinductor_ubuntu/7m/c7mcceaqwhkxfo25gtt6z6deh5kc24e5larml3tir64zzlg7u2ls.py
inductor_output_code: /tmp/torchinductor_ubuntu/mr/cmrf5iwusj7ppaxt65o3cka54gvs3nskkxbibvcq2ec3flayler5.py
inductor_output_code: /tmp/torchinductor_ubuntu/y2/cy27xexdq3uy24qdnom66lejnydlviosxblbrahtgxlcjsn2nfcu.py
inductor_output_code: /tmp/torchinductor_ubuntu/kj/ckjscjlqwgbvzl5chr4w7asosnyptemylrorotmc5dafgo6mgdyg.py
inductor_output_code: /tmp/torchinductor_ubuntu/om/comnhqjt5ejns5cvw3lsgn6oofsjpbn2mc65likenpblbjttjr4k.py
inductor_output_code: /tmp/torchinductor_ubuntu/ic/cicajx3cn44vgfp2hj4yrxsu4zg55ao6s5tuuzf3gqynb4n5aei3.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/4g/c4g7sx7n5znkhhbc54uqvdxktlpbohoatd22todbxakltfuyq7xj.py
inductor_output_code: /tmp/torchinductor_ubuntu/vz/cvzmihtwtvc4z436rlwnps5vjvj3khdnsbx4fhlpaaoxcuxtxjjr.py
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/ei/ceihzmsbtrr2gp4tg4iqjfqdox5czomhvweztpj5b3c5y3wuf473.py
inductor_output_code: /tmp/torchinductor_ubuntu/27/c27xigeeuwotem6hlshv23nb7xvsj3zjrwayehurvqr4pri2hats.py
inductor_output_code: /tmp/torchinductor_ubuntu/44/c44gfjrynanau4olb5cxz6mvnnwlbo26bo4dvres3z3cq42scgkh.py
inductor_output_code: /tmp/torchinductor_ubuntu/ql/cqlbbiv4tnpmphfpqbquz37q4qqn767c5yjmdchujey6omwmvqqy.py
inductor_output_code: /tmp/torchinductor_ubuntu/xs/cxsnpngitcah7e2kduknn7ceti7je4v2j3yumztw47bcu6za6mcu.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vo/cvokruoazaxmhkd6d2kuiaagltu6u3rpovkqcrbndwwz3ltbk75q.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/nw/cnwmvztqrbjwoi473u5qitnxkngbgcuw5kcyf7re5yovaflz7lu2.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ea/ceaq2lx6uciw27w63cxgcnqqm5xteez6dezf5mx5sqok2gv4cg6l.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ps/cpsliltnujy72slrbeq44fp3oye3ldviqbljjv3inoa66dlmk5lg.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/7z/c7zihhtgrytywzcdhlvc2uyabsvsfqf3mzdih3d64vy3fjr2auvg.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vf/cvfa6qtw4adef6nklcpbiwjwtshopzljqwyglpakkzkfskqglq26.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/yy/cyyy3jozpp7o3m6jxcbmv5ytzhs2p2pszf4ryo5wjrtjur5wzwrn.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vn/cvnp3hye32d6gtum6ssg53ko23znadoaop747hdwkw7tlcar4dik.py
inductor_output_code: /tmp/torchinductor_ubuntu/qi/cqijmax67f7bnmnslxmq64yo422uqudtakvm7wifucvc4zt32h57.py
inductor_output_code: /tmp/torchinductor_ubuntu/rk/crk7su4b7xpejvheo5gz6rpdorzzgpth65exdwfvo7ezfgyzgqfh.py
inductor_output_code: /tmp/torchinductor_ubuntu/ha/chaulm7ltsokkarrumul5qjrnx4ahkimqhauxh26exd2hcuk3l7x.py
inductor_output_code: /tmp/torchinductor_ubuntu/xp/cxpgiz2wiajvso43kie77hcmxvtsiaqz2te7otoesquvdyoapxm6.py
inductor_output_code: /tmp/torchinductor_ubuntu/ry/crykauzc3oifekn667dgcyrf5bibnkbghoch5mqvljqasw2k7aqg.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/kl/ckllj5sjejqdb6ipkfp4m745swsno7n6gygf22clrcp74t3u3wti.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/z5/cz5f7iwr6al2eokhvc2i57wbq3sgdcans5vfvv6wx3fp5ammhigu.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/n4/cn4fwpvyaac5phl4qcqmrfwwi646mxowmyuqb57mj5mnnzskkapw.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/zd/czdr7mghhrcxjpxd4e7awowuyl4xv64mqklrxdzlbgmtg2ikmnlo.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ml/cml5y4cguscckibnxjkdkym25pt2fgjmvitan7zr4ybgrlraqps6.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/pe/cpeghbtcj37h3j2ztaq7llhet653sbihhvmnsvv7eqh6vopspdii.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/qg/cqgedru6kihsfgglrxbjmedufnrcaydomq3kwszain4vavckrgxu.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/r5/cr5klalefi6b6skemtsuq7frgj2ouai7ilonjkvwg5o574xtchjg.py
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/mc/cmcm6fww7tjiwmcvahcg4lzc7lyqpox2n56ccnewo33dhcin2knk.py
inductor_output_code: /tmp/torchinductor_ubuntu/p4/cp4fa4yeij2caf5yvvh2et4fngrovgk5x7w6srdh2i2o2bjjz6cb.py
inductor_output_code: /tmp/torchinductor_ubuntu/7c/c7ckg2hjgek3w2j6waxt5d5ffzdyeznjkhbqtrcmn42no6x5td3d.py
Kernel warmup complete.
Starting training.
Running validation...
step:0/1750 val_loss:10.960747 train_time:1ms step_avg:0.94ms
[train step 0] avg_loss=10.955255 main=10.955255 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:1/1750 train_time:282ms step_avg:281.91ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 1] avg_loss=10.105411 main=10.105411 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:2/1750 train_time:661ms step_avg:330.57ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 2] avg_loss=8.350322 main=8.350322 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:3/1750 train_time:1234ms step_avg:411.40ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 3] avg_loss=7.886352 main=7.886352 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:4/1750 train_time:1831ms step_avg:457.64ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 4] avg_loss=7.165972 main=7.165972 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:5/1750 train_time:2207ms step_avg:441.47ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 5] avg_loss=7.720235 main=7.720235 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:6/1750 train_time:2594ms step_avg:432.28ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 6] avg_loss=7.338155 main=7.338155 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:7/1750 train_time:2966ms step_avg:423.78ms
[train step 7] avg_loss=6.893276 main=6.893276 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:8/1750 train_time:3188ms step_avg:398.49ms
[train step 8] avg_loss=6.771872 main=6.771872 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:9/1750 train_time:3409ms step_avg:378.83ms
[train step 9] avg_loss=7.175312 main=7.175312 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:10/1750 train_time:3631ms step_avg:363.11ms
[train step 10] avg_loss=7.057865 main=7.057865 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:11/1750 train_time:3852ms step_avg:350.20ms
[train step 11] avg_loss=6.814643 main=6.814643 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:12/1750 train_time:4077ms step_avg:339.79ms
[train step 12] avg_loss=6.569028 main=6.569028 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:13/1750 train_time:4299ms step_avg:330.69ms
[train step 13] avg_loss=6.607749 main=6.607749 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:14/1750 train_time:4521ms step_avg:322.92ms
[train step 14] avg_loss=6.327837 main=6.327837 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:15/1750 train_time:4742ms step_avg:316.13ms
[train step 15] avg_loss=6.492425 main=6.492425 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:16/1750 train_time:4963ms step_avg:310.19ms
[train step 16] avg_loss=6.168610 main=6.168610 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:17/1750 train_time:5185ms step_avg:304.98ms
[train step 17] avg_loss=6.232407 main=6.232407 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:18/1750 train_time:5407ms step_avg:300.39ms
[train step 18] avg_loss=6.370092 main=6.370092 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:19/1750 train_time:5630ms step_avg:296.32ms
[train step 19] avg_loss=6.048681 main=6.048681 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:20/1750 train_time:5851ms step_avg:292.55ms
[train step 20] avg_loss=6.540887 main=6.540887 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:21/1750 train_time:6074ms step_avg:289.22ms
[train step 21] avg_loss=6.436309 main=6.436309 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:22/1750 train_time:6295ms step_avg:286.12ms
[train step 22] avg_loss=6.270456 main=6.270456 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:23/1750 train_time:6516ms step_avg:283.32ms
[train step 23] avg_loss=6.383236 main=6.383236 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:24/1750 train_time:6738ms step_avg:280.75ms
[train step 24] avg_loss=6.122234 main=6.122234 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:25/1750 train_time:6963ms step_avg:278.50ms
[train step 25] avg_loss=6.008073 main=6.008073 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:26/1750 train_time:7185ms step_avg:276.36ms
[train step 26] avg_loss=6.117113 main=6.117113 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:27/1750 train_time:7407ms step_avg:274.32ms
[train step 27] avg_loss=5.989127 main=5.989127 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:28/1750 train_time:7628ms step_avg:272.43ms
[train step 28] avg_loss=5.661778 main=5.661778 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:29/1750 train_time:7849ms step_avg:270.67ms
[train step 29] avg_loss=6.102859 main=6.102859 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:30/1750 train_time:8071ms step_avg:269.02ms
[train step 30] avg_loss=5.912609 main=5.912609 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:31/1750 train_time:8292ms step_avg:267.48ms
[train step 31] avg_loss=6.055480 main=6.055480 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:32/1750 train_time:8513ms step_avg:266.03ms
[train step 32] avg_loss=6.185842 main=6.185842 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:33/1750 train_time:8734ms step_avg:264.66ms
[train step 33] avg_loss=5.930151 main=5.930151 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:34/1750 train_time:8956ms step_avg:263.40ms
[train step 34] avg_loss=6.275693 main=6.275693 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:35/1750 train_time:9176ms step_avg:262.17ms
[train step 35] avg_loss=6.147295 main=6.147295 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:36/1750 train_time:9397ms step_avg:261.02ms
[train step 36] avg_loss=5.634508 main=5.634508 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:37/1750 train_time:9618ms step_avg:259.94ms
[train step 37] avg_loss=5.880469 main=5.880469 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:38/1750 train_time:9839ms step_avg:258.91ms
[train step 38] avg_loss=5.657722 main=5.657722 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:39/1750 train_time:10061ms step_avg:257.98ms
[train step 39] avg_loss=5.930722 main=5.930722 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:40/1750 train_time:10286ms step_avg:257.14ms
[train step 40] avg_loss=4.527934 main=4.527934 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:41/1750 train_time:10506ms step_avg:256.24ms
[train step 41] avg_loss=5.921324 main=5.921324 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:42/1750 train_time:10727ms step_avg:255.39ms
[train step 42] avg_loss=5.500467 main=5.500467 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:43/1750 train_time:10947ms step_avg:254.58ms
[train step 43] avg_loss=5.712041 main=5.712041 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:44/1750 train_time:11168ms step_avg:253.81ms
[train step 44] avg_loss=5.783212 main=5.783212 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:45/1750 train_time:11388ms step_avg:253.07ms
[train step 45] avg_loss=5.895257 main=5.895257 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:46/1750 train_time:11612ms step_avg:252.43ms
[train step 46] avg_loss=5.481053 main=5.481053 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:47/1750 train_time:11833ms step_avg:251.76ms
[train step 47] avg_loss=5.508907 main=5.508907 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:48/1750 train_time:12056ms step_avg:251.16ms
[train step 48] avg_loss=5.893668 main=5.893668 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:49/1750 train_time:12277ms step_avg:250.54ms
[train step 49] avg_loss=5.607710 main=5.607710 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:50/1750 train_time:12498ms step_avg:249.96ms
Running validation...
step:50/1750 val_loss:5.804089 train_time:12514ms step_avg:250.29ms
[train step 50] avg_loss=5.482712 main=5.482712 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:51/1750 train_time:12726ms step_avg:249.52ms
[train step 51] avg_loss=5.584536 main=5.584536 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:52/1750 train_time:12947ms step_avg:248.98ms
[train step 52] avg_loss=5.356893 main=5.356893 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:53/1750 train_time:13168ms step_avg:248.45ms
[train step 53] avg_loss=5.619460 main=5.619460 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:54/1750 train_time:13390ms step_avg:247.97ms
[train step 54] avg_loss=5.506832 main=5.506832 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:55/1750 train_time:13611ms step_avg:247.47ms
[train step 55] avg_loss=5.498993 main=5.498993 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:56/1750 train_time:13832ms step_avg:247.00ms
[train step 56] avg_loss=5.628854 main=5.628854 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:57/1750 train_time:14054ms step_avg:246.56ms
[train step 57] avg_loss=5.496716 main=5.496716 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:58/1750 train_time:14275ms step_avg:246.12ms
[train step 58] avg_loss=6.501978 main=6.501978 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:59/1750 train_time:14497ms step_avg:245.71ms
[train step 59] avg_loss=5.484051 main=5.484051 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:60/1750 train_time:14719ms step_avg:245.32ms
[train step 60] avg_loss=5.644764 main=5.644764 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:61/1750 train_time:14940ms step_avg:244.92ms
[train step 61] avg_loss=5.253979 main=5.253979 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:62/1750 train_time:15161ms step_avg:244.53ms
[train step 62] avg_loss=5.546587 main=5.546587 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:63/1750 train_time:15381ms step_avg:244.15ms
[train step 63] avg_loss=5.653642 main=5.653642 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:64/1750 train_time:15602ms step_avg:243.79ms
[train step 64] avg_loss=5.348862 main=5.348862 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:65/1750 train_time:15827ms step_avg:243.50ms
[train step 65] avg_loss=5.464801 main=5.464801 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:66/1750 train_time:16049ms step_avg:243.17ms
[train step 66] avg_loss=5.741407 main=5.741407 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:67/1750 train_time:16270ms step_avg:242.84ms
[train step 67] avg_loss=5.526264 main=5.526264 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:68/1750 train_time:16493ms step_avg:242.55ms
[train step 68] avg_loss=5.522314 main=5.522314 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:69/1750 train_time:16716ms step_avg:242.25ms
[train step 69] avg_loss=5.650893 main=5.650893 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:70/1750 train_time:16936ms step_avg:241.95ms
[train step 70] avg_loss=5.561983 main=5.561983 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:71/1750 train_time:17157ms step_avg:241.65ms
[train step 71] avg_loss=5.300922 main=5.300922 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:72/1750 train_time:17380ms step_avg:241.39ms
[train step 72] avg_loss=5.372353 main=5.372353 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:73/1750 train_time:17604ms step_avg:241.15ms
[train step 73] avg_loss=4.995206 main=4.995206 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:74/1750 train_time:17826ms step_avg:240.89ms
[train step 74] avg_loss=5.367181 main=5.367181 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:75/1750 train_time:18048ms step_avg:240.63ms
[train step 75] avg_loss=5.796942 main=5.345099 aux=0.451843 imp_cv2=3.0097 load_cv2=3.0343 usage_frac=0.2500 topk_prob_mean=0.6632 ema_alpha_reverse=nan max_logit=1.1660
step:76/1750 train_time:18937ms step_avg:249.16ms
[train step 76] avg_loss=6.518438 main=5.491284 aux=1.027155 imp_cv2=5.5104 load_cv2=6.8750 usage_frac=0.2411 topk_prob_mean=0.8851 ema_alpha_reverse=nan max_logit=1.1660
step:77/1750 train_time:19431ms step_avg:252.36ms
[train step 77] avg_loss=6.613915 main=5.578829 aux=1.035086 imp_cv2=5.5012 load_cv2=6.9641 usage_frac=0.2500 topk_prob_mean=0.8832 ema_alpha_reverse=nan max_logit=1.1660
step:78/1750 train_time:19868ms step_avg:254.71ms
[train step 78] avg_loss=6.600680 main=5.566181 aux=1.034498 imp_cv2=5.4908 load_cv2=6.9677 usage_frac=0.2500 topk_prob_mean=0.8817 ema_alpha_reverse=nan max_logit=1.1660
step:79/1750 train_time:20329ms step_avg:257.33ms
[train step 79] avg_loss=6.592299 main=5.558524 aux=1.033775 imp_cv2=5.4770 load_cv2=6.9739 usage_frac=0.2455 topk_prob_mean=0.8807 ema_alpha_reverse=nan max_logit=1.1660
step:80/1750 train_time:20857ms step_avg:260.71ms
[train step 80] avg_loss=6.709504 main=5.684068 aux=1.025435 imp_cv2=5.4342 load_cv2=6.9340 usage_frac=0.2455 topk_prob_mean=0.8789 ema_alpha_reverse=nan max_logit=1.1660
step:81/1750 train_time:21369ms step_avg:263.82ms
[train step 81] avg_loss=6.314516 main=5.301207 aux=1.013309 imp_cv2=5.3679 load_cv2=6.8767 usage_frac=0.2411 topk_prob_mean=0.8761 ema_alpha_reverse=nan max_logit=1.1660
step:82/1750 train_time:21983ms step_avg:268.08ms
[train step 82] avg_loss=6.145538 main=5.171608 aux=0.973930 imp_cv2=5.1842 load_cv2=6.6582 usage_frac=0.2455 topk_prob_mean=0.8711 ema_alpha_reverse=nan max_logit=1.1660
step:83/1750 train_time:22635ms step_avg:272.71ms
[train step 83] avg_loss=6.247580 main=5.325949 aux=0.921631 imp_cv2=4.9268 load_cv2=6.3732 usage_frac=0.2500 topk_prob_mean=0.8582 ema_alpha_reverse=nan max_logit=1.1660
step:84/1750 train_time:23310ms step_avg:277.50ms
[train step 84] avg_loss=6.476749 main=5.575726 aux=0.901023 imp_cv2=4.8312 load_cv2=6.2505 usage_frac=0.2455 topk_prob_mean=0.8543 ema_alpha_reverse=nan max_logit=1.1660
step:85/1750 train_time:24052ms step_avg:282.96ms
[train step 85] avg_loss=6.491268 main=5.712312 aux=0.778956 imp_cv2=4.3409 load_cv2=5.4079 usage_frac=0.2500 topk_prob_mean=0.8453 ema_alpha_reverse=nan max_logit=1.1660
step:86/1750 train_time:24821ms step_avg:288.62ms
[train step 86] avg_loss=5.966712 main=5.208341 aux=0.758371 imp_cv2=4.2595 load_cv2=5.2729 usage_frac=0.2500 topk_prob_mean=0.8400 ema_alpha_reverse=nan max_logit=1.1660
step:87/1750 train_time:25584ms step_avg:294.07ms
[train step 87] avg_loss=5.943754 main=5.301975 aux=0.641779 imp_cv2=3.8049 load_cv2=4.4416 usage_frac=0.2500 topk_prob_mean=0.8451 ema_alpha_reverse=nan max_logit=1.1660
step:88/1750 train_time:26279ms step_avg:298.62ms
[train step 88] avg_loss=5.554870 main=4.935658 aux=0.619212 imp_cv2=3.6962 load_cv2=4.3064 usage_frac=0.2500 topk_prob_mean=0.8399 ema_alpha_reverse=nan max_logit=1.1660
step:89/1750 train_time:26945ms step_avg:302.76ms
[train step 89] avg_loss=6.066307 main=5.501455 aux=0.564853 imp_cv2=3.4493 load_cv2=3.9360 usage_frac=0.2500 topk_prob_mean=0.8389 ema_alpha_reverse=nan max_logit=1.1660
step:90/1750 train_time:27605ms step_avg:306.73ms
[train step 90] avg_loss=5.888341 main=5.331265 aux=0.557076 imp_cv2=3.3581 load_cv2=3.9246 usage_frac=0.2500 topk_prob_mean=0.8357 ema_alpha_reverse=nan max_logit=1.1660
step:91/1750 train_time:28277ms step_avg:310.73ms
[train step 91] avg_loss=5.905430 main=5.364800 aux=0.540630 imp_cv2=3.2749 load_cv2=3.8105 usage_frac=0.2500 topk_prob_mean=0.8399 ema_alpha_reverse=nan max_logit=1.1661
step:92/1750 train_time:28923ms step_avg:314.38ms
[train step 92] avg_loss=6.088032 main=5.559298 aux=0.528735 imp_cv2=3.2110 load_cv2=3.7261 usage_frac=0.2500 topk_prob_mean=0.8420 ema_alpha_reverse=nan max_logit=1.1661
step:93/1750 train_time:29563ms step_avg:317.88ms
[train step 93] avg_loss=6.540283 main=6.012680 aux=0.527603 imp_cv2=3.1754 load_cv2=3.7352 usage_frac=0.2500 topk_prob_mean=0.8427 ema_alpha_reverse=nan max_logit=1.1661
step:94/1750 train_time:30213ms step_avg:321.41ms
[train step 94] avg_loss=5.764217 main=5.219246 aux=0.544971 imp_cv2=3.1954 load_cv2=3.9046 usage_frac=0.2500 topk_prob_mean=0.8354 ema_alpha_reverse=nan max_logit=1.1661
step:95/1750 train_time:30845ms step_avg:324.69ms
[train step 95] avg_loss=5.839535 main=5.301747 aux=0.537789 imp_cv2=3.1408 load_cv2=3.8599 usage_frac=0.2500 topk_prob_mean=0.8307 ema_alpha_reverse=nan max_logit=1.1661
step:96/1750 train_time:31470ms step_avg:327.82ms
[train step 96] avg_loss=5.781624 main=5.255947 aux=0.525678 imp_cv2=3.0866 load_cv2=3.7621 usage_frac=0.2500 topk_prob_mean=0.8294 ema_alpha_reverse=nan max_logit=1.1662
step:97/1750 train_time:32106ms step_avg:330.99ms
[train step 97] avg_loss=5.704341 main=5.179842 aux=0.524500 imp_cv2=3.0708 load_cv2=3.7571 usage_frac=0.2500 topk_prob_mean=0.8309 ema_alpha_reverse=nan max_logit=1.1662
step:98/1750 train_time:32743ms step_avg:334.11ms
[train step 98] avg_loss=5.975214 main=5.457814 aux=0.517400 imp_cv2=3.0422 load_cv2=3.6954 usage_frac=0.2500 topk_prob_mean=0.8276 ema_alpha_reverse=nan max_logit=1.1663
step:99/1750 train_time:33380ms step_avg:337.17ms
[train step 99] avg_loss=6.055514 main=5.536466 aux=0.519048 imp_cv2=3.0554 load_cv2=3.7070 usage_frac=0.2500 topk_prob_mean=0.8301 ema_alpha_reverse=nan max_logit=1.1663
step:100/1750 train_time:34007ms step_avg:340.07ms
Running validation...
step:100/1750 val_loss:5.349448 train_time:34018ms step_avg:340.18ms
[train step 100] avg_loss=5.514574 main=4.999044 aux=0.515530 imp_cv2=3.0165 load_cv2=3.6882 usage_frac=0.2500 topk_prob_mean=0.8258 ema_alpha_reverse=nan max_logit=1.1664
step:101/1750 train_time:34610ms step_avg:342.67ms
[train step 101] avg_loss=5.917819 main=5.406521 aux=0.511298 imp_cv2=3.0162 load_cv2=3.6442 usage_frac=0.2500 topk_prob_mean=0.8256 ema_alpha_reverse=nan max_logit=1.1664
step:102/1750 train_time:35216ms step_avg:345.25ms
[train step 102] avg_loss=5.615873 main=5.099163 aux=0.516710 imp_cv2=3.0130 load_cv2=3.7008 usage_frac=0.2500 topk_prob_mean=0.8231 ema_alpha_reverse=nan max_logit=1.1665
step:103/1750 train_time:35823ms step_avg:347.79ms
[train step 103] avg_loss=5.667819 main=5.152649 aux=0.515170 imp_cv2=3.0105 load_cv2=3.6868 usage_frac=0.2500 topk_prob_mean=0.8228 ema_alpha_reverse=nan max_logit=1.1666
step:104/1750 train_time:36424ms step_avg:350.23ms
[train step 104] avg_loss=5.745452 main=5.232442 aux=0.513010 imp_cv2=3.0065 load_cv2=3.6660 usage_frac=0.2500 topk_prob_mean=0.8232 ema_alpha_reverse=nan max_logit=1.1666
step:105/1750 train_time:37018ms step_avg:352.55ms
[train step 105] avg_loss=5.796766 main=5.280264 aux=0.516502 imp_cv2=3.0323 load_cv2=3.6818 usage_frac=0.2500 topk_prob_mean=0.8201 ema_alpha_reverse=nan max_logit=1.1667
step:106/1750 train_time:37623ms step_avg:354.93ms
[train step 106] avg_loss=5.950181 main=5.422396 aux=0.527785 imp_cv2=3.0460 load_cv2=3.7973 usage_frac=0.2500 topk_prob_mean=0.8220 ema_alpha_reverse=nan max_logit=1.1668
step:107/1750 train_time:38221ms step_avg:357.20ms
[train step 107] avg_loss=5.675574 main=5.161334 aux=0.514240 imp_cv2=3.0085 load_cv2=3.6778 usage_frac=0.2500 topk_prob_mean=0.8224 ema_alpha_reverse=nan max_logit=1.1670
step:108/1750 train_time:38803ms step_avg:359.29ms
[train step 108] avg_loss=5.813773 main=5.296193 aux=0.517581 imp_cv2=3.0040 load_cv2=3.7145 usage_frac=0.2500 topk_prob_mean=0.8180 ema_alpha_reverse=nan max_logit=1.1671
step:109/1750 train_time:39379ms step_avg:361.28ms
[train step 109] avg_loss=5.537315 main=5.020408 aux=0.516907 imp_cv2=3.0075 load_cv2=3.7008 usage_frac=0.2500 topk_prob_mean=0.8189 ema_alpha_reverse=nan max_logit=1.1672
step:110/1750 train_time:39950ms step_avg:363.19ms
[train step 110] avg_loss=5.621957 main=5.103627 aux=0.518330 imp_cv2=3.0049 load_cv2=3.7188 usage_frac=0.2500 topk_prob_mean=0.8144 ema_alpha_reverse=nan max_logit=1.1674
step:111/1750 train_time:40531ms step_avg:365.14ms
[train step 111] avg_loss=5.626962 main=5.110700 aux=0.516262 imp_cv2=3.0026 load_cv2=3.7004 usage_frac=0.2500 topk_prob_mean=0.8166 ema_alpha_reverse=nan max_logit=1.1675
step:112/1750 train_time:41096ms step_avg:366.93ms
[train step 112] avg_loss=6.084689 main=5.565831 aux=0.518858 imp_cv2=3.0052 load_cv2=3.7279 usage_frac=0.2500 topk_prob_mean=0.8142 ema_alpha_reverse=nan max_logit=1.1677
step:113/1750 train_time:41685ms step_avg:368.89ms
[train step 113] avg_loss=5.791791 main=5.275142 aux=0.516649 imp_cv2=3.0083 load_cv2=3.6977 usage_frac=0.2500 topk_prob_mean=0.8134 ema_alpha_reverse=nan max_logit=1.1679
step:114/1750 train_time:42247ms step_avg:370.59ms
[train step 114] avg_loss=6.254985 main=5.732520 aux=0.522465 imp_cv2=3.0178 load_cv2=3.7589 usage_frac=0.2500 topk_prob_mean=0.8124 ema_alpha_reverse=nan max_logit=1.1681
step:115/1750 train_time:42833ms step_avg:372.46ms
[train step 115] avg_loss=5.499185 main=4.983052 aux=0.516133 imp_cv2=3.0014 load_cv2=3.6986 usage_frac=0.2500 topk_prob_mean=0.8188 ema_alpha_reverse=nan max_logit=1.1683
step:116/1750 train_time:43399ms step_avg:374.13ms
[train step 116] avg_loss=5.880000 main=5.360982 aux=0.519018 imp_cv2=3.0053 load_cv2=3.7333 usage_frac=0.2500 topk_prob_mean=0.8120 ema_alpha_reverse=nan max_logit=1.1686
step:117/1750 train_time:43953ms step_avg:375.66ms
[train step 117] avg_loss=5.672956 main=5.152620 aux=0.520337 imp_cv2=3.0099 load_cv2=3.7410 usage_frac=0.2455 topk_prob_mean=0.8135 ema_alpha_reverse=nan max_logit=1.1688
step:118/1750 train_time:44496ms step_avg:377.09ms
[train step 118] avg_loss=5.599975 main=5.085289 aux=0.514687 imp_cv2=3.0031 load_cv2=3.6843 usage_frac=0.2500 topk_prob_mean=0.8132 ema_alpha_reverse=nan max_logit=1.1691
step:119/1750 train_time:45032ms step_avg:378.42ms
[train step 119] avg_loss=5.410708 main=4.895556 aux=0.515152 imp_cv2=3.0119 load_cv2=3.6772 usage_frac=0.2455 topk_prob_mean=0.8189 ema_alpha_reverse=nan max_logit=1.1694
step:120/1750 train_time:45575ms step_avg:379.79ms
[train step 120] avg_loss=5.614866 main=5.094530 aux=0.520336 imp_cv2=3.0032 load_cv2=3.7481 usage_frac=0.2500 topk_prob_mean=0.8080 ema_alpha_reverse=nan max_logit=1.1697
step:121/1750 train_time:46118ms step_avg:381.14ms
[train step 121] avg_loss=5.547222 main=5.026913 aux=0.520309 imp_cv2=3.0016 load_cv2=3.7507 usage_frac=0.2500 topk_prob_mean=0.8050 ema_alpha_reverse=nan max_logit=1.1701
step:122/1750 train_time:46680ms step_avg:382.62ms
[train step 122] avg_loss=5.315077 main=4.795383 aux=0.519694 imp_cv2=3.0015 load_cv2=3.7453 usage_frac=0.2455 topk_prob_mean=0.8031 ema_alpha_reverse=nan max_logit=1.1705
step:123/1750 train_time:47218ms step_avg:383.88ms
[train step 123] avg_loss=5.581085 main=5.059018 aux=0.522068 imp_cv2=3.0016 load_cv2=3.7683 usage_frac=0.2500 topk_prob_mean=0.8008 ema_alpha_reverse=nan max_logit=1.1709
step:124/1750 train_time:47816ms step_avg:385.61ms
[train step 124] avg_loss=5.469599 main=4.951235 aux=0.518365 imp_cv2=3.0058 load_cv2=3.7244 usage_frac=0.2455 topk_prob_mean=0.8036 ema_alpha_reverse=nan max_logit=1.1713
step:125/1750 train_time:48382ms step_avg:387.06ms
[train step 125] avg_loss=5.570277 main=5.044628 aux=0.525650 imp_cv2=3.0050 load_cv2=3.8124 usage_frac=0.2455 topk_prob_mean=0.7953 ema_alpha_reverse=nan max_logit=1.1717
step:126/1750 train_time:48942ms step_avg:388.42ms
[train step 126] avg_loss=5.680640 main=5.152733 aux=0.527907 imp_cv2=3.0086 load_cv2=3.8353 usage_frac=0.2455 topk_prob_mean=0.7953 ema_alpha_reverse=nan max_logit=1.1722
step:127/1750 train_time:49493ms step_avg:389.71ms
[train step 127] avg_loss=5.392117 main=4.869305 aux=0.522813 imp_cv2=3.0076 load_cv2=3.7800 usage_frac=0.2455 topk_prob_mean=0.7958 ema_alpha_reverse=nan max_logit=1.1727
step:128/1750 train_time:50061ms step_avg:391.10ms
[train step 128] avg_loss=5.298148 main=4.771664 aux=0.526484 imp_cv2=3.0025 load_cv2=3.8260 usage_frac=0.2455 topk_prob_mean=0.7902 ema_alpha_reverse=nan max_logit=1.1732
step:129/1750 train_time:50600ms step_avg:392.25ms
[train step 129] avg_loss=5.390853 main=4.870438 aux=0.520416 imp_cv2=3.0066 load_cv2=3.7453 usage_frac=0.2500 topk_prob_mean=0.7937 ema_alpha_reverse=nan max_logit=1.1738
step:130/1750 train_time:51170ms step_avg:393.62ms
[train step 130] avg_loss=5.506590 main=4.981343 aux=0.525248 imp_cv2=3.0017 load_cv2=3.8063 usage_frac=0.2455 topk_prob_mean=0.7936 ema_alpha_reverse=nan max_logit=1.1744
step:131/1750 train_time:51736ms step_avg:394.93ms
[train step 131] avg_loss=5.371076 main=4.840366 aux=0.530710 imp_cv2=3.0216 load_cv2=3.8634 usage_frac=0.2500 topk_prob_mean=0.7974 ema_alpha_reverse=nan max_logit=1.1750
step:132/1750 train_time:52291ms step_avg:396.15ms
[train step 132] avg_loss=5.510049 main=4.979869 aux=0.530180 imp_cv2=3.0038 load_cv2=3.8643 usage_frac=0.2455 topk_prob_mean=0.7889 ema_alpha_reverse=nan max_logit=1.1757
step:133/1750 train_time:52842ms step_avg:397.31ms
[train step 133] avg_loss=5.656525 main=5.131677 aux=0.524848 imp_cv2=3.0091 load_cv2=3.7934 usage_frac=0.2455 topk_prob_mean=0.7843 ema_alpha_reverse=nan max_logit=1.1764
step:134/1750 train_time:53562ms step_avg:399.71ms
[train step 134] avg_loss=5.695530 main=5.153390 aux=0.542140 imp_cv2=3.0388 load_cv2=3.9845 usage_frac=0.2455 topk_prob_mean=0.7912 ema_alpha_reverse=nan max_logit=1.1771
step:135/1750 train_time:54127ms step_avg:400.94ms
[train step 135] avg_loss=5.576915 main=5.047571 aux=0.529344 imp_cv2=3.0067 load_cv2=3.8531 usage_frac=0.2455 topk_prob_mean=0.7886 ema_alpha_reverse=nan max_logit=1.1779
step:136/1750 train_time:54669ms step_avg:401.98ms
[train step 136] avg_loss=5.337225 main=4.800382 aux=0.536843 imp_cv2=3.0051 load_cv2=3.9530 usage_frac=0.2455 topk_prob_mean=0.7751 ema_alpha_reverse=nan max_logit=1.1787
step:137/1750 train_time:55204ms step_avg:402.95ms
[train step 137] avg_loss=5.384184 main=4.847514 aux=0.536670 imp_cv2=3.0062 load_cv2=3.9503 usage_frac=0.2455 topk_prob_mean=0.7759 ema_alpha_reverse=nan max_logit=1.1796
step:138/1750 train_time:55781ms step_avg:404.21ms
[train step 138] avg_loss=5.463470 main=4.927856 aux=0.535614 imp_cv2=3.0074 load_cv2=3.9371 usage_frac=0.2455 topk_prob_mean=0.7769 ema_alpha_reverse=nan max_logit=1.1805
step:139/1750 train_time:56333ms step_avg:405.28ms
[train step 139] avg_loss=5.412906 main=4.876416 aux=0.536489 imp_cv2=3.0097 load_cv2=3.9413 usage_frac=0.2455 topk_prob_mean=0.7770 ema_alpha_reverse=nan max_logit=1.1814
step:140/1750 train_time:56918ms step_avg:406.56ms
[train step 140] avg_loss=5.326829 main=4.795553 aux=0.531276 imp_cv2=3.0161 load_cv2=3.8728 usage_frac=0.2455 topk_prob_mean=0.7785 ema_alpha_reverse=nan max_logit=1.1824
step:141/1750 train_time:57487ms step_avg:407.71ms
[train step 141] avg_loss=5.382918 main=4.992069 aux=0.390848 imp_cv2=1.9397 load_cv2=2.9383 usage_frac=0.3705 topk_prob_mean=0.6537 ema_alpha_reverse=nan max_logit=1.1834
step:142/1750 train_time:58235ms step_avg:410.11ms
[train step 142] avg_loss=5.158128 main=4.677185 aux=0.480943 imp_cv2=2.0463 load_cv2=3.8604 usage_frac=0.2857 topk_prob_mean=0.6347 ema_alpha_reverse=nan max_logit=1.1845
step:143/1750 train_time:58822ms step_avg:411.35ms
[train step 143] avg_loss=5.373476 main=4.899572 aux=0.473905 imp_cv2=1.9321 load_cv2=3.9108 usage_frac=0.2946 topk_prob_mean=0.5945 ema_alpha_reverse=nan max_logit=1.1857
step:144/1750 train_time:59456ms step_avg:412.89ms
[train step 144] avg_loss=5.194574 main=4.712471 aux=0.482103 imp_cv2=1.8774 load_cv2=4.0672 usage_frac=0.2946 topk_prob_mean=0.5659 ema_alpha_reverse=nan max_logit=1.1869
step:145/1750 train_time:60106ms step_avg:414.53ms
[train step 145] avg_loss=5.468691 main=4.981640 aux=0.487051 imp_cv2=1.7845 load_cv2=4.2179 usage_frac=0.3036 topk_prob_mean=0.5148 ema_alpha_reverse=nan max_logit=1.1881
step:146/1750 train_time:60745ms step_avg:416.06ms
[train step 146] avg_loss=5.430899 main=4.933183 aux=0.497716 imp_cv2=1.7560 load_cv2=4.3615 usage_frac=0.2902 topk_prob_mean=0.4954 ema_alpha_reverse=nan max_logit=1.1894
step:147/1750 train_time:61414ms step_avg:417.78ms
[train step 147] avg_loss=5.271602 main=4.749064 aux=0.522538 imp_cv2=1.7313 load_cv2=4.6737 usage_frac=0.2946 topk_prob_mean=0.4705 ema_alpha_reverse=nan max_logit=1.1908
step:148/1750 train_time:62097ms step_avg:419.58ms
[train step 148] avg_loss=5.349245 main=4.839260 aux=0.509986 imp_cv2=1.7301 load_cv2=4.5474 usage_frac=0.3080 topk_prob_mean=0.4648 ema_alpha_reverse=nan max_logit=1.1922
step:149/1750 train_time:62782ms step_avg:421.35ms
[train step 149] avg_loss=5.325601 main=4.777071 aux=0.548530 imp_cv2=1.7173 load_cv2=4.9952 usage_frac=0.2857 topk_prob_mean=0.4510 ema_alpha_reverse=nan max_logit=1.1937
step:150/1750 train_time:63444ms step_avg:422.96ms
Running validation...
step:150/1750 val_loss:4.904274 train_time:63455ms step_avg:423.03ms
[train step 150] avg_loss=5.494184 main=4.944663 aux=0.549522 imp_cv2=1.7088 load_cv2=5.0301 usage_frac=0.2857 topk_prob_mean=0.4466 ema_alpha_reverse=nan max_logit=1.1952
step:151/1750 train_time:64125ms step_avg:424.67ms
[train step 151] avg_loss=5.445682 main=4.888453 aux=0.557229 imp_cv2=1.7084 load_cv2=5.1102 usage_frac=0.2946 topk_prob_mean=0.4452 ema_alpha_reverse=nan max_logit=1.1968
step:152/1750 train_time:64828ms step_avg:426.50ms
[train step 152] avg_loss=5.666879 main=5.082865 aux=0.584014 imp_cv2=1.7362 load_cv2=5.4080 usage_frac=0.2991 topk_prob_mean=0.4487 ema_alpha_reverse=nan max_logit=1.1985
step:153/1750 train_time:65473ms step_avg:427.93ms
[train step 153] avg_loss=5.758383 main=5.182498 aux=0.575885 imp_cv2=1.6966 load_cv2=5.3352 usage_frac=0.2857 topk_prob_mean=0.4250 ema_alpha_reverse=nan max_logit=1.2003
step:154/1750 train_time:66153ms step_avg:429.56ms
[train step 154] avg_loss=5.035116 main=4.455915 aux=0.579201 imp_cv2=1.7079 load_cv2=5.3575 usage_frac=0.2857 topk_prob_mean=0.4386 ema_alpha_reverse=nan max_logit=1.2021
step:155/1750 train_time:66805ms step_avg:431.00ms
[train step 155] avg_loss=5.251263 main=4.664448 aux=0.586815 imp_cv2=1.6925 load_cv2=5.4567 usage_frac=0.2902 topk_prob_mean=0.4252 ema_alpha_reverse=nan max_logit=1.2040
step:156/1750 train_time:67435ms step_avg:432.28ms
[train step 156] avg_loss=5.281047 main=4.686373 aux=0.594674 imp_cv2=1.6950 load_cv2=5.5477 usage_frac=0.2902 topk_prob_mean=0.4244 ema_alpha_reverse=nan max_logit=1.2059
step:157/1750 train_time:68058ms step_avg:433.49ms
[train step 157] avg_loss=5.070607 main=4.482658 aux=0.587949 imp_cv2=1.6941 load_cv2=5.4728 usage_frac=0.2946 topk_prob_mean=0.4252 ema_alpha_reverse=nan max_logit=1.2080
step:158/1750 train_time:68877ms step_avg:435.93ms
[train step 158] avg_loss=5.351389 main=4.761391 aux=0.589999 imp_cv2=1.6862 load_cv2=5.5003 usage_frac=0.3170 topk_prob_mean=0.4190 ema_alpha_reverse=nan max_logit=1.2101
step:159/1750 train_time:69519ms step_avg:437.22ms
[train step 159] avg_loss=5.240359 main=4.642172 aux=0.598187 imp_cv2=1.6916 load_cv2=5.6011 usage_frac=0.3080 topk_prob_mean=0.4130 ema_alpha_reverse=nan max_logit=1.2123
step:160/1750 train_time:70155ms step_avg:438.47ms
[train step 160] avg_loss=5.088530 main=4.501262 aux=0.587267 imp_cv2=1.6935 load_cv2=5.4614 usage_frac=0.2857 topk_prob_mean=0.4227 ema_alpha_reverse=nan max_logit=1.2146
step:161/1750 train_time:70783ms step_avg:439.65ms
[train step 161] avg_loss=5.269542 main=4.678562 aux=0.590980 imp_cv2=1.7037 load_cv2=5.4763 usage_frac=0.2991 topk_prob_mean=0.4305 ema_alpha_reverse=nan max_logit=1.2170
step:162/1750 train_time:71597ms step_avg:441.96ms
[train step 162] avg_loss=5.240521 main=4.640841 aux=0.599680 imp_cv2=1.6897 load_cv2=5.6110 usage_frac=0.2857 topk_prob_mean=0.4127 ema_alpha_reverse=nan max_logit=1.2194
step:163/1750 train_time:72188ms step_avg:442.87ms
[train step 163] avg_loss=6.017565 main=5.405001 aux=0.612565 imp_cv2=1.7052 load_cv2=5.7507 usage_frac=0.3080 topk_prob_mean=0.4159 ema_alpha_reverse=nan max_logit=1.2220
step:164/1750 train_time:72774ms step_avg:443.74ms
[train step 164] avg_loss=5.174962 main=4.571756 aux=0.603206 imp_cv2=1.6968 load_cv2=5.6455 usage_frac=0.2991 topk_prob_mean=0.4185 ema_alpha_reverse=nan max_logit=1.2247
step:165/1750 train_time:73373ms step_avg:444.69ms
[train step 165] avg_loss=5.197652 main=4.588033 aux=0.609619 imp_cv2=1.6887 load_cv2=5.7290 usage_frac=0.2991 topk_prob_mean=0.4097 ema_alpha_reverse=nan max_logit=1.2274
step:166/1750 train_time:73972ms step_avg:445.62ms
[train step 166] avg_loss=5.029199 main=4.414699 aux=0.614500 imp_cv2=1.6896 load_cv2=5.7809 usage_frac=0.2902 topk_prob_mean=0.4086 ema_alpha_reverse=nan max_logit=1.2303
step:167/1750 train_time:74575ms step_avg:446.56ms
[train step 167] avg_loss=5.242658 main=4.638933 aux=0.603724 imp_cv2=1.6970 load_cv2=5.6421 usage_frac=0.2857 topk_prob_mean=0.4161 ema_alpha_reverse=nan max_logit=1.2332
step:168/1750 train_time:75173ms step_avg:447.46ms
[train step 168] avg_loss=5.188329 main=4.581668 aux=0.606661 imp_cv2=1.7023 load_cv2=5.6745 usage_frac=0.2946 topk_prob_mean=0.4207 ema_alpha_reverse=nan max_logit=1.2363
step:169/1750 train_time:75782ms step_avg:448.41ms
[train step 169] avg_loss=5.247800 main=4.641706 aux=0.606093 imp_cv2=1.6933 load_cv2=5.6709 usage_frac=0.2946 topk_prob_mean=0.4163 ema_alpha_reverse=nan max_logit=1.2394
step:170/1750 train_time:76350ms step_avg:449.12ms
[train step 170] avg_loss=5.183242 main=4.576865 aux=0.606377 imp_cv2=1.6855 load_cv2=5.6880 usage_frac=0.2902 topk_prob_mean=0.4146 ema_alpha_reverse=nan max_logit=1.2427
step:171/1750 train_time:76921ms step_avg:449.83ms
[train step 171] avg_loss=5.476948 main=4.870654 aux=0.606294 imp_cv2=1.7133 load_cv2=5.6526 usage_frac=0.2946 topk_prob_mean=0.4172 ema_alpha_reverse=nan max_logit=1.2461
step:172/1750 train_time:77493ms step_avg:450.54ms
[train step 172] avg_loss=5.236024 main=4.623012 aux=0.613012 imp_cv2=1.6863 load_cv2=5.7604 usage_frac=0.2902 topk_prob_mean=0.4153 ema_alpha_reverse=nan max_logit=1.2496
step:173/1750 train_time:78033ms step_avg:451.06ms
[train step 173] avg_loss=5.386395 main=4.779253 aux=0.607142 imp_cv2=1.6838 load_cv2=5.7035 usage_frac=0.2812 topk_prob_mean=0.4136 ema_alpha_reverse=nan max_logit=1.2532
step:174/1750 train_time:78587ms step_avg:451.65ms
[train step 174] avg_loss=5.508384 main=4.890161 aux=0.618223 imp_cv2=1.6893 load_cv2=5.8164 usage_frac=0.2857 topk_prob_mean=0.4087 ema_alpha_reverse=nan max_logit=1.2570
step:175/1750 train_time:79120ms step_avg:452.11ms
[train step 175] avg_loss=5.110477 main=4.492904 aux=0.617572 imp_cv2=1.7047 load_cv2=5.7907 usage_frac=0.2991 topk_prob_mean=0.4158 ema_alpha_reverse=nan max_logit=1.2609
step:176/1750 train_time:79665ms step_avg:452.64ms
[train step 176] avg_loss=5.410693 main=4.797129 aux=0.613565 imp_cv2=1.6788 load_cv2=5.7789 usage_frac=0.2991 topk_prob_mean=0.4025 ema_alpha_reverse=nan max_logit=1.2649
step:177/1750 train_time:80204ms step_avg:453.13ms
[train step 177] avg_loss=5.087364 main=4.475632 aux=0.611732 imp_cv2=1.6846 load_cv2=5.7624 usage_frac=0.2857 topk_prob_mean=0.4077 ema_alpha_reverse=nan max_logit=1.2690
step:178/1750 train_time:80753ms step_avg:453.67ms
[train step 178] avg_loss=5.126033 main=4.511197 aux=0.614836 imp_cv2=1.6906 load_cv2=5.7848 usage_frac=0.3036 topk_prob_mean=0.4108 ema_alpha_reverse=nan max_logit=1.2733
step:179/1750 train_time:81314ms step_avg:454.27ms
[train step 179] avg_loss=5.111920 main=4.501519 aux=0.610401 imp_cv2=1.7027 load_cv2=5.7119 usage_frac=0.3080 topk_prob_mean=0.4219 ema_alpha_reverse=nan max_logit=1.2777
step:180/1750 train_time:81868ms step_avg:454.82ms
[train step 180] avg_loss=5.396537 main=4.775836 aux=0.620702 imp_cv2=1.6976 load_cv2=5.8465 usage_frac=0.2857 topk_prob_mean=0.4141 ema_alpha_reverse=nan max_logit=1.2823
step:181/1750 train_time:82369ms step_avg:455.08ms
[train step 181] avg_loss=5.307436 main=4.686294 aux=0.621141 imp_cv2=1.7004 load_cv2=5.8483 usage_frac=0.2812 topk_prob_mean=0.4161 ema_alpha_reverse=nan max_logit=1.2870
step:182/1750 train_time:82908ms step_avg:455.54ms
[train step 182] avg_loss=5.384799 main=4.773921 aux=0.610879 imp_cv2=1.6913 load_cv2=5.7251 usage_frac=0.2991 topk_prob_mean=0.4024 ema_alpha_reverse=nan max_logit=1.2919
step:183/1750 train_time:83471ms step_avg:456.13ms
[train step 183] avg_loss=5.527626 main=4.905360 aux=0.622266 imp_cv2=1.6870 load_cv2=5.8704 usage_frac=0.2946 topk_prob_mean=0.4063 ema_alpha_reverse=nan max_logit=1.2969
step:184/1750 train_time:84022ms step_avg:456.64ms
[train step 184] avg_loss=5.322563 main=4.707912 aux=0.614651 imp_cv2=1.6859 load_cv2=5.7774 usage_frac=0.2902 topk_prob_mean=0.4082 ema_alpha_reverse=nan max_logit=1.3021
step:185/1750 train_time:84555ms step_avg:457.05ms
[train step 185] avg_loss=5.218776 main=4.606042 aux=0.612734 imp_cv2=1.6898 load_cv2=5.7494 usage_frac=0.2946 topk_prob_mean=0.4171 ema_alpha_reverse=nan max_logit=1.3075
step:186/1750 train_time:85104ms step_avg:457.55ms
[train step 186] avg_loss=5.214861 main=4.594101 aux=0.620760 imp_cv2=1.6912 load_cv2=5.8381 usage_frac=0.2946 topk_prob_mean=0.4094 ema_alpha_reverse=nan max_logit=1.3130
step:187/1750 train_time:85633ms step_avg:457.93ms
[train step 187] avg_loss=5.494957 main=4.865932 aux=0.629025 imp_cv2=1.6823 load_cv2=5.9535 usage_frac=0.2902 topk_prob_mean=0.4025 ema_alpha_reverse=nan max_logit=1.3187
step:188/1750 train_time:86151ms step_avg:458.25ms
[train step 188] avg_loss=5.175768 main=4.557854 aux=0.617913 imp_cv2=1.6890 load_cv2=5.8131 usage_frac=0.2946 topk_prob_mean=0.4116 ema_alpha_reverse=nan max_logit=1.3246
step:189/1750 train_time:86684ms step_avg:458.65ms
[train step 189] avg_loss=5.578447 main=4.944159 aux=0.634289 imp_cv2=1.6887 load_cv2=6.0110 usage_frac=0.2902 topk_prob_mean=0.4023 ema_alpha_reverse=nan max_logit=1.3307
step:190/1750 train_time:87199ms step_avg:458.94ms
[train step 190] avg_loss=4.981935 main=4.357011 aux=0.624924 imp_cv2=1.6865 load_cv2=5.8899 usage_frac=0.2857 topk_prob_mean=0.4046 ema_alpha_reverse=nan max_logit=1.3370
step:191/1750 train_time:87718ms step_avg:459.25ms
[train step 191] avg_loss=5.118179 main=4.491434 aux=0.626746 imp_cv2=1.7004 load_cv2=5.9051 usage_frac=0.2902 topk_prob_mean=0.4100 ema_alpha_reverse=nan max_logit=1.3434
step:192/1750 train_time:88241ms step_avg:459.59ms
[train step 192] avg_loss=5.232105 main=4.607647 aux=0.624458 imp_cv2=1.6891 load_cv2=5.8834 usage_frac=0.2857 topk_prob_mean=0.4018 ema_alpha_reverse=nan max_logit=1.3501
step:193/1750 train_time:88753ms step_avg:459.86ms
[train step 193] avg_loss=5.237886 main=4.607346 aux=0.630541 imp_cv2=1.6886 load_cv2=5.9626 usage_frac=0.2902 topk_prob_mean=0.4016 ema_alpha_reverse=nan max_logit=1.3570
step:194/1750 train_time:89282ms step_avg:460.22ms
[train step 194] avg_loss=5.405572 main=4.791717 aux=0.613855 imp_cv2=1.7176 load_cv2=5.6996 usage_frac=0.2723 topk_prob_mean=0.4105 ema_alpha_reverse=nan max_logit=1.2666
step:195/1750 train_time:89804ms step_avg:460.54ms
[train step 195] avg_loss=5.506857 main=4.868763 aux=0.638094 imp_cv2=1.6957 load_cv2=6.0428 usage_frac=0.2812 topk_prob_mean=0.4061 ema_alpha_reverse=nan max_logit=1.3713
step:196/1750 train_time:90291ms step_avg:460.67ms
[train step 196] avg_loss=4.943222 main=4.310987 aux=0.632235 imp_cv2=1.6885 load_cv2=5.9764 usage_frac=0.2812 topk_prob_mean=0.4004 ema_alpha_reverse=nan max_logit=1.3789
step:197/1750 train_time:90833ms step_avg:461.08ms
[train step 197] avg_loss=5.007455 main=4.379964 aux=0.627491 imp_cv2=1.7002 load_cv2=5.9058 usage_frac=0.2946 topk_prob_mean=0.4077 ema_alpha_reverse=nan max_logit=1.3866
step:198/1750 train_time:91348ms step_avg:461.35ms
[train step 198] avg_loss=5.271538 main=4.640164 aux=0.631374 imp_cv2=1.6934 load_cv2=5.9626 usage_frac=0.2902 topk_prob_mean=0.4018 ema_alpha_reverse=nan max_logit=1.3946
step:199/1750 train_time:91854ms step_avg:461.58ms
[train step 199] avg_loss=5.083191 main=4.450591 aux=0.632600 imp_cv2=1.6854 load_cv2=5.9847 usage_frac=0.2946 topk_prob_mean=0.3989 ema_alpha_reverse=nan max_logit=1.4029
step:200/1750 train_time:92357ms step_avg:461.79ms
Running validation...
step:200/1750 val_loss:4.565819 train_time:92369ms step_avg:461.84ms
[train step 200] avg_loss=5.453265 main=4.813787 aux=0.639478 imp_cv2=1.7107 load_cv2=6.0475 usage_frac=0.2857 topk_prob_mean=0.4102 ema_alpha_reverse=nan max_logit=1.4114
step:201/1750 train_time:92881ms step_avg:462.10ms
[train step 201] avg_loss=5.241006 main=4.617813 aux=0.623194 imp_cv2=1.7041 load_cv2=5.8542 usage_frac=0.3036 topk_prob_mean=0.4144 ema_alpha_reverse=nan max_logit=1.4201
step:202/1750 train_time:93386ms step_avg:462.31ms
[train step 202] avg_loss=5.327998 main=4.698890 aux=0.629108 imp_cv2=1.6984 load_cv2=5.9289 usage_frac=0.3036 topk_prob_mean=0.4036 ema_alpha_reverse=nan max_logit=1.4291
step:203/1750 train_time:93873ms step_avg:462.43ms
[train step 203] avg_loss=5.070387 main=4.457882 aux=0.612505 imp_cv2=1.7063 load_cv2=5.7166 usage_frac=0.2991 topk_prob_mean=0.4101 ema_alpha_reverse=nan max_logit=1.4384
step:204/1750 train_time:94393ms step_avg:462.71ms
[train step 204] avg_loss=4.961353 main=4.340550 aux=0.620803 imp_cv2=1.6911 load_cv2=5.8341 usage_frac=0.2991 topk_prob_mean=0.4067 ema_alpha_reverse=nan max_logit=1.4480
step:205/1750 train_time:94890ms step_avg:462.88ms
[train step 205] avg_loss=5.125662 main=4.497215 aux=0.628447 imp_cv2=1.6899 load_cv2=5.9285 usage_frac=0.3036 topk_prob_mean=0.4034 ema_alpha_reverse=nan max_logit=1.4579
step:206/1750 train_time:95395ms step_avg:463.08ms
[train step 206] avg_loss=5.008869 main=4.385278 aux=0.623590 imp_cv2=1.7006 load_cv2=5.8614 usage_frac=0.3036 topk_prob_mean=0.4080 ema_alpha_reverse=nan max_logit=1.4681
step:207/1750 train_time:95911ms step_avg:463.34ms
[train step 207] avg_loss=5.094771 main=4.464532 aux=0.630239 imp_cv2=1.6941 load_cv2=5.9427 usage_frac=0.2991 topk_prob_mean=0.4073 ema_alpha_reverse=nan max_logit=1.4786
step:208/1750 train_time:96412ms step_avg:463.52ms
[train step 208] avg_loss=5.142126 main=4.500581 aux=0.641545 imp_cv2=1.7052 load_cv2=6.0762 usage_frac=0.2991 topk_prob_mean=0.4077 ema_alpha_reverse=nan max_logit=1.4894
step:209/1750 train_time:96901ms step_avg:463.64ms
[train step 209] avg_loss=5.202189 main=4.556941 aux=0.645249 imp_cv2=1.6866 load_cv2=6.1343 usage_frac=0.3036 topk_prob_mean=0.3918 ema_alpha_reverse=nan max_logit=1.5005
step:210/1750 train_time:97388ms step_avg:463.75ms
[train step 210] avg_loss=5.137217 main=4.501297 aux=0.635921 imp_cv2=1.6987 load_cv2=6.0091 usage_frac=0.2991 topk_prob_mean=0.4062 ema_alpha_reverse=nan max_logit=1.5120
step:211/1750 train_time:97876ms step_avg:463.86ms
[train step 211] avg_loss=4.990630 main=4.355922 aux=0.634708 imp_cv2=1.7009 load_cv2=5.9905 usage_frac=0.2946 topk_prob_mean=0.4069 ema_alpha_reverse=nan max_logit=1.5238
step:212/1750 train_time:98362ms step_avg:463.97ms
[train step 212] avg_loss=5.153101 main=4.516190 aux=0.636912 imp_cv2=1.7112 load_cv2=6.0185 usage_frac=0.2991 topk_prob_mean=0.4081 ema_alpha_reverse=nan max_logit=1.5359
step:213/1750 train_time:98862ms step_avg:464.14ms
[train step 213] avg_loss=5.424932 main=4.768395 aux=0.656537 imp_cv2=1.7036 load_cv2=6.2461 usage_frac=0.2857 topk_prob_mean=0.3893 ema_alpha_reverse=nan max_logit=1.5485
step:214/1750 train_time:99359ms step_avg:464.30ms
[train step 214] avg_loss=5.046390 main=4.407665 aux=0.638725 imp_cv2=1.7072 load_cv2=6.0435 usage_frac=0.2902 topk_prob_mean=0.4074 ema_alpha_reverse=nan max_logit=1.5614
step:215/1750 train_time:99839ms step_avg:464.37ms
[train step 215] avg_loss=5.263155 main=4.619095 aux=0.644060 imp_cv2=1.6982 load_cv2=6.1052 usage_frac=0.2857 topk_prob_mean=0.4049 ema_alpha_reverse=nan max_logit=1.5747
step:216/1750 train_time:100334ms step_avg:464.51ms
[train step 216] avg_loss=5.078837 main=4.433468 aux=0.645368 imp_cv2=1.7056 load_cv2=6.1216 usage_frac=0.2946 topk_prob_mean=0.4061 ema_alpha_reverse=nan max_logit=1.5885
step:217/1750 train_time:100802ms step_avg:464.52ms
[train step 217] avg_loss=5.125352 main=4.482746 aux=0.642606 imp_cv2=1.7130 load_cv2=6.0796 usage_frac=0.2857 topk_prob_mean=0.4043 ema_alpha_reverse=nan max_logit=1.6026
step:218/1750 train_time:101262ms step_avg:464.50ms
[train step 218] avg_loss=5.297414 main=4.654294 aux=0.643120 imp_cv2=1.6974 load_cv2=6.0960 usage_frac=0.2857 topk_prob_mean=0.4021 ema_alpha_reverse=nan max_logit=1.6172
step:219/1750 train_time:101718ms step_avg:464.47ms
[train step 219] avg_loss=5.212900 main=4.566350 aux=0.646549 imp_cv2=1.6951 load_cv2=6.1463 usage_frac=0.2723 topk_prob_mean=0.3955 ema_alpha_reverse=nan max_logit=1.6322
step:220/1750 train_time:102177ms step_avg:464.44ms
[train step 220] avg_loss=4.935320 main=4.282452 aux=0.652869 imp_cv2=1.6990 load_cv2=6.2096 usage_frac=0.2723 topk_prob_mean=0.3954 ema_alpha_reverse=nan max_logit=1.6477
step:221/1750 train_time:102640ms step_avg:464.44ms
[train step 221] avg_loss=5.142200 main=4.500851 aux=0.641349 imp_cv2=1.7063 load_cv2=6.0741 usage_frac=0.2812 topk_prob_mean=0.4056 ema_alpha_reverse=nan max_logit=1.6636
step:222/1750 train_time:103112ms step_avg:464.47ms
[train step 222] avg_loss=5.059055 main=4.406112 aux=0.652943 imp_cv2=1.6902 load_cv2=6.2203 usage_frac=0.2768 topk_prob_mean=0.3959 ema_alpha_reverse=nan max_logit=1.6801
step:223/1750 train_time:103568ms step_avg:464.43ms
[train step 223] avg_loss=5.379243 main=4.737909 aux=0.641334 imp_cv2=1.6968 load_cv2=6.0693 usage_frac=0.2768 topk_prob_mean=0.4039 ema_alpha_reverse=nan max_logit=1.6971
step:224/1750 train_time:104040ms step_avg:464.46ms
[train step 224] avg_loss=5.235554 main=4.578678 aux=0.656875 imp_cv2=1.7238 load_cv2=6.2212 usage_frac=0.2812 topk_prob_mean=0.4083 ema_alpha_reverse=nan max_logit=1.7145
step:225/1750 train_time:104514ms step_avg:464.51ms
[train step 225] avg_loss=5.266847 main=4.620493 aux=0.646354 imp_cv2=1.6969 load_cv2=6.1348 usage_frac=0.2812 topk_prob_mean=0.4060 ema_alpha_reverse=nan max_logit=1.7325
step:226/1750 train_time:104983ms step_avg:464.53ms
[train step 226] avg_loss=5.835193 main=5.190300 aux=0.644894 imp_cv2=1.6986 load_cv2=6.1147 usage_frac=0.2857 topk_prob_mean=0.4031 ema_alpha_reverse=nan max_logit=1.7511
step:227/1750 train_time:105463ms step_avg:464.60ms
[train step 227] avg_loss=5.138879 main=4.500712 aux=0.638167 imp_cv2=1.6998 load_cv2=6.0274 usage_frac=0.2902 topk_prob_mean=0.4079 ema_alpha_reverse=nan max_logit=1.7703
step:228/1750 train_time:105924ms step_avg:464.58ms
[train step 228] avg_loss=5.114614 main=4.469798 aux=0.644817 imp_cv2=1.6974 load_cv2=6.1155 usage_frac=0.2723 topk_prob_mean=0.4079 ema_alpha_reverse=nan max_logit=1.7900
step:229/1750 train_time:106434ms step_avg:464.78ms
[train step 229] avg_loss=5.041882 main=4.398914 aux=0.642968 imp_cv2=1.6956 load_cv2=6.0941 usage_frac=0.2768 topk_prob_mean=0.4029 ema_alpha_reverse=nan max_logit=1.8104
step:230/1750 train_time:106905ms step_avg:464.80ms
[train step 230] avg_loss=5.118677 main=4.485636 aux=0.633042 imp_cv2=1.6971 load_cv2=5.9840 usage_frac=0.2857 topk_prob_mean=0.4064 ema_alpha_reverse=nan max_logit=1.8314
step:231/1750 train_time:107404ms step_avg:464.95ms
[train step 231] avg_loss=4.994692 main=4.364825 aux=0.629867 imp_cv2=1.7066 load_cv2=5.9307 usage_frac=0.2812 topk_prob_mean=0.4145 ema_alpha_reverse=nan max_logit=1.8531
step:232/1750 train_time:107887ms step_avg:465.03ms
[train step 232] avg_loss=4.971478 main=4.334432 aux=0.637046 imp_cv2=1.7016 load_cv2=6.0292 usage_frac=0.2723 topk_prob_mean=0.4101 ema_alpha_reverse=nan max_logit=1.8755
step:233/1750 train_time:108368ms step_avg:465.10ms
[train step 233] avg_loss=5.009151 main=4.359936 aux=0.649215 imp_cv2=1.7235 load_cv2=6.1391 usage_frac=0.2812 topk_prob_mean=0.3998 ema_alpha_reverse=nan max_logit=1.8985
step:234/1750 train_time:108841ms step_avg:465.13ms
[train step 234] avg_loss=5.137309 main=4.491301 aux=0.646008 imp_cv2=2.4005 load_cv2=5.2707 usage_frac=0.3839 topk_prob_mean=0.6369 ema_alpha_reverse=nan max_logit=1.9223
step:235/1750 train_time:109420ms step_avg:465.62ms
[train step 235] avg_loss=5.537386 main=4.947447 aux=0.589939 imp_cv2=1.1150 load_cv2=5.9489 usage_frac=0.3214 topk_prob_mean=0.3608 ema_alpha_reverse=nan max_logit=1.9469
step:236/1750 train_time:109938ms step_avg:465.84ms
[train step 236] avg_loss=4.811692 main=4.228271 aux=0.583421 imp_cv2=1.1080 load_cv2=5.8797 usage_frac=0.3214 topk_prob_mean=0.3620 ema_alpha_reverse=nan max_logit=1.9722
step:237/1750 train_time:110420ms step_avg:465.91ms
[train step 237] avg_loss=4.913770 main=4.326253 aux=0.587517 imp_cv2=1.0844 load_cv2=5.9471 usage_frac=0.3214 topk_prob_mean=0.3500 ema_alpha_reverse=nan max_logit=1.9984
step:238/1750 train_time:110940ms step_avg:466.13ms
[train step 238] avg_loss=4.866111 main=4.272820 aux=0.593291 imp_cv2=1.0922 load_cv2=5.9858 usage_frac=0.3170 topk_prob_mean=0.3422 ema_alpha_reverse=nan max_logit=2.0254
step:239/1750 train_time:111441ms step_avg:466.28ms
[train step 239] avg_loss=5.047003 main=4.450269 aux=0.596733 imp_cv2=1.0763 load_cv2=6.0677 usage_frac=0.2991 topk_prob_mean=0.3404 ema_alpha_reverse=nan max_logit=2.0533
step:240/1750 train_time:111927ms step_avg:466.36ms
[train step 240] avg_loss=5.185481 main=4.587538 aux=0.597943 imp_cv2=1.0908 load_cv2=6.0545 usage_frac=0.3036 topk_prob_mean=0.3452 ema_alpha_reverse=nan max_logit=2.0821
step:241/1750 train_time:112377ms step_avg:466.30ms
[train step 241] avg_loss=4.864219 main=4.266538 aux=0.597681 imp_cv2=1.0956 load_cv2=6.0663 usage_frac=0.2991 topk_prob_mean=0.3500 ema_alpha_reverse=nan max_logit=2.1119
step:242/1750 train_time:112857ms step_avg:466.35ms
[train step 242] avg_loss=4.933303 main=4.330842 aux=0.602461 imp_cv2=1.0742 load_cv2=6.1277 usage_frac=0.2946 topk_prob_mean=0.3349 ema_alpha_reverse=nan max_logit=2.1426
step:243/1750 train_time:113326ms step_avg:466.36ms
[train step 243] avg_loss=5.016449 main=4.419403 aux=0.597046 imp_cv2=1.0916 load_cv2=6.0526 usage_frac=0.2946 topk_prob_mean=0.3466 ema_alpha_reverse=nan max_logit=2.1743
step:244/1750 train_time:113795ms step_avg:466.37ms
[train step 244] avg_loss=5.083021 main=4.483174 aux=0.599847 imp_cv2=1.0780 load_cv2=6.0951 usage_frac=0.2991 topk_prob_mean=0.3392 ema_alpha_reverse=nan max_logit=2.2071
step:245/1750 train_time:114268ms step_avg:466.40ms
[train step 245] avg_loss=4.778036 main=4.182610 aux=0.595426 imp_cv2=1.0893 load_cv2=6.0332 usage_frac=0.2902 topk_prob_mean=0.3408 ema_alpha_reverse=nan max_logit=2.2410
step:246/1750 train_time:114740ms step_avg:466.42ms
[train step 246] avg_loss=5.087144 main=4.488567 aux=0.598577 imp_cv2=1.0875 load_cv2=6.0702 usage_frac=0.2991 topk_prob_mean=0.3427 ema_alpha_reverse=nan max_logit=2.2760
step:247/1750 train_time:115199ms step_avg:466.39ms
[train step 247] avg_loss=4.671824 main=4.069956 aux=0.601868 imp_cv2=1.0954 load_cv2=6.1104 usage_frac=0.2902 topk_prob_mean=0.3390 ema_alpha_reverse=nan max_logit=2.3122
step:248/1750 train_time:115665ms step_avg:466.39ms
[train step 248] avg_loss=4.999939 main=4.394166 aux=0.605773 imp_cv2=1.0874 load_cv2=6.1569 usage_frac=0.2946 topk_prob_mean=0.3378 ema_alpha_reverse=nan max_logit=2.1818
step:249/1750 train_time:116150ms step_avg:466.46ms
[train step 249] avg_loss=4.722773 main=4.110848 aux=0.611925 imp_cv2=1.0948 load_cv2=6.2333 usage_frac=0.2902 topk_prob_mean=0.3358 ema_alpha_reverse=nan max_logit=2.2178
step:250/1750 train_time:116617ms step_avg:466.47ms
Running validation...
step:250/1750 val_loss:4.359080 train_time:116629ms step_avg:466.51ms
[train step 250] avg_loss=4.861441 main=4.257777 aux=0.603664 imp_cv2=1.0721 load_cv2=6.1546 usage_frac=0.3036 topk_prob_mean=0.3335 ema_alpha_reverse=nan max_logit=2.2550
step:251/1750 train_time:117090ms step_avg:466.49ms
[train step 251] avg_loss=4.982666 main=4.377718 aux=0.604948 imp_cv2=1.1086 load_cv2=6.1441 usage_frac=0.2902 topk_prob_mean=0.3459 ema_alpha_reverse=nan max_logit=2.4699
step:252/1750 train_time:117562ms step_avg:466.52ms
[train step 252] avg_loss=5.388819 main=4.780445 aux=0.608374 imp_cv2=1.0978 load_cv2=6.1764 usage_frac=0.2946 topk_prob_mean=0.3342 ema_alpha_reverse=nan max_logit=2.3332
step:253/1750 train_time:118030ms step_avg:466.52ms
[train step 253] avg_loss=4.781002 main=4.182315 aux=0.598686 imp_cv2=1.0994 load_cv2=6.0660 usage_frac=0.2902 topk_prob_mean=0.3477 ema_alpha_reverse=nan max_logit=2.3744
step:254/1750 train_time:118499ms step_avg:466.53ms
[train step 254] avg_loss=4.913880 main=4.310594 aux=0.603286 imp_cv2=1.0835 load_cv2=6.1372 usage_frac=0.2991 topk_prob_mean=0.3378 ema_alpha_reverse=nan max_logit=2.4171
step:255/1750 train_time:118968ms step_avg:466.54ms
[train step 255] avg_loss=5.021617 main=4.419735 aux=0.601881 imp_cv2=1.0956 load_cv2=6.1117 usage_frac=0.2902 topk_prob_mean=0.3462 ema_alpha_reverse=nan max_logit=2.4658
step:256/1750 train_time:119429ms step_avg:466.52ms
[train step 256] avg_loss=4.741154 main=4.133998 aux=0.607155 imp_cv2=1.0899 load_cv2=6.1804 usage_frac=0.2902 topk_prob_mean=0.3394 ema_alpha_reverse=nan max_logit=2.5069
step:257/1750 train_time:119899ms step_avg:466.53ms
[train step 257] avg_loss=5.037256 main=4.432542 aux=0.604714 imp_cv2=1.1072 load_cv2=6.1382 usage_frac=0.2946 topk_prob_mean=0.3493 ema_alpha_reverse=nan max_logit=2.5542
step:258/1750 train_time:120371ms step_avg:466.55ms
[train step 258] avg_loss=5.082229 main=4.476655 aux=0.605575 imp_cv2=1.0758 load_cv2=6.1732 usage_frac=0.2946 topk_prob_mean=0.3377 ema_alpha_reverse=nan max_logit=2.6149
step:259/1750 train_time:120830ms step_avg:466.53ms
[train step 259] avg_loss=4.795002 main=4.188301 aux=0.606702 imp_cv2=1.0812 load_cv2=6.1859 usage_frac=0.2902 topk_prob_mean=0.3378 ema_alpha_reverse=nan max_logit=2.8583
step:260/1750 train_time:121301ms step_avg:466.54ms
[train step 260] avg_loss=5.009283 main=4.403347 aux=0.605936 imp_cv2=1.0793 load_cv2=6.1647 usage_frac=0.2902 topk_prob_mean=0.3398 ema_alpha_reverse=nan max_logit=2.7271
step:261/1750 train_time:121758ms step_avg:466.51ms
[train step 261] avg_loss=4.804059 main=4.200171 aux=0.603888 imp_cv2=1.0872 load_cv2=6.1426 usage_frac=0.2991 topk_prob_mean=0.3456 ema_alpha_reverse=nan max_logit=2.9309
step:262/1750 train_time:122238ms step_avg:466.56ms
[train step 262] avg_loss=4.929549 main=4.323187 aux=0.606362 imp_cv2=1.0644 load_cv2=6.1895 usage_frac=0.2991 topk_prob_mean=0.3277 ema_alpha_reverse=nan max_logit=2.8180
step:263/1750 train_time:122718ms step_avg:466.61ms
[train step 263] avg_loss=5.005449 main=4.402194 aux=0.603255 imp_cv2=1.0683 load_cv2=6.1510 usage_frac=0.2946 topk_prob_mean=0.3315 ema_alpha_reverse=nan max_logit=2.8767
step:264/1750 train_time:123202ms step_avg:466.67ms
[train step 264] avg_loss=4.726566 main=4.127422 aux=0.599144 imp_cv2=1.0751 load_cv2=6.0976 usage_frac=0.2991 topk_prob_mean=0.3423 ema_alpha_reverse=nan max_logit=2.9377
step:265/1750 train_time:123667ms step_avg:466.67ms
[train step 265] avg_loss=4.814815 main=4.219194 aux=0.595621 imp_cv2=1.0688 load_cv2=6.0498 usage_frac=0.2902 topk_prob_mean=0.3408 ema_alpha_reverse=nan max_logit=3.0009
step:266/1750 train_time:124136ms step_avg:466.68ms
[train step 266] avg_loss=4.764457 main=4.166071 aux=0.598385 imp_cv2=1.0748 load_cv2=6.0932 usage_frac=0.2946 topk_prob_mean=0.3417 ema_alpha_reverse=nan max_logit=3.0665
step:267/1750 train_time:124633ms step_avg:466.79ms
[train step 267] avg_loss=4.928539 main=4.326466 aux=0.602073 imp_cv2=1.0743 load_cv2=6.1314 usage_frac=0.2902 topk_prob_mean=0.3380 ema_alpha_reverse=nan max_logit=3.1346
step:268/1750 train_time:125110ms step_avg:466.83ms
[train step 268] avg_loss=4.639448 main=4.037097 aux=0.602352 imp_cv2=1.0829 load_cv2=6.1346 usage_frac=0.2991 topk_prob_mean=0.3405 ema_alpha_reverse=nan max_logit=3.2054
step:269/1750 train_time:125582ms step_avg:466.85ms
[train step 269] avg_loss=4.686171 main=4.083535 aux=0.602636 imp_cv2=1.0759 load_cv2=6.1368 usage_frac=0.2946 topk_prob_mean=0.3363 ema_alpha_reverse=nan max_logit=3.5311
step:270/1750 train_time:126038ms step_avg:466.81ms
[train step 270] avg_loss=4.514645 main=3.899377 aux=0.615268 imp_cv2=1.0828 load_cv2=6.2621 usage_frac=0.2545 topk_prob_mean=0.3100 ema_alpha_reverse=nan max_logit=2.6913
step:271/1750 train_time:126481ms step_avg:466.72ms
[train step 271] avg_loss=4.858555 main=4.237597 aux=0.620958 imp_cv2=1.0738 load_cv2=6.3546 usage_frac=0.3036 topk_prob_mean=0.3246 ema_alpha_reverse=nan max_logit=3.4732
step:272/1750 train_time:126940ms step_avg:466.69ms
[train step 272] avg_loss=4.716422 main=4.110034 aux=0.606388 imp_cv2=1.0896 load_cv2=6.1736 usage_frac=0.2991 topk_prob_mean=0.3438 ema_alpha_reverse=nan max_logit=3.7716
step:273/1750 train_time:127405ms step_avg:466.69ms
[train step 273] avg_loss=4.898656 main=4.301052 aux=0.597605 imp_cv2=1.0959 load_cv2=6.0686 usage_frac=0.3080 topk_prob_mean=0.3492 ema_alpha_reverse=nan max_logit=3.6030
step:274/1750 train_time:127871ms step_avg:466.68ms
[train step 274] avg_loss=4.715198 main=4.121730 aux=0.593468 imp_cv2=1.0627 load_cv2=6.0371 usage_frac=0.3125 topk_prob_mean=0.3289 ema_alpha_reverse=nan max_logit=3.8197
step:275/1750 train_time:128326ms step_avg:466.64ms
[train step 275] avg_loss=4.861288 main=4.257976 aux=0.603312 imp_cv2=1.0612 load_cv2=6.1532 usage_frac=0.3036 topk_prob_mean=0.3331 ema_alpha_reverse=nan max_logit=3.7851
step:276/1750 train_time:128770ms step_avg:466.56ms
[train step 276] avg_loss=4.933565 main=4.319899 aux=0.613666 imp_cv2=1.0657 load_cv2=6.2706 usage_frac=0.2991 topk_prob_mean=0.3165 ema_alpha_reverse=nan max_logit=3.8818
step:277/1750 train_time:129236ms step_avg:466.56ms
[train step 277] avg_loss=4.654255 main=4.053675 aux=0.600580 imp_cv2=1.0818 load_cv2=6.1061 usage_frac=0.3036 topk_prob_mean=0.3468 ema_alpha_reverse=nan max_logit=4.1884
step:278/1750 train_time:129695ms step_avg:466.53ms
[train step 278] avg_loss=4.711140 main=4.101271 aux=0.609868 imp_cv2=1.0805 load_cv2=6.2036 usage_frac=0.3080 topk_prob_mean=0.3330 ema_alpha_reverse=nan max_logit=4.3191
step:279/1750 train_time:130152ms step_avg:466.49ms
[train step 279] avg_loss=4.792885 main=4.187662 aux=0.605223 imp_cv2=1.0805 load_cv2=6.1636 usage_frac=0.3036 topk_prob_mean=0.3422 ema_alpha_reverse=nan max_logit=4.1965
step:280/1750 train_time:130606ms step_avg:466.45ms
[train step 280] avg_loss=4.758385 main=4.145361 aux=0.613024 imp_cv2=1.0687 load_cv2=6.2680 usage_frac=0.2991 topk_prob_mean=0.3286 ema_alpha_reverse=nan max_logit=4.3635
step:281/1750 train_time:131067ms step_avg:466.43ms
[train step 281] avg_loss=4.818969 main=4.213677 aux=0.605292 imp_cv2=1.0712 load_cv2=6.1716 usage_frac=0.2991 topk_prob_mean=0.3367 ema_alpha_reverse=nan max_logit=4.4289
step:282/1750 train_time:131532ms step_avg:466.43ms
[train step 282] avg_loss=4.663585 main=4.062812 aux=0.600773 imp_cv2=1.0856 load_cv2=6.1099 usage_frac=0.3036 topk_prob_mean=0.3462 ema_alpha_reverse=nan max_logit=4.5527
step:283/1750 train_time:131985ms step_avg:466.38ms
[train step 283] avg_loss=4.693337 main=4.080915 aux=0.612422 imp_cv2=1.0706 load_cv2=6.2665 usage_frac=0.2991 topk_prob_mean=0.3304 ema_alpha_reverse=nan max_logit=4.6817
step:284/1750 train_time:132451ms step_avg:466.38ms
[train step 284] avg_loss=4.806804 main=4.202916 aux=0.603888 imp_cv2=1.0969 load_cv2=6.1339 usage_frac=0.3036 topk_prob_mean=0.3494 ema_alpha_reverse=nan max_logit=5.0330
step:285/1750 train_time:132905ms step_avg:466.33ms
[train step 285] avg_loss=4.813298 main=4.210944 aux=0.602355 imp_cv2=1.0840 load_cv2=6.1229 usage_frac=0.3036 topk_prob_mean=0.3449 ema_alpha_reverse=nan max_logit=5.3383
step:286/1750 train_time:133378ms step_avg:466.36ms
[train step 286] avg_loss=4.840640 main=4.236951 aux=0.603690 imp_cv2=1.0778 load_cv2=6.1436 usage_frac=0.3080 topk_prob_mean=0.3396 ema_alpha_reverse=nan max_logit=5.2522
step:287/1750 train_time:133828ms step_avg:466.30ms
[train step 287] avg_loss=4.662490 main=4.063162 aux=0.599328 imp_cv2=1.0840 load_cv2=6.0857 usage_frac=0.2991 topk_prob_mean=0.3458 ema_alpha_reverse=nan max_logit=5.2572
step:288/1750 train_time:134287ms step_avg:466.28ms
[train step 288] avg_loss=4.801432 main=4.193258 aux=0.608174 imp_cv2=1.0758 load_cv2=6.2081 usage_frac=0.3170 topk_prob_mean=0.3392 ema_alpha_reverse=nan max_logit=5.4174
step:289/1750 train_time:134735ms step_avg:466.21ms
[train step 289] avg_loss=4.642535 main=4.043084 aux=0.599451 imp_cv2=1.0940 load_cv2=6.0875 usage_frac=0.3125 topk_prob_mean=0.3509 ema_alpha_reverse=nan max_logit=5.5849
step:290/1750 train_time:135208ms step_avg:466.23ms
[train step 290] avg_loss=4.639819 main=4.037560 aux=0.602259 imp_cv2=1.0671 load_cv2=6.1350 usage_frac=0.3036 topk_prob_mean=0.3365 ema_alpha_reverse=nan max_logit=5.7601
step:291/1750 train_time:135675ms step_avg:466.24ms
[train step 291] avg_loss=4.801810 main=4.204289 aux=0.597521 imp_cv2=1.0769 load_cv2=6.0708 usage_frac=0.3080 topk_prob_mean=0.3440 ema_alpha_reverse=nan max_logit=6.4005
step:292/1750 train_time:136162ms step_avg:466.31ms
[train step 292] avg_loss=4.592848 main=3.995867 aux=0.596981 imp_cv2=1.0749 load_cv2=6.0666 usage_frac=0.3125 topk_prob_mean=0.3462 ema_alpha_reverse=nan max_logit=6.1956
step:293/1750 train_time:136638ms step_avg:466.34ms
[train step 293] avg_loss=4.598787 main=3.975833 aux=0.622955 imp_cv2=1.1321 load_cv2=6.3077 usage_frac=0.2545 topk_prob_mean=0.3237 ema_alpha_reverse=nan max_logit=5.3610
step:294/1750 train_time:137099ms step_avg:466.32ms
[train step 294] avg_loss=5.035302 main=4.428038 aux=0.607264 imp_cv2=1.0937 load_cv2=6.1618 usage_frac=0.2991 topk_prob_mean=0.3410 ema_alpha_reverse=nan max_logit=7.0495
step:295/1750 train_time:137557ms step_avg:466.29ms
[train step 295] avg_loss=4.858502 main=4.261502 aux=0.597000 imp_cv2=1.0684 load_cv2=6.0713 usage_frac=0.3036 topk_prob_mean=0.3397 ema_alpha_reverse=nan max_logit=6.8089
step:296/1750 train_time:138030ms step_avg:466.32ms
[train step 296] avg_loss=4.677431 main=4.078602 aux=0.598829 imp_cv2=1.0785 load_cv2=6.0895 usage_frac=0.3036 topk_prob_mean=0.3458 ema_alpha_reverse=nan max_logit=7.1437
step:297/1750 train_time:138481ms step_avg:466.27ms
[train step 297] avg_loss=4.762096 main=4.162632 aux=0.599463 imp_cv2=1.0777 load_cv2=6.0933 usage_frac=0.3036 topk_prob_mean=0.3442 ema_alpha_reverse=nan max_logit=7.2391
step:298/1750 train_time:138941ms step_avg:466.25ms
[train step 298] avg_loss=4.862962 main=4.267480 aux=0.595482 imp_cv2=1.0901 load_cv2=6.0360 usage_frac=0.3080 topk_prob_mean=0.3533 ema_alpha_reverse=nan max_logit=7.5054
step:299/1750 train_time:139411ms step_avg:466.26ms
[train step 299] avg_loss=4.627735 main=4.028454 aux=0.599281 imp_cv2=1.0744 load_cv2=6.0956 usage_frac=0.3080 topk_prob_mean=0.3438 ema_alpha_reverse=nan max_logit=7.7593
step:300/1750 train_time:139874ms step_avg:466.25ms
Running validation...
step:300/1750 val_loss:4.190858 train_time:139886ms step_avg:466.29ms
[train step 300] avg_loss=5.029067 main=4.425581 aux=0.603486 imp_cv2=1.0872 load_cv2=6.1205 usage_frac=0.3214 topk_prob_mean=0.3417 ema_alpha_reverse=nan max_logit=8.0573
step:301/1750 train_time:140327ms step_avg:466.20ms
[train step 301] avg_loss=4.907336 main=4.305651 aux=0.601685 imp_cv2=1.0794 load_cv2=6.1182 usage_frac=0.3214 topk_prob_mean=0.3466 ema_alpha_reverse=nan max_logit=8.5198
step:302/1750 train_time:140786ms step_avg:466.18ms
[train step 302] avg_loss=4.753912 main=4.155282 aux=0.598630 imp_cv2=1.0739 load_cv2=6.0820 usage_frac=0.3527 topk_prob_mean=0.3436 ema_alpha_reverse=nan max_logit=9.2319
step:303/1750 train_time:141241ms step_avg:466.14ms
[train step 303] avg_loss=4.749194 main=4.150856 aux=0.598338 imp_cv2=1.0832 load_cv2=6.0595 usage_frac=0.3125 topk_prob_mean=0.3404 ema_alpha_reverse=nan max_logit=9.2941
step:304/1750 train_time:141708ms step_avg:466.14ms
[train step 304] avg_loss=4.526320 main=3.933768 aux=0.592552 imp_cv2=1.0879 load_cv2=6.0006 usage_frac=0.3170 topk_prob_mean=0.3528 ema_alpha_reverse=nan max_logit=9.4770
step:305/1750 train_time:142168ms step_avg:466.12ms
[train step 305] avg_loss=4.686720 main=4.086656 aux=0.600064 imp_cv2=1.0751 load_cv2=6.0987 usage_frac=0.3125 topk_prob_mean=0.3425 ema_alpha_reverse=nan max_logit=10.2407
step:306/1750 train_time:142637ms step_avg:466.13ms
[train step 306] avg_loss=5.044897 main=4.450029 aux=0.594868 imp_cv2=1.0838 load_cv2=6.0256 usage_frac=0.3214 topk_prob_mean=0.3500 ema_alpha_reverse=nan max_logit=10.1957
step:307/1750 train_time:143102ms step_avg:466.13ms
[train step 307] avg_loss=5.249685 main=4.645098 aux=0.604587 imp_cv2=1.0731 load_cv2=6.1560 usage_frac=0.3170 topk_prob_mean=0.3385 ema_alpha_reverse=nan max_logit=10.4403
step:308/1750 train_time:143575ms step_avg:466.15ms
[train step 308] avg_loss=4.266766 main=3.649121 aux=0.617645 imp_cv2=1.1140 load_cv2=6.2704 usage_frac=0.2991 topk_prob_mean=0.3276 ema_alpha_reverse=nan max_logit=10.8590
step:309/1750 train_time:144031ms step_avg:466.12ms
[train step 309] avg_loss=4.706470 main=4.096922 aux=0.609548 imp_cv2=1.0781 load_cv2=6.2110 usage_frac=0.3080 topk_prob_mean=0.3311 ema_alpha_reverse=nan max_logit=11.3003
step:310/1750 train_time:144492ms step_avg:466.10ms
[train step 310] avg_loss=4.591842 main=4.000423 aux=0.591419 imp_cv2=1.0843 load_cv2=5.9943 usage_frac=0.3214 topk_prob_mean=0.3514 ema_alpha_reverse=nan max_logit=11.7699
step:311/1750 train_time:144946ms step_avg:466.07ms
[train step 311] avg_loss=4.706102 main=4.110291 aux=0.595811 imp_cv2=1.0706 load_cv2=6.0590 usage_frac=0.3080 topk_prob_mean=0.3448 ema_alpha_reverse=nan max_logit=12.3789
step:312/1750 train_time:145420ms step_avg:466.09ms
[train step 312] avg_loss=4.702266 main=4.104083 aux=0.598184 imp_cv2=1.0880 load_cv2=6.0718 usage_frac=0.3080 topk_prob_mean=0.3482 ema_alpha_reverse=nan max_logit=12.9017
step:313/1750 train_time:145884ms step_avg:466.08ms
[train step 313] avg_loss=4.632533 main=4.038620 aux=0.593912 imp_cv2=1.0768 load_cv2=6.0251 usage_frac=0.3125 topk_prob_mean=0.3451 ema_alpha_reverse=nan max_logit=12.7744
step:314/1750 train_time:146353ms step_avg:466.09ms
[train step 314] avg_loss=4.547155 main=3.957233 aux=0.589922 imp_cv2=1.0807 load_cv2=5.9752 usage_frac=0.3125 topk_prob_mean=0.3477 ema_alpha_reverse=nan max_logit=13.2066
step:315/1750 train_time:146818ms step_avg:466.09ms
[train step 315] avg_loss=4.995535 main=4.395051 aux=0.600484 imp_cv2=1.0718 load_cv2=6.1045 usage_frac=0.3170 topk_prob_mean=0.3365 ema_alpha_reverse=nan max_logit=12.7744
step:316/1750 train_time:147272ms step_avg:466.05ms
[train step 316] avg_loss=4.633279 main=4.041314 aux=0.591965 imp_cv2=1.0753 load_cv2=5.9977 usage_frac=0.3214 topk_prob_mean=0.3459 ema_alpha_reverse=nan max_logit=12.7744
step:317/1750 train_time:147749ms step_avg:466.08ms
[train step 317] avg_loss=4.521518 main=3.936192 aux=0.585326 imp_cv2=1.0776 load_cv2=5.9330 usage_frac=0.3304 topk_prob_mean=0.3521 ema_alpha_reverse=nan max_logit=12.8368
step:318/1750 train_time:148241ms step_avg:466.17ms
[train step 318] avg_loss=4.907495 main=4.313503 aux=0.593992 imp_cv2=1.0871 load_cv2=6.0278 usage_frac=0.3125 topk_prob_mean=0.3539 ema_alpha_reverse=nan max_logit=12.8817
step:319/1750 train_time:148702ms step_avg:466.15ms
[train step 319] avg_loss=4.600366 main=4.014551 aux=0.585815 imp_cv2=1.0961 load_cv2=5.9231 usage_frac=0.3125 topk_prob_mean=0.3603 ema_alpha_reverse=nan max_logit=12.8716
step:320/1750 train_time:149220ms step_avg:466.31ms
[train step 320] avg_loss=4.565160 main=3.966248 aux=0.598912 imp_cv2=1.0822 load_cv2=6.0826 usage_frac=0.3304 topk_prob_mean=0.3497 ema_alpha_reverse=nan max_logit=13.1576
step:321/1750 train_time:149689ms step_avg:466.32ms
[train step 321] avg_loss=4.807004 main=4.209523 aux=0.597481 imp_cv2=1.0878 load_cv2=6.0647 usage_frac=0.3214 topk_prob_mean=0.3489 ema_alpha_reverse=nan max_logit=12.9543
step:322/1750 train_time:150164ms step_avg:466.35ms
[train step 322] avg_loss=4.585945 main=3.987532 aux=0.598413 imp_cv2=1.0754 load_cv2=6.0877 usage_frac=0.3214 topk_prob_mean=0.3463 ema_alpha_reverse=nan max_logit=12.9617
step:323/1750 train_time:150644ms step_avg:466.39ms
[train step 323] avg_loss=4.920579 main=4.288663 aux=0.631916 imp_cv2=1.2541 load_cv2=6.3199 usage_frac=0.2455 topk_prob_mean=0.3351 ema_alpha_reverse=nan max_logit=12.0595
step:324/1750 train_time:151113ms step_avg:466.40ms
[train step 324] avg_loss=4.756548 main=4.145290 aux=0.611257 imp_cv2=1.0930 load_cv2=6.2193 usage_frac=0.3259 topk_prob_mean=0.3422 ema_alpha_reverse=nan max_logit=12.9047
step:325/1750 train_time:151577ms step_avg:466.39ms
[train step 325] avg_loss=4.491967 main=3.894714 aux=0.597253 imp_cv2=1.0898 load_cv2=6.0679 usage_frac=0.3080 topk_prob_mean=0.3529 ema_alpha_reverse=nan max_logit=12.8494
step:326/1750 train_time:152055ms step_avg:466.43ms
[train step 326] avg_loss=4.688967 main=4.091835 aux=0.597132 imp_cv2=1.0883 load_cv2=6.0601 usage_frac=0.3304 topk_prob_mean=0.3544 ema_alpha_reverse=nan max_logit=13.0693
step:327/1750 train_time:152533ms step_avg:466.46ms
[train step 327] avg_loss=4.637569 main=4.033225 aux=0.604345 imp_cv2=1.0808 load_cv2=6.1551 usage_frac=0.3259 topk_prob_mean=0.3466 ema_alpha_reverse=nan max_logit=13.2799
step:328/1750 train_time:153002ms step_avg:466.47ms
[train step 328] avg_loss=4.807642 main=4.193615 aux=0.614027 imp_cv2=1.0814 load_cv2=6.2667 usage_frac=0.3170 topk_prob_mean=0.3331 ema_alpha_reverse=nan max_logit=12.7744
step:329/1750 train_time:153479ms step_avg:466.50ms
[train step 329] avg_loss=4.680148 main=4.048456 aux=0.631692 imp_cv2=1.1340 load_cv2=6.4104 usage_frac=0.3036 topk_prob_mean=0.3295 ema_alpha_reverse=nan max_logit=12.7744
step:330/1750 train_time:153944ms step_avg:466.50ms
[train step 330] avg_loss=4.531904 main=3.929739 aux=0.602164 imp_cv2=1.0888 load_cv2=6.1268 usage_frac=0.3259 topk_prob_mean=0.3509 ema_alpha_reverse=nan max_logit=12.7744
step:331/1750 train_time:154404ms step_avg:466.48ms
[train step 331] avg_loss=4.551939 main=3.945871 aux=0.606068 imp_cv2=1.1053 load_cv2=6.1619 usage_frac=0.3214 topk_prob_mean=0.3529 ema_alpha_reverse=nan max_logit=12.9442
step:332/1750 train_time:154864ms step_avg:466.46ms
[train step 332] avg_loss=4.678061 main=4.074341 aux=0.603721 imp_cv2=1.0772 load_cv2=6.1413 usage_frac=0.3214 topk_prob_mean=0.3411 ema_alpha_reverse=nan max_logit=12.7744
step:333/1750 train_time:155320ms step_avg:466.43ms
[train step 333] avg_loss=4.734228 main=4.121359 aux=0.612868 imp_cv2=1.0771 load_cv2=6.2558 usage_frac=0.3170 topk_prob_mean=0.3364 ema_alpha_reverse=nan max_logit=13.3376
step:334/1750 train_time:155986ms step_avg:467.02ms
[train step 334] avg_loss=4.656451 main=4.047560 aux=0.608891 imp_cv2=1.0932 load_cv2=6.2058 usage_frac=0.3080 topk_prob_mean=0.3445 ema_alpha_reverse=nan max_logit=12.8838
step:335/1750 train_time:156442ms step_avg:466.99ms
[train step 335] avg_loss=4.442865 main=3.853792 aux=0.589072 imp_cv2=1.1392 load_cv2=5.9374 usage_frac=0.3170 topk_prob_mean=0.3707 ema_alpha_reverse=nan max_logit=12.9180
step:336/1750 train_time:156902ms step_avg:466.97ms
[train step 336] avg_loss=3.964947 main=3.324279 aux=0.640668 imp_cv2=1.2614 load_cv2=6.3837 usage_frac=0.2857 topk_prob_mean=0.3425 ema_alpha_reverse=nan max_logit=8.8772
step:337/1750 train_time:157364ms step_avg:466.96ms
[train step 337] avg_loss=4.520383 main=3.907964 aux=0.612419 imp_cv2=1.0711 load_cv2=6.2405 usage_frac=0.2946 topk_prob_mean=0.3187 ema_alpha_reverse=nan max_logit=12.7744
step:338/1750 train_time:157807ms step_avg:466.88ms
[train step 338] avg_loss=5.064958 main=4.234484 aux=0.830474 imp_cv2=4.2530 load_cv2=5.5335 usage_frac=0.3973 topk_prob_mean=0.8354 ema_alpha_reverse=nan max_logit=13.5631
step:339/1750 train_time:158348ms step_avg:467.10ms
[train step 339] avg_loss=4.920893 main=4.398431 aux=0.522461 imp_cv2=1.5049 load_cv2=4.7249 usage_frac=0.4152 topk_prob_mean=0.4769 ema_alpha_reverse=nan max_logit=13.1955
step:340/1750 train_time:158930ms step_avg:467.44ms
[train step 340] avg_loss=5.218099 main=4.636762 aux=0.581338 imp_cv2=0.9288 load_cv2=5.9477 usage_frac=0.3839 topk_prob_mean=0.3436 ema_alpha_reverse=nan max_logit=12.8127
step:341/1750 train_time:159424ms step_avg:467.52ms
[train step 341] avg_loss=4.682516 main=4.134235 aux=0.548281 imp_cv2=0.7270 load_cv2=5.7543 usage_frac=0.3839 topk_prob_mean=0.3462 ema_alpha_reverse=nan max_logit=12.9739
step:342/1750 train_time:159921ms step_avg:467.61ms
[train step 342] avg_loss=4.458133 main=3.900253 aux=0.557880 imp_cv2=0.6954 load_cv2=5.8950 usage_frac=0.3527 topk_prob_mean=0.3227 ema_alpha_reverse=nan max_logit=12.7744
step:343/1750 train_time:160419ms step_avg:467.69ms
[train step 343] avg_loss=5.010429 main=4.447439 aux=0.562991 imp_cv2=0.7095 load_cv2=5.9560 usage_frac=0.3571 topk_prob_mean=0.3238 ema_alpha_reverse=nan max_logit=12.7744
step:344/1750 train_time:160939ms step_avg:467.85ms
[train step 344] avg_loss=4.763550 main=4.188788 aux=0.574762 imp_cv2=0.7137 load_cv2=6.0788 usage_frac=0.3393 topk_prob_mean=0.3041 ema_alpha_reverse=nan max_logit=12.7744
step:345/1750 train_time:161400ms step_avg:467.83ms
[train step 345] avg_loss=4.311624 main=3.753780 aux=0.557845 imp_cv2=0.7087 load_cv2=5.9012 usage_frac=0.3616 topk_prob_mean=0.3291 ema_alpha_reverse=nan max_logit=12.8918
step:346/1750 train_time:161893ms step_avg:467.90ms
[train step 346] avg_loss=4.676312 main=4.115922 aux=0.560389 imp_cv2=0.6895 load_cv2=5.9559 usage_frac=0.3393 topk_prob_mean=0.3182 ema_alpha_reverse=nan max_logit=13.1582
step:347/1750 train_time:162391ms step_avg:467.98ms
[train step 347] avg_loss=4.437483 main=3.878648 aux=0.558835 imp_cv2=0.7581 load_cv2=5.8949 usage_frac=0.3527 topk_prob_mean=0.3398 ema_alpha_reverse=nan max_logit=13.5432
step:348/1750 train_time:162868ms step_avg:468.01ms
[train step 348] avg_loss=4.446465 main=3.884706 aux=0.561759 imp_cv2=0.6804 load_cv2=5.9863 usage_frac=0.3438 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=13.2147
step:349/1750 train_time:163335ms step_avg:468.01ms
[train step 349] avg_loss=4.799480 main=4.230177 aux=0.569303 imp_cv2=0.6692 load_cv2=6.0788 usage_frac=0.3393 topk_prob_mean=0.2974 ema_alpha_reverse=nan max_logit=13.7570
step:350/1750 train_time:163813ms step_avg:468.04ms
Running validation...
step:350/1750 val_loss:4.073695 train_time:163825ms step_avg:468.07ms
[train step 350] avg_loss=4.614012 main=4.045510 aux=0.568502 imp_cv2=0.6815 load_cv2=6.0628 usage_frac=0.3482 topk_prob_mean=0.3052 ema_alpha_reverse=nan max_logit=12.7744
step:351/1750 train_time:164289ms step_avg:468.06ms
[train step 351] avg_loss=4.655037 main=4.090989 aux=0.564048 imp_cv2=0.6779 load_cv2=6.0181 usage_frac=0.3438 topk_prob_mean=0.3044 ema_alpha_reverse=nan max_logit=13.4720
step:352/1750 train_time:164751ms step_avg:468.04ms
[train step 352] avg_loss=4.505620 main=3.944305 aux=0.561315 imp_cv2=0.7014 load_cv2=5.9650 usage_frac=0.3661 topk_prob_mean=0.3160 ema_alpha_reverse=nan max_logit=13.7570
step:353/1750 train_time:165231ms step_avg:468.08ms
[train step 353] avg_loss=4.385884 main=3.828254 aux=0.557630 imp_cv2=0.7113 load_cv2=5.9104 usage_frac=0.3527 topk_prob_mean=0.3229 ema_alpha_reverse=nan max_logit=13.6171
step:354/1750 train_time:165711ms step_avg:468.11ms
[train step 354] avg_loss=4.674979 main=4.115633 aux=0.559347 imp_cv2=0.6816 load_cv2=5.9548 usage_frac=0.3438 topk_prob_mean=0.3132 ema_alpha_reverse=nan max_logit=13.7570
step:355/1750 train_time:166180ms step_avg:468.11ms
[train step 355] avg_loss=4.819741 main=4.260191 aux=0.559550 imp_cv2=0.6697 load_cv2=5.9666 usage_frac=0.3527 topk_prob_mean=0.3049 ema_alpha_reverse=nan max_logit=13.6674
step:356/1750 train_time:166667ms step_avg:468.17ms
[train step 356] avg_loss=4.380273 main=3.811168 aux=0.569105 imp_cv2=0.6708 load_cv2=6.0686 usage_frac=0.3705 topk_prob_mean=0.2987 ema_alpha_reverse=nan max_logit=13.7570
step:357/1750 train_time:167372ms step_avg:468.83ms
[train step 357] avg_loss=4.720285 main=4.162555 aux=0.557730 imp_cv2=0.6618 load_cv2=5.9511 usage_frac=0.3527 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=13.7570
step:358/1750 train_time:167834ms step_avg:468.81ms
[train step 358] avg_loss=5.055459 main=4.502057 aux=0.553402 imp_cv2=0.6549 load_cv2=5.9054 usage_frac=0.3705 topk_prob_mean=0.3011 ema_alpha_reverse=nan max_logit=13.6686
step:359/1750 train_time:168341ms step_avg:468.92ms
[train step 359] avg_loss=4.849330 main=4.271232 aux=0.578098 imp_cv2=0.6648 load_cv2=6.1750 usage_frac=0.3304 topk_prob_mean=0.2718 ema_alpha_reverse=nan max_logit=12.7744
step:360/1750 train_time:168817ms step_avg:468.94ms
[train step 360] avg_loss=4.467329 main=3.915069 aux=0.552260 imp_cv2=0.7105 load_cv2=5.8473 usage_frac=0.3839 topk_prob_mean=0.3251 ema_alpha_reverse=nan max_logit=12.7909
step:361/1750 train_time:169302ms step_avg:468.98ms
[train step 361] avg_loss=4.925564 main=4.369237 aux=0.556328 imp_cv2=0.6639 load_cv2=5.9214 usage_frac=0.3527 topk_prob_mean=0.2999 ema_alpha_reverse=nan max_logit=13.2136
step:362/1750 train_time:169784ms step_avg:469.02ms
[train step 362] avg_loss=4.897571 main=4.347645 aux=0.549926 imp_cv2=0.6672 load_cv2=5.8460 usage_frac=0.3750 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=12.7744
step:363/1750 train_time:170270ms step_avg:469.06ms
[train step 363] avg_loss=4.618838 main=4.071018 aux=0.547820 imp_cv2=0.6676 load_cv2=5.8205 usage_frac=0.3571 topk_prob_mean=0.3102 ema_alpha_reverse=nan max_logit=13.0492
step:364/1750 train_time:170768ms step_avg:469.14ms
[train step 364] avg_loss=5.067333 main=4.517973 aux=0.549360 imp_cv2=0.6720 load_cv2=5.8360 usage_frac=0.3527 topk_prob_mean=0.3105 ema_alpha_reverse=nan max_logit=12.9881
step:365/1750 train_time:171240ms step_avg:469.15ms
[train step 365] avg_loss=4.701058 main=4.146333 aux=0.554725 imp_cv2=0.6551 load_cv2=5.9172 usage_frac=0.3527 topk_prob_mean=0.3009 ema_alpha_reverse=nan max_logit=12.8713
step:366/1750 train_time:171707ms step_avg:469.14ms
[train step 366] avg_loss=4.454402 main=3.883053 aux=0.571349 imp_cv2=0.7452 load_cv2=6.0211 usage_frac=0.3527 topk_prob_mean=0.3044 ema_alpha_reverse=nan max_logit=12.7744
step:367/1750 train_time:172169ms step_avg:469.13ms
[train step 367] avg_loss=4.864039 main=4.306076 aux=0.557964 imp_cv2=0.6576 load_cv2=5.9537 usage_frac=0.3571 topk_prob_mean=0.3009 ema_alpha_reverse=nan max_logit=12.9349
step:368/1750 train_time:172646ms step_avg:469.15ms
[train step 368] avg_loss=4.784097 main=4.226932 aux=0.557165 imp_cv2=0.6622 load_cv2=5.9353 usage_frac=0.3482 topk_prob_mean=0.3024 ema_alpha_reverse=nan max_logit=13.2945
step:369/1750 train_time:173117ms step_avg:469.15ms
[train step 369] avg_loss=4.206256 main=3.658521 aux=0.547736 imp_cv2=0.7208 load_cv2=5.7763 usage_frac=0.3527 topk_prob_mean=0.3263 ema_alpha_reverse=nan max_logit=13.1893
step:370/1750 train_time:173634ms step_avg:469.28ms
[train step 370] avg_loss=4.455616 main=3.908216 aux=0.547400 imp_cv2=0.7062 load_cv2=5.7867 usage_frac=0.3750 topk_prob_mean=0.3217 ema_alpha_reverse=nan max_logit=13.7570
step:371/1750 train_time:174135ms step_avg:469.37ms
[train step 371] avg_loss=4.295166 main=3.741344 aux=0.553821 imp_cv2=0.6733 load_cv2=5.8929 usage_frac=0.3482 topk_prob_mean=0.3082 ema_alpha_reverse=nan max_logit=13.7570
step:372/1750 train_time:174614ms step_avg:469.39ms
[train step 372] avg_loss=4.506177 main=3.954612 aux=0.551565 imp_cv2=0.7028 load_cv2=5.8428 usage_frac=0.3482 topk_prob_mean=0.3212 ema_alpha_reverse=nan max_logit=13.7570
step:373/1750 train_time:175252ms step_avg:469.84ms
[train step 373] avg_loss=4.988611 main=4.421710 aux=0.566901 imp_cv2=0.6494 load_cv2=6.0619 usage_frac=0.3616 topk_prob_mean=0.2844 ema_alpha_reverse=nan max_logit=13.1341
step:374/1750 train_time:175717ms step_avg:469.83ms
[train step 374] avg_loss=4.342421 main=3.774091 aux=0.568330 imp_cv2=0.6643 load_cv2=6.0744 usage_frac=0.3438 topk_prob_mean=0.2966 ema_alpha_reverse=nan max_logit=13.6017
step:375/1750 train_time:176181ms step_avg:469.82ms
[train step 375] avg_loss=4.469485 main=3.911107 aux=0.558377 imp_cv2=0.6730 load_cv2=5.9422 usage_frac=0.3571 topk_prob_mean=0.3057 ema_alpha_reverse=nan max_logit=12.7744
step:376/1750 train_time:176652ms step_avg:469.82ms
[train step 376] avg_loss=4.460488 main=3.906679 aux=0.553809 imp_cv2=0.7151 load_cv2=5.8580 usage_frac=0.3482 topk_prob_mean=0.3259 ema_alpha_reverse=nan max_logit=13.7570
step:377/1750 train_time:177320ms step_avg:470.34ms
[train step 377] avg_loss=5.002249 main=4.419614 aux=0.582635 imp_cv2=0.6584 load_cv2=6.2223 usage_frac=0.2768 topk_prob_mean=0.2672 ema_alpha_reverse=nan max_logit=10.7550
step:378/1750 train_time:177810ms step_avg:470.40ms
[train step 378] avg_loss=4.526410 main=3.971413 aux=0.554997 imp_cv2=0.6990 load_cv2=5.8811 usage_frac=0.3482 topk_prob_mean=0.3197 ema_alpha_reverse=nan max_logit=12.7744
step:379/1750 train_time:178271ms step_avg:470.37ms
[train step 379] avg_loss=4.562469 main=4.011599 aux=0.550869 imp_cv2=0.7041 load_cv2=5.8251 usage_frac=0.3661 topk_prob_mean=0.3252 ema_alpha_reverse=nan max_logit=12.7744
step:380/1750 train_time:178747ms step_avg:470.39ms
[train step 380] avg_loss=4.528714 main=3.985311 aux=0.543403 imp_cv2=0.6928 load_cv2=5.7452 usage_frac=0.3705 topk_prob_mean=0.3243 ema_alpha_reverse=nan max_logit=12.7744
step:381/1750 train_time:179440ms step_avg:470.97ms
[train step 381] avg_loss=4.358561 main=3.809016 aux=0.549545 imp_cv2=0.6799 load_cv2=5.8263 usage_frac=0.3571 topk_prob_mean=0.3166 ema_alpha_reverse=nan max_logit=12.7744
step:382/1750 train_time:179910ms step_avg:470.97ms
[train step 382] avg_loss=4.457857 main=3.916247 aux=0.541610 imp_cv2=0.6840 load_cv2=5.7343 usage_frac=0.3616 topk_prob_mean=0.3252 ema_alpha_reverse=nan max_logit=12.7744
step:383/1750 train_time:180391ms step_avg:470.99ms
[train step 383] avg_loss=4.481473 main=3.949290 aux=0.532183 imp_cv2=0.6956 load_cv2=5.6108 usage_frac=0.3527 topk_prob_mean=0.3309 ema_alpha_reverse=nan max_logit=12.7744
step:384/1750 train_time:180875ms step_avg:471.03ms
[train step 384] avg_loss=4.462823 main=3.926718 aux=0.536105 imp_cv2=0.6776 load_cv2=5.6648 usage_frac=0.3527 topk_prob_mean=0.3197 ema_alpha_reverse=nan max_logit=12.7744
step:385/1750 train_time:181384ms step_avg:471.13ms
[train step 385] avg_loss=4.363918 main=3.830615 aux=0.533303 imp_cv2=0.7339 load_cv2=5.5934 usage_frac=0.3482 topk_prob_mean=0.3416 ema_alpha_reverse=nan max_logit=13.7570
step:386/1750 train_time:181887ms step_avg:471.21ms
[train step 386] avg_loss=4.818184 main=4.275116 aux=0.543068 imp_cv2=0.6695 load_cv2=5.7482 usage_frac=0.3795 topk_prob_mean=0.3117 ema_alpha_reverse=nan max_logit=13.7570
step:387/1750 train_time:182373ms step_avg:471.25ms
[train step 387] avg_loss=4.333065 main=3.794267 aux=0.538798 imp_cv2=0.6639 load_cv2=5.7070 usage_frac=0.3661 topk_prob_mean=0.3138 ema_alpha_reverse=nan max_logit=12.7744
step:388/1750 train_time:182859ms step_avg:471.29ms
[train step 388] avg_loss=4.171845 main=3.615882 aux=0.555963 imp_cv2=0.6457 load_cv2=5.9162 usage_frac=0.3527 topk_prob_mean=0.2868 ema_alpha_reverse=nan max_logit=13.2139
step:389/1750 train_time:183354ms step_avg:471.35ms
[train step 389] avg_loss=4.350826 main=3.814124 aux=0.536703 imp_cv2=0.6956 load_cv2=5.6620 usage_frac=0.3571 topk_prob_mean=0.3305 ema_alpha_reverse=nan max_logit=13.7570
step:390/1750 train_time:183854ms step_avg:471.42ms
[train step 390] avg_loss=4.447704 main=3.908065 aux=0.539639 imp_cv2=0.6775 load_cv2=5.7105 usage_frac=0.3616 topk_prob_mean=0.3191 ema_alpha_reverse=nan max_logit=13.7570
step:391/1750 train_time:184331ms step_avg:471.43ms
[train step 391] avg_loss=4.331291 main=3.759959 aux=0.571332 imp_cv2=0.7238 load_cv2=6.0515 usage_frac=0.3482 topk_prob_mean=0.2973 ema_alpha_reverse=nan max_logit=13.7570
step:392/1750 train_time:184811ms step_avg:471.46ms
[train step 392] avg_loss=4.316418 main=3.762166 aux=0.554252 imp_cv2=0.6569 load_cv2=5.8952 usage_frac=0.3661 topk_prob_mean=0.2979 ema_alpha_reverse=nan max_logit=13.7570
step:393/1750 train_time:185457ms step_avg:471.90ms
[train step 393] avg_loss=4.665924 main=4.120780 aux=0.545144 imp_cv2=0.6801 load_cv2=5.7750 usage_frac=0.3661 topk_prob_mean=0.3177 ema_alpha_reverse=nan max_logit=13.7570
step:394/1750 train_time:185941ms step_avg:471.93ms
[train step 394] avg_loss=4.394213 main=3.853991 aux=0.540222 imp_cv2=0.7106 load_cv2=5.6921 usage_frac=0.3616 topk_prob_mean=0.3309 ema_alpha_reverse=nan max_logit=13.7570
step:395/1750 train_time:186425ms step_avg:471.96ms
[train step 395] avg_loss=4.348194 main=3.803983 aux=0.544211 imp_cv2=0.6579 load_cv2=5.7820 usage_frac=0.3705 topk_prob_mean=0.3058 ema_alpha_reverse=nan max_logit=13.7570
step:396/1750 train_time:186896ms step_avg:471.96ms
[train step 396] avg_loss=4.489035 main=3.955640 aux=0.533395 imp_cv2=0.6882 load_cv2=5.6268 usage_frac=0.3661 topk_prob_mean=0.3259 ema_alpha_reverse=nan max_logit=13.7570
step:397/1750 train_time:187379ms step_avg:471.99ms
[train step 397] avg_loss=4.502382 main=3.954619 aux=0.547763 imp_cv2=0.6582 load_cv2=5.8184 usage_frac=0.3616 topk_prob_mean=0.3017 ema_alpha_reverse=nan max_logit=13.7570
step:398/1750 train_time:187860ms step_avg:472.01ms
[train step 398] avg_loss=4.052261 main=3.511184 aux=0.541076 imp_cv2=0.6709 load_cv2=5.7335 usage_frac=0.3571 topk_prob_mean=0.3135 ema_alpha_reverse=nan max_logit=13.7570
step:399/1750 train_time:188341ms step_avg:472.03ms
[train step 399] avg_loss=4.510746 main=3.962202 aux=0.548544 imp_cv2=0.6418 load_cv2=5.8369 usage_frac=0.3661 topk_prob_mean=0.2976 ema_alpha_reverse=nan max_logit=13.7570
step:400/1750 train_time:188850ms step_avg:472.12ms
Running validation...
step:400/1750 val_loss:3.981421 train_time:188861ms step_avg:472.15ms
[train step 400] avg_loss=4.468726 main=3.898656 aux=0.570070 imp_cv2=0.6804 load_cv2=6.0560 usage_frac=0.3527 topk_prob_mean=0.2805 ema_alpha_reverse=nan max_logit=13.7570
step:401/1750 train_time:189338ms step_avg:472.17ms
[train step 401] avg_loss=4.432442 main=3.877931 aux=0.554511 imp_cv2=0.6431 load_cv2=5.8959 usage_frac=0.3616 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=13.7570
step:402/1750 train_time:189805ms step_avg:472.15ms
[train step 402] avg_loss=4.785920 main=4.201857 aux=0.584063 imp_cv2=0.6769 load_cv2=6.2016 usage_frac=0.2679 topk_prob_mean=0.2687 ema_alpha_reverse=nan max_logit=11.3889
step:403/1750 train_time:190269ms step_avg:472.13ms
[train step 403] avg_loss=4.501753 main=3.950868 aux=0.550886 imp_cv2=0.6486 load_cv2=5.8457 usage_frac=0.3571 topk_prob_mean=0.2952 ema_alpha_reverse=nan max_logit=13.7570
step:404/1750 train_time:190755ms step_avg:472.17ms
[train step 404] avg_loss=4.194843 main=3.653664 aux=0.541179 imp_cv2=0.6856 load_cv2=5.7279 usage_frac=0.3616 topk_prob_mean=0.3184 ema_alpha_reverse=nan max_logit=13.7570
step:405/1750 train_time:191226ms step_avg:472.16ms
[train step 405] avg_loss=4.337357 main=3.792678 aux=0.544679 imp_cv2=0.6663 load_cv2=5.7746 usage_frac=0.3616 topk_prob_mean=0.3070 ema_alpha_reverse=nan max_logit=13.7570
step:406/1750 train_time:191705ms step_avg:472.18ms
[train step 406] avg_loss=4.764018 main=4.182138 aux=0.581880 imp_cv2=0.7088 load_cv2=6.1642 usage_frac=0.2768 topk_prob_mean=0.2707 ema_alpha_reverse=nan max_logit=10.8525
step:407/1750 train_time:192174ms step_avg:472.17ms
[train step 407] avg_loss=4.182097 main=3.612748 aux=0.569348 imp_cv2=0.6514 load_cv2=6.0629 usage_frac=0.3482 topk_prob_mean=0.2683 ema_alpha_reverse=nan max_logit=13.7570
step:408/1750 train_time:192646ms step_avg:472.17ms
[train step 408] avg_loss=4.547670 main=4.007165 aux=0.540504 imp_cv2=0.6686 load_cv2=5.7285 usage_frac=0.3705 topk_prob_mean=0.3147 ema_alpha_reverse=nan max_logit=13.7570
step:409/1750 train_time:193128ms step_avg:472.20ms
[train step 409] avg_loss=4.375499 main=3.821054 aux=0.554445 imp_cv2=0.6410 load_cv2=5.9111 usage_frac=0.3705 topk_prob_mean=0.2924 ema_alpha_reverse=nan max_logit=13.7570
step:410/1750 train_time:193607ms step_avg:472.21ms
[train step 410] avg_loss=4.534449 main=3.992228 aux=0.542222 imp_cv2=0.6849 load_cv2=5.7356 usage_frac=0.3616 topk_prob_mean=0.3201 ema_alpha_reverse=nan max_logit=13.7570
step:411/1750 train_time:194106ms step_avg:472.28ms
[train step 411] avg_loss=6.121222 main=5.575773 aux=0.545448 imp_cv2=0.6421 load_cv2=5.8053 usage_frac=0.3571 topk_prob_mean=0.2968 ema_alpha_reverse=nan max_logit=13.7570
step:412/1750 train_time:194587ms step_avg:472.30ms
[train step 412] avg_loss=4.467316 main=3.932681 aux=0.534634 imp_cv2=0.6728 load_cv2=5.6611 usage_frac=0.3616 topk_prob_mean=0.3185 ema_alpha_reverse=nan max_logit=13.7570
step:413/1750 train_time:195074ms step_avg:472.33ms
[train step 413] avg_loss=4.455075 main=3.918653 aux=0.536422 imp_cv2=0.7013 load_cv2=5.6607 usage_frac=0.3571 topk_prob_mean=0.3268 ema_alpha_reverse=nan max_logit=13.7570
step:414/1750 train_time:195574ms step_avg:472.40ms
[train step 414] avg_loss=4.212884 main=3.637476 aux=0.575408 imp_cv2=0.6440 load_cv2=6.1419 usage_frac=0.2857 topk_prob_mean=0.2568 ema_alpha_reverse=nan max_logit=10.5340
step:415/1750 train_time:196043ms step_avg:472.39ms
[train step 415] avg_loss=4.811426 main=4.272418 aux=0.539008 imp_cv2=0.6666 load_cv2=5.7133 usage_frac=0.3482 topk_prob_mean=0.3109 ema_alpha_reverse=nan max_logit=13.7570
step:416/1750 train_time:196529ms step_avg:472.42ms
[train step 416] avg_loss=4.311345 main=3.765461 aux=0.545884 imp_cv2=0.6631 load_cv2=5.8007 usage_frac=0.3661 topk_prob_mean=0.3015 ema_alpha_reverse=nan max_logit=13.7570
step:417/1750 train_time:197006ms step_avg:472.44ms
[train step 417] avg_loss=4.830658 main=4.259179 aux=0.571479 imp_cv2=0.6512 load_cv2=6.0858 usage_frac=0.2723 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=11.3315
step:418/1750 train_time:197477ms step_avg:472.43ms
[train step 418] avg_loss=4.290794 main=3.751757 aux=0.539036 imp_cv2=0.7180 load_cv2=5.6751 usage_frac=0.3438 topk_prob_mean=0.3267 ema_alpha_reverse=nan max_logit=13.7570
step:419/1750 train_time:197943ms step_avg:472.42ms
[train step 419] avg_loss=4.389292 main=3.826258 aux=0.563035 imp_cv2=0.6529 load_cv2=5.9977 usage_frac=0.3348 topk_prob_mean=0.2751 ema_alpha_reverse=nan max_logit=13.7570
step:420/1750 train_time:198409ms step_avg:472.40ms
[train step 420] avg_loss=4.556159 main=4.009778 aux=0.546381 imp_cv2=0.6767 load_cv2=5.7917 usage_frac=0.3482 topk_prob_mean=0.3123 ema_alpha_reverse=nan max_logit=13.7570
step:421/1750 train_time:198873ms step_avg:472.38ms
[train step 421] avg_loss=4.578074 main=3.992067 aux=0.586007 imp_cv2=0.6585 load_cv2=6.2517 usage_frac=0.2902 topk_prob_mean=0.2636 ema_alpha_reverse=nan max_logit=11.0349
step:422/1750 train_time:199340ms step_avg:472.37ms
[train step 422] avg_loss=4.334159 main=3.796901 aux=0.537259 imp_cv2=0.6921 load_cv2=5.6682 usage_frac=0.3482 topk_prob_mean=0.3246 ema_alpha_reverse=nan max_logit=13.7570
step:423/1750 train_time:199827ms step_avg:472.40ms
[train step 423] avg_loss=4.721808 main=4.175253 aux=0.546555 imp_cv2=0.6774 load_cv2=5.7849 usage_frac=0.3482 topk_prob_mean=0.3120 ema_alpha_reverse=nan max_logit=13.7570
step:424/1750 train_time:200304ms step_avg:472.42ms
[train step 424] avg_loss=4.439470 main=3.895373 aux=0.544097 imp_cv2=0.7303 load_cv2=5.7111 usage_frac=0.3393 topk_prob_mean=0.3338 ema_alpha_reverse=nan max_logit=13.7570
step:425/1750 train_time:200760ms step_avg:472.38ms
[train step 425] avg_loss=4.553588 main=4.008984 aux=0.544604 imp_cv2=0.6870 load_cv2=5.7604 usage_frac=0.3527 topk_prob_mean=0.3180 ema_alpha_reverse=nan max_logit=13.7570
step:426/1750 train_time:201230ms step_avg:472.37ms
[train step 426] avg_loss=4.510679 main=3.962466 aux=0.548212 imp_cv2=0.6857 load_cv2=5.8025 usage_frac=0.3393 topk_prob_mean=0.3143 ema_alpha_reverse=nan max_logit=13.7570
step:427/1750 train_time:201702ms step_avg:472.37ms
[train step 427] avg_loss=4.580960 main=4.030939 aux=0.550022 imp_cv2=0.6798 load_cv2=5.8302 usage_frac=0.3571 topk_prob_mean=0.3094 ema_alpha_reverse=nan max_logit=13.7570
step:428/1750 train_time:202168ms step_avg:472.35ms
[train step 428] avg_loss=4.113091 main=3.571332 aux=0.541759 imp_cv2=0.7449 load_cv2=5.6853 usage_frac=0.3527 topk_prob_mean=0.3388 ema_alpha_reverse=nan max_logit=13.7570
step:429/1750 train_time:202644ms step_avg:472.36ms
[train step 429] avg_loss=4.454860 main=3.906301 aux=0.548559 imp_cv2=0.7097 load_cv2=5.7971 usage_frac=0.3527 topk_prob_mean=0.3250 ema_alpha_reverse=nan max_logit=13.7570
step:430/1750 train_time:203099ms step_avg:472.32ms
[train step 430] avg_loss=4.545256 main=3.994767 aux=0.550489 imp_cv2=0.6547 load_cv2=5.8551 usage_frac=0.3527 topk_prob_mean=0.3006 ema_alpha_reverse=nan max_logit=13.7570
step:431/1750 train_time:203579ms step_avg:472.34ms
[train step 431] avg_loss=4.431914 main=3.887701 aux=0.544213 imp_cv2=0.7048 load_cv2=5.7409 usage_frac=0.3571 topk_prob_mean=0.3265 ema_alpha_reverse=nan max_logit=13.7570
step:432/1750 train_time:204075ms step_avg:472.40ms
[train step 432] avg_loss=4.306084 main=3.760723 aux=0.545360 imp_cv2=0.6673 load_cv2=5.7825 usage_frac=0.3527 topk_prob_mean=0.3104 ema_alpha_reverse=nan max_logit=13.7570
step:433/1750 train_time:204541ms step_avg:472.38ms
[train step 433] avg_loss=4.539540 main=3.993689 aux=0.545851 imp_cv2=0.6447 load_cv2=5.8015 usage_frac=0.3571 topk_prob_mean=0.2949 ema_alpha_reverse=nan max_logit=13.7570
step:434/1750 train_time:205028ms step_avg:472.41ms
[train step 434] avg_loss=4.879920 main=4.318864 aux=0.561056 imp_cv2=0.6456 load_cv2=5.9764 usage_frac=0.3438 topk_prob_mean=0.2809 ema_alpha_reverse=nan max_logit=13.7570
step:435/1750 train_time:205510ms step_avg:472.44ms
[train step 435] avg_loss=4.588539 main=4.043161 aux=0.545378 imp_cv2=0.6607 load_cv2=5.7831 usage_frac=0.3438 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=13.7570
step:436/1750 train_time:205982ms step_avg:472.44ms
[train step 436] avg_loss=4.104174 main=3.568384 aux=0.535790 imp_cv2=0.6733 load_cv2=5.6704 usage_frac=0.3527 topk_prob_mean=0.3172 ema_alpha_reverse=nan max_logit=13.7570
step:437/1750 train_time:206445ms step_avg:472.41ms
[train step 437] avg_loss=4.488501 main=3.953116 aux=0.535385 imp_cv2=0.6926 load_cv2=5.6390 usage_frac=0.3571 topk_prob_mean=0.3223 ema_alpha_reverse=nan max_logit=13.7570
step:438/1750 train_time:206917ms step_avg:472.41ms
[train step 438] avg_loss=4.143617 main=3.609137 aux=0.534481 imp_cv2=0.7196 load_cv2=5.6067 usage_frac=0.3527 topk_prob_mean=0.3324 ema_alpha_reverse=nan max_logit=13.7570
step:439/1750 train_time:207404ms step_avg:472.45ms
[train step 439] avg_loss=4.437615 main=3.898809 aux=0.538806 imp_cv2=0.6998 load_cv2=5.6709 usage_frac=0.3482 topk_prob_mean=0.3266 ema_alpha_reverse=nan max_logit=13.7570
step:440/1750 train_time:207885ms step_avg:472.47ms
[train step 440] avg_loss=4.437282 main=3.897892 aux=0.539390 imp_cv2=0.7067 load_cv2=5.6810 usage_frac=0.3482 topk_prob_mean=0.3298 ema_alpha_reverse=nan max_logit=13.7570
step:441/1750 train_time:208370ms step_avg:472.49ms
[train step 441] avg_loss=5.303680 main=4.451999 aux=0.851681 imp_cv2=4.3099 load_cv2=5.6603 usage_frac=0.4241 topk_prob_mean=0.7955 ema_alpha_reverse=nan max_logit=13.7570
step:442/1750 train_time:208897ms step_avg:472.62ms
[train step 442] avg_loss=4.352946 main=3.898858 aux=0.454088 imp_cv2=1.1527 load_cv2=4.1867 usage_frac=0.4554 topk_prob_mean=0.4632 ema_alpha_reverse=nan max_logit=13.7570
step:443/1750 train_time:209462ms step_avg:472.83ms
[train step 443] avg_loss=4.742264 main=4.207716 aux=0.534548 imp_cv2=0.6189 load_cv2=5.6472 usage_frac=0.4062 topk_prob_mean=0.3157 ema_alpha_reverse=nan max_logit=13.7570
step:444/1750 train_time:209968ms step_avg:472.90ms
[train step 444] avg_loss=4.318707 main=3.791857 aux=0.526850 imp_cv2=0.4174 load_cv2=5.7406 usage_frac=0.4062 topk_prob_mean=0.2810 ema_alpha_reverse=nan max_logit=13.7570
step:445/1750 train_time:210464ms step_avg:472.95ms
[train step 445] avg_loss=4.251943 main=3.742633 aux=0.509310 imp_cv2=0.4729 load_cv2=5.4877 usage_frac=0.4018 topk_prob_mean=0.3186 ema_alpha_reverse=nan max_logit=13.7570
step:446/1750 train_time:210988ms step_avg:473.07ms
[train step 446] avg_loss=4.703509 main=4.147322 aux=0.556187 imp_cv2=0.4417 load_cv2=6.0489 usage_frac=0.3304 topk_prob_mean=0.2535 ema_alpha_reverse=nan max_logit=11.9529
step:447/1750 train_time:211484ms step_avg:473.12ms
[train step 447] avg_loss=4.469712 main=3.951383 aux=0.518328 imp_cv2=0.4237 load_cv2=5.6390 usage_frac=0.3929 topk_prob_mean=0.2878 ema_alpha_reverse=nan max_logit=13.7570
step:448/1750 train_time:211967ms step_avg:473.14ms
[train step 448] avg_loss=4.297138 main=3.787809 aux=0.509329 imp_cv2=0.4375 load_cv2=5.5262 usage_frac=0.3884 topk_prob_mean=0.2972 ema_alpha_reverse=nan max_logit=13.7570
step:449/1750 train_time:212458ms step_avg:473.18ms
[train step 449] avg_loss=4.245121 main=3.729502 aux=0.515620 imp_cv2=0.4263 load_cv2=5.6136 usage_frac=0.3795 topk_prob_mean=0.2896 ema_alpha_reverse=nan max_logit=13.7570
step:450/1750 train_time:212938ms step_avg:473.20ms
Running validation...
step:450/1750 val_loss:3.893742 train_time:212950ms step_avg:473.22ms
[train step 450] avg_loss=4.533284 main=4.023315 aux=0.509968 imp_cv2=0.4163 load_cv2=5.5497 usage_frac=0.3839 topk_prob_mean=0.2885 ema_alpha_reverse=nan max_logit=13.7570
step:451/1750 train_time:213428ms step_avg:473.23ms
[train step 451] avg_loss=4.391575 main=3.858368 aux=0.533208 imp_cv2=0.4109 load_cv2=5.8267 usage_frac=0.3661 topk_prob_mean=0.2598 ema_alpha_reverse=nan max_logit=13.7570
step:452/1750 train_time:213914ms step_avg:473.26ms
[train step 452] avg_loss=4.504979 main=4.001573 aux=0.503406 imp_cv2=0.4166 load_cv2=5.4786 usage_frac=0.3884 topk_prob_mean=0.2950 ema_alpha_reverse=nan max_logit=13.7570
step:453/1750 train_time:214398ms step_avg:473.28ms
[train step 453] avg_loss=4.468668 main=3.959179 aux=0.509489 imp_cv2=0.4146 load_cv2=5.5424 usage_frac=0.3884 topk_prob_mean=0.2896 ema_alpha_reverse=nan max_logit=13.7570
step:454/1750 train_time:214891ms step_avg:473.33ms
[train step 454] avg_loss=4.158011 main=3.659169 aux=0.498842 imp_cv2=0.4852 load_cv2=5.3638 usage_frac=0.3795 topk_prob_mean=0.3255 ema_alpha_reverse=nan max_logit=13.7570
step:455/1750 train_time:215378ms step_avg:473.36ms
[train step 455] avg_loss=4.372832 main=3.860426 aux=0.512405 imp_cv2=0.4609 load_cv2=5.5465 usage_frac=0.3884 topk_prob_mean=0.3075 ema_alpha_reverse=nan max_logit=13.7570
step:456/1750 train_time:215868ms step_avg:473.40ms
[train step 456] avg_loss=4.338786 main=3.822727 aux=0.516059 imp_cv2=0.4667 load_cv2=5.5888 usage_frac=0.3795 topk_prob_mean=0.3111 ema_alpha_reverse=nan max_logit=13.7570
step:457/1750 train_time:216344ms step_avg:473.40ms
[train step 457] avg_loss=4.546561 main=4.029530 aux=0.517031 imp_cv2=0.4452 load_cv2=5.6188 usage_frac=0.3839 topk_prob_mean=0.3039 ema_alpha_reverse=nan max_logit=13.7570
step:458/1750 train_time:216813ms step_avg:473.39ms
[train step 458] avg_loss=4.441757 main=3.925208 aux=0.516549 imp_cv2=0.3959 load_cv2=5.6517 usage_frac=0.3884 topk_prob_mean=0.2809 ema_alpha_reverse=nan max_logit=13.7570
step:459/1750 train_time:217285ms step_avg:473.39ms
[train step 459] avg_loss=4.108740 main=3.599179 aux=0.509561 imp_cv2=0.4251 load_cv2=5.5494 usage_frac=0.3839 topk_prob_mean=0.2987 ema_alpha_reverse=nan max_logit=13.7570
step:460/1750 train_time:217754ms step_avg:473.38ms
[train step 460] avg_loss=4.070116 main=3.565105 aux=0.505010 imp_cv2=0.4565 load_cv2=5.4718 usage_frac=0.3884 topk_prob_mean=0.3110 ema_alpha_reverse=nan max_logit=13.7570
step:461/1750 train_time:218228ms step_avg:473.38ms
[train step 461] avg_loss=4.453363 main=3.938681 aux=0.514682 imp_cv2=0.4011 load_cv2=5.6392 usage_frac=0.3884 topk_prob_mean=0.2829 ema_alpha_reverse=nan max_logit=13.7570
step:462/1750 train_time:218704ms step_avg:473.39ms
[train step 462] avg_loss=4.650528 main=4.135316 aux=0.515212 imp_cv2=0.3927 load_cv2=5.6482 usage_frac=0.3839 topk_prob_mean=0.2759 ema_alpha_reverse=nan max_logit=13.7570
step:463/1750 train_time:219189ms step_avg:473.41ms
[train step 463] avg_loss=4.498321 main=3.995295 aux=0.503026 imp_cv2=0.4183 load_cv2=5.4772 usage_frac=0.3795 topk_prob_mean=0.2957 ema_alpha_reverse=nan max_logit=13.7570
step:464/1750 train_time:219672ms step_avg:473.43ms
[train step 464] avg_loss=4.476126 main=3.948650 aux=0.527476 imp_cv2=0.4010 load_cv2=5.7878 usage_frac=0.3884 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=13.7570
step:465/1750 train_time:220131ms step_avg:473.40ms
[train step 465] avg_loss=4.213235 main=3.701813 aux=0.511422 imp_cv2=0.4444 load_cv2=5.5651 usage_frac=0.3750 topk_prob_mean=0.2996 ema_alpha_reverse=nan max_logit=13.7570
step:466/1750 train_time:220596ms step_avg:473.38ms
[train step 466] avg_loss=4.371677 main=3.861209 aux=0.510468 imp_cv2=0.4306 load_cv2=5.5651 usage_frac=0.3884 topk_prob_mean=0.2951 ema_alpha_reverse=nan max_logit=13.7570
step:467/1750 train_time:221077ms step_avg:473.40ms
[train step 467] avg_loss=4.455377 main=3.948572 aux=0.506804 imp_cv2=0.4345 load_cv2=5.5146 usage_frac=0.3929 topk_prob_mean=0.2979 ema_alpha_reverse=nan max_logit=13.7570
step:468/1750 train_time:221546ms step_avg:473.39ms
[train step 468] avg_loss=4.760442 main=4.239199 aux=0.521243 imp_cv2=0.4112 load_cv2=5.7020 usage_frac=0.3839 topk_prob_mean=0.2735 ema_alpha_reverse=nan max_logit=13.7570
step:469/1750 train_time:222010ms step_avg:473.37ms
[train step 469] avg_loss=4.319489 main=3.806095 aux=0.513394 imp_cv2=0.4206 load_cv2=5.6039 usage_frac=0.3884 topk_prob_mean=0.2901 ema_alpha_reverse=nan max_logit=13.7570
step:470/1750 train_time:222474ms step_avg:473.35ms
[train step 470] avg_loss=4.499644 main=3.970886 aux=0.528758 imp_cv2=0.3850 load_cv2=5.8048 usage_frac=0.3839 topk_prob_mean=0.2612 ema_alpha_reverse=nan max_logit=13.7570
step:471/1750 train_time:222952ms step_avg:473.36ms
[train step 471] avg_loss=4.311062 main=3.798113 aux=0.512949 imp_cv2=0.4141 load_cv2=5.6040 usage_frac=0.3839 topk_prob_mean=0.2908 ema_alpha_reverse=nan max_logit=13.7570
step:472/1750 train_time:223422ms step_avg:473.35ms
[train step 472] avg_loss=4.256360 main=3.750097 aux=0.506264 imp_cv2=0.4502 load_cv2=5.4894 usage_frac=0.3839 topk_prob_mean=0.3061 ema_alpha_reverse=nan max_logit=13.7570
step:473/1750 train_time:223890ms step_avg:473.34ms
[train step 473] avg_loss=4.361131 main=3.850659 aux=0.510473 imp_cv2=0.4173 load_cv2=5.5658 usage_frac=0.3839 topk_prob_mean=0.2911 ema_alpha_reverse=nan max_logit=13.7570
step:474/1750 train_time:224365ms step_avg:473.34ms
[train step 474] avg_loss=4.261411 main=3.741262 aux=0.520148 imp_cv2=0.3995 load_cv2=5.7018 usage_frac=0.3795 topk_prob_mean=0.2760 ema_alpha_reverse=nan max_logit=13.7570
step:475/1750 train_time:224854ms step_avg:473.38ms
[train step 475] avg_loss=4.401776 main=3.883488 aux=0.518288 imp_cv2=0.4005 load_cv2=5.6786 usage_frac=0.3884 topk_prob_mean=0.2777 ema_alpha_reverse=nan max_logit=13.7570
step:476/1750 train_time:225344ms step_avg:473.41ms
[train step 476] avg_loss=4.187740 main=3.667981 aux=0.519759 imp_cv2=0.3953 load_cv2=5.7032 usage_frac=0.3839 topk_prob_mean=0.2751 ema_alpha_reverse=nan max_logit=13.7570
step:477/1750 train_time:225822ms step_avg:473.42ms
[train step 477] avg_loss=4.659523 main=4.122888 aux=0.536635 imp_cv2=0.3638 load_cv2=5.9265 usage_frac=0.3839 topk_prob_mean=0.2427 ema_alpha_reverse=nan max_logit=13.7570
step:478/1750 train_time:226299ms step_avg:473.43ms
[train step 478] avg_loss=4.275919 main=3.758796 aux=0.517123 imp_cv2=0.3961 load_cv2=5.6744 usage_frac=0.3795 topk_prob_mean=0.2766 ema_alpha_reverse=nan max_logit=13.7570
step:479/1750 train_time:226763ms step_avg:473.41ms
[train step 479] avg_loss=4.250309 main=3.730424 aux=0.519885 imp_cv2=0.3915 load_cv2=5.7108 usage_frac=0.3750 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=13.7570
step:480/1750 train_time:227226ms step_avg:473.39ms
[train step 480] avg_loss=4.642211 main=4.103445 aux=0.538767 imp_cv2=0.3654 load_cv2=5.9627 usage_frac=0.3750 topk_prob_mean=0.2396 ema_alpha_reverse=nan max_logit=13.7570
step:481/1750 train_time:227701ms step_avg:473.39ms
[train step 481] avg_loss=4.376197 main=3.867107 aux=0.509090 imp_cv2=0.4128 load_cv2=5.5647 usage_frac=0.3839 topk_prob_mean=0.2840 ema_alpha_reverse=nan max_logit=13.7570
step:482/1750 train_time:228165ms step_avg:473.37ms
[train step 482] avg_loss=4.219383 main=3.712484 aux=0.506899 imp_cv2=0.4446 load_cv2=5.5027 usage_frac=0.3750 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=13.7570
step:483/1750 train_time:228644ms step_avg:473.38ms
[train step 483] avg_loss=4.323264 main=3.813025 aux=0.510238 imp_cv2=0.4057 load_cv2=5.5771 usage_frac=0.3839 topk_prob_mean=0.2807 ema_alpha_reverse=nan max_logit=13.7570
step:484/1750 train_time:229125ms step_avg:473.40ms
[train step 484] avg_loss=4.102465 main=3.588460 aux=0.514005 imp_cv2=0.4047 load_cv2=5.6269 usage_frac=0.3750 topk_prob_mean=0.2787 ema_alpha_reverse=nan max_logit=13.7570
step:485/1750 train_time:229600ms step_avg:473.40ms
[train step 485] avg_loss=5.382098 main=4.846179 aux=0.535919 imp_cv2=0.3665 load_cv2=5.9177 usage_frac=0.3795 topk_prob_mean=0.2461 ema_alpha_reverse=nan max_logit=13.7570
step:486/1750 train_time:230081ms step_avg:473.42ms
[train step 486] avg_loss=4.213328 main=3.706434 aux=0.506894 imp_cv2=0.4537 load_cv2=5.4986 usage_frac=0.3839 topk_prob_mean=0.3034 ema_alpha_reverse=nan max_logit=13.7570
step:487/1750 train_time:230558ms step_avg:473.42ms
[train step 487] avg_loss=4.077830 main=3.573546 aux=0.504284 imp_cv2=0.4456 load_cv2=5.4702 usage_frac=0.3839 topk_prob_mean=0.2995 ema_alpha_reverse=nan max_logit=13.7570
step:488/1750 train_time:231033ms step_avg:473.43ms
[train step 488] avg_loss=4.206589 main=3.690516 aux=0.516073 imp_cv2=0.3860 load_cv2=5.6681 usage_frac=0.3839 topk_prob_mean=0.2705 ema_alpha_reverse=nan max_logit=13.7570
step:489/1750 train_time:231507ms step_avg:473.43ms
[train step 489] avg_loss=4.183493 main=3.673027 aux=0.510466 imp_cv2=0.4239 load_cv2=5.5628 usage_frac=0.3839 topk_prob_mean=0.2899 ema_alpha_reverse=nan max_logit=13.7570
step:490/1750 train_time:231975ms step_avg:473.42ms
[train step 490] avg_loss=4.580949 main=4.052293 aux=0.528655 imp_cv2=0.3954 load_cv2=5.8117 usage_frac=0.3750 topk_prob_mean=0.2622 ema_alpha_reverse=nan max_logit=13.7570
step:491/1750 train_time:232433ms step_avg:473.39ms
[train step 491] avg_loss=4.350421 main=3.837573 aux=0.512847 imp_cv2=0.4151 load_cv2=5.6049 usage_frac=0.3705 topk_prob_mean=0.2816 ema_alpha_reverse=nan max_logit=13.7570
step:492/1750 train_time:232908ms step_avg:473.39ms
[train step 492] avg_loss=4.146425 main=3.638073 aux=0.508352 imp_cv2=0.4068 load_cv2=5.5605 usage_frac=0.3795 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=13.7570
step:493/1750 train_time:233359ms step_avg:473.35ms
[train step 493] avg_loss=4.330749 main=3.822160 aux=0.508589 imp_cv2=0.3977 load_cv2=5.5675 usage_frac=0.3795 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=13.7570
step:494/1750 train_time:233831ms step_avg:473.34ms
[train step 494] avg_loss=4.359204 main=3.836335 aux=0.522869 imp_cv2=0.3619 load_cv2=5.7675 usage_frac=0.3750 topk_prob_mean=0.2533 ema_alpha_reverse=nan max_logit=13.7570
step:495/1750 train_time:234312ms step_avg:473.36ms
[train step 495] avg_loss=4.318477 main=3.789174 aux=0.529303 imp_cv2=0.3665 load_cv2=5.8414 usage_frac=0.3750 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=13.7570
step:496/1750 train_time:234777ms step_avg:473.34ms
[train step 496] avg_loss=4.479150 main=3.950453 aux=0.528697 imp_cv2=0.3649 load_cv2=5.8367 usage_frac=0.3750 topk_prob_mean=0.2480 ema_alpha_reverse=nan max_logit=13.7570
step:497/1750 train_time:235256ms step_avg:473.35ms
[train step 497] avg_loss=4.163529 main=3.647306 aux=0.516222 imp_cv2=0.4134 load_cv2=5.6499 usage_frac=0.3705 topk_prob_mean=0.2831 ema_alpha_reverse=nan max_logit=13.7570
step:498/1750 train_time:235724ms step_avg:473.34ms
[train step 498] avg_loss=4.409881 main=3.868067 aux=0.541815 imp_cv2=0.3764 load_cv2=5.9800 usage_frac=0.3750 topk_prob_mean=0.2447 ema_alpha_reverse=nan max_logit=12.7744
step:499/1750 train_time:236191ms step_avg:473.33ms
[train step 499] avg_loss=5.780072 main=5.204497 aux=0.575575 imp_cv2=0.5015 load_cv2=6.2778 usage_frac=0.3214 topk_prob_mean=0.2324 ema_alpha_reverse=nan max_logit=10.4330
step:500/1750 train_time:236656ms step_avg:473.31ms
Running validation...
step:500/1750 val_loss:3.796903 train_time:236668ms step_avg:473.34ms
[train step 500] avg_loss=4.203398 main=3.685268 aux=0.518130 imp_cv2=0.4005 load_cv2=5.6760 usage_frac=0.3839 topk_prob_mean=0.2726 ema_alpha_reverse=nan max_logit=13.7570
step:501/1750 train_time:237116ms step_avg:473.28ms
[train step 501] avg_loss=4.250472 main=3.731820 aux=0.518652 imp_cv2=0.4015 load_cv2=5.6881 usage_frac=0.3795 topk_prob_mean=0.2726 ema_alpha_reverse=nan max_logit=13.7570
step:502/1750 train_time:237590ms step_avg:473.29ms
[train step 502] avg_loss=4.241982 main=3.731238 aux=0.510745 imp_cv2=0.4475 load_cv2=5.5494 usage_frac=0.3839 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=13.7570
step:503/1750 train_time:238057ms step_avg:473.28ms
[train step 503] avg_loss=4.176332 main=3.668368 aux=0.507963 imp_cv2=0.4629 load_cv2=5.4944 usage_frac=0.3839 topk_prob_mean=0.2990 ema_alpha_reverse=nan max_logit=13.7570
step:504/1750 train_time:238526ms step_avg:473.26ms
[train step 504] avg_loss=4.196348 main=3.680827 aux=0.515521 imp_cv2=0.3946 load_cv2=5.6544 usage_frac=0.3795 topk_prob_mean=0.2703 ema_alpha_reverse=nan max_logit=13.7570
step:505/1750 train_time:238998ms step_avg:473.26ms
[train step 505] avg_loss=4.144500 main=3.637581 aux=0.506919 imp_cv2=0.4160 load_cv2=5.5272 usage_frac=0.3839 topk_prob_mean=0.2845 ema_alpha_reverse=nan max_logit=13.7570
step:506/1750 train_time:239495ms step_avg:473.31ms
[train step 506] avg_loss=4.021869 main=3.521855 aux=0.500015 imp_cv2=0.4652 load_cv2=5.4022 usage_frac=0.3795 topk_prob_mean=0.3044 ema_alpha_reverse=nan max_logit=13.7570
step:507/1750 train_time:239987ms step_avg:473.35ms
[train step 507] avg_loss=4.220852 main=3.708982 aux=0.511870 imp_cv2=0.4017 load_cv2=5.6021 usage_frac=0.3750 topk_prob_mean=0.2751 ema_alpha_reverse=nan max_logit=13.7570
step:508/1750 train_time:240468ms step_avg:473.36ms
[train step 508] avg_loss=4.463407 main=3.951485 aux=0.511923 imp_cv2=0.4025 load_cv2=5.6017 usage_frac=0.3750 topk_prob_mean=0.2754 ema_alpha_reverse=nan max_logit=13.7570
step:509/1750 train_time:240929ms step_avg:473.34ms
[train step 509] avg_loss=4.174332 main=3.668352 aux=0.505980 imp_cv2=0.4550 load_cv2=5.4843 usage_frac=0.3839 topk_prob_mean=0.3005 ema_alpha_reverse=nan max_logit=13.7570
step:510/1750 train_time:241401ms step_avg:473.34ms
[train step 510] avg_loss=4.071890 main=3.566987 aux=0.504903 imp_cv2=0.4217 load_cv2=5.5020 usage_frac=0.3839 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=13.7570
step:511/1750 train_time:241895ms step_avg:473.38ms
[train step 511] avg_loss=4.069673 main=3.561670 aux=0.508003 imp_cv2=0.4030 load_cv2=5.5619 usage_frac=0.3795 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=13.7570
step:512/1750 train_time:242356ms step_avg:473.35ms
[train step 512] avg_loss=4.198966 main=3.683491 aux=0.515475 imp_cv2=0.3846 load_cv2=5.6555 usage_frac=0.3795 topk_prob_mean=0.2699 ema_alpha_reverse=nan max_logit=13.7570
step:513/1750 train_time:242820ms step_avg:473.33ms
[train step 513] avg_loss=4.161740 main=3.662930 aux=0.498810 imp_cv2=0.4560 load_cv2=5.3978 usage_frac=0.3884 topk_prob_mean=0.3013 ema_alpha_reverse=nan max_logit=13.7570
step:514/1750 train_time:243308ms step_avg:473.36ms
[train step 514] avg_loss=4.214166 main=3.703392 aux=0.510774 imp_cv2=0.3929 load_cv2=5.6009 usage_frac=0.3884 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=13.7570
step:515/1750 train_time:243805ms step_avg:473.41ms
[train step 515] avg_loss=4.157791 main=3.654891 aux=0.502899 imp_cv2=0.4176 load_cv2=5.4825 usage_frac=0.3795 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=13.7570
step:516/1750 train_time:244280ms step_avg:473.41ms
[train step 516] avg_loss=4.333576 main=3.827580 aux=0.505996 imp_cv2=0.4221 load_cv2=5.5151 usage_frac=0.3795 topk_prob_mean=0.2874 ema_alpha_reverse=nan max_logit=13.7570
step:517/1750 train_time:244743ms step_avg:473.39ms
[train step 517] avg_loss=5.410547 main=4.889647 aux=0.520900 imp_cv2=0.3958 load_cv2=5.7108 usage_frac=0.3839 topk_prob_mean=0.2595 ema_alpha_reverse=nan max_logit=13.7570
step:518/1750 train_time:245200ms step_avg:473.36ms
[train step 518] avg_loss=4.897185 main=4.359460 aux=0.537725 imp_cv2=0.3791 load_cv2=5.9284 usage_frac=0.3795 topk_prob_mean=0.2445 ema_alpha_reverse=nan max_logit=13.7570
step:519/1750 train_time:245690ms step_avg:473.39ms
[train step 519] avg_loss=4.145992 main=3.643146 aux=0.502846 imp_cv2=0.4292 load_cv2=5.4753 usage_frac=0.3750 topk_prob_mean=0.2897 ema_alpha_reverse=nan max_logit=13.7570
step:520/1750 train_time:246177ms step_avg:473.42ms
[train step 520] avg_loss=4.227105 main=3.717087 aux=0.510018 imp_cv2=0.4063 load_cv2=5.5763 usage_frac=0.3705 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=13.7570
step:521/1750 train_time:246650ms step_avg:473.42ms
[train step 521] avg_loss=4.002744 main=3.501348 aux=0.501397 imp_cv2=0.4455 load_cv2=5.4387 usage_frac=0.3750 topk_prob_mean=0.2962 ema_alpha_reverse=nan max_logit=13.7570
step:522/1750 train_time:247132ms step_avg:473.43ms
[train step 522] avg_loss=4.902440 main=4.358765 aux=0.543676 imp_cv2=0.3804 load_cv2=6.0063 usage_frac=0.3661 topk_prob_mean=0.2236 ema_alpha_reverse=nan max_logit=12.7744
step:523/1750 train_time:247606ms step_avg:473.43ms
[train step 523] avg_loss=4.232195 main=3.725816 aux=0.506379 imp_cv2=0.4325 load_cv2=5.5134 usage_frac=0.3795 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=13.7570
step:524/1750 train_time:248067ms step_avg:473.41ms
[train step 524] avg_loss=4.587247 main=4.070115 aux=0.517133 imp_cv2=0.4030 load_cv2=5.6509 usage_frac=0.3795 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=13.7570
step:525/1750 train_time:248540ms step_avg:473.41ms
[train step 525] avg_loss=4.515462 main=3.967333 aux=0.548129 imp_cv2=0.3716 load_cv2=6.0509 usage_frac=0.3661 topk_prob_mean=0.2304 ema_alpha_reverse=nan max_logit=13.7570
step:526/1750 train_time:249004ms step_avg:473.39ms
[train step 526] avg_loss=4.294481 main=3.774481 aux=0.520000 imp_cv2=0.3745 load_cv2=5.7283 usage_frac=0.3661 topk_prob_mean=0.2602 ema_alpha_reverse=nan max_logit=13.7570
step:527/1750 train_time:249477ms step_avg:473.39ms
[train step 527] avg_loss=3.953562 main=3.448422 aux=0.505140 imp_cv2=0.4195 load_cv2=5.5118 usage_frac=0.3750 topk_prob_mean=0.2862 ema_alpha_reverse=nan max_logit=13.7570
step:528/1750 train_time:249949ms step_avg:473.39ms
[train step 528] avg_loss=4.523620 main=4.000496 aux=0.523124 imp_cv2=0.3634 load_cv2=5.7815 usage_frac=0.3884 topk_prob_mean=0.2516 ema_alpha_reverse=nan max_logit=13.7570
step:529/1750 train_time:250411ms step_avg:473.37ms
[train step 529] avg_loss=4.169392 main=3.653523 aux=0.515868 imp_cv2=0.3769 load_cv2=5.6736 usage_frac=0.3750 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=13.7570
step:530/1750 train_time:250878ms step_avg:473.35ms
[train step 530] avg_loss=4.254488 main=3.740885 aux=0.513603 imp_cv2=0.3932 load_cv2=5.6323 usage_frac=0.3795 topk_prob_mean=0.2696 ema_alpha_reverse=nan max_logit=13.7570
step:531/1750 train_time:251346ms step_avg:473.34ms
[train step 531] avg_loss=4.323790 main=3.800834 aux=0.522956 imp_cv2=0.3722 load_cv2=5.7688 usage_frac=0.3705 topk_prob_mean=0.2550 ema_alpha_reverse=nan max_logit=13.7570
step:532/1750 train_time:251819ms step_avg:473.34ms
[train step 532] avg_loss=4.582484 main=4.023412 aux=0.559073 imp_cv2=0.4250 load_cv2=6.1246 usage_frac=0.3036 topk_prob_mean=0.2262 ema_alpha_reverse=nan max_logit=11.4888
step:533/1750 train_time:252289ms step_avg:473.34ms
[train step 533] avg_loss=4.570454 main=4.018010 aux=0.552444 imp_cv2=0.3615 load_cv2=6.1289 usage_frac=0.3080 topk_prob_mean=0.2172 ema_alpha_reverse=nan max_logit=11.7917
step:534/1750 train_time:252905ms step_avg:473.60ms
[train step 534] avg_loss=4.265815 main=3.752475 aux=0.513341 imp_cv2=0.4081 load_cv2=5.6277 usage_frac=0.3884 topk_prob_mean=0.2783 ema_alpha_reverse=nan max_logit=13.7570
step:535/1750 train_time:253374ms step_avg:473.60ms
[train step 535] avg_loss=4.316463 main=3.803624 aux=0.512839 imp_cv2=0.4118 load_cv2=5.6141 usage_frac=0.3839 topk_prob_mean=0.2804 ema_alpha_reverse=nan max_logit=13.7570
step:536/1750 train_time:253830ms step_avg:473.56ms
[train step 536] avg_loss=4.191866 main=3.673259 aux=0.518608 imp_cv2=0.3918 load_cv2=5.7045 usage_frac=0.3839 topk_prob_mean=0.2671 ema_alpha_reverse=nan max_logit=13.7570
step:537/1750 train_time:254308ms step_avg:473.57ms
[train step 537] avg_loss=3.905981 main=3.391505 aux=0.514476 imp_cv2=0.5117 load_cv2=5.5469 usage_frac=0.3884 topk_prob_mean=0.3129 ema_alpha_reverse=nan max_logit=13.7570
step:538/1750 train_time:254906ms step_avg:473.80ms
[train step 538] avg_loss=4.105972 main=3.579378 aux=0.526594 imp_cv2=0.4330 load_cv2=5.7595 usage_frac=0.3750 topk_prob_mean=0.2815 ema_alpha_reverse=nan max_logit=13.7570
step:539/1750 train_time:255381ms step_avg:473.80ms
[train step 539] avg_loss=4.421953 main=3.898318 aux=0.523635 imp_cv2=0.3880 load_cv2=5.7641 usage_frac=0.3705 topk_prob_mean=0.2634 ema_alpha_reverse=nan max_logit=13.7570
step:540/1750 train_time:255848ms step_avg:473.79ms
[train step 540] avg_loss=4.420098 main=3.898662 aux=0.521436 imp_cv2=0.4156 load_cv2=5.7174 usage_frac=0.3839 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=13.7570
step:541/1750 train_time:256497ms step_avg:474.12ms
[train step 541] avg_loss=4.084723 main=3.566339 aux=0.518384 imp_cv2=0.4131 load_cv2=5.6825 usage_frac=0.3929 topk_prob_mean=0.2781 ema_alpha_reverse=nan max_logit=13.7570
step:542/1750 train_time:256953ms step_avg:474.08ms
[train step 542] avg_loss=4.399987 main=3.855280 aux=0.544707 imp_cv2=0.3794 load_cv2=6.0179 usage_frac=0.3750 topk_prob_mean=0.2329 ema_alpha_reverse=nan max_logit=13.7570
step:543/1750 train_time:257420ms step_avg:474.07ms
[train step 543] avg_loss=4.375164 main=3.851956 aux=0.523208 imp_cv2=0.4050 load_cv2=5.7523 usage_frac=0.3884 topk_prob_mean=0.2674 ema_alpha_reverse=nan max_logit=13.7570
step:544/1750 train_time:257904ms step_avg:474.09ms
[train step 544] avg_loss=4.372085 main=3.859803 aux=0.512282 imp_cv2=0.4059 load_cv2=5.6183 usage_frac=0.3929 topk_prob_mean=0.2759 ema_alpha_reverse=nan max_logit=13.7570
step:545/1750 train_time:258394ms step_avg:474.12ms
[train step 545] avg_loss=4.152425 main=3.639112 aux=0.513313 imp_cv2=0.4194 load_cv2=5.6165 usage_frac=0.3884 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=13.7570
step:546/1750 train_time:258871ms step_avg:474.12ms
[train step 546] avg_loss=4.342492 main=3.827827 aux=0.514665 imp_cv2=0.3991 load_cv2=5.6455 usage_frac=0.3839 topk_prob_mean=0.2713 ema_alpha_reverse=nan max_logit=13.7570
step:547/1750 train_time:259352ms step_avg:474.14ms
[train step 547] avg_loss=4.776131 main=4.232414 aux=0.543717 imp_cv2=0.3699 load_cv2=6.0263 usage_frac=0.3705 topk_prob_mean=0.2356 ema_alpha_reverse=nan max_logit=13.7570
step:548/1750 train_time:259813ms step_avg:474.11ms
[train step 548] avg_loss=4.762582 main=4.231392 aux=0.531190 imp_cv2=0.3772 load_cv2=5.8722 usage_frac=0.3795 topk_prob_mean=0.2477 ema_alpha_reverse=nan max_logit=13.7570
step:549/1750 train_time:260285ms step_avg:474.11ms
[train step 549] avg_loss=4.218075 main=3.686772 aux=0.531303 imp_cv2=0.4265 load_cv2=5.8214 usage_frac=0.3750 topk_prob_mean=0.2721 ema_alpha_reverse=nan max_logit=13.7570
step:550/1750 train_time:260738ms step_avg:474.07ms
Running validation...
step:550/1750 val_loss:3.720262 train_time:260750ms step_avg:474.09ms
[train step 550] avg_loss=4.671394 main=4.140122 aux=0.531272 imp_cv2=0.3858 load_cv2=5.8609 usage_frac=0.3839 topk_prob_mean=0.2597 ema_alpha_reverse=nan max_logit=13.7570
step:551/1750 train_time:261193ms step_avg:474.04ms
[train step 551] avg_loss=6.622803 main=6.062996 aux=0.559807 imp_cv2=0.4028 load_cv2=6.1697 usage_frac=0.3080 topk_prob_mean=0.2238 ema_alpha_reverse=nan max_logit=10.8091
step:552/1750 train_time:261648ms step_avg:474.00ms
[train step 552] avg_loss=3.820144 main=3.308529 aux=0.511615 imp_cv2=0.4814 load_cv2=5.5386 usage_frac=0.3929 topk_prob_mean=0.3066 ema_alpha_reverse=nan max_logit=13.7570
step:553/1750 train_time:262118ms step_avg:473.99ms
[train step 553] avg_loss=4.349056 main=3.819659 aux=0.529397 imp_cv2=0.3962 load_cv2=5.8280 usage_frac=0.3884 topk_prob_mean=0.2597 ema_alpha_reverse=nan max_logit=12.8285
step:554/1750 train_time:262586ms step_avg:473.98ms
[train step 554] avg_loss=4.323492 main=3.803433 aux=0.520059 imp_cv2=0.4143 load_cv2=5.7015 usage_frac=0.3839 topk_prob_mean=0.2732 ema_alpha_reverse=nan max_logit=13.7570
step:555/1750 train_time:263043ms step_avg:473.95ms
[train step 555] avg_loss=4.164379 main=3.645604 aux=0.518775 imp_cv2=0.4112 load_cv2=5.6912 usage_frac=0.3795 topk_prob_mean=0.2762 ema_alpha_reverse=nan max_logit=13.7570
step:556/1750 train_time:263720ms step_avg:474.32ms
[train step 556] avg_loss=4.442231 main=3.919387 aux=0.522844 imp_cv2=0.3871 load_cv2=5.7655 usage_frac=0.3750 topk_prob_mean=0.2560 ema_alpha_reverse=nan max_logit=13.7570
step:557/1750 train_time:264177ms step_avg:474.28ms
[train step 557] avg_loss=3.871855 main=3.361750 aux=0.510106 imp_cv2=0.4470 load_cv2=5.5490 usage_frac=0.3795 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=13.7570
step:558/1750 train_time:264646ms step_avg:474.28ms
[train step 558] avg_loss=4.939882 main=4.412140 aux=0.527742 imp_cv2=0.3830 load_cv2=5.8192 usage_frac=0.3705 topk_prob_mean=0.2462 ema_alpha_reverse=nan max_logit=13.7570
step:559/1750 train_time:265109ms step_avg:474.26ms
[train step 559] avg_loss=3.910524 main=3.397391 aux=0.513133 imp_cv2=0.4370 load_cv2=5.5984 usage_frac=0.3705 topk_prob_mean=0.2922 ema_alpha_reverse=nan max_logit=13.7570
step:560/1750 train_time:265559ms step_avg:474.21ms
[train step 560] avg_loss=4.086928 main=3.570354 aux=0.516574 imp_cv2=0.4107 load_cv2=5.6678 usage_frac=0.3616 topk_prob_mean=0.2791 ema_alpha_reverse=nan max_logit=13.7570
step:561/1750 train_time:266021ms step_avg:474.19ms
[train step 561] avg_loss=4.094807 main=3.574072 aux=0.520735 imp_cv2=0.3998 load_cv2=5.7273 usage_frac=0.3795 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=13.7570
step:562/1750 train_time:266481ms step_avg:474.17ms
[train step 562] avg_loss=4.022397 main=3.513914 aux=0.508484 imp_cv2=0.4033 load_cv2=5.5754 usage_frac=0.3839 topk_prob_mean=0.2798 ema_alpha_reverse=nan max_logit=13.7570
step:563/1750 train_time:266939ms step_avg:474.14ms
[train step 563] avg_loss=4.210364 main=3.703779 aux=0.506585 imp_cv2=0.4285 load_cv2=5.5245 usage_frac=0.3795 topk_prob_mean=0.2906 ema_alpha_reverse=nan max_logit=13.7570
step:564/1750 train_time:267398ms step_avg:474.11ms
[train step 564] avg_loss=4.359759 main=3.852245 aux=0.507514 imp_cv2=0.4255 load_cv2=5.5364 usage_frac=0.3839 topk_prob_mean=0.2900 ema_alpha_reverse=nan max_logit=13.7570
step:565/1750 train_time:267882ms step_avg:474.13ms
[train step 565] avg_loss=4.081250 main=3.576280 aux=0.504971 imp_cv2=0.4421 load_cv2=5.4892 usage_frac=0.3839 topk_prob_mean=0.2966 ema_alpha_reverse=nan max_logit=13.7570
step:566/1750 train_time:268349ms step_avg:474.12ms
[train step 566] avg_loss=4.082183 main=3.574713 aux=0.507469 imp_cv2=0.4170 load_cv2=5.5390 usage_frac=0.3795 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=13.7570
step:567/1750 train_time:268818ms step_avg:474.11ms
[train step 567] avg_loss=4.741215 main=4.204398 aux=0.536817 imp_cv2=0.3789 load_cv2=5.9159 usage_frac=0.3705 topk_prob_mean=0.2397 ema_alpha_reverse=nan max_logit=13.7570
step:568/1750 train_time:269271ms step_avg:474.07ms
[train step 568] avg_loss=4.029490 main=3.524286 aux=0.505203 imp_cv2=0.4177 load_cv2=5.5175 usage_frac=0.3795 topk_prob_mean=0.2889 ema_alpha_reverse=nan max_logit=13.7570
step:569/1750 train_time:269740ms step_avg:474.06ms
[train step 569] avg_loss=4.198652 main=3.694344 aux=0.504308 imp_cv2=0.4035 load_cv2=5.5157 usage_frac=0.3795 topk_prob_mean=0.2863 ema_alpha_reverse=nan max_logit=13.7570
step:570/1750 train_time:270216ms step_avg:474.06ms
[train step 570] avg_loss=3.923241 main=3.408405 aux=0.514836 imp_cv2=0.3778 load_cv2=5.6644 usage_frac=0.3750 topk_prob_mean=0.2671 ema_alpha_reverse=nan max_logit=13.7570
step:571/1750 train_time:270678ms step_avg:474.04ms
[train step 571] avg_loss=4.200607 main=3.676603 aux=0.524003 imp_cv2=0.3761 load_cv2=5.7704 usage_frac=0.3705 topk_prob_mean=0.2562 ema_alpha_reverse=nan max_logit=13.7570
step:572/1750 train_time:271133ms step_avg:474.01ms
[train step 572] avg_loss=3.894664 main=3.390750 aux=0.503914 imp_cv2=0.4134 load_cv2=5.5062 usage_frac=0.3750 topk_prob_mean=0.2888 ema_alpha_reverse=nan max_logit=13.7570
step:573/1750 train_time:271613ms step_avg:474.02ms
[train step 573] avg_loss=4.217935 main=3.707238 aux=0.510697 imp_cv2=0.3854 load_cv2=5.6151 usage_frac=0.3839 topk_prob_mean=0.2733 ema_alpha_reverse=nan max_logit=13.7570
step:574/1750 train_time:272091ms step_avg:474.03ms
[train step 574] avg_loss=4.143900 main=3.636193 aux=0.507707 imp_cv2=0.3935 load_cv2=5.5701 usage_frac=0.3750 topk_prob_mean=0.2779 ema_alpha_reverse=nan max_logit=13.7570
step:575/1750 train_time:272753ms step_avg:474.35ms
[train step 575] avg_loss=4.224624 main=3.721182 aux=0.503443 imp_cv2=0.4353 load_cv2=5.4777 usage_frac=0.3750 topk_prob_mean=0.2969 ema_alpha_reverse=nan max_logit=13.7570
step:576/1750 train_time:273227ms step_avg:474.35ms
[train step 576] avg_loss=4.423893 main=3.895622 aux=0.528272 imp_cv2=0.3736 load_cv2=5.8304 usage_frac=0.3705 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=13.7570
step:577/1750 train_time:273688ms step_avg:474.33ms
[train step 577] avg_loss=4.079350 main=3.563839 aux=0.515511 imp_cv2=0.3905 load_cv2=5.6681 usage_frac=0.3705 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=13.7570
step:578/1750 train_time:274149ms step_avg:474.31ms
[train step 578] avg_loss=4.442473 main=3.930926 aux=0.511547 imp_cv2=0.4242 load_cv2=5.5867 usage_frac=0.3661 topk_prob_mean=0.2866 ema_alpha_reverse=nan max_logit=13.7570
step:579/1750 train_time:274615ms step_avg:474.29ms
[train step 579] avg_loss=4.623610 main=4.093439 aux=0.530171 imp_cv2=0.3839 load_cv2=5.8493 usage_frac=0.3661 topk_prob_mean=0.2550 ema_alpha_reverse=nan max_logit=13.7570
step:580/1750 train_time:275070ms step_avg:474.26ms
[train step 580] avg_loss=3.937989 main=3.425473 aux=0.512516 imp_cv2=0.4230 load_cv2=5.5959 usage_frac=0.3750 topk_prob_mean=0.2884 ema_alpha_reverse=nan max_logit=13.7570
step:581/1750 train_time:275539ms step_avg:474.25ms
[train step 581] avg_loss=4.401617 main=3.884665 aux=0.516953 imp_cv2=0.4109 load_cv2=5.6663 usage_frac=0.3661 topk_prob_mean=0.2804 ema_alpha_reverse=nan max_logit=13.7570
step:582/1750 train_time:275978ms step_avg:474.19ms
[train step 582] avg_loss=4.465783 main=3.944181 aux=0.521602 imp_cv2=0.3991 load_cv2=5.7312 usage_frac=0.3661 topk_prob_mean=0.2710 ema_alpha_reverse=nan max_logit=13.7570
step:583/1750 train_time:276436ms step_avg:474.16ms
[train step 583] avg_loss=4.229110 main=3.699502 aux=0.529608 imp_cv2=0.3946 load_cv2=5.8353 usage_frac=0.3705 topk_prob_mean=0.2636 ema_alpha_reverse=nan max_logit=13.7570
step:584/1750 train_time:276892ms step_avg:474.13ms
[train step 584] avg_loss=4.314891 main=3.800969 aux=0.513921 imp_cv2=0.4398 load_cv2=5.5987 usage_frac=0.3750 topk_prob_mean=0.2926 ema_alpha_reverse=nan max_logit=13.7570
step:585/1750 train_time:277346ms step_avg:474.10ms
[train step 585] avg_loss=4.139221 main=3.626332 aux=0.512889 imp_cv2=0.4753 load_cv2=5.5586 usage_frac=0.3661 topk_prob_mean=0.3027 ema_alpha_reverse=nan max_logit=12.7744
step:586/1750 train_time:277834ms step_avg:474.12ms
[train step 586] avg_loss=4.030585 main=3.505733 aux=0.524853 imp_cv2=0.3807 load_cv2=5.7796 usage_frac=0.3750 topk_prob_mean=0.2611 ema_alpha_reverse=nan max_logit=12.7744
step:587/1750 train_time:278286ms step_avg:474.08ms
[train step 587] avg_loss=3.978607 main=3.463404 aux=0.515203 imp_cv2=0.4682 load_cv2=5.5982 usage_frac=0.3616 topk_prob_mean=0.2988 ema_alpha_reverse=nan max_logit=13.7570
step:588/1750 train_time:278749ms step_avg:474.06ms
[train step 588] avg_loss=4.198277 main=3.677510 aux=0.520766 imp_cv2=0.4388 load_cv2=5.6863 usage_frac=0.3750 topk_prob_mean=0.2893 ema_alpha_reverse=nan max_logit=13.7570
step:589/1750 train_time:279214ms step_avg:474.05ms
[train step 589] avg_loss=4.071630 main=3.554923 aux=0.516707 imp_cv2=0.4320 load_cv2=5.6380 usage_frac=0.3705 topk_prob_mean=0.2888 ema_alpha_reverse=nan max_logit=13.2324
step:590/1750 train_time:279662ms step_avg:474.00ms
[train step 590] avg_loss=4.113125 main=3.600331 aux=0.512795 imp_cv2=0.4132 load_cv2=5.6086 usage_frac=0.3705 topk_prob_mean=0.2839 ema_alpha_reverse=nan max_logit=13.3402
step:591/1750 train_time:280113ms step_avg:473.96ms
[train step 591] avg_loss=4.413614 main=3.674726 aux=0.738889 imp_cv2=3.6307 load_cv2=4.9952 usage_frac=0.4509 topk_prob_mean=0.7858 ema_alpha_reverse=nan max_logit=13.7570
step:592/1750 train_time:280670ms step_avg:474.10ms
[train step 592] avg_loss=4.933006 main=4.353352 aux=0.579654 imp_cv2=2.0266 load_cv2=4.7139 usage_frac=0.4554 topk_prob_mean=0.5405 ema_alpha_reverse=nan max_logit=13.7570
step:593/1750 train_time:281201ms step_avg:474.20ms
[train step 593] avg_loss=4.248647 main=3.731964 aux=0.516683 imp_cv2=0.8941 load_cv2=5.2049 usage_frac=0.4643 topk_prob_mean=0.3724 ema_alpha_reverse=nan max_logit=13.7570
step:594/1750 train_time:281700ms step_avg:474.24ms
[train step 594] avg_loss=4.203928 main=3.693144 aux=0.510784 imp_cv2=0.6117 load_cv2=5.3872 usage_frac=0.4286 topk_prob_mean=0.3237 ema_alpha_reverse=nan max_logit=13.7570
step:595/1750 train_time:282195ms step_avg:474.28ms
[train step 595] avg_loss=4.183232 main=3.683570 aux=0.499662 imp_cv2=0.6038 load_cv2=5.2508 usage_frac=0.4330 topk_prob_mean=0.3389 ema_alpha_reverse=nan max_logit=13.7570
step:596/1750 train_time:282695ms step_avg:474.32ms
[train step 596] avg_loss=3.952870 main=3.447151 aux=0.505719 imp_cv2=0.6605 load_cv2=5.2693 usage_frac=0.4196 topk_prob_mean=0.3463 ema_alpha_reverse=nan max_logit=13.7570
step:597/1750 train_time:283188ms step_avg:474.35ms
[train step 597] avg_loss=4.154186 main=3.645506 aux=0.508680 imp_cv2=0.5583 load_cv2=5.3997 usage_frac=0.4107 topk_prob_mean=0.3163 ema_alpha_reverse=nan max_logit=13.7570
step:598/1750 train_time:283673ms step_avg:474.37ms
[train step 598] avg_loss=4.422054 main=3.910682 aux=0.511371 imp_cv2=0.5365 load_cv2=5.4660 usage_frac=0.4152 topk_prob_mean=0.3068 ema_alpha_reverse=nan max_logit=13.7570
step:599/1750 train_time:284148ms step_avg:474.37ms
[train step 599] avg_loss=4.016061 main=3.510947 aux=0.505114 imp_cv2=0.5056 load_cv2=5.4089 usage_frac=0.4107 topk_prob_mean=0.3107 ema_alpha_reverse=nan max_logit=13.7570
step:600/1750 train_time:284624ms step_avg:474.37ms
Running validation...
step:600/1750 val_loss:3.696376 train_time:284636ms step_avg:474.39ms
[train step 600] avg_loss=4.078218 main=3.579026 aux=0.499192 imp_cv2=0.3132 load_cv2=5.4808 usage_frac=0.4018 topk_prob_mean=0.2657 ema_alpha_reverse=nan max_logit=13.3645
step:601/1750 train_time:285100ms step_avg:474.38ms
[train step 601] avg_loss=4.039913 main=3.552330 aux=0.487584 imp_cv2=0.4198 load_cv2=5.2597 usage_frac=0.4018 topk_prob_mean=0.3109 ema_alpha_reverse=nan max_logit=13.7570
step:602/1750 train_time:285588ms step_avg:474.40ms
[train step 602] avg_loss=4.358571 main=3.869919 aux=0.488652 imp_cv2=0.2861 load_cv2=5.3888 usage_frac=0.4062 topk_prob_mean=0.2758 ema_alpha_reverse=nan max_logit=13.7570
step:603/1750 train_time:286080ms step_avg:474.43ms
[train step 603] avg_loss=4.011213 main=3.526776 aux=0.484437 imp_cv2=0.2907 load_cv2=5.3434 usage_frac=0.3973 topk_prob_mean=0.2808 ema_alpha_reverse=nan max_logit=13.7570
step:604/1750 train_time:286573ms step_avg:474.46ms
[train step 604] avg_loss=4.362613 main=3.858206 aux=0.504408 imp_cv2=0.2332 load_cv2=5.6376 usage_frac=0.3973 topk_prob_mean=0.2463 ema_alpha_reverse=nan max_logit=13.7570
step:605/1750 train_time:287081ms step_avg:474.51ms
[train step 605] avg_loss=4.052187 main=3.570099 aux=0.482088 imp_cv2=0.2813 load_cv2=5.3300 usage_frac=0.4018 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=13.7570
step:606/1750 train_time:287563ms step_avg:474.53ms
[train step 606] avg_loss=4.184679 main=3.691238 aux=0.493441 imp_cv2=0.2674 load_cv2=5.4813 usage_frac=0.4018 topk_prob_mean=0.2725 ema_alpha_reverse=nan max_logit=13.7570
step:607/1750 train_time:288043ms step_avg:474.54ms
[train step 607] avg_loss=4.206565 main=3.704123 aux=0.502441 imp_cv2=0.2156 load_cv2=5.6379 usage_frac=0.4062 topk_prob_mean=0.2484 ema_alpha_reverse=nan max_logit=13.7570
step:608/1750 train_time:288525ms step_avg:474.55ms
[train step 608] avg_loss=3.830164 main=3.338192 aux=0.491972 imp_cv2=0.3318 load_cv2=5.4106 usage_frac=0.3973 topk_prob_mean=0.2978 ema_alpha_reverse=nan max_logit=13.7570
step:609/1750 train_time:288997ms step_avg:474.54ms
[train step 609] avg_loss=4.168219 main=3.672237 aux=0.495981 imp_cv2=0.2251 load_cv2=5.5587 usage_frac=0.4152 topk_prob_mean=0.2541 ema_alpha_reverse=nan max_logit=13.7570
step:610/1750 train_time:289471ms step_avg:474.54ms
[train step 610] avg_loss=4.295345 main=3.798031 aux=0.497314 imp_cv2=0.2230 load_cv2=5.5767 usage_frac=0.4152 topk_prob_mean=0.2527 ema_alpha_reverse=nan max_logit=13.7570
step:611/1750 train_time:289954ms step_avg:474.56ms
[train step 611] avg_loss=3.968418 main=3.474252 aux=0.494165 imp_cv2=0.2435 load_cv2=5.5264 usage_frac=0.3973 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=13.7570
step:612/1750 train_time:290443ms step_avg:474.58ms
[train step 612] avg_loss=4.197334 main=3.704314 aux=0.493020 imp_cv2=0.2514 load_cv2=5.5032 usage_frac=0.4062 topk_prob_mean=0.2696 ema_alpha_reverse=nan max_logit=13.7570
step:613/1750 train_time:290909ms step_avg:474.57ms
[train step 613] avg_loss=4.005729 main=3.514605 aux=0.491124 imp_cv2=0.2525 load_cv2=5.4714 usage_frac=0.4062 topk_prob_mean=0.2720 ema_alpha_reverse=nan max_logit=13.7570
step:614/1750 train_time:291379ms step_avg:474.56ms
[train step 614] avg_loss=4.068369 main=3.568280 aux=0.500089 imp_cv2=0.2062 load_cv2=5.6204 usage_frac=0.4107 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=13.7570
step:615/1750 train_time:291845ms step_avg:474.55ms
[train step 615] avg_loss=4.435838 main=3.931870 aux=0.503968 imp_cv2=0.2290 load_cv2=5.6735 usage_frac=0.4107 topk_prob_mean=0.2476 ema_alpha_reverse=nan max_logit=13.7570
step:616/1750 train_time:292327ms step_avg:474.56ms
[train step 616] avg_loss=4.163682 main=3.641040 aux=0.522643 imp_cv2=0.1878 load_cv2=5.9207 usage_frac=0.3884 topk_prob_mean=0.2129 ema_alpha_reverse=nan max_logit=13.7570
step:617/1750 train_time:292802ms step_avg:474.56ms
[train step 617] avg_loss=3.780786 main=3.288372 aux=0.492414 imp_cv2=0.3318 load_cv2=5.4299 usage_frac=0.4062 topk_prob_mean=0.2976 ema_alpha_reverse=nan max_logit=13.7570
step:618/1750 train_time:293298ms step_avg:474.59ms
[train step 618] avg_loss=4.320871 main=3.830044 aux=0.490827 imp_cv2=0.2420 load_cv2=5.4896 usage_frac=0.3973 topk_prob_mean=0.2662 ema_alpha_reverse=nan max_logit=13.7570
step:619/1750 train_time:293767ms step_avg:474.58ms
[train step 619] avg_loss=4.232337 main=3.739441 aux=0.492896 imp_cv2=0.2273 load_cv2=5.5302 usage_frac=0.3973 topk_prob_mean=0.2594 ema_alpha_reverse=nan max_logit=13.7570
step:620/1750 train_time:294228ms step_avg:474.56ms
[train step 620] avg_loss=3.944248 main=3.443038 aux=0.501210 imp_cv2=0.2027 load_cv2=5.6509 usage_frac=0.4018 topk_prob_mean=0.2429 ema_alpha_reverse=nan max_logit=13.7570
step:621/1750 train_time:294700ms step_avg:474.56ms
[train step 621] avg_loss=3.926168 main=3.436598 aux=0.489570 imp_cv2=0.2359 load_cv2=5.4840 usage_frac=0.4062 topk_prob_mean=0.2688 ema_alpha_reverse=nan max_logit=13.7570
step:622/1750 train_time:295176ms step_avg:474.56ms
[train step 622] avg_loss=3.963729 main=3.468690 aux=0.495039 imp_cv2=0.2258 load_cv2=5.5571 usage_frac=0.4062 topk_prob_mean=0.2613 ema_alpha_reverse=nan max_logit=13.7570
step:623/1750 train_time:295638ms step_avg:474.54ms
[train step 623] avg_loss=4.487365 main=3.972459 aux=0.514906 imp_cv2=0.1782 load_cv2=5.8495 usage_frac=0.3839 topk_prob_mean=0.2166 ema_alpha_reverse=nan max_logit=13.5255
step:624/1750 train_time:296101ms step_avg:474.52ms
[train step 624] avg_loss=4.326149 main=3.832776 aux=0.493373 imp_cv2=0.1960 load_cv2=5.5652 usage_frac=0.4107 topk_prob_mean=0.2449 ema_alpha_reverse=nan max_logit=13.7570
step:625/1750 train_time:296570ms step_avg:474.51ms
[train step 625] avg_loss=4.104347 main=3.611812 aux=0.492534 imp_cv2=0.1967 load_cv2=5.5586 usage_frac=0.3929 topk_prob_mean=0.2497 ema_alpha_reverse=nan max_logit=13.7570
step:626/1750 train_time:297029ms step_avg:474.49ms
[train step 626] avg_loss=4.079998 main=3.593128 aux=0.486869 imp_cv2=0.2274 load_cv2=5.4617 usage_frac=0.4062 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=13.7570
step:627/1750 train_time:297503ms step_avg:474.49ms
[train step 627] avg_loss=3.592390 main=3.105662 aux=0.486728 imp_cv2=0.3624 load_cv2=5.3348 usage_frac=0.4018 topk_prob_mean=0.3065 ema_alpha_reverse=nan max_logit=13.7570
step:628/1750 train_time:297989ms step_avg:474.51ms
[train step 628] avg_loss=4.109962 main=3.619808 aux=0.490154 imp_cv2=0.2168 load_cv2=5.5115 usage_frac=0.4062 topk_prob_mean=0.2560 ema_alpha_reverse=nan max_logit=13.2997
step:629/1750 train_time:298467ms step_avg:474.51ms
[train step 629] avg_loss=3.866371 main=3.364906 aux=0.501465 imp_cv2=0.2271 load_cv2=5.6533 usage_frac=0.3973 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=12.7744
step:630/1750 train_time:298928ms step_avg:474.49ms
[train step 630] avg_loss=3.751435 main=3.255223 aux=0.496212 imp_cv2=0.2963 load_cv2=5.5311 usage_frac=0.4018 topk_prob_mean=0.2823 ema_alpha_reverse=nan max_logit=13.7570
step:631/1750 train_time:299411ms step_avg:474.50ms
[train step 631] avg_loss=4.414923 main=3.907459 aux=0.507465 imp_cv2=0.2018 load_cv2=5.7398 usage_frac=0.4062 topk_prob_mean=0.2403 ema_alpha_reverse=nan max_logit=13.7570
step:632/1750 train_time:299878ms step_avg:474.49ms
[train step 632] avg_loss=3.902549 main=3.392159 aux=0.510389 imp_cv2=0.1971 load_cv2=5.7804 usage_frac=0.3929 topk_prob_mean=0.2372 ema_alpha_reverse=nan max_logit=13.7570
step:633/1750 train_time:300349ms step_avg:474.48ms
[train step 633] avg_loss=4.093545 main=3.597385 aux=0.496160 imp_cv2=0.2288 load_cv2=5.5841 usage_frac=0.3884 topk_prob_mean=0.2560 ema_alpha_reverse=nan max_logit=13.4197
step:634/1750 train_time:300816ms step_avg:474.47ms
[train step 634] avg_loss=3.873361 main=3.371353 aux=0.502008 imp_cv2=0.2824 load_cv2=5.6135 usage_frac=0.4062 topk_prob_mean=0.2720 ema_alpha_reverse=nan max_logit=13.7570
step:635/1750 train_time:301292ms step_avg:474.48ms
[train step 635] avg_loss=4.207464 main=3.670012 aux=0.537452 imp_cv2=0.2280 load_cv2=6.0663 usage_frac=0.3839 topk_prob_mean=0.2213 ema_alpha_reverse=nan max_logit=13.7570
step:636/1750 train_time:301758ms step_avg:474.46ms
[train step 636] avg_loss=4.157815 main=3.642109 aux=0.515706 imp_cv2=0.3126 load_cv2=5.7422 usage_frac=0.3929 topk_prob_mean=0.2698 ema_alpha_reverse=nan max_logit=13.7570
step:637/1750 train_time:302207ms step_avg:474.42ms
[train step 637] avg_loss=4.229418 main=3.726166 aux=0.503252 imp_cv2=0.3141 load_cv2=5.5910 usage_frac=0.3884 topk_prob_mean=0.2824 ema_alpha_reverse=nan max_logit=13.7570
step:638/1750 train_time:302685ms step_avg:474.43ms
[train step 638] avg_loss=3.891713 main=3.389740 aux=0.501973 imp_cv2=0.3815 load_cv2=5.5161 usage_frac=0.4152 topk_prob_mean=0.3024 ema_alpha_reverse=nan max_logit=13.7570
step:639/1750 train_time:303167ms step_avg:474.44ms
[train step 639] avg_loss=4.069593 main=3.569730 aux=0.499863 imp_cv2=0.2273 load_cv2=5.6295 usage_frac=0.4018 topk_prob_mean=0.2550 ema_alpha_reverse=nan max_logit=13.7570
step:640/1750 train_time:303638ms step_avg:474.43ms
[train step 640] avg_loss=3.859387 main=3.360015 aux=0.499372 imp_cv2=0.2829 load_cv2=5.5770 usage_frac=0.3884 topk_prob_mean=0.2756 ema_alpha_reverse=nan max_logit=13.7570
step:641/1750 train_time:304100ms step_avg:474.42ms
[train step 641] avg_loss=3.987084 main=3.487112 aux=0.499973 imp_cv2=0.2514 load_cv2=5.6128 usage_frac=0.3884 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=13.0294
step:642/1750 train_time:304559ms step_avg:474.39ms
[train step 642] avg_loss=4.323945 main=3.814903 aux=0.509042 imp_cv2=0.2024 load_cv2=5.7607 usage_frac=0.3929 topk_prob_mean=0.2422 ema_alpha_reverse=nan max_logit=13.7570
step:643/1750 train_time:305004ms step_avg:474.34ms
[train step 643] avg_loss=3.778527 main=3.280482 aux=0.498045 imp_cv2=0.3010 load_cv2=5.5390 usage_frac=0.3973 topk_prob_mean=0.2856 ema_alpha_reverse=nan max_logit=13.7570
step:644/1750 train_time:305489ms step_avg:474.36ms
[train step 644] avg_loss=4.168119 main=3.664540 aux=0.503578 imp_cv2=0.2083 load_cv2=5.6817 usage_frac=0.3929 topk_prob_mean=0.2494 ema_alpha_reverse=nan max_logit=13.7570
step:645/1750 train_time:305942ms step_avg:474.33ms
[train step 645] avg_loss=4.196520 main=3.690486 aux=0.506034 imp_cv2=0.2174 load_cv2=5.7053 usage_frac=0.3884 topk_prob_mean=0.2511 ema_alpha_reverse=nan max_logit=13.7570
step:646/1750 train_time:306408ms step_avg:474.32ms
[train step 646] avg_loss=4.047741 main=3.548662 aux=0.499079 imp_cv2=0.2496 load_cv2=5.5828 usage_frac=0.3884 topk_prob_mean=0.2688 ema_alpha_reverse=nan max_logit=13.7570
step:647/1750 train_time:306883ms step_avg:474.32ms
[train step 647] avg_loss=4.264676 main=3.751492 aux=0.513184 imp_cv2=0.1931 load_cv2=5.8094 usage_frac=0.3839 topk_prob_mean=0.2366 ema_alpha_reverse=nan max_logit=13.5617
step:648/1750 train_time:307340ms step_avg:474.29ms
[train step 648] avg_loss=3.702740 main=3.202099 aux=0.500641 imp_cv2=0.2962 load_cv2=5.5578 usage_frac=0.3929 topk_prob_mean=0.2825 ema_alpha_reverse=nan max_logit=13.7570
step:649/1750 train_time:307798ms step_avg:474.27ms
[train step 649] avg_loss=4.865471 main=4.335892 aux=0.529579 imp_cv2=0.1800 load_cv2=6.0185 usage_frac=0.3884 topk_prob_mean=0.2119 ema_alpha_reverse=nan max_logit=12.7744
step:650/1750 train_time:308260ms step_avg:474.25ms
Running validation...
step:650/1750 val_loss:3.594555 train_time:308272ms step_avg:474.26ms
[train step 650] avg_loss=4.119565 main=3.584796 aux=0.534769 imp_cv2=0.1912 load_cv2=6.0699 usage_frac=0.3393 topk_prob_mean=0.1945 ema_alpha_reverse=nan max_logit=10.2125
step:651/1750 train_time:308715ms step_avg:474.22ms
[train step 651] avg_loss=4.171443 main=3.661494 aux=0.509949 imp_cv2=0.1881 load_cv2=5.7673 usage_frac=0.4062 topk_prob_mean=0.2346 ema_alpha_reverse=nan max_logit=12.7744
step:652/1750 train_time:309176ms step_avg:474.20ms
[train step 652] avg_loss=3.808849 main=3.309961 aux=0.498889 imp_cv2=0.2880 load_cv2=5.5413 usage_frac=0.3929 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=12.7744
step:653/1750 train_time:309639ms step_avg:474.18ms
[train step 653] avg_loss=3.912733 main=3.416842 aux=0.495891 imp_cv2=0.2458 load_cv2=5.5484 usage_frac=0.4018 topk_prob_mean=0.2692 ema_alpha_reverse=nan max_logit=13.7570
step:654/1750 train_time:310106ms step_avg:474.17ms
[train step 654] avg_loss=5.068091 main=4.561931 aux=0.506160 imp_cv2=0.1919 load_cv2=5.7202 usage_frac=0.3884 topk_prob_mean=0.2315 ema_alpha_reverse=nan max_logit=12.5255
step:655/1750 train_time:310562ms step_avg:474.14ms
[train step 655] avg_loss=3.922617 main=3.436929 aux=0.485687 imp_cv2=0.2792 load_cv2=5.4006 usage_frac=0.4062 topk_prob_mean=0.2813 ema_alpha_reverse=nan max_logit=12.7744
step:656/1750 train_time:311026ms step_avg:474.12ms
[train step 656] avg_loss=3.912875 main=3.426833 aux=0.486042 imp_cv2=0.3103 load_cv2=5.3747 usage_frac=0.3973 topk_prob_mean=0.2896 ema_alpha_reverse=nan max_logit=12.7744
step:657/1750 train_time:311502ms step_avg:474.13ms
[train step 657] avg_loss=4.565478 main=4.063137 aux=0.502341 imp_cv2=0.1948 load_cv2=5.6726 usage_frac=0.3973 topk_prob_mean=0.2347 ema_alpha_reverse=nan max_logit=12.7744
step:658/1750 train_time:311984ms step_avg:474.14ms
[train step 658] avg_loss=3.813318 main=3.333467 aux=0.479850 imp_cv2=0.2707 load_cv2=5.3310 usage_frac=0.4062 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=12.7744
step:659/1750 train_time:312479ms step_avg:474.17ms
[train step 659] avg_loss=3.806753 main=3.324369 aux=0.482384 imp_cv2=0.2643 load_cv2=5.3691 usage_frac=0.3929 topk_prob_mean=0.2765 ema_alpha_reverse=nan max_logit=12.7744
step:660/1750 train_time:312945ms step_avg:474.16ms
[train step 660] avg_loss=4.009291 main=3.524237 aux=0.485054 imp_cv2=0.2369 load_cv2=5.4279 usage_frac=0.3973 topk_prob_mean=0.2640 ema_alpha_reverse=nan max_logit=12.7744
step:661/1750 train_time:313408ms step_avg:474.14ms
[train step 661] avg_loss=3.895692 main=3.410727 aux=0.484966 imp_cv2=0.2523 load_cv2=5.4103 usage_frac=0.4018 topk_prob_mean=0.2692 ema_alpha_reverse=nan max_logit=12.7744
step:662/1750 train_time:313908ms step_avg:474.18ms
[train step 662] avg_loss=4.184883 main=3.695293 aux=0.489590 imp_cv2=0.2023 load_cv2=5.5170 usage_frac=0.3884 topk_prob_mean=0.2470 ema_alpha_reverse=nan max_logit=12.7744
step:663/1750 train_time:314366ms step_avg:474.16ms
[train step 663] avg_loss=4.099736 main=3.604805 aux=0.494931 imp_cv2=0.1884 load_cv2=5.5928 usage_frac=0.3839 topk_prob_mean=0.2371 ema_alpha_reverse=nan max_logit=12.7744
step:664/1750 train_time:314846ms step_avg:474.17ms
[train step 664] avg_loss=4.136502 main=3.638809 aux=0.497692 imp_cv2=0.1795 load_cv2=5.6379 usage_frac=0.3929 topk_prob_mean=0.2296 ema_alpha_reverse=nan max_logit=12.7744
step:665/1750 train_time:315322ms step_avg:474.17ms
[train step 665] avg_loss=3.950607 main=3.462218 aux=0.488390 imp_cv2=0.2048 load_cv2=5.5007 usage_frac=0.3884 topk_prob_mean=0.2477 ema_alpha_reverse=nan max_logit=12.7744
step:666/1750 train_time:315796ms step_avg:474.17ms
[train step 666] avg_loss=4.149109 main=3.664800 aux=0.484309 imp_cv2=0.2150 load_cv2=5.4433 usage_frac=0.3973 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=12.7744
step:667/1750 train_time:316290ms step_avg:474.20ms
[train step 667] avg_loss=3.986128 main=3.496392 aux=0.489736 imp_cv2=0.1845 load_cv2=5.5384 usage_frac=0.3884 topk_prob_mean=0.2390 ema_alpha_reverse=nan max_logit=13.1461
step:668/1750 train_time:316754ms step_avg:474.18ms
[train step 668] avg_loss=4.514798 main=4.019745 aux=0.495053 imp_cv2=0.1857 load_cv2=5.6018 usage_frac=0.3884 topk_prob_mean=0.2320 ema_alpha_reverse=nan max_logit=13.0823
step:669/1750 train_time:317218ms step_avg:474.17ms
[train step 669] avg_loss=3.894348 main=3.420367 aux=0.473981 imp_cv2=0.2984 load_cv2=5.2337 usage_frac=0.4018 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=12.7744
step:670/1750 train_time:317697ms step_avg:474.17ms
[train step 670] avg_loss=4.444664 main=3.935289 aux=0.509374 imp_cv2=0.1733 load_cv2=5.7803 usage_frac=0.3884 topk_prob_mean=0.2127 ema_alpha_reverse=nan max_logit=12.7744
step:671/1750 train_time:318192ms step_avg:474.20ms
[train step 671] avg_loss=3.837699 main=3.358326 aux=0.479374 imp_cv2=0.2636 load_cv2=5.3374 usage_frac=0.3884 topk_prob_mean=0.2745 ema_alpha_reverse=nan max_logit=13.6120
step:672/1750 train_time:318662ms step_avg:474.20ms
[train step 672] avg_loss=3.737562 main=3.259078 aux=0.478484 imp_cv2=0.2508 load_cv2=5.3403 usage_frac=0.3884 topk_prob_mean=0.2708 ema_alpha_reverse=nan max_logit=13.7570
step:673/1750 train_time:319139ms step_avg:474.20ms
[train step 673] avg_loss=3.891907 main=3.408355 aux=0.483553 imp_cv2=0.2296 load_cv2=5.4177 usage_frac=0.3929 topk_prob_mean=0.2611 ema_alpha_reverse=nan max_logit=12.7744
step:674/1750 train_time:319599ms step_avg:474.18ms
[train step 674] avg_loss=4.267001 main=3.774800 aux=0.492201 imp_cv2=0.2146 load_cv2=5.5406 usage_frac=0.3929 topk_prob_mean=0.2514 ema_alpha_reverse=nan max_logit=12.3549
step:675/1750 train_time:320098ms step_avg:474.22ms
[train step 675] avg_loss=3.961448 main=3.479329 aux=0.482118 imp_cv2=0.2537 load_cv2=5.3771 usage_frac=0.3973 topk_prob_mean=0.2720 ema_alpha_reverse=nan max_logit=12.7042
step:676/1750 train_time:320599ms step_avg:474.26ms
[train step 676] avg_loss=4.952687 main=4.450731 aux=0.501956 imp_cv2=0.1889 load_cv2=5.6782 usage_frac=0.3929 topk_prob_mean=0.2306 ema_alpha_reverse=nan max_logit=12.7744
step:677/1750 train_time:321070ms step_avg:474.25ms
[train step 677] avg_loss=4.165048 main=3.668050 aux=0.496998 imp_cv2=0.1934 load_cv2=5.6141 usage_frac=0.3973 topk_prob_mean=0.2373 ema_alpha_reverse=nan max_logit=12.7744
step:678/1750 train_time:321536ms step_avg:474.24ms
[train step 678] avg_loss=4.070382 main=3.570311 aux=0.500071 imp_cv2=0.1831 load_cv2=5.6715 usage_frac=0.3839 topk_prob_mean=0.2279 ema_alpha_reverse=nan max_logit=12.8491
step:679/1750 train_time:322017ms step_avg:474.25ms
[train step 679] avg_loss=3.953689 main=3.457981 aux=0.495708 imp_cv2=0.1877 load_cv2=5.6105 usage_frac=0.3884 topk_prob_mean=0.2374 ema_alpha_reverse=nan max_logit=11.7917
step:680/1750 train_time:322483ms step_avg:474.24ms
[train step 680] avg_loss=3.903076 main=3.421638 aux=0.481437 imp_cv2=0.2783 load_cv2=5.3520 usage_frac=0.3839 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=11.7917
step:681/1750 train_time:322951ms step_avg:474.23ms
[train step 681] avg_loss=4.562800 main=4.064573 aux=0.498227 imp_cv2=0.2079 load_cv2=5.6217 usage_frac=0.3884 topk_prob_mean=0.2375 ema_alpha_reverse=nan max_logit=11.7917
step:682/1750 train_time:323430ms step_avg:474.24ms
[train step 682] avg_loss=4.397742 main=3.901342 aux=0.496400 imp_cv2=0.1851 load_cv2=5.6178 usage_frac=0.3839 topk_prob_mean=0.2345 ema_alpha_reverse=nan max_logit=11.7917
step:683/1750 train_time:323900ms step_avg:474.23ms
[train step 683] avg_loss=4.557831 main=4.049431 aux=0.508400 imp_cv2=0.1734 load_cv2=5.7705 usage_frac=0.3884 topk_prob_mean=0.2165 ema_alpha_reverse=nan max_logit=11.7917
step:684/1750 train_time:324359ms step_avg:474.21ms
[train step 684] avg_loss=3.712791 main=3.237032 aux=0.475759 imp_cv2=0.2764 load_cv2=5.2826 usage_frac=0.3884 topk_prob_mean=0.2827 ema_alpha_reverse=nan max_logit=11.7917
step:685/1750 train_time:324839ms step_avg:474.22ms
[train step 685] avg_loss=4.276248 main=3.780119 aux=0.496128 imp_cv2=0.1776 load_cv2=5.6290 usage_frac=0.3795 topk_prob_mean=0.2278 ema_alpha_reverse=nan max_logit=11.7917
step:686/1750 train_time:325296ms step_avg:474.19ms
[train step 686] avg_loss=3.981416 main=3.498189 aux=0.483226 imp_cv2=0.2211 load_cv2=5.4310 usage_frac=0.3973 topk_prob_mean=0.2569 ema_alpha_reverse=nan max_logit=11.7917
step:687/1750 train_time:325767ms step_avg:474.19ms
[train step 687] avg_loss=4.116250 main=3.627961 aux=0.488289 imp_cv2=0.2038 load_cv2=5.5100 usage_frac=0.3795 topk_prob_mean=0.2459 ema_alpha_reverse=nan max_logit=11.7917
step:688/1750 train_time:326228ms step_avg:474.17ms
[train step 688] avg_loss=4.453227 main=3.929949 aux=0.523278 imp_cv2=0.1672 load_cv2=5.9621 usage_frac=0.3795 topk_prob_mean=0.1981 ema_alpha_reverse=nan max_logit=12.4288
step:689/1750 train_time:326693ms step_avg:474.15ms
[train step 689] avg_loss=3.821892 main=3.337361 aux=0.484531 imp_cv2=0.2323 load_cv2=5.4369 usage_frac=0.3973 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=12.7744
step:690/1750 train_time:327158ms step_avg:474.14ms
[train step 690] avg_loss=3.793093 main=3.300290 aux=0.492803 imp_cv2=0.1940 load_cv2=5.5684 usage_frac=0.3839 topk_prob_mean=0.2392 ema_alpha_reverse=nan max_logit=12.1796
step:691/1750 train_time:327792ms step_avg:474.37ms
[train step 691] avg_loss=3.961862 main=3.481059 aux=0.480803 imp_cv2=0.2223 load_cv2=5.4005 usage_frac=0.3839 topk_prob_mean=0.2558 ema_alpha_reverse=nan max_logit=12.5816
step:692/1750 train_time:328259ms step_avg:474.36ms
[train step 692] avg_loss=3.529924 main=3.047455 aux=0.482469 imp_cv2=0.2946 load_cv2=5.3448 usage_frac=0.3884 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=12.7343
step:693/1750 train_time:328728ms step_avg:474.36ms
[train step 693] avg_loss=4.116217 main=3.617059 aux=0.499159 imp_cv2=0.1799 load_cv2=5.6609 usage_frac=0.3884 topk_prob_mean=0.2252 ema_alpha_reverse=nan max_logit=12.7744
step:694/1750 train_time:329181ms step_avg:474.32ms
[train step 694] avg_loss=3.962710 main=3.479739 aux=0.482971 imp_cv2=0.2437 load_cv2=5.4017 usage_frac=0.3929 topk_prob_mean=0.2669 ema_alpha_reverse=nan max_logit=12.7744
step:695/1750 train_time:329654ms step_avg:474.32ms
[train step 695] avg_loss=4.282129 main=3.536004 aux=0.746126 imp_cv2=3.6327 load_cv2=5.0771 usage_frac=0.4420 topk_prob_mean=0.7609 ema_alpha_reverse=nan max_logit=13.4623
step:696/1750 train_time:330166ms step_avg:474.38ms
[train step 696] avg_loss=3.837857 main=3.372348 aux=0.465509 imp_cv2=1.0662 load_cv2=4.4088 usage_frac=0.4821 topk_prob_mean=0.4356 ema_alpha_reverse=nan max_logit=13.3648
step:697/1750 train_time:330706ms step_avg:474.47ms
[train step 697] avg_loss=3.982580 main=3.470802 aux=0.511778 imp_cv2=0.5450 load_cv2=5.4535 usage_frac=0.4554 topk_prob_mean=0.3033 ema_alpha_reverse=nan max_logit=13.2404
step:698/1750 train_time:331194ms step_avg:474.49ms
[train step 698] avg_loss=4.224752 main=3.729263 aux=0.495488 imp_cv2=0.4399 load_cv2=5.3622 usage_frac=0.4375 topk_prob_mean=0.2931 ema_alpha_reverse=nan max_logit=13.0962
step:699/1750 train_time:331682ms step_avg:474.51ms
[train step 699] avg_loss=4.137794 main=3.630312 aux=0.507482 imp_cv2=0.3513 load_cv2=5.5817 usage_frac=0.4375 topk_prob_mean=0.2604 ema_alpha_reverse=nan max_logit=12.8845
step:700/1750 train_time:332359ms step_avg:474.80ms
Running validation...
step:700/1750 val_loss:3.632257 train_time:332371ms step_avg:474.82ms
[train step 700] avg_loss=3.892335 main=3.409881 aux=0.482454 imp_cv2=0.3853 load_cv2=5.2429 usage_frac=0.4375 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=12.7744
step:701/1750 train_time:332837ms step_avg:474.80ms
[train step 701] avg_loss=3.971350 main=3.487206 aux=0.484144 imp_cv2=0.4015 load_cv2=5.2540 usage_frac=0.4375 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=12.7744
step:702/1750 train_time:333323ms step_avg:474.82ms
[train step 702] avg_loss=3.911039 main=3.431220 aux=0.479819 imp_cv2=0.4527 load_cv2=5.1568 usage_frac=0.4241 topk_prob_mean=0.3114 ema_alpha_reverse=nan max_logit=12.7744
step:703/1750 train_time:333805ms step_avg:474.83ms
[train step 703] avg_loss=4.075330 main=3.591483 aux=0.483847 imp_cv2=0.3980 load_cv2=5.2482 usage_frac=0.4286 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=12.7744
step:704/1750 train_time:334285ms step_avg:474.84ms
[train step 704] avg_loss=4.017263 main=3.534126 aux=0.483137 imp_cv2=0.4068 load_cv2=5.2316 usage_frac=0.4330 topk_prob_mean=0.3012 ema_alpha_reverse=nan max_logit=12.7744
step:705/1750 train_time:334937ms step_avg:475.09ms
[train step 705] avg_loss=3.779726 main=3.300550 aux=0.479176 imp_cv2=0.4614 load_cv2=5.1348 usage_frac=0.4330 topk_prob_mean=0.3185 ema_alpha_reverse=nan max_logit=12.7744
step:706/1750 train_time:335424ms step_avg:475.11ms
[train step 706] avg_loss=3.839277 main=3.361256 aux=0.478022 imp_cv2=0.4596 load_cv2=5.1185 usage_frac=0.4375 topk_prob_mean=0.3183 ema_alpha_reverse=nan max_logit=12.7744
step:707/1750 train_time:335898ms step_avg:475.10ms
[train step 707] avg_loss=3.898195 main=3.416714 aux=0.481481 imp_cv2=0.4009 load_cv2=5.2102 usage_frac=0.4330 topk_prob_mean=0.3003 ema_alpha_reverse=nan max_logit=12.7744
step:708/1750 train_time:336385ms step_avg:475.12ms
[train step 708] avg_loss=4.165150 main=3.677154 aux=0.487997 imp_cv2=0.3474 load_cv2=5.3427 usage_frac=0.4330 topk_prob_mean=0.2807 ema_alpha_reverse=nan max_logit=12.7744
step:709/1750 train_time:336865ms step_avg:475.13ms
[train step 709] avg_loss=3.926089 main=3.460447 aux=0.465642 imp_cv2=0.3581 load_cv2=5.0535 usage_frac=0.4375 topk_prob_mean=0.3034 ema_alpha_reverse=nan max_logit=12.7744
step:710/1750 train_time:337351ms step_avg:475.14ms
[train step 710] avg_loss=4.039932 main=3.579820 aux=0.460112 imp_cv2=0.1956 load_cv2=5.1201 usage_frac=0.4464 topk_prob_mean=0.2727 ema_alpha_reverse=nan max_logit=12.7744
step:711/1750 train_time:338039ms step_avg:475.44ms
[train step 711] avg_loss=3.888676 main=3.429353 aux=0.459324 imp_cv2=0.1840 load_cv2=5.1214 usage_frac=0.4420 topk_prob_mean=0.2697 ema_alpha_reverse=nan max_logit=12.1917
step:712/1750 train_time:338530ms step_avg:475.46ms
[train step 712] avg_loss=4.538426 main=4.029631 aux=0.508795 imp_cv2=0.0576 load_cv2=5.8464 usage_frac=0.4286 topk_prob_mean=0.1884 ema_alpha_reverse=nan max_logit=12.1679
step:713/1750 train_time:339035ms step_avg:475.51ms
[train step 713] avg_loss=3.697296 main=3.246132 aux=0.451164 imp_cv2=0.2353 load_cv2=4.9784 usage_frac=0.4464 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=12.7744
step:714/1750 train_time:339527ms step_avg:475.53ms
[train step 714] avg_loss=3.684412 main=3.229577 aux=0.454835 imp_cv2=0.2934 load_cv2=4.9701 usage_frac=0.4509 topk_prob_mean=0.3021 ema_alpha_reverse=nan max_logit=12.7744
step:715/1750 train_time:340016ms step_avg:475.55ms
[train step 715] avg_loss=4.081000 main=3.629467 aux=0.451533 imp_cv2=0.1668 load_cv2=5.0534 usage_frac=0.4420 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=12.4803
step:716/1750 train_time:340486ms step_avg:475.54ms
[train step 716] avg_loss=3.644109 main=3.181273 aux=0.462835 imp_cv2=0.0844 load_cv2=5.2758 usage_frac=0.4464 topk_prob_mean=0.2413 ema_alpha_reverse=nan max_logit=11.7917
step:717/1750 train_time:340984ms step_avg:475.57ms
[train step 717] avg_loss=4.728873 main=4.250115 aux=0.478758 imp_cv2=0.0596 load_cv2=5.4908 usage_frac=0.4464 topk_prob_mean=0.2251 ema_alpha_reverse=nan max_logit=11.7917
step:718/1750 train_time:341464ms step_avg:475.58ms
[train step 718] avg_loss=3.959752 main=3.491899 aux=0.467853 imp_cv2=0.0773 load_cv2=5.3475 usage_frac=0.4509 topk_prob_mean=0.2408 ema_alpha_reverse=nan max_logit=11.7917
step:719/1750 train_time:341948ms step_avg:475.59ms
[train step 719] avg_loss=4.027034 main=3.563303 aux=0.463731 imp_cv2=0.1046 load_cv2=5.2716 usage_frac=0.4464 topk_prob_mean=0.2504 ema_alpha_reverse=nan max_logit=11.7917
step:720/1750 train_time:342435ms step_avg:475.60ms
[train step 720] avg_loss=3.870126 main=3.410319 aux=0.459807 imp_cv2=0.1070 load_cv2=5.2156 usage_frac=0.4509 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:721/1750 train_time:342911ms step_avg:475.60ms
[train step 721] avg_loss=3.814137 main=3.343841 aux=0.470296 imp_cv2=0.0821 load_cv2=5.3660 usage_frac=0.4464 topk_prob_mean=0.2392 ema_alpha_reverse=nan max_logit=11.7917
step:722/1750 train_time:343405ms step_avg:475.63ms
[train step 722] avg_loss=3.852348 main=3.396374 aux=0.455974 imp_cv2=0.1394 load_cv2=5.1466 usage_frac=0.4509 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=11.7917
step:723/1750 train_time:343890ms step_avg:475.64ms
[train step 723] avg_loss=4.305369 main=3.797985 aux=0.507384 imp_cv2=0.0492 load_cv2=5.8490 usage_frac=0.4330 topk_prob_mean=0.1955 ema_alpha_reverse=nan max_logit=11.7917
step:724/1750 train_time:344371ms step_avg:475.65ms
[train step 724] avg_loss=3.781169 main=3.321455 aux=0.459714 imp_cv2=0.1678 load_cv2=5.1619 usage_frac=0.4420 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:725/1750 train_time:344845ms step_avg:475.65ms
[train step 725] avg_loss=4.226521 main=3.754357 aux=0.472163 imp_cv2=0.0709 load_cv2=5.4086 usage_frac=0.4286 topk_prob_mean=0.2337 ema_alpha_reverse=nan max_logit=12.7744
step:726/1750 train_time:345340ms step_avg:475.68ms
[train step 726] avg_loss=4.146371 main=3.680490 aux=0.465880 imp_cv2=0.1003 load_cv2=5.2928 usage_frac=0.4420 topk_prob_mean=0.2499 ema_alpha_reverse=nan max_logit=11.7917
step:727/1750 train_time:345819ms step_avg:475.68ms
[train step 727] avg_loss=3.934031 main=3.474082 aux=0.459948 imp_cv2=0.1404 load_cv2=5.1867 usage_frac=0.4375 topk_prob_mean=0.2668 ema_alpha_reverse=nan max_logit=12.7301
step:728/1750 train_time:346288ms step_avg:475.67ms
[train step 728] avg_loss=4.502906 main=3.980478 aux=0.522428 imp_cv2=0.0693 load_cv2=6.0166 usage_frac=0.3705 topk_prob_mean=0.1718 ema_alpha_reverse=nan max_logit=8.8438
step:729/1750 train_time:346759ms step_avg:475.66ms
[train step 729] avg_loss=4.209868 main=3.734926 aux=0.474943 imp_cv2=0.0664 load_cv2=5.4452 usage_frac=0.4241 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=11.7917
step:730/1750 train_time:347250ms step_avg:475.68ms
[train step 730] avg_loss=3.865680 main=3.400836 aux=0.464844 imp_cv2=0.0944 load_cv2=5.2947 usage_frac=0.4375 topk_prob_mean=0.2486 ema_alpha_reverse=nan max_logit=11.7917
step:731/1750 train_time:347716ms step_avg:475.67ms
[train step 731] avg_loss=3.945704 main=3.478413 aux=0.467291 imp_cv2=0.1418 load_cv2=5.2752 usage_frac=0.4330 topk_prob_mean=0.2624 ema_alpha_reverse=nan max_logit=11.7917
step:732/1750 train_time:348193ms step_avg:475.67ms
[train step 732] avg_loss=4.279737 main=3.803765 aux=0.475971 imp_cv2=0.0849 load_cv2=5.4346 usage_frac=0.4375 topk_prob_mean=0.2401 ema_alpha_reverse=nan max_logit=12.7744
step:733/1750 train_time:348678ms step_avg:475.69ms
[train step 733] avg_loss=4.073047 main=3.598385 aux=0.474662 imp_cv2=0.0860 load_cv2=5.4225 usage_frac=0.4286 topk_prob_mean=0.2368 ema_alpha_reverse=nan max_logit=11.7917
step:734/1750 train_time:349152ms step_avg:475.68ms
[train step 734] avg_loss=3.773152 main=3.312614 aux=0.460539 imp_cv2=0.1924 load_cv2=5.1454 usage_frac=0.4375 topk_prob_mean=0.2804 ema_alpha_reverse=nan max_logit=12.7744
step:735/1750 train_time:349622ms step_avg:475.68ms
[train step 735] avg_loss=4.287774 main=3.809294 aux=0.478480 imp_cv2=0.0736 load_cv2=5.4824 usage_frac=0.4196 topk_prob_mean=0.2332 ema_alpha_reverse=nan max_logit=12.5163
step:736/1750 train_time:350098ms step_avg:475.68ms
[train step 736] avg_loss=4.305035 main=3.824189 aux=0.480845 imp_cv2=0.0849 load_cv2=5.4988 usage_frac=0.4330 topk_prob_mean=0.2358 ema_alpha_reverse=nan max_logit=11.7917
step:737/1750 train_time:350792ms step_avg:475.97ms
[train step 737] avg_loss=3.821586 main=3.365697 aux=0.455889 imp_cv2=0.1874 load_cv2=5.0943 usage_frac=0.4241 topk_prob_mean=0.2827 ema_alpha_reverse=nan max_logit=12.7744
step:738/1750 train_time:351269ms step_avg:475.97ms
[train step 738] avg_loss=4.136326 main=3.674102 aux=0.462224 imp_cv2=0.1251 load_cv2=5.2349 usage_frac=0.4330 topk_prob_mean=0.2595 ema_alpha_reverse=nan max_logit=12.7685
step:739/1750 train_time:351742ms step_avg:475.97ms
[train step 739] avg_loss=4.269665 main=3.793527 aux=0.476138 imp_cv2=0.0992 load_cv2=5.4232 usage_frac=0.4152 topk_prob_mean=0.2419 ema_alpha_reverse=nan max_logit=12.7214
step:740/1750 train_time:352205ms step_avg:475.95ms
[train step 740] avg_loss=4.308035 main=3.836746 aux=0.471288 imp_cv2=0.0745 load_cv2=5.3918 usage_frac=0.4196 topk_prob_mean=0.2359 ema_alpha_reverse=nan max_logit=11.7917
step:741/1750 train_time:352683ms step_avg:475.96ms
[train step 741] avg_loss=4.240007 main=3.765764 aux=0.474243 imp_cv2=0.0843 load_cv2=5.4153 usage_frac=0.4241 topk_prob_mean=0.2384 ema_alpha_reverse=nan max_logit=12.6022
step:742/1750 train_time:353143ms step_avg:475.93ms
[train step 742] avg_loss=4.159027 main=3.683113 aux=0.475914 imp_cv2=0.0649 load_cv2=5.4586 usage_frac=0.4196 topk_prob_mean=0.2290 ema_alpha_reverse=nan max_logit=11.7917
step:743/1750 train_time:353606ms step_avg:475.92ms
[train step 743] avg_loss=3.901061 main=3.440976 aux=0.460085 imp_cv2=0.1309 load_cv2=5.2025 usage_frac=0.4420 topk_prob_mean=0.2598 ema_alpha_reverse=nan max_logit=11.7917
step:744/1750 train_time:354098ms step_avg:475.94ms
[train step 744] avg_loss=4.020773 main=3.557052 aux=0.463721 imp_cv2=0.1141 load_cv2=5.2633 usage_frac=0.4241 topk_prob_mean=0.2540 ema_alpha_reverse=nan max_logit=12.7220
step:745/1750 train_time:354569ms step_avg:475.93ms
[train step 745] avg_loss=4.362647 main=3.898034 aux=0.464613 imp_cv2=0.1155 load_cv2=5.2810 usage_frac=0.4196 topk_prob_mean=0.2534 ema_alpha_reverse=nan max_logit=12.7744
step:746/1750 train_time:355039ms step_avg:475.92ms
[train step 746] avg_loss=3.920465 main=3.458632 aux=0.461833 imp_cv2=0.1673 load_cv2=5.1862 usage_frac=0.4196 topk_prob_mean=0.2721 ema_alpha_reverse=nan max_logit=11.7917
step:747/1750 train_time:355515ms step_avg:475.92ms
[train step 747] avg_loss=3.834792 main=3.371634 aux=0.463159 imp_cv2=0.1164 load_cv2=5.2461 usage_frac=0.4107 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:748/1750 train_time:355995ms step_avg:475.93ms
[train step 748] avg_loss=4.123475 main=3.660374 aux=0.463100 imp_cv2=0.1080 load_cv2=5.2602 usage_frac=0.4286 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:749/1750 train_time:356460ms step_avg:475.91ms
[train step 749] avg_loss=4.439442 main=3.923422 aux=0.516020 imp_cv2=0.0632 load_cv2=5.9357 usage_frac=0.3973 topk_prob_mean=0.1863 ema_alpha_reverse=nan max_logit=10.8091
step:750/1750 train_time:356935ms step_avg:475.91ms
Running validation...
step:750/1750 val_loss:3.509706 train_time:356948ms step_avg:475.93ms
[train step 750] avg_loss=4.460524 main=3.969259 aux=0.491265 imp_cv2=0.0463 load_cv2=5.6663 usage_frac=0.4107 topk_prob_mean=0.2032 ema_alpha_reverse=nan max_logit=12.7744
step:751/1750 train_time:357399ms step_avg:475.90ms
[train step 751] avg_loss=4.342496 main=3.853524 aux=0.488972 imp_cv2=0.0622 load_cv2=5.6292 usage_frac=0.4062 topk_prob_mean=0.2120 ema_alpha_reverse=nan max_logit=12.7744
step:752/1750 train_time:357870ms step_avg:475.89ms
[train step 752] avg_loss=3.996885 main=3.514333 aux=0.482552 imp_cv2=0.0723 load_cv2=5.5450 usage_frac=0.4062 topk_prob_mean=0.2205 ema_alpha_reverse=nan max_logit=11.7917
step:753/1750 train_time:358329ms step_avg:475.87ms
[train step 753] avg_loss=3.992861 main=3.529109 aux=0.463752 imp_cv2=0.1133 load_cv2=5.2692 usage_frac=0.4062 topk_prob_mean=0.2500 ema_alpha_reverse=nan max_logit=12.7744
step:754/1750 train_time:358803ms step_avg:475.87ms
[train step 754] avg_loss=4.199263 main=3.733145 aux=0.466118 imp_cv2=0.1126 load_cv2=5.2992 usage_frac=0.4196 topk_prob_mean=0.2470 ema_alpha_reverse=nan max_logit=12.0991
step:755/1750 train_time:359264ms step_avg:475.85ms
[train step 755] avg_loss=4.760128 main=4.214924 aux=0.545203 imp_cv2=0.0870 load_cv2=6.2563 usage_frac=0.3571 topk_prob_mean=0.1838 ema_alpha_reverse=nan max_logit=8.8438
step:756/1750 train_time:359753ms step_avg:475.86ms
[train step 756] avg_loss=4.401522 main=3.923409 aux=0.478113 imp_cv2=0.0767 load_cv2=5.4846 usage_frac=0.4196 topk_prob_mean=0.2270 ema_alpha_reverse=nan max_logit=12.7744
step:757/1750 train_time:360223ms step_avg:475.86ms
[train step 757] avg_loss=4.225244 main=3.743190 aux=0.482054 imp_cv2=0.0662 load_cv2=5.5391 usage_frac=0.4152 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=11.7917
step:758/1750 train_time:360699ms step_avg:475.86ms
[train step 758] avg_loss=3.418224 main=2.950390 aux=0.467834 imp_cv2=0.2582 load_cv2=5.1801 usage_frac=0.4107 topk_prob_mean=0.2926 ema_alpha_reverse=nan max_logit=12.7744
step:759/1750 train_time:361177ms step_avg:475.86ms
[train step 759] avg_loss=3.702850 main=3.235332 aux=0.467519 imp_cv2=0.1566 load_cv2=5.2716 usage_frac=0.4241 topk_prob_mean=0.2658 ema_alpha_reverse=nan max_logit=12.6038
step:760/1750 train_time:361658ms step_avg:475.87ms
[train step 760] avg_loss=4.254851 main=3.774941 aux=0.479910 imp_cv2=0.0771 load_cv2=5.4982 usage_frac=0.4196 topk_prob_mean=0.2303 ema_alpha_reverse=nan max_logit=11.7917
step:761/1750 train_time:362129ms step_avg:475.86ms
[train step 761] avg_loss=4.010982 main=3.540150 aux=0.470833 imp_cv2=0.1312 load_cv2=5.3355 usage_frac=0.4152 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=12.7744
step:762/1750 train_time:362603ms step_avg:475.86ms
[train step 762] avg_loss=3.901060 main=3.424432 aux=0.476628 imp_cv2=0.1035 load_cv2=5.4312 usage_frac=0.4241 topk_prob_mean=0.2441 ema_alpha_reverse=nan max_logit=12.7428
step:763/1750 train_time:363064ms step_avg:475.84ms
[train step 763] avg_loss=3.825163 main=3.356287 aux=0.468876 imp_cv2=0.1690 load_cv2=5.2655 usage_frac=0.4196 topk_prob_mean=0.2687 ema_alpha_reverse=nan max_logit=12.7744
step:764/1750 train_time:363531ms step_avg:475.83ms
[train step 764] avg_loss=4.337769 main=3.859320 aux=0.478449 imp_cv2=0.0737 load_cv2=5.4841 usage_frac=0.4196 topk_prob_mean=0.2280 ema_alpha_reverse=nan max_logit=12.7744
step:765/1750 train_time:363998ms step_avg:475.81ms
[train step 765] avg_loss=3.764525 main=3.296727 aux=0.467797 imp_cv2=0.1823 load_cv2=5.2457 usage_frac=0.4107 topk_prob_mean=0.2739 ema_alpha_reverse=nan max_logit=12.4737
step:766/1750 train_time:364470ms step_avg:475.81ms
[train step 766] avg_loss=4.087681 main=3.609447 aux=0.478234 imp_cv2=0.0742 load_cv2=5.4771 usage_frac=0.4152 topk_prob_mean=0.2317 ema_alpha_reverse=nan max_logit=12.7744
step:767/1750 train_time:364941ms step_avg:475.80ms
[train step 767] avg_loss=3.731228 main=3.243887 aux=0.487341 imp_cv2=0.0479 load_cv2=5.6186 usage_frac=0.4107 topk_prob_mean=0.2105 ema_alpha_reverse=nan max_logit=11.7917
step:768/1750 train_time:365400ms step_avg:475.78ms
[train step 768] avg_loss=3.684308 main=3.212198 aux=0.472110 imp_cv2=0.1005 load_cv2=5.3766 usage_frac=0.4062 topk_prob_mean=0.2471 ema_alpha_reverse=nan max_logit=11.7007
step:769/1750 train_time:365857ms step_avg:475.76ms
[train step 769] avg_loss=3.664004 main=3.196353 aux=0.467652 imp_cv2=0.1291 load_cv2=5.2957 usage_frac=0.4062 topk_prob_mean=0.2557 ema_alpha_reverse=nan max_logit=10.8091
step:770/1750 train_time:366329ms step_avg:475.75ms
[train step 770] avg_loss=4.135756 main=3.645083 aux=0.490673 imp_cv2=0.0409 load_cv2=5.6626 usage_frac=0.4018 topk_prob_mean=0.2058 ema_alpha_reverse=nan max_logit=10.8091
step:771/1750 train_time:366809ms step_avg:475.76ms
[train step 771] avg_loss=3.754235 main=3.283746 aux=0.470489 imp_cv2=0.1082 load_cv2=5.3525 usage_frac=0.4107 topk_prob_mean=0.2483 ema_alpha_reverse=nan max_logit=11.7917
step:772/1750 train_time:367282ms step_avg:475.75ms
[train step 772] avg_loss=3.722900 main=3.257656 aux=0.465244 imp_cv2=0.1526 load_cv2=5.2397 usage_frac=0.4062 topk_prob_mean=0.2660 ema_alpha_reverse=nan max_logit=11.7917
step:773/1750 train_time:367763ms step_avg:475.76ms
[train step 773] avg_loss=3.918346 main=3.446508 aux=0.471837 imp_cv2=0.1475 load_cv2=5.3270 usage_frac=0.4107 topk_prob_mean=0.2575 ema_alpha_reverse=nan max_logit=11.7917
step:774/1750 train_time:368242ms step_avg:475.76ms
[train step 774] avg_loss=3.595455 main=3.106863 aux=0.488592 imp_cv2=0.0698 load_cv2=5.5887 usage_frac=0.4062 topk_prob_mean=0.2192 ema_alpha_reverse=nan max_logit=11.2933
step:775/1750 train_time:368705ms step_avg:475.75ms
[train step 775] avg_loss=4.035067 main=3.557165 aux=0.477902 imp_cv2=0.1131 load_cv2=5.4345 usage_frac=0.4196 topk_prob_mean=0.2437 ema_alpha_reverse=nan max_logit=10.8091
step:776/1750 train_time:369169ms step_avg:475.73ms
[train step 776] avg_loss=3.950590 main=3.488896 aux=0.461694 imp_cv2=0.1743 load_cv2=5.1812 usage_frac=0.4152 topk_prob_mean=0.2698 ema_alpha_reverse=nan max_logit=11.7917
step:777/1750 train_time:369642ms step_avg:475.73ms
[train step 777] avg_loss=3.731892 main=3.259838 aux=0.472054 imp_cv2=0.1014 load_cv2=5.3808 usage_frac=0.4152 topk_prob_mean=0.2430 ema_alpha_reverse=nan max_logit=11.7917
step:778/1750 train_time:370103ms step_avg:475.71ms
[train step 778] avg_loss=3.749427 main=3.284890 aux=0.464537 imp_cv2=0.1425 load_cv2=5.2453 usage_frac=0.4152 topk_prob_mean=0.2619 ema_alpha_reverse=nan max_logit=11.4647
step:779/1750 train_time:370574ms step_avg:475.70ms
[train step 779] avg_loss=4.462936 main=3.983712 aux=0.479224 imp_cv2=0.0617 load_cv2=5.4929 usage_frac=0.4152 topk_prob_mean=0.2186 ema_alpha_reverse=nan max_logit=10.8091
step:780/1750 train_time:371049ms step_avg:475.70ms
[train step 780] avg_loss=3.682251 main=3.220081 aux=0.462170 imp_cv2=0.1142 load_cv2=5.2403 usage_frac=0.4107 topk_prob_mean=0.2504 ema_alpha_reverse=nan max_logit=11.4502
step:781/1750 train_time:371524ms step_avg:475.70ms
[train step 781] avg_loss=3.893151 main=3.432679 aux=0.460472 imp_cv2=0.1439 load_cv2=5.1939 usage_frac=0.4152 topk_prob_mean=0.2622 ema_alpha_reverse=nan max_logit=11.0782
step:782/1750 train_time:371996ms step_avg:475.70ms
[train step 782] avg_loss=3.810587 main=3.345107 aux=0.465480 imp_cv2=0.1053 load_cv2=5.2951 usage_frac=0.4196 topk_prob_mean=0.2473 ema_alpha_reverse=nan max_logit=10.8091
step:783/1750 train_time:372475ms step_avg:475.70ms
[train step 783] avg_loss=3.812124 main=3.345264 aux=0.466860 imp_cv2=0.1063 load_cv2=5.3115 usage_frac=0.4152 topk_prob_mean=0.2463 ema_alpha_reverse=nan max_logit=10.8091
step:784/1750 train_time:372944ms step_avg:475.69ms
[train step 784] avg_loss=4.071793 main=3.601064 aux=0.470729 imp_cv2=0.0757 load_cv2=5.3874 usage_frac=0.4152 topk_prob_mean=0.2346 ema_alpha_reverse=nan max_logit=10.8091
step:785/1750 train_time:373430ms step_avg:475.71ms
[train step 785] avg_loss=4.120838 main=3.651149 aux=0.469689 imp_cv2=0.0651 load_cv2=5.3836 usage_frac=0.4241 topk_prob_mean=0.2282 ema_alpha_reverse=nan max_logit=10.8091
step:786/1750 train_time:373912ms step_avg:475.71ms
[train step 786] avg_loss=3.566067 main=3.105645 aux=0.460422 imp_cv2=0.2039 load_cv2=5.1358 usage_frac=0.4152 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=10.8091
step:787/1750 train_time:374374ms step_avg:475.70ms
[train step 787] avg_loss=4.026848 main=3.545329 aux=0.481520 imp_cv2=0.0659 load_cv2=5.5375 usage_frac=0.4152 topk_prob_mean=0.2230 ema_alpha_reverse=nan max_logit=10.8091
step:788/1750 train_time:374829ms step_avg:475.67ms
[train step 788] avg_loss=4.184060 main=3.687366 aux=0.496694 imp_cv2=0.0510 load_cv2=5.7202 usage_frac=0.4152 topk_prob_mean=0.1929 ema_alpha_reverse=nan max_logit=10.8091
step:789/1750 train_time:375294ms step_avg:475.66ms
[train step 789] avg_loss=4.741375 main=4.226763 aux=0.514611 imp_cv2=0.0535 load_cv2=5.9303 usage_frac=0.4018 topk_prob_mean=0.1771 ema_alpha_reverse=nan max_logit=10.8091
step:790/1750 train_time:375753ms step_avg:475.64ms
[train step 790] avg_loss=3.755986 main=3.295982 aux=0.460003 imp_cv2=0.1554 load_cv2=5.1781 usage_frac=0.4107 topk_prob_mean=0.2638 ema_alpha_reverse=nan max_logit=10.8091
step:791/1750 train_time:376241ms step_avg:475.65ms
[train step 791] avg_loss=4.038274 main=3.569387 aux=0.468888 imp_cv2=0.0675 load_cv2=5.3631 usage_frac=0.4107 topk_prob_mean=0.2294 ema_alpha_reverse=nan max_logit=10.8091
step:792/1750 train_time:376711ms step_avg:475.65ms
[train step 792] avg_loss=3.850593 main=3.384875 aux=0.465717 imp_cv2=0.1003 load_cv2=5.3043 usage_frac=0.4152 topk_prob_mean=0.2454 ema_alpha_reverse=nan max_logit=10.8091
step:793/1750 train_time:377179ms step_avg:475.64ms
[train step 793] avg_loss=3.756056 main=3.293953 aux=0.462103 imp_cv2=0.1138 load_cv2=5.2471 usage_frac=0.4152 topk_prob_mean=0.2497 ema_alpha_reverse=nan max_logit=10.8091
step:794/1750 train_time:377657ms step_avg:475.64ms
[train step 794] avg_loss=4.725884 main=4.217103 aux=0.508781 imp_cv2=0.0529 load_cv2=5.8553 usage_frac=0.4062 topk_prob_mean=0.1848 ema_alpha_reverse=nan max_logit=10.8091
step:795/1750 train_time:378125ms step_avg:475.63ms
[train step 795] avg_loss=4.138464 main=3.669232 aux=0.469231 imp_cv2=0.0757 load_cv2=5.3753 usage_frac=0.4196 topk_prob_mean=0.2339 ema_alpha_reverse=nan max_logit=10.8091
step:796/1750 train_time:378590ms step_avg:475.62ms
[train step 796] avg_loss=5.624656 main=5.121949 aux=0.502707 imp_cv2=0.0521 load_cv2=5.7987 usage_frac=0.4152 topk_prob_mean=0.1879 ema_alpha_reverse=nan max_logit=10.8091
step:797/1750 train_time:379040ms step_avg:475.58ms
[train step 797] avg_loss=3.934667 main=3.442348 aux=0.492318 imp_cv2=0.0425 load_cv2=5.6866 usage_frac=0.4062 topk_prob_mean=0.2051 ema_alpha_reverse=nan max_logit=10.8091
step:798/1750 train_time:379511ms step_avg:475.58ms
[train step 798] avg_loss=3.663896 main=3.203042 aux=0.460854 imp_cv2=0.1494 load_cv2=5.2036 usage_frac=0.4107 topk_prob_mean=0.2643 ema_alpha_reverse=nan max_logit=10.8091
step:799/1750 train_time:379988ms step_avg:475.58ms
[train step 799] avg_loss=4.023762 main=3.547909 aux=0.475853 imp_cv2=0.0852 load_cv2=5.4506 usage_frac=0.4152 topk_prob_mean=0.2336 ema_alpha_reverse=nan max_logit=10.8091
step:800/1750 train_time:380461ms step_avg:475.58ms
Running validation...
step:800/1750 val_loss:3.458064 train_time:380473ms step_avg:475.59ms
[train step 800] avg_loss=3.694606 main=3.234074 aux=0.460532 imp_cv2=0.1638 load_cv2=5.1851 usage_frac=0.4107 topk_prob_mean=0.2666 ema_alpha_reverse=nan max_logit=10.8091
step:801/1750 train_time:380936ms step_avg:475.58ms
[train step 801] avg_loss=3.615721 main=3.151156 aux=0.464565 imp_cv2=0.1857 load_cv2=5.2207 usage_frac=0.4152 topk_prob_mean=0.2711 ema_alpha_reverse=nan max_logit=11.2345
step:802/1750 train_time:381406ms step_avg:475.57ms
[train step 802] avg_loss=3.706819 main=3.244790 aux=0.462029 imp_cv2=0.1453 load_cv2=5.2262 usage_frac=0.4152 topk_prob_mean=0.2601 ema_alpha_reverse=nan max_logit=10.8091
step:803/1750 train_time:381873ms step_avg:475.56ms
[train step 803] avg_loss=3.874696 main=3.408249 aux=0.466447 imp_cv2=0.1566 load_cv2=5.2657 usage_frac=0.4062 topk_prob_mean=0.2579 ema_alpha_reverse=nan max_logit=10.8091
step:804/1750 train_time:382554ms step_avg:475.81ms
[train step 804] avg_loss=4.444407 main=3.920649 aux=0.523758 imp_cv2=0.0510 load_cv2=6.0507 usage_frac=0.3616 topk_prob_mean=0.1714 ema_alpha_reverse=nan max_logit=8.8438
step:805/1750 train_time:383025ms step_avg:475.81ms
[train step 805] avg_loss=4.012774 main=3.546157 aux=0.466616 imp_cv2=0.1639 load_cv2=5.2682 usage_frac=0.4107 topk_prob_mean=0.2635 ema_alpha_reverse=nan max_logit=10.8091
step:806/1750 train_time:383496ms step_avg:475.80ms
[train step 806] avg_loss=4.137495 main=3.636935 aux=0.500560 imp_cv2=0.0440 load_cv2=5.7897 usage_frac=0.4107 topk_prob_mean=0.1908 ema_alpha_reverse=nan max_logit=10.8091
step:807/1750 train_time:383950ms step_avg:475.77ms
[train step 807] avg_loss=3.652599 main=3.182311 aux=0.470287 imp_cv2=0.1011 load_cv2=5.3701 usage_frac=0.4152 topk_prob_mean=0.2422 ema_alpha_reverse=nan max_logit=10.8091
step:808/1750 train_time:384422ms step_avg:475.77ms
[train step 808] avg_loss=4.275843 main=3.752616 aux=0.523227 imp_cv2=0.0530 load_cv2=6.0494 usage_frac=0.3795 topk_prob_mean=0.1698 ema_alpha_reverse=nan max_logit=8.9876
step:809/1750 train_time:384882ms step_avg:475.75ms
[train step 809] avg_loss=3.566105 main=3.100141 aux=0.465964 imp_cv2=0.1962 load_cv2=5.2211 usage_frac=0.4107 topk_prob_mean=0.2729 ema_alpha_reverse=nan max_logit=10.8091
step:810/1750 train_time:385350ms step_avg:475.74ms
[train step 810] avg_loss=4.037789 main=3.567294 aux=0.470495 imp_cv2=0.1171 load_cv2=5.3536 usage_frac=0.4196 topk_prob_mean=0.2480 ema_alpha_reverse=nan max_logit=11.0918
step:811/1750 train_time:385818ms step_avg:475.73ms
[train step 811] avg_loss=3.910138 main=3.450774 aux=0.459364 imp_cv2=0.1470 load_cv2=5.1927 usage_frac=0.4107 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=10.8091
step:812/1750 train_time:386282ms step_avg:475.72ms
[train step 812] avg_loss=3.816596 main=3.360790 aux=0.455806 imp_cv2=0.1340 load_cv2=5.1601 usage_frac=0.4152 topk_prob_mean=0.2598 ema_alpha_reverse=nan max_logit=10.8091
step:813/1750 train_time:386747ms step_avg:475.70ms
[train step 813] avg_loss=3.700702 main=3.237612 aux=0.463089 imp_cv2=0.0866 load_cv2=5.2974 usage_frac=0.4107 topk_prob_mean=0.2398 ema_alpha_reverse=nan max_logit=11.7917
step:814/1750 train_time:387214ms step_avg:475.69ms
[train step 814] avg_loss=3.999811 main=3.535313 aux=0.464498 imp_cv2=0.1047 load_cv2=5.2979 usage_frac=0.4107 topk_prob_mean=0.2449 ema_alpha_reverse=nan max_logit=10.8091
step:815/1750 train_time:387676ms step_avg:475.68ms
[train step 815] avg_loss=4.018822 main=3.555122 aux=0.463700 imp_cv2=0.0973 load_cv2=5.2937 usage_frac=0.4152 topk_prob_mean=0.2417 ema_alpha_reverse=nan max_logit=10.8091
step:816/1750 train_time:388157ms step_avg:475.68ms
[train step 816] avg_loss=3.780144 main=3.319910 aux=0.460234 imp_cv2=0.1434 load_cv2=5.2099 usage_frac=0.4107 topk_prob_mean=0.2592 ema_alpha_reverse=nan max_logit=10.8091
step:817/1750 train_time:388632ms step_avg:475.68ms
[train step 817] avg_loss=4.080593 main=3.599312 aux=0.481281 imp_cv2=0.0598 load_cv2=5.5416 usage_frac=0.4107 topk_prob_mean=0.2176 ema_alpha_reverse=nan max_logit=10.8091
step:818/1750 train_time:389097ms step_avg:475.67ms
[train step 818] avg_loss=4.517076 main=4.039104 aux=0.477972 imp_cv2=0.0612 load_cv2=5.4903 usage_frac=0.4107 topk_prob_mean=0.2201 ema_alpha_reverse=nan max_logit=10.8091
step:819/1750 train_time:389558ms step_avg:475.65ms
[train step 819] avg_loss=3.994546 main=3.509565 aux=0.484981 imp_cv2=0.0577 load_cv2=5.5679 usage_frac=0.4196 topk_prob_mean=0.2088 ema_alpha_reverse=nan max_logit=10.8091
step:820/1750 train_time:390020ms step_avg:475.63ms
[train step 820] avg_loss=4.111202 main=3.630678 aux=0.480524 imp_cv2=0.0805 load_cv2=5.5073 usage_frac=0.4152 topk_prob_mean=0.2253 ema_alpha_reverse=nan max_logit=10.8091
step:821/1750 train_time:390473ms step_avg:475.61ms
[train step 821] avg_loss=3.826965 main=3.366835 aux=0.460131 imp_cv2=0.1526 load_cv2=5.1857 usage_frac=0.4107 topk_prob_mean=0.2626 ema_alpha_reverse=nan max_logit=10.8091
step:822/1750 train_time:390935ms step_avg:475.59ms
[train step 822] avg_loss=4.222351 main=3.741952 aux=0.480399 imp_cv2=0.0672 load_cv2=5.5174 usage_frac=0.4107 topk_prob_mean=0.2198 ema_alpha_reverse=nan max_logit=10.8091
step:823/1750 train_time:391404ms step_avg:475.58ms
[train step 823] avg_loss=3.857166 main=3.392748 aux=0.464417 imp_cv2=0.1276 load_cv2=5.2663 usage_frac=0.4107 topk_prob_mean=0.2540 ema_alpha_reverse=nan max_logit=10.8091
step:824/1750 train_time:391870ms step_avg:475.57ms
[train step 824] avg_loss=3.355714 main=2.887074 aux=0.468641 imp_cv2=0.1114 load_cv2=5.3221 usage_frac=0.4152 topk_prob_mean=0.2473 ema_alpha_reverse=nan max_logit=10.8091
step:825/1750 train_time:392330ms step_avg:475.55ms
[train step 825] avg_loss=4.799469 main=4.315612 aux=0.483856 imp_cv2=0.0710 load_cv2=5.5337 usage_frac=0.4196 topk_prob_mean=0.2203 ema_alpha_reverse=nan max_logit=10.8091
step:826/1750 train_time:392788ms step_avg:475.53ms
[train step 826] avg_loss=3.532473 main=3.071577 aux=0.460895 imp_cv2=0.2015 load_cv2=5.1442 usage_frac=0.4152 topk_prob_mean=0.2780 ema_alpha_reverse=nan max_logit=10.8091
step:827/1750 train_time:393271ms step_avg:475.54ms
[train step 827] avg_loss=3.659194 main=3.192638 aux=0.466556 imp_cv2=0.1626 load_cv2=5.2471 usage_frac=0.4196 topk_prob_mean=0.2664 ema_alpha_reverse=nan max_logit=10.8091
step:828/1750 train_time:393739ms step_avg:475.53ms
[train step 828] avg_loss=4.104820 main=3.628282 aux=0.476538 imp_cv2=0.0806 load_cv2=5.4527 usage_frac=0.4107 topk_prob_mean=0.2324 ema_alpha_reverse=nan max_logit=10.8091
step:829/1750 train_time:394201ms step_avg:475.51ms
[train step 829] avg_loss=4.106230 main=3.626297 aux=0.479933 imp_cv2=0.0700 load_cv2=5.5022 usage_frac=0.4152 topk_prob_mean=0.2270 ema_alpha_reverse=nan max_logit=10.8091
step:830/1750 train_time:394655ms step_avg:475.49ms
[train step 830] avg_loss=3.995437 main=3.517507 aux=0.477931 imp_cv2=0.0744 load_cv2=5.4688 usage_frac=0.4107 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=10.8091
step:831/1750 train_time:395132ms step_avg:475.49ms
[train step 831] avg_loss=3.673589 main=3.199680 aux=0.473910 imp_cv2=0.1206 load_cv2=5.3763 usage_frac=0.4107 topk_prob_mean=0.2490 ema_alpha_reverse=nan max_logit=10.8091
step:832/1750 train_time:395616ms step_avg:475.50ms
[train step 832] avg_loss=4.243424 main=3.767993 aux=0.475431 imp_cv2=0.0950 load_cv2=5.4249 usage_frac=0.4107 topk_prob_mean=0.2402 ema_alpha_reverse=nan max_logit=10.8091
step:833/1750 train_time:396083ms step_avg:475.49ms
[train step 833] avg_loss=4.158456 main=3.676805 aux=0.481651 imp_cv2=0.0699 load_cv2=5.5243 usage_frac=0.4107 topk_prob_mean=0.2275 ema_alpha_reverse=nan max_logit=10.8091
step:834/1750 train_time:396544ms step_avg:475.47ms
[train step 834] avg_loss=3.668795 main=3.197794 aux=0.471001 imp_cv2=0.1629 load_cv2=5.3028 usage_frac=0.4107 topk_prob_mean=0.2661 ema_alpha_reverse=nan max_logit=10.8091
step:835/1750 train_time:396999ms step_avg:475.45ms
[train step 835] avg_loss=3.826472 main=3.352181 aux=0.474291 imp_cv2=0.1214 load_cv2=5.3844 usage_frac=0.4062 topk_prob_mean=0.2496 ema_alpha_reverse=nan max_logit=10.8091
step:836/1750 train_time:397459ms step_avg:475.43ms
[train step 836] avg_loss=3.984486 main=3.511140 aux=0.473346 imp_cv2=0.0927 load_cv2=5.3877 usage_frac=0.4107 topk_prob_mean=0.2398 ema_alpha_reverse=nan max_logit=10.8091
step:837/1750 train_time:397927ms step_avg:475.42ms
[train step 837] avg_loss=3.972112 main=3.497686 aux=0.474426 imp_cv2=0.1031 load_cv2=5.4075 usage_frac=0.4062 topk_prob_mean=0.2437 ema_alpha_reverse=nan max_logit=10.8091
step:838/1750 train_time:398384ms step_avg:475.40ms
[train step 838] avg_loss=3.958063 main=3.486802 aux=0.471262 imp_cv2=0.1012 load_cv2=5.3723 usage_frac=0.4018 topk_prob_mean=0.2433 ema_alpha_reverse=nan max_logit=10.8091
step:839/1750 train_time:398849ms step_avg:475.39ms
[train step 839] avg_loss=3.957270 main=3.479549 aux=0.477721 imp_cv2=0.0896 load_cv2=5.4619 usage_frac=0.4062 topk_prob_mean=0.2343 ema_alpha_reverse=nan max_logit=10.8091
step:840/1750 train_time:399317ms step_avg:475.38ms
[train step 840] avg_loss=3.680744 main=3.209146 aux=0.471598 imp_cv2=0.1514 load_cv2=5.3260 usage_frac=0.4062 topk_prob_mean=0.2560 ema_alpha_reverse=nan max_logit=10.8091
step:841/1750 train_time:399788ms step_avg:475.37ms
[train step 841] avg_loss=4.138319 main=3.660357 aux=0.477962 imp_cv2=0.0677 load_cv2=5.4879 usage_frac=0.4152 topk_prob_mean=0.2263 ema_alpha_reverse=nan max_logit=10.8091
step:842/1750 train_time:400233ms step_avg:475.34ms
[train step 842] avg_loss=4.374685 main=3.885862 aux=0.488823 imp_cv2=0.0443 load_cv2=5.6435 usage_frac=0.4018 topk_prob_mean=0.2036 ema_alpha_reverse=nan max_logit=10.8091
step:843/1750 train_time:400887ms step_avg:475.55ms
[train step 843] avg_loss=3.778452 main=3.297415 aux=0.481037 imp_cv2=0.0683 load_cv2=5.5155 usage_frac=0.4018 topk_prob_mean=0.2259 ema_alpha_reverse=nan max_logit=10.8091
step:844/1750 train_time:401353ms step_avg:475.54ms
[train step 844] avg_loss=3.835703 main=3.365797 aux=0.469906 imp_cv2=0.1085 load_cv2=5.3444 usage_frac=0.4062 topk_prob_mean=0.2472 ema_alpha_reverse=nan max_logit=10.8091
step:845/1750 train_time:401811ms step_avg:475.52ms
[train step 845] avg_loss=4.149882 main=3.675440 aux=0.474442 imp_cv2=0.0638 load_cv2=5.4336 usage_frac=0.4152 topk_prob_mean=0.2284 ema_alpha_reverse=nan max_logit=10.8091
step:846/1750 train_time:402262ms step_avg:475.49ms
[train step 846] avg_loss=3.561952 main=3.096600 aux=0.465352 imp_cv2=0.1527 load_cv2=5.2439 usage_frac=0.4018 topk_prob_mean=0.2652 ema_alpha_reverse=nan max_logit=10.8091
step:847/1750 train_time:402732ms step_avg:475.48ms
[train step 847] avg_loss=4.050363 main=3.573025 aux=0.477338 imp_cv2=0.0653 load_cv2=5.4802 usage_frac=0.4018 topk_prob_mean=0.2281 ema_alpha_reverse=nan max_logit=10.8091
step:848/1750 train_time:403201ms step_avg:475.47ms
[train step 848] avg_loss=3.731304 main=3.260844 aux=0.470460 imp_cv2=0.0887 load_cv2=5.3665 usage_frac=0.3973 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=10.8091
step:849/1750 train_time:403661ms step_avg:475.46ms
[train step 849] avg_loss=3.926426 main=3.457460 aux=0.468966 imp_cv2=0.0970 load_cv2=5.3381 usage_frac=0.4018 topk_prob_mean=0.2458 ema_alpha_reverse=nan max_logit=10.8091
step:850/1750 train_time:404119ms step_avg:475.43ms
Running validation...
step:850/1750 val_loss:3.401912 train_time:404131ms step_avg:475.45ms
[train step 850] avg_loss=3.871955 main=3.408427 aux=0.463528 imp_cv2=0.1272 load_cv2=5.2539 usage_frac=0.3973 topk_prob_mean=0.2582 ema_alpha_reverse=nan max_logit=10.8091
step:851/1750 train_time:404582ms step_avg:475.42ms
[train step 851] avg_loss=3.830915 main=3.368047 aux=0.462868 imp_cv2=0.1302 load_cv2=5.2339 usage_frac=0.3973 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=10.8091
step:852/1750 train_time:405046ms step_avg:475.41ms
[train step 852] avg_loss=3.887505 main=3.411501 aux=0.476004 imp_cv2=0.0821 load_cv2=5.4456 usage_frac=0.4107 topk_prob_mean=0.2349 ema_alpha_reverse=nan max_logit=10.8091
step:853/1750 train_time:405511ms step_avg:475.39ms
[train step 853] avg_loss=4.365133 main=3.883154 aux=0.481979 imp_cv2=0.0624 load_cv2=5.5348 usage_frac=0.3973 topk_prob_mean=0.2175 ema_alpha_reverse=nan max_logit=10.8091
step:854/1750 train_time:405962ms step_avg:475.37ms
[train step 854] avg_loss=4.148044 main=3.679251 aux=0.468794 imp_cv2=0.0933 load_cv2=5.3459 usage_frac=0.3973 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=10.8091
step:855/1750 train_time:406432ms step_avg:475.36ms
[train step 855] avg_loss=4.652934 main=4.159674 aux=0.493260 imp_cv2=0.0459 load_cv2=5.6864 usage_frac=0.4018 topk_prob_mean=0.2013 ema_alpha_reverse=nan max_logit=10.8091
step:856/1750 train_time:406890ms step_avg:475.34ms
[train step 856] avg_loss=4.086769 main=3.591956 aux=0.494813 imp_cv2=0.0484 load_cv2=5.7113 usage_frac=0.3929 topk_prob_mean=0.1971 ema_alpha_reverse=nan max_logit=10.8091
step:857/1750 train_time:407343ms step_avg:475.31ms
[train step 857] avg_loss=3.570035 main=3.109767 aux=0.460268 imp_cv2=0.1270 load_cv2=5.2066 usage_frac=0.4062 topk_prob_mean=0.2606 ema_alpha_reverse=nan max_logit=10.8091
step:858/1750 train_time:407816ms step_avg:475.31ms
[train step 858] avg_loss=3.860966 main=3.385399 aux=0.475567 imp_cv2=0.0560 load_cv2=5.4734 usage_frac=0.3973 topk_prob_mean=0.2210 ema_alpha_reverse=nan max_logit=10.8091
step:859/1750 train_time:408283ms step_avg:475.30ms
[train step 859] avg_loss=4.175373 main=3.707853 aux=0.467520 imp_cv2=0.0875 load_cv2=5.3362 usage_frac=0.3929 topk_prob_mean=0.2411 ema_alpha_reverse=nan max_logit=10.8091
step:860/1750 train_time:408747ms step_avg:475.29ms
[train step 860] avg_loss=4.102510 main=3.628563 aux=0.473947 imp_cv2=0.0733 load_cv2=5.4310 usage_frac=0.4062 topk_prob_mean=0.2317 ema_alpha_reverse=nan max_logit=10.8091
step:861/1750 train_time:409216ms step_avg:475.28ms
[train step 861] avg_loss=3.902186 main=3.438157 aux=0.464030 imp_cv2=0.1197 load_cv2=5.2580 usage_frac=0.4107 topk_prob_mean=0.2570 ema_alpha_reverse=nan max_logit=10.8091
step:862/1750 train_time:409672ms step_avg:475.26ms
[train step 862] avg_loss=3.826142 main=3.359299 aux=0.466843 imp_cv2=0.1179 load_cv2=5.2962 usage_frac=0.4107 topk_prob_mean=0.2533 ema_alpha_reverse=nan max_logit=10.8091
step:863/1750 train_time:410318ms step_avg:475.46ms
[train step 863] avg_loss=3.690244 main=3.229463 aux=0.460780 imp_cv2=0.1404 load_cv2=5.1994 usage_frac=0.4062 topk_prob_mean=0.2669 ema_alpha_reverse=nan max_logit=11.0120
step:864/1750 train_time:410774ms step_avg:475.43ms
[train step 864] avg_loss=3.868962 main=3.397875 aux=0.471087 imp_cv2=0.0855 load_cv2=5.3797 usage_frac=0.3973 topk_prob_mean=0.2420 ema_alpha_reverse=nan max_logit=10.8091
step:865/1750 train_time:411235ms step_avg:475.42ms
[train step 865] avg_loss=3.909422 main=3.443532 aux=0.465890 imp_cv2=0.1022 load_cv2=5.2969 usage_frac=0.4062 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=10.8091
step:866/1750 train_time:411708ms step_avg:475.41ms
[train step 866] avg_loss=4.042834 main=3.575183 aux=0.467651 imp_cv2=0.0866 load_cv2=5.3292 usage_frac=0.4062 topk_prob_mean=0.2435 ema_alpha_reverse=nan max_logit=10.8091
step:867/1750 train_time:412167ms step_avg:475.39ms
[train step 867] avg_loss=3.630700 main=3.168660 aux=0.462040 imp_cv2=0.1623 load_cv2=5.1953 usage_frac=0.4152 topk_prob_mean=0.2715 ema_alpha_reverse=nan max_logit=10.8091
step:868/1750 train_time:412812ms step_avg:475.59ms
[train step 868] avg_loss=3.913394 main=3.443860 aux=0.469534 imp_cv2=0.0826 load_cv2=5.3635 usage_frac=0.4062 topk_prob_mean=0.2394 ema_alpha_reverse=nan max_logit=10.8091
step:869/1750 train_time:413275ms step_avg:475.58ms
[train step 869] avg_loss=3.787280 main=3.321302 aux=0.465977 imp_cv2=0.1169 load_cv2=5.2800 usage_frac=0.3973 topk_prob_mean=0.2552 ema_alpha_reverse=nan max_logit=10.8091
step:870/1750 train_time:413730ms step_avg:475.55ms
[train step 870] avg_loss=3.740875 main=3.280387 aux=0.460488 imp_cv2=0.1552 load_cv2=5.1833 usage_frac=0.4107 topk_prob_mean=0.2711 ema_alpha_reverse=nan max_logit=10.8091
step:871/1750 train_time:414192ms step_avg:475.54ms
[train step 871] avg_loss=3.518060 main=3.057112 aux=0.460948 imp_cv2=0.1733 load_cv2=5.1715 usage_frac=0.4107 topk_prob_mean=0.2748 ema_alpha_reverse=nan max_logit=10.8091
step:872/1750 train_time:414853ms step_avg:475.75ms
[train step 872] avg_loss=3.739698 main=3.275052 aux=0.464646 imp_cv2=0.0914 load_cv2=5.2908 usage_frac=0.4152 topk_prob_mean=0.2446 ema_alpha_reverse=nan max_logit=10.8091
step:873/1750 train_time:415317ms step_avg:475.74ms
[train step 873] avg_loss=4.184187 main=3.716297 aux=0.467889 imp_cv2=0.0806 load_cv2=5.3504 usage_frac=0.4062 topk_prob_mean=0.2383 ema_alpha_reverse=nan max_logit=10.8091
step:874/1750 train_time:415785ms step_avg:475.73ms
[train step 874] avg_loss=4.009027 main=3.536386 aux=0.472641 imp_cv2=0.0615 load_cv2=5.4275 usage_frac=0.4062 topk_prob_mean=0.2251 ema_alpha_reverse=nan max_logit=10.8091
step:875/1750 train_time:416245ms step_avg:475.71ms
[train step 875] avg_loss=3.990371 main=3.521705 aux=0.468666 imp_cv2=0.0853 load_cv2=5.3586 usage_frac=0.4062 topk_prob_mean=0.2388 ema_alpha_reverse=nan max_logit=10.8091
step:876/1750 train_time:416701ms step_avg:475.69ms
[train step 876] avg_loss=3.538225 main=3.078864 aux=0.459361 imp_cv2=0.1602 load_cv2=5.1691 usage_frac=0.4062 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=10.8091
step:877/1750 train_time:417166ms step_avg:475.67ms
[train step 877] avg_loss=3.739955 main=3.273426 aux=0.466528 imp_cv2=0.1236 load_cv2=5.2886 usage_frac=0.4152 topk_prob_mean=0.2533 ema_alpha_reverse=nan max_logit=10.8091
step:878/1750 train_time:417635ms step_avg:475.67ms
[train step 878] avg_loss=3.875005 main=3.411054 aux=0.463952 imp_cv2=0.1299 load_cv2=5.2566 usage_frac=0.4018 topk_prob_mean=0.2564 ema_alpha_reverse=nan max_logit=10.8091
step:879/1750 train_time:418099ms step_avg:475.65ms
[train step 879] avg_loss=3.881776 main=3.393355 aux=0.488420 imp_cv2=0.0473 load_cv2=5.6275 usage_frac=0.4018 topk_prob_mean=0.2090 ema_alpha_reverse=nan max_logit=10.8091
step:880/1750 train_time:418579ms step_avg:475.66ms
[train step 880] avg_loss=3.989818 main=3.521290 aux=0.468529 imp_cv2=0.1196 load_cv2=5.3144 usage_frac=0.4062 topk_prob_mean=0.2526 ema_alpha_reverse=nan max_logit=10.8091
step:881/1750 train_time:419038ms step_avg:475.64ms
[train step 881] avg_loss=4.134555 main=3.658623 aux=0.475932 imp_cv2=0.0766 load_cv2=5.4433 usage_frac=0.4062 topk_prob_mean=0.2320 ema_alpha_reverse=nan max_logit=10.8091
step:882/1750 train_time:419499ms step_avg:475.62ms
[train step 882] avg_loss=4.142838 main=3.643726 aux=0.499111 imp_cv2=0.0530 load_cv2=5.7517 usage_frac=0.4018 topk_prob_mean=0.2006 ema_alpha_reverse=nan max_logit=9.8264
step:883/1750 train_time:419952ms step_avg:475.60ms
[train step 883] avg_loss=3.985375 main=3.511480 aux=0.473895 imp_cv2=0.0921 load_cv2=5.4053 usage_frac=0.4152 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=10.8091
step:884/1750 train_time:420416ms step_avg:475.58ms
[train step 884] avg_loss=3.800885 main=3.330503 aux=0.470381 imp_cv2=0.1118 load_cv2=5.3497 usage_frac=0.4018 topk_prob_mean=0.2501 ema_alpha_reverse=nan max_logit=10.8091
step:885/1750 train_time:420876ms step_avg:475.57ms
[train step 885] avg_loss=3.663456 main=3.191409 aux=0.472046 imp_cv2=0.0713 load_cv2=5.4064 usage_frac=0.4018 topk_prob_mean=0.2331 ema_alpha_reverse=nan max_logit=10.8091
step:886/1750 train_time:421345ms step_avg:475.56ms
[train step 886] avg_loss=3.768026 main=3.293654 aux=0.474373 imp_cv2=0.0877 load_cv2=5.4171 usage_frac=0.4018 topk_prob_mean=0.2387 ema_alpha_reverse=nan max_logit=10.8091
step:887/1750 train_time:421808ms step_avg:475.54ms
[train step 887] avg_loss=3.966906 main=3.479246 aux=0.487660 imp_cv2=0.0589 load_cv2=5.6093 usage_frac=0.4018 topk_prob_mean=0.2139 ema_alpha_reverse=nan max_logit=10.8091
step:888/1750 train_time:422256ms step_avg:475.51ms
[train step 888] avg_loss=4.093045 main=3.617588 aux=0.475457 imp_cv2=0.1364 load_cv2=5.3817 usage_frac=0.4018 topk_prob_mean=0.2506 ema_alpha_reverse=nan max_logit=10.8091
step:889/1750 train_time:422715ms step_avg:475.50ms
[train step 889] avg_loss=3.997564 main=3.523663 aux=0.473900 imp_cv2=0.1427 load_cv2=5.3608 usage_frac=0.4062 topk_prob_mean=0.2553 ema_alpha_reverse=nan max_logit=10.8091
step:890/1750 train_time:423170ms step_avg:475.47ms
[train step 890] avg_loss=3.749508 main=3.278541 aux=0.470967 imp_cv2=0.1400 load_cv2=5.3318 usage_frac=0.4062 topk_prob_mean=0.2566 ema_alpha_reverse=nan max_logit=11.1331
step:891/1750 train_time:423630ms step_avg:475.46ms
[train step 891] avg_loss=3.510367 main=3.039162 aux=0.471205 imp_cv2=0.1737 load_cv2=5.2966 usage_frac=0.4018 topk_prob_mean=0.2671 ema_alpha_reverse=nan max_logit=10.8091
step:892/1750 train_time:424091ms step_avg:475.44ms
[train step 892] avg_loss=4.140958 main=3.664358 aux=0.476600 imp_cv2=0.0708 load_cv2=5.4635 usage_frac=0.4018 topk_prob_mean=0.2250 ema_alpha_reverse=nan max_logit=10.8091
step:893/1750 train_time:424552ms step_avg:475.42ms
[train step 893] avg_loss=3.528311 main=3.056244 aux=0.472067 imp_cv2=0.0850 load_cv2=5.3971 usage_frac=0.4107 topk_prob_mean=0.2354 ema_alpha_reverse=nan max_logit=11.7917
step:894/1750 train_time:425015ms step_avg:475.41ms
[train step 894] avg_loss=4.606220 main=4.099827 aux=0.506393 imp_cv2=0.0459 load_cv2=5.8429 usage_frac=0.4062 topk_prob_mean=0.1948 ema_alpha_reverse=nan max_logit=10.8610
step:895/1750 train_time:425477ms step_avg:475.39ms
[train step 895] avg_loss=3.696556 main=3.232882 aux=0.463674 imp_cv2=0.1167 load_cv2=5.2603 usage_frac=0.4107 topk_prob_mean=0.2525 ema_alpha_reverse=nan max_logit=11.5500
step:896/1750 train_time:425943ms step_avg:475.38ms
[train step 896] avg_loss=3.839545 main=3.370863 aux=0.468682 imp_cv2=0.0971 load_cv2=5.3469 usage_frac=0.4196 topk_prob_mean=0.2432 ema_alpha_reverse=nan max_logit=11.5533
step:897/1750 train_time:426398ms step_avg:475.36ms
[train step 897] avg_loss=3.873927 main=3.409304 aux=0.464623 imp_cv2=0.0865 load_cv2=5.3033 usage_frac=0.4018 topk_prob_mean=0.2410 ema_alpha_reverse=nan max_logit=11.7917
step:898/1750 train_time:426872ms step_avg:475.36ms
[train step 898] avg_loss=3.967403 main=3.498651 aux=0.468752 imp_cv2=0.1018 load_cv2=5.3404 usage_frac=0.4062 topk_prob_mean=0.2474 ema_alpha_reverse=nan max_logit=11.7917
step:899/1750 train_time:427337ms step_avg:475.35ms
[train step 899] avg_loss=4.138054 main=3.651008 aux=0.487046 imp_cv2=0.0785 load_cv2=5.5918 usage_frac=0.4107 topk_prob_mean=0.2222 ema_alpha_reverse=nan max_logit=11.7917
step:900/1750 train_time:427799ms step_avg:475.33ms
Running validation...
step:900/1750 val_loss:3.365175 train_time:427811ms step_avg:475.35ms
[train step 900] avg_loss=4.081420 main=3.609899 aux=0.471522 imp_cv2=0.0692 load_cv2=5.4008 usage_frac=0.4107 topk_prob_mean=0.2304 ema_alpha_reverse=nan max_logit=11.7917
step:901/1750 train_time:428269ms step_avg:475.33ms
[train step 901] avg_loss=3.747442 main=3.290432 aux=0.457010 imp_cv2=0.1530 load_cv2=5.1458 usage_frac=0.4062 topk_prob_mean=0.2711 ema_alpha_reverse=nan max_logit=11.7917
step:902/1750 train_time:428744ms step_avg:475.33ms
[train step 902] avg_loss=4.182670 main=3.670779 aux=0.511891 imp_cv2=0.0400 load_cv2=5.9113 usage_frac=0.3973 topk_prob_mean=0.1874 ema_alpha_reverse=nan max_logit=10.8091
step:903/1750 train_time:429209ms step_avg:475.31ms
[train step 903] avg_loss=3.704323 main=3.242813 aux=0.461511 imp_cv2=0.1102 load_cv2=5.2431 usage_frac=0.4062 topk_prob_mean=0.2538 ema_alpha_reverse=nan max_logit=11.7917
step:904/1750 train_time:429897ms step_avg:475.55ms
[train step 904] avg_loss=4.131512 main=3.651668 aux=0.479845 imp_cv2=0.0590 load_cv2=5.5197 usage_frac=0.4018 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=11.7917
step:905/1750 train_time:430364ms step_avg:475.54ms
[train step 905] avg_loss=3.550650 main=3.089038 aux=0.461611 imp_cv2=0.1990 load_cv2=5.1608 usage_frac=0.4107 topk_prob_mean=0.2822 ema_alpha_reverse=nan max_logit=11.7917
step:906/1750 train_time:430829ms step_avg:475.53ms
[train step 906] avg_loss=4.056614 main=3.535996 aux=0.520618 imp_cv2=0.0379 load_cv2=6.0342 usage_frac=0.3973 topk_prob_mean=0.1752 ema_alpha_reverse=nan max_logit=10.8091
step:907/1750 train_time:431288ms step_avg:475.51ms
[train step 907] avg_loss=3.960422 main=3.487785 aux=0.472636 imp_cv2=0.0695 load_cv2=5.4158 usage_frac=0.4018 topk_prob_mean=0.2285 ema_alpha_reverse=nan max_logit=11.7917
step:908/1750 train_time:431756ms step_avg:475.50ms
[train step 908] avg_loss=4.209757 main=3.741618 aux=0.468139 imp_cv2=0.0750 load_cv2=5.3647 usage_frac=0.4107 topk_prob_mean=0.2349 ema_alpha_reverse=nan max_logit=11.7917
step:909/1750 train_time:432212ms step_avg:475.48ms
[train step 909] avg_loss=3.666785 main=3.200764 aux=0.466022 imp_cv2=0.1844 load_cv2=5.2308 usage_frac=0.4107 topk_prob_mean=0.2769 ema_alpha_reverse=nan max_logit=11.7917
step:910/1750 train_time:432681ms step_avg:475.47ms
[train step 910] avg_loss=4.026844 main=3.556369 aux=0.470475 imp_cv2=0.0825 load_cv2=5.3760 usage_frac=0.4062 topk_prob_mean=0.2389 ema_alpha_reverse=nan max_logit=11.7917
step:911/1750 train_time:433141ms step_avg:475.46ms
[train step 911] avg_loss=3.741066 main=3.275176 aux=0.465890 imp_cv2=0.1459 load_cv2=5.2592 usage_frac=0.4152 topk_prob_mean=0.2638 ema_alpha_reverse=nan max_logit=11.7917
step:912/1750 train_time:433616ms step_avg:475.46ms
[train step 912] avg_loss=3.842309 main=3.376662 aux=0.465647 imp_cv2=0.1375 load_cv2=5.2640 usage_frac=0.4062 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=11.7917
step:913/1750 train_time:434077ms step_avg:475.44ms
[train step 913] avg_loss=4.293991 main=3.781929 aux=0.512062 imp_cv2=0.0364 load_cv2=5.9266 usage_frac=0.4018 topk_prob_mean=0.1832 ema_alpha_reverse=nan max_logit=10.8091
step:914/1750 train_time:434537ms step_avg:475.42ms
[train step 914] avg_loss=4.039597 main=3.542400 aux=0.497197 imp_cv2=0.0437 load_cv2=5.7381 usage_frac=0.4062 topk_prob_mean=0.2004 ema_alpha_reverse=nan max_logit=11.7917
step:915/1750 train_time:435002ms step_avg:475.41ms
[train step 915] avg_loss=3.728905 main=3.258218 aux=0.470687 imp_cv2=0.1236 load_cv2=5.3398 usage_frac=0.4107 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:916/1750 train_time:435460ms step_avg:475.39ms
[train step 916] avg_loss=4.240833 main=3.760027 aux=0.480806 imp_cv2=0.0662 load_cv2=5.5134 usage_frac=0.4152 topk_prob_mean=0.2254 ema_alpha_reverse=nan max_logit=11.7917
step:917/1750 train_time:435910ms step_avg:475.37ms
[train step 917] avg_loss=3.463591 main=2.989574 aux=0.474017 imp_cv2=0.1888 load_cv2=5.3183 usage_frac=0.4286 topk_prob_mean=0.2717 ema_alpha_reverse=nan max_logit=11.7917
step:918/1750 train_time:436370ms step_avg:475.35ms
[train step 918] avg_loss=3.608764 main=3.139838 aux=0.468926 imp_cv2=0.1320 load_cv2=5.3104 usage_frac=0.4196 topk_prob_mean=0.2555 ema_alpha_reverse=nan max_logit=11.7917
step:919/1750 train_time:436829ms step_avg:475.33ms
[train step 919] avg_loss=3.597276 main=3.127466 aux=0.469810 imp_cv2=0.1961 load_cv2=5.2619 usage_frac=0.4062 topk_prob_mean=0.2759 ema_alpha_reverse=nan max_logit=11.7917
step:920/1750 train_time:437301ms step_avg:475.33ms
[train step 920] avg_loss=3.960390 main=3.481981 aux=0.478410 imp_cv2=0.0553 load_cv2=5.5024 usage_frac=0.4107 topk_prob_mean=0.2208 ema_alpha_reverse=nan max_logit=11.7917
step:921/1750 train_time:437753ms step_avg:475.30ms
[train step 921] avg_loss=3.774829 main=3.303360 aux=0.471469 imp_cv2=0.0872 load_cv2=5.3820 usage_frac=0.4062 topk_prob_mean=0.2392 ema_alpha_reverse=nan max_logit=11.7917
step:922/1750 train_time:438216ms step_avg:475.29ms
[train step 922] avg_loss=3.926516 main=3.454531 aux=0.471984 imp_cv2=0.0581 load_cv2=5.4219 usage_frac=0.4152 topk_prob_mean=0.2249 ema_alpha_reverse=nan max_logit=11.7917
step:923/1750 train_time:438682ms step_avg:475.28ms
[train step 923] avg_loss=4.148735 main=3.687026 aux=0.461709 imp_cv2=0.1064 load_cv2=5.2463 usage_frac=0.4196 topk_prob_mean=0.2525 ema_alpha_reverse=nan max_logit=11.7917
step:924/1750 train_time:439152ms step_avg:475.27ms
[train step 924] avg_loss=4.276346 main=3.775823 aux=0.500522 imp_cv2=0.0476 load_cv2=5.7726 usage_frac=0.3973 topk_prob_mean=0.1868 ema_alpha_reverse=nan max_logit=11.7917
step:925/1750 train_time:439609ms step_avg:475.25ms
[train step 925] avg_loss=3.500031 main=3.036702 aux=0.463329 imp_cv2=0.1820 load_cv2=5.1940 usage_frac=0.4152 topk_prob_mean=0.2776 ema_alpha_reverse=nan max_logit=11.7917
step:926/1750 train_time:440079ms step_avg:475.25ms
[train step 926] avg_loss=3.541688 main=3.072117 aux=0.469571 imp_cv2=0.1150 load_cv2=5.3293 usage_frac=0.4152 topk_prob_mean=0.2534 ema_alpha_reverse=nan max_logit=11.7917
step:927/1750 train_time:440537ms step_avg:475.23ms
[train step 927] avg_loss=3.681582 main=3.207310 aux=0.474272 imp_cv2=0.0722 load_cv2=5.4346 usage_frac=0.4196 topk_prob_mean=0.2336 ema_alpha_reverse=nan max_logit=11.7917
step:928/1750 train_time:440998ms step_avg:475.21ms
[train step 928] avg_loss=4.168743 main=3.685198 aux=0.483545 imp_cv2=0.0681 load_cv2=5.5563 usage_frac=0.4152 topk_prob_mean=0.2262 ema_alpha_reverse=nan max_logit=11.7917
step:929/1750 train_time:441454ms step_avg:475.19ms
[train step 929] avg_loss=3.285213 main=2.819787 aux=0.465425 imp_cv2=0.2209 load_cv2=5.1865 usage_frac=0.4152 topk_prob_mean=0.2897 ema_alpha_reverse=nan max_logit=11.7917
step:930/1750 train_time:441924ms step_avg:475.19ms
[train step 930] avg_loss=3.799624 main=3.334102 aux=0.465522 imp_cv2=0.1533 load_cv2=5.2534 usage_frac=0.4196 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=11.7917
step:931/1750 train_time:442409ms step_avg:475.20ms
[train step 931] avg_loss=3.751763 main=3.253810 aux=0.497953 imp_cv2=0.0513 load_cv2=5.7399 usage_frac=0.4018 topk_prob_mean=0.2041 ema_alpha_reverse=nan max_logit=11.7917
step:932/1750 train_time:442881ms step_avg:475.19ms
[train step 932] avg_loss=3.573407 main=3.107116 aux=0.466292 imp_cv2=0.1329 load_cv2=5.2853 usage_frac=0.4196 topk_prob_mean=0.2608 ema_alpha_reverse=nan max_logit=11.7917
step:933/1750 train_time:443344ms step_avg:475.18ms
[train step 933] avg_loss=3.941499 main=3.468846 aux=0.472652 imp_cv2=0.0869 load_cv2=5.4036 usage_frac=0.4107 topk_prob_mean=0.2390 ema_alpha_reverse=nan max_logit=11.7917
step:934/1750 train_time:443800ms step_avg:475.16ms
[train step 934] avg_loss=4.034130 main=3.555182 aux=0.478947 imp_cv2=0.0734 load_cv2=5.4944 usage_frac=0.4062 topk_prob_mean=0.2261 ema_alpha_reverse=nan max_logit=11.7917
step:935/1750 train_time:444257ms step_avg:475.14ms
[train step 935] avg_loss=3.653051 main=3.181620 aux=0.471430 imp_cv2=0.0968 load_cv2=5.3746 usage_frac=0.4107 topk_prob_mean=0.2431 ema_alpha_reverse=nan max_logit=11.7917
step:936/1750 train_time:444712ms step_avg:475.12ms
[train step 936] avg_loss=3.743040 main=3.277285 aux=0.465755 imp_cv2=0.1257 load_cv2=5.2706 usage_frac=0.4152 topk_prob_mean=0.2567 ema_alpha_reverse=nan max_logit=11.7917
step:937/1750 train_time:445180ms step_avg:475.11ms
[train step 937] avg_loss=4.404482 main=3.890108 aux=0.514374 imp_cv2=0.0461 load_cv2=5.9414 usage_frac=0.4152 topk_prob_mean=0.1820 ema_alpha_reverse=nan max_logit=11.7917
step:938/1750 train_time:445640ms step_avg:475.10ms
[train step 938] avg_loss=3.982993 main=3.515712 aux=0.467281 imp_cv2=0.1167 load_cv2=5.3094 usage_frac=0.4241 topk_prob_mean=0.2510 ema_alpha_reverse=nan max_logit=11.7917
step:939/1750 train_time:446101ms step_avg:475.08ms
[train step 939] avg_loss=3.443169 main=2.978503 aux=0.464665 imp_cv2=0.1616 load_cv2=5.2282 usage_frac=0.4196 topk_prob_mean=0.2693 ema_alpha_reverse=nan max_logit=11.7917
step:940/1750 train_time:446566ms step_avg:475.07ms
[train step 940] avg_loss=3.538663 main=3.077818 aux=0.460845 imp_cv2=0.1883 load_cv2=5.1578 usage_frac=0.4196 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=11.7917
step:941/1750 train_time:447033ms step_avg:475.06ms
[train step 941] avg_loss=3.472442 main=3.011710 aux=0.460731 imp_cv2=0.1864 load_cv2=5.1593 usage_frac=0.4241 topk_prob_mean=0.2790 ema_alpha_reverse=nan max_logit=11.7917
step:942/1750 train_time:447519ms step_avg:475.07ms
[train step 942] avg_loss=4.127616 main=3.645517 aux=0.482100 imp_cv2=0.0606 load_cv2=5.5452 usage_frac=0.4062 topk_prob_mean=0.2211 ema_alpha_reverse=nan max_logit=11.7917
step:943/1750 train_time:447992ms step_avg:475.07ms
[train step 943] avg_loss=4.032507 main=3.566595 aux=0.465911 imp_cv2=0.1009 load_cv2=5.3039 usage_frac=0.4152 topk_prob_mean=0.2478 ema_alpha_reverse=nan max_logit=11.7917
step:944/1750 train_time:448447ms step_avg:475.05ms
[train step 944] avg_loss=3.731184 main=3.263902 aux=0.467282 imp_cv2=0.1250 load_cv2=5.3020 usage_frac=0.4107 topk_prob_mean=0.2558 ema_alpha_reverse=nan max_logit=11.7917
step:945/1750 train_time:448920ms step_avg:475.05ms
[train step 945] avg_loss=3.987103 main=3.500572 aux=0.486531 imp_cv2=0.0930 load_cv2=5.5696 usage_frac=0.4196 topk_prob_mean=0.2263 ema_alpha_reverse=nan max_logit=11.7917
step:946/1750 train_time:449371ms step_avg:475.02ms
[train step 946] avg_loss=3.470996 main=3.008737 aux=0.462259 imp_cv2=0.2153 load_cv2=5.1504 usage_frac=0.4152 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=11.7917
step:947/1750 train_time:449833ms step_avg:475.01ms
[train step 947] avg_loss=4.035798 main=3.564506 aux=0.471292 imp_cv2=0.0811 load_cv2=5.3942 usage_frac=0.4196 topk_prob_mean=0.2378 ema_alpha_reverse=nan max_logit=11.7917
step:948/1750 train_time:450292ms step_avg:474.99ms
[train step 948] avg_loss=3.889285 main=3.421553 aux=0.467732 imp_cv2=0.1358 load_cv2=5.2999 usage_frac=0.4152 topk_prob_mean=0.2604 ema_alpha_reverse=nan max_logit=11.7917
step:949/1750 train_time:450756ms step_avg:474.98ms
[train step 949] avg_loss=3.945811 main=3.474849 aux=0.470962 imp_cv2=0.1119 load_cv2=5.3671 usage_frac=0.4196 topk_prob_mean=0.2478 ema_alpha_reverse=nan max_logit=11.7917
step:950/1750 train_time:451227ms step_avg:474.98ms
Running validation...
step:950/1750 val_loss:3.326460 train_time:451239ms step_avg:474.99ms
[train step 950] avg_loss=3.877842 main=3.386495 aux=0.491347 imp_cv2=0.0617 load_cv2=5.6496 usage_frac=0.4107 topk_prob_mean=0.2158 ema_alpha_reverse=nan max_logit=11.7917
step:951/1750 train_time:451694ms step_avg:474.97ms
[train step 951] avg_loss=3.670812 main=3.206316 aux=0.464496 imp_cv2=0.1998 load_cv2=5.1975 usage_frac=0.4152 topk_prob_mean=0.2778 ema_alpha_reverse=nan max_logit=11.7917
step:952/1750 train_time:452152ms step_avg:474.95ms
[train step 952] avg_loss=3.776244 main=3.311678 aux=0.464566 imp_cv2=0.1518 load_cv2=5.2365 usage_frac=0.4107 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=11.7917
step:953/1750 train_time:452618ms step_avg:474.94ms
[train step 953] avg_loss=3.772545 main=3.307291 aux=0.465254 imp_cv2=0.1280 load_cv2=5.2680 usage_frac=0.4196 topk_prob_mean=0.2567 ema_alpha_reverse=nan max_logit=11.7917
step:954/1750 train_time:453076ms step_avg:474.92ms
[train step 954] avg_loss=4.426724 main=3.920583 aux=0.506141 imp_cv2=0.0872 load_cv2=5.8073 usage_frac=0.4062 topk_prob_mean=0.2066 ema_alpha_reverse=nan max_logit=11.7917
step:955/1750 train_time:453537ms step_avg:474.91ms
[train step 955] avg_loss=3.558055 main=3.099665 aux=0.458390 imp_cv2=0.1291 load_cv2=5.1824 usage_frac=0.4196 topk_prob_mean=0.2609 ema_alpha_reverse=nan max_logit=11.7917
step:956/1750 train_time:454003ms step_avg:474.90ms
[train step 956] avg_loss=3.907828 main=3.443816 aux=0.464012 imp_cv2=0.1078 load_cv2=5.2679 usage_frac=0.4196 topk_prob_mean=0.2508 ema_alpha_reverse=nan max_logit=11.7917
step:957/1750 train_time:454467ms step_avg:474.89ms
[train step 957] avg_loss=3.694759 main=3.238120 aux=0.456640 imp_cv2=0.1278 load_cv2=5.1604 usage_frac=0.4062 topk_prob_mean=0.2642 ema_alpha_reverse=nan max_logit=11.7917
step:958/1750 train_time:454923ms step_avg:474.87ms
[train step 958] avg_loss=3.811190 main=3.345622 aux=0.465568 imp_cv2=0.0866 load_cv2=5.3082 usage_frac=0.4107 topk_prob_mean=0.2424 ema_alpha_reverse=nan max_logit=11.7917
step:959/1750 train_time:455384ms step_avg:474.85ms
[train step 959] avg_loss=3.463588 main=3.009459 aux=0.454129 imp_cv2=0.1693 load_cv2=5.0937 usage_frac=0.4196 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=11.7917
step:960/1750 train_time:455864ms step_avg:474.86ms
[train step 960] avg_loss=3.388920 main=2.931219 aux=0.457700 imp_cv2=0.1386 load_cv2=5.1596 usage_frac=0.4152 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=11.7917
step:961/1750 train_time:456324ms step_avg:474.84ms
[train step 961] avg_loss=3.688339 main=3.227443 aux=0.460896 imp_cv2=0.1004 load_cv2=5.2384 usage_frac=0.4107 topk_prob_mean=0.2471 ema_alpha_reverse=nan max_logit=11.7917
step:962/1750 train_time:456789ms step_avg:474.83ms
[train step 962] avg_loss=3.532590 main=3.078091 aux=0.454499 imp_cv2=0.1276 load_cv2=5.1342 usage_frac=0.4152 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=11.7917
step:963/1750 train_time:457254ms step_avg:474.82ms
[train step 963] avg_loss=3.465199 main=3.014032 aux=0.451167 imp_cv2=0.1590 load_cv2=5.0627 usage_frac=0.4152 topk_prob_mean=0.2764 ema_alpha_reverse=nan max_logit=11.7917
step:964/1750 train_time:457717ms step_avg:474.81ms
[train step 964] avg_loss=4.028895 main=3.565694 aux=0.463201 imp_cv2=0.0777 load_cv2=5.2945 usage_frac=0.4107 topk_prob_mean=0.2388 ema_alpha_reverse=nan max_logit=11.7917
step:965/1750 train_time:458186ms step_avg:474.80ms
[train step 965] avg_loss=4.258622 main=3.782415 aux=0.476208 imp_cv2=0.0676 load_cv2=5.4645 usage_frac=0.4107 topk_prob_mean=0.2274 ema_alpha_reverse=nan max_logit=11.7917
step:966/1750 train_time:458649ms step_avg:474.79ms
[train step 966] avg_loss=3.902478 main=3.438538 aux=0.463940 imp_cv2=0.0749 load_cv2=5.3058 usage_frac=0.4196 topk_prob_mean=0.2380 ema_alpha_reverse=nan max_logit=11.7917
step:967/1750 train_time:459105ms step_avg:474.77ms
[train step 967] avg_loss=3.651069 main=3.190608 aux=0.460461 imp_cv2=0.1073 load_cv2=5.2347 usage_frac=0.4152 topk_prob_mean=0.2542 ema_alpha_reverse=nan max_logit=11.7917
step:968/1750 train_time:459569ms step_avg:474.76ms
[train step 968] avg_loss=3.575227 main=3.114934 aux=0.460294 imp_cv2=0.1216 load_cv2=5.2168 usage_frac=0.4196 topk_prob_mean=0.2576 ema_alpha_reverse=nan max_logit=11.7917
step:969/1750 train_time:460032ms step_avg:474.75ms
[train step 969] avg_loss=4.545562 main=4.072666 aux=0.472895 imp_cv2=0.0703 load_cv2=5.4263 usage_frac=0.4241 topk_prob_mean=0.2286 ema_alpha_reverse=nan max_logit=11.7917
step:970/1750 train_time:460491ms step_avg:474.73ms
[train step 970] avg_loss=4.347276 main=3.874237 aux=0.473039 imp_cv2=0.0618 load_cv2=5.4322 usage_frac=0.4152 topk_prob_mean=0.2267 ema_alpha_reverse=nan max_logit=11.7917
step:971/1750 train_time:460956ms step_avg:474.72ms
[train step 971] avg_loss=3.962303 main=3.481532 aux=0.480771 imp_cv2=0.0563 load_cv2=5.5284 usage_frac=0.4107 topk_prob_mean=0.2211 ema_alpha_reverse=nan max_logit=11.7917
step:972/1750 train_time:461422ms step_avg:474.71ms
[train step 972] avg_loss=3.534609 main=3.077177 aux=0.457432 imp_cv2=0.1146 load_cv2=5.1877 usage_frac=0.4196 topk_prob_mean=0.2585 ema_alpha_reverse=nan max_logit=11.7917
step:973/1750 train_time:461879ms step_avg:474.70ms
[train step 973] avg_loss=3.262123 main=2.803177 aux=0.458946 imp_cv2=0.1709 load_cv2=5.1526 usage_frac=0.4152 topk_prob_mean=0.2776 ema_alpha_reverse=nan max_logit=11.7917
step:974/1750 train_time:462353ms step_avg:474.69ms
[train step 974] avg_loss=3.662744 main=3.198699 aux=0.464045 imp_cv2=0.1089 load_cv2=5.2777 usage_frac=0.4196 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=11.7917
step:975/1750 train_time:462834ms step_avg:474.70ms
[train step 975] avg_loss=3.998801 main=3.490068 aux=0.508732 imp_cv2=0.0572 load_cv2=5.8563 usage_frac=0.4062 topk_prob_mean=0.1918 ema_alpha_reverse=nan max_logit=11.7917
step:976/1750 train_time:463319ms step_avg:474.71ms
[train step 976] avg_loss=3.656996 main=3.197715 aux=0.459282 imp_cv2=0.1173 load_cv2=5.2064 usage_frac=0.4152 topk_prob_mean=0.2589 ema_alpha_reverse=nan max_logit=11.7917
step:977/1750 train_time:463798ms step_avg:474.72ms
[train step 977] avg_loss=4.487384 main=3.973299 aux=0.514085 imp_cv2=0.0593 load_cv2=5.9211 usage_frac=0.3973 topk_prob_mean=0.1829 ema_alpha_reverse=nan max_logit=11.7917
step:978/1750 train_time:464268ms step_avg:474.71ms
[train step 978] avg_loss=3.516173 main=3.057170 aux=0.459003 imp_cv2=0.1235 load_cv2=5.2017 usage_frac=0.4107 topk_prob_mean=0.2599 ema_alpha_reverse=nan max_logit=11.7917
step:979/1750 train_time:464727ms step_avg:474.70ms
[train step 979] avg_loss=3.958347 main=3.493247 aux=0.465099 imp_cv2=0.0698 load_cv2=5.3301 usage_frac=0.4062 topk_prob_mean=0.2343 ema_alpha_reverse=nan max_logit=11.7917
step:980/1750 train_time:465393ms step_avg:474.89ms
[train step 980] avg_loss=3.701564 main=3.233831 aux=0.467733 imp_cv2=0.0808 load_cv2=5.3511 usage_frac=0.4107 topk_prob_mean=0.2366 ema_alpha_reverse=nan max_logit=11.7917
step:981/1750 train_time:465843ms step_avg:474.87ms
[train step 981] avg_loss=3.358164 main=2.884881 aux=0.473283 imp_cv2=0.0705 load_cv2=5.4309 usage_frac=0.3973 topk_prob_mean=0.2286 ema_alpha_reverse=nan max_logit=11.7917
step:982/1750 train_time:466301ms step_avg:474.85ms
[train step 982] avg_loss=3.798225 main=3.326625 aux=0.471601 imp_cv2=0.0739 load_cv2=5.4107 usage_frac=0.3973 topk_prob_mean=0.2338 ema_alpha_reverse=nan max_logit=10.8091
step:983/1750 train_time:466763ms step_avg:474.84ms
[train step 983] avg_loss=3.687424 main=3.220486 aux=0.466938 imp_cv2=0.0755 load_cv2=5.3468 usage_frac=0.3973 topk_prob_mean=0.2357 ema_alpha_reverse=nan max_logit=11.7917
step:984/1750 train_time:467229ms step_avg:474.83ms
[train step 984] avg_loss=3.343148 main=2.886459 aux=0.456689 imp_cv2=0.3033 load_cv2=5.0003 usage_frac=0.4018 topk_prob_mean=0.3139 ema_alpha_reverse=nan max_logit=11.7917
step:985/1750 train_time:467704ms step_avg:474.83ms
[train step 985] avg_loss=4.014347 main=3.538851 aux=0.475496 imp_cv2=0.0517 load_cv2=5.4778 usage_frac=0.4062 topk_prob_mean=0.2195 ema_alpha_reverse=nan max_logit=11.7917
step:986/1750 train_time:468162ms step_avg:474.81ms
[train step 986] avg_loss=3.751608 main=3.291653 aux=0.459955 imp_cv2=0.0909 load_cv2=5.2443 usage_frac=0.4107 topk_prob_mean=0.2487 ema_alpha_reverse=nan max_logit=11.7917
step:987/1750 train_time:468622ms step_avg:474.79ms
[train step 987] avg_loss=3.486345 main=3.027687 aux=0.458659 imp_cv2=0.1530 load_cv2=5.1715 usage_frac=0.4062 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=11.7917
step:988/1750 train_time:469086ms step_avg:474.78ms
[train step 988] avg_loss=3.634347 main=3.177546 aux=0.456802 imp_cv2=0.1375 load_cv2=5.1574 usage_frac=0.4018 topk_prob_mean=0.2639 ema_alpha_reverse=nan max_logit=11.7917
step:989/1750 train_time:469552ms step_avg:474.77ms
[train step 989] avg_loss=3.539850 main=3.086390 aux=0.453460 imp_cv2=0.1581 load_cv2=5.1003 usage_frac=0.4018 topk_prob_mean=0.2761 ema_alpha_reverse=nan max_logit=11.7917
step:990/1750 train_time:470021ms step_avg:474.77ms
[train step 990] avg_loss=3.671461 main=3.206960 aux=0.464502 imp_cv2=0.0888 load_cv2=5.3004 usage_frac=0.3973 topk_prob_mean=0.2445 ema_alpha_reverse=nan max_logit=11.7917
step:991/1750 train_time:470477ms step_avg:474.75ms
[train step 991] avg_loss=3.509455 main=3.055105 aux=0.454350 imp_cv2=0.1760 load_cv2=5.0927 usage_frac=0.4018 topk_prob_mean=0.2800 ema_alpha_reverse=nan max_logit=11.7917
step:992/1750 train_time:470934ms step_avg:474.73ms
[train step 992] avg_loss=4.111462 main=3.647534 aux=0.463928 imp_cv2=0.0730 load_cv2=5.3196 usage_frac=0.4107 topk_prob_mean=0.2368 ema_alpha_reverse=nan max_logit=11.7917
step:993/1750 train_time:471397ms step_avg:474.72ms
[train step 993] avg_loss=4.183007 main=3.670661 aux=0.512346 imp_cv2=0.0646 load_cv2=5.9103 usage_frac=0.4018 topk_prob_mean=0.1814 ema_alpha_reverse=nan max_logit=11.7917
step:994/1750 train_time:471854ms step_avg:474.70ms
[train step 994] avg_loss=3.915875 main=3.450723 aux=0.465153 imp_cv2=0.0700 load_cv2=5.3325 usage_frac=0.3929 topk_prob_mean=0.2358 ema_alpha_reverse=nan max_logit=11.7917
step:995/1750 train_time:472307ms step_avg:474.68ms
[train step 995] avg_loss=3.327082 main=2.871890 aux=0.455192 imp_cv2=0.2056 load_cv2=5.0764 usage_frac=0.4018 topk_prob_mean=0.2901 ema_alpha_reverse=nan max_logit=11.7917
step:996/1750 train_time:472771ms step_avg:474.67ms
[train step 996] avg_loss=3.496717 main=3.035664 aux=0.461052 imp_cv2=0.1449 load_cv2=5.1992 usage_frac=0.4062 topk_prob_mean=0.2666 ema_alpha_reverse=nan max_logit=11.7917
step:997/1750 train_time:473228ms step_avg:474.65ms
[train step 997] avg_loss=3.719615 main=3.261808 aux=0.457806 imp_cv2=0.1254 load_cv2=5.1797 usage_frac=0.4018 topk_prob_mean=0.2629 ema_alpha_reverse=nan max_logit=11.7917
step:998/1750 train_time:473692ms step_avg:474.64ms
[train step 998] avg_loss=3.396820 main=2.940772 aux=0.456048 imp_cv2=0.2268 load_cv2=5.0519 usage_frac=0.4062 topk_prob_mean=0.2944 ema_alpha_reverse=nan max_logit=11.7917
step:999/1750 train_time:474186ms step_avg:474.66ms
[train step 999] avg_loss=3.822823 main=3.358792 aux=0.464031 imp_cv2=0.1079 load_cv2=5.2757 usage_frac=0.4018 topk_prob_mean=0.2516 ema_alpha_reverse=nan max_logit=11.7917
step:1000/1750 train_time:474664ms step_avg:474.66ms
Running validation...
step:1000/1750 val_loss:3.283574 train_time:474676ms step_avg:474.68ms
[train step 1000] avg_loss=3.806038 main=3.334447 aux=0.471591 imp_cv2=0.0647 load_cv2=5.4079 usage_frac=0.4018 topk_prob_mean=0.2293 ema_alpha_reverse=nan max_logit=11.7917
step:1001/1750 train_time:475130ms step_avg:474.66ms
[train step 1001] avg_loss=3.413640 main=2.956079 aux=0.457561 imp_cv2=0.1305 load_cv2=5.1708 usage_frac=0.4018 topk_prob_mean=0.2629 ema_alpha_reverse=nan max_logit=11.7917
step:1002/1750 train_time:475587ms step_avg:474.64ms
[train step 1002] avg_loss=3.587406 main=3.119647 aux=0.467759 imp_cv2=0.0906 load_cv2=5.3380 usage_frac=0.4018 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=11.7917
step:1003/1750 train_time:476054ms step_avg:474.63ms
[train step 1003] avg_loss=3.562078 main=3.103562 aux=0.458516 imp_cv2=0.1186 load_cv2=5.1985 usage_frac=0.4062 topk_prob_mean=0.2572 ema_alpha_reverse=nan max_logit=11.7917
step:1004/1750 train_time:476520ms step_avg:474.62ms
[train step 1004] avg_loss=3.783534 main=3.325151 aux=0.458383 imp_cv2=0.1119 load_cv2=5.2054 usage_frac=0.4018 topk_prob_mean=0.2521 ema_alpha_reverse=nan max_logit=11.7917
step:1005/1750 train_time:476973ms step_avg:474.60ms
[train step 1005] avg_loss=3.390690 main=2.935754 aux=0.454936 imp_cv2=0.2464 load_cv2=5.0287 usage_frac=0.4107 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=11.7917
step:1006/1750 train_time:477444ms step_avg:474.60ms
[train step 1006] avg_loss=3.786537 main=3.330561 aux=0.455976 imp_cv2=0.1539 load_cv2=5.1327 usage_frac=0.4018 topk_prob_mean=0.2714 ema_alpha_reverse=nan max_logit=11.7917
step:1007/1750 train_time:477920ms step_avg:474.60ms
[train step 1007] avg_loss=3.999407 main=3.468555 aux=0.530852 imp_cv2=0.0556 load_cv2=6.1473 usage_frac=0.3482 topk_prob_mean=0.1753 ema_alpha_reverse=nan max_logit=9.8264
step:1008/1750 train_time:478571ms step_avg:474.77ms
[train step 1008] avg_loss=3.624800 main=3.164894 aux=0.459906 imp_cv2=0.1544 load_cv2=5.1847 usage_frac=0.4062 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=11.7917
step:1009/1750 train_time:479029ms step_avg:474.76ms
[train step 1009] avg_loss=3.979605 main=3.519320 aux=0.460285 imp_cv2=0.1378 load_cv2=5.2072 usage_frac=0.4062 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=11.7917
step:1010/1750 train_time:479493ms step_avg:474.75ms
[train step 1010] avg_loss=4.051347 main=3.575862 aux=0.475485 imp_cv2=0.0879 load_cv2=5.4405 usage_frac=0.4062 topk_prob_mean=0.2373 ema_alpha_reverse=nan max_logit=11.7917
step:1011/1750 train_time:479947ms step_avg:474.73ms
[train step 1011] avg_loss=3.404477 main=2.942901 aux=0.461576 imp_cv2=0.2775 load_cv2=5.0852 usage_frac=0.4062 topk_prob_mean=0.3058 ema_alpha_reverse=nan max_logit=11.7917
step:1012/1750 train_time:480410ms step_avg:474.71ms
[train step 1012] avg_loss=3.944273 main=3.468394 aux=0.475879 imp_cv2=0.0707 load_cv2=5.4612 usage_frac=0.3973 topk_prob_mean=0.2295 ema_alpha_reverse=nan max_logit=11.7917
step:1013/1750 train_time:480862ms step_avg:474.69ms
[train step 1013] avg_loss=3.726258 main=3.262425 aux=0.463833 imp_cv2=0.1707 load_cv2=5.2194 usage_frac=0.4018 topk_prob_mean=0.2746 ema_alpha_reverse=nan max_logit=11.7917
step:1014/1750 train_time:481326ms step_avg:474.68ms
[train step 1014] avg_loss=4.063653 main=3.594933 aux=0.468719 imp_cv2=0.1323 load_cv2=5.3193 usage_frac=0.4018 topk_prob_mean=0.2591 ema_alpha_reverse=nan max_logit=11.7917
step:1015/1750 train_time:481778ms step_avg:474.66ms
[train step 1015] avg_loss=3.639825 main=3.130929 aux=0.508896 imp_cv2=0.0400 load_cv2=5.8954 usage_frac=0.4107 topk_prob_mean=0.1929 ema_alpha_reverse=nan max_logit=11.7917
step:1016/1750 train_time:482236ms step_avg:474.64ms
[train step 1016] avg_loss=3.880312 main=3.388880 aux=0.491431 imp_cv2=0.0520 load_cv2=5.6763 usage_frac=0.3973 topk_prob_mean=0.2097 ema_alpha_reverse=nan max_logit=11.7917
step:1017/1750 train_time:482708ms step_avg:474.64ms
[train step 1017] avg_loss=3.613933 main=3.146100 aux=0.467833 imp_cv2=0.1159 load_cv2=5.3182 usage_frac=0.4018 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=11.7917
step:1018/1750 train_time:483214ms step_avg:474.67ms
[train step 1018] avg_loss=3.350882 main=2.892991 aux=0.457890 imp_cv2=0.2260 load_cv2=5.0912 usage_frac=0.4018 topk_prob_mean=0.2940 ema_alpha_reverse=nan max_logit=11.7917
step:1019/1750 train_time:483680ms step_avg:474.66ms
[train step 1019] avg_loss=3.599013 main=3.139867 aux=0.459147 imp_cv2=0.1808 load_cv2=5.1527 usage_frac=0.4107 topk_prob_mean=0.2801 ema_alpha_reverse=nan max_logit=11.7917
step:1020/1750 train_time:484152ms step_avg:474.66ms
[train step 1020] avg_loss=3.615278 main=3.156745 aux=0.458532 imp_cv2=0.1426 load_cv2=5.1692 usage_frac=0.4062 topk_prob_mean=0.2666 ema_alpha_reverse=nan max_logit=11.7917
step:1021/1750 train_time:484617ms step_avg:474.65ms
[train step 1021] avg_loss=3.432311 main=2.964972 aux=0.467339 imp_cv2=0.1048 load_cv2=5.3255 usage_frac=0.4018 topk_prob_mean=0.2496 ema_alpha_reverse=nan max_logit=11.7917
step:1022/1750 train_time:485072ms step_avg:474.63ms
[train step 1022] avg_loss=4.072789 main=3.562644 aux=0.510145 imp_cv2=0.0560 load_cv2=5.8915 usage_frac=0.3973 topk_prob_mean=0.1854 ema_alpha_reverse=nan max_logit=11.7917
step:1023/1750 train_time:485517ms step_avg:474.60ms
[train step 1023] avg_loss=4.207245 main=3.721193 aux=0.486052 imp_cv2=0.0616 load_cv2=5.5918 usage_frac=0.3929 topk_prob_mean=0.2200 ema_alpha_reverse=nan max_logit=11.7917
step:1024/1750 train_time:486152ms step_avg:474.76ms
[train step 1024] avg_loss=3.532771 main=3.073767 aux=0.459004 imp_cv2=0.1857 load_cv2=5.1486 usage_frac=0.4018 topk_prob_mean=0.2812 ema_alpha_reverse=nan max_logit=11.7917
step:1025/1750 train_time:486602ms step_avg:474.73ms
[train step 1025] avg_loss=3.587375 main=3.123536 aux=0.463839 imp_cv2=0.1231 load_cv2=5.2661 usage_frac=0.4062 topk_prob_mean=0.2596 ema_alpha_reverse=nan max_logit=11.7917
step:1026/1750 train_time:487058ms step_avg:474.72ms
[train step 1026] avg_loss=3.584510 main=3.126617 aux=0.457893 imp_cv2=0.1532 load_cv2=5.1662 usage_frac=0.4018 topk_prob_mean=0.2725 ema_alpha_reverse=nan max_logit=11.7917
step:1027/1750 train_time:487525ms step_avg:474.71ms
[train step 1027] avg_loss=3.745101 main=3.277154 aux=0.467947 imp_cv2=0.0826 load_cv2=5.3559 usage_frac=0.4018 topk_prob_mean=0.2402 ema_alpha_reverse=nan max_logit=11.7917
step:1028/1750 train_time:487984ms step_avg:474.69ms
[train step 1028] avg_loss=3.595827 main=3.138719 aux=0.457109 imp_cv2=0.1644 load_cv2=5.1420 usage_frac=0.4018 topk_prob_mean=0.2762 ema_alpha_reverse=nan max_logit=11.7917
step:1029/1750 train_time:488442ms step_avg:474.68ms
[train step 1029] avg_loss=4.242193 main=3.706670 aux=0.535523 imp_cv2=0.0418 load_cv2=6.2116 usage_frac=0.3527 topk_prob_mean=0.1628 ema_alpha_reverse=nan max_logit=9.8264
step:1030/1750 train_time:488890ms step_avg:474.65ms
[train step 1030] avg_loss=3.868221 main=3.401073 aux=0.467148 imp_cv2=0.0979 load_cv2=5.3328 usage_frac=0.4018 topk_prob_mean=0.2474 ema_alpha_reverse=nan max_logit=11.7917
step:1031/1750 train_time:489346ms step_avg:474.63ms
[train step 1031] avg_loss=3.584912 main=3.122522 aux=0.462389 imp_cv2=0.1168 load_cv2=5.2511 usage_frac=0.4018 topk_prob_mean=0.2569 ema_alpha_reverse=nan max_logit=11.7917
step:1032/1750 train_time:489795ms step_avg:474.61ms
[train step 1032] avg_loss=3.395698 main=2.937246 aux=0.458452 imp_cv2=0.1534 load_cv2=5.1758 usage_frac=0.4062 topk_prob_mean=0.2708 ema_alpha_reverse=nan max_logit=11.7917
step:1033/1750 train_time:490255ms step_avg:474.59ms
[train step 1033] avg_loss=3.668888 main=3.205280 aux=0.463608 imp_cv2=0.0891 load_cv2=5.2940 usage_frac=0.4062 topk_prob_mean=0.2453 ema_alpha_reverse=nan max_logit=11.7917
step:1034/1750 train_time:490727ms step_avg:474.59ms
[train step 1034] avg_loss=3.662416 main=3.204484 aux=0.457933 imp_cv2=0.1505 load_cv2=5.1678 usage_frac=0.4018 topk_prob_mean=0.2693 ema_alpha_reverse=nan max_logit=11.7917
step:1035/1750 train_time:491188ms step_avg:474.58ms
[train step 1035] avg_loss=3.408022 main=2.951507 aux=0.456515 imp_cv2=0.1472 load_cv2=5.1556 usage_frac=0.4018 topk_prob_mean=0.2687 ema_alpha_reverse=nan max_logit=11.7917
step:1036/1750 train_time:491643ms step_avg:474.56ms
[train step 1036] avg_loss=3.513524 main=3.062135 aux=0.451390 imp_cv2=0.1797 load_cv2=5.0573 usage_frac=0.4018 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=11.7917
step:1037/1750 train_time:492110ms step_avg:474.55ms
[train step 1037] avg_loss=4.589939 main=4.117007 aux=0.472932 imp_cv2=0.0731 load_cv2=5.4311 usage_frac=0.4018 topk_prob_mean=0.2303 ema_alpha_reverse=nan max_logit=11.7917
step:1038/1750 train_time:492786ms step_avg:474.75ms
[train step 1038] avg_loss=4.250229 main=3.761420 aux=0.488809 imp_cv2=0.0662 load_cv2=5.6380 usage_frac=0.3973 topk_prob_mean=0.2143 ema_alpha_reverse=nan max_logit=11.7917
step:1039/1750 train_time:493237ms step_avg:474.72ms
[train step 1039] avg_loss=3.521486 main=3.064245 aux=0.457242 imp_cv2=0.1236 load_cv2=5.1886 usage_frac=0.4018 topk_prob_mean=0.2616 ema_alpha_reverse=nan max_logit=11.7917
step:1040/1750 train_time:493700ms step_avg:474.71ms
[train step 1040] avg_loss=3.765472 main=3.306098 aux=0.459374 imp_cv2=0.0929 load_cv2=5.2456 usage_frac=0.4062 topk_prob_mean=0.2494 ema_alpha_reverse=nan max_logit=11.7917
step:1041/1750 train_time:494161ms step_avg:474.70ms
[train step 1041] avg_loss=4.403107 main=3.910754 aux=0.492353 imp_cv2=0.0431 load_cv2=5.6881 usage_frac=0.4018 topk_prob_mean=0.1968 ema_alpha_reverse=nan max_logit=11.7917
step:1042/1750 train_time:494797ms step_avg:474.85ms
[train step 1042] avg_loss=3.594451 main=3.119322 aux=0.475130 imp_cv2=0.0482 load_cv2=5.4849 usage_frac=0.4018 topk_prob_mean=0.2184 ema_alpha_reverse=nan max_logit=11.7917
step:1043/1750 train_time:495261ms step_avg:474.84ms
[train step 1043] avg_loss=3.559382 main=3.104891 aux=0.454491 imp_cv2=0.1383 load_cv2=5.1352 usage_frac=0.3973 topk_prob_mean=0.2704 ema_alpha_reverse=nan max_logit=11.7917
step:1044/1750 train_time:495721ms step_avg:474.83ms
[train step 1044] avg_loss=3.564860 main=3.109532 aux=0.455328 imp_cv2=0.1486 load_cv2=5.1351 usage_frac=0.4062 topk_prob_mean=0.2725 ema_alpha_reverse=nan max_logit=11.7917
step:1045/1750 train_time:496178ms step_avg:474.81ms
[train step 1045] avg_loss=4.660707 main=4.139652 aux=0.521055 imp_cv2=0.0433 load_cv2=6.0474 usage_frac=0.3616 topk_prob_mean=0.1698 ema_alpha_reverse=nan max_logit=9.8264
step:1046/1750 train_time:496626ms step_avg:474.79ms
[train step 1046] avg_loss=3.843634 main=3.384396 aux=0.459238 imp_cv2=0.1092 load_cv2=5.2137 usage_frac=0.4062 topk_prob_mean=0.2529 ema_alpha_reverse=nan max_logit=11.7917
step:1047/1750 train_time:497095ms step_avg:474.78ms
[train step 1047] avg_loss=4.043505 main=3.560977 aux=0.482527 imp_cv2=0.0549 load_cv2=5.5599 usage_frac=0.4018 topk_prob_mean=0.2178 ema_alpha_reverse=nan max_logit=11.7917
step:1048/1750 train_time:497559ms step_avg:474.77ms
[train step 1048] avg_loss=3.407996 main=2.953634 aux=0.454363 imp_cv2=0.1835 load_cv2=5.0897 usage_frac=0.4062 topk_prob_mean=0.2825 ema_alpha_reverse=nan max_logit=11.7917
step:1049/1750 train_time:498015ms step_avg:474.75ms
[train step 1049] avg_loss=3.666298 main=3.193675 aux=0.472623 imp_cv2=0.0645 load_cv2=5.4245 usage_frac=0.4018 topk_prob_mean=0.2290 ema_alpha_reverse=nan max_logit=11.7917
step:1050/1750 train_time:498472ms step_avg:474.74ms
Running validation...
step:1050/1750 val_loss:3.234645 train_time:498484ms step_avg:474.75ms
[train step 1050] avg_loss=3.471812 main=3.011376 aux=0.460436 imp_cv2=0.1256 load_cv2=5.2179 usage_frac=0.3884 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=11.7917
step:1051/1750 train_time:498919ms step_avg:474.71ms
[train step 1051] avg_loss=4.512384 main=4.016264 aux=0.496119 imp_cv2=0.0364 load_cv2=5.7486 usage_frac=0.3929 topk_prob_mean=0.1942 ema_alpha_reverse=nan max_logit=11.7917
step:1052/1750 train_time:499368ms step_avg:474.68ms
[train step 1052] avg_loss=3.756489 main=3.297974 aux=0.458515 imp_cv2=0.1090 load_cv2=5.2175 usage_frac=0.3973 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:1053/1750 train_time:499833ms step_avg:474.68ms
[train step 1053] avg_loss=3.993686 main=3.510665 aux=0.483021 imp_cv2=0.0451 load_cv2=5.5835 usage_frac=0.3929 topk_prob_mean=0.2117 ema_alpha_reverse=nan max_logit=11.7917
step:1054/1750 train_time:500290ms step_avg:474.66ms
[train step 1054] avg_loss=3.527187 main=3.071216 aux=0.455972 imp_cv2=0.1474 load_cv2=5.1502 usage_frac=0.4018 topk_prob_mean=0.2710 ema_alpha_reverse=nan max_logit=11.7917
step:1055/1750 train_time:500744ms step_avg:474.64ms
[train step 1055] avg_loss=4.274588 main=3.772385 aux=0.502203 imp_cv2=0.0417 load_cv2=5.8115 usage_frac=0.3884 topk_prob_mean=0.1910 ema_alpha_reverse=nan max_logit=11.6103
step:1056/1750 train_time:501197ms step_avg:474.62ms
[train step 1056] avg_loss=3.576587 main=3.123201 aux=0.453386 imp_cv2=0.2141 load_cv2=5.0455 usage_frac=0.4018 topk_prob_mean=0.2931 ema_alpha_reverse=nan max_logit=11.7917
step:1057/1750 train_time:501664ms step_avg:474.61ms
[train step 1057] avg_loss=3.440833 main=2.985933 aux=0.454900 imp_cv2=0.2301 load_cv2=5.0439 usage_frac=0.3973 topk_prob_mean=0.2955 ema_alpha_reverse=nan max_logit=11.7917
step:1058/1750 train_time:502138ms step_avg:474.61ms
[train step 1058] avg_loss=4.016033 main=3.540902 aux=0.475131 imp_cv2=0.0852 load_cv2=5.4520 usage_frac=0.3929 topk_prob_mean=0.2349 ema_alpha_reverse=nan max_logit=11.7917
step:1059/1750 train_time:502592ms step_avg:474.59ms
[train step 1059] avg_loss=4.462882 main=3.964578 aux=0.498305 imp_cv2=0.0432 load_cv2=5.7618 usage_frac=0.3884 topk_prob_mean=0.1980 ema_alpha_reverse=nan max_logit=11.7917
step:1060/1750 train_time:503043ms step_avg:474.57ms
[train step 1060] avg_loss=3.567875 main=3.107193 aux=0.460682 imp_cv2=0.0999 load_cv2=5.2523 usage_frac=0.3973 topk_prob_mean=0.2534 ema_alpha_reverse=nan max_logit=11.7917
step:1061/1750 train_time:503500ms step_avg:474.55ms
[train step 1061] avg_loss=3.701987 main=3.241401 aux=0.460585 imp_cv2=0.1085 load_cv2=5.2443 usage_frac=0.3973 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=11.7917
step:1062/1750 train_time:503957ms step_avg:474.54ms
[train step 1062] avg_loss=3.849709 main=3.383739 aux=0.465971 imp_cv2=0.0784 load_cv2=5.3428 usage_frac=0.3973 topk_prob_mean=0.2402 ema_alpha_reverse=nan max_logit=11.7917
step:1063/1750 train_time:504422ms step_avg:474.53ms
[train step 1063] avg_loss=3.400667 main=2.948122 aux=0.452545 imp_cv2=0.2348 load_cv2=5.0230 usage_frac=0.3973 topk_prob_mean=0.3006 ema_alpha_reverse=nan max_logit=11.7917
step:1064/1750 train_time:504879ms step_avg:474.51ms
[train step 1064] avg_loss=3.766701 main=3.287666 aux=0.479035 imp_cv2=0.0437 load_cv2=5.5380 usage_frac=0.3929 topk_prob_mean=0.2128 ema_alpha_reverse=nan max_logit=11.7917
step:1065/1750 train_time:505344ms step_avg:474.50ms
[train step 1065] avg_loss=3.503102 main=3.049386 aux=0.453716 imp_cv2=0.1569 load_cv2=5.1147 usage_frac=0.3929 topk_prob_mean=0.2771 ema_alpha_reverse=nan max_logit=11.7917
step:1066/1750 train_time:505812ms step_avg:474.49ms
[train step 1066] avg_loss=4.210527 main=3.746221 aux=0.464306 imp_cv2=0.0836 load_cv2=5.3120 usage_frac=0.4018 topk_prob_mean=0.2446 ema_alpha_reverse=nan max_logit=11.7917
step:1067/1750 train_time:506264ms step_avg:474.47ms
[train step 1067] avg_loss=3.530383 main=3.071888 aux=0.458495 imp_cv2=0.1153 load_cv2=5.2065 usage_frac=0.4062 topk_prob_mean=0.2587 ema_alpha_reverse=nan max_logit=11.7917
step:1068/1750 train_time:506719ms step_avg:474.46ms
[train step 1068] avg_loss=4.006365 main=3.550195 aux=0.456170 imp_cv2=0.1282 load_cv2=5.1722 usage_frac=0.4018 topk_prob_mean=0.2651 ema_alpha_reverse=nan max_logit=11.7917
step:1069/1750 train_time:507176ms step_avg:474.44ms
[train step 1069] avg_loss=3.600615 main=3.144737 aux=0.455878 imp_cv2=0.1210 load_cv2=5.1722 usage_frac=0.4062 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=11.7917
step:1070/1750 train_time:507640ms step_avg:474.43ms
[train step 1070] avg_loss=3.833202 main=3.357864 aux=0.475337 imp_cv2=0.0694 load_cv2=5.4627 usage_frac=0.3973 topk_prob_mean=0.2290 ema_alpha_reverse=nan max_logit=11.7917
step:1071/1750 train_time:508084ms step_avg:474.40ms
[train step 1071] avg_loss=3.482473 main=3.024421 aux=0.458052 imp_cv2=0.2105 load_cv2=5.1117 usage_frac=0.4018 topk_prob_mean=0.2880 ema_alpha_reverse=nan max_logit=11.7917
step:1072/1750 train_time:508537ms step_avg:474.38ms
[train step 1072] avg_loss=4.176879 main=3.712118 aux=0.464761 imp_cv2=0.1015 load_cv2=5.3043 usage_frac=0.4018 topk_prob_mean=0.2486 ema_alpha_reverse=nan max_logit=11.7917
step:1073/1750 train_time:508994ms step_avg:474.37ms
[train step 1073] avg_loss=5.739568 main=5.230002 aux=0.509566 imp_cv2=0.0587 load_cv2=5.8878 usage_frac=0.3973 topk_prob_mean=0.1913 ema_alpha_reverse=nan max_logit=11.7917
step:1074/1750 train_time:509444ms step_avg:474.34ms
[train step 1074] avg_loss=3.630054 main=3.157772 aux=0.472281 imp_cv2=0.0847 load_cv2=5.4060 usage_frac=0.4107 topk_prob_mean=0.2389 ema_alpha_reverse=nan max_logit=11.7917
step:1075/1750 train_time:509902ms step_avg:474.33ms
[train step 1075] avg_loss=3.476238 main=3.010362 aux=0.465876 imp_cv2=0.1711 load_cv2=5.2336 usage_frac=0.4018 topk_prob_mean=0.2740 ema_alpha_reverse=nan max_logit=11.7917
step:1076/1750 train_time:510367ms step_avg:474.32ms
[train step 1076] avg_loss=3.842987 main=3.368724 aux=0.474262 imp_cv2=0.0997 load_cv2=5.4058 usage_frac=0.4062 topk_prob_mean=0.2459 ema_alpha_reverse=nan max_logit=11.7917
step:1077/1750 train_time:510811ms step_avg:474.29ms
[train step 1077] avg_loss=3.996623 main=3.530216 aux=0.466407 imp_cv2=0.1389 load_cv2=5.2762 usage_frac=0.4107 topk_prob_mean=0.2629 ema_alpha_reverse=nan max_logit=11.7917
step:1078/1750 train_time:511278ms step_avg:474.28ms
[train step 1078] avg_loss=3.540957 main=3.075698 aux=0.465259 imp_cv2=0.1307 load_cv2=5.2742 usage_frac=0.4062 topk_prob_mean=0.2584 ema_alpha_reverse=nan max_logit=11.7917
step:1079/1750 train_time:511733ms step_avg:474.27ms
[train step 1079] avg_loss=3.539340 main=3.076356 aux=0.462984 imp_cv2=0.1667 load_cv2=5.2051 usage_frac=0.4062 topk_prob_mean=0.2715 ema_alpha_reverse=nan max_logit=11.7917
step:1080/1750 train_time:512197ms step_avg:474.26ms
[train step 1080] avg_loss=3.385199 main=2.924021 aux=0.461178 imp_cv2=0.1636 load_cv2=5.1856 usage_frac=0.4062 topk_prob_mean=0.2716 ema_alpha_reverse=nan max_logit=11.7917
step:1081/1750 train_time:512655ms step_avg:474.24ms
[train step 1081] avg_loss=3.513287 main=3.047466 aux=0.465821 imp_cv2=0.1734 load_cv2=5.2364 usage_frac=0.4062 topk_prob_mean=0.2748 ema_alpha_reverse=nan max_logit=11.7917
step:1082/1750 train_time:513123ms step_avg:474.24ms
[train step 1082] avg_loss=3.788798 main=3.322980 aux=0.465818 imp_cv2=0.1679 load_cv2=5.2417 usage_frac=0.4062 topk_prob_mean=0.2751 ema_alpha_reverse=nan max_logit=11.7917
step:1083/1750 train_time:513576ms step_avg:474.22ms
[train step 1083] avg_loss=3.826471 main=3.357236 aux=0.469235 imp_cv2=0.1269 load_cv2=5.3236 usage_frac=0.4062 topk_prob_mean=0.2596 ema_alpha_reverse=nan max_logit=11.7917
step:1084/1750 train_time:514038ms step_avg:474.20ms
[train step 1084] avg_loss=3.522857 main=3.056533 aux=0.466325 imp_cv2=0.1555 load_cv2=5.2658 usage_frac=0.4062 topk_prob_mean=0.2683 ema_alpha_reverse=nan max_logit=11.7917
step:1085/1750 train_time:514494ms step_avg:474.19ms
[train step 1085] avg_loss=3.604080 main=3.137301 aux=0.466779 imp_cv2=0.1658 load_cv2=5.2588 usage_frac=0.4018 topk_prob_mean=0.2727 ema_alpha_reverse=nan max_logit=11.7917
step:1086/1750 train_time:514966ms step_avg:474.19ms
[train step 1086] avg_loss=3.647326 main=3.177792 aux=0.469535 imp_cv2=0.1289 load_cv2=5.3282 usage_frac=0.4107 topk_prob_mean=0.2607 ema_alpha_reverse=nan max_logit=11.7917
step:1087/1750 train_time:515431ms step_avg:474.18ms
[train step 1087] avg_loss=3.749277 main=3.281818 aux=0.467458 imp_cv2=0.1088 load_cv2=5.3220 usage_frac=0.4018 topk_prob_mean=0.2525 ema_alpha_reverse=nan max_logit=11.7917
step:1088/1750 train_time:515886ms step_avg:474.16ms
[train step 1088] avg_loss=3.451612 main=2.983491 aux=0.468121 imp_cv2=0.1091 load_cv2=5.3329 usage_frac=0.4018 topk_prob_mean=0.2502 ema_alpha_reverse=nan max_logit=11.7917
step:1089/1750 train_time:516349ms step_avg:474.15ms
[train step 1089] avg_loss=3.623230 main=3.159611 aux=0.463620 imp_cv2=0.1194 load_cv2=5.2668 usage_frac=0.4018 topk_prob_mean=0.2575 ema_alpha_reverse=nan max_logit=11.7917
step:1090/1750 train_time:516808ms step_avg:474.14ms
[train step 1090] avg_loss=3.621978 main=3.160867 aux=0.461110 imp_cv2=0.1563 load_cv2=5.1930 usage_frac=0.4062 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=11.7917
step:1091/1750 train_time:517276ms step_avg:474.13ms
[train step 1091] avg_loss=3.507916 main=3.044816 aux=0.463100 imp_cv2=0.1080 load_cv2=5.2660 usage_frac=0.4107 topk_prob_mean=0.2561 ema_alpha_reverse=nan max_logit=11.7917
step:1092/1750 train_time:517727ms step_avg:474.11ms
[train step 1092] avg_loss=4.655128 main=4.153063 aux=0.502065 imp_cv2=0.0465 load_cv2=5.8139 usage_frac=0.4018 topk_prob_mean=0.1909 ema_alpha_reverse=nan max_logit=11.7917
step:1093/1750 train_time:518190ms step_avg:474.10ms
[train step 1093] avg_loss=3.584016 main=3.114174 aux=0.469842 imp_cv2=0.1129 load_cv2=5.3463 usage_frac=0.4062 topk_prob_mean=0.2523 ema_alpha_reverse=nan max_logit=11.7917
step:1094/1750 train_time:518642ms step_avg:474.08ms
[train step 1094] avg_loss=3.611608 main=3.144954 aux=0.466654 imp_cv2=0.1475 load_cv2=5.2787 usage_frac=0.4062 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=11.7917
step:1095/1750 train_time:519102ms step_avg:474.07ms
[train step 1095] avg_loss=3.523500 main=3.056269 aux=0.467231 imp_cv2=0.1386 load_cv2=5.2860 usage_frac=0.4062 topk_prob_mean=0.2629 ema_alpha_reverse=nan max_logit=11.7917
step:1096/1750 train_time:519555ms step_avg:474.05ms
[train step 1096] avg_loss=3.853943 main=3.388348 aux=0.465595 imp_cv2=0.1345 load_cv2=5.2751 usage_frac=0.4062 topk_prob_mean=0.2646 ema_alpha_reverse=nan max_logit=11.7917
step:1097/1750 train_time:520253ms step_avg:474.25ms
[train step 1097] avg_loss=3.476867 main=3.013571 aux=0.463296 imp_cv2=0.1404 load_cv2=5.2344 usage_frac=0.3973 topk_prob_mean=0.2660 ema_alpha_reverse=nan max_logit=11.7917
step:1098/1750 train_time:520712ms step_avg:474.24ms
[train step 1098] avg_loss=3.665944 main=3.195610 aux=0.470334 imp_cv2=0.0922 load_cv2=5.3678 usage_frac=0.4062 topk_prob_mean=0.2445 ema_alpha_reverse=nan max_logit=11.7917
step:1099/1750 train_time:521172ms step_avg:474.22ms
[train step 1099] avg_loss=3.467451 main=3.010372 aux=0.457079 imp_cv2=0.1561 load_cv2=5.1426 usage_frac=0.4107 topk_prob_mean=0.2760 ema_alpha_reverse=nan max_logit=11.7917
step:1100/1750 train_time:521638ms step_avg:474.22ms
Running validation...
step:1100/1750 val_loss:3.211464 train_time:521649ms step_avg:474.23ms
[train step 1100] avg_loss=3.564851 main=3.106456 aux=0.458395 imp_cv2=0.1168 load_cv2=5.2041 usage_frac=0.4018 topk_prob_mean=0.2606 ema_alpha_reverse=nan max_logit=11.7917
step:1101/1750 train_time:522103ms step_avg:474.21ms
[train step 1101] avg_loss=3.813603 main=3.352009 aux=0.461594 imp_cv2=0.1164 load_cv2=5.2376 usage_frac=0.4062 topk_prob_mean=0.2583 ema_alpha_reverse=nan max_logit=11.7917
step:1102/1750 train_time:522564ms step_avg:474.20ms
[train step 1102] avg_loss=3.695314 main=3.227135 aux=0.468179 imp_cv2=0.0735 load_cv2=5.3735 usage_frac=0.4018 topk_prob_mean=0.2365 ema_alpha_reverse=nan max_logit=11.7917
step:1103/1750 train_time:523020ms step_avg:474.18ms
[train step 1103] avg_loss=3.852291 main=3.385059 aux=0.467232 imp_cv2=0.0904 load_cv2=5.3382 usage_frac=0.4018 topk_prob_mean=0.2436 ema_alpha_reverse=nan max_logit=11.7917
step:1104/1750 train_time:523482ms step_avg:474.17ms
[train step 1104] avg_loss=3.776374 main=3.310719 aux=0.465654 imp_cv2=0.0927 load_cv2=5.3103 usage_frac=0.4018 topk_prob_mean=0.2465 ema_alpha_reverse=nan max_logit=11.7917
step:1105/1750 train_time:523937ms step_avg:474.15ms
[train step 1105] avg_loss=3.654617 main=3.200537 aux=0.454080 imp_cv2=0.1554 load_cv2=5.1032 usage_frac=0.4018 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:1106/1750 train_time:524405ms step_avg:474.15ms
[train step 1106] avg_loss=3.198194 main=2.748653 aux=0.449540 imp_cv2=0.2297 load_cv2=4.9799 usage_frac=0.4018 topk_prob_mean=0.2991 ema_alpha_reverse=nan max_logit=11.7917
step:1107/1750 train_time:524868ms step_avg:474.14ms
[train step 1107] avg_loss=3.475449 main=3.022835 aux=0.452614 imp_cv2=0.1784 load_cv2=5.0750 usage_frac=0.4018 topk_prob_mean=0.2813 ema_alpha_reverse=nan max_logit=11.7917
step:1108/1750 train_time:525350ms step_avg:474.14ms
[train step 1108] avg_loss=3.496319 main=3.038236 aux=0.458083 imp_cv2=0.1160 load_cv2=5.2039 usage_frac=0.3973 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=11.7917
step:1109/1750 train_time:525824ms step_avg:474.14ms
[train step 1109] avg_loss=4.013848 main=3.544875 aux=0.468972 imp_cv2=0.0700 load_cv2=5.3859 usage_frac=0.4018 topk_prob_mean=0.2342 ema_alpha_reverse=nan max_logit=11.7917
step:1110/1750 train_time:526272ms step_avg:474.12ms
[train step 1110] avg_loss=3.816766 main=3.352849 aux=0.463917 imp_cv2=0.0967 load_cv2=5.2979 usage_frac=0.4018 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:1111/1750 train_time:526725ms step_avg:474.10ms
[train step 1111] avg_loss=3.410215 main=2.957723 aux=0.452491 imp_cv2=0.1545 load_cv2=5.0957 usage_frac=0.4018 topk_prob_mean=0.2786 ema_alpha_reverse=nan max_logit=11.7917
step:1112/1750 train_time:527182ms step_avg:474.08ms
[train step 1112] avg_loss=3.755980 main=3.277699 aux=0.478282 imp_cv2=0.0545 load_cv2=5.5245 usage_frac=0.3973 topk_prob_mean=0.2227 ema_alpha_reverse=nan max_logit=11.7917
step:1113/1750 train_time:527640ms step_avg:474.07ms
[train step 1113] avg_loss=3.786381 main=3.330119 aux=0.456261 imp_cv2=0.1317 load_cv2=5.1631 usage_frac=0.4018 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=11.7917
step:1114/1750 train_time:528095ms step_avg:474.05ms
[train step 1114] avg_loss=3.921411 main=3.448901 aux=0.472509 imp_cv2=0.0639 load_cv2=5.4346 usage_frac=0.4018 topk_prob_mean=0.2250 ema_alpha_reverse=nan max_logit=11.7917
step:1115/1750 train_time:528550ms step_avg:474.04ms
[train step 1115] avg_loss=3.821911 main=3.354089 aux=0.467823 imp_cv2=0.0788 load_cv2=5.3494 usage_frac=0.3973 topk_prob_mean=0.2384 ema_alpha_reverse=nan max_logit=11.7917
step:1116/1750 train_time:529007ms step_avg:474.02ms
[train step 1116] avg_loss=3.761008 main=3.298129 aux=0.462879 imp_cv2=0.0786 load_cv2=5.3013 usage_frac=0.4018 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=11.7917
step:1117/1750 train_time:529469ms step_avg:474.01ms
[train step 1117] avg_loss=3.664075 main=3.206915 aux=0.457160 imp_cv2=0.1331 load_cv2=5.1729 usage_frac=0.4062 topk_prob_mean=0.2646 ema_alpha_reverse=nan max_logit=11.7917
step:1118/1750 train_time:529925ms step_avg:473.99ms
[train step 1118] avg_loss=3.609631 main=3.141034 aux=0.468596 imp_cv2=0.0594 load_cv2=5.3928 usage_frac=0.3973 topk_prob_mean=0.2283 ema_alpha_reverse=nan max_logit=12.7744
step:1119/1750 train_time:530380ms step_avg:473.98ms
[train step 1119] avg_loss=3.364178 main=2.916809 aux=0.447369 imp_cv2=0.1895 load_cv2=4.9938 usage_frac=0.3973 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=11.7917
step:1120/1750 train_time:530843ms step_avg:473.97ms
[train step 1120] avg_loss=4.344236 main=3.863189 aux=0.481047 imp_cv2=0.0474 load_cv2=5.5571 usage_frac=0.4018 topk_prob_mean=0.2147 ema_alpha_reverse=nan max_logit=11.7917
step:1121/1750 train_time:531298ms step_avg:473.95ms
[train step 1121] avg_loss=3.731697 main=3.276251 aux=0.455446 imp_cv2=0.1150 load_cv2=5.1694 usage_frac=0.3929 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=11.7917
step:1122/1750 train_time:531754ms step_avg:473.93ms
[train step 1122] avg_loss=3.683754 main=3.219442 aux=0.464311 imp_cv2=0.0821 load_cv2=5.3112 usage_frac=0.4018 topk_prob_mean=0.2432 ema_alpha_reverse=nan max_logit=11.7917
step:1123/1750 train_time:532215ms step_avg:473.92ms
[train step 1123] avg_loss=3.423156 main=2.966588 aux=0.456568 imp_cv2=0.1384 load_cv2=5.1574 usage_frac=0.4062 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=11.7917
step:1124/1750 train_time:532677ms step_avg:473.91ms
[train step 1124] avg_loss=3.380289 main=2.928827 aux=0.451463 imp_cv2=0.1307 load_cv2=5.1080 usage_frac=0.4018 topk_prob_mean=0.2688 ema_alpha_reverse=nan max_logit=11.7917
step:1125/1750 train_time:533138ms step_avg:473.90ms
[train step 1125] avg_loss=3.556868 main=3.102564 aux=0.454304 imp_cv2=0.1274 load_cv2=5.1408 usage_frac=0.4018 topk_prob_mean=0.2663 ema_alpha_reverse=nan max_logit=11.7917
step:1126/1750 train_time:533599ms step_avg:473.89ms
[train step 1126] avg_loss=3.708367 main=3.247384 aux=0.460983 imp_cv2=0.0821 load_cv2=5.2759 usage_frac=0.4107 topk_prob_mean=0.2457 ema_alpha_reverse=nan max_logit=11.9809
step:1127/1750 train_time:534060ms step_avg:473.88ms
[train step 1127] avg_loss=3.816203 main=3.352325 aux=0.463878 imp_cv2=0.0763 load_cv2=5.3166 usage_frac=0.4152 topk_prob_mean=0.2407 ema_alpha_reverse=nan max_logit=12.0654
step:1128/1750 train_time:534519ms step_avg:473.86ms
[train step 1128] avg_loss=3.328831 main=2.874576 aux=0.454255 imp_cv2=0.1188 load_cv2=5.1497 usage_frac=0.4062 topk_prob_mean=0.2636 ema_alpha_reverse=nan max_logit=12.2891
step:1129/1750 train_time:534973ms step_avg:473.85ms
[train step 1129] avg_loss=3.649607 main=3.197458 aux=0.452150 imp_cv2=0.1400 load_cv2=5.1134 usage_frac=0.4062 topk_prob_mean=0.2720 ema_alpha_reverse=nan max_logit=12.7501
step:1130/1750 train_time:535431ms step_avg:473.83ms
[train step 1130] avg_loss=3.592583 main=3.134928 aux=0.457655 imp_cv2=0.1072 load_cv2=5.2044 usage_frac=0.4107 topk_prob_mean=0.2577 ema_alpha_reverse=nan max_logit=11.7917
step:1131/1750 train_time:535885ms step_avg:473.82ms
[train step 1131] avg_loss=3.598662 main=3.148037 aux=0.450625 imp_cv2=0.1446 load_cv2=5.0893 usage_frac=0.4107 topk_prob_mean=0.2724 ema_alpha_reverse=nan max_logit=12.7744
step:1132/1750 train_time:536348ms step_avg:473.81ms
[train step 1132] avg_loss=3.556318 main=3.099039 aux=0.457279 imp_cv2=0.1257 load_cv2=5.1816 usage_frac=0.4107 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=12.0230
step:1133/1750 train_time:536807ms step_avg:473.79ms
[train step 1133] avg_loss=3.989357 main=3.532242 aux=0.457115 imp_cv2=0.1547 load_cv2=5.1614 usage_frac=0.4062 topk_prob_mean=0.2749 ema_alpha_reverse=nan max_logit=11.7917
step:1134/1750 train_time:537261ms step_avg:473.77ms
[train step 1134] avg_loss=3.890247 main=3.418853 aux=0.471394 imp_cv2=0.0636 load_cv2=5.4300 usage_frac=0.4062 topk_prob_mean=0.2311 ema_alpha_reverse=nan max_logit=11.7917
step:1135/1750 train_time:537713ms step_avg:473.76ms
[train step 1135] avg_loss=3.770018 main=3.305224 aux=0.464795 imp_cv2=0.0994 load_cv2=5.2947 usage_frac=0.4062 topk_prob_mean=0.2487 ema_alpha_reverse=nan max_logit=11.7917
step:1136/1750 train_time:538171ms step_avg:473.74ms
[train step 1136] avg_loss=3.877679 main=3.405009 aux=0.472670 imp_cv2=0.0780 load_cv2=5.4251 usage_frac=0.4062 topk_prob_mean=0.2371 ema_alpha_reverse=nan max_logit=11.7917
step:1137/1750 train_time:538620ms step_avg:473.72ms
[train step 1137] avg_loss=3.331167 main=2.873513 aux=0.457654 imp_cv2=0.1324 load_cv2=5.1872 usage_frac=0.4107 topk_prob_mean=0.2677 ema_alpha_reverse=nan max_logit=11.7917
step:1138/1750 train_time:539081ms step_avg:473.71ms
[train step 1138] avg_loss=4.033396 main=3.547269 aux=0.486127 imp_cv2=0.0438 load_cv2=5.6227 usage_frac=0.4018 topk_prob_mean=0.2100 ema_alpha_reverse=nan max_logit=11.7917
step:1139/1750 train_time:539544ms step_avg:473.70ms
[train step 1139] avg_loss=3.932109 main=3.453925 aux=0.478184 imp_cv2=0.0515 load_cv2=5.5201 usage_frac=0.4018 topk_prob_mean=0.2201 ema_alpha_reverse=nan max_logit=11.7917
step:1140/1750 train_time:539998ms step_avg:473.68ms
[train step 1140] avg_loss=3.601535 main=3.133151 aux=0.468384 imp_cv2=0.0998 load_cv2=5.3482 usage_frac=0.4107 topk_prob_mean=0.2485 ema_alpha_reverse=nan max_logit=11.7917
step:1141/1750 train_time:540467ms step_avg:473.68ms
[train step 1141] avg_loss=3.612210 main=3.141151 aux=0.471059 imp_cv2=0.0692 load_cv2=5.4089 usage_frac=0.4018 topk_prob_mean=0.2342 ema_alpha_reverse=nan max_logit=11.7917
step:1142/1750 train_time:540927ms step_avg:473.67ms
[train step 1142] avg_loss=3.397552 main=2.941966 aux=0.455586 imp_cv2=0.1705 load_cv2=5.1112 usage_frac=0.4062 topk_prob_mean=0.2782 ema_alpha_reverse=nan max_logit=11.7917
step:1143/1750 train_time:541393ms step_avg:473.66ms
[train step 1143] avg_loss=3.734782 main=3.257235 aux=0.477548 imp_cv2=0.0622 load_cv2=5.4949 usage_frac=0.3973 topk_prob_mean=0.2259 ema_alpha_reverse=nan max_logit=11.7917
step:1144/1750 train_time:541846ms step_avg:473.64ms
[train step 1144] avg_loss=4.204258 main=3.725965 aux=0.478292 imp_cv2=0.0557 load_cv2=5.5160 usage_frac=0.4018 topk_prob_mean=0.2220 ema_alpha_reverse=nan max_logit=11.7917
step:1145/1750 train_time:542301ms step_avg:473.63ms
[train step 1145] avg_loss=3.550009 main=3.075608 aux=0.474401 imp_cv2=0.0565 load_cv2=5.4644 usage_frac=0.4062 topk_prob_mean=0.2246 ema_alpha_reverse=nan max_logit=11.7917
step:1146/1750 train_time:542767ms step_avg:473.62ms
[train step 1146] avg_loss=3.726134 main=3.272262 aux=0.453872 imp_cv2=0.1581 load_cv2=5.1088 usage_frac=0.4018 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=11.7917
step:1147/1750 train_time:543229ms step_avg:473.61ms
[train step 1147] avg_loss=3.736422 main=3.278764 aux=0.457658 imp_cv2=0.1312 load_cv2=5.1829 usage_frac=0.4062 topk_prob_mean=0.2637 ema_alpha_reverse=nan max_logit=11.7917
step:1148/1750 train_time:543705ms step_avg:473.61ms
[train step 1148] avg_loss=3.725467 main=3.252567 aux=0.472900 imp_cv2=0.0572 load_cv2=5.4451 usage_frac=0.4018 topk_prob_mean=0.2238 ema_alpha_reverse=nan max_logit=11.7917
step:1149/1750 train_time:544159ms step_avg:473.59ms
[train step 1149] avg_loss=3.385308 main=2.929063 aux=0.456245 imp_cv2=0.1260 load_cv2=5.1728 usage_frac=0.4062 topk_prob_mean=0.2641 ema_alpha_reverse=nan max_logit=11.7917
step:1150/1750 train_time:544612ms step_avg:473.58ms
Running validation...
step:1150/1750 val_loss:3.175525 train_time:544624ms step_avg:473.59ms
[train step 1150] avg_loss=3.478251 main=2.973274 aux=0.504977 imp_cv2=0.0504 load_cv2=5.8378 usage_frac=0.3884 topk_prob_mean=0.1899 ema_alpha_reverse=nan max_logit=11.6325
step:1151/1750 train_time:545060ms step_avg:473.55ms
[train step 1151] avg_loss=3.249485 main=2.794410 aux=0.455075 imp_cv2=0.2319 load_cv2=5.0544 usage_frac=0.4062 topk_prob_mean=0.2959 ema_alpha_reverse=nan max_logit=11.7917
step:1152/1750 train_time:545542ms step_avg:473.56ms
[train step 1152] avg_loss=3.663950 main=3.208564 aux=0.455386 imp_cv2=0.1496 load_cv2=5.1345 usage_frac=0.4062 topk_prob_mean=0.2735 ema_alpha_reverse=nan max_logit=11.7917
step:1153/1750 train_time:546002ms step_avg:473.55ms
[train step 1153] avg_loss=3.589759 main=3.135061 aux=0.454698 imp_cv2=0.1765 load_cv2=5.0980 usage_frac=0.4107 topk_prob_mean=0.2809 ema_alpha_reverse=nan max_logit=11.7917
step:1154/1750 train_time:546460ms step_avg:473.54ms
[train step 1154] avg_loss=3.677260 main=3.213729 aux=0.463530 imp_cv2=0.1083 load_cv2=5.2752 usage_frac=0.4018 topk_prob_mean=0.2540 ema_alpha_reverse=nan max_logit=11.7917
step:1155/1750 train_time:547115ms step_avg:473.69ms
[train step 1155] avg_loss=3.454913 main=2.995935 aux=0.458978 imp_cv2=0.1465 load_cv2=5.1830 usage_frac=0.4018 topk_prob_mean=0.2712 ema_alpha_reverse=nan max_logit=11.7917
step:1156/1750 train_time:547583ms step_avg:473.69ms
[train step 1156] avg_loss=3.778968 main=3.308554 aux=0.470414 imp_cv2=0.0760 load_cv2=5.3927 usage_frac=0.4018 topk_prob_mean=0.2389 ema_alpha_reverse=nan max_logit=11.7917
step:1157/1750 train_time:548035ms step_avg:473.67ms
[train step 1157] avg_loss=3.352090 main=2.897895 aux=0.454195 imp_cv2=0.1708 load_cv2=5.0983 usage_frac=0.4062 topk_prob_mean=0.2826 ema_alpha_reverse=nan max_logit=11.7917
step:1158/1750 train_time:548494ms step_avg:473.66ms
[train step 1158] avg_loss=3.916601 main=3.439375 aux=0.477226 imp_cv2=0.0613 load_cv2=5.4759 usage_frac=0.3973 topk_prob_mean=0.2268 ema_alpha_reverse=nan max_logit=11.7917
step:1159/1750 train_time:548958ms step_avg:473.65ms
[train step 1159] avg_loss=3.951535 main=3.472914 aux=0.478621 imp_cv2=0.0548 load_cv2=5.5138 usage_frac=0.4018 topk_prob_mean=0.2230 ema_alpha_reverse=nan max_logit=11.7917
step:1160/1750 train_time:549605ms step_avg:473.80ms
[train step 1160] avg_loss=3.496632 main=3.037332 aux=0.459300 imp_cv2=0.1546 load_cv2=5.1763 usage_frac=0.4018 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=11.7917
step:1161/1750 train_time:550077ms step_avg:473.80ms
[train step 1161] avg_loss=3.277013 main=2.819199 aux=0.457814 imp_cv2=0.2018 load_cv2=5.1151 usage_frac=0.4018 topk_prob_mean=0.2874 ema_alpha_reverse=nan max_logit=11.7917
step:1162/1750 train_time:550731ms step_avg:473.95ms
[train step 1162] avg_loss=3.583893 main=3.123480 aux=0.460413 imp_cv2=0.1588 load_cv2=5.1893 usage_frac=0.4018 topk_prob_mean=0.2752 ema_alpha_reverse=nan max_logit=11.7917
step:1163/1750 train_time:551191ms step_avg:473.94ms
[train step 1163] avg_loss=3.511921 main=3.049948 aux=0.461972 imp_cv2=0.1373 load_cv2=5.2324 usage_frac=0.4107 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=11.7917
step:1164/1750 train_time:551650ms step_avg:473.93ms
[train step 1164] avg_loss=3.608918 main=3.132530 aux=0.476388 imp_cv2=0.0693 load_cv2=5.4787 usage_frac=0.4062 topk_prob_mean=0.2304 ema_alpha_reverse=nan max_logit=11.7917
step:1165/1750 train_time:552105ms step_avg:473.91ms
[train step 1165] avg_loss=3.446709 main=2.981853 aux=0.464855 imp_cv2=0.1556 load_cv2=5.2491 usage_frac=0.4062 topk_prob_mean=0.2696 ema_alpha_reverse=nan max_logit=11.7917
step:1166/1750 train_time:552560ms step_avg:473.89ms
[train step 1166] avg_loss=3.413940 main=2.943978 aux=0.469962 imp_cv2=0.0851 load_cv2=5.3767 usage_frac=0.4062 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=11.7917
step:1167/1750 train_time:553016ms step_avg:473.88ms
[train step 1167] avg_loss=3.832205 main=3.362062 aux=0.470143 imp_cv2=0.1044 load_cv2=5.3633 usage_frac=0.4018 topk_prob_mean=0.2492 ema_alpha_reverse=nan max_logit=11.7917
step:1168/1750 train_time:553489ms step_avg:473.88ms
[train step 1168] avg_loss=3.565321 main=3.103284 aux=0.462037 imp_cv2=0.1289 load_cv2=5.2341 usage_frac=0.4062 topk_prob_mean=0.2624 ema_alpha_reverse=nan max_logit=11.7917
step:1169/1750 train_time:553945ms step_avg:473.86ms
[train step 1169] avg_loss=3.518913 main=3.050118 aux=0.468795 imp_cv2=0.1262 load_cv2=5.3254 usage_frac=0.4062 topk_prob_mean=0.2582 ema_alpha_reverse=nan max_logit=11.7917
step:1170/1750 train_time:554406ms step_avg:473.85ms
[train step 1170] avg_loss=4.585881 main=4.093462 aux=0.492419 imp_cv2=0.0505 load_cv2=5.6910 usage_frac=0.3973 topk_prob_mean=0.2096 ema_alpha_reverse=nan max_logit=11.7917
step:1171/1750 train_time:554866ms step_avg:473.84ms
[train step 1171] avg_loss=3.355196 main=2.896935 aux=0.458261 imp_cv2=0.2294 load_cv2=5.0984 usage_frac=0.4062 topk_prob_mean=0.2956 ema_alpha_reverse=nan max_logit=11.7917
step:1172/1750 train_time:555328ms step_avg:473.83ms
[train step 1172] avg_loss=3.396579 main=2.936762 aux=0.459817 imp_cv2=0.1976 load_cv2=5.1435 usage_frac=0.4062 topk_prob_mean=0.2859 ema_alpha_reverse=nan max_logit=11.7917
step:1173/1750 train_time:555793ms step_avg:473.82ms
[train step 1173] avg_loss=3.670648 main=3.202063 aux=0.468586 imp_cv2=0.0957 load_cv2=5.3545 usage_frac=0.4062 topk_prob_mean=0.2499 ema_alpha_reverse=nan max_logit=11.7917
step:1174/1750 train_time:556248ms step_avg:473.81ms
[train step 1174] avg_loss=3.407412 main=2.954372 aux=0.453039 imp_cv2=0.1855 load_cv2=5.0755 usage_frac=0.4062 topk_prob_mean=0.2872 ema_alpha_reverse=nan max_logit=11.7917
step:1175/1750 train_time:556705ms step_avg:473.79ms
[train step 1175] avg_loss=3.616465 main=3.152761 aux=0.463704 imp_cv2=0.1154 load_cv2=5.2798 usage_frac=0.4018 topk_prob_mean=0.2597 ema_alpha_reverse=nan max_logit=11.7917
step:1176/1750 train_time:557157ms step_avg:473.77ms
[train step 1176] avg_loss=3.624649 main=3.163981 aux=0.460668 imp_cv2=0.1120 load_cv2=5.2353 usage_frac=0.4062 topk_prob_mean=0.2589 ema_alpha_reverse=nan max_logit=11.7917
step:1177/1750 train_time:557612ms step_avg:473.76ms
[train step 1177] avg_loss=3.515964 main=3.059851 aux=0.456112 imp_cv2=0.1343 load_cv2=5.1601 usage_frac=0.4018 topk_prob_mean=0.2687 ema_alpha_reverse=nan max_logit=11.7917
step:1178/1750 train_time:558074ms step_avg:473.75ms
[train step 1178] avg_loss=3.837340 main=3.330521 aux=0.506819 imp_cv2=0.0319 load_cv2=5.8869 usage_frac=0.3973 topk_prob_mean=0.1893 ema_alpha_reverse=nan max_logit=11.7917
step:1179/1750 train_time:558517ms step_avg:473.72ms
[train step 1179] avg_loss=3.636745 main=3.175912 aux=0.460833 imp_cv2=0.1222 load_cv2=5.2291 usage_frac=0.4018 topk_prob_mean=0.2625 ema_alpha_reverse=nan max_logit=11.7917
step:1180/1750 train_time:558968ms step_avg:473.70ms
[train step 1180] avg_loss=4.089572 main=3.619157 aux=0.470416 imp_cv2=0.0755 load_cv2=5.3918 usage_frac=0.4018 topk_prob_mean=0.2402 ema_alpha_reverse=nan max_logit=11.7917
step:1181/1750 train_time:559416ms step_avg:473.68ms
[train step 1181] avg_loss=3.549029 main=3.088889 aux=0.460140 imp_cv2=0.1313 load_cv2=5.2145 usage_frac=0.4062 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=11.7917
step:1182/1750 train_time:559872ms step_avg:473.67ms
[train step 1182] avg_loss=3.715958 main=3.248775 aux=0.467182 imp_cv2=0.0907 load_cv2=5.3381 usage_frac=0.4018 topk_prob_mean=0.2462 ema_alpha_reverse=nan max_logit=11.7917
step:1183/1750 train_time:560319ms step_avg:473.64ms
[train step 1183] avg_loss=3.680634 main=3.212407 aux=0.468227 imp_cv2=0.0934 load_cv2=5.3544 usage_frac=0.4062 topk_prob_mean=0.2476 ema_alpha_reverse=nan max_logit=11.7917
step:1184/1750 train_time:560773ms step_avg:473.63ms
[train step 1184] avg_loss=3.583793 main=3.117955 aux=0.465838 imp_cv2=0.1366 load_cv2=5.2799 usage_frac=0.4062 topk_prob_mean=0.2652 ema_alpha_reverse=nan max_logit=11.7917
step:1185/1750 train_time:561222ms step_avg:473.61ms
[train step 1185] avg_loss=4.335135 main=3.814575 aux=0.520560 imp_cv2=0.0507 load_cv2=6.0365 usage_frac=0.3973 topk_prob_mean=0.1855 ema_alpha_reverse=nan max_logit=10.8091
step:1186/1750 train_time:561684ms step_avg:473.60ms
[train step 1186] avg_loss=4.374831 main=3.882458 aux=0.492373 imp_cv2=0.0714 load_cv2=5.6675 usage_frac=0.4062 topk_prob_mean=0.2264 ema_alpha_reverse=nan max_logit=11.7917
step:1187/1750 train_time:562356ms step_avg:473.76ms
[train step 1187] avg_loss=3.913995 main=3.433781 aux=0.480214 imp_cv2=0.0721 load_cv2=5.5235 usage_frac=0.4062 topk_prob_mean=0.2342 ema_alpha_reverse=nan max_logit=11.7917
step:1188/1750 train_time:562809ms step_avg:473.75ms
[train step 1188] avg_loss=3.553170 main=3.090618 aux=0.462552 imp_cv2=0.1563 load_cv2=5.2188 usage_frac=0.4062 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=11.7917
step:1189/1750 train_time:563280ms step_avg:473.74ms
[train step 1189] avg_loss=3.266995 main=2.802591 aux=0.464404 imp_cv2=0.1473 load_cv2=5.2500 usage_frac=0.4018 topk_prob_mean=0.2687 ema_alpha_reverse=nan max_logit=11.7917
step:1190/1750 train_time:563732ms step_avg:473.72ms
[train step 1190] avg_loss=3.205857 main=2.745695 aux=0.460162 imp_cv2=0.2076 load_cv2=5.1389 usage_frac=0.4062 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=11.7917
step:1191/1750 train_time:564197ms step_avg:473.72ms
[train step 1191] avg_loss=3.960073 main=3.469806 aux=0.490267 imp_cv2=0.0541 load_cv2=5.6611 usage_frac=0.4018 topk_prob_mean=0.2178 ema_alpha_reverse=nan max_logit=11.7917
step:1192/1750 train_time:564650ms step_avg:473.70ms
[train step 1192] avg_loss=4.477585 main=4.002491 aux=0.475094 imp_cv2=0.0937 load_cv2=5.4290 usage_frac=0.4062 topk_prob_mean=0.2421 ema_alpha_reverse=nan max_logit=11.7917
step:1193/1750 train_time:565107ms step_avg:473.69ms
[train step 1193] avg_loss=4.727147 main=4.226238 aux=0.500909 imp_cv2=0.0435 load_cv2=5.8028 usage_frac=0.4018 topk_prob_mean=0.2025 ema_alpha_reverse=nan max_logit=11.7917
step:1194/1750 train_time:565561ms step_avg:473.67ms
[train step 1194] avg_loss=3.789493 main=3.319333 aux=0.470159 imp_cv2=0.0908 load_cv2=5.3829 usage_frac=0.3973 topk_prob_mean=0.2457 ema_alpha_reverse=nan max_logit=11.7917
step:1195/1750 train_time:566002ms step_avg:473.64ms
[train step 1195] avg_loss=4.166605 main=3.664710 aux=0.501895 imp_cv2=0.0514 load_cv2=5.8106 usage_frac=0.4062 topk_prob_mean=0.2063 ema_alpha_reverse=nan max_logit=11.7917
step:1196/1750 train_time:566458ms step_avg:473.63ms
[train step 1196] avg_loss=3.407891 main=2.935414 aux=0.472477 imp_cv2=0.0844 load_cv2=5.4178 usage_frac=0.4018 topk_prob_mean=0.2414 ema_alpha_reverse=nan max_logit=11.7917
step:1197/1750 train_time:566905ms step_avg:473.60ms
[train step 1197] avg_loss=3.386756 main=2.926096 aux=0.460660 imp_cv2=0.1795 load_cv2=5.1759 usage_frac=0.4062 topk_prob_mean=0.2821 ema_alpha_reverse=nan max_logit=11.7917
step:1198/1750 train_time:567362ms step_avg:473.59ms
[train step 1198] avg_loss=3.101921 main=2.642199 aux=0.459722 imp_cv2=0.2674 load_cv2=5.0768 usage_frac=0.4018 topk_prob_mean=0.3059 ema_alpha_reverse=nan max_logit=11.7917
step:1199/1750 train_time:567827ms step_avg:473.58ms
[train step 1199] avg_loss=3.616169 main=3.147038 aux=0.469132 imp_cv2=0.1039 load_cv2=5.3542 usage_frac=0.4018 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=11.7917
step:1200/1750 train_time:568280ms step_avg:473.57ms
Running validation...
step:1200/1750 val_loss:3.141206 train_time:568291ms step_avg:473.58ms
[train step 1200] avg_loss=3.299032 main=2.839581 aux=0.459451 imp_cv2=0.2100 load_cv2=5.1282 usage_frac=0.4107 topk_prob_mean=0.2919 ema_alpha_reverse=nan max_logit=11.7917
step:1201/1750 train_time:568740ms step_avg:473.56ms
[train step 1201] avg_loss=3.552128 main=3.090649 aux=0.461479 imp_cv2=0.1422 load_cv2=5.2228 usage_frac=0.4062 topk_prob_mean=0.2688 ema_alpha_reverse=nan max_logit=11.7917
step:1202/1750 train_time:569187ms step_avg:473.53ms
[train step 1202] avg_loss=3.143917 main=2.684134 aux=0.459782 imp_cv2=0.2277 load_cv2=5.1182 usage_frac=0.4062 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=11.7917
step:1203/1750 train_time:569649ms step_avg:473.52ms
[train step 1203] avg_loss=3.344014 main=2.878941 aux=0.465073 imp_cv2=0.1304 load_cv2=5.2799 usage_frac=0.4062 topk_prob_mean=0.2643 ema_alpha_reverse=nan max_logit=11.7917
step:1204/1750 train_time:570294ms step_avg:473.67ms
[train step 1204] avg_loss=3.218622 main=2.759669 aux=0.458953 imp_cv2=0.2436 load_cv2=5.0874 usage_frac=0.3973 topk_prob_mean=0.3013 ema_alpha_reverse=nan max_logit=11.7917
step:1205/1750 train_time:570758ms step_avg:473.66ms
[train step 1205] avg_loss=3.963083 main=3.485823 aux=0.477259 imp_cv2=0.0919 load_cv2=5.4671 usage_frac=0.4062 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=11.7917
step:1206/1750 train_time:571213ms step_avg:473.64ms
[train step 1206] avg_loss=3.626082 main=3.150140 aux=0.475942 imp_cv2=0.0872 load_cv2=5.4570 usage_frac=0.3973 topk_prob_mean=0.2434 ema_alpha_reverse=nan max_logit=11.7917
step:1207/1750 train_time:571660ms step_avg:473.62ms
[train step 1207] avg_loss=3.520989 main=3.050505 aux=0.470484 imp_cv2=0.0964 load_cv2=5.3849 usage_frac=0.3973 topk_prob_mean=0.2448 ema_alpha_reverse=nan max_logit=11.7917
step:1208/1750 train_time:572109ms step_avg:473.60ms
[train step 1208] avg_loss=3.749134 main=3.284889 aux=0.464246 imp_cv2=0.1413 load_cv2=5.2540 usage_frac=0.4062 topk_prob_mean=0.2650 ema_alpha_reverse=nan max_logit=11.7917
step:1209/1750 train_time:572567ms step_avg:473.59ms
[train step 1209] avg_loss=3.603944 main=3.134629 aux=0.469315 imp_cv2=0.1081 load_cv2=5.3570 usage_frac=0.4062 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=11.7917
step:1210/1750 train_time:573016ms step_avg:473.57ms
[train step 1210] avg_loss=3.144685 main=2.686390 aux=0.458295 imp_cv2=0.2462 load_cv2=5.0821 usage_frac=0.4062 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=11.7917
step:1211/1750 train_time:573472ms step_avg:473.55ms
[train step 1211] avg_loss=4.064325 main=3.572570 aux=0.491756 imp_cv2=0.0785 load_cv2=5.6461 usage_frac=0.3973 topk_prob_mean=0.2188 ema_alpha_reverse=nan max_logit=11.7917
step:1212/1750 train_time:573927ms step_avg:473.54ms
[train step 1212] avg_loss=3.752353 main=3.287334 aux=0.465019 imp_cv2=0.1166 load_cv2=5.2964 usage_frac=0.4062 topk_prob_mean=0.2573 ema_alpha_reverse=nan max_logit=11.7917
step:1213/1750 train_time:574390ms step_avg:473.53ms
[train step 1213] avg_loss=3.312409 main=2.855862 aux=0.456547 imp_cv2=0.1863 load_cv2=5.1254 usage_frac=0.4018 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=11.7917
step:1214/1750 train_time:574840ms step_avg:473.51ms
[train step 1214] avg_loss=3.473899 main=3.012773 aux=0.461126 imp_cv2=0.1541 load_cv2=5.2106 usage_frac=0.4018 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=11.7917
step:1215/1750 train_time:575299ms step_avg:473.50ms
[train step 1215] avg_loss=3.517599 main=3.053830 aux=0.463769 imp_cv2=0.1340 load_cv2=5.2677 usage_frac=0.4018 topk_prob_mean=0.2640 ema_alpha_reverse=nan max_logit=11.7917
step:1216/1750 train_time:575754ms step_avg:473.48ms
[train step 1216] avg_loss=3.386788 main=2.929552 aux=0.457236 imp_cv2=0.1854 load_cv2=5.1370 usage_frac=0.4018 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=11.7917
step:1217/1750 train_time:576224ms step_avg:473.48ms
[train step 1217] avg_loss=3.308055 main=2.852185 aux=0.455870 imp_cv2=0.2281 load_cv2=5.0790 usage_frac=0.4062 topk_prob_mean=0.2960 ema_alpha_reverse=nan max_logit=11.7917
step:1218/1750 train_time:576691ms step_avg:473.47ms
[train step 1218] avg_loss=3.868220 main=3.403230 aux=0.464990 imp_cv2=0.1037 load_cv2=5.3134 usage_frac=0.4018 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:1219/1750 train_time:577137ms step_avg:473.45ms
[train step 1219] avg_loss=3.620995 main=3.157293 aux=0.463703 imp_cv2=0.1031 load_cv2=5.2987 usage_frac=0.4062 topk_prob_mean=0.2528 ema_alpha_reverse=nan max_logit=11.7917
step:1220/1750 train_time:577586ms step_avg:473.43ms
[train step 1220] avg_loss=3.574243 main=3.102758 aux=0.471485 imp_cv2=0.0751 load_cv2=5.4180 usage_frac=0.4062 topk_prob_mean=0.2380 ema_alpha_reverse=nan max_logit=11.7917
step:1221/1750 train_time:578038ms step_avg:473.41ms
[train step 1221] avg_loss=3.586975 main=3.123804 aux=0.463171 imp_cv2=0.1157 load_cv2=5.2777 usage_frac=0.4018 topk_prob_mean=0.2573 ema_alpha_reverse=nan max_logit=11.7917
step:1222/1750 train_time:578493ms step_avg:473.40ms
[train step 1222] avg_loss=3.157591 main=2.699825 aux=0.457765 imp_cv2=0.2297 load_cv2=5.0966 usage_frac=0.4062 topk_prob_mean=0.2947 ema_alpha_reverse=nan max_logit=11.7917
step:1223/1750 train_time:578953ms step_avg:473.39ms
[train step 1223] avg_loss=3.705370 main=3.229888 aux=0.475482 imp_cv2=0.0598 load_cv2=5.4806 usage_frac=0.3973 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=11.7917
step:1224/1750 train_time:579398ms step_avg:473.36ms
[train step 1224] avg_loss=3.851129 main=3.374188 aux=0.476941 imp_cv2=0.0593 load_cv2=5.5018 usage_frac=0.3973 topk_prob_mean=0.2261 ema_alpha_reverse=nan max_logit=11.7917
step:1225/1750 train_time:579863ms step_avg:473.36ms
[train step 1225] avg_loss=3.212727 main=2.759858 aux=0.452868 imp_cv2=0.1804 load_cv2=5.0873 usage_frac=0.4018 topk_prob_mean=0.2847 ema_alpha_reverse=nan max_logit=11.7917
step:1226/1750 train_time:580322ms step_avg:473.35ms
[train step 1226] avg_loss=3.261578 main=2.810642 aux=0.450935 imp_cv2=0.2154 load_cv2=5.0269 usage_frac=0.3973 topk_prob_mean=0.2953 ema_alpha_reverse=nan max_logit=11.7917
step:1227/1750 train_time:580800ms step_avg:473.35ms
[train step 1227] avg_loss=4.699364 main=4.182508 aux=0.516856 imp_cv2=0.0305 load_cv2=6.0121 usage_frac=0.3973 topk_prob_mean=0.1782 ema_alpha_reverse=nan max_logit=11.7917
step:1228/1750 train_time:581243ms step_avg:473.33ms
[train step 1228] avg_loss=3.690142 main=3.233195 aux=0.456947 imp_cv2=0.1151 load_cv2=5.2053 usage_frac=0.4062 topk_prob_mean=0.2577 ema_alpha_reverse=nan max_logit=11.7917
step:1229/1750 train_time:581688ms step_avg:473.30ms
[train step 1229] avg_loss=3.619854 main=3.129533 aux=0.490322 imp_cv2=0.0411 load_cv2=5.6819 usage_frac=0.3973 topk_prob_mean=0.2084 ema_alpha_reverse=nan max_logit=10.8091
step:1230/1750 train_time:582134ms step_avg:473.28ms
[train step 1230] avg_loss=3.793912 main=3.313385 aux=0.480527 imp_cv2=0.0523 load_cv2=5.5477 usage_frac=0.3973 topk_prob_mean=0.2164 ema_alpha_reverse=nan max_logit=11.7917
step:1231/1750 train_time:582581ms step_avg:473.26ms
[train step 1231] avg_loss=3.819678 main=3.346116 aux=0.473561 imp_cv2=0.0838 load_cv2=5.4369 usage_frac=0.4062 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=11.7917
step:1232/1750 train_time:583035ms step_avg:473.24ms
[train step 1232] avg_loss=3.679983 main=3.208244 aux=0.471740 imp_cv2=0.0824 load_cv2=5.4081 usage_frac=0.4018 topk_prob_mean=0.2393 ema_alpha_reverse=nan max_logit=11.7917
step:1233/1750 train_time:583483ms step_avg:473.22ms
[train step 1233] avg_loss=3.615233 main=3.149501 aux=0.465732 imp_cv2=0.0884 load_cv2=5.3311 usage_frac=0.4062 topk_prob_mean=0.2459 ema_alpha_reverse=nan max_logit=11.7917
step:1234/1750 train_time:583925ms step_avg:473.20ms
[train step 1234] avg_loss=3.395139 main=2.936966 aux=0.458173 imp_cv2=0.1548 load_cv2=5.1697 usage_frac=0.4062 topk_prob_mean=0.2740 ema_alpha_reverse=nan max_logit=11.7917
step:1235/1750 train_time:584381ms step_avg:473.18ms
[train step 1235] avg_loss=3.288917 main=2.835964 aux=0.452953 imp_cv2=0.1853 load_cv2=5.0771 usage_frac=0.4018 topk_prob_mean=0.2858 ema_alpha_reverse=nan max_logit=11.7917
step:1236/1750 train_time:584846ms step_avg:473.18ms
[train step 1236] avg_loss=3.693888 main=3.228037 aux=0.465851 imp_cv2=0.0866 load_cv2=5.3314 usage_frac=0.3973 topk_prob_mean=0.2479 ema_alpha_reverse=nan max_logit=11.7917
step:1237/1750 train_time:585297ms step_avg:473.16ms
[train step 1237] avg_loss=3.422209 main=2.968752 aux=0.453458 imp_cv2=0.1645 load_cv2=5.0983 usage_frac=0.4062 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=11.7917
step:1238/1750 train_time:585748ms step_avg:473.14ms
[train step 1238] avg_loss=3.908477 main=3.437872 aux=0.470605 imp_cv2=0.0730 load_cv2=5.4068 usage_frac=0.4107 topk_prob_mean=0.2376 ema_alpha_reverse=nan max_logit=11.7917
step:1239/1750 train_time:586199ms step_avg:473.12ms
[train step 1239] avg_loss=3.494686 main=3.026652 aux=0.468034 imp_cv2=0.0775 load_cv2=5.3715 usage_frac=0.3929 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=11.7917
step:1240/1750 train_time:586660ms step_avg:473.11ms
[train step 1240] avg_loss=3.791920 main=3.317342 aux=0.474579 imp_cv2=0.0648 load_cv2=5.4605 usage_frac=0.4018 topk_prob_mean=0.2314 ema_alpha_reverse=nan max_logit=11.7917
step:1241/1750 train_time:587110ms step_avg:473.09ms
[train step 1241] avg_loss=4.541525 main=4.023469 aux=0.518056 imp_cv2=0.0406 load_cv2=6.0153 usage_frac=0.3795 topk_prob_mean=0.1745 ema_alpha_reverse=nan max_logit=10.8091
step:1242/1750 train_time:587579ms step_avg:473.09ms
[train step 1242] avg_loss=3.329534 main=2.872530 aux=0.457004 imp_cv2=0.1411 load_cv2=5.1765 usage_frac=0.4107 topk_prob_mean=0.2696 ema_alpha_reverse=nan max_logit=11.7917
step:1243/1750 train_time:588039ms step_avg:473.08ms
[train step 1243] avg_loss=3.990906 main=3.519215 aux=0.471691 imp_cv2=0.0573 load_cv2=5.4381 usage_frac=0.4018 topk_prob_mean=0.2299 ema_alpha_reverse=nan max_logit=11.7917
step:1244/1750 train_time:588506ms step_avg:473.08ms
[train step 1244] avg_loss=3.296730 main=2.841992 aux=0.454738 imp_cv2=0.1914 load_cv2=5.0973 usage_frac=0.3973 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=11.7917
step:1245/1750 train_time:588967ms step_avg:473.07ms
[train step 1245] avg_loss=3.755040 main=3.282391 aux=0.472649 imp_cv2=0.0749 load_cv2=5.4274 usage_frac=0.4018 topk_prob_mean=0.2351 ema_alpha_reverse=nan max_logit=11.7917
step:1246/1750 train_time:589428ms step_avg:473.06ms
[train step 1246] avg_loss=3.821000 main=3.361980 aux=0.459020 imp_cv2=0.1333 load_cv2=5.2071 usage_frac=0.3973 topk_prob_mean=0.2675 ema_alpha_reverse=nan max_logit=11.7917
step:1247/1750 train_time:589880ms step_avg:473.04ms
[train step 1247] avg_loss=3.598510 main=3.125748 aux=0.472762 imp_cv2=0.0700 load_cv2=5.4397 usage_frac=0.4107 topk_prob_mean=0.2369 ema_alpha_reverse=nan max_logit=11.7917
step:1248/1750 train_time:590328ms step_avg:473.02ms
[train step 1248] avg_loss=4.611486 main=4.075325 aux=0.536161 imp_cv2=0.0331 load_cv2=6.2458 usage_frac=0.3750 topk_prob_mean=0.1613 ema_alpha_reverse=nan max_logit=8.8438
step:1249/1750 train_time:590780ms step_avg:473.00ms
[train step 1249] avg_loss=3.951012 main=3.457033 aux=0.493979 imp_cv2=0.0377 load_cv2=5.7289 usage_frac=0.3973 topk_prob_mean=0.2042 ema_alpha_reverse=nan max_logit=11.7917
step:1250/1750 train_time:591245ms step_avg:473.00ms
Running validation...
step:1250/1750 val_loss:3.124929 train_time:591257ms step_avg:473.01ms
[train step 1250] avg_loss=3.370756 main=2.912318 aux=0.458438 imp_cv2=0.1507 load_cv2=5.1864 usage_frac=0.4107 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=11.7917
step:1251/1750 train_time:591699ms step_avg:472.98ms
[train step 1251] avg_loss=3.834798 main=3.366141 aux=0.468657 imp_cv2=0.0871 load_cv2=5.3749 usage_frac=0.3973 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=11.7917
step:1252/1750 train_time:592155ms step_avg:472.97ms
[train step 1252] avg_loss=3.701635 main=3.240701 aux=0.460934 imp_cv2=0.1194 load_cv2=5.2493 usage_frac=0.3973 topk_prob_mean=0.2600 ema_alpha_reverse=nan max_logit=11.7917
step:1253/1750 train_time:592603ms step_avg:472.95ms
[train step 1253] avg_loss=3.796584 main=3.316567 aux=0.480017 imp_cv2=0.0578 load_cv2=5.5440 usage_frac=0.3973 topk_prob_mean=0.2249 ema_alpha_reverse=nan max_logit=11.7917
step:1254/1750 train_time:593062ms step_avg:472.94ms
[train step 1254] avg_loss=4.161240 main=3.673454 aux=0.487786 imp_cv2=0.0474 load_cv2=5.6480 usage_frac=0.4018 topk_prob_mean=0.2131 ema_alpha_reverse=nan max_logit=11.8999
step:1255/1750 train_time:593530ms step_avg:472.93ms
[train step 1255] avg_loss=3.478658 main=3.022388 aux=0.456270 imp_cv2=0.1827 load_cv2=5.1321 usage_frac=0.4018 topk_prob_mean=0.2794 ema_alpha_reverse=nan max_logit=11.7917
step:1256/1750 train_time:593990ms step_avg:472.92ms
[train step 1256] avg_loss=4.476307 main=3.952896 aux=0.523410 imp_cv2=0.0553 load_cv2=6.0837 usage_frac=0.3705 topk_prob_mean=0.1738 ema_alpha_reverse=nan max_logit=9.8264
step:1257/1750 train_time:594446ms step_avg:472.91ms
[train step 1257] avg_loss=3.425546 main=2.969550 aux=0.455996 imp_cv2=0.2060 load_cv2=5.1015 usage_frac=0.4018 topk_prob_mean=0.2879 ema_alpha_reverse=nan max_logit=11.7917
step:1258/1750 train_time:594920ms step_avg:472.91ms
[train step 1258] avg_loss=3.595773 main=3.138318 aux=0.457454 imp_cv2=0.1394 load_cv2=5.1849 usage_frac=0.4107 topk_prob_mean=0.2685 ema_alpha_reverse=nan max_logit=11.7917
step:1259/1750 train_time:595367ms step_avg:472.89ms
[train step 1259] avg_loss=3.460893 main=3.003055 aux=0.457837 imp_cv2=0.1755 load_cv2=5.1522 usage_frac=0.4107 topk_prob_mean=0.2810 ema_alpha_reverse=nan max_logit=11.7917
step:1260/1750 train_time:595824ms step_avg:472.88ms
[train step 1260] avg_loss=3.330495 main=2.864252 aux=0.466243 imp_cv2=0.0965 load_cv2=5.3315 usage_frac=0.3973 topk_prob_mean=0.2530 ema_alpha_reverse=nan max_logit=11.7917
step:1261/1750 train_time:596294ms step_avg:472.87ms
[train step 1261] avg_loss=3.997272 main=3.528142 aux=0.469130 imp_cv2=0.1221 load_cv2=5.3515 usage_frac=0.4018 topk_prob_mean=0.2531 ema_alpha_reverse=nan max_logit=11.7917
step:1262/1750 train_time:596747ms step_avg:472.86ms
[train step 1262] avg_loss=3.263492 main=2.812574 aux=0.450917 imp_cv2=0.2360 load_cv2=5.0027 usage_frac=0.4018 topk_prob_mean=0.3018 ema_alpha_reverse=nan max_logit=11.7917
step:1263/1750 train_time:597201ms step_avg:472.84ms
[train step 1263] avg_loss=3.433309 main=2.968486 aux=0.464823 imp_cv2=0.0942 load_cv2=5.3197 usage_frac=0.4062 topk_prob_mean=0.2479 ema_alpha_reverse=nan max_logit=11.7917
step:1264/1750 train_time:597665ms step_avg:472.84ms
[train step 1264] avg_loss=4.193560 main=3.658829 aux=0.534731 imp_cv2=0.0366 load_cv2=6.2314 usage_frac=0.3571 topk_prob_mean=0.1622 ema_alpha_reverse=nan max_logit=9.8264
step:1265/1750 train_time:598111ms step_avg:472.82ms
[train step 1265] avg_loss=3.400146 main=2.947289 aux=0.452857 imp_cv2=0.1519 load_cv2=5.1147 usage_frac=0.4062 topk_prob_mean=0.2742 ema_alpha_reverse=nan max_logit=11.7917
step:1266/1750 train_time:598560ms step_avg:472.80ms
[train step 1266] avg_loss=3.501648 main=3.047001 aux=0.454647 imp_cv2=0.1439 load_cv2=5.1444 usage_frac=0.4018 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:1267/1750 train_time:599025ms step_avg:472.79ms
[train step 1267] avg_loss=3.556530 main=3.087620 aux=0.468910 imp_cv2=0.0701 load_cv2=5.3990 usage_frac=0.4062 topk_prob_mean=0.2351 ema_alpha_reverse=nan max_logit=11.7917
step:1268/1750 train_time:599478ms step_avg:472.77ms
[train step 1268] avg_loss=3.593385 main=3.126737 aux=0.466648 imp_cv2=0.0861 load_cv2=5.3553 usage_frac=0.4062 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=11.7917
step:1269/1750 train_time:599930ms step_avg:472.76ms
[train step 1269] avg_loss=3.558346 main=3.090086 aux=0.468260 imp_cv2=0.0942 load_cv2=5.3637 usage_frac=0.4018 topk_prob_mean=0.2444 ema_alpha_reverse=nan max_logit=11.7917
step:1270/1750 train_time:600391ms step_avg:472.75ms
[train step 1270] avg_loss=3.620024 main=3.158015 aux=0.462009 imp_cv2=0.1036 load_cv2=5.2801 usage_frac=0.4107 topk_prob_mean=0.2525 ema_alpha_reverse=nan max_logit=11.7917
step:1271/1750 train_time:600845ms step_avg:472.73ms
[train step 1271] avg_loss=3.413857 main=2.959102 aux=0.454755 imp_cv2=0.1590 load_cv2=5.1315 usage_frac=0.4107 topk_prob_mean=0.2731 ema_alpha_reverse=nan max_logit=11.7917
step:1272/1750 train_time:601307ms step_avg:472.73ms
[train step 1272] avg_loss=3.782882 main=3.302041 aux=0.480841 imp_cv2=0.0617 load_cv2=5.5512 usage_frac=0.4062 topk_prob_mean=0.2229 ema_alpha_reverse=nan max_logit=11.7917
step:1273/1750 train_time:601754ms step_avg:472.71ms
[train step 1273] avg_loss=3.282922 main=2.829889 aux=0.453032 imp_cv2=0.1918 load_cv2=5.0794 usage_frac=0.4152 topk_prob_mean=0.2860 ema_alpha_reverse=nan max_logit=11.7917
step:1274/1750 train_time:602222ms step_avg:472.70ms
[train step 1274] avg_loss=3.223623 main=2.770445 aux=0.453178 imp_cv2=0.2344 load_cv2=5.0294 usage_frac=0.4062 topk_prob_mean=0.2978 ema_alpha_reverse=nan max_logit=11.7917
step:1275/1750 train_time:602674ms step_avg:472.69ms
[train step 1275] avg_loss=3.182556 main=2.731973 aux=0.450583 imp_cv2=0.1915 load_cv2=5.0459 usage_frac=0.4062 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=11.7917
step:1276/1750 train_time:603140ms step_avg:472.68ms
[train step 1276] avg_loss=3.205257 main=2.753667 aux=0.451590 imp_cv2=0.1995 load_cv2=5.0477 usage_frac=0.4107 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=11.7917
step:1277/1750 train_time:603600ms step_avg:472.67ms
[train step 1277] avg_loss=3.849755 main=3.368040 aux=0.481714 imp_cv2=0.0498 load_cv2=5.5733 usage_frac=0.4062 topk_prob_mean=0.2178 ema_alpha_reverse=nan max_logit=11.7917
step:1278/1750 train_time:604056ms step_avg:472.66ms
[train step 1278] avg_loss=3.305780 main=2.845307 aux=0.460473 imp_cv2=0.1259 load_cv2=5.2307 usage_frac=0.4107 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=11.7917
step:1279/1750 train_time:604736ms step_avg:472.82ms
[train step 1279] avg_loss=3.726987 main=3.230546 aux=0.496441 imp_cv2=0.0382 load_cv2=5.7709 usage_frac=0.4018 topk_prob_mean=0.2005 ema_alpha_reverse=nan max_logit=11.7917
step:1280/1750 train_time:605178ms step_avg:472.80ms
[train step 1280] avg_loss=3.739421 main=3.254047 aux=0.485373 imp_cv2=0.0473 load_cv2=5.6125 usage_frac=0.4062 topk_prob_mean=0.2159 ema_alpha_reverse=nan max_logit=11.7917
step:1281/1750 train_time:605626ms step_avg:472.78ms
[train step 1281] avg_loss=3.989040 main=3.506271 aux=0.482769 imp_cv2=0.0462 load_cv2=5.5931 usage_frac=0.4107 topk_prob_mean=0.2140 ema_alpha_reverse=nan max_logit=11.7917
step:1282/1750 train_time:606070ms step_avg:472.75ms
[train step 1282] avg_loss=4.100750 main=3.600044 aux=0.500706 imp_cv2=0.0334 load_cv2=5.8167 usage_frac=0.4018 topk_prob_mean=0.1908 ema_alpha_reverse=nan max_logit=11.7917
step:1283/1750 train_time:606522ms step_avg:472.74ms
[train step 1283] avg_loss=3.429322 main=2.965164 aux=0.464158 imp_cv2=0.0970 load_cv2=5.3130 usage_frac=0.4107 topk_prob_mean=0.2498 ema_alpha_reverse=nan max_logit=11.7917
step:1284/1750 train_time:606978ms step_avg:472.72ms
[train step 1284] avg_loss=3.337422 main=2.876155 aux=0.461267 imp_cv2=0.1246 load_cv2=5.2426 usage_frac=0.4062 topk_prob_mean=0.2593 ema_alpha_reverse=nan max_logit=11.7917
step:1285/1750 train_time:607435ms step_avg:472.71ms
[train step 1285] avg_loss=3.583224 main=3.123278 aux=0.459947 imp_cv2=0.1449 load_cv2=5.2152 usage_frac=0.4062 topk_prob_mean=0.2688 ema_alpha_reverse=nan max_logit=11.7917
step:1286/1750 train_time:607885ms step_avg:472.69ms
[train step 1286] avg_loss=3.661507 main=3.198360 aux=0.463146 imp_cv2=0.1108 load_cv2=5.2850 usage_frac=0.4062 topk_prob_mean=0.2554 ema_alpha_reverse=nan max_logit=11.7917
step:1287/1750 train_time:608336ms step_avg:472.68ms
[train step 1287] avg_loss=5.709856 main=5.193069 aux=0.516787 imp_cv2=0.0444 load_cv2=5.9948 usage_frac=0.3929 topk_prob_mean=0.1779 ema_alpha_reverse=nan max_logit=11.7917
step:1288/1750 train_time:608794ms step_avg:472.67ms
[train step 1288] avg_loss=5.185818 main=4.693010 aux=0.492809 imp_cv2=0.0387 load_cv2=5.7136 usage_frac=0.4062 topk_prob_mean=0.2024 ema_alpha_reverse=nan max_logit=11.7917
step:1289/1750 train_time:609251ms step_avg:472.65ms
[train step 1289] avg_loss=3.590599 main=3.107770 aux=0.482829 imp_cv2=0.0432 load_cv2=5.5887 usage_frac=0.3973 topk_prob_mean=0.2138 ema_alpha_reverse=nan max_logit=10.8091
step:1290/1750 train_time:609709ms step_avg:472.64ms
[train step 1290] avg_loss=3.513245 main=3.042035 aux=0.471210 imp_cv2=0.0680 load_cv2=5.4188 usage_frac=0.4107 topk_prob_mean=0.2346 ema_alpha_reverse=nan max_logit=11.7917
step:1291/1750 train_time:610155ms step_avg:472.62ms
[train step 1291] avg_loss=3.203906 main=2.747686 aux=0.456220 imp_cv2=0.1785 load_cv2=5.1239 usage_frac=0.4018 topk_prob_mean=0.2796 ema_alpha_reverse=nan max_logit=11.7917
step:1292/1750 train_time:610624ms step_avg:472.62ms
[train step 1292] avg_loss=3.565777 main=3.106194 aux=0.459583 imp_cv2=0.1395 load_cv2=5.2086 usage_frac=0.4018 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=11.7917
step:1293/1750 train_time:611074ms step_avg:472.60ms
[train step 1293] avg_loss=3.489748 main=3.029670 aux=0.460079 imp_cv2=0.1574 load_cv2=5.1919 usage_frac=0.4107 topk_prob_mean=0.2703 ema_alpha_reverse=nan max_logit=11.7917
step:1294/1750 train_time:611517ms step_avg:472.58ms
[train step 1294] avg_loss=3.242053 main=2.786061 aux=0.455992 imp_cv2=0.2119 load_cv2=5.0859 usage_frac=0.4018 topk_prob_mean=0.2897 ema_alpha_reverse=nan max_logit=11.7917
step:1295/1750 train_time:611975ms step_avg:472.57ms
[train step 1295] avg_loss=3.827668 main=3.352047 aux=0.475621 imp_cv2=0.0685 load_cv2=5.4764 usage_frac=0.4062 topk_prob_mean=0.2282 ema_alpha_reverse=nan max_logit=11.7917
step:1296/1750 train_time:612433ms step_avg:472.56ms
[train step 1296] avg_loss=3.286876 main=2.824894 aux=0.461982 imp_cv2=0.1287 load_cv2=5.2471 usage_frac=0.4062 topk_prob_mean=0.2610 ema_alpha_reverse=nan max_logit=11.7917
step:1297/1750 train_time:612887ms step_avg:472.54ms
[train step 1297] avg_loss=3.633671 main=3.172818 aux=0.460853 imp_cv2=0.1232 load_cv2=5.2411 usage_frac=0.4062 topk_prob_mean=0.2599 ema_alpha_reverse=nan max_logit=11.7917
step:1298/1750 train_time:613350ms step_avg:472.53ms
[train step 1298] avg_loss=4.060662 main=3.589293 aux=0.471369 imp_cv2=0.0644 load_cv2=5.4202 usage_frac=0.4107 topk_prob_mean=0.2299 ema_alpha_reverse=nan max_logit=11.7917
step:1299/1750 train_time:613814ms step_avg:472.53ms
[train step 1299] avg_loss=3.655117 main=3.179427 aux=0.475691 imp_cv2=0.0555 load_cv2=5.4929 usage_frac=0.4062 topk_prob_mean=0.2233 ema_alpha_reverse=nan max_logit=11.7917
step:1300/1750 train_time:614265ms step_avg:472.51ms
Running validation...
step:1300/1750 val_loss:3.089767 train_time:614276ms step_avg:472.52ms
[train step 1300] avg_loss=3.664454 main=3.201077 aux=0.463377 imp_cv2=0.1076 load_cv2=5.2854 usage_frac=0.4107 topk_prob_mean=0.2530 ema_alpha_reverse=nan max_logit=11.7917
step:1301/1750 train_time:614722ms step_avg:472.50ms
[train step 1301] avg_loss=4.601612 main=4.108283 aux=0.493329 imp_cv2=0.0358 load_cv2=5.7190 usage_frac=0.4107 topk_prob_mean=0.2050 ema_alpha_reverse=nan max_logit=11.7917
step:1302/1750 train_time:615167ms step_avg:472.48ms
[train step 1302] avg_loss=3.747732 main=3.270902 aux=0.476831 imp_cv2=0.0544 load_cv2=5.5001 usage_frac=0.4062 topk_prob_mean=0.2250 ema_alpha_reverse=nan max_logit=11.7917
step:1303/1750 train_time:615629ms step_avg:472.47ms
[train step 1303] avg_loss=3.003118 main=2.547355 aux=0.455763 imp_cv2=0.2206 load_cv2=5.0815 usage_frac=0.4107 topk_prob_mean=0.2938 ema_alpha_reverse=nan max_logit=11.7917
step:1304/1750 train_time:616095ms step_avg:472.47ms
[train step 1304] avg_loss=4.111781 main=3.626532 aux=0.485249 imp_cv2=0.0477 load_cv2=5.6156 usage_frac=0.4062 topk_prob_mean=0.2170 ema_alpha_reverse=nan max_logit=11.7917
step:1305/1750 train_time:616541ms step_avg:472.45ms
[train step 1305] avg_loss=4.062798 main=3.585718 aux=0.477079 imp_cv2=0.0647 load_cv2=5.5006 usage_frac=0.4107 topk_prob_mean=0.2307 ema_alpha_reverse=nan max_logit=11.7917
step:1306/1750 train_time:616987ms step_avg:472.43ms
[train step 1306] avg_loss=3.321225 main=2.862805 aux=0.458420 imp_cv2=0.2149 load_cv2=5.1188 usage_frac=0.4062 topk_prob_mean=0.2915 ema_alpha_reverse=nan max_logit=11.7917
step:1307/1750 train_time:617463ms step_avg:472.43ms
[train step 1307] avg_loss=3.823422 main=3.341549 aux=0.481873 imp_cv2=0.0612 load_cv2=5.5617 usage_frac=0.4107 topk_prob_mean=0.2247 ema_alpha_reverse=nan max_logit=11.7917
step:1308/1750 train_time:617919ms step_avg:472.42ms
[train step 1308] avg_loss=3.820711 main=3.347611 aux=0.473100 imp_cv2=0.0780 load_cv2=5.4361 usage_frac=0.4018 topk_prob_mean=0.2401 ema_alpha_reverse=nan max_logit=11.7917
step:1309/1750 train_time:618364ms step_avg:472.39ms
[train step 1309] avg_loss=3.137974 main=2.681632 aux=0.456342 imp_cv2=0.1628 load_cv2=5.1493 usage_frac=0.4062 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=11.7917
step:1310/1750 train_time:618819ms step_avg:472.38ms
[train step 1310] avg_loss=3.692282 main=3.226460 aux=0.465823 imp_cv2=0.0871 load_cv2=5.3349 usage_frac=0.4107 topk_prob_mean=0.2480 ema_alpha_reverse=nan max_logit=11.7917
step:1311/1750 train_time:619278ms step_avg:472.37ms
[train step 1311] avg_loss=3.805826 main=3.316737 aux=0.489089 imp_cv2=0.0515 load_cv2=5.6537 usage_frac=0.4062 topk_prob_mean=0.2119 ema_alpha_reverse=nan max_logit=11.7917
step:1312/1750 train_time:619729ms step_avg:472.35ms
[train step 1312] avg_loss=3.278006 main=2.815543 aux=0.462463 imp_cv2=0.1076 load_cv2=5.2763 usage_frac=0.4062 topk_prob_mean=0.2555 ema_alpha_reverse=nan max_logit=11.7917
step:1313/1750 train_time:620180ms step_avg:472.34ms
[train step 1313] avg_loss=3.329569 main=2.870367 aux=0.459202 imp_cv2=0.1318 load_cv2=5.2083 usage_frac=0.4107 topk_prob_mean=0.2661 ema_alpha_reverse=nan max_logit=11.7917
step:1314/1750 train_time:620638ms step_avg:472.33ms
[train step 1314] avg_loss=3.301645 main=2.845389 aux=0.456256 imp_cv2=0.1779 load_cv2=5.1301 usage_frac=0.4107 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=11.7917
step:1315/1750 train_time:621107ms step_avg:472.32ms
[train step 1315] avg_loss=3.515713 main=3.037977 aux=0.477736 imp_cv2=0.0686 load_cv2=5.5073 usage_frac=0.4107 topk_prob_mean=0.2296 ema_alpha_reverse=nan max_logit=11.7917
step:1316/1750 train_time:621551ms step_avg:472.30ms
[train step 1316] avg_loss=3.373197 main=2.907843 aux=0.465353 imp_cv2=0.1153 load_cv2=5.3098 usage_frac=0.4062 topk_prob_mean=0.2561 ema_alpha_reverse=nan max_logit=11.7917
step:1317/1750 train_time:622006ms step_avg:472.29ms
[train step 1317] avg_loss=3.147928 main=2.692688 aux=0.455240 imp_cv2=0.1687 load_cv2=5.1290 usage_frac=0.4152 topk_prob_mean=0.2798 ema_alpha_reverse=nan max_logit=11.7917
step:1318/1750 train_time:622457ms step_avg:472.27ms
[train step 1318] avg_loss=3.651982 main=3.183359 aux=0.468623 imp_cv2=0.0869 load_cv2=5.3712 usage_frac=0.4152 topk_prob_mean=0.2453 ema_alpha_reverse=nan max_logit=11.7917
step:1319/1750 train_time:622911ms step_avg:472.26ms
[train step 1319] avg_loss=3.408442 main=2.940498 aux=0.467944 imp_cv2=0.0853 load_cv2=5.3721 usage_frac=0.4018 topk_prob_mean=0.2436 ema_alpha_reverse=nan max_logit=11.7917
step:1320/1750 train_time:623366ms step_avg:472.25ms
[train step 1320] avg_loss=3.938101 main=3.447491 aux=0.490610 imp_cv2=0.0461 load_cv2=5.6847 usage_frac=0.3973 topk_prob_mean=0.2081 ema_alpha_reverse=nan max_logit=11.7917
step:1321/1750 train_time:623828ms step_avg:472.24ms
[train step 1321] avg_loss=3.878619 main=3.389327 aux=0.489293 imp_cv2=0.0553 load_cv2=5.6518 usage_frac=0.4062 topk_prob_mean=0.2139 ema_alpha_reverse=nan max_logit=11.7917
step:1322/1750 train_time:624284ms step_avg:472.23ms
[train step 1322] avg_loss=3.758508 main=3.298170 aux=0.460338 imp_cv2=0.1353 load_cv2=5.2219 usage_frac=0.4018 topk_prob_mean=0.2696 ema_alpha_reverse=nan max_logit=11.7917
step:1323/1750 train_time:624734ms step_avg:472.21ms
[train step 1323] avg_loss=4.300806 main=3.791591 aux=0.509215 imp_cv2=0.0396 load_cv2=5.9161 usage_frac=0.4152 topk_prob_mean=0.1965 ema_alpha_reverse=nan max_logit=11.7917
step:1324/1750 train_time:625186ms step_avg:472.19ms
[train step 1324] avg_loss=3.385409 main=2.929841 aux=0.455568 imp_cv2=0.1881 load_cv2=5.1162 usage_frac=0.4107 topk_prob_mean=0.2876 ema_alpha_reverse=nan max_logit=11.7917
step:1325/1750 train_time:625640ms step_avg:472.18ms
[train step 1325] avg_loss=3.421205 main=2.959008 aux=0.462197 imp_cv2=0.1362 load_cv2=5.2460 usage_frac=0.4062 topk_prob_mean=0.2660 ema_alpha_reverse=nan max_logit=11.7917
step:1326/1750 train_time:626094ms step_avg:472.17ms
[train step 1326] avg_loss=3.175473 main=2.705270 aux=0.470203 imp_cv2=0.0826 load_cv2=5.4031 usage_frac=0.4018 topk_prob_mean=0.2414 ema_alpha_reverse=nan max_logit=11.7917
step:1327/1750 train_time:626536ms step_avg:472.14ms
[train step 1327] avg_loss=3.574487 main=3.094651 aux=0.479836 imp_cv2=0.0565 load_cv2=5.5419 usage_frac=0.4018 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=11.7917
step:1328/1750 train_time:626989ms step_avg:472.13ms
[train step 1328] avg_loss=3.671954 main=3.200143 aux=0.471811 imp_cv2=0.0753 load_cv2=5.4293 usage_frac=0.4062 topk_prob_mean=0.2379 ema_alpha_reverse=nan max_logit=11.7917
step:1329/1750 train_time:627440ms step_avg:472.11ms
[train step 1329] avg_loss=3.368861 main=2.917312 aux=0.451550 imp_cv2=0.2147 load_cv2=5.0421 usage_frac=0.4062 topk_prob_mean=0.2968 ema_alpha_reverse=nan max_logit=11.7917
step:1330/1750 train_time:627899ms step_avg:472.10ms
[train step 1330] avg_loss=3.501261 main=3.038050 aux=0.463211 imp_cv2=0.1106 load_cv2=5.2892 usage_frac=0.4062 topk_prob_mean=0.2589 ema_alpha_reverse=nan max_logit=11.7917
step:1331/1750 train_time:628361ms step_avg:472.10ms
[train step 1331] avg_loss=4.040599 main=3.556325 aux=0.484274 imp_cv2=0.0557 load_cv2=5.6025 usage_frac=0.4062 topk_prob_mean=0.2189 ema_alpha_reverse=nan max_logit=11.7917
step:1332/1750 train_time:628827ms step_avg:472.09ms
[train step 1332] avg_loss=3.347603 main=2.892499 aux=0.455104 imp_cv2=0.1545 load_cv2=5.1406 usage_frac=0.4107 topk_prob_mean=0.2774 ema_alpha_reverse=nan max_logit=11.7917
step:1333/1750 train_time:629290ms step_avg:472.09ms
[train step 1333] avg_loss=3.628833 main=3.168486 aux=0.460347 imp_cv2=0.1075 load_cv2=5.2536 usage_frac=0.4107 topk_prob_mean=0.2585 ema_alpha_reverse=nan max_logit=11.7917
step:1334/1750 train_time:629749ms step_avg:472.08ms
[train step 1334] avg_loss=3.283413 main=2.828342 aux=0.455071 imp_cv2=0.1561 load_cv2=5.1391 usage_frac=0.4018 topk_prob_mean=0.2776 ema_alpha_reverse=nan max_logit=11.7917
step:1335/1750 train_time:630213ms step_avg:472.07ms
[train step 1335] avg_loss=4.178334 main=3.699250 aux=0.479084 imp_cv2=0.0584 load_cv2=5.5301 usage_frac=0.4018 topk_prob_mean=0.2201 ema_alpha_reverse=nan max_logit=11.7917
step:1336/1750 train_time:630668ms step_avg:472.06ms
[train step 1336] avg_loss=3.262827 main=2.796533 aux=0.466294 imp_cv2=0.0664 load_cv2=5.3613 usage_frac=0.4107 topk_prob_mean=0.2380 ema_alpha_reverse=nan max_logit=11.7917
step:1337/1750 train_time:631122ms step_avg:472.04ms
[train step 1337] avg_loss=3.336345 main=2.886280 aux=0.450065 imp_cv2=0.1714 load_cv2=5.0604 usage_frac=0.4018 topk_prob_mean=0.2845 ema_alpha_reverse=nan max_logit=11.7917
step:1338/1750 train_time:631567ms step_avg:472.02ms
[train step 1338] avg_loss=3.413293 main=2.950833 aux=0.462460 imp_cv2=0.0979 load_cv2=5.2891 usage_frac=0.4107 topk_prob_mean=0.2502 ema_alpha_reverse=nan max_logit=11.7917
step:1339/1750 train_time:632018ms step_avg:472.01ms
[train step 1339] avg_loss=3.234995 main=2.784507 aux=0.450488 imp_cv2=0.1840 load_cv2=5.0531 usage_frac=0.4018 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=11.7917
step:1340/1750 train_time:632473ms step_avg:471.99ms
[train step 1340] avg_loss=3.771288 main=3.285892 aux=0.485396 imp_cv2=0.0477 load_cv2=5.6145 usage_frac=0.4018 topk_prob_mean=0.2122 ema_alpha_reverse=nan max_logit=11.7917
step:1341/1750 train_time:632923ms step_avg:471.98ms
[train step 1341] avg_loss=3.701408 main=3.243178 aux=0.458230 imp_cv2=0.0922 load_cv2=5.2429 usage_frac=0.4062 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=11.7917
step:1342/1750 train_time:633583ms step_avg:472.12ms
[train step 1342] avg_loss=3.149314 main=2.703167 aux=0.446146 imp_cv2=0.2497 load_cv2=4.9320 usage_frac=0.3973 topk_prob_mean=0.3083 ema_alpha_reverse=nan max_logit=11.7917
step:1343/1750 train_time:634054ms step_avg:472.12ms
[train step 1343] avg_loss=3.156335 main=2.707318 aux=0.449017 imp_cv2=0.2016 load_cv2=5.0185 usage_frac=0.4107 topk_prob_mean=0.2925 ema_alpha_reverse=nan max_logit=11.7917
step:1344/1750 train_time:634508ms step_avg:472.10ms
[train step 1344] avg_loss=3.225853 main=2.774626 aux=0.451226 imp_cv2=0.1631 load_cv2=5.0846 usage_frac=0.4062 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=11.7917
step:1345/1750 train_time:635157ms step_avg:472.24ms
[train step 1345] avg_loss=3.668207 main=3.195272 aux=0.472936 imp_cv2=0.0674 load_cv2=5.4440 usage_frac=0.4018 topk_prob_mean=0.2321 ema_alpha_reverse=nan max_logit=11.7917
step:1346/1750 train_time:635612ms step_avg:472.22ms
[train step 1346] avg_loss=3.907009 main=3.441602 aux=0.465407 imp_cv2=0.0728 load_cv2=5.3474 usage_frac=0.4062 topk_prob_mean=0.2384 ema_alpha_reverse=nan max_logit=11.7917
step:1347/1750 train_time:636074ms step_avg:472.22ms
[train step 1347] avg_loss=3.054469 main=2.601776 aux=0.452693 imp_cv2=0.1871 load_cv2=5.0753 usage_frac=0.4018 topk_prob_mean=0.2857 ema_alpha_reverse=nan max_logit=11.7917
step:1348/1750 train_time:636531ms step_avg:472.20ms
[train step 1348] avg_loss=3.824630 main=3.358849 aux=0.465781 imp_cv2=0.0862 load_cv2=5.3341 usage_frac=0.4107 topk_prob_mean=0.2440 ema_alpha_reverse=nan max_logit=11.7917
step:1349/1750 train_time:636982ms step_avg:472.19ms
[train step 1349] avg_loss=3.654668 main=3.157970 aux=0.496698 imp_cv2=0.0431 load_cv2=5.7586 usage_frac=0.3973 topk_prob_mean=0.2012 ema_alpha_reverse=nan max_logit=11.7917
step:1350/1750 train_time:637427ms step_avg:472.17ms
Running validation...
step:1350/1750 val_loss:3.050507 train_time:637439ms step_avg:472.18ms
[train step 1350] avg_loss=3.320953 main=2.873776 aux=0.447177 imp_cv2=0.1713 load_cv2=5.0238 usage_frac=0.4107 topk_prob_mean=0.2855 ema_alpha_reverse=nan max_logit=11.7917
step:1351/1750 train_time:637888ms step_avg:472.16ms
[train step 1351] avg_loss=3.939685 main=3.469187 aux=0.470498 imp_cv2=0.0659 load_cv2=5.4163 usage_frac=0.4018 topk_prob_mean=0.2346 ema_alpha_reverse=nan max_logit=11.7917
step:1352/1750 train_time:638340ms step_avg:472.15ms
[train step 1352] avg_loss=3.454793 main=2.995393 aux=0.459400 imp_cv2=0.1055 load_cv2=5.2393 usage_frac=0.4107 topk_prob_mean=0.2569 ema_alpha_reverse=nan max_logit=12.4293
step:1353/1750 train_time:638791ms step_avg:472.13ms
[train step 1353] avg_loss=3.670852 main=3.203715 aux=0.467137 imp_cv2=0.0960 load_cv2=5.3401 usage_frac=0.4107 topk_prob_mean=0.2492 ema_alpha_reverse=nan max_logit=11.7917
step:1354/1750 train_time:639255ms step_avg:472.12ms
[train step 1354] avg_loss=2.941613 main=2.490231 aux=0.451382 imp_cv2=0.2499 load_cv2=4.9916 usage_frac=0.4107 topk_prob_mean=0.3049 ema_alpha_reverse=nan max_logit=11.7917
step:1355/1750 train_time:639710ms step_avg:472.11ms
[train step 1355] avg_loss=3.108200 main=2.652484 aux=0.455717 imp_cv2=0.1937 load_cv2=5.0988 usage_frac=0.4018 topk_prob_mean=0.2878 ema_alpha_reverse=nan max_logit=11.7917
step:1356/1750 train_time:640163ms step_avg:472.10ms
[train step 1356] avg_loss=3.403262 main=2.924604 aux=0.478658 imp_cv2=0.0580 load_cv2=5.5173 usage_frac=0.4062 topk_prob_mean=0.2276 ema_alpha_reverse=nan max_logit=11.7917
step:1357/1750 train_time:640615ms step_avg:472.08ms
[train step 1357] avg_loss=4.147165 main=3.622383 aux=0.524781 imp_cv2=0.0293 load_cv2=6.0972 usage_frac=0.3884 topk_prob_mean=0.1719 ema_alpha_reverse=nan max_logit=10.8091
step:1358/1750 train_time:641057ms step_avg:472.06ms
[train step 1358] avg_loss=3.468478 main=3.012193 aux=0.456285 imp_cv2=0.1863 load_cv2=5.1172 usage_frac=0.4018 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=11.7917
step:1359/1750 train_time:641506ms step_avg:472.04ms
[train step 1359] avg_loss=4.045322 main=3.565900 aux=0.479423 imp_cv2=0.0712 load_cv2=5.5108 usage_frac=0.4062 topk_prob_mean=0.2325 ema_alpha_reverse=nan max_logit=11.7917
step:1360/1750 train_time:641955ms step_avg:472.03ms
[train step 1360] avg_loss=3.529744 main=3.068327 aux=0.461417 imp_cv2=0.1407 load_cv2=5.2247 usage_frac=0.4062 topk_prob_mean=0.2696 ema_alpha_reverse=nan max_logit=11.7917
step:1361/1750 train_time:642413ms step_avg:472.02ms
[train step 1361] avg_loss=3.531056 main=3.070546 aux=0.460510 imp_cv2=0.1337 load_cv2=5.2243 usage_frac=0.4018 topk_prob_mean=0.2664 ema_alpha_reverse=nan max_logit=11.7917
step:1362/1750 train_time:642860ms step_avg:472.00ms
[train step 1362] avg_loss=3.445960 main=2.987795 aux=0.458165 imp_cv2=0.1192 load_cv2=5.2078 usage_frac=0.4107 topk_prob_mean=0.2634 ema_alpha_reverse=nan max_logit=11.7917
step:1363/1750 train_time:643304ms step_avg:471.98ms
[train step 1363] avg_loss=3.173689 main=2.718292 aux=0.455397 imp_cv2=0.1563 load_cv2=5.1397 usage_frac=0.4062 topk_prob_mean=0.2767 ema_alpha_reverse=nan max_logit=11.7917
step:1364/1750 train_time:643753ms step_avg:471.96ms
[train step 1364] avg_loss=3.065878 main=2.608258 aux=0.457620 imp_cv2=0.1485 load_cv2=5.1752 usage_frac=0.4107 topk_prob_mean=0.2727 ema_alpha_reverse=nan max_logit=11.7917
step:1365/1750 train_time:644201ms step_avg:471.94ms
[train step 1365] avg_loss=3.785183 main=3.305400 aux=0.479783 imp_cv2=0.0648 load_cv2=5.5362 usage_frac=0.4062 topk_prob_mean=0.2273 ema_alpha_reverse=nan max_logit=11.7917
step:1366/1750 train_time:644649ms step_avg:471.92ms
[train step 1366] avg_loss=3.242208 main=2.791648 aux=0.450560 imp_cv2=0.2054 load_cv2=5.0302 usage_frac=0.4107 topk_prob_mean=0.2920 ema_alpha_reverse=nan max_logit=11.7917
step:1367/1750 train_time:645100ms step_avg:471.91ms
[train step 1367] avg_loss=3.727902 main=3.216671 aux=0.511230 imp_cv2=0.0444 load_cv2=5.9254 usage_frac=0.4018 topk_prob_mean=0.1844 ema_alpha_reverse=nan max_logit=11.7917
step:1368/1750 train_time:645548ms step_avg:471.89ms
[train step 1368] avg_loss=3.546504 main=3.087512 aux=0.458992 imp_cv2=0.1115 load_cv2=5.2315 usage_frac=0.4018 topk_prob_mean=0.2574 ema_alpha_reverse=nan max_logit=11.7917
step:1369/1750 train_time:646209ms step_avg:472.03ms
[train step 1369] avg_loss=3.295481 main=2.839789 aux=0.455692 imp_cv2=0.1444 load_cv2=5.1569 usage_frac=0.4152 topk_prob_mean=0.2721 ema_alpha_reverse=nan max_logit=11.7917
step:1370/1750 train_time:646665ms step_avg:472.02ms
[train step 1370] avg_loss=3.542138 main=3.074405 aux=0.467733 imp_cv2=0.0856 load_cv2=5.3588 usage_frac=0.4107 topk_prob_mean=0.2450 ema_alpha_reverse=nan max_logit=11.7917
step:1371/1750 train_time:647112ms step_avg:472.00ms
[train step 1371] avg_loss=3.117966 main=2.662686 aux=0.455280 imp_cv2=0.1605 load_cv2=5.1347 usage_frac=0.4107 topk_prob_mean=0.2785 ema_alpha_reverse=nan max_logit=11.7917
step:1372/1750 train_time:647560ms step_avg:471.98ms
[train step 1372] avg_loss=3.473968 main=3.016439 aux=0.457529 imp_cv2=0.1186 load_cv2=5.2007 usage_frac=0.4152 topk_prob_mean=0.2642 ema_alpha_reverse=nan max_logit=11.7917
step:1373/1750 train_time:648011ms step_avg:471.97ms
[train step 1373] avg_loss=3.326961 main=2.871079 aux=0.455882 imp_cv2=0.1478 load_cv2=5.1537 usage_frac=0.4062 topk_prob_mean=0.2750 ema_alpha_reverse=nan max_logit=11.7917
step:1374/1750 train_time:648462ms step_avg:471.95ms
[train step 1374] avg_loss=3.567890 main=3.103911 aux=0.463979 imp_cv2=0.1169 load_cv2=5.2880 usage_frac=0.4107 topk_prob_mean=0.2586 ema_alpha_reverse=nan max_logit=11.7917
step:1375/1750 train_time:648910ms step_avg:471.93ms
[train step 1375] avg_loss=3.956523 main=3.476428 aux=0.480095 imp_cv2=0.0647 load_cv2=5.5400 usage_frac=0.4062 topk_prob_mean=0.2279 ema_alpha_reverse=nan max_logit=11.7917
step:1376/1750 train_time:649352ms step_avg:471.91ms
[train step 1376] avg_loss=4.342568 main=3.848220 aux=0.494348 imp_cv2=0.0401 load_cv2=5.7336 usage_frac=0.4107 topk_prob_mean=0.2084 ema_alpha_reverse=nan max_logit=11.7917
step:1377/1750 train_time:649809ms step_avg:471.90ms
[train step 1377] avg_loss=3.242127 main=2.784082 aux=0.458044 imp_cv2=0.1234 load_cv2=5.2069 usage_frac=0.4062 topk_prob_mean=0.2643 ema_alpha_reverse=nan max_logit=11.7917
step:1378/1750 train_time:650258ms step_avg:471.89ms
[train step 1378] avg_loss=4.374867 main=3.856650 aux=0.518218 imp_cv2=0.0398 load_cv2=6.0177 usage_frac=0.3973 topk_prob_mean=0.1900 ema_alpha_reverse=nan max_logit=11.7917
step:1379/1750 train_time:650707ms step_avg:471.87ms
[train step 1379] avg_loss=3.624779 main=3.165010 aux=0.459768 imp_cv2=0.1253 load_cv2=5.2266 usage_frac=0.4018 topk_prob_mean=0.2638 ema_alpha_reverse=nan max_logit=11.7917
step:1380/1750 train_time:651153ms step_avg:471.85ms
[train step 1380] avg_loss=3.566064 main=3.107347 aux=0.458717 imp_cv2=0.1327 load_cv2=5.2077 usage_frac=0.4107 topk_prob_mean=0.2662 ema_alpha_reverse=nan max_logit=11.7917
step:1381/1750 train_time:651608ms step_avg:471.84ms
[train step 1381] avg_loss=3.200101 main=2.746581 aux=0.453520 imp_cv2=0.1798 load_cv2=5.0986 usage_frac=0.4062 topk_prob_mean=0.2826 ema_alpha_reverse=nan max_logit=11.7917
step:1382/1750 train_time:652059ms step_avg:471.82ms
[train step 1382] avg_loss=3.439769 main=2.982646 aux=0.457123 imp_cv2=0.1411 load_cv2=5.1816 usage_frac=0.3973 topk_prob_mean=0.2693 ema_alpha_reverse=nan max_logit=11.7917
step:1383/1750 train_time:652505ms step_avg:471.80ms
[train step 1383] avg_loss=3.354219 main=2.893816 aux=0.460402 imp_cv2=0.1110 load_cv2=5.2467 usage_frac=0.4062 topk_prob_mean=0.2577 ema_alpha_reverse=nan max_logit=11.7917
step:1384/1750 train_time:652975ms step_avg:471.80ms
[train step 1384] avg_loss=3.925508 main=3.440472 aux=0.485037 imp_cv2=0.0738 load_cv2=5.5978 usage_frac=0.4107 topk_prob_mean=0.2237 ema_alpha_reverse=nan max_logit=11.7917
step:1385/1750 train_time:653429ms step_avg:471.79ms
[train step 1385] avg_loss=4.510522 main=3.966370 aux=0.544152 imp_cv2=0.0690 load_cv2=6.3274 usage_frac=0.3616 topk_prob_mean=0.1709 ema_alpha_reverse=nan max_logit=9.8264
step:1386/1750 train_time:653873ms step_avg:471.77ms
[train step 1386] avg_loss=3.137155 main=2.682164 aux=0.454990 imp_cv2=0.1975 load_cv2=5.0994 usage_frac=0.3973 topk_prob_mean=0.2881 ema_alpha_reverse=nan max_logit=11.7917
step:1387/1750 train_time:654320ms step_avg:471.75ms
[train step 1387] avg_loss=3.180867 main=2.725928 aux=0.454940 imp_cv2=0.1243 load_cv2=5.1689 usage_frac=0.4018 topk_prob_mean=0.2648 ema_alpha_reverse=nan max_logit=11.7917
step:1388/1750 train_time:654774ms step_avg:471.74ms
[train step 1388] avg_loss=3.790362 main=3.315779 aux=0.474583 imp_cv2=0.0657 load_cv2=5.4674 usage_frac=0.4018 topk_prob_mean=0.2301 ema_alpha_reverse=nan max_logit=11.7917
step:1389/1750 train_time:655227ms step_avg:471.73ms
[train step 1389] avg_loss=3.490503 main=3.014643 aux=0.475861 imp_cv2=0.0786 load_cv2=5.4714 usage_frac=0.4062 topk_prob_mean=0.2356 ema_alpha_reverse=nan max_logit=11.7917
step:1390/1750 train_time:655868ms step_avg:471.85ms
[train step 1390] avg_loss=3.616130 main=3.144244 aux=0.471886 imp_cv2=0.0739 load_cv2=5.4292 usage_frac=0.4018 topk_prob_mean=0.2343 ema_alpha_reverse=nan max_logit=11.7917
step:1391/1750 train_time:656311ms step_avg:471.83ms
[train step 1391] avg_loss=3.284287 main=2.820951 aux=0.463336 imp_cv2=0.1227 load_cv2=5.2742 usage_frac=0.4062 topk_prob_mean=0.2607 ema_alpha_reverse=nan max_logit=11.7917
step:1392/1750 train_time:656747ms step_avg:471.80ms
[train step 1392] avg_loss=3.747975 main=3.271107 aux=0.476868 imp_cv2=0.0826 load_cv2=5.4747 usage_frac=0.4018 topk_prob_mean=0.2383 ema_alpha_reverse=nan max_logit=11.7917
step:1393/1750 train_time:657196ms step_avg:471.78ms
[train step 1393] avg_loss=3.268687 main=2.802963 aux=0.465724 imp_cv2=0.1345 load_cv2=5.2949 usage_frac=0.3973 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=11.7917
step:1394/1750 train_time:657644ms step_avg:471.77ms
[train step 1394] avg_loss=3.669457 main=3.192266 aux=0.477190 imp_cv2=0.0852 load_cv2=5.4803 usage_frac=0.4107 topk_prob_mean=0.2419 ema_alpha_reverse=nan max_logit=11.7917
step:1395/1750 train_time:658249ms step_avg:471.86ms
[train step 1395] avg_loss=4.088941 main=3.559647 aux=0.529294 imp_cv2=0.0456 load_cv2=6.1518 usage_frac=0.3616 topk_prob_mean=0.1737 ema_alpha_reverse=nan max_logit=9.8264
step:1396/1750 train_time:658703ms step_avg:471.85ms
[train step 1396] avg_loss=3.851276 main=3.374845 aux=0.476431 imp_cv2=0.0758 load_cv2=5.4818 usage_frac=0.3973 topk_prob_mean=0.2351 ema_alpha_reverse=nan max_logit=11.7917
step:1397/1750 train_time:659151ms step_avg:471.83ms
[train step 1397] avg_loss=3.985093 main=3.512581 aux=0.472512 imp_cv2=0.0897 load_cv2=5.4214 usage_frac=0.4018 topk_prob_mean=0.2441 ema_alpha_reverse=nan max_logit=11.7917
step:1398/1750 train_time:659599ms step_avg:471.82ms
[train step 1398] avg_loss=3.910096 main=3.436169 aux=0.473927 imp_cv2=0.1149 load_cv2=5.4151 usage_frac=0.4062 topk_prob_mean=0.2505 ema_alpha_reverse=nan max_logit=11.7917
step:1399/1750 train_time:660048ms step_avg:471.80ms
[train step 1399] avg_loss=3.814228 main=3.339725 aux=0.474503 imp_cv2=0.0923 load_cv2=5.4473 usage_frac=0.3973 topk_prob_mean=0.2408 ema_alpha_reverse=nan max_logit=11.7917
step:1400/1750 train_time:660493ms step_avg:471.78ms
Running validation...
step:1400/1750 val_loss:3.035538 train_time:660505ms step_avg:471.79ms
[train step 1400] avg_loss=3.446300 main=2.978956 aux=0.467344 imp_cv2=0.1313 load_cv2=5.3185 usage_frac=0.3929 topk_prob_mean=0.2611 ema_alpha_reverse=nan max_logit=11.7917
step:1401/1750 train_time:660944ms step_avg:471.77ms
[train step 1401] avg_loss=3.474193 main=3.005532 aux=0.468661 imp_cv2=0.1291 load_cv2=5.3368 usage_frac=0.4062 topk_prob_mean=0.2577 ema_alpha_reverse=nan max_logit=11.7917
step:1402/1750 train_time:661395ms step_avg:471.75ms
[train step 1402] avg_loss=4.104437 main=3.588392 aux=0.516046 imp_cv2=0.0390 load_cv2=6.0113 usage_frac=0.3973 topk_prob_mean=0.1844 ema_alpha_reverse=nan max_logit=11.7917
step:1403/1750 train_time:661834ms step_avg:471.73ms
[train step 1403] avg_loss=3.491246 main=3.017689 aux=0.473557 imp_cv2=0.0971 load_cv2=5.4302 usage_frac=0.4107 topk_prob_mean=0.2453 ema_alpha_reverse=nan max_logit=11.7917
step:1404/1750 train_time:662290ms step_avg:471.72ms
[train step 1404] avg_loss=3.149991 main=2.691520 aux=0.458471 imp_cv2=0.2156 load_cv2=5.1269 usage_frac=0.3973 topk_prob_mean=0.2904 ema_alpha_reverse=nan max_logit=11.7917
step:1405/1750 train_time:662740ms step_avg:471.70ms
[train step 1405] avg_loss=3.193912 main=2.737617 aux=0.456294 imp_cv2=0.2179 load_cv2=5.0984 usage_frac=0.4018 topk_prob_mean=0.2938 ema_alpha_reverse=nan max_logit=11.7917
step:1406/1750 train_time:663204ms step_avg:471.70ms
[train step 1406] avg_loss=4.220249 main=3.721642 aux=0.498607 imp_cv2=0.0473 load_cv2=5.7914 usage_frac=0.4018 topk_prob_mean=0.2043 ema_alpha_reverse=nan max_logit=11.7917
step:1407/1750 train_time:663652ms step_avg:471.68ms
[train step 1407] avg_loss=3.964777 main=3.476983 aux=0.487794 imp_cv2=0.0420 load_cv2=5.6585 usage_frac=0.4018 topk_prob_mean=0.2094 ema_alpha_reverse=nan max_logit=11.7917
step:1408/1750 train_time:664115ms step_avg:471.67ms
[train step 1408] avg_loss=3.595289 main=3.127555 aux=0.467735 imp_cv2=0.1033 load_cv2=5.3509 usage_frac=0.4018 topk_prob_mean=0.2513 ema_alpha_reverse=nan max_logit=11.7917
step:1409/1750 train_time:664563ms step_avg:471.66ms
[train step 1409] avg_loss=3.828708 main=3.358858 aux=0.469850 imp_cv2=0.0799 load_cv2=5.4034 usage_frac=0.3973 topk_prob_mean=0.2398 ema_alpha_reverse=nan max_logit=11.7917
step:1410/1750 train_time:665008ms step_avg:471.64ms
[train step 1410] avg_loss=4.468321 main=3.954534 aux=0.513787 imp_cv2=0.0407 load_cv2=5.9724 usage_frac=0.3929 topk_prob_mean=0.1809 ema_alpha_reverse=nan max_logit=10.8091
step:1411/1750 train_time:665451ms step_avg:471.62ms
[train step 1411] avg_loss=3.403599 main=2.943194 aux=0.460405 imp_cv2=0.1219 load_cv2=5.2458 usage_frac=0.4107 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=11.7917
step:1412/1750 train_time:665895ms step_avg:471.60ms
[train step 1412] avg_loss=3.181449 main=2.727386 aux=0.454064 imp_cv2=0.1974 load_cv2=5.0906 usage_frac=0.4107 topk_prob_mean=0.2878 ema_alpha_reverse=nan max_logit=11.7917
step:1413/1750 train_time:666345ms step_avg:471.58ms
[train step 1413] avg_loss=3.687316 main=3.193816 aux=0.493500 imp_cv2=0.0426 load_cv2=5.7333 usage_frac=0.4062 topk_prob_mean=0.2036 ema_alpha_reverse=nan max_logit=11.7917
step:1414/1750 train_time:666792ms step_avg:471.56ms
[train step 1414] avg_loss=3.533663 main=3.075094 aux=0.458568 imp_cv2=0.1188 load_cv2=5.2252 usage_frac=0.4018 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=11.7917
step:1415/1750 train_time:667237ms step_avg:471.55ms
[train step 1415] avg_loss=3.242633 main=2.790368 aux=0.452264 imp_cv2=0.1517 load_cv2=5.1171 usage_frac=0.4107 topk_prob_mean=0.2753 ema_alpha_reverse=nan max_logit=11.7917
step:1416/1750 train_time:667686ms step_avg:471.53ms
[train step 1416] avg_loss=3.555212 main=3.065778 aux=0.489434 imp_cv2=0.0421 load_cv2=5.6730 usage_frac=0.3973 topk_prob_mean=0.2090 ema_alpha_reverse=nan max_logit=11.7917
step:1417/1750 train_time:668128ms step_avg:471.51ms
[train step 1417] avg_loss=3.922717 main=3.439990 aux=0.482727 imp_cv2=0.0504 load_cv2=5.5852 usage_frac=0.4062 topk_prob_mean=0.2158 ema_alpha_reverse=nan max_logit=11.7917
step:1418/1750 train_time:668575ms step_avg:471.49ms
[train step 1418] avg_loss=3.363539 main=2.909019 aux=0.454521 imp_cv2=0.1828 load_cv2=5.1056 usage_frac=0.4018 topk_prob_mean=0.2815 ema_alpha_reverse=nan max_logit=11.7917
step:1419/1750 train_time:669032ms step_avg:471.48ms
[train step 1419] avg_loss=3.763947 main=3.293875 aux=0.470071 imp_cv2=0.0773 load_cv2=5.4019 usage_frac=0.4062 topk_prob_mean=0.2379 ema_alpha_reverse=nan max_logit=11.7917
step:1420/1750 train_time:669479ms step_avg:471.46ms
[train step 1420] avg_loss=3.221456 main=2.768292 aux=0.453164 imp_cv2=0.1568 load_cv2=5.1153 usage_frac=0.4107 topk_prob_mean=0.2772 ema_alpha_reverse=nan max_logit=11.7917
step:1421/1750 train_time:669931ms step_avg:471.45ms
[train step 1421] avg_loss=3.508101 main=2.999133 aux=0.508968 imp_cv2=0.0626 load_cv2=5.8872 usage_frac=0.3973 topk_prob_mean=0.1983 ema_alpha_reverse=nan max_logit=10.8091
step:1422/1750 train_time:670390ms step_avg:471.44ms
[train step 1422] avg_loss=3.498722 main=3.026450 aux=0.472272 imp_cv2=0.0742 load_cv2=5.4332 usage_frac=0.4062 topk_prob_mean=0.2364 ema_alpha_reverse=nan max_logit=11.7917
step:1423/1750 train_time:670834ms step_avg:471.42ms
[train step 1423] avg_loss=3.781942 main=3.313902 aux=0.468040 imp_cv2=0.0758 load_cv2=5.3761 usage_frac=0.4018 topk_prob_mean=0.2384 ema_alpha_reverse=nan max_logit=11.7917
step:1424/1750 train_time:671281ms step_avg:471.40ms
[train step 1424] avg_loss=3.631240 main=3.157732 aux=0.473508 imp_cv2=0.0579 load_cv2=5.4676 usage_frac=0.4062 topk_prob_mean=0.2267 ema_alpha_reverse=nan max_logit=11.7917
step:1425/1750 train_time:671725ms step_avg:471.39ms
[train step 1425] avg_loss=4.296999 main=3.755074 aux=0.541925 imp_cv2=0.0494 load_cv2=6.3066 usage_frac=0.3705 topk_prob_mean=0.1637 ema_alpha_reverse=nan max_logit=9.8264
step:1426/1750 train_time:672185ms step_avg:471.38ms
[train step 1426] avg_loss=3.412918 main=2.959950 aux=0.452967 imp_cv2=0.1486 load_cv2=5.1200 usage_frac=0.4018 topk_prob_mean=0.2768 ema_alpha_reverse=nan max_logit=11.7917
step:1427/1750 train_time:672637ms step_avg:471.36ms
[train step 1427] avg_loss=3.447564 main=2.964653 aux=0.482911 imp_cv2=0.0499 load_cv2=5.5788 usage_frac=0.4018 topk_prob_mean=0.2192 ema_alpha_reverse=nan max_logit=11.7917
step:1428/1750 train_time:673095ms step_avg:471.36ms
[train step 1428] avg_loss=3.122236 main=2.663899 aux=0.458337 imp_cv2=0.1519 load_cv2=5.1740 usage_frac=0.3973 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:1429/1750 train_time:673551ms step_avg:471.34ms
[train step 1429] avg_loss=3.467414 main=3.006942 aux=0.460473 imp_cv2=0.1053 load_cv2=5.2584 usage_frac=0.4018 topk_prob_mean=0.2578 ema_alpha_reverse=nan max_logit=11.7917
step:1430/1750 train_time:674004ms step_avg:471.33ms
[train step 1430] avg_loss=3.834592 main=3.344189 aux=0.490402 imp_cv2=0.0369 load_cv2=5.6873 usage_frac=0.3973 topk_prob_mean=0.2022 ema_alpha_reverse=nan max_logit=11.7917
step:1431/1750 train_time:674445ms step_avg:471.31ms
[train step 1431] avg_loss=3.289132 main=2.819563 aux=0.469569 imp_cv2=0.0917 load_cv2=5.3769 usage_frac=0.4018 topk_prob_mean=0.2448 ema_alpha_reverse=nan max_logit=11.7917
step:1432/1750 train_time:674892ms step_avg:471.29ms
[train step 1432] avg_loss=3.337098 main=2.880577 aux=0.456521 imp_cv2=0.1329 load_cv2=5.1802 usage_frac=0.4018 topk_prob_mean=0.2681 ema_alpha_reverse=nan max_logit=11.7917
step:1433/1750 train_time:675347ms step_avg:471.28ms
[train step 1433] avg_loss=3.097139 main=2.640389 aux=0.456749 imp_cv2=0.1611 load_cv2=5.1541 usage_frac=0.3973 topk_prob_mean=0.2773 ema_alpha_reverse=nan max_logit=11.7917
step:1434/1750 train_time:675795ms step_avg:471.27ms
[train step 1434] avg_loss=3.594410 main=3.137202 aux=0.457208 imp_cv2=0.1568 load_cv2=5.1635 usage_frac=0.3973 topk_prob_mean=0.2756 ema_alpha_reverse=nan max_logit=11.7917
step:1435/1750 train_time:676263ms step_avg:471.26ms
[train step 1435] avg_loss=3.391259 main=2.931620 aux=0.459639 imp_cv2=0.1096 load_cv2=5.2410 usage_frac=0.4018 topk_prob_mean=0.2571 ema_alpha_reverse=nan max_logit=11.7917
step:1436/1750 train_time:676726ms step_avg:471.26ms
[train step 1436] avg_loss=3.570393 main=3.106747 aux=0.463646 imp_cv2=0.1117 load_cv2=5.2882 usage_frac=0.3929 topk_prob_mean=0.2572 ema_alpha_reverse=nan max_logit=11.7917
step:1437/1750 train_time:677182ms step_avg:471.25ms
[train step 1437] avg_loss=3.567302 main=3.099784 aux=0.467518 imp_cv2=0.0887 load_cv2=5.3602 usage_frac=0.4018 topk_prob_mean=0.2449 ema_alpha_reverse=nan max_logit=11.7917
step:1438/1750 train_time:677633ms step_avg:471.23ms
[train step 1438] avg_loss=3.445823 main=2.991331 aux=0.454492 imp_cv2=0.1662 load_cv2=5.1244 usage_frac=0.3973 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=11.7917
step:1439/1750 train_time:678083ms step_avg:471.22ms
[train step 1439] avg_loss=3.257647 main=2.795889 aux=0.461758 imp_cv2=0.1265 load_cv2=5.2452 usage_frac=0.3973 topk_prob_mean=0.2637 ema_alpha_reverse=nan max_logit=11.7917
step:1440/1750 train_time:678530ms step_avg:471.20ms
[train step 1440] avg_loss=3.143538 main=2.690319 aux=0.453219 imp_cv2=0.1750 load_cv2=5.0995 usage_frac=0.3973 topk_prob_mean=0.2838 ema_alpha_reverse=nan max_logit=11.7917
step:1441/1750 train_time:678986ms step_avg:471.19ms
[train step 1441] avg_loss=3.530072 main=3.065583 aux=0.464489 imp_cv2=0.0974 load_cv2=5.3157 usage_frac=0.4018 topk_prob_mean=0.2507 ema_alpha_reverse=nan max_logit=11.7917
step:1442/1750 train_time:679434ms step_avg:471.17ms
[train step 1442] avg_loss=3.243511 main=2.793994 aux=0.449517 imp_cv2=0.2031 load_cv2=5.0277 usage_frac=0.3973 topk_prob_mean=0.2942 ema_alpha_reverse=nan max_logit=11.7917
step:1443/1750 train_time:679889ms step_avg:471.16ms
[train step 1443] avg_loss=3.218125 main=2.766002 aux=0.452124 imp_cv2=0.1378 load_cv2=5.1187 usage_frac=0.3973 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=11.7917
step:1444/1750 train_time:680340ms step_avg:471.15ms
[train step 1444] avg_loss=3.239240 main=2.789020 aux=0.450220 imp_cv2=0.1453 load_cv2=5.0883 usage_frac=0.3973 topk_prob_mean=0.2759 ema_alpha_reverse=nan max_logit=11.7917
step:1445/1750 train_time:680805ms step_avg:471.15ms
[train step 1445] avg_loss=3.353984 main=2.902050 aux=0.451934 imp_cv2=0.1438 load_cv2=5.1155 usage_frac=0.4062 topk_prob_mean=0.2746 ema_alpha_reverse=nan max_logit=11.7917
step:1446/1750 train_time:681263ms step_avg:471.14ms
[train step 1446] avg_loss=3.733752 main=3.265698 aux=0.468054 imp_cv2=0.0777 load_cv2=5.3802 usage_frac=0.4018 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=11.7917
step:1447/1750 train_time:681716ms step_avg:471.12ms
[train step 1447] avg_loss=3.466313 main=3.007975 aux=0.458339 imp_cv2=0.1181 load_cv2=5.2173 usage_frac=0.4062 topk_prob_mean=0.2604 ema_alpha_reverse=nan max_logit=11.7917
step:1448/1750 train_time:682165ms step_avg:471.11ms
[train step 1448] avg_loss=3.297542 main=2.846978 aux=0.450565 imp_cv2=0.1854 load_cv2=5.0529 usage_frac=0.3929 topk_prob_mean=0.2894 ema_alpha_reverse=nan max_logit=11.7917
step:1449/1750 train_time:682617ms step_avg:471.10ms
[train step 1449] avg_loss=3.307206 main=2.849219 aux=0.457987 imp_cv2=0.1074 load_cv2=5.2226 usage_frac=0.4018 topk_prob_mean=0.2595 ema_alpha_reverse=nan max_logit=11.7917
step:1450/1750 train_time:683070ms step_avg:471.08ms
Running validation...
step:1450/1750 val_loss:2.998832 train_time:683081ms step_avg:471.09ms
[train step 1450] avg_loss=3.743821 main=3.275652 aux=0.468169 imp_cv2=0.1020 load_cv2=5.3514 usage_frac=0.4018 topk_prob_mean=0.2482 ema_alpha_reverse=nan max_logit=11.7917
step:1451/1750 train_time:683512ms step_avg:471.06ms
[train step 1451] avg_loss=3.664584 main=3.195528 aux=0.469056 imp_cv2=0.0664 load_cv2=5.3947 usage_frac=0.4062 topk_prob_mean=0.2341 ema_alpha_reverse=nan max_logit=11.7917
step:1452/1750 train_time:683964ms step_avg:471.05ms
[train step 1452] avg_loss=3.485685 main=3.023366 aux=0.462319 imp_cv2=0.0955 load_cv2=5.2837 usage_frac=0.4018 topk_prob_mean=0.2514 ema_alpha_reverse=nan max_logit=11.7917
step:1453/1750 train_time:684410ms step_avg:471.03ms
[train step 1453] avg_loss=3.266338 main=2.816742 aux=0.449596 imp_cv2=0.1856 load_cv2=5.0428 usage_frac=0.4062 topk_prob_mean=0.2881 ema_alpha_reverse=nan max_logit=11.7917
step:1454/1750 train_time:684856ms step_avg:471.02ms
[train step 1454] avg_loss=3.499234 main=3.041320 aux=0.457914 imp_cv2=0.1200 load_cv2=5.2073 usage_frac=0.4018 topk_prob_mean=0.2630 ema_alpha_reverse=nan max_logit=11.7917
step:1455/1750 train_time:685305ms step_avg:471.00ms
[train step 1455] avg_loss=3.303043 main=2.851094 aux=0.451948 imp_cv2=0.1731 load_cv2=5.0802 usage_frac=0.4062 topk_prob_mean=0.2830 ema_alpha_reverse=nan max_logit=11.7917
step:1456/1750 train_time:685757ms step_avg:470.99ms
[train step 1456] avg_loss=3.292595 main=2.838820 aux=0.453774 imp_cv2=0.1452 load_cv2=5.1348 usage_frac=0.4062 topk_prob_mean=0.2730 ema_alpha_reverse=nan max_logit=11.7917
step:1457/1750 train_time:686432ms step_avg:471.13ms
[train step 1457] avg_loss=4.113441 main=3.579304 aux=0.534137 imp_cv2=0.0373 load_cv2=6.1910 usage_frac=0.3661 topk_prob_mean=0.1664 ema_alpha_reverse=nan max_logit=9.8264
step:1458/1750 train_time:686872ms step_avg:471.11ms
[train step 1458] avg_loss=4.065247 main=3.584469 aux=0.480779 imp_cv2=0.0519 load_cv2=5.5536 usage_frac=0.4018 topk_prob_mean=0.2237 ema_alpha_reverse=nan max_logit=11.7917
step:1459/1750 train_time:687320ms step_avg:471.09ms
[train step 1459] avg_loss=3.263693 main=2.814488 aux=0.449205 imp_cv2=0.1702 load_cv2=5.0543 usage_frac=0.4107 topk_prob_mean=0.2827 ema_alpha_reverse=nan max_logit=11.7917
step:1460/1750 train_time:687775ms step_avg:471.08ms
[train step 1460] avg_loss=3.337211 main=2.888039 aux=0.449172 imp_cv2=0.1568 load_cv2=5.0663 usage_frac=0.4062 topk_prob_mean=0.2802 ema_alpha_reverse=nan max_logit=11.7917
step:1461/1750 train_time:688228ms step_avg:471.07ms
[train step 1461] avg_loss=3.069512 main=2.623938 aux=0.445574 imp_cv2=0.2118 load_cv2=4.9614 usage_frac=0.4018 topk_prob_mean=0.2973 ema_alpha_reverse=nan max_logit=11.7917
step:1462/1750 train_time:688676ms step_avg:471.05ms
[train step 1462] avg_loss=3.445219 main=2.988618 aux=0.456601 imp_cv2=0.0997 load_cv2=5.2115 usage_frac=0.4018 topk_prob_mean=0.2560 ema_alpha_reverse=nan max_logit=11.7917
step:1463/1750 train_time:689116ms step_avg:471.03ms
[train step 1463] avg_loss=3.699744 main=3.231388 aux=0.468356 imp_cv2=0.0623 load_cv2=5.3914 usage_frac=0.4062 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=11.7917
step:1464/1750 train_time:689567ms step_avg:471.02ms
[train step 1464] avg_loss=3.645992 main=3.175863 aux=0.470129 imp_cv2=0.0640 load_cv2=5.4215 usage_frac=0.4018 topk_prob_mean=0.2309 ema_alpha_reverse=nan max_logit=11.7917
step:1465/1750 train_time:690013ms step_avg:471.00ms
[train step 1465] avg_loss=3.867142 main=3.391903 aux=0.475239 imp_cv2=0.0588 load_cv2=5.4808 usage_frac=0.4062 topk_prob_mean=0.2248 ema_alpha_reverse=nan max_logit=11.7917
step:1466/1750 train_time:690464ms step_avg:470.99ms
[train step 1466] avg_loss=3.522805 main=3.068855 aux=0.453951 imp_cv2=0.1021 load_cv2=5.1770 usage_frac=0.4062 topk_prob_mean=0.2574 ema_alpha_reverse=nan max_logit=12.3263
step:1467/1750 train_time:690907ms step_avg:470.97ms
[train step 1467] avg_loss=3.273592 main=2.820678 aux=0.452914 imp_cv2=0.1252 load_cv2=5.1434 usage_frac=0.4018 topk_prob_mean=0.2660 ema_alpha_reverse=nan max_logit=11.7917
step:1468/1750 train_time:691355ms step_avg:470.95ms
[train step 1468] avg_loss=3.169550 main=2.713179 aux=0.456371 imp_cv2=0.1276 load_cv2=5.1801 usage_frac=0.4062 topk_prob_mean=0.2648 ema_alpha_reverse=nan max_logit=11.7917
step:1469/1750 train_time:691799ms step_avg:470.93ms
[train step 1469] avg_loss=3.349765 main=2.898415 aux=0.451350 imp_cv2=0.1531 load_cv2=5.0951 usage_frac=0.4107 topk_prob_mean=0.2778 ema_alpha_reverse=nan max_logit=11.7917
step:1470/1750 train_time:692249ms step_avg:470.92ms
[train step 1470] avg_loss=2.882603 main=2.433551 aux=0.449052 imp_cv2=0.2001 load_cv2=5.0200 usage_frac=0.4062 topk_prob_mean=0.2945 ema_alpha_reverse=nan max_logit=11.7917
step:1471/1750 train_time:692700ms step_avg:470.90ms
[train step 1471] avg_loss=4.335029 main=3.854731 aux=0.480298 imp_cv2=0.0484 load_cv2=5.5490 usage_frac=0.4062 topk_prob_mean=0.2184 ema_alpha_reverse=nan max_logit=11.7917
step:1472/1750 train_time:693164ms step_avg:470.90ms
[train step 1472] avg_loss=3.639169 main=3.178406 aux=0.460764 imp_cv2=0.0980 load_cv2=5.2649 usage_frac=0.4062 topk_prob_mean=0.2510 ema_alpha_reverse=nan max_logit=11.7917
step:1473/1750 train_time:693607ms step_avg:470.88ms
[train step 1473] avg_loss=4.142116 main=3.662071 aux=0.480045 imp_cv2=0.0496 load_cv2=5.5443 usage_frac=0.4018 topk_prob_mean=0.2203 ema_alpha_reverse=nan max_logit=11.7917
step:1474/1750 train_time:694059ms step_avg:470.87ms
[train step 1474] avg_loss=3.513117 main=3.057510 aux=0.455607 imp_cv2=0.1302 load_cv2=5.1706 usage_frac=0.4107 topk_prob_mean=0.2667 ema_alpha_reverse=nan max_logit=11.7917
step:1475/1750 train_time:694509ms step_avg:470.85ms
[train step 1475] avg_loss=4.156363 main=3.622620 aux=0.533743 imp_cv2=0.0394 load_cv2=6.2129 usage_frac=0.3661 topk_prob_mean=0.1633 ema_alpha_reverse=nan max_logit=9.8264
step:1476/1750 train_time:694961ms step_avg:470.84ms
[train step 1476] avg_loss=3.874780 main=3.411493 aux=0.463287 imp_cv2=0.1042 load_cv2=5.2926 usage_frac=0.4062 topk_prob_mean=0.2549 ema_alpha_reverse=nan max_logit=11.7917
step:1477/1750 train_time:695411ms step_avg:470.83ms
[train step 1477] avg_loss=3.334112 main=2.877362 aux=0.456750 imp_cv2=0.1213 load_cv2=5.1918 usage_frac=0.4062 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=11.7917
step:1478/1750 train_time:695870ms step_avg:470.82ms
[train step 1478] avg_loss=3.801249 main=3.335601 aux=0.465648 imp_cv2=0.1097 load_cv2=5.3160 usage_frac=0.4062 topk_prob_mean=0.2561 ema_alpha_reverse=nan max_logit=11.7917
step:1479/1750 train_time:696313ms step_avg:470.80ms
[train step 1479] avg_loss=3.180434 main=2.727161 aux=0.453272 imp_cv2=0.2095 load_cv2=5.0640 usage_frac=0.3973 topk_prob_mean=0.2940 ema_alpha_reverse=nan max_logit=11.7917
step:1480/1750 train_time:696757ms step_avg:470.78ms
[train step 1480] avg_loss=3.230433 main=2.780888 aux=0.449545 imp_cv2=0.1951 load_cv2=5.0331 usage_frac=0.4018 topk_prob_mean=0.2910 ema_alpha_reverse=nan max_logit=11.7917
step:1481/1750 train_time:697206ms step_avg:470.77ms
[train step 1481] avg_loss=3.546631 main=3.076036 aux=0.470595 imp_cv2=0.0818 load_cv2=5.4078 usage_frac=0.4062 topk_prob_mean=0.2401 ema_alpha_reverse=nan max_logit=11.7917
step:1482/1750 train_time:697657ms step_avg:470.75ms
[train step 1482] avg_loss=3.083220 main=2.636087 aux=0.447133 imp_cv2=0.2547 load_cv2=4.9449 usage_frac=0.3973 topk_prob_mean=0.3091 ema_alpha_reverse=nan max_logit=11.7917
step:1483/1750 train_time:698143ms step_avg:470.76ms
[train step 1483] avg_loss=3.470991 main=3.009603 aux=0.461388 imp_cv2=0.0925 load_cv2=5.2811 usage_frac=0.4062 topk_prob_mean=0.2499 ema_alpha_reverse=nan max_logit=11.7917
step:1484/1750 train_time:698599ms step_avg:470.75ms
[train step 1484] avg_loss=3.399338 main=2.949725 aux=0.449613 imp_cv2=0.1552 load_cv2=5.0803 usage_frac=0.4062 topk_prob_mean=0.2777 ema_alpha_reverse=nan max_logit=11.7917
step:1485/1750 train_time:699066ms step_avg:470.75ms
[train step 1485] avg_loss=3.028658 main=2.581934 aux=0.446723 imp_cv2=0.2230 load_cv2=4.9729 usage_frac=0.4062 topk_prob_mean=0.2991 ema_alpha_reverse=nan max_logit=11.7917
step:1486/1750 train_time:699535ms step_avg:470.75ms
[train step 1486] avg_loss=3.215366 main=2.770648 aux=0.444718 imp_cv2=0.1834 load_cv2=4.9858 usage_frac=0.4062 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=11.7917
step:1487/1750 train_time:699982ms step_avg:470.73ms
[train step 1487] avg_loss=3.321020 main=2.867900 aux=0.453120 imp_cv2=0.1429 load_cv2=5.1275 usage_frac=0.4062 topk_prob_mean=0.2713 ema_alpha_reverse=nan max_logit=11.7917
step:1488/1750 train_time:700441ms step_avg:470.73ms
[train step 1488] avg_loss=3.273162 main=2.822091 aux=0.451071 imp_cv2=0.1404 load_cv2=5.1072 usage_frac=0.3973 topk_prob_mean=0.2712 ema_alpha_reverse=nan max_logit=11.7917
step:1489/1750 train_time:700890ms step_avg:470.71ms
[train step 1489] avg_loss=3.575971 main=3.115786 aux=0.460185 imp_cv2=0.1041 load_cv2=5.2595 usage_frac=0.4018 topk_prob_mean=0.2532 ema_alpha_reverse=nan max_logit=11.7917
step:1490/1750 train_time:701350ms step_avg:470.70ms
[train step 1490] avg_loss=3.406838 main=2.949433 aux=0.457404 imp_cv2=0.1031 load_cv2=5.2269 usage_frac=0.4018 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=11.7917
step:1491/1750 train_time:701800ms step_avg:470.69ms
[train step 1491] avg_loss=3.548010 main=3.092609 aux=0.455400 imp_cv2=0.1060 load_cv2=5.1932 usage_frac=0.3929 topk_prob_mean=0.2563 ema_alpha_reverse=nan max_logit=11.7917
step:1492/1750 train_time:702262ms step_avg:470.69ms
[train step 1492] avg_loss=3.837295 main=3.362507 aux=0.474788 imp_cv2=0.0506 load_cv2=5.4900 usage_frac=0.4018 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=11.7917
step:1493/1750 train_time:702719ms step_avg:470.68ms
[train step 1493] avg_loss=3.143636 main=2.699567 aux=0.444069 imp_cv2=0.1987 load_cv2=4.9662 usage_frac=0.4062 topk_prob_mean=0.2932 ema_alpha_reverse=nan max_logit=11.7917
step:1494/1750 train_time:703173ms step_avg:470.66ms
[train step 1494] avg_loss=3.487956 main=3.029521 aux=0.458435 imp_cv2=0.1094 load_cv2=5.2272 usage_frac=0.4062 topk_prob_mean=0.2578 ema_alpha_reverse=nan max_logit=11.7917
step:1495/1750 train_time:703630ms step_avg:470.66ms
[train step 1495] avg_loss=3.464795 main=3.010474 aux=0.454321 imp_cv2=0.1105 load_cv2=5.1817 usage_frac=0.4107 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=11.7917
step:1496/1750 train_time:704078ms step_avg:470.64ms
[train step 1496] avg_loss=3.173050 main=2.717546 aux=0.455503 imp_cv2=0.1162 load_cv2=5.1884 usage_frac=0.4107 topk_prob_mean=0.2604 ema_alpha_reverse=nan max_logit=11.7917
step:1497/1750 train_time:704537ms step_avg:470.63ms
[train step 1497] avg_loss=3.346840 main=2.892991 aux=0.453849 imp_cv2=0.1423 load_cv2=5.1392 usage_frac=0.4062 topk_prob_mean=0.2698 ema_alpha_reverse=nan max_logit=11.7917
step:1498/1750 train_time:704997ms step_avg:470.63ms
[train step 1498] avg_loss=3.887686 main=3.428399 aux=0.459287 imp_cv2=0.0932 load_cv2=5.2482 usage_frac=0.4018 topk_prob_mean=0.2484 ema_alpha_reverse=nan max_logit=11.7917
step:1499/1750 train_time:705448ms step_avg:470.61ms
[train step 1499] avg_loss=3.424507 main=2.963458 aux=0.461049 imp_cv2=0.0835 load_cv2=5.2904 usage_frac=0.4107 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=11.7917
step:1500/1750 train_time:705900ms step_avg:470.60ms
Running validation...
step:1500/1750 val_loss:2.983929 train_time:705911ms step_avg:470.61ms
[train step 1500] avg_loss=3.365513 main=2.899279 aux=0.466234 imp_cv2=0.0755 load_cv2=5.3529 usage_frac=0.4062 topk_prob_mean=0.2412 ema_alpha_reverse=nan max_logit=11.7917
step:1501/1750 train_time:706357ms step_avg:470.59ms
[train step 1501] avg_loss=3.253041 main=2.803769 aux=0.449272 imp_cv2=0.1559 load_cv2=5.0696 usage_frac=0.4107 topk_prob_mean=0.2785 ema_alpha_reverse=nan max_logit=11.7917
step:1502/1750 train_time:706810ms step_avg:470.58ms
[train step 1502] avg_loss=3.937011 main=3.410875 aux=0.526136 imp_cv2=0.0589 load_cv2=6.0844 usage_frac=0.3661 topk_prob_mean=0.1732 ema_alpha_reverse=nan max_logit=9.8264
step:1503/1750 train_time:707246ms step_avg:470.56ms
[train step 1503] avg_loss=4.663593 main=4.141195 aux=0.522398 imp_cv2=0.0581 load_cv2=6.0424 usage_frac=0.3661 topk_prob_mean=0.1751 ema_alpha_reverse=nan max_logit=9.8264
step:1504/1750 train_time:707686ms step_avg:470.54ms
[train step 1504] avg_loss=3.091086 main=2.640798 aux=0.450289 imp_cv2=0.1582 load_cv2=5.0794 usage_frac=0.4062 topk_prob_mean=0.2784 ema_alpha_reverse=nan max_logit=11.7917
step:1505/1750 train_time:708138ms step_avg:470.52ms
[train step 1505] avg_loss=3.831098 main=3.336024 aux=0.495073 imp_cv2=0.0368 load_cv2=5.7566 usage_frac=0.4062 topk_prob_mean=0.1969 ema_alpha_reverse=nan max_logit=11.7917
step:1506/1750 train_time:708578ms step_avg:470.50ms
[train step 1506] avg_loss=3.143106 main=2.690922 aux=0.452184 imp_cv2=0.1332 load_cv2=5.1255 usage_frac=0.4107 topk_prob_mean=0.2689 ema_alpha_reverse=nan max_logit=11.7917
step:1507/1750 train_time:709028ms step_avg:470.49ms
[train step 1507] avg_loss=3.336159 main=2.876612 aux=0.459546 imp_cv2=0.0927 load_cv2=5.2530 usage_frac=0.4018 topk_prob_mean=0.2506 ema_alpha_reverse=nan max_logit=11.7917
step:1508/1750 train_time:709476ms step_avg:470.47ms
[train step 1508] avg_loss=3.585595 main=3.129808 aux=0.455788 imp_cv2=0.0917 load_cv2=5.2084 usage_frac=0.4107 topk_prob_mean=0.2529 ema_alpha_reverse=nan max_logit=11.7917
step:1509/1750 train_time:709931ms step_avg:470.46ms
[train step 1509] avg_loss=3.235621 main=2.785926 aux=0.449695 imp_cv2=0.1378 load_cv2=5.0931 usage_frac=0.3973 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=11.7917
step:1510/1750 train_time:710384ms step_avg:470.45ms
[train step 1510] avg_loss=3.223322 main=2.779659 aux=0.443664 imp_cv2=0.1957 load_cv2=4.9578 usage_frac=0.4062 topk_prob_mean=0.2932 ema_alpha_reverse=nan max_logit=11.7917
step:1511/1750 train_time:710839ms step_avg:470.44ms
[train step 1511] avg_loss=3.557210 main=3.083970 aux=0.473240 imp_cv2=0.0657 load_cv2=5.4493 usage_frac=0.4107 topk_prob_mean=0.2294 ema_alpha_reverse=nan max_logit=11.7917
step:1512/1750 train_time:711285ms step_avg:470.43ms
[train step 1512] avg_loss=2.991125 main=2.546148 aux=0.444977 imp_cv2=0.1742 load_cv2=4.9968 usage_frac=0.4062 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=11.7917
step:1513/1750 train_time:711739ms step_avg:470.42ms
[train step 1513] avg_loss=3.948564 main=3.442319 aux=0.506245 imp_cv2=0.0507 load_cv2=5.8715 usage_frac=0.3973 topk_prob_mean=0.1868 ema_alpha_reverse=nan max_logit=10.8091
step:1514/1750 train_time:712178ms step_avg:470.40ms
[train step 1514] avg_loss=3.331377 main=2.883136 aux=0.448241 imp_cv2=0.1374 load_cv2=5.0745 usage_frac=0.4018 topk_prob_mean=0.2750 ema_alpha_reverse=nan max_logit=11.7917
step:1515/1750 train_time:712630ms step_avg:470.38ms
[train step 1515] avg_loss=3.316225 main=2.861952 aux=0.454273 imp_cv2=0.1162 load_cv2=5.1706 usage_frac=0.4018 topk_prob_mean=0.2638 ema_alpha_reverse=nan max_logit=11.7917
step:1516/1750 train_time:713078ms step_avg:470.37ms
[train step 1516] avg_loss=3.737870 main=3.269916 aux=0.467955 imp_cv2=0.0663 load_cv2=5.3902 usage_frac=0.4107 topk_prob_mean=0.2364 ema_alpha_reverse=nan max_logit=11.7917
step:1517/1750 train_time:713535ms step_avg:470.36ms
[train step 1517] avg_loss=3.505330 main=3.043575 aux=0.461755 imp_cv2=0.0879 load_cv2=5.2862 usage_frac=0.4062 topk_prob_mean=0.2493 ema_alpha_reverse=nan max_logit=11.7917
step:1518/1750 train_time:714182ms step_avg:470.48ms
[train step 1518] avg_loss=3.389284 main=2.927330 aux=0.461954 imp_cv2=0.0817 load_cv2=5.2991 usage_frac=0.4018 topk_prob_mean=0.2475 ema_alpha_reverse=nan max_logit=11.7917
step:1519/1750 train_time:714629ms step_avg:470.46ms
[train step 1519] avg_loss=3.306965 main=2.855827 aux=0.451137 imp_cv2=0.1574 load_cv2=5.0866 usage_frac=0.4107 topk_prob_mean=0.2766 ema_alpha_reverse=nan max_logit=11.7917
step:1520/1750 train_time:715087ms step_avg:470.45ms
[train step 1520] avg_loss=3.974046 main=3.493235 aux=0.480812 imp_cv2=0.0516 load_cv2=5.5611 usage_frac=0.4062 topk_prob_mean=0.2187 ema_alpha_reverse=nan max_logit=11.7917
step:1521/1750 train_time:715527ms step_avg:470.43ms
[train step 1521] avg_loss=3.381721 main=2.928930 aux=0.452791 imp_cv2=0.1506 load_cv2=5.1156 usage_frac=0.4018 topk_prob_mean=0.2755 ema_alpha_reverse=nan max_logit=11.7917
step:1522/1750 train_time:715974ms step_avg:470.42ms
[train step 1522] avg_loss=4.049073 main=3.540938 aux=0.508135 imp_cv2=0.0306 load_cv2=5.9003 usage_frac=0.4107 topk_prob_mean=0.1862 ema_alpha_reverse=nan max_logit=11.7917
step:1523/1750 train_time:716623ms step_avg:470.53ms
[train step 1523] avg_loss=3.493363 main=3.029782 aux=0.463581 imp_cv2=0.0813 load_cv2=5.3157 usage_frac=0.4062 topk_prob_mean=0.2458 ema_alpha_reverse=nan max_logit=11.7917
step:1524/1750 train_time:717287ms step_avg:470.66ms
[train step 1524] avg_loss=3.524267 main=3.063296 aux=0.460971 imp_cv2=0.0952 load_cv2=5.2751 usage_frac=0.4062 topk_prob_mean=0.2513 ema_alpha_reverse=nan max_logit=11.7917
step:1525/1750 train_time:717917ms step_avg:470.77ms
[train step 1525] avg_loss=3.061411 main=2.611718 aux=0.449693 imp_cv2=0.1748 load_cv2=5.0538 usage_frac=0.4062 topk_prob_mean=0.2866 ema_alpha_reverse=nan max_logit=11.7917
step:1526/1750 train_time:718367ms step_avg:470.75ms
[train step 1526] avg_loss=2.886128 main=2.437170 aux=0.448958 imp_cv2=0.2339 load_cv2=4.9872 usage_frac=0.4018 topk_prob_mean=0.3030 ema_alpha_reverse=nan max_logit=11.7917
step:1527/1750 train_time:718827ms step_avg:470.74ms
[train step 1527] avg_loss=3.426366 main=2.966199 aux=0.460167 imp_cv2=0.0976 load_cv2=5.2579 usage_frac=0.4018 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:1528/1750 train_time:719280ms step_avg:470.73ms
[train step 1528] avg_loss=3.310488 main=2.853306 aux=0.457182 imp_cv2=0.1001 load_cv2=5.2207 usage_frac=0.4062 topk_prob_mean=0.2580 ema_alpha_reverse=nan max_logit=11.7917
step:1529/1750 train_time:719734ms step_avg:470.72ms
[train step 1529] avg_loss=3.352526 main=2.898540 aux=0.453986 imp_cv2=0.1005 load_cv2=5.1831 usage_frac=0.3973 topk_prob_mean=0.2585 ema_alpha_reverse=nan max_logit=11.7917
step:1530/1750 train_time:720177ms step_avg:470.70ms
[train step 1530] avg_loss=3.183017 main=2.732282 aux=0.450736 imp_cv2=0.1360 load_cv2=5.1071 usage_frac=0.4062 topk_prob_mean=0.2717 ema_alpha_reverse=nan max_logit=11.7917
step:1531/1750 train_time:720636ms step_avg:470.70ms
[train step 1531] avg_loss=3.557815 main=3.097872 aux=0.459944 imp_cv2=0.0817 load_cv2=5.2689 usage_frac=0.4062 topk_prob_mean=0.2467 ema_alpha_reverse=nan max_logit=11.7917
step:1532/1750 train_time:721086ms step_avg:470.68ms
[train step 1532] avg_loss=3.555017 main=3.098737 aux=0.456280 imp_cv2=0.1038 load_cv2=5.2071 usage_frac=0.4018 topk_prob_mean=0.2565 ema_alpha_reverse=nan max_logit=11.7917
step:1533/1750 train_time:721541ms step_avg:470.67ms
[train step 1533] avg_loss=3.113040 main=2.664789 aux=0.448251 imp_cv2=0.1620 load_cv2=5.0467 usage_frac=0.4062 topk_prob_mean=0.2809 ema_alpha_reverse=nan max_logit=11.7917
step:1534/1750 train_time:722003ms step_avg:470.67ms
[train step 1534] avg_loss=3.523610 main=3.045933 aux=0.477678 imp_cv2=0.0563 load_cv2=5.5094 usage_frac=0.4062 topk_prob_mean=0.2276 ema_alpha_reverse=nan max_logit=11.7917
step:1535/1750 train_time:722461ms step_avg:470.66ms
[train step 1535] avg_loss=3.139496 main=2.691326 aux=0.448170 imp_cv2=0.1585 load_cv2=5.0466 usage_frac=0.4107 topk_prob_mean=0.2794 ema_alpha_reverse=nan max_logit=11.7917
step:1536/1750 train_time:722909ms step_avg:470.64ms
[train step 1536] avg_loss=3.282464 main=2.831081 aux=0.451382 imp_cv2=0.1059 load_cv2=5.1404 usage_frac=0.4062 topk_prob_mean=0.2596 ema_alpha_reverse=nan max_logit=11.7917
step:1537/1750 train_time:723359ms step_avg:470.63ms
[train step 1537] avg_loss=2.966857 main=2.524438 aux=0.442419 imp_cv2=0.2145 load_cv2=4.9191 usage_frac=0.4062 topk_prob_mean=0.3001 ema_alpha_reverse=nan max_logit=11.7917
step:1538/1750 train_time:723828ms step_avg:470.63ms
[train step 1538] avg_loss=3.291231 main=2.840315 aux=0.450917 imp_cv2=0.1378 load_cv2=5.1053 usage_frac=0.4107 topk_prob_mean=0.2726 ema_alpha_reverse=nan max_logit=11.7917
step:1539/1750 train_time:724279ms step_avg:470.62ms
[train step 1539] avg_loss=4.045365 main=3.561296 aux=0.484069 imp_cv2=0.0514 load_cv2=5.5979 usage_frac=0.4018 topk_prob_mean=0.2166 ema_alpha_reverse=nan max_logit=11.7917
step:1540/1750 train_time:724950ms step_avg:470.75ms
[train step 1540] avg_loss=3.469719 main=2.990223 aux=0.479496 imp_cv2=0.0504 load_cv2=5.5446 usage_frac=0.4062 topk_prob_mean=0.2210 ema_alpha_reverse=nan max_logit=11.7917
step:1541/1750 train_time:725399ms step_avg:470.73ms
[train step 1541] avg_loss=3.054444 main=2.607259 aux=0.447185 imp_cv2=0.1706 load_cv2=5.0207 usage_frac=0.4018 topk_prob_mean=0.2848 ema_alpha_reverse=nan max_logit=11.7917
step:1542/1750 train_time:725856ms step_avg:470.72ms
[train step 1542] avg_loss=3.284025 main=2.827693 aux=0.456332 imp_cv2=0.1049 load_cv2=5.1990 usage_frac=0.4107 topk_prob_mean=0.2594 ema_alpha_reverse=nan max_logit=11.7917
step:1543/1750 train_time:726309ms step_avg:470.71ms
[train step 1543] avg_loss=3.559492 main=3.093825 aux=0.465667 imp_cv2=0.0767 load_cv2=5.3415 usage_frac=0.4062 topk_prob_mean=0.2417 ema_alpha_reverse=nan max_logit=11.7917
step:1544/1750 train_time:726768ms step_avg:470.70ms
[train step 1544] avg_loss=3.213993 main=2.764856 aux=0.449137 imp_cv2=0.1396 load_cv2=5.0765 usage_frac=0.4062 topk_prob_mean=0.2756 ema_alpha_reverse=nan max_logit=11.7917
step:1545/1750 train_time:727215ms step_avg:470.69ms
[train step 1545] avg_loss=3.016123 main=2.569077 aux=0.447047 imp_cv2=0.2327 load_cv2=4.9596 usage_frac=0.4018 topk_prob_mean=0.3049 ema_alpha_reverse=nan max_logit=11.7917
step:1546/1750 train_time:727672ms step_avg:470.68ms
[train step 1546] avg_loss=3.112529 main=2.653100 aux=0.459430 imp_cv2=0.0821 load_cv2=5.2493 usage_frac=0.4018 topk_prob_mean=0.2451 ema_alpha_reverse=nan max_logit=11.7917
step:1547/1750 train_time:728115ms step_avg:470.66ms
[train step 1547] avg_loss=3.213336 main=2.754646 aux=0.458691 imp_cv2=0.0943 load_cv2=5.2395 usage_frac=0.4062 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=11.7917
step:1548/1750 train_time:728570ms step_avg:470.65ms
[train step 1548] avg_loss=3.052990 main=2.608221 aux=0.444769 imp_cv2=0.2058 load_cv2=4.9562 usage_frac=0.4107 topk_prob_mean=0.2951 ema_alpha_reverse=nan max_logit=11.7917
step:1549/1750 train_time:729030ms step_avg:470.65ms
[train step 1549] avg_loss=3.057346 main=2.610422 aux=0.446924 imp_cv2=0.1619 load_cv2=5.0292 usage_frac=0.4018 topk_prob_mean=0.2823 ema_alpha_reverse=nan max_logit=11.7917
step:1550/1750 train_time:729491ms step_avg:470.64ms
Running validation...
step:1550/1750 val_loss:2.948622 train_time:729503ms step_avg:470.65ms
[train step 1550] avg_loss=2.808035 main=2.365513 aux=0.442522 imp_cv2=0.2760 load_cv2=4.8606 usage_frac=0.4062 topk_prob_mean=0.3148 ema_alpha_reverse=nan max_logit=11.7917
step:1551/1750 train_time:729954ms step_avg:470.63ms
[train step 1551] avg_loss=3.151824 main=2.708951 aux=0.442873 imp_cv2=0.1846 load_cv2=4.9502 usage_frac=0.4018 topk_prob_mean=0.2903 ema_alpha_reverse=nan max_logit=11.7917
step:1552/1750 train_time:730416ms step_avg:470.63ms
[train step 1552] avg_loss=3.437370 main=2.986788 aux=0.450583 imp_cv2=0.1086 load_cv2=5.1261 usage_frac=0.4018 topk_prob_mean=0.2643 ema_alpha_reverse=nan max_logit=11.7917
step:1553/1750 train_time:730874ms step_avg:470.62ms
[train step 1553] avg_loss=3.190464 main=2.739376 aux=0.451088 imp_cv2=0.1273 load_cv2=5.1126 usage_frac=0.4062 topk_prob_mean=0.2681 ema_alpha_reverse=nan max_logit=11.7917
step:1554/1750 train_time:731326ms step_avg:470.61ms
[train step 1554] avg_loss=3.086889 main=2.643698 aux=0.443191 imp_cv2=0.1880 load_cv2=4.9604 usage_frac=0.4018 topk_prob_mean=0.2917 ema_alpha_reverse=nan max_logit=11.7917
step:1555/1750 train_time:731784ms step_avg:470.60ms
[train step 1555] avg_loss=3.301848 main=2.844532 aux=0.457316 imp_cv2=0.0874 load_cv2=5.2330 usage_frac=0.4107 topk_prob_mean=0.2494 ema_alpha_reverse=nan max_logit=11.7917
step:1556/1750 train_time:732229ms step_avg:470.58ms
[train step 1556] avg_loss=3.288774 main=2.834985 aux=0.453789 imp_cv2=0.1079 load_cv2=5.1692 usage_frac=0.4018 topk_prob_mean=0.2598 ema_alpha_reverse=nan max_logit=11.7917
step:1557/1750 train_time:732678ms step_avg:470.57ms
[train step 1557] avg_loss=3.689710 main=3.233976 aux=0.455734 imp_cv2=0.1011 load_cv2=5.2033 usage_frac=0.4062 topk_prob_mean=0.2504 ema_alpha_reverse=nan max_logit=11.7917
step:1558/1750 train_time:733140ms step_avg:470.56ms
[train step 1558] avg_loss=3.513123 main=3.051408 aux=0.461715 imp_cv2=0.0782 load_cv2=5.3003 usage_frac=0.4107 topk_prob_mean=0.2416 ema_alpha_reverse=nan max_logit=11.7917
step:1559/1750 train_time:733589ms step_avg:470.55ms
[train step 1559] avg_loss=3.636405 main=3.180120 aux=0.456285 imp_cv2=0.0912 load_cv2=5.2146 usage_frac=0.4062 topk_prob_mean=0.2507 ema_alpha_reverse=nan max_logit=11.7917
step:1560/1750 train_time:734045ms step_avg:470.54ms
[train step 1560] avg_loss=3.564182 main=3.113847 aux=0.450335 imp_cv2=0.1016 load_cv2=5.1355 usage_frac=0.4062 topk_prob_mean=0.2587 ema_alpha_reverse=nan max_logit=11.7917
step:1561/1750 train_time:734499ms step_avg:470.53ms
[train step 1561] avg_loss=2.959850 main=2.514482 aux=0.445368 imp_cv2=0.1583 load_cv2=5.0155 usage_frac=0.4152 topk_prob_mean=0.2819 ema_alpha_reverse=nan max_logit=11.7917
step:1562/1750 train_time:734959ms step_avg:470.52ms
[train step 1562] avg_loss=3.201205 main=2.747627 aux=0.453578 imp_cv2=0.1027 load_cv2=5.1729 usage_frac=0.4107 topk_prob_mean=0.2564 ema_alpha_reverse=nan max_logit=11.7917
step:1563/1750 train_time:735411ms step_avg:470.51ms
[train step 1563] avg_loss=3.583572 main=3.113667 aux=0.469905 imp_cv2=0.0565 load_cv2=5.4200 usage_frac=0.4062 topk_prob_mean=0.2285 ema_alpha_reverse=nan max_logit=11.7917
step:1564/1750 train_time:735865ms step_avg:470.50ms
[train step 1564] avg_loss=3.108207 main=2.660073 aux=0.448134 imp_cv2=0.1212 load_cv2=5.0834 usage_frac=0.4107 topk_prob_mean=0.2680 ema_alpha_reverse=nan max_logit=11.7917
step:1565/1750 train_time:736319ms step_avg:470.49ms
[train step 1565] avg_loss=3.166501 main=2.712856 aux=0.453645 imp_cv2=0.1067 load_cv2=5.1679 usage_frac=0.4107 topk_prob_mean=0.2600 ema_alpha_reverse=nan max_logit=11.7917
step:1566/1750 train_time:736771ms step_avg:470.48ms
[train step 1566] avg_loss=3.481598 main=3.018495 aux=0.463103 imp_cv2=0.0829 load_cv2=5.3106 usage_frac=0.4018 topk_prob_mean=0.2443 ema_alpha_reverse=nan max_logit=11.7917
step:1567/1750 train_time:737225ms step_avg:470.47ms
[train step 1567] avg_loss=3.228280 main=2.779483 aux=0.448797 imp_cv2=0.1151 load_cv2=5.0966 usage_frac=0.4062 topk_prob_mean=0.2640 ema_alpha_reverse=nan max_logit=11.7917
step:1568/1750 train_time:737669ms step_avg:470.45ms
[train step 1568] avg_loss=3.349815 main=2.901475 aux=0.448339 imp_cv2=0.1437 load_cv2=5.0669 usage_frac=0.4062 topk_prob_mean=0.2757 ema_alpha_reverse=nan max_logit=11.7917
step:1569/1750 train_time:738117ms step_avg:470.44ms
[train step 1569] avg_loss=3.324479 main=2.876964 aux=0.447515 imp_cv2=0.1383 load_cv2=5.0564 usage_frac=0.4062 topk_prob_mean=0.2742 ema_alpha_reverse=nan max_logit=11.7917
step:1570/1750 train_time:738575ms step_avg:470.43ms
[train step 1570] avg_loss=3.978483 main=3.510325 aux=0.468157 imp_cv2=0.0656 load_cv2=5.3870 usage_frac=0.4018 topk_prob_mean=0.2364 ema_alpha_reverse=nan max_logit=11.7917
step:1571/1750 train_time:739018ms step_avg:470.41ms
[train step 1571] avg_loss=3.324086 main=2.875251 aux=0.448835 imp_cv2=0.1530 load_cv2=5.0583 usage_frac=0.4018 topk_prob_mean=0.2781 ema_alpha_reverse=nan max_logit=11.7917
step:1572/1750 train_time:739470ms step_avg:470.40ms
[train step 1572] avg_loss=3.131442 main=2.681487 aux=0.449955 imp_cv2=0.1608 load_cv2=5.0681 usage_frac=0.4018 topk_prob_mean=0.2801 ema_alpha_reverse=nan max_logit=11.7917
step:1573/1750 train_time:739931ms step_avg:470.39ms
[train step 1573] avg_loss=3.251926 main=2.797012 aux=0.454914 imp_cv2=0.1268 load_cv2=5.1652 usage_frac=0.4062 topk_prob_mean=0.2664 ema_alpha_reverse=nan max_logit=11.7917
step:1574/1750 train_time:740380ms step_avg:470.38ms
[train step 1574] avg_loss=3.729057 main=3.215622 aux=0.513435 imp_cv2=0.0392 load_cv2=5.9531 usage_frac=0.3884 topk_prob_mean=0.1793 ema_alpha_reverse=nan max_logit=10.8091
step:1575/1750 train_time:740827ms step_avg:470.37ms
[train step 1575] avg_loss=3.388377 main=2.942259 aux=0.446118 imp_cv2=0.1521 load_cv2=5.0259 usage_frac=0.4062 topk_prob_mean=0.2796 ema_alpha_reverse=nan max_logit=11.7917
step:1576/1750 train_time:741288ms step_avg:470.36ms
[train step 1576] avg_loss=3.904550 main=3.425872 aux=0.478678 imp_cv2=0.0484 load_cv2=5.5371 usage_frac=0.4062 topk_prob_mean=0.2190 ema_alpha_reverse=nan max_logit=11.7917
step:1577/1750 train_time:741756ms step_avg:470.36ms
[train step 1577] avg_loss=3.282528 main=2.838488 aux=0.444040 imp_cv2=0.1443 load_cv2=5.0135 usage_frac=0.4062 topk_prob_mean=0.2789 ema_alpha_reverse=nan max_logit=11.7917
step:1578/1750 train_time:742213ms step_avg:470.35ms
[train step 1578] avg_loss=3.468412 main=3.021192 aux=0.447219 imp_cv2=0.1547 load_cv2=5.0486 usage_frac=0.4062 topk_prob_mean=0.2793 ema_alpha_reverse=nan max_logit=11.7917
step:1579/1750 train_time:742684ms step_avg:470.35ms
[train step 1579] avg_loss=3.346935 main=2.887361 aux=0.459574 imp_cv2=0.0708 load_cv2=5.2818 usage_frac=0.4018 topk_prob_mean=0.2402 ema_alpha_reverse=nan max_logit=11.7917
step:1580/1750 train_time:743125ms step_avg:470.33ms
[train step 1580] avg_loss=3.176716 main=2.730017 aux=0.446699 imp_cv2=0.1254 load_cv2=5.0681 usage_frac=0.4018 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=11.7917
step:1581/1750 train_time:743577ms step_avg:470.32ms
[train step 1581] avg_loss=3.906962 main=3.434137 aux=0.472825 imp_cv2=0.0629 load_cv2=5.4513 usage_frac=0.4018 topk_prob_mean=0.2333 ema_alpha_reverse=nan max_logit=11.7917
step:1582/1750 train_time:744024ms step_avg:470.31ms
[train step 1582] avg_loss=4.133917 main=3.628576 aux=0.505341 imp_cv2=0.0372 load_cv2=5.8621 usage_frac=0.3973 topk_prob_mean=0.1921 ema_alpha_reverse=nan max_logit=11.7917
step:1583/1750 train_time:744479ms step_avg:470.30ms
[train step 1583] avg_loss=3.863771 main=3.386920 aux=0.476851 imp_cv2=0.0520 load_cv2=5.5107 usage_frac=0.4107 topk_prob_mean=0.2204 ema_alpha_reverse=nan max_logit=11.7917
step:1584/1750 train_time:744926ms step_avg:470.28ms
[train step 1584] avg_loss=3.514358 main=3.045815 aux=0.468543 imp_cv2=0.0732 load_cv2=5.3987 usage_frac=0.4018 topk_prob_mean=0.2344 ema_alpha_reverse=nan max_logit=11.7917
step:1585/1750 train_time:745374ms step_avg:470.27ms
[train step 1585] avg_loss=3.193774 main=2.750188 aux=0.443587 imp_cv2=0.1453 load_cv2=5.0122 usage_frac=0.4062 topk_prob_mean=0.2794 ema_alpha_reverse=nan max_logit=11.7917
step:1586/1750 train_time:745822ms step_avg:470.25ms
[train step 1586] avg_loss=3.632003 main=3.174905 aux=0.457098 imp_cv2=0.0781 load_cv2=5.2442 usage_frac=0.4062 topk_prob_mean=0.2484 ema_alpha_reverse=nan max_logit=11.7917
step:1587/1750 train_time:746277ms step_avg:470.24ms
[train step 1587] avg_loss=3.067678 main=2.627895 aux=0.439784 imp_cv2=0.1604 load_cv2=4.9456 usage_frac=0.4062 topk_prob_mean=0.2877 ema_alpha_reverse=nan max_logit=11.7917
step:1588/1750 train_time:746731ms step_avg:470.23ms
[train step 1588] avg_loss=3.072948 main=2.633296 aux=0.439652 imp_cv2=0.1520 load_cv2=4.9517 usage_frac=0.4062 topk_prob_mean=0.2823 ema_alpha_reverse=nan max_logit=11.7917
step:1589/1750 train_time:747190ms step_avg:470.23ms
[train step 1589] avg_loss=3.294250 main=2.848043 aux=0.446207 imp_cv2=0.1414 load_cv2=5.0485 usage_frac=0.4018 topk_prob_mean=0.2770 ema_alpha_reverse=nan max_logit=11.7917
step:1590/1750 train_time:747640ms step_avg:470.21ms
[train step 1590] avg_loss=3.424100 main=2.979400 aux=0.444700 imp_cv2=0.1209 load_cv2=5.0507 usage_frac=0.4062 topk_prob_mean=0.2691 ema_alpha_reverse=nan max_logit=11.7917
step:1591/1750 train_time:748085ms step_avg:470.20ms
[train step 1591] avg_loss=3.096416 main=2.643941 aux=0.452475 imp_cv2=0.1053 load_cv2=5.1570 usage_frac=0.4062 topk_prob_mean=0.2599 ema_alpha_reverse=nan max_logit=11.7917
step:1592/1750 train_time:748536ms step_avg:470.19ms
[train step 1592] avg_loss=3.382253 main=2.922080 aux=0.460173 imp_cv2=0.0775 load_cv2=5.2824 usage_frac=0.4018 topk_prob_mean=0.2426 ema_alpha_reverse=nan max_logit=11.7917
step:1593/1750 train_time:748980ms step_avg:470.17ms
[train step 1593] avg_loss=3.422721 main=2.972137 aux=0.450584 imp_cv2=0.1022 load_cv2=5.1377 usage_frac=0.4018 topk_prob_mean=0.2612 ema_alpha_reverse=nan max_logit=11.7917
step:1594/1750 train_time:749429ms step_avg:470.16ms
[train step 1594] avg_loss=3.329879 main=2.828978 aux=0.500901 imp_cv2=0.0499 load_cv2=5.8035 usage_frac=0.4018 topk_prob_mean=0.1960 ema_alpha_reverse=nan max_logit=11.7917
step:1595/1750 train_time:749881ms step_avg:470.15ms
[train step 1595] avg_loss=3.770098 main=3.278924 aux=0.491174 imp_cv2=0.0514 load_cv2=5.6855 usage_frac=0.3973 topk_prob_mean=0.2100 ema_alpha_reverse=nan max_logit=11.7917
step:1596/1750 train_time:750318ms step_avg:470.12ms
[train step 1596] avg_loss=3.361159 main=2.892752 aux=0.468407 imp_cv2=0.0659 load_cv2=5.3923 usage_frac=0.4062 topk_prob_mean=0.2346 ema_alpha_reverse=nan max_logit=11.7917
step:1597/1750 train_time:750777ms step_avg:470.12ms
[train step 1597] avg_loss=3.172701 main=2.725724 aux=0.446977 imp_cv2=0.1726 load_cv2=5.0231 usage_frac=0.4018 topk_prob_mean=0.2873 ema_alpha_reverse=nan max_logit=11.7917
step:1598/1750 train_time:751230ms step_avg:470.11ms
[train step 1598] avg_loss=3.026516 main=2.582823 aux=0.443693 imp_cv2=0.1876 load_cv2=4.9694 usage_frac=0.3929 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=11.7917
step:1599/1750 train_time:751686ms step_avg:470.10ms
[train step 1599] avg_loss=2.939356 main=2.498454 aux=0.440901 imp_cv2=0.2092 load_cv2=4.9153 usage_frac=0.4018 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=11.7917
step:1600/1750 train_time:752145ms step_avg:470.09ms
Running validation...
step:1600/1750 val_loss:2.926916 train_time:752156ms step_avg:470.10ms
[train step 1600] avg_loss=3.770559 main=3.301666 aux=0.468893 imp_cv2=0.0711 load_cv2=5.3957 usage_frac=0.4062 topk_prob_mean=0.2393 ema_alpha_reverse=nan max_logit=11.7917
step:1601/1750 train_time:752588ms step_avg:470.07ms
[train step 1601] avg_loss=3.495831 main=3.041313 aux=0.454518 imp_cv2=0.0990 load_cv2=5.1883 usage_frac=0.3973 topk_prob_mean=0.2573 ema_alpha_reverse=nan max_logit=11.7917
step:1602/1750 train_time:753032ms step_avg:470.06ms
[train step 1602] avg_loss=3.532391 main=3.059764 aux=0.472627 imp_cv2=0.0619 load_cv2=5.4528 usage_frac=0.4018 topk_prob_mean=0.2298 ema_alpha_reverse=nan max_logit=11.7917
step:1603/1750 train_time:753480ms step_avg:470.04ms
[train step 1603] avg_loss=3.035609 main=2.590575 aux=0.445034 imp_cv2=0.2071 load_cv2=4.9657 usage_frac=0.3973 topk_prob_mean=0.2976 ema_alpha_reverse=nan max_logit=11.7917
step:1604/1750 train_time:753941ms step_avg:470.04ms
[train step 1604] avg_loss=3.609462 main=3.152187 aux=0.457274 imp_cv2=0.1025 load_cv2=5.2216 usage_frac=0.4062 topk_prob_mean=0.2557 ema_alpha_reverse=nan max_logit=11.7917
step:1605/1750 train_time:754382ms step_avg:470.02ms
[train step 1605] avg_loss=3.399352 main=2.943418 aux=0.455935 imp_cv2=0.1014 load_cv2=5.2045 usage_frac=0.4062 topk_prob_mean=0.2572 ema_alpha_reverse=nan max_logit=11.7917
step:1606/1750 train_time:754831ms step_avg:470.01ms
[train step 1606] avg_loss=3.338976 main=2.886584 aux=0.452392 imp_cv2=0.1010 load_cv2=5.1608 usage_frac=0.3973 topk_prob_mean=0.2593 ema_alpha_reverse=nan max_logit=11.7917
step:1607/1750 train_time:755280ms step_avg:469.99ms
[train step 1607] avg_loss=3.262554 main=2.813656 aux=0.448898 imp_cv2=0.1292 load_cv2=5.0913 usage_frac=0.3973 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=11.7917
step:1608/1750 train_time:755732ms step_avg:469.98ms
[train step 1608] avg_loss=3.311535 main=2.855998 aux=0.455537 imp_cv2=0.0957 load_cv2=5.2106 usage_frac=0.4018 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:1609/1750 train_time:756174ms step_avg:469.97ms
[train step 1609] avg_loss=3.099839 main=2.655351 aux=0.444488 imp_cv2=0.1581 load_cv2=5.0060 usage_frac=0.4018 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=11.7917
step:1610/1750 train_time:756628ms step_avg:469.96ms
[train step 1610] avg_loss=3.872681 main=3.372200 aux=0.500481 imp_cv2=0.0470 load_cv2=5.7930 usage_frac=0.4062 topk_prob_mean=0.1980 ema_alpha_reverse=nan max_logit=11.7917
step:1611/1750 train_time:757076ms step_avg:469.94ms
[train step 1611] avg_loss=3.062070 main=2.620642 aux=0.441428 imp_cv2=0.1917 load_cv2=4.9398 usage_frac=0.4018 topk_prob_mean=0.2949 ema_alpha_reverse=nan max_logit=11.7917
step:1612/1750 train_time:757523ms step_avg:469.93ms
[train step 1612] avg_loss=3.434350 main=2.970367 aux=0.463984 imp_cv2=0.0724 load_cv2=5.3351 usage_frac=0.4107 topk_prob_mean=0.2402 ema_alpha_reverse=nan max_logit=11.7917
step:1613/1750 train_time:757975ms step_avg:469.92ms
[train step 1613] avg_loss=3.485605 main=3.036720 aux=0.448885 imp_cv2=0.1166 load_cv2=5.1073 usage_frac=0.4107 topk_prob_mean=0.2658 ema_alpha_reverse=nan max_logit=11.7917
step:1614/1750 train_time:758434ms step_avg:469.91ms
[train step 1614] avg_loss=3.537346 main=3.091888 aux=0.445458 imp_cv2=0.1298 load_cv2=5.0525 usage_frac=0.4018 topk_prob_mean=0.2741 ema_alpha_reverse=nan max_logit=11.7917
step:1615/1750 train_time:758892ms step_avg:469.90ms
[train step 1615] avg_loss=3.481305 main=3.030910 aux=0.450394 imp_cv2=0.1232 load_cv2=5.1167 usage_frac=0.4018 topk_prob_mean=0.2672 ema_alpha_reverse=nan max_logit=11.7917
step:1616/1750 train_time:759350ms step_avg:469.89ms
[train step 1616] avg_loss=3.252918 main=2.808476 aux=0.444442 imp_cv2=0.1688 load_cv2=5.0009 usage_frac=0.4062 topk_prob_mean=0.2852 ema_alpha_reverse=nan max_logit=11.7917
step:1617/1750 train_time:759803ms step_avg:469.88ms
[train step 1617] avg_loss=3.235133 main=2.789942 aux=0.445191 imp_cv2=0.1550 load_cv2=5.0228 usage_frac=0.4062 topk_prob_mean=0.2819 ema_alpha_reverse=nan max_logit=11.7917
step:1618/1750 train_time:760258ms step_avg:469.88ms
[train step 1618] avg_loss=3.506501 main=3.050156 aux=0.456344 imp_cv2=0.0871 load_cv2=5.2235 usage_frac=0.4062 topk_prob_mean=0.2501 ema_alpha_reverse=nan max_logit=11.7917
step:1619/1750 train_time:760707ms step_avg:469.86ms
[train step 1619] avg_loss=2.965740 main=2.525337 aux=0.440403 imp_cv2=0.1971 load_cv2=4.9231 usage_frac=0.4062 topk_prob_mean=0.2960 ema_alpha_reverse=nan max_logit=11.7917
step:1620/1750 train_time:761162ms step_avg:469.85ms
[train step 1620] avg_loss=3.590555 main=3.118036 aux=0.472520 imp_cv2=0.0624 load_cv2=5.4483 usage_frac=0.4062 topk_prob_mean=0.2316 ema_alpha_reverse=nan max_logit=11.7917
step:1621/1750 train_time:761626ms step_avg:469.85ms
[train step 1621] avg_loss=3.259451 main=2.815558 aux=0.443893 imp_cv2=0.1241 load_cv2=5.0337 usage_frac=0.4107 topk_prob_mean=0.2721 ema_alpha_reverse=nan max_logit=11.7917
step:1622/1750 train_time:762074ms step_avg:469.84ms
[train step 1622] avg_loss=3.562843 main=3.099177 aux=0.463666 imp_cv2=0.0715 load_cv2=5.3316 usage_frac=0.4062 topk_prob_mean=0.2403 ema_alpha_reverse=nan max_logit=11.7917
step:1623/1750 train_time:762522ms step_avg:469.82ms
[train step 1623] avg_loss=3.235169 main=2.791078 aux=0.444091 imp_cv2=0.1236 load_cv2=5.0388 usage_frac=0.4107 topk_prob_mean=0.2726 ema_alpha_reverse=nan max_logit=11.7917
step:1624/1750 train_time:762975ms step_avg:469.81ms
[train step 1624] avg_loss=3.353957 main=2.874661 aux=0.479296 imp_cv2=0.0540 load_cv2=5.5239 usage_frac=0.4062 topk_prob_mean=0.2199 ema_alpha_reverse=nan max_logit=11.7917
step:1625/1750 train_time:763421ms step_avg:469.80ms
[train step 1625] avg_loss=6.229828 main=5.692713 aux=0.537115 imp_cv2=0.0576 load_cv2=6.2356 usage_frac=0.3616 topk_prob_mean=0.1729 ema_alpha_reverse=nan max_logit=9.8264
step:1626/1750 train_time:763885ms step_avg:469.79ms
[train step 1626] avg_loss=3.248220 main=2.790485 aux=0.457735 imp_cv2=0.0834 load_cv2=5.2467 usage_frac=0.4107 topk_prob_mean=0.2486 ema_alpha_reverse=nan max_logit=11.7917
step:1627/1750 train_time:764335ms step_avg:469.78ms
[train step 1627] avg_loss=3.310309 main=2.857234 aux=0.453075 imp_cv2=0.1054 load_cv2=5.1657 usage_frac=0.4062 topk_prob_mean=0.2586 ema_alpha_reverse=nan max_logit=11.7917
step:1628/1750 train_time:764783ms step_avg:469.77ms
[train step 1628] avg_loss=3.314840 main=2.875969 aux=0.438871 imp_cv2=0.1757 load_cv2=4.9186 usage_frac=0.4062 topk_prob_mean=0.2909 ema_alpha_reverse=nan max_logit=11.7917
step:1629/1750 train_time:765233ms step_avg:469.76ms
[train step 1629] avg_loss=3.782784 main=3.246445 aux=0.536339 imp_cv2=0.0388 load_cv2=6.2381 usage_frac=0.3661 topk_prob_mean=0.1628 ema_alpha_reverse=nan max_logit=9.8264
step:1630/1750 train_time:765682ms step_avg:469.74ms
[train step 1630] avg_loss=3.121885 main=2.677997 aux=0.443889 imp_cv2=0.1546 load_cv2=5.0010 usage_frac=0.4062 topk_prob_mean=0.2820 ema_alpha_reverse=nan max_logit=11.7917
step:1631/1750 train_time:766134ms step_avg:469.73ms
[train step 1631] avg_loss=4.020105 main=3.511588 aux=0.508517 imp_cv2=0.0287 load_cv2=5.9133 usage_frac=0.3973 topk_prob_mean=0.1795 ema_alpha_reverse=nan max_logit=11.7917
step:1632/1750 train_time:766581ms step_avg:469.72ms
[train step 1632] avg_loss=3.208267 main=2.761895 aux=0.446371 imp_cv2=0.1167 load_cv2=5.0689 usage_frac=0.4018 topk_prob_mean=0.2680 ema_alpha_reverse=nan max_logit=11.7917
step:1633/1750 train_time:767028ms step_avg:469.71ms
[train step 1633] avg_loss=3.032246 main=2.593780 aux=0.438466 imp_cv2=0.2235 load_cv2=4.8670 usage_frac=0.4018 topk_prob_mean=0.3050 ema_alpha_reverse=nan max_logit=11.7917
step:1634/1750 train_time:767480ms step_avg:469.69ms
[train step 1634] avg_loss=3.376322 main=2.924915 aux=0.451407 imp_cv2=0.1136 load_cv2=5.1373 usage_frac=0.3973 topk_prob_mean=0.2619 ema_alpha_reverse=nan max_logit=11.7917
step:1635/1750 train_time:767929ms step_avg:469.68ms
[train step 1635] avg_loss=3.164044 main=2.720086 aux=0.443958 imp_cv2=0.1429 load_cv2=5.0136 usage_frac=0.4107 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=11.7917
step:1636/1750 train_time:768390ms step_avg:469.68ms
[train step 1636] avg_loss=3.391136 main=2.937845 aux=0.453290 imp_cv2=0.0839 load_cv2=5.1890 usage_frac=0.4107 topk_prob_mean=0.2512 ema_alpha_reverse=nan max_logit=11.7917
step:1637/1750 train_time:768828ms step_avg:469.66ms
[train step 1637] avg_loss=4.963665 main=4.429774 aux=0.533891 imp_cv2=0.0402 load_cv2=6.2129 usage_frac=0.3661 topk_prob_mean=0.1646 ema_alpha_reverse=nan max_logit=9.8264
step:1638/1750 train_time:769271ms step_avg:469.64ms
[train step 1638] avg_loss=3.248431 main=2.775599 aux=0.472832 imp_cv2=0.0503 load_cv2=5.4565 usage_frac=0.4062 topk_prob_mean=0.2251 ema_alpha_reverse=nan max_logit=11.7917
step:1639/1750 train_time:769720ms step_avg:469.63ms
[train step 1639] avg_loss=3.251266 main=2.802382 aux=0.448885 imp_cv2=0.1169 load_cv2=5.1014 usage_frac=0.4062 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=11.7917
step:1640/1750 train_time:770182ms step_avg:469.62ms
[train step 1640] avg_loss=3.238031 main=2.784565 aux=0.453466 imp_cv2=0.1024 load_cv2=5.1704 usage_frac=0.4018 topk_prob_mean=0.2606 ema_alpha_reverse=nan max_logit=11.7917
step:1641/1750 train_time:770633ms step_avg:469.61ms
[train step 1641] avg_loss=3.799014 main=3.341669 aux=0.457345 imp_cv2=0.0800 load_cv2=5.2413 usage_frac=0.3973 topk_prob_mean=0.2483 ema_alpha_reverse=nan max_logit=11.7917
step:1642/1750 train_time:771082ms step_avg:469.60ms
[train step 1642] avg_loss=3.469465 main=3.009546 aux=0.459918 imp_cv2=0.0651 load_cv2=5.2891 usage_frac=0.4018 topk_prob_mean=0.2385 ema_alpha_reverse=nan max_logit=11.7917
step:1643/1750 train_time:771529ms step_avg:469.59ms
[train step 1643] avg_loss=3.325376 main=2.881654 aux=0.443723 imp_cv2=0.1446 load_cv2=5.0110 usage_frac=0.4107 topk_prob_mean=0.2762 ema_alpha_reverse=nan max_logit=11.7917
step:1644/1750 train_time:771977ms step_avg:469.57ms
[train step 1644] avg_loss=2.955821 main=2.517763 aux=0.438057 imp_cv2=0.1829 load_cv2=4.9065 usage_frac=0.3973 topk_prob_mean=0.2931 ema_alpha_reverse=nan max_logit=11.7917
step:1645/1750 train_time:772429ms step_avg:469.56ms
[train step 1645] avg_loss=3.844698 main=3.352283 aux=0.492415 imp_cv2=0.0340 load_cv2=5.7104 usage_frac=0.3973 topk_prob_mean=0.1952 ema_alpha_reverse=nan max_logit=11.7917
step:1646/1750 train_time:772889ms step_avg:469.56ms
[train step 1646] avg_loss=2.934424 main=2.497774 aux=0.436649 imp_cv2=0.1704 load_cv2=4.8997 usage_frac=0.4107 topk_prob_mean=0.2922 ema_alpha_reverse=nan max_logit=11.7917
step:1647/1750 train_time:773354ms step_avg:469.55ms
[train step 1647] avg_loss=3.066090 main=2.627343 aux=0.438747 imp_cv2=0.1709 load_cv2=4.9293 usage_frac=0.4018 topk_prob_mean=0.2894 ema_alpha_reverse=nan max_logit=11.7917
step:1648/1750 train_time:773805ms step_avg:469.54ms
[train step 1648] avg_loss=3.210935 main=2.769572 aux=0.441363 imp_cv2=0.1417 load_cv2=4.9866 usage_frac=0.4018 topk_prob_mean=0.2780 ema_alpha_reverse=nan max_logit=11.7917
step:1649/1750 train_time:774254ms step_avg:469.53ms
[train step 1649] avg_loss=3.248683 main=2.798587 aux=0.450096 imp_cv2=0.1070 load_cv2=5.1272 usage_frac=0.4018 topk_prob_mean=0.2623 ema_alpha_reverse=nan max_logit=11.7917
step:1650/1750 train_time:774706ms step_avg:469.52ms
Running validation...
step:1650/1750 val_loss:2.907957 train_time:774718ms step_avg:469.53ms
[train step 1650] avg_loss=2.823613 main=2.383947 aux=0.439666 imp_cv2=0.1580 load_cv2=4.9506 usage_frac=0.4062 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=11.7917
step:1651/1750 train_time:775159ms step_avg:469.51ms
[train step 1651] avg_loss=3.599953 main=3.141476 aux=0.458477 imp_cv2=0.0774 load_cv2=5.2592 usage_frac=0.4062 topk_prob_mean=0.2446 ema_alpha_reverse=nan max_logit=11.7917
step:1652/1750 train_time:775615ms step_avg:469.50ms
[train step 1652] avg_loss=3.422847 main=2.974355 aux=0.448492 imp_cv2=0.1106 load_cv2=5.1061 usage_frac=0.3973 topk_prob_mean=0.2619 ema_alpha_reverse=nan max_logit=11.7917
step:1653/1750 train_time:776059ms step_avg:469.49ms
[train step 1653] avg_loss=3.352050 main=2.907062 aux=0.444988 imp_cv2=0.1304 load_cv2=5.0418 usage_frac=0.4018 topk_prob_mean=0.2726 ema_alpha_reverse=nan max_logit=11.7917
step:1654/1750 train_time:776522ms step_avg:469.48ms
[train step 1654] avg_loss=3.173820 main=2.725822 aux=0.447998 imp_cv2=0.1115 load_cv2=5.0972 usage_frac=0.4018 topk_prob_mean=0.2650 ema_alpha_reverse=nan max_logit=11.7917
step:1655/1750 train_time:776974ms step_avg:469.47ms
[train step 1655] avg_loss=4.413104 main=3.949476 aux=0.463628 imp_cv2=0.0635 load_cv2=5.3373 usage_frac=0.4107 topk_prob_mean=0.2352 ema_alpha_reverse=nan max_logit=11.7917
step:1656/1750 train_time:777424ms step_avg:469.46ms
[train step 1656] avg_loss=3.295827 main=2.842958 aux=0.452869 imp_cv2=0.0928 load_cv2=5.1760 usage_frac=0.3973 topk_prob_mean=0.2556 ema_alpha_reverse=nan max_logit=11.7917
step:1657/1750 train_time:777880ms step_avg:469.45ms
[train step 1657] avg_loss=3.385403 main=2.914286 aux=0.471117 imp_cv2=0.0489 load_cv2=5.4418 usage_frac=0.3929 topk_prob_mean=0.2222 ema_alpha_reverse=nan max_logit=11.7917
step:1658/1750 train_time:778346ms step_avg:469.45ms
[train step 1658] avg_loss=3.428575 main=2.969285 aux=0.459291 imp_cv2=0.0847 load_cv2=5.2683 usage_frac=0.4018 topk_prob_mean=0.2457 ema_alpha_reverse=nan max_logit=11.7917
step:1659/1750 train_time:778801ms step_avg:469.44ms
[train step 1659] avg_loss=3.075595 main=2.636075 aux=0.439520 imp_cv2=0.1833 load_cv2=4.9202 usage_frac=0.4018 topk_prob_mean=0.2925 ema_alpha_reverse=nan max_logit=11.7917
step:1660/1750 train_time:779255ms step_avg:469.43ms
[train step 1660] avg_loss=3.372535 main=2.917711 aux=0.454823 imp_cv2=0.0920 load_cv2=5.2028 usage_frac=0.4062 topk_prob_mean=0.2518 ema_alpha_reverse=nan max_logit=11.7917
step:1661/1750 train_time:779707ms step_avg:469.42ms
[train step 1661] avg_loss=2.985649 main=2.546494 aux=0.439155 imp_cv2=0.2091 load_cv2=4.8931 usage_frac=0.4018 topk_prob_mean=0.2994 ema_alpha_reverse=nan max_logit=11.7917
step:1662/1750 train_time:780167ms step_avg:469.41ms
[train step 1662] avg_loss=3.252012 main=2.801002 aux=0.451010 imp_cv2=0.0989 load_cv2=5.1466 usage_frac=0.3929 topk_prob_mean=0.2561 ema_alpha_reverse=nan max_logit=11.7917
step:1663/1750 train_time:780619ms step_avg:469.40ms
[train step 1663] avg_loss=3.703004 main=3.230334 aux=0.472669 imp_cv2=0.0517 load_cv2=5.4588 usage_frac=0.4062 topk_prob_mean=0.2229 ema_alpha_reverse=nan max_logit=11.7917
step:1664/1750 train_time:781079ms step_avg:469.40ms
[train step 1664] avg_loss=3.468759 main=3.005525 aux=0.463234 imp_cv2=0.0664 load_cv2=5.3271 usage_frac=0.4062 topk_prob_mean=0.2356 ema_alpha_reverse=nan max_logit=11.7917
step:1665/1750 train_time:781526ms step_avg:469.39ms
[train step 1665] avg_loss=3.523141 main=3.061193 aux=0.461948 imp_cv2=0.0684 load_cv2=5.3090 usage_frac=0.3973 topk_prob_mean=0.2389 ema_alpha_reverse=nan max_logit=11.7917
step:1666/1750 train_time:781968ms step_avg:469.37ms
[train step 1666] avg_loss=4.449813 main=3.927837 aux=0.521976 imp_cv2=0.0455 load_cv2=6.0550 usage_frac=0.3661 topk_prob_mean=0.1694 ema_alpha_reverse=nan max_logit=9.8264
step:1667/1750 train_time:782432ms step_avg:469.37ms
[train step 1667] avg_loss=3.289612 main=2.840462 aux=0.449150 imp_cv2=0.1027 load_cv2=5.1195 usage_frac=0.4062 topk_prob_mean=0.2595 ema_alpha_reverse=nan max_logit=11.7917
step:1668/1750 train_time:782880ms step_avg:469.35ms
[train step 1668] avg_loss=4.089069 main=3.551538 aux=0.537532 imp_cv2=0.0508 load_cv2=6.2449 usage_frac=0.3661 topk_prob_mean=0.1623 ema_alpha_reverse=nan max_logit=9.8264
step:1669/1750 train_time:783340ms step_avg:469.35ms
[train step 1669] avg_loss=3.559450 main=3.108538 aux=0.450912 imp_cv2=0.1048 load_cv2=5.1413 usage_frac=0.4018 topk_prob_mean=0.2585 ema_alpha_reverse=nan max_logit=11.7917
step:1670/1750 train_time:783797ms step_avg:469.34ms
[train step 1670] avg_loss=3.438831 main=2.985546 aux=0.453285 imp_cv2=0.1108 load_cv2=5.1680 usage_frac=0.4018 topk_prob_mean=0.2622 ema_alpha_reverse=nan max_logit=11.7917
step:1671/1750 train_time:784244ms step_avg:469.33ms
[train step 1671] avg_loss=3.343103 main=2.897219 aux=0.445884 imp_cv2=0.1310 load_cv2=5.0477 usage_frac=0.4107 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=11.7917
step:1672/1750 train_time:784691ms step_avg:469.31ms
[train step 1672] avg_loss=3.380346 main=2.925945 aux=0.454401 imp_cv2=0.0933 load_cv2=5.1957 usage_frac=0.4107 topk_prob_mean=0.2518 ema_alpha_reverse=nan max_logit=11.7917
step:1673/1750 train_time:785141ms step_avg:469.30ms
[train step 1673] avg_loss=3.146205 main=2.703706 aux=0.442499 imp_cv2=0.1660 load_cv2=4.9748 usage_frac=0.3973 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=11.7917
step:1674/1750 train_time:785596ms step_avg:469.29ms
[train step 1674] avg_loss=3.002157 main=2.564124 aux=0.438033 imp_cv2=0.1691 load_cv2=4.9145 usage_frac=0.4062 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=11.7917
step:1675/1750 train_time:786052ms step_avg:469.28ms
[train step 1675] avg_loss=3.180614 main=2.731714 aux=0.448900 imp_cv2=0.1032 load_cv2=5.1152 usage_frac=0.4018 topk_prob_mean=0.2586 ema_alpha_reverse=nan max_logit=11.7917
step:1676/1750 train_time:786510ms step_avg:469.28ms
[train step 1676] avg_loss=3.593348 main=3.138929 aux=0.454418 imp_cv2=0.0690 load_cv2=5.2148 usage_frac=0.3973 topk_prob_mean=0.2417 ema_alpha_reverse=nan max_logit=11.7917
step:1677/1750 train_time:786961ms step_avg:469.27ms
[train step 1677] avg_loss=4.024503 main=3.559209 aux=0.465295 imp_cv2=0.0606 load_cv2=5.3504 usage_frac=0.4062 topk_prob_mean=0.2312 ema_alpha_reverse=nan max_logit=11.7917
step:1678/1750 train_time:787415ms step_avg:469.26ms
[train step 1678] avg_loss=4.184486 main=3.681216 aux=0.503270 imp_cv2=0.0425 load_cv2=5.8462 usage_frac=0.3929 topk_prob_mean=0.1901 ema_alpha_reverse=nan max_logit=10.8091
step:1679/1750 train_time:787870ms step_avg:469.25ms
[train step 1679] avg_loss=3.150668 main=2.708894 aux=0.441773 imp_cv2=0.1409 load_cv2=4.9887 usage_frac=0.4062 topk_prob_mean=0.2753 ema_alpha_reverse=nan max_logit=11.7917
step:1680/1750 train_time:788322ms step_avg:469.24ms
[train step 1680] avg_loss=3.855958 main=3.392133 aux=0.463826 imp_cv2=0.0599 load_cv2=5.3394 usage_frac=0.3929 topk_prob_mean=0.2343 ema_alpha_reverse=nan max_logit=11.7917
step:1681/1750 train_time:788768ms step_avg:469.23ms
[train step 1681] avg_loss=3.223404 main=2.778033 aux=0.445371 imp_cv2=0.1168 load_cv2=5.0604 usage_frac=0.4018 topk_prob_mean=0.2655 ema_alpha_reverse=nan max_logit=11.7917
step:1682/1750 train_time:789216ms step_avg:469.21ms
[train step 1682] avg_loss=3.232034 main=2.784118 aux=0.447915 imp_cv2=0.1152 load_cv2=5.0898 usage_frac=0.4107 topk_prob_mean=0.2637 ema_alpha_reverse=nan max_logit=11.7917
step:1683/1750 train_time:789673ms step_avg:469.21ms
[train step 1683] avg_loss=3.037984 main=2.600240 aux=0.437744 imp_cv2=0.1928 load_cv2=4.8909 usage_frac=0.4062 topk_prob_mean=0.2938 ema_alpha_reverse=nan max_logit=11.7917
step:1684/1750 train_time:790128ms step_avg:469.20ms
[train step 1684] avg_loss=3.718067 main=3.239983 aux=0.478085 imp_cv2=0.0470 load_cv2=5.5302 usage_frac=0.3929 topk_prob_mean=0.2170 ema_alpha_reverse=nan max_logit=11.7917
step:1685/1750 train_time:790596ms step_avg:469.20ms
[train step 1685] avg_loss=3.186424 main=2.740047 aux=0.446377 imp_cv2=0.1270 load_cv2=5.0620 usage_frac=0.4062 topk_prob_mean=0.2704 ema_alpha_reverse=nan max_logit=11.7917
step:1686/1750 train_time:791045ms step_avg:469.18ms
[train step 1686] avg_loss=3.341499 main=2.894498 aux=0.447001 imp_cv2=0.1111 load_cv2=5.0858 usage_frac=0.4018 topk_prob_mean=0.2641 ema_alpha_reverse=nan max_logit=11.7917
step:1687/1750 train_time:791485ms step_avg:469.17ms
[train step 1687] avg_loss=3.265384 main=2.823118 aux=0.442265 imp_cv2=0.1597 load_cv2=4.9796 usage_frac=0.4062 topk_prob_mean=0.2824 ema_alpha_reverse=nan max_logit=11.7917
step:1688/1750 train_time:791939ms step_avg:469.16ms
[train step 1688] avg_loss=2.707074 main=2.268606 aux=0.438468 imp_cv2=0.2884 load_cv2=4.8011 usage_frac=0.4107 topk_prob_mean=0.3213 ema_alpha_reverse=nan max_logit=11.7917
step:1689/1750 train_time:792401ms step_avg:469.15ms
[train step 1689] avg_loss=4.271212 main=3.754466 aux=0.516746 imp_cv2=0.0349 load_cv2=6.0110 usage_frac=0.4018 topk_prob_mean=0.1784 ema_alpha_reverse=nan max_logit=11.7917
step:1690/1750 train_time:792857ms step_avg:469.15ms
[train step 1690] avg_loss=3.172207 main=2.728055 aux=0.444152 imp_cv2=0.1649 load_cv2=5.0017 usage_frac=0.4062 topk_prob_mean=0.2829 ema_alpha_reverse=nan max_logit=11.7917
step:1691/1750 train_time:793311ms step_avg:469.14ms
[train step 1691] avg_loss=3.373484 main=2.916716 aux=0.456767 imp_cv2=0.0790 load_cv2=5.2384 usage_frac=0.4062 topk_prob_mean=0.2454 ema_alpha_reverse=nan max_logit=11.7917
step:1692/1750 train_time:793760ms step_avg:469.13ms
[train step 1692] avg_loss=3.430642 main=2.976036 aux=0.454606 imp_cv2=0.0880 load_cv2=5.2066 usage_frac=0.4062 topk_prob_mean=0.2517 ema_alpha_reverse=nan max_logit=11.7917
step:1693/1750 train_time:794211ms step_avg:469.11ms
[train step 1693] avg_loss=3.355042 main=2.900008 aux=0.455034 imp_cv2=0.0998 load_cv2=5.1930 usage_frac=0.3973 topk_prob_mean=0.2548 ema_alpha_reverse=nan max_logit=11.7917
step:1694/1750 train_time:794655ms step_avg:469.10ms
[train step 1694] avg_loss=3.747151 main=3.273636 aux=0.473515 imp_cv2=0.0531 load_cv2=5.4694 usage_frac=0.4018 topk_prob_mean=0.2239 ema_alpha_reverse=nan max_logit=11.7917
step:1695/1750 train_time:795103ms step_avg:469.09ms
[train step 1695] avg_loss=4.162065 main=3.666125 aux=0.495939 imp_cv2=0.0276 load_cv2=5.7636 usage_frac=0.4062 topk_prob_mean=0.1915 ema_alpha_reverse=nan max_logit=11.7917
step:1696/1750 train_time:795565ms step_avg:469.08ms
[train step 1696] avg_loss=3.809626 main=3.298484 aux=0.511142 imp_cv2=0.0406 load_cv2=5.9383 usage_frac=0.3973 topk_prob_mean=0.1814 ema_alpha_reverse=nan max_logit=10.8091
step:1697/1750 train_time:796014ms step_avg:469.07ms
[train step 1697] avg_loss=3.022013 main=2.578326 aux=0.443687 imp_cv2=0.1629 load_cv2=4.9883 usage_frac=0.3973 topk_prob_mean=0.2832 ema_alpha_reverse=nan max_logit=11.7917
step:1698/1750 train_time:796462ms step_avg:469.06ms
[train step 1698] avg_loss=3.105271 main=2.660120 aux=0.445151 imp_cv2=0.1673 load_cv2=5.0074 usage_frac=0.4018 topk_prob_mean=0.2836 ema_alpha_reverse=nan max_logit=11.7917
step:1699/1750 train_time:796911ms step_avg:469.05ms
[train step 1699] avg_loss=3.043971 main=2.602764 aux=0.441207 imp_cv2=0.1733 load_cv2=4.9541 usage_frac=0.4018 topk_prob_mean=0.2886 ema_alpha_reverse=nan max_logit=11.7917
step:1700/1750 train_time:797374ms step_avg:469.04ms
Running validation...
step:1700/1750 val_loss:2.892060 train_time:797386ms step_avg:469.05ms
[train step 1700] avg_loss=3.617216 main=3.145927 aux=0.471289 imp_cv2=0.0528 load_cv2=5.4439 usage_frac=0.4018 topk_prob_mean=0.2232 ema_alpha_reverse=nan max_logit=11.7917
step:1701/1750 train_time:797833ms step_avg:469.04ms
[train step 1701] avg_loss=3.609999 main=3.152655 aux=0.457344 imp_cv2=0.0859 load_cv2=5.2351 usage_frac=0.4018 topk_prob_mean=0.2476 ema_alpha_reverse=nan max_logit=11.7917
step:1702/1750 train_time:798285ms step_avg:469.03ms
[train step 1702] avg_loss=3.138182 main=2.690598 aux=0.447585 imp_cv2=0.1276 load_cv2=5.0778 usage_frac=0.4062 topk_prob_mean=0.2699 ema_alpha_reverse=nan max_logit=11.7917
step:1703/1750 train_time:798732ms step_avg:469.01ms
[train step 1703] avg_loss=2.954999 main=2.514910 aux=0.440089 imp_cv2=0.1883 load_cv2=4.9210 usage_frac=0.4018 topk_prob_mean=0.2935 ema_alpha_reverse=nan max_logit=11.7917
step:1704/1750 train_time:799179ms step_avg:469.00ms
[train step 1704] avg_loss=3.036565 main=2.589273 aux=0.447292 imp_cv2=0.1570 load_cv2=5.0454 usage_frac=0.4062 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=11.7917
step:1705/1750 train_time:799632ms step_avg:468.99ms
[train step 1705] avg_loss=4.871984 main=4.340338 aux=0.531646 imp_cv2=0.0315 load_cv2=6.1993 usage_frac=0.3616 topk_prob_mean=0.1597 ema_alpha_reverse=nan max_logit=9.8264
step:1706/1750 train_time:800073ms step_avg:468.98ms
[train step 1706] avg_loss=3.232700 main=2.784168 aux=0.448532 imp_cv2=0.1394 load_cv2=5.0783 usage_frac=0.4018 topk_prob_mean=0.2750 ema_alpha_reverse=nan max_logit=11.7917
step:1707/1750 train_time:800517ms step_avg:468.96ms
[train step 1707] avg_loss=3.377913 main=2.921050 aux=0.456863 imp_cv2=0.0864 load_cv2=5.2299 usage_frac=0.4062 topk_prob_mean=0.2497 ema_alpha_reverse=nan max_logit=11.7917
step:1708/1750 train_time:800971ms step_avg:468.95ms
[train step 1708] avg_loss=3.346271 main=2.890978 aux=0.455294 imp_cv2=0.0969 load_cv2=5.2004 usage_frac=0.4062 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:1709/1750 train_time:801412ms step_avg:468.94ms
[train step 1709] avg_loss=3.304939 main=2.854614 aux=0.450325 imp_cv2=0.1107 load_cv2=5.1194 usage_frac=0.4018 topk_prob_mean=0.2600 ema_alpha_reverse=nan max_logit=11.7917
step:1710/1750 train_time:801858ms step_avg:468.92ms
[train step 1710] avg_loss=3.443287 main=2.990871 aux=0.452415 imp_cv2=0.1024 load_cv2=5.1626 usage_frac=0.4018 topk_prob_mean=0.2591 ema_alpha_reverse=nan max_logit=11.7917
step:1711/1750 train_time:802310ms step_avg:468.91ms
[train step 1711] avg_loss=3.506041 main=3.032847 aux=0.473194 imp_cv2=0.0495 load_cv2=5.4633 usage_frac=0.3973 topk_prob_mean=0.2227 ema_alpha_reverse=nan max_logit=11.7917
step:1712/1750 train_time:802968ms step_avg:469.02ms
[train step 1712] avg_loss=3.046107 main=2.604563 aux=0.441544 imp_cv2=0.1601 load_cv2=4.9653 usage_frac=0.4062 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=11.7917
step:1713/1750 train_time:803419ms step_avg:469.01ms
[train step 1713] avg_loss=4.098755 main=3.605486 aux=0.493269 imp_cv2=0.0298 load_cv2=5.7271 usage_frac=0.3973 topk_prob_mean=0.1964 ema_alpha_reverse=nan max_logit=11.7917
step:1714/1750 train_time:803868ms step_avg:469.00ms
[train step 1714] avg_loss=3.325815 main=2.871608 aux=0.454207 imp_cv2=0.0939 load_cv2=5.1919 usage_frac=0.4062 topk_prob_mean=0.2545 ema_alpha_reverse=nan max_logit=11.7917
step:1715/1750 train_time:804321ms step_avg:468.99ms
[train step 1715] avg_loss=3.712129 main=3.237099 aux=0.475030 imp_cv2=0.0467 load_cv2=5.4947 usage_frac=0.3929 topk_prob_mean=0.2198 ema_alpha_reverse=nan max_logit=11.7917
step:1716/1750 train_time:804768ms step_avg:468.98ms
[train step 1716] avg_loss=3.438570 main=2.989869 aux=0.448701 imp_cv2=0.1148 load_cv2=5.1007 usage_frac=0.4062 topk_prob_mean=0.2644 ema_alpha_reverse=nan max_logit=11.7917
step:1717/1750 train_time:805220ms step_avg:468.97ms
[train step 1717] avg_loss=3.204656 main=2.758242 aux=0.446414 imp_cv2=0.1289 load_cv2=5.0606 usage_frac=0.4062 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=11.7917
step:1718/1750 train_time:805669ms step_avg:468.96ms
[train step 1718] avg_loss=3.099344 main=2.658061 aux=0.441283 imp_cv2=0.1905 load_cv2=4.9397 usage_frac=0.3973 topk_prob_mean=0.2929 ema_alpha_reverse=nan max_logit=11.7917
step:1719/1750 train_time:806126ms step_avg:468.95ms
[train step 1719] avg_loss=3.187149 main=2.728316 aux=0.458833 imp_cv2=0.0728 load_cv2=5.2698 usage_frac=0.3973 topk_prob_mean=0.2439 ema_alpha_reverse=nan max_logit=11.7917
step:1720/1750 train_time:806769ms step_avg:469.05ms
[train step 1720] avg_loss=3.043397 main=2.600968 aux=0.442429 imp_cv2=0.1684 load_cv2=4.9722 usage_frac=0.4062 topk_prob_mean=0.2858 ema_alpha_reverse=nan max_logit=11.7917
step:1721/1750 train_time:807217ms step_avg:469.04ms
[train step 1721] avg_loss=3.996433 main=3.531570 aux=0.464863 imp_cv2=0.0725 load_cv2=5.3404 usage_frac=0.4018 topk_prob_mean=0.2390 ema_alpha_reverse=nan max_logit=11.7917
step:1722/1750 train_time:807659ms step_avg:469.02ms
[train step 1722] avg_loss=3.074438 main=2.621270 aux=0.453168 imp_cv2=0.1038 load_cv2=5.1686 usage_frac=0.4062 topk_prob_mean=0.2587 ema_alpha_reverse=nan max_logit=11.7917
step:1723/1750 train_time:808110ms step_avg:469.01ms
[train step 1723] avg_loss=3.852137 main=3.325476 aux=0.526662 imp_cv2=0.0356 load_cv2=6.1262 usage_frac=0.3839 topk_prob_mean=0.1694 ema_alpha_reverse=nan max_logit=10.8091
step:1724/1750 train_time:808564ms step_avg:469.00ms
[train step 1724] avg_loss=3.383861 main=2.916727 aux=0.467134 imp_cv2=0.0591 load_cv2=5.3850 usage_frac=0.4018 topk_prob_mean=0.2312 ema_alpha_reverse=nan max_logit=11.7917
step:1725/1750 train_time:809011ms step_avg:468.99ms
[train step 1725] avg_loss=3.287777 main=2.840825 aux=0.446952 imp_cv2=0.1676 load_cv2=5.0270 usage_frac=0.3973 topk_prob_mean=0.2830 ema_alpha_reverse=nan max_logit=11.7917
step:1726/1750 train_time:809463ms step_avg:468.98ms
[train step 1726] avg_loss=3.218093 main=2.768746 aux=0.449348 imp_cv2=0.1547 load_cv2=5.0711 usage_frac=0.4018 topk_prob_mean=0.2765 ema_alpha_reverse=nan max_logit=11.7917
step:1727/1750 train_time:809915ms step_avg:468.97ms
[train step 1727] avg_loss=3.642409 main=3.184095 aux=0.458315 imp_cv2=0.0845 load_cv2=5.2484 usage_frac=0.4062 topk_prob_mean=0.2479 ema_alpha_reverse=nan max_logit=11.7917
step:1728/1750 train_time:810360ms step_avg:468.96ms
[train step 1728] avg_loss=3.174328 main=2.724311 aux=0.450017 imp_cv2=0.1329 load_cv2=5.0986 usage_frac=0.4062 topk_prob_mean=0.2708 ema_alpha_reverse=nan max_logit=11.7917
step:1729/1750 train_time:810806ms step_avg:468.95ms
[train step 1729] avg_loss=3.190194 main=2.737350 aux=0.452844 imp_cv2=0.1204 load_cv2=5.1458 usage_frac=0.4018 topk_prob_mean=0.2648 ema_alpha_reverse=nan max_logit=11.7917
step:1730/1750 train_time:811249ms step_avg:468.93ms
[train step 1730] avg_loss=3.227581 main=2.763540 aux=0.464041 imp_cv2=0.0691 load_cv2=5.3346 usage_frac=0.3929 topk_prob_mean=0.2397 ema_alpha_reverse=nan max_logit=11.7917
step:1731/1750 train_time:811696ms step_avg:468.92ms
[train step 1731] avg_loss=2.780283 main=2.333111 aux=0.447172 imp_cv2=0.1837 load_cv2=5.0155 usage_frac=0.4018 topk_prob_mean=0.2897 ema_alpha_reverse=nan max_logit=11.7917
step:1732/1750 train_time:812148ms step_avg:468.91ms
[train step 1732] avg_loss=4.059761 main=3.595227 aux=0.464534 imp_cv2=0.0639 load_cv2=5.3423 usage_frac=0.4018 topk_prob_mean=0.2359 ema_alpha_reverse=nan max_logit=11.7917
step:1733/1750 train_time:812823ms step_avg:469.03ms
[train step 1733] avg_loss=4.290001 main=3.785840 aux=0.504161 imp_cv2=0.0348 load_cv2=5.8546 usage_frac=0.3973 topk_prob_mean=0.1935 ema_alpha_reverse=nan max_logit=11.7917
step:1734/1750 train_time:813274ms step_avg:469.02ms
[train step 1734] avg_loss=4.105137 main=3.627589 aux=0.477548 imp_cv2=0.0455 load_cv2=5.5220 usage_frac=0.3973 topk_prob_mean=0.2208 ema_alpha_reverse=nan max_logit=11.7917
step:1735/1750 train_time:813729ms step_avg:469.01ms
[train step 1735] avg_loss=3.105499 main=2.661258 aux=0.444241 imp_cv2=0.1632 load_cv2=4.9972 usage_frac=0.4018 topk_prob_mean=0.2831 ema_alpha_reverse=nan max_logit=11.7917
step:1736/1750 train_time:814169ms step_avg:468.99ms
[train step 1736] avg_loss=3.304437 main=2.844639 aux=0.459799 imp_cv2=0.0771 load_cv2=5.2769 usage_frac=0.3973 topk_prob_mean=0.2449 ema_alpha_reverse=nan max_logit=11.7917
step:1737/1750 train_time:814626ms step_avg:468.98ms
[train step 1737] avg_loss=3.342445 main=2.871076 aux=0.471369 imp_cv2=0.0552 load_cv2=5.4365 usage_frac=0.4062 topk_prob_mean=0.2262 ema_alpha_reverse=nan max_logit=11.7917
step:1738/1750 train_time:815081ms step_avg:468.98ms
[train step 1738] avg_loss=3.187290 main=2.732905 aux=0.454385 imp_cv2=0.1009 load_cv2=5.1887 usage_frac=0.4018 topk_prob_mean=0.2577 ema_alpha_reverse=nan max_logit=11.7917
step:1739/1750 train_time:815530ms step_avg:468.97ms
[train step 1739] avg_loss=3.930588 main=3.429855 aux=0.500733 imp_cv2=0.0405 load_cv2=5.8151 usage_frac=0.3973 topk_prob_mean=0.1966 ema_alpha_reverse=nan max_logit=11.7917
step:1740/1750 train_time:815976ms step_avg:468.95ms
[train step 1740] avg_loss=3.284762 main=2.825106 aux=0.459656 imp_cv2=0.0796 load_cv2=5.2721 usage_frac=0.4062 topk_prob_mean=0.2450 ema_alpha_reverse=nan max_logit=11.7917
step:1741/1750 train_time:816424ms step_avg:468.94ms
[train step 1741] avg_loss=4.265994 main=3.764351 aux=0.501643 imp_cv2=0.0362 load_cv2=5.8226 usage_frac=0.3973 topk_prob_mean=0.1948 ema_alpha_reverse=nan max_logit=11.7917
step:1742/1750 train_time:816879ms step_avg:468.93ms
[train step 1742] avg_loss=2.904936 main=2.463304 aux=0.441631 imp_cv2=0.1999 load_cv2=4.9316 usage_frac=0.4062 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=11.7917
step:1743/1750 train_time:817323ms step_avg:468.92ms
[train step 1743] avg_loss=3.150412 main=2.705989 aux=0.444422 imp_cv2=0.1618 load_cv2=5.0030 usage_frac=0.4018 topk_prob_mean=0.2827 ema_alpha_reverse=nan max_logit=11.7917
step:1744/1750 train_time:817771ms step_avg:468.91ms
[train step 1744] avg_loss=4.015118 main=3.544231 aux=0.470887 imp_cv2=0.0547 load_cv2=5.4320 usage_frac=0.4018 topk_prob_mean=0.2287 ema_alpha_reverse=nan max_logit=11.7917
step:1745/1750 train_time:818218ms step_avg:468.89ms
[train step 1745] avg_loss=3.458483 main=2.994217 aux=0.464266 imp_cv2=0.0629 load_cv2=5.3412 usage_frac=0.4018 topk_prob_mean=0.2335 ema_alpha_reverse=nan max_logit=11.7917
step:1746/1750 train_time:818660ms step_avg:468.88ms
[train step 1746] avg_loss=3.436180 main=2.971689 aux=0.464492 imp_cv2=0.0743 load_cv2=5.3318 usage_frac=0.4062 topk_prob_mean=0.2417 ema_alpha_reverse=nan max_logit=11.7917
step:1747/1750 train_time:819103ms step_avg:468.86ms
[train step 1747] avg_loss=3.529748 main=3.062017 aux=0.467731 imp_cv2=0.0623 load_cv2=5.3897 usage_frac=0.4062 topk_prob_mean=0.2343 ema_alpha_reverse=nan max_logit=11.7917
step:1748/1750 train_time:819550ms step_avg:468.85ms
[train step 1748] avg_loss=3.316358 main=2.866229 aux=0.450129 imp_cv2=0.1214 load_cv2=5.1144 usage_frac=0.4018 topk_prob_mean=0.2663 ema_alpha_reverse=nan max_logit=11.7917
step:1749/1750 train_time:820003ms step_avg:468.84ms
[train step 1749] avg_loss=3.664749 main=3.184948 aux=0.479801 imp_cv2=0.0417 load_cv2=5.5524 usage_frac=0.4018 topk_prob_mean=0.2129 ema_alpha_reverse=nan max_logit=11.7917
step:1750/1750 train_time:820445ms step_avg:468.83ms
Running validation...
step:1750/1750 val_loss:2.916882 train_time:820456ms step_avg:468.83ms
peak memory allocated: 29973 MiB reserved: 33242 MiB
