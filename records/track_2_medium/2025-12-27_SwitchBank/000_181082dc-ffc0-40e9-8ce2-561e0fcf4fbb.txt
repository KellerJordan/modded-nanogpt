wandb logging enabled.
===== /home/ubuntu/switch-bank/train_switch_bank.py =====\n# ========== train_switch_bank.py ==========

import csv
import json
import os
import sys
from pathlib import Path

def _read_text(path: Path) -> str:
    try:
        return path.read_text()
    except Exception:
        return ""

def _build_code() -> str:
    code_paths = [
        Path(__file__).resolve(),
        Path("switch_bank/utils.py"),
        Path("switch_bank/optim/muon.py"),
        Path("switch_bank/model/components.py"),
        Path("switch_bank/model/gpt.py"),
        Path("switch_bank/data.py"),
        Path("switch_bank/trainer.py"),
    ]
    code_parts = []
    for p in code_paths:
        if p.exists():
            code_parts.append(f"===== {p} =====\\n{_read_text(p)}")
    return "\\n\\n".join(code_parts)

code = _build_code()
import uuid
import copy
from dataclasses import dataclass
from switch_bank.utils import compute_train_micro_len
from switch_bank.optim.muon import Muon
from switch_bank.model.components import CausalSelfAttention
from switch_bank.model.gpt import GPT
from switch_bank.data import summarize_router_metrics, summarize_expert_usage, summarize_expert_activity, \
    router_summary_str, distributed_data_generator
from switch_bank import trainer

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
import torch._functorch.config
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import nn
import torch.distributed as dist
torch._inductor.config.coordinate_descent_tuning = True   # allowed for medium track; false for rocm / single-GPU
torch._functorch.config.donated_buffer = False
torch._dynamo.config.compiled_autograd = False  # torch nightly build issue??


#
# -----------------------------------------------------------------------------
# The main model
# -----------------------------------------------------------------------------

# ----- Parameter accounting / logging -----
def _num_params(tensors_iter):
    return sum(p.numel() for p in tensors_iter)

def _unique_params(params):
    seen = set()
    unique = []
    for p in params:
        pid = id(p)
        if pid in seen:
            continue
        seen.add(pid)
        unique.append(p)
    return unique

def _fmt(n: int) -> str:
    return f"{n:,} ({n/1e6:.3f}M)"

@torch.no_grad()
def log_param_counts(model: nn.Module, args, print_fn) -> None:
    #if not args.enable_extra_logging:
    #    return
    # totals
    total = _num_params(model.parameters())

    # attention stack: merged QKV/out per block that has attention
    attn_params = []
    attn_layers = 0
    for b in model.blocks:
        if isinstance(b.attn, CausalSelfAttention):
            attn_params.append(b.attn.qkvo_w)
            attn_layers += 1
    attn_total = _num_params(_unique_params(attn_params))

    # FFN bank: experts + routers
    bank_expert_params = list(model.bank.W1) + list(model.bank.W2)
    bank_router_params = list(model.bank.router_w) + list(model.bank.router_b)
    bank_expert_total = _num_params(bank_expert_params)
    bank_router_total = _num_params(bank_router_params)
    bank_total = bank_expert_total + bank_router_total

    # embeddings: tied token embedding + N value-embedding tables
    tok_embed_total = _num_params(model.embed.parameters())
    ve_total = sum(_num_params(ve.parameters()) for ve in model.value_embeds)
    embeds_total = tok_embed_total + ve_total

    # lm head (if untied / instantiated)
    head_total = _num_params([model.lm_head]) if model.lm_head is not None else 0

    # scalars (skip lambdas / SA lambdas / skip weights)
    scalars_total = model.scalars.numel()

    adapter_total = 0
    if getattr(model.bank, "use_adapters", False):
        adapter_total = model.bank.adapter_scale.numel() + model.bank.adapter_bias.numel()

    # anything unaccounted (should be ~0; keeps us honest)
    accounted = attn_total + bank_total + embeds_total + head_total + scalars_total + adapter_total
    other_total = total - accounted

    # pretty print
    print_fn("=== Parameter counts ===", console=True)
    print_fn(f"model total:           {_fmt(total)}", console=True)
    print_fn(f"  attention stack ({attn_layers} of {args.num_layers} layers run attention): {_fmt(attn_total)}", console=True)
    print_fn(f"  FFN bank total:      {_fmt(bank_total)}", console=True)
    print_fn(f"    ├─ experts W1/W2:  {_fmt(bank_expert_total)}", console=True)
    print_fn(f"    └─ routers:        {_fmt(bank_router_total)}", console=True)
    print_fn(f"  embeddings (tok + {model.num_value_embeds}× value): {_fmt(embeds_total)}", console=True)
    print_fn(f"    └─ token embed:    {_fmt(tok_embed_total)}", console=True)
    print_fn(f"    └─ value embeds:   {_fmt(ve_total)}", console=True)
    if head_total:
        tied_state = "tied" if model._head_tied_runtime else "untied"
        print_fn(f"  lm head ({tied_state}):   {_fmt(head_total)}", console=True)
    if adapter_total:
        print_fn(f"  adapters:            {_fmt(adapter_total)}", console=True)
    print_fn(f"  scalars:             {_fmt(scalars_total)}", console=True)
    if other_total != 0:
        print_fn(f"  other (unclassified): {_fmt(other_total)}", console=True)
    print_fn("="*100, console=False)

# -----------------------------------------------------------------------------
# int main
# -----------------------------------------------------------------------------

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin"
    val_files = "data/fineweb10B/fineweb_val_*.bin"
    val_tokens = 10485760
    val_tokens_intermediate: int | None = 32768 * 7
    val_tokens_final: int | None = 10485760
    train_seq_len = 12*1024 #64*1024          # effective tokens per optimizer step per rank
    val_seq_len = 8192 #4*64*1024
    # minibatch / gradient accumulation
    grad_accum_steps = 1 # default=1 keeps original, multi-GPU behavior
    train_micro_seq_len: int | None = None  # if None, computed as train_seq_len // grad_accum_steps
    # optimization
    num_iterations = 1750
    early_stop_step: int | None = None
    cooldown_frac = 0.65  #0.7
    lr_final_mult = 0.0  # decay to this % of original lr at final iteration
    lr_freeze_last_steps = 0 # decay toward lr_final_mult at final step, but freeze lr at num_iterations-lr_freeze_last_steps
    lr_embed = 0.3
    lr_scalar = 0.015
    lr_head = 1/320
    lr_router = 0.095
    lr_adapter = 0.03
    lr_muon = 0.025
    router_grad_clip_norm = 0.0
    router_autoclip = True
    # Muon optimizer parameters (see switch_bank/optim/muon.py)
    muon_betas: tuple[float, float] = (0.8, 0.95)
    muon_eps: float = 1e-10
    muon_weight_decay: float = 0.0
    muon_momentum: float = 0.95
    muon_ns_iters: int = 4
    use_turbo_muon: bool = True
    turbo_muon_warmstart_smax_start_frac: float = -1 #0.725  # <0 disables; >=0 enables warm-started sigma-max (near end)
    # architecture
    vocab_size = 50257
    model_dim = 896
    num_layers = 28
    # Layer weight tying (attention + router adapters). Set to () to disable. Avoid tying layers with different attention types (short/long).
    layer_tie_groups: tuple[tuple[int, ...], ...] = (
        #(9, 10), (13, 14), (17, 18), (21, 22), (25, 26),  # Add 5,6 if need more. Remove from the beginning for fewer.
        #(17, 18), (21, 22), (25, 26),
    )
    head_dim = 128
    num_heads = model_dim // head_dim #7
    # value-embeddings integer count: 0, 1, 2, or 3 supported.
    num_value_embeds = 2
    tie_lm_head = False
    untie_lm_head_frac = -1.0
    # Bank / routing
    num_experts = 8 #9
    ffn_hidden = 1024
    topk = 1
    topk_val: int | None = None
    lb_coeff = 2.15e-3
    router_entropy_coeff = 2.5e-3  # coefficient for router entropy aux loss component
    use_router_adapters = True
    router_block_pos_bins = 8  # 4 / 8 / 16
    first_doc_tokens_N = 64
    router_enable_forward_ema = False
    router_enable_reverse_ema = True
    ema_alpha_fwd = 0.80
    ema_alpha_rev = 0.85
    ema_window_size_fwd = 128  # <=0 means full sequence
    ema_block_size_fwd = 128
    ema_window_size_rev = 384
    ema_block_size_rev = 384
    router_ema_layer_stride = -1  # How often to calculate fresh EMAs (which are then used by the next N-1 layers).  N < 0 -> num_layers (one shared EMA calculation for all layers).
    # Parameter freezing
    router_freeze_frac = 1.0
    router_freeze_adapters = False
    router_lr_reduce_start_frac = -1.0
    shared_ffn_freeze_frac = 1.0
    shared_ffn_lr_reduce_start_frac = -1.0
    # skip-attention layers (short-SWA) — exactly two
    skip_attn_layers = (11,)  # (7,)
    expert_activation_schedule: tuple[tuple[int, int], ...] = ((0, 1), (75, 2), (141, 3), (234, 4), (338, 5), (441, 6), (591, 7), (695, 8),)     #((0, 1), (200, 2), (375, 3), (625, 4), (900, 5), (1175, 6), (1575, 7), (1850, 8),) # (2175, 9))
    router_temp_init = 1.464
    router_temp_final = 0.93744
    router_temp_power = 1.5  # fallback if anchor disabled
    router_temp_anchor_delta_steps = 284 #756  # steps after 2nd expert activation to hit anchor ratio
    router_temp_anchor_ratio = 0.49  # temp curve hits this ratio at anchor delta
    router_logit_cap_initial = 1.166
    router_logit_cap_final = 13.757
    router_logit_cap_delta_steps = 237 #632  # ramp length after second expert activation
    # Optional Gumbel exploration (off by default)
    router_use_gumbel = True
    router_gumbel_schedule: tuple[tuple[int, int], ...] = ((75, 441), (459, 488), (534, 722), (900, 909), (1004, 1022), (1097, 1107), (1200, 1209), (1284, 1313), (1472, 1500))       #((200, 1175), (1225, 1300), (1425, 1925),) # (2400, 2425), (2675, 2725), (2925, 2950), (3200, 3225), ) #(3425, 3500), (3925, -1))
    # Layerwise router temp & lb boosts.
    router_boost_shape = "peak"  # options: peak (default), valley, linear_start, linear_end
    router_temp_boost = 0.2
    router_lb_boost = 0.5
    router_layer_peak_frac = 0.475  # only used for peak or valley shapes. boosts are calculated continuously
    # evaluation and logging
    val_loss_every = 50  # 0 for only at end
    save_final_checkpoint = True
    save_final_checkpoint_if_loss_below: bool = True
    save_final_checkpoint_max_loss: float = 2.92
    checkpoint_save_step: int = -1  # -1 disables mid-training save
    resume_checkpoint: str | None = None
    log_dir: str = "records/track_2_medium/2025-12-27_SwitchBank"
    use_wandb = True
    wandb_project = "switch-bank-final"
    wandb_run_name = ""
    wandb_log_every = 1
    enable_extra_logging = False
    enable_extra_wandb_logging = False
    do_model_warmup = True
    metrics_log_every = 25


def _coerce_override(value, current):
    if current is None:
        return value
    if isinstance(current, bool):
        return bool(value)
    if isinstance(current, int) and not isinstance(current, bool):
        return int(value)
    if isinstance(current, float):
        return float(value)
    if isinstance(current, tuple):
        if isinstance(value, (list, tuple)):
            return tuple(value)
    return value


def _apply_overrides(args, overrides: dict, source: str) -> None:
    for key, value in overrides.items():
        if not hasattr(args, key):
            raise KeyError(f"Unknown Hyperparameters override '{key}' from {source}")
        current = getattr(args, key)
        coerced = _coerce_override(value, current)
        setattr(args, key, coerced)


def _parse_overrides_env() -> dict:
    raw = os.environ.get("SWB_OVERRIDES_JSON") or os.environ.get("SWITCH_BANK_OVERRIDES_JSON")
    if not raw:
        return {}
    try:
        data = json.loads(raw)
    except json.JSONDecodeError as exc:
        raise ValueError(f"Failed to parse overrides JSON: {exc}") from exc
    if not isinstance(data, dict):
        raise ValueError("Overrides JSON must be an object/dict")
    return data


def _reset_runtime_state(model: nn.Module) -> None:
    base_model = getattr(model, "_orig_mod", model)
    for name, value in (
        ("_router_frozen_logged", False),
        ("_ffn_frozen_logged", False),
        ("_last_active_expert_count", None),
        ("_pending_active_count", None),
    ):
        if hasattr(base_model, name):
            setattr(base_model, name, value)


def _set_seed(seed: int | None) -> None:
    if seed is None:
        return
    import random
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def run_training(
    overrides: dict | None = None,
    single_gpu: bool = False,
    early_stop_step: int | None = None,
    early_stop_val_multiplier: int = 1,
    reuse_state: dict | None = None,
    results_path: str | None = None,
    destroy_process_group: bool = True,
    seed: int | None = None,
):
    args = Hyperparameters()
    env_overrides = _parse_overrides_env()
    if env_overrides:
        _apply_overrides(args, env_overrides, "env")
    if overrides:
        _apply_overrides(args, overrides, "call")
    if args.router_ema_layer_stride < 0:
        args.router_ema_layer_stride = args.num_layers
    _set_seed(seed)
    early_stop_is_final = False
    if early_stop_step is None:
        early_stop_step = getattr(args, "early_stop_step", None)
        if early_stop_step is not None:
            early_stop_is_final = True

    def hyperparams_to_config(h: Hyperparameters) -> dict:
        cfg: dict[str, object] = {}
        for name in dir(h):
            if name.startswith("_"):
                continue
            value = getattr(h, name)
            if callable(value):
                continue
            cfg[name] = value
        return cfg

    untie_lm_head_after = -1
    if args.tie_lm_head and args.untie_lm_head_frac is not None and args.untie_lm_head_frac >= 0:
        untie_lm_head_after = int(args.untie_lm_head_frac * args.num_iterations)
        untie_lm_head_after = min(max(untie_lm_head_after, 0), args.num_iterations)

    if single_gpu:
        os.environ.setdefault("RANK", "0")
        os.environ.setdefault("WORLD_SIZE", "1")
        os.environ.setdefault("LOCAL_RANK", "0")
        os.environ.setdefault("MASTER_ADDR", "127.0.0.1")
        os.environ.setdefault("MASTER_PORT", "29500")
    run_id = int(os.environ.get("RUN_ID", 0))
    import torch
    assert torch.cuda.is_available()
    if dist.is_initialized():
        rank = dist.get_rank()
        world_size = dist.get_world_size()
    else:
        rank = int(os.environ.get("RANK", "0"))
        world_size = int(os.environ.get("WORLD_SIZE", "1"))
        device = torch.device("cuda", int(os.environ.get("LOCAL_RANK", "0")))
        torch.cuda.set_device(device)
        dist.init_process_group(backend="nccl", device_id=device)
    device = torch.device("cuda", int(os.environ.get("LOCAL_RANK", "0")))
    torch.cuda.set_device(device)
    dist.barrier()
    master_process = (rank == 0)
    run_id_full: str | None = None

    if master_process:
        run_id_full = f"{run_id:03d}_{uuid.uuid4()}"
        log_dir = args.log_dir
        os.makedirs(log_dir, exist_ok=True)
        logfile = os.path.join(log_dir, f"{run_id_full}.txt")
        print(logfile)
    def print0(s, console=False):
        if master_process:
            with open(logfile, "a") as f:
                if console:
                    print(s)
                print(s, file=f)

    # --- Robust Inductor trace hook (compatible with callsites with/without metadata_fn) ---
    from torch._logging._internal import trace_structured as _orig_trace_structured  # keep original
    import torch._inductor.codecache  # noqa: E402
    import torch._inductor.graph      # noqa: E402

    def _patched_trace_structured(name, *args, **kwargs):
        """
        Torch Inductor sometimes calls trace_structured(name, metadata_fn, **kwargs),
        and other times as trace_structured(name, **kwargs) with metadata_fn omitted.
        Be permissive and forward both forms. Also print compiled filename when available.
        """
        metadata_fn = kwargs.get("metadata_fn", None)
        if metadata_fn is None and len(args) > 0 and callable(args[0]):
            # first positional could be metadata_fn
            metadata_fn = args[0]
        try:
            if name == "inductor_output_code" and callable(metadata_fn):
                md = metadata_fn()
                filename = (md.get("filename", "Unknown") if isinstance(md, dict) else "Unknown")
                print0(f"inductor_output_code: {filename}")
        except Exception:
            # never let logging break compilation
            pass
        return _orig_trace_structured(name, *args, **kwargs)

    torch._inductor.codecache.trace_structured = _patched_trace_structured
    torch._inductor.graph.trace_structured = _patched_trace_structured
    # --- end robust hook ---

    wandb_run = None
    if args.use_wandb and os.environ.get("WANDB_DISABLED", "0").lower() not in ("1", "true", "yes") and master_process:
        wandb_reinit = os.environ.get("WANDB_REINIT", "0").lower() in ("1", "true", "yes")
        try:
            import wandb  # type: ignore
            wandb_run = wandb.init(
                project=args.wandb_project,
                config=hyperparams_to_config(args),
                reinit=wandb_reinit,
                #name=args.wandb_run_name or run_id_full or f"rank{rank}",
            )
            print0("wandb logging enabled.", console=True)
        except Exception as err:
            print0(f"wandb init failed ({err}); disabling wandb.", console=True)
            wandb_run = None

    metrics_csv_file = None
    metrics_csv_writer = None
    expert_usage_headers: list[str] = []
    expert_active_headers: list[str] = []
    if master_process and run_id_full is not None and args.enable_extra_logging:
        metrics_csv_path = os.path.join(args.log_dir, f"{run_id_full}_metrics.csv")
        metrics_csv_file = open(metrics_csv_path, "w", newline="")
        metrics_csv_writer = csv.writer(metrics_csv_file)
        expert_usage_headers = [f"expert_usage_e{i}" for i in range(args.num_experts)]
        expert_active_headers = [f"expert_active_e{i}" for i in range(args.num_experts)]
        router_ema_headers: list[str] = []
        if args.router_enable_forward_ema:
            router_ema_headers.append("router_ema_alpha_forward")
        if args.router_enable_reverse_ema:
            router_ema_headers.append("router_ema_alpha_reverse")
        metrics_csv_writer.writerow([
            "step", "loss", "loss_main", "loss_aux",
            "router_imp_cv2", "router_load_cv2", "router_usage_frac",
            "router_topk_prob_mean", *router_ema_headers, "router_max_logit",
            "logit_cap", "router_temp", "window_blocks", *expert_usage_headers, *expert_active_headers
        ])

    def log_metrics_row(step_value: int, avg_loss: float, avg_main: float, avg_aux: float,
                        router_summary: dict[str, float], logit_cap_value: float | None,
                        router_temp_value: float, window_blocks_value: int,
                        expert_usage: torch.Tensor | None,
                        expert_active: torch.Tensor | None):
        if metrics_csv_writer is None:
            return
        expert_usage_list = []
        if expert_usage is not None:
            expert_usage_list = [float(x) for x in expert_usage.tolist()]
        else:
            expert_usage_list = [float("nan")] * len(expert_usage_headers)
        expert_active_list = []
        if expert_active is not None:
            expert_active_list = [float(x) for x in expert_active.tolist()]
        else:
            expert_active_list = [float("nan")] * len(expert_active_headers)
        row = [
            step_value,
            avg_loss,
            avg_main,
            avg_aux,
            router_summary.get("imp_cv2", float("nan")),
            router_summary.get("load_cv2", float("nan")),
            router_summary.get("usage_frac", float("nan")),
            router_summary.get("topk_prob_mean", float("nan")),
        ]
        if args.router_enable_forward_ema:
            row.append(router_summary.get("ema_alpha_forward", float("nan")))
        if args.router_enable_reverse_ema:
            row.append(router_summary.get("ema_alpha_reverse", float("nan")))
        row.extend([
            router_summary.get("max_logit", float("nan")),
            (logit_cap_value if logit_cap_value is not None else float("nan")),
            router_temp_value,
            window_blocks_value,
        ])
        row.extend(expert_usage_list)
        row.extend(expert_active_list)
        metrics_csv_writer.writerow(row)

    print0(code)
    print0("="*100)
    print0(f"Running Python {sys.version}")
    print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
    def nvidia_smi():
        import subprocess
        try:
            return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
        except FileNotFoundError:
            return "nvidia-smi not available."
    print0(nvidia_smi())
    print0("="*100)

    shared_state = reuse_state if reuse_state is not None else {}
    model: nn.Module | None = shared_state.get("model")
    optimizers: list[torch.optim.Optimizer] | None = shared_state.get("optimizers")
    opt2params: dict | None = shared_state.get("opt2params")
    using_cached = model is not None and optimizers is not None and opt2params is not None

    ########################################
    #    Construct model and optimizer     #
    ########################################

    if not using_cached:
        model: nn.Module = GPT(
            vocab_size=args.vocab_size,
            num_layers=args.num_layers,
            num_heads=args.num_heads,
            model_dim=args.model_dim,
            max_seq_len=max(args.train_seq_len, args.val_seq_len),
            skip_attn_layers=set(args.skip_attn_layers),
            layer_tie_groups=tuple(args.layer_tie_groups) if args.layer_tie_groups is not None else tuple(),
            E=args.num_experts,
            h=args.ffn_hidden,
            lb_coeff=args.lb_coeff,
            ent_coeff=args.router_entropy_coeff,
            k=args.topk,
            num_value_embeds=args.num_value_embeds,
            tie_lm_head=args.tie_lm_head,
            untie_lm_head_after=untie_lm_head_after,
            ema_alpha_fwd=args.ema_alpha_fwd,
            ema_alpha_rev=args.ema_alpha_rev,
            router_temp_init=args.router_temp_init,
            router_temp_final=args.router_temp_final,
            router_temp_power=args.router_temp_power,
            router_temp_anchor_delta_steps=args.router_temp_anchor_delta_steps,
            router_temp_anchor_ratio=args.router_temp_anchor_ratio,
            router_logit_cap_initial=args.router_logit_cap_initial,
            router_logit_cap_final=args.router_logit_cap_final,
            router_logit_cap_delta_steps=args.router_logit_cap_delta_steps,
            router_layer_peak_frac=args.router_layer_peak_frac,
            router_temp_boost=args.router_temp_boost,
            router_lb_boost=args.router_lb_boost,
            router_boost_shape=args.router_boost_shape,
            use_router_adapters=args.use_router_adapters,
            expert_activation_schedule=args.expert_activation_schedule,
            router_freeze_frac=args.router_freeze_frac,
            router_freeze_adapters=args.router_freeze_adapters,
            ema_block_size_fwd=args.ema_block_size_fwd,
            ema_block_size_rev=args.ema_block_size_rev,
            ema_window_size_fwd=args.ema_window_size_fwd,
            ema_window_size_rev=args.ema_window_size_rev,
            ema_layer_stride=args.router_ema_layer_stride,
            shared_ffn_freeze_frac=args.shared_ffn_freeze_frac,
            router_use_gumbel=args.router_use_gumbel,
            router_gumbel_schedule=args.router_gumbel_schedule,
            router_block_pos_bins=args.router_block_pos_bins,
            first_doc_tokens_N=args.first_doc_tokens_N,
            router_enable_forward_ema=args.router_enable_forward_ema,
            router_enable_reverse_ema=args.router_enable_reverse_ema,
            extra_console_logging=args.enable_extra_logging,
            extra_wandb_logging=args.enable_extra_wandb_logging,
            print_fn=print0,
        ).cuda()

        for m in model.modules():
            if isinstance(m, nn.Embedding):
                m.bfloat16()
        for param in model.parameters():
            dist.broadcast(param.detach(), 0)

        log_param_counts(model, args, print0)

        # collect the parameters to optimize
        # ### FFNBANK MOD: include bank expert matrices in Muon spectral groups;
        # non-spectral params (routers/embeds/scalars/head/adapters) use AdamW branch.
        def is_2d(p: nn.Parameter) -> bool:
            return p.ndim >= 2

        attn_2d_params = []
        for b in model.blocks:
            if isinstance(b.attn, CausalSelfAttention):
                attn_2d_params.append(b.attn.qkvo_w)
        attn_2d_params = _unique_params(attn_2d_params)
        ffn_matrix_params = [*model.bank.W1, *model.bank.W2]
        hidden_matrix_params = attn_2d_params + ffn_matrix_params

        embed_params = [*model.embed.parameters(), *model.value_embeds.parameters()]
        head_params: list[nn.Parameter] = [model.lm_head] if model.lm_head is not None else []
        adapter_params = []
        if model.bank.use_adapters:
            adapter_params.extend([model.bank.adapter_scale, model.bank.adapter_bias])
        scalar_params = [model.scalars]
        router_params = list(model.bank.router_w) + list(model.bank.router_b)

        # sanity / completeness checks
        params_collections = [hidden_matrix_params, embed_params, head_params, adapter_params, scalar_params, router_params]
        optimized_parameters_set = {p for params in params_collections for p in params}
        assert optimized_parameters_set == {*model.parameters()}
        assert len(optimized_parameters_set) == sum(len(lst) for lst in params_collections)

        # init the optimizer(s)
        muon_param_groups: list[dict] = [
            dict(params=embed_params, lr=args.lr_embed, component="embed", spectral=False),
            dict(params=scalar_params, lr=args.lr_scalar, component="scalar", spectral=False),
            dict(params=router_params, lr=args.lr_router, component="router", spectral=False),
        ]
        if adapter_params:
            muon_param_groups.append(dict(params=adapter_params, lr=args.lr_adapter, component="adapter", spectral=False))
        if head_params:
            muon_param_groups.append(dict(params=head_params, lr=args.lr_head, component="head", spectral=False))
        if attn_2d_params:
            muon_param_groups.append(dict(params=attn_2d_params, lr=args.lr_muon, component="attention", spectral=True))
        if ffn_matrix_params:
            muon_param_groups.append(dict(params=ffn_matrix_params, lr=args.lr_muon, component="shared_ffn", spectral=True))

        optimizer = Muon(
            muon_param_groups,
            lr=args.lr_muon,  # default lr for spectral groups; overridden per-group above
            betas=tuple(args.muon_betas),
            eps=float(args.muon_eps),
            weight_decay=float(args.muon_weight_decay),
            muon_momentum=float(args.muon_momentum),
            lr_spec=None,
            ns_iters=int(args.muon_ns_iters),
            rank=rank,
            world_size=world_size,
            enable_turbomuon=bool(args.use_turbo_muon),
        )
        optimizers: list[torch.optim.Optimizer] = [optimizer]
        def opt_params(opt: torch.optim.Optimizer) -> list[nn.Parameter]:
            return [p for group in opt.param_groups for p in group["params"]]
        opt2params = {opt: opt_params(opt) for opt in optimizers}
        for opt in optimizers:
            for group in opt.param_groups:
                group["initial_lr"] = group["lr"]

    if not using_cached and reuse_state is not None:
        shared_state["model"] = model
        shared_state["optimizers"] = optimizers
        shared_state["opt2params"] = opt2params
    if using_cached:
        model = shared_state["model"]
        optimizers = shared_state["optimizers"]
        opt2params = shared_state["opt2params"]
        base_model = getattr(model, "_orig_mod", model)
        for key in (
            "router_temp_init",
            "router_temp_final",
            "router_temp_power",
            "router_temp_anchor_delta_steps",
            "router_temp_anchor_ratio",
            "router_logit_cap_initial",
            "router_logit_cap_final",
            "router_logit_cap_delta_steps",
            "router_use_gumbel",
            "router_gumbel_schedule",
            "router_temp_boost",
            "router_lb_boost",
            "router_layer_peak_frac",
            "router_boost_shape",
        ):
            if hasattr(base_model, key):
                setattr(base_model, key, getattr(args, key))
        if hasattr(base_model, "extra_console_logging"):
            base_model.extra_console_logging = bool(args.enable_extra_logging)
        if hasattr(base_model, "extra_wandb_logging"):
            base_model.extra_wandb_logging = bool(args.enable_extra_wandb_logging)
        if hasattr(base_model, "_print0"):
            base_model._print0 = print0
        if hasattr(base_model, "bank") and hasattr(base_model.bank, "enable_extra_wandb_logging"):
            base_model.bank.enable_extra_wandb_logging = bool(args.enable_extra_wandb_logging)
        _reset_runtime_state(model)
    start_step = 0
    resume_path = args.resume_checkpoint
    if resume_path:
        print0(f"Loading checkpoint from {resume_path}", console=True)
        checkpoint = torch.load(resume_path, map_location="cuda")
        model_state = checkpoint.get("model", {})
        if all(k.startswith("_orig_mod.") for k in model_state.keys()):
            model_state = {k.removeprefix("_orig_mod."): v for k, v in model_state.items()}
        args.approx_step_time_ms = float(checkpoint.get("approx_step_time_ms", 0))
        meta = checkpoint.get("meta", {}) or {}
        meta_checks = {
            "model_dim": args.model_dim,
            "num_layers": args.num_layers,
            "num_heads": args.num_heads,
            "num_experts": args.num_experts,
            "ffn_hidden": args.ffn_hidden,
            "vocab_size": args.vocab_size,
        }
        for key, current_val in meta_checks.items():
            saved_val = meta.get(key, current_val)
            assert saved_val == current_val, f"Checkpoint {key}={saved_val} does not match current args ({current_val})"
        model.load_state_dict(model_state)
        ckpt_opts = checkpoint.get("optimizers", [])
        assert len(ckpt_opts) == len(optimizers), "Optimizer count mismatch in checkpoint."
        for opt, state in zip(optimizers, ckpt_opts):
            opt.load_state_dict(state)
            for group in opt.param_groups:
                group.setdefault("initial_lr", group.get("lr", 0.0))
            # ensure Muon state dtypes survive checkpoint reload
            if isinstance(opt, Muon):
                for p, st in opt.state.items():
                    if not st:
                        continue
                    if "mantissa" in st and st["mantissa"].dtype != torch.uint16:
                        st["mantissa"] = st["mantissa"].to(dtype=torch.uint16)
                    if "momentum_buffer" in st and st["momentum_buffer"].dtype != torch.float32:
                        st["momentum_buffer"] = st["momentum_buffer"].to(dtype=torch.float32)
        start_step = int(checkpoint.get("step", -1)) + 1
        assert start_step >= 0, "Invalid checkpoint step."
        assert start_step <= args.num_iterations, "Checkpoint step exceeds configured num_iterations."
        print0(f"Resumed from checkpoint at step {start_step - 1}. Continuing from step {start_step}.", console=True)
        dist.barrier()

    if using_cached and shared_state.get("base_state") is not None and not resume_path:
        base_state = shared_state["base_state"]
        model.load_state_dict(base_state["model"])
        for opt, opt_state in zip(optimizers, base_state["optimizers"]):
            opt.load_state_dict(opt_state)
        _reset_runtime_state(model)

    for param in model.parameters():
        dist.broadcast(param.detach(), 0)

    if not using_cached:
        if not shared_state.get("compiled", False):
            print0("Compiling model...", console=True)
            model = torch.compile(model, dynamic=False)
            print0("Compile complete.", console=True)
        if reuse_state is not None:
            shared_state["model"] = model
            shared_state["compiled"] = True

    ########################################
    #            Warmup kernels            #
    ########################################

    train_micro_len = compute_train_micro_len(args.train_seq_len, args.grad_accum_steps, args.train_micro_seq_len)
    effective_train_tokens = train_micro_len * args.grad_accum_steps
    if effective_train_tokens != args.train_seq_len:
        print0(
            f"Adjusted train_micro_seq_len to {train_micro_len} (block-aligned). "
            f"Effective tokens per step: {effective_train_tokens} (requested {args.train_seq_len}).",
            console=True)

    warmup_needed = bool(args.do_model_warmup) and not shared_state.get("warmup_done", False)
    if warmup_needed and not using_cached:
        print0("Warming up kernels...", console=True)
        warmup_steps = 10
        initial_state = copy.deepcopy(dict(model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers]))
        warmup_loader = distributed_data_generator(
            args.train_files,
            world_size * train_micro_len,
            rank,
            world_size,
        )
        for warm_step in range(warmup_steps):
            model.zero_grad(set_to_none=True)
            for micro in range(args.grad_accum_steps):
                if micro == 0:
                    inputs, targets = next(warmup_loader)
                else:
                    inputs = targets = torch.randint(0, args.vocab_size, size=(train_micro_len,), device="cuda")
                outputs = model(inputs.to(torch.int32), targets, trainer.get_window_size_blocks(args, 0), 0, args.num_iterations)
                if isinstance(outputs, tuple):
                    loss_main, loss_aux = outputs
                    loss_val = float((loss_main + loss_aux).detach().item())
                    main_loss = float(loss_main.detach().item())
                    aux_loss = float(loss_aux.detach().item())
                    loss_total = (loss_main + loss_aux) / args.grad_accum_steps
                    loss_total.backward()
                else:
                    loss = outputs
                    loss_val = float(loss.detach().item())
                    components = model.latest_loss_components
                    main_loss = float(components[0].item()) if components else float("nan")
                    aux_loss = float(components[1].item()) if components else float("nan")
                    (loss / args.grad_accum_steps).backward()
                router_summary = summarize_router_metrics(model.latest_router_metrics or [])
                if args.enable_extra_logging:
                    print0(
                        f"[warmup {warm_step + 1}/{warmup_steps} micro {micro + 1}/{args.grad_accum_steps}] "
                        f"loss={loss_val:.6f} main={main_loss:.6f} aux={aux_loss:.6f} "
                        f"{router_summary_str(router_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
                        console=True)
            opt2futures = {
                opt: [dist.all_reduce(p.grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
                      for p in params if (p.grad is not None)]
                for opt, params in opt2params.items()
            }
            for opt in optimizers:
                torch.futures.collect_all(opt2futures[opt]).wait()
                opt.step()
            model.zero_grad(set_to_none=True)

        with torch.no_grad():
            model.bank.compile_warm_all_experts(d=args.model_dim, T_warm=128)

        with torch.no_grad():
            model.eval()
            val_inputs = torch.randint(0, args.vocab_size, size=(args.val_seq_len,), device="cuda")
            val_targets = torch.randint(0, args.vocab_size, size=(args.val_seq_len,), device="cuda")
            model(val_inputs.to(torch.int32), val_targets, trainer.get_window_size_blocks(args, 0), 0, args.num_iterations)
            model.train()


        model.load_state_dict(initial_state["model"])
        for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
            opt.load_state_dict(opt_state)
        if reuse_state is not None:
            shared_state["base_state"] = initial_state
            shared_state["warmup_done"] = True
        else:
            del initial_state
        print0("Kernel warmup complete.", console=True)

    if reuse_state is not None and shared_state.get("base_state") is None and not resume_path:
        shared_state["base_state"] = copy.deepcopy(
            dict(model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        )

    ########################################
    #        Training and validation       #
    ########################################

    torch.cuda.reset_peak_memory_stats()
    result = trainer.run_training(
        args=args,
        model=model,
        optimizers=optimizers,
        opt2params=opt2params,
        train_micro_len=train_micro_len,
        untie_lm_head_after=untie_lm_head_after,
        run_id_full=run_id_full,
        master_process=master_process,
        print0=print0,
        code=code,
        wandb_run=wandb_run,
        metrics_csv_writer=metrics_csv_writer,
        expert_usage_headers=expert_usage_headers,
        expert_active_headers=expert_active_headers,
        world_size=world_size,
        rank=rank,
        log_param_counts_fn=(lambda m: log_param_counts(m, args, print0)),
        start_step=start_step,
        checkpoint_save_step=args.checkpoint_save_step,
        early_stop_step=early_stop_step,
        early_stop_val_multiplier=early_stop_val_multiplier,
        early_stop_as_final=early_stop_is_final,
    )

    print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
        f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
    if master_process and results_path:
        payload = {"run_id": run_id_full}
        if isinstance(result, dict):
            payload.update(result)
        try:
            with open(results_path, "w") as f:
                json.dump(payload, f, indent=2, sort_keys=True)
        except Exception as err:
            print0(f"Failed to write results to {results_path}: {err}", console=True)
    if destroy_process_group and dist.is_initialized():
        dist.destroy_process_group()
    if wandb_run is not None:
        wandb_run.finish()
    if metrics_csv_file is not None:
        metrics_csv_file.close()
    return result

if __name__ == '__main__':
    run_training()
\n\n===== switch_bank/utils.py =====\nimport math
from functools import lru_cache
from typing import Iterable

import torch
from torch import Tensor
import torch.nn.functional as F


def _sanitize(t: Tensor, *, value: float = 0.0) -> Tensor:
    if torch.isfinite(t).all():
        return t
    return torch.nan_to_num(t, nan=value, posinf=value, neginf=value)


def _safe_softmax(logits: Tensor, dim: int) -> Tensor:
    logits = torch.nan_to_num(logits, nan=0.0, posinf=0.0)
    probs = logits.softmax(dim=dim)
    probs = _sanitize(probs)
    denom = probs.sum(dim=dim, keepdim=True).clamp_min(1e-6)
    return probs / denom


def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)


def rampdown_multiplier(progress: float, start_frac: float, end_frac: float) -> float:
    if end_frac < 0:
        return 1.0
    if progress >= end_frac:
        return 0.0
    if start_frac < 0 or start_frac >= end_frac:
        return 1.0
    if progress <= start_frac:
        return 1.0
    span = max(end_frac - start_frac, 1e-6)
    frac = 1.0 - (progress - start_frac) / span
    return min(max(frac, 0.0), 1.0)


def compute_train_micro_len(train_seq_len: int, grad_accum_steps: int, train_micro_seq_len: int | None) -> int:
    if train_micro_seq_len is not None:
        micro = train_micro_seq_len
    else:
        approx = max(train_seq_len // grad_accum_steps, 128)
        approx = (approx // 128) * 128
        if approx == 0:
            approx = 128
        micro = approx
    assert micro % 128 == 0, "train_micro_seq_len must be a multiple of 128 tokens (block size)"
    return micro


def summarize(values: Iterable[Tensor | float], reducer) -> dict:
    # Placeholder utility for potential future reductions; kept for parity with planned structure.
    return {}
\n\n===== switch_bank/optim/muon.py =====\nimport math
from typing import Any, Dict, Iterable, List, Optional, Tuple

import torch
import torch.distributed as dist
from torch import Tensor
from torch.optim import Optimizer

# Optional torch.compile compatibility
if hasattr(torch, "compile"):
    _compile = torch.compile
else:  # pragma: no cover
    def _compile(f):
        return f


def _as_full_prec_tensor(val: float, device: torch.device) -> Tensor:
    """
    Helper that mimics torch._as_tensor_fullprec where available, but safely
    falls back to a standard float32 tensor otherwise.
    """
    if hasattr(torch, "_as_tensor_fullprec"):
        # type: ignore[attr-defined]
        return torch._as_tensor_fullprec(val)  # pragma: no cover
    return torch.tensor(val, dtype=torch.float32, device=device)


def zeropower_via_newtonschulz5(G: Tensor) -> Tensor:
    """
    Reference Muon Newton–Schulz quintic iteration (unchanged).
    """
    assert G.ndim >= 2
    X = G.bfloat16()
    transposed = False
    if G.size(-2) > G.size(-1):
        X = X.mT
        transposed = True

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)

    # Quintic NS iterations
    for a, b, c in [
        (4.0848, -6.8946, 2.9270),
        (3.9505, -6.3029, 2.6377),
        (3.7418, -5.5913, 2.3037),
        (2.8769, -3.1427, 1.2046),
        (2.8366, -3.0525, 1.2012),
    ]:
        A = X @ X.mT
        B = b * A + c * (A @ A)
        X = a * X + B @ X

    if transposed:
        X = X.mT
    return X


@_compile
def _muon_update_kernel(
    acc_bf16_view_u16: Tensor,
    mantissa: Tensor,
    momentum_buffer: Tensor,
    grad: Tensor,
    momentum: Tensor,
    eff_lr: Tensor,
    eff_weight_decay: Tensor,
) -> None:
    """
    Bit-for-bit equivalent to the reference Muon update (kept intact).
    """
    assert acc_bf16_view_u16.dtype == mantissa.dtype == torch.uint16
    grad = grad.float()
    # Same two-step use of momentum as in the reference implementation
    momentum_buffer.copy_(momentum * momentum_buffer + (1 - momentum) * grad)
    v = zeropower_via_newtonschulz5(momentum * momentum_buffer + (1 - momentum) * grad)

    acc_m_u32 = (acc_bf16_view_u16.to(torch.uint32) << 16) | mantissa.to(torch.uint32)
    acc_view_f32 = acc_m_u32.view(torch.float32)
    acc_view_f32.mul_(1 - eff_weight_decay)
    acc_view_f32.add_(other=v, alpha=-eff_lr)
    acc_m_u32 = acc_view_f32.view(torch.uint32)
    acc_bf16_view_u16.copy_((acc_m_u32 >> 16).to(torch.uint16))
    mantissa.copy_(acc_m_u32.to(torch.uint16))


def power_iteration_smax(
    A: Tensor,
    iters: int = 2,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Approximate largest singular value of a (batched) 2D tensor via power iteration.
    """
    A = A.float()
    if A.ndim == 2:
        m, n = A.shape
        if (
            v_buf is not None
            and (v_buf.shape != (n,) or v_buf.device != A.device or v_buf.dtype != A.dtype)
        ):
            v_buf = None

        if v_buf is None:
            v = torch.randn(n, device=A.device, dtype=A.dtype, generator=generator)
        else:
            v = v_buf

        v.div_(v.norm() + 1e-8)
        for _ in range(iters):
            u = A @ v
            u = u / (u.norm() + 1e-8)
            v_new = A.mT @ u
            v_new = v_new / (v_new.norm() + 1e-8)
            if v_buf is None:
                v = v_new
            else:
                v.copy_(v_new)
        sigma = (A @ v).norm()
        return sigma

    # Batched matrices: treat leading dims as batch.
    m, n = int(A.size(-2)), int(A.size(-1))
    lead_shape = A.shape[:-2]
    A_flat = A.reshape(-1, m, n)
    batch = A_flat.size(0)

    if (
        v_buf is not None
        and (
            v_buf.shape != (*lead_shape, n)
            or v_buf.device != A.device
            or v_buf.dtype != A.dtype
        )
    ):
        v_buf = None

    if v_buf is None:
        v = torch.randn(batch, n, device=A.device, dtype=A.dtype, generator=generator)
    else:
        v = v_buf.reshape(batch, n)

    v.div_(v.norm(dim=1, keepdim=True) + 1e-8)
    for _ in range(iters):
        u = torch.bmm(A_flat, v.unsqueeze(-1)).squeeze(-1)
        u = u / (u.norm(dim=1, keepdim=True) + 1e-8)
        v_new = torch.bmm(A_flat.mT, u.unsqueeze(-1)).squeeze(-1)
        v_new = v_new / (v_new.norm(dim=1, keepdim=True) + 1e-8)
        if v_buf is None:
            v = v_new
        else:
            v.copy_(v_new)
    sigma = torch.bmm(A_flat, v.unsqueeze(-1)).squeeze(-1).norm(dim=1)
    return sigma.view(*lead_shape)


# ---- Turbo-Muon-style polar approximations ----

_ADANEWTON_COEFF_TABLE: Dict[Tuple[int, int], Tuple[float, float, float]] = {
    (2048, 2048): (3.3, -4.6, 2.0),
    (4096, 4096): (3.37, -4.9, 2.31),
    (3072, 2048): (2.9, -3.8, 1.86),
    (4096, 2048): (2.78, -3.49, 1.70),
}


def _get_adanewton_coeffs(m: int, n: int) -> Tuple[float, float, float]:
    if (m, n) in _ADANEWTON_COEFF_TABLE:
        return _ADANEWTON_COEFF_TABLE[(m, n)]
    if (n, m) in _ADANEWTON_COEFF_TABLE:
        return _ADANEWTON_COEFF_TABLE[(n, m)]
    # Default Muon-like coefficients
    return (3.44, -4.78, 2.03)


def _turbo_muon_polar(B: Tensor, ns_iters: int = 4) -> Tensor:
    """
    Turbo-Muon-inspired polar approximation:
    - Column-wise RMS preconditioning + few NS steps.
    """
    X = B.float()
    transposed = False
    if X.size(-2) > X.size(-1):
        X = X.mT
        transposed = True

    # Column-wise RMS preconditioning (per matrix, no batch mixing)
    col_rms = X.pow(2).mean(dim=-2, keepdim=True).sqrt().clamp_min(1e-6)
    X = X / col_rms

    # Normalize spectral norm
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)

    m, n = int(X.size(-2)), int(X.size(-1))
    a, b, c = _get_adanewton_coeffs(m, n)
    for _ in range(ns_iters):
        A = X @ X.mT
        X = a * X + b * (A @ X) + c * (A @ (A @ X))

    if transposed:
        X = X.mT
    return X


def approx_polar(
    B: Tensor,
    backend: str = "baseline",
    ns_iters: int = 4,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Approximate polar factor U for B ≈ U H with ||U||_op ≈ 1.
    backend:
      - "baseline": Muon zeropower_via_newtonschulz5
      - "turbo":    Turbo-Muon-style preconditioned NS
    """
    if backend == "turbo":
        U = _turbo_muon_polar(B, ns_iters=ns_iters)
    elif backend == "baseline":
        U = zeropower_via_newtonschulz5(B)
    else:
        raise ValueError(f"Unknown polar backend: {backend}")

    U = U.float()
    sigma_max = power_iteration_smax(U, iters=1, generator=generator, v_buf=v_buf)
    U = U / (sigma_max[..., None, None] + 1e-8)
    return U


def muon_like_spectral_update(
    B: Tensor,
    lr_spec_base: float,
    backend: str = "baseline",
    ns_iters: int = 4,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Plain Muon-style spectral update.
    """
    U = approx_polar(B, backend=backend, ns_iters=ns_iters, generator=generator, v_buf=v_buf)
    m, n = int(U.size(-2)), int(U.size(-1))
    shape_scale = math.sqrt(max(1.0, float(m) / max(1.0, float(n))))
    return -lr_spec_base * shape_scale * U


def _adamw_update_param(
    p: Tensor,
    state: Dict[str, Any],
    lr: float,
    betas: Tuple[float, float],
    eps: float,
    weight_decay: float,
) -> None:
    """
    Full AdamW update for non-spectral (AdamW-only) parameters.
    """
    if p.grad is None:
        return
    g = p.grad
    if g.is_sparse:  # pragma: no cover
        raise RuntimeError("Muon does not support sparse gradients")

    g32 = g.detach().to(torch.float32)

    exp_avg = state.get("exp_avg")
    exp_avg_sq = state.get("exp_avg_sq")
    if exp_avg is None:
        exp_avg = torch.zeros_like(p, dtype=torch.float32)
        exp_avg_sq = torch.zeros_like(p, dtype=torch.float32)
        state["exp_avg"] = exp_avg
        state["exp_avg_sq"] = exp_avg_sq
        state["adam_step"] = 0

    beta1, beta2 = betas
    t = int(state.get("adam_step", 0)) + 1
    state["adam_step"] = t

    exp_avg.mul_(beta1).add_(g32, alpha=1.0 - beta1)
    exp_avg_sq.mul_(beta2).addcmul_(g32, g32, value=1.0 - beta2)

    bias_correction1 = 1.0 - beta1**t
    bias_correction2 = 1.0 - beta2**t

    m_hat = exp_avg / bias_correction1
    v_hat = exp_avg_sq / bias_correction2

    denom = v_hat.sqrt().add_(eps)
    step_dir = -lr * (m_hat / denom)

    # Decoupled weight decay
    if weight_decay != 0.0:
        p.mul_(1.0 - lr * weight_decay)

    p.add_(step_dir.to(p.dtype))


class Muon(Optimizer):
    """
    Muon: hybrid optimizer for switch-bank.

    - Muon mode is based on Keller Jordan's Muon (MomentUm Orthogonalized by Newton–Schulz):
      https://kellerjordan.github.io/posts/muon/
    - TurboMuon mode is a faster Muon-inspired approximate-polar update (see `_turbo_muon_polar`
      and `approx_polar`).

    Param groups:
      - spectral=True  (default): 2D+ bfloat16 matrices updated via Muon (Turbo off)
        or TurboMuon-style spectral updates (Turbo on).
      - spectral=False: AdamW-only parameters (embeddings, heads, biases, norms, etc).
    """

    def __init__(
        self,
        params: Iterable[Tensor] | Iterable[Dict[str, Any]],
        # AdamW / Euclidean hyperparams
        lr: float = 1e-3,
        betas: Tuple[float, float] = (0.9, 0.95),
        eps: float = 1e-8,
        weight_decay: float = 0.01,
        # Muon spectral hyperparams
        muon_momentum: float = 0.95,
        lr_spec: Optional[float] = None,
        ns_iters: int = 4,
        rank: int = 0,
        world_size: int = 1,
        enable_turbomuon: bool = True,
    ) -> None:
        if lr_spec is None:
            lr_spec = lr

        defaults: Dict[str, Any] = dict(
            lr=lr,
            betas=betas,
            eps=eps,
            weight_decay=weight_decay,
            momentum=muon_momentum,
            lr_spec=lr_spec,
            spectral=True,  # default; can be overridden per param-group
        )
        super().__init__(params, defaults)

        self.rank = int(rank)
        self.world_size = int(world_size)
        self.enable_turbomuon = bool(enable_turbomuon)
        self.ns_iters = int(ns_iters)

        self._step_count: int = 0
        self._turbo_rng: Optional[torch.Generator] = None
        self._turbo_rng_state: Optional[Tensor] = None
        self._turbomuon_warmstart_smax: bool = False

        # Muon constraint: spectral parameters must be bfloat16
        for group in self.param_groups:
            if group.get("spectral", True):
                for p in group["params"]:
                    if not isinstance(p, Tensor):
                        continue
                    # Only enforce for >=2D tensors; 0/1D will usually go to AdamW or be ignored.
                    if p.ndim >= 2 and p.dtype != torch.bfloat16:
                        raise ValueError(
                            "Muon spectral parameters (2D) must be torch.bfloat16 "
                            f"(got dtype={p.dtype} for param shape {tuple(p.shape)}). "
                            "Put non-bfloat16 or non-2D parameters into a param group "
                            "with spectral=False to use pure AdamW."
                        )

    def _get_turbo_rng(self, device: torch.device) -> torch.Generator:
        if self._turbo_rng is not None:
            return self._turbo_rng

        gen = torch.Generator(device=device)
        base_seed = int(torch.initial_seed())
        seed = (base_seed + 1000003 * int(self.rank)) & 0xFFFFFFFFFFFFFFFF
        gen.manual_seed(seed)

        if self._turbo_rng_state is not None:
            state_cpu = self._turbo_rng_state.detach().to(device="cpu")
            gen.set_state(state_cpu)
            self._turbo_rng_state = None

        self._turbo_rng = gen
        return gen

    def set_turbomuon_warmstart_smax(self, enabled: bool) -> None:
        self._turbomuon_warmstart_smax = bool(enabled)

    def state_dict(self) -> Dict[str, Any]:
        out = super().state_dict()
        if not out.get("param_groups"):
            return out

        turbo_state: Optional[Tensor] = None
        if self._turbo_rng is not None:
            turbo_state = self._turbo_rng.get_state()
        elif self._turbo_rng_state is not None:
            turbo_state = self._turbo_rng_state

        if turbo_state is not None:
            out["param_groups"][0]["turbo_rng_state"] = turbo_state.detach().to(device="cpu")

        return out

    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:
        turbo_state: Optional[Tensor] = None
        try:
            param_groups = state_dict.get("param_groups", [])
            if param_groups:
                turbo_state = param_groups[0].get("turbo_rng_state")
        except Exception:
            turbo_state = None

        super().load_state_dict(state_dict)
        self._turbo_rng = None
        self._turbo_rng_state = turbo_state

    @torch.no_grad()
    def step(self, closure: Optional[Any] = None) -> Optional[Tensor]:
        loss = None
        if closure is not None:
            with torch.enable_grad():
                loss = closure()

        self._step_count += 1
        global_step = self._step_count

        # 1) AdamW-only param groups (spectral=False) – always AdamW.
        for group in self.param_groups:
            if group.get("spectral", True):
                continue  # handled in spectral pass

            lr: float = float(group["lr"])
            betas: Tuple[float, float] = tuple(group["betas"])  # type: ignore[arg-type]
            eps: float = float(group["eps"])
            weight_decay: float = float(group["weight_decay"])

            for p in group["params"]:
                if not isinstance(p, Tensor):
                    continue
                if p.grad is None:
                    continue
                state = self.state[p]
                _adamw_update_param(p, state, lr, betas, eps, weight_decay)

        # If no spectral groups, we're done.
        has_spectral = any(group.get("spectral", True) for group in self.param_groups)
        if not has_spectral:
            return loss

        use_dist = (
            self.world_size > 1 and dist.is_available() and dist.is_initialized()
        )

        # 2) Spectral groups.
        if not self.enable_turbomuon:
            # --- Pure Muon mode for spectral groups (reference behaviour) ---
            futures: List[torch.futures.Future] = []

            for group in self.param_groups:
                if not group.get("spectral", True):
                    continue

                params: List[Tensor] = [p for p in group["params"] if isinstance(p, Tensor)]
                if not params:
                    continue

                if use_dist:
                    params_pad = params + [torch.empty_like(params[-1])] * self.world_size
                    momentum_t: Optional[Tensor] = None

                    for base_i in range(0, len(params), self.world_size):
                        idx = base_i + self.rank
                        if idx < len(params):
                            p = params[idx]
                            if p.grad is not None:
                                state = self.state[p]
                                if "mantissa" not in state:
                                    state["mantissa"] = torch.zeros_like(p, dtype=torch.uint16)
                                    state["momentum_buffer"] = torch.zeros_like(p, dtype=torch.float32)
                                if momentum_t is None:
                                    momentum_t = _as_full_prec_tensor(
                                        float(group["momentum"]), device=p.device
                                    )

                                eff_lr = float(group["lr"]) * math.sqrt(
                                    max(
                                        1.0,
                                        float(p.size(-2))
                                        / max(1.0, float(p.size(-1))),
                                    )
                                )
                                eff_lr_t = _as_full_prec_tensor(eff_lr, device=p.device)

                                eff_wd = float(group["lr"]) * float(group["weight_decay"]) * float(
                                    getattr(p, "wd_mul", 1.0)
                                )
                                eff_wd_t = _as_full_prec_tensor(eff_wd, device=p.device)

                                _muon_update_kernel(
                                    p.view(torch.uint16),
                                    state["mantissa"],
                                    state["momentum_buffer"],
                                    p.grad,
                                    momentum_t,
                                    eff_lr_t,
                                    eff_wd_t,
                                )
                            src = params_pad[idx]
                        else:
                            src = params_pad[-1]

                        out_list = params_pad[base_i : base_i + self.world_size]
                        work = dist.all_gather(out_list, src, async_op=True)
                        futures.append(work.get_future())

                    torch.futures.collect_all(futures).wait()

                else:
                    momentum_t: Optional[Tensor] = None
                    for p in params:
                        if p.grad is None:
                            continue
                        state = self.state[p]
                        if "mantissa" not in state:
                            state["mantissa"] = torch.zeros_like(p, dtype=torch.uint16)
                            state["momentum_buffer"] = torch.zeros_like(p, dtype=torch.float32)
                        if momentum_t is None:
                            momentum_t = _as_full_prec_tensor(
                                float(group["momentum"]), device=p.device
                            )

                        eff_lr = float(group["lr"]) * math.sqrt(
                            max(
                                1.0,
                                float(p.size(-2)) / max(1.0, float(p.size(-1))),
                            )
                        )
                        eff_lr_t = _as_full_prec_tensor(eff_lr, device=p.device)

                        eff_wd = float(group["lr"]) * float(group["weight_decay"]) * float(
                            getattr(p, "wd_mul", 1.0)
                        )
                        eff_wd_t = _as_full_prec_tensor(eff_wd, device=p.device)

                        _muon_update_kernel(
                            p.view(torch.uint16),
                            state["mantissa"],
                            state["momentum_buffer"],
                            p.grad,
                            momentum_t,
                            eff_lr_t,
                            eff_wd_t,
                        )

            return loss

        # --- TurboMuon mode for spectral groups ---
        for group in self.param_groups:
            if not group.get("spectral", True):
                continue

            params: List[Tensor] = [p for p in group["params"] if isinstance(p, Tensor)]
            if not params:
                continue

            lr: float = float(group["lr"])
            betas: Tuple[float, float] = tuple(group["betas"])  # type: ignore[arg-type]
            eps: float = float(group["eps"])
            weight_decay: float = float(group["weight_decay"])
            lr_spec: float = float(group.get("lr_spec", lr))

            if use_dist:
                params_pad = params + [torch.empty_like(params[-1])] * self.world_size

                for base_i in range(0, len(params), self.world_size):
                    idx = base_i + self.rank
                    if idx < len(params):
                        p = params[idx]
                        if p.grad is not None:
                            self._update_spectral_param_turbomuon(
                                p=p,
                                group_lr=lr,
                                lr_spec=lr_spec,
                                betas=betas,
                                eps=eps,
                                weight_decay=weight_decay,
                                global_step=global_step,
                            )
                        src = params_pad[idx]
                    else:
                        src = params_pad[-1]

                    out_list = params_pad[base_i : base_i + self.world_size]
                    dist.all_gather(out_list, src, async_op=False)

            else:
                for p in params:
                    if p.grad is None:
                        continue
                    self._update_spectral_param_turbomuon(
                        p=p,
                        group_lr=lr,
                        lr_spec=lr_spec,
                        betas=betas,
                        eps=eps,
                        weight_decay=weight_decay,
                        global_step=global_step,
                    )

        return loss

    @torch.no_grad()
    def _update_spectral_param_turbomuon(
        self,
        p: Tensor,
        group_lr: float,
        lr_spec: float,
        betas: Tuple[float, float],
        eps: float,
        weight_decay: float,
        global_step: int,
    ) -> None:
        state = self.state[p]
        g = p.grad
        if g is None:
            return

        # 0/1D in spectral groups → treat as AdamW for robustness.
        if p.ndim < 2:
            _adamw_update_param(p, state, group_lr, betas, eps, weight_decay)
            return

        g32 = g.detach().to(torch.float32)

        M = state.get("M")
        if M is None:
            M = torch.zeros_like(p, dtype=torch.float32)
        beta1_spec = betas[0]
        M.mul_(beta1_spec).add_(g32, alpha=1.0 - beta1_spec)
        state["M"] = M

        turbo_gen = self._get_turbo_rng(device=p.device)
        v_buf = None
        if self._turbomuon_warmstart_smax:
            v_buf = state.get("pi_v")
            if v_buf is None:
                v_shape = (*p.shape[:-2], int(p.size(-1)))
                v_buf = torch.randn(v_shape, device=p.device, dtype=torch.float32, generator=turbo_gen)
                state["pi_v"] = v_buf

        spec_dir = muon_like_spectral_update(
            M,
            lr_spec_base=lr_spec,
            backend="turbo",
            ns_iters=self.ns_iters,
            generator=turbo_gen,
            v_buf=v_buf,
        )

        if weight_decay != 0.0:
            p.mul_(1.0 - group_lr * weight_decay)

        p.add_(spec_dir.to(p.dtype))
\n\n===== switch_bank/model/components.py =====\nimport math
from collections import defaultdict
from typing import Any

import torch
from torch import Tensor, nn
import torch.nn.functional as F
from torch.nn.attention.flex_attention import BlockMask, flex_attention

from switch_bank.utils import _sanitize, _safe_softmax


def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))


@torch.no_grad()
def init_linear(w: Tensor):
    std = 0.5 * (w.size(-1) ** -0.5)
    bound = (3 ** 0.5) * std
    return w.uniform_(-bound, bound)


class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)


class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        self.qkvo_w = nn.Parameter(init_linear(torch.empty(4, hdim, dim)).bfloat16())
        self.qkvo_w.detach()[3].zero_()  # out zero init
        self.rotary = Rotary(head_dim, max_seq_len)
        self.attn_scale = 0.12

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask, lambdas: Tensor):
        B, T = x.size(0), x.size(1)
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        # Record input activations for Muon spectral gating.
        # This is a detached side-channel only; it does not affect numerics.
        self.qkvo_w._neomuon_last_activation = x.detach()
        q, k, v = F.linear(x, self.qkvo_w[:3].flatten(end_dim=1))\
                   .view(B, T, 3 * self.num_heads, self.head_dim)\
                   .chunk(3, dim=-2)
        q, k = norm(q), norm(k)
        q, k = self.rotary(q), self.rotary(k)
        v = norm(v)
        if ve is not None:
            v = lambdas[0] * v + lambdas[1] * ve.view_as(v)
        else:
            v = lambdas[0] * v
        q = _sanitize(q)
        k = _sanitize(k)
        v = _sanitize(v)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2),
                           block_mask=block_mask, scale=self.attn_scale).transpose(1, 2)
        y = _sanitize(y)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim)
        y = F.linear(y, self.qkvo_w[3])
        return _sanitize(y)


class SharedFFNBank(nn.Module):
    def __init__(self, d: int, h: int, E: int, L: int, flags_dim: int,
                 lb_coeff: float = 1e-3, ent_coeff: float = 0.0, k: int = 1,
                 use_adapters: bool = False,
                 ema_alpha_fwd: float = 0.80, ema_alpha_rev: float | None = None,
                 use_forward_ema: bool = True, use_reverse_ema: bool = False,
                 ema_block_size_fwd: int = 128, ema_block_size_rev: int = 128,
                 ema_window_size_fwd: int = -1, ema_window_size_rev: int = 128,
                 ema_layer_stride: int = 1,
                 extra_wandb_logging: bool = True,
                 adapter_layer_tie_map: list[int] | tuple[int, ...] | None = None):
        super().__init__()
        self.d, self.h, self.E, self.L = d, h, E, L
        self.flags_dim = flags_dim
        self.lb_coeff = lb_coeff
        self.ent_coeff = ent_coeff
        self.k = int(k)
        alpha_fwd_val = float(ema_alpha_fwd)
        alpha_rev_val = float(ema_alpha_rev if ema_alpha_rev is not None else ema_alpha_fwd)
        self.ema_alpha_min_fwd = alpha_fwd_val
        self.ema_alpha_max_fwd = alpha_fwd_val
        self.ema_alpha_min_rev = alpha_rev_val
        self.ema_alpha_max_rev = alpha_rev_val
        self.use_adapters = bool(use_adapters)
        self.use_forward_ema = bool(use_forward_ema)
        self.use_reverse_ema = bool(use_reverse_ema)
        self.enable_extra_wandb_logging = bool(extra_wandb_logging)
        self.ema_block_size_fwd = int(ema_block_size_fwd)
        self.ema_block_size_rev = int(ema_block_size_rev)
        self.ema_window_size_fwd = int(ema_window_size_fwd)
        self.ema_window_size_rev = int(ema_window_size_rev)
        self.ema_layer_stride = max(int(ema_layer_stride), 1)
        assert self.ema_layer_stride <= L, "ema_layer_stride must be <= number of layers"
        self._ema_cache_fwd: dict[int, Tensor] | None = None
        self._ema_cache_rev: dict[int, Tensor] | None = None
        if adapter_layer_tie_map is not None:
            if len(adapter_layer_tie_map) != L:
                raise ValueError("adapter_layer_tie_map must match number of layers")
            tie_map = [int(idx) for idx in adapter_layer_tie_map]
            for idx in tie_map:
                if idx < 0 or idx >= L:
                    raise ValueError("adapter_layer_tie_map contains out-of-range indices")
            self.adapter_layer_tie_map = tie_map
        else:
            self.adapter_layer_tie_map = None
        if self.use_adapters:
            self.adapter_scale = nn.Parameter(torch.ones(L, E, d).bfloat16())
            self.adapter_bias = nn.Parameter(torch.zeros(L, E, d).bfloat16())
            self.register_buffer("adapter_initialized", torch.zeros(L, E, dtype=torch.bool), persistent=False)
        else:
            self.adapter_scale = None
            self.adapter_bias = None
            self.adapter_initialized = None
        self.register_buffer("pruned_experts", torch.zeros(E, dtype=torch.bool), persistent=False)
        self.W1 = nn.ParameterList([nn.Parameter(init_linear(torch.empty(h, d)).bfloat16()) for _ in range(E)])
        self.W2 = nn.ParameterList([nn.Parameter(torch.zeros(d, h).bfloat16()) for _ in range(E)])
        for w in list(self.W1) + list(self.W2):
            w.wd_mul = 2.0
        feat_multiplier = 1 + int(self.use_forward_ema) + int(self.use_reverse_ema)
        in_dim = feat_multiplier * d + flags_dim
        self.router_w = nn.ParameterList([nn.Parameter(init_linear(torch.empty(E, in_dim)).bfloat16()) for _ in range(L)])
        self.router_b = nn.ParameterList([nn.Parameter(torch.zeros(E).bfloat16()) for _ in range(L)])
        if self.use_forward_ema:
            alpha_fwd = torch.full((L,), alpha_fwd_val, dtype=torch.bfloat16)
            self.register_buffer("ema_alpha", alpha_fwd)
        else:
            self.ema_alpha = None
        if self.use_reverse_ema:
            alpha_rev = torch.full((L,), alpha_rev_val, dtype=torch.bfloat16)
            self.register_buffer("ema_alpha_rev", alpha_rev)
        else:
            self.ema_alpha_rev = None
        self._router_metrics_buffer: list[dict[str, float] | None] | None = None

    def _adapter_layer_idx(self, layer_idx: int) -> int:
        if self.adapter_layer_tie_map is None:
            return layer_idx
        return int(self.adapter_layer_tie_map[layer_idx])

    @torch.no_grad()
    @torch._dynamo.disable
    def maybe_init_adapters(self, active_mask: torch.Tensor | None):
        if not (self.use_adapters and self.adapter_initialized is not None):
            return
        if active_mask is None:
            init_mask = torch.ones(self.E, dtype=torch.bool, device=self.adapter_initialized.device)
        else:
            init_mask = active_mask.to(device=self.adapter_initialized.device, dtype=torch.bool)
        if self.pruned_experts.any():
            init_mask = init_mask & (~self.pruned_experts.to(device=init_mask.device))
        if not init_mask.any():
            return
        seen_layers = set()
        for layer_idx in range(self.L):
            adapter_layer = self._adapter_layer_idx(layer_idx)
            if adapter_layer in seen_layers:
                continue
            seen_layers.add(adapter_layer)
            init_flags = self.adapter_initialized[adapter_layer]
            to_init = init_mask & (~init_flags)
            if not to_init.any():
                continue
            src_mask = init_mask & init_flags
            if src_mask.any():
                scale_mean = self.adapter_scale[adapter_layer, src_mask].mean(dim=0, keepdim=True)
                bias_mean = self.adapter_bias[adapter_layer, src_mask].mean(dim=0, keepdim=True)
            else:
                scale_mean = None
                bias_mean = None
            if scale_mean is not None:
                self.adapter_scale[adapter_layer, to_init] = scale_mean
                self.adapter_bias[adapter_layer, to_init] = bias_mean
            self.adapter_initialized[adapter_layer, to_init] = True

    @staticmethod
    def _ema_blockwise(x: Tensor, alpha: Tensor, block_size: int = 128) -> Tensor:
        B, T, D = x.shape
        assert B == 1
        a = _sanitize(alpha.float(), value=0.8).clamp(1e-4, 0.9999)
        one_minus = (1.0 - a)
        assert T % block_size == 0, "Sequence length must be a multiple of 128."
        nb = T // block_size
        x_blk = x.view(1, nb, block_size, D).float()
        ar = torch.arange(block_size, device=x.device, dtype=torch.float32)
        pow_a = a.pow(ar)
        pow_a_p1 = a.pow(ar + 1.0)
        pow_a_inv = a.pow(-ar)
        y = torch.empty_like(x_blk)
        carry = torch.zeros(1, 1, D, device=x.device, dtype=torch.float32)
        for b in range(nb):
            xb = x_blk[:, b]
            u = xb * pow_a_inv.view(1, -1, 1)
            prefix = torch.cumsum(u, dim=1)
            yb = pow_a_p1.view(1, -1, 1) * carry + (one_minus * (pow_a.view(1, -1, 1) * prefix))
            y[:, b] = yb
            carry = yb[:, -1:, :]
        out = y.view(1, T, D).to(dtype=x.dtype)
        return _sanitize(out)

    @staticmethod
    @torch._dynamo.disable
    def _ema_reverse_since_doc_start(x: Tensor, alpha: Tensor, doc_starts: torch.Tensor, window: int = 128, block_size: int = 128) -> Tensor:
        B, T, D = x.shape
        assert B == 1
        doc_starts = doc_starts.to(dtype=torch.bool, device=x.device)
        if not bool(doc_starts[0]):
            doc_starts[0] = True
        doc_bounds = torch.nonzero(doc_starts, as_tuple=True)[0]
        if doc_bounds.numel() == 0 or doc_bounds[0].item() != 0:
            doc_bounds = torch.cat([doc_bounds.new_tensor([0]), doc_bounds])
        doc_bounds = torch.cat([doc_bounds, doc_bounds.new_tensor([T])])
        out = torch.empty_like(x, dtype=torch.float32)
        a = _sanitize(alpha.float(), value=0.8).clamp(1e-4, 0.9999)
        for idx in range(doc_bounds.numel() - 1):
            start = int(doc_bounds[idx].item())
            end = int(doc_bounds[idx + 1].item())
            if end <= start:
                continue
            seg = x[:, start:end, :]
            length = end - start
            limit = min(window, length)
            if limit > 0:
                head = seg[:, :limit, :]
                rev = torch.flip(head, dims=(1,))
                pad = (-limit) % block_size
                if pad:
                    zero_pad = torch.zeros(1, pad, D, device=x.device, dtype=rev.dtype)
                    rev = torch.cat([rev, zero_pad], dim=1)
                ema = SharedFFNBank._ema_blockwise(rev, a, block_size=block_size)
                ema = ema[:, :limit]
                ema = torch.flip(ema, dims=(1,))
                out[:, start:start + limit] = ema
                if length > limit:
                    out[:, start + limit:end] = ema[:, -1:].expand(1, length - limit, D)
            else:
                out[:, start:end] = 0
        return _sanitize(out.to(dtype=x.dtype))

    def forward(self, x_norm: Tensor, layer_idx: int, flags: Tensor, temperature: float,
                logit_cap: float | None, freeze_ema_alpha: bool, use_gumbel: bool,
                lb_multiplier: float = 1.0, active_mask: Tensor | None = None,
                freeze_router_params: bool = False, freeze_adapter_params: bool = False,
                ema_limits_fwd: tuple[float, float] | None = None,
                ema_limits_rev: tuple[float, float] | None = None,
                freeze_ema_alpha_rev: bool = False) -> tuple[Tensor, Tensor]:
        assert x_norm.size(0) == 1
        deterministic_topk = False
        base_mask = torch.ones(self.E, dtype=torch.bool, device=x_norm.device)
        if active_mask is not None:
            base_mask &= active_mask.to(device=x_norm.device, dtype=torch.bool)
        if self.pruned_experts.any():
            base_mask &= (~self.pruned_experts.to(device=x_norm.device))
        if not base_mask.any():
            base_mask = torch.ones(self.E, dtype=torch.bool, device=x_norm.device)
        regular_active_count = int(base_mask.sum().item())
        if (regular_active_count == 1):
            deterministic_topk = True
            active_idx = int(base_mask.nonzero(as_tuple=True)[0].item())
        features: list[Tensor] = [x_norm]
        feat_names: list[str] = ["tok"]
        feat_sizes: list[int] = [self.d]
        alpha_use_rev = None
        alpha_use = None
        group_stride = max(self.ema_layer_stride, 1)
        base_layer = (layer_idx // group_stride) * group_stride
        if (not deterministic_topk) and self.use_forward_ema and self.ema_alpha is not None:
            min_alpha, max_alpha = (ema_limits_fwd if ema_limits_fwd is not None else (self.ema_alpha_min_fwd, self.ema_alpha_max_fwd))
            alpha_raw = self.ema_alpha[base_layer].float()
            alpha_clip = _sanitize(alpha_raw).clamp(min_alpha, max_alpha)
            alpha_use = alpha_clip.detach() if freeze_ema_alpha else alpha_clip
            cache_fwd = self._ema_cache_fwd if isinstance(self._ema_cache_fwd, dict) else None
            if cache_fwd is not None and base_layer in cache_fwd:
                ema_feat = cache_fwd[base_layer]
            else:
                if 0 < self.ema_window_size_fwd < x_norm.size(1):
                    head_len = min(self.ema_window_size_fwd, x_norm.size(1))
                    pad = (-head_len) % self.ema_block_size_fwd
                    head = x_norm[:, :head_len]
                    if pad:
                        head = torch.cat([head, torch.zeros(1, pad, self.d, device=head.device, dtype=head.dtype)], dim=1)
                    ema_head = self._ema_blockwise(head, alpha_use, block_size=self.ema_block_size_fwd)[:, :head_len]
                    ema_feat = x_norm.new_empty(x_norm.shape)
                    ema_feat[:, :head_len] = ema_head
                    ema_feat[:, head_len:] = ema_head[:, -1:].expand(1, x_norm.size(1) - head_len, self.d)
                else:
                    ema_feat = self._ema_blockwise(x_norm, alpha_use, block_size=self.ema_block_size_fwd)
                if cache_fwd is not None:
                    cache_fwd[base_layer] = ema_feat
            features.append(ema_feat)
            feat_names.append("ema_fwd")
            feat_sizes.append(self.d)
        if (not deterministic_topk) and self.use_reverse_ema and self.ema_alpha_rev is not None:
            min_alpha_rev, max_alpha_rev = (ema_limits_rev if ema_limits_rev is not None else (self.ema_alpha_min_rev, self.ema_alpha_max_rev))
            alpha_raw_rev = self.ema_alpha_rev[base_layer].float()
            alpha_clip_rev = _sanitize(alpha_raw_rev).clamp(min_alpha_rev, max_alpha_rev)
            alpha_use_rev = alpha_clip_rev.detach() if freeze_ema_alpha_rev else alpha_clip_rev
            cache_rev = self._ema_cache_rev if isinstance(self._ema_cache_rev, dict) else None
            if cache_rev is not None and base_layer in cache_rev:
                ema_rev = cache_rev[base_layer]
            else:
                doc_starts = (flags[0, :, 1].float() > 0.5)
                ema_rev = self._ema_reverse_since_doc_start(
                    x_norm, alpha_use_rev, doc_starts,
                    window=self.ema_window_size_rev, block_size=self.ema_block_size_rev,
                )
                if cache_rev is not None:
                    cache_rev[base_layer] = ema_rev
            features.append(ema_rev)
            feat_names.append("ema_rev")
            feat_sizes.append(self.d)
        feat_names.append("flags")
        feat_sizes.append(self.flags_dim)
        if deterministic_topk:
            effective_mask = base_mask
            probs = torch.zeros((1, x_norm.size(1), self.E), device=x_norm.device, dtype=x_norm.dtype)
            probs[..., active_idx] = 1.0
            topk_idx = torch.full((1, x_norm.size(1), 1), active_idx, device=x_norm.device, dtype=torch.int64)
            topk_prob = torch.ones_like(topk_idx, dtype=x_norm.dtype)
            max_logit = float("nan")
            imp = torch.zeros(self.E, device=x_norm.device, dtype=x_norm.dtype)
            imp[active_idx] = 1.0
            load = imp.clone()
            k = 1
        else:
            rin = _sanitize(torch.cat([*features, flags], dim=-1))
            logits = F.linear(rin, self.router_w[layer_idx], self.router_b[layer_idx]).float()
            if use_gumbel:
                u = torch.rand_like(logits).clamp_(1e-6, 1 - 1e-6)
                g = -torch.log(-torch.log(u))
                logits = logits + g
            logits = logits / max(temperature, 1e-6)
            if logit_cap is not None and logit_cap > 0:
                logits = logits.clamp(-logit_cap, logit_cap)
            logits = _sanitize(logits)
            if freeze_router_params:
                logits = logits.detach()
            effective_mask = None
            if base_mask is not None:
                effective_mask = base_mask.to(device=logits.device, dtype=torch.bool)
            if effective_mask is not None:
                if not effective_mask.any():
                    fallback = (~self.pruned_experts).to(device=logits.device)
                    if not fallback.any():
                        fallback = torch.ones(self.E, dtype=torch.bool, device=logits.device)
                    effective_mask = fallback
                logits = logits.masked_fill(~effective_mask.view(1, 1, -1), float("-inf"))
            probs = _safe_softmax(logits, dim=-1)
            max_logit = logits.max().item() if logits.numel() > 0 else float("nan")

            active_count = int(effective_mask.sum().item()) if effective_mask is not None else self.E
            k = max(1, min(self.k, active_count))
            topk_prob, topk_idx = probs.topk(k, dim=-1)
            if torch.isnan(topk_prob).any():
                probs = _safe_softmax(torch.zeros_like(logits), dim=-1)
                topk_prob, topk_idx = probs.topk(k, dim=-1)

            imp = _sanitize(probs.mean(dim=(0, 1)))
            top1 = topk_idx[..., 0]
            one_hot = F.one_hot(top1.view(-1), num_classes=self.E).float()
            load = _sanitize(one_hot.mean(dim=0))

        def cv2(v: Tensor):
            m = v.mean()
            return v.var(unbiased=False) / (m * m + 1e-6)

        imp_f = imp.float()
        load_f = load.float()
        single_active = (regular_active_count <= 1)

        imp_entropy = (-(imp_f + 1e-6).log().mul(imp_f)).sum()
        load_entropy = (-(load_f + 1e-6).log().mul(load_f)).sum()

        lb_term = (self.lb_coeff * lb_multiplier) * (cv2(imp_f) + cv2(load_f))
        #entropy_term = -self.ent_coeff * (load_entropy + imp_entropy)

        ############# Test
        expected_entropy = math.log(regular_active_count) if regular_active_count > 0 else float("nan")

        def _entropy_gap(val):
            if math.isnan(val) or math.isnan(expected_entropy) or expected_entropy <= 0:
                return float("nan")
            return max(0.0, abs(expected_entropy - val) / expected_entropy)

        load_entropy_gap = _entropy_gap(load_entropy)
        imp_entropy_gap = _entropy_gap(imp_entropy)
        entropy_term = self.ent_coeff * (load_entropy_gap + imp_entropy_gap)
        ############

        router_aux = lb_term + entropy_term

        if single_active:
            router_aux = router_aux.new_zeros(())

        other_aux = router_aux.new_zeros(())
        aux = router_aux + other_aux
        if freeze_router_params:
            if freeze_adapter_params:
                aux = x_norm.new_zeros(())
            else:
                aux = other_aux

        y = torch.zeros_like(x_norm)
        pruned_flags = self.pruned_experts.to(dtype=torch.bool, device=x_norm.device)
        for e in range(self.E):
            if pruned_flags[e]:
                continue
            union_mask = torch.zeros(topk_idx.size(1), dtype=torch.bool, device=x_norm.device)
            per_rank_masks = []
            for r in range(k):
                mr = (topk_idx[0, :, r] == e)
                per_rank_masks.append(mr)
                union_mask |= mr
            if not union_mask.any():
                continue
            x_e = x_norm[:, union_mask]
            if self.use_adapters:
                adapter_layer = self._adapter_layer_idx(layer_idx)
                scale = self.adapter_scale[adapter_layer, e]
                bias = self.adapter_bias[adapter_layer, e]
                if freeze_adapter_params:
                    scale = scale.detach()
                    bias = bias.detach()
                x_e = x_e * scale.to(x_e.dtype) + bias.to(x_e.dtype)
            # Record activations for Muon spectral gating.
            self.W1[e]._neomuon_last_activation = x_e.detach()
            h1 = F.linear(x_e, self.W1[e])
            h1 = F.relu(h1).square()
            self.W2[e]._neomuon_last_activation = h1.detach()
            out_e = F.linear(h1, self.W2[e])
            idx_union = union_mask.nonzero(as_tuple=True)[0]
            accum = torch.zeros_like(out_e)
            for r in range(k):
                mr = per_rank_masks[r]
                if not mr.any():
                    continue
                rel = torch.nonzero(mr[union_mask], as_tuple=True)[0]
                scales = topk_prob[0, mr, r].unsqueeze(-1)
                accum[:, rel] += scales * out_e[:, rel]
            y[:, idx_union] += accum

        stats: dict[str, Any] = dict(
            imp_cv2=float(cv2(_sanitize(imp_f)).item()),
            load_cv2=float(cv2(_sanitize(load_f)).item()),
            usage_frac=float(((load_f > 0).float().mean()).item()),
            topk_prob_mean=float(_sanitize(topk_prob).mean().item()),
            imp_entropy=float(imp_entropy.item()),
            load_entropy=float(load_entropy.item()),
        )
        if self.enable_extra_wandb_logging:
            if self.use_forward_ema and self.ema_alpha is not None and alpha_use is not None:
                stats["ema_alpha_forward"] = float(alpha_use.float().item())
            if self.use_reverse_ema and self.ema_alpha_rev is not None and alpha_use_rev is not None:
                stats["ema_alpha_reverse"] = float(alpha_use_rev.float().item())
            start_idx = 0
            for name, size in zip(feat_names, feat_sizes):
                end_idx = start_idx + size
                if end_idx > self.router_w[layer_idx].size(1):
                    break
                w_slice = self.router_w[layer_idx][:, start_idx:end_idx].float()
                stats[f"feat_w_{name}"] = float(w_slice.abs().mean().item())
                start_idx = end_idx
        stats["load_vector"] = _sanitize(load_f).detach().float().cpu()
        self._record_router_metrics(layer_idx, stats, max_logit)

        return y, aux

    @torch.no_grad()
    def compile_warm_all_experts(self, d: int, T_warm: int = 128):
        x = torch.randn(1, T_warm, d, device=self.W1[0].device, dtype=torch.bfloat16)
        for e in range(self.E):
            h1 = F.linear(x, self.W1[e]); h1 = F.relu(h1).square(); _ = F.linear(h1, self.W2[e])

    def begin_router_metrics(self):
        self._router_metrics_buffer = [None] * self.L
        self._ema_cache_fwd = {}
        self._ema_cache_rev = {}

    def _record_router_metrics(self, layer_idx: int, stats: dict[str, float], max_logit: float):
        if self._router_metrics_buffer is not None:
            stats = dict(stats)
            stats["max_logit"] = max_logit
            self._router_metrics_buffer[layer_idx] = stats

    def pop_router_metrics(self):
        metrics = self._router_metrics_buffer
        self._router_metrics_buffer = None
        return metrics or []

    @torch.no_grad()
    def prune_inactive_experts(self, activity: torch.Tensor, threshold: float) -> list[int]:
        if activity is None:
            return []
        if activity.numel() != self.E:
            return []
        device = self.pruned_experts.device
        activity = activity.to(device=device, dtype=torch.float32)
        available = (~self.pruned_experts)
        if not available.any():
            return []
        keep = (activity >= threshold) & available
        if not keep.any():
            masked_activity = activity.clone()
            masked_activity[~available] = float("-inf")
            best_idx = int(torch.argmax(masked_activity).item())
            keep[best_idx] = True
        pruned_mask = available & (~keep)
        new_pruned = pruned_mask.nonzero(as_tuple=True)[0].tolist()
        if not new_pruned:
            return []
        self.pruned_experts |= pruned_mask
        for idx in new_pruned:
            self.W1[idx].zero_()
            self.W2[idx].zero_()
        if self.use_adapters:
            mask = self.pruned_experts
            self.adapter_scale[:, mask] = 0
            self.adapter_bias[:, mask] = 0
        return new_pruned


class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int, skip_attn_layers: set[int],
                 peak_frac: float, temp_boost: float, lb_boost: float, boost_shape: str = "peak"):
        super().__init__()
        self.attn = None if layer_idx in skip_attn_layers else CausalSelfAttention(dim, num_heads, max_seq_len)
        self.layer_idx = layer_idx
        self.total_layers = None
        self.layer_peak_frac = float(peak_frac)
        self.temp_boost = float(temp_boost)
        self.lb_boost = float(lb_boost)
        self.boost_shape = (boost_shape or "peak").lower()

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask,
                lambdas: Tensor, sa_lambdas: Tensor, bank: SharedFFNBank, layer_idx: int,
                flags: Tensor, temperature: float, logit_cap: float | None,
                freeze_ema_alpha: bool, use_gumbel: bool, active_mask: Tensor | None,
                freeze_router_params: bool, freeze_adapter_params: bool,
                ema_limits_fwd: tuple[float, float] | None,
                ema_limits_rev: tuple[float, float] | None,
                freeze_ema_alpha_rev: bool, decay_scale: float) -> tuple[Tensor, Tensor]:
        if self.total_layers is None:
            self.total_layers = getattr(bank, "L", layer_idx + 1)
        layer_frac = layer_idx / max(self.total_layers - 1, 1)
        x = lambdas[0] * x + lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(x, ve, block_mask, sa_lambdas)
        peak = self.layer_peak_frac
        dist = abs(layer_frac - peak)
        denom = peak if layer_frac <= peak else max(1.0 - peak, 1e-6)
        shape_peak = max(0.0, 1.0 - dist / denom)
        if self.boost_shape == "valley":
            shape = 1.0 - shape_peak
        elif self.boost_shape == "linear_start":
            shape = max(0.0, min(1.0, 1.0 - layer_frac))
        elif self.boost_shape == "linear_end":
            shape = max(0.0, min(1.0, layer_frac))
        else:
            shape = shape_peak
        decay_scale = float(decay_scale)
        temp_multiplier = 1.0 + decay_scale * self.temp_boost * shape
        lb_multiplier = 1.0 + decay_scale * self.lb_boost * shape
        y, aux = bank(
            norm(x),
            layer_idx,
            flags,
            temperature * temp_multiplier,
            logit_cap,
            freeze_ema_alpha,
            use_gumbel,
            lb_multiplier,
            active_mask,
            freeze_router_params=freeze_router_params,
            freeze_adapter_params=freeze_adapter_params,
            ema_limits_fwd=ema_limits_fwd,
            ema_limits_rev=ema_limits_rev,
            freeze_ema_alpha_rev=freeze_ema_alpha_rev,
        )
        x = x + y
        return x, aux
\n\n===== switch_bank/model/gpt.py =====\nimport math
import os
from functools import lru_cache

import torch
from torch import Tensor, nn
import torch.nn.functional as F
from torch.nn.attention.flex_attention import BlockMask

from switch_bank.model.components import Block, SharedFFNBank, norm, init_linear
from switch_bank.utils import next_multiple_of_n


def _compute_router_temp(step: int, total_steps: int, t_init: float, t_final: float,
                         power: float, anchor_delta_steps: int, anchor_ratio: float | None,
                         start_step: int) -> float:
    if step <= start_step:
        return t_init
    effective_total = max(total_steps - start_step, 1)
    progress = (step - start_step) / effective_total
    power_use = power
    if anchor_delta_steps > 0 and anchor_ratio is not None and 0 < anchor_ratio < 1:
        anchor_progress = min(max(anchor_delta_steps / effective_total, 1e-6), 0.999999)
        power_use = math.log(anchor_ratio) / math.log(1.0 - anchor_progress)
    return t_final + (t_init - t_final) * (1.0 - progress) ** power_use


@lru_cache(None)
def _second_expert_step(expert_activation_schedule: tuple[tuple[int, int], ...]) -> int:
    if len(expert_activation_schedule) >= 2:
        return max(0, int(expert_activation_schedule[1][0]))
    if len(expert_activation_schedule) == 1:
        return max(0, int(expert_activation_schedule[0][0]))
    return 0


def _normalize_layer_tie_groups(
    tie_groups: tuple[tuple[int, ...], ...] | None,
    num_layers: int,
    skip_attn_layers: set[int],
) -> tuple[int, ...]:
    tie_map = list(range(num_layers))
    if not tie_groups:
        return tuple(tie_map)
    if not isinstance(tie_groups, (list, tuple)):
        raise ValueError("layer_tie_groups must be a sequence of layer index groups")
    tie_groups = tuple(tie_groups)
    if (
        len(tie_groups) == 1
        and isinstance(tie_groups[0], (list, tuple))
        and tie_groups[0]
        and all(isinstance(entry, (list, tuple)) for entry in tie_groups[0])
    ):
        tie_groups = tuple(tie_groups[0])
    used = set()
    for group in tie_groups:
        if not group:
            continue
        group_layers = []
        for idx in group:
            if isinstance(idx, (list, tuple)):
                raise ValueError("layer_tie_groups should be a sequence of layer indices; remove extra nesting")
            idx_i = int(idx)
            if idx_i < 0 or idx_i >= num_layers:
                raise ValueError(f"Layer tie index {idx_i} out of range for num_layers={num_layers}")
            if idx_i in used or idx_i in group_layers:
                raise ValueError(f"Layer {idx_i} appears multiple times in layer_tie_groups")
            if idx_i in skip_attn_layers:
                raise ValueError(f"Layer tie groups cannot include skip-attn layer {idx_i}")
            group_layers.append(idx_i)
        if len(group_layers) < 2:
            continue
        base = group_layers[0]
        for idx_i in group_layers:
            used.add(idx_i)
            tie_map[idx_i] = base
    return tuple(tie_map)


class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int,
                 skip_attn_layers: set[int], layer_tie_groups: tuple[tuple[int, ...], ...],
                 E: int, h: int, lb_coeff: float, ent_coeff: float, k: int,
                 num_value_embeds: int,
                 tie_lm_head: bool, untie_lm_head_after: int,
                 ema_alpha_fwd: float, ema_alpha_rev: float,
                 router_temp_init: float, router_temp_final: float, router_temp_power: float,
                 router_temp_anchor_delta_steps: int | None, router_temp_anchor_ratio: float | None,
                 router_logit_cap_initial: float, router_logit_cap_final: float, router_logit_cap_delta_steps: int,
                 router_layer_peak_frac: float, router_temp_boost: float, router_lb_boost: float, router_boost_shape: str,
                 use_router_adapters: bool, expert_activation_schedule: tuple[tuple[int, int], ...],
                 router_freeze_frac: float, router_freeze_adapters: bool,
                 ema_block_size_fwd: int, ema_block_size_rev: int,
                 ema_window_size_fwd: int, ema_window_size_rev: int,
                 ema_layer_stride: int,
                 shared_ffn_freeze_frac: float,
                 router_use_gumbel: bool, router_gumbel_schedule: tuple[tuple[int, int], ...],
                 router_block_pos_bins: int, first_doc_tokens_N: int,
                 router_enable_forward_ema: bool, router_enable_reverse_ema: bool,
                 extra_console_logging: bool, extra_wandb_logging: bool,
                 print_fn=None):
        super().__init__()
        self.vocab_size = vocab_size
        self.vocab_size_padded = next_multiple_of_n(vocab_size, n=128)
        self.embed = nn.Embedding(self.vocab_size_padded, model_dim)

        assert 0 <= num_value_embeds <= 3
        self.num_value_embeds = int(num_value_embeds)
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(self.num_value_embeds)])
        self.enable_forward_ema = bool(router_enable_forward_ema)
        self.enable_reverse_ema = bool(router_enable_reverse_ema)
        self.extra_console_logging = bool(extra_console_logging)
        self.extra_wandb_logging = bool(extra_wandb_logging)

        self.num_layers = num_layers
        self.layer_tie_map = _normalize_layer_tie_groups(layer_tie_groups, num_layers, skip_attn_layers)
        self.blocks = nn.ModuleList([
            Block(model_dim, num_heads, max_seq_len, i, skip_attn_layers,
                  router_layer_peak_frac, router_temp_boost, router_lb_boost, boost_shape=router_boost_shape)
            for i in range(num_layers)
        ])
        for idx, base in enumerate(self.layer_tie_map):
            if idx == base:
                continue
            base_attn = self.blocks[base].attn
            if base_attn is None:
                raise ValueError(f"Layer {base} has no attention but is used as a tie base")
            self.blocks[idx].attn = base_attn
        self.router_temp_boost = float(router_temp_boost)
        self.router_lb_boost = float(router_lb_boost)
        self.tie_lm_head = bool(tie_lm_head)
        self.untie_lm_head_after = int(untie_lm_head_after)
        needs_lm_head = (not self.tie_lm_head) or (self.untie_lm_head_after >= 0)
        self.lm_head = nn.Parameter(init_linear(torch.empty(self.vocab_size_padded, model_dim)).bfloat16()) if needs_lm_head else None
        self._head_tied_runtime = True
        if not self.tie_lm_head:
            self._head_tied_runtime = False

        assert 1 <= ema_layer_stride <= self.num_layers, "ema_layer_stride must be between 1 and num_layers"
        self.scalars = nn.Parameter(torch.cat([
            torch.ones(num_layers),
            *[torch.tensor([1.0, 0.0]) for _ in range(num_layers)],
            *[torch.tensor([0.5, 0.5]) for _ in range(num_layers)],
        ]))
        self.router_temp_init = float(router_temp_init)
        self.router_temp_final = float(router_temp_final)
        self.router_temp_power = float(router_temp_power)
        self.router_temp_anchor_delta_steps = (int(router_temp_anchor_delta_steps) if router_temp_anchor_delta_steps is not None else -1)
        self.router_temp_anchor_ratio = (float(router_temp_anchor_ratio) if router_temp_anchor_ratio is not None else None)
        self.router_logit_cap_delta_steps = int(router_logit_cap_delta_steps)
        self.router_logit_cap_initial = float(router_logit_cap_initial)
        self.router_logit_cap_final = float(router_logit_cap_final)
        self.router_use_gumbel = bool(router_use_gumbel)
        schedule: list[tuple[int, int]] = []
        for entry in router_gumbel_schedule:
            if len(entry) < 2:
                continue
            start, end = entry
            schedule.append((max(0, int(start)), int(end)))
        schedule.sort(key=lambda x: x[0])
        self.router_gumbel_schedule: tuple[tuple[int, int], ...] = tuple(schedule)
        self.second_expert_step_const = _second_expert_step(expert_activation_schedule)
        self.router_freeze_frac = float(router_freeze_frac)
        self.router_freeze_adapters = bool(router_freeze_adapters)
        self.shared_ffn_freeze_frac = float(shared_ffn_freeze_frac)
        self._router_frozen_logged = False
        self._ffn_frozen_logged = False

        assert router_block_pos_bins in (4, 8, 16), "router_block_pos_bins must be 4, 8, or 16"
        self.router_block_pos_bins = int(router_block_pos_bins)
        self.first_doc_tokens_N = int(first_doc_tokens_N)
        self.use_router_adapters = bool(use_router_adapters)
        self.num_experts = E
        schedule: list[tuple[int, int]] = []
        for entry in expert_activation_schedule:
            if len(entry) < 2:
                continue
            step_v, count = entry[0], entry[1]
            step_i = max(0, int(step_v))
            count_i = max(1, min(self.num_experts, int(count)))
            schedule.append((step_i, count_i))
        schedule.sort(key=lambda x: x[0])
        self.expert_activation_schedule: list[tuple[int, int]] = []
        for step_v, count in schedule:
            if self.expert_activation_schedule and step_v == self.expert_activation_schedule[-1][0]:
                self.expert_activation_schedule[-1] = (step_v, count)
            else:
                self.expert_activation_schedule.append((step_v, count))
        mask_needed = any(count < self.num_experts for _, count in self.expert_activation_schedule)
        if mask_needed:
            if not self.expert_activation_schedule:
                self.expert_activation_schedule = [(0, self.num_experts)]
            elif self.expert_activation_schedule[0][0] > 0:
                first = self.expert_activation_schedule[0][1]
                self.expert_activation_schedule.insert(0, (0, first))
            last_step, last_count = self.expert_activation_schedule[-1]
            if last_count < self.num_experts:
                self.expert_activation_schedule.append((last_step, self.num_experts))
        self._expert_schedule_requires_mask = mask_needed
        self._full_activation_step = self._compute_full_activation_step()
        self._full_activation_step = self._compute_full_activation_step()

        flags_dim = 3 + self.router_block_pos_bins

        self.bank = SharedFFNBank(
            d=model_dim, h=h, E=E, L=num_layers, flags_dim=flags_dim,
            lb_coeff=lb_coeff, ent_coeff=ent_coeff, k=k,
            use_adapters=use_router_adapters,
            ema_alpha_fwd=ema_alpha_fwd, ema_alpha_rev=ema_alpha_rev,
            use_forward_ema=self.enable_forward_ema, use_reverse_ema=self.enable_reverse_ema,
            ema_block_size_fwd=ema_block_size_fwd, ema_block_size_rev=ema_block_size_rev,
            ema_window_size_fwd=ema_window_size_fwd, ema_window_size_rev=ema_window_size_rev,
            ema_layer_stride=ema_layer_stride,
            extra_wandb_logging=self.extra_wandb_logging,
            adapter_layer_tie_map=self.layer_tie_map,
        )
        self.latest_router_metrics: list[dict[str, float] | None] | None = None
        self.latest_loss_components: tuple[Tensor, Tensor] | None = None
        self._last_active_expert_count: int | None = None
        self._current_base_active: int = self.num_experts
        self._pending_active_count: tuple[int, int] | None = None
        self._print0 = print_fn or (lambda *args, **kwargs: None)

    def _build_flags(self, input_seq: Tensor) -> Tensor:
        T = input_seq.size(0)
        device = input_seq.device
        is_eod_bool = (input_seq == 50256)
        is_eod = is_eod_bool.float().unsqueeze(0).unsqueeze(-1)
        start_flags = torch.zeros(T, dtype=torch.bool, device=device)
        start_flags[0] = True
        if T > 1:
            start_flags[1:] = is_eod_bool[:-1]
        is_after_eod = start_flags.float().unsqueeze(0).unsqueeze(-1)
        idx = torch.arange(T, device=device, dtype=torch.int64)
        start_idx = torch.where(start_flags, idx, torch.zeros_like(idx))
        last_start = torch.cummax(start_idx, dim=0)[0]
        dist_since_start = (idx - last_start).to(torch.int64)
        N = max(self.first_doc_tokens_N, 0)
        is_first_docN = (dist_since_start < N).float().unsqueeze(0).unsqueeze(-1)
        bins = self.router_block_pos_bins
        pos128 = idx % 128
        bin_idx = torch.clamp((pos128 * bins) // 128, max=bins - 1)
        onehot_bins = F.one_hot(bin_idx, num_classes=bins).float().unsqueeze(0)
        flags = torch.cat([is_eod, is_after_eod, is_first_docN, onehot_bins], dim=-1).to(dtype=torch.bfloat16)
        return flags

    def _ema_limits_for_progress(self, progress: float, reverse: bool = False) -> tuple[float, float]:
        if reverse:
            return (float(self.bank.ema_alpha_min_rev), float(self.bank.ema_alpha_max_rev))
        return (float(self.bank.ema_alpha_min_fwd), float(self.bank.ema_alpha_max_fwd))

    @torch._dynamo.disable
    def _active_expert_mask(self, step: int, device: torch.device) -> torch.Tensor | None:
        if not self._expert_schedule_requires_mask or not self.expert_activation_schedule:
            self._current_base_active = self.num_experts
            return None
        current = self.expert_activation_schedule[0]
        for stage in self.expert_activation_schedule:
            if step >= stage[0]:
                current = stage
            else:
                break
        active_count = max(1, min(self.num_experts, int(current[1])))
        self._current_base_active = active_count
        if active_count >= self.num_experts:
            self._expert_schedule_requires_mask = False
            self._mask_for_runtime = None
            return None
        mask = torch.zeros(self.num_experts, dtype=torch.bool, device=device)
        mask[:active_count] = True
        if mask.all():
            self._mask_for_runtime = None
            return None
        self._mask_for_runtime = mask
        return mask

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx

        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)

        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all

        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)

        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def compute_router_temp(self, step: int, total_steps: int) -> float:
        return _compute_router_temp(
            step, total_steps, self.router_temp_init, self.router_temp_final,
            self.router_temp_power, self.router_temp_anchor_delta_steps, self.router_temp_anchor_ratio,
            start_step=self.second_expert_step_const)

    def compute_logit_cap(self, step: int) -> float | None:
        start_step = self.second_expert_step_const
        delta = max(int(self.router_logit_cap_delta_steps), 0)
        start = self.router_logit_cap_initial
        end = self.router_logit_cap_final
        if delta <= 0:
            return end if end > 0 else None
        if step < start_step:
            return start if start > 0 else None
        frac = min(max((step - start_step) / max(delta, 1), 0.0), 1.0)
        if start <= 0 and end <= 0:
            return None
        if start <= 0:
            return end
        if end <= 0:
            return max(start * (1.0 - frac), 0.0)
        shaped = frac ** 4.0
        return start * math.exp(math.log(end / start) * shaped)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor,
                step: int, total_steps: int):
        assert input_seq.ndim == 1
        self.bank.begin_router_metrics()
        self.latest_loss_components = None
        head_should_be_tied = self._head_should_be_tied(step)
        if self.lm_head is not None and self._head_tied_runtime and not head_should_be_tied:
            self.lm_head.data.copy_(self.embed.weight.data)
        self._head_tied_runtime = head_should_be_tied

        progress = step / max(total_steps, 1)
        active_mask = self._active_expert_mask(step, input_seq.device)
        self.bank.maybe_init_adapters(active_mask)
        ema_limits_fwd = self._ema_limits_for_progress(progress, reverse=False)
        ema_limits_rev = self._ema_limits_for_progress(progress, reverse=True)
        freeze_router_params = (progress >= self.router_freeze_frac)
        freeze_adapter_params = (freeze_router_params and self.router_freeze_adapters)
        freeze_ffn = (progress >= self.shared_ffn_freeze_frac)
        base_active = getattr(self, "_current_base_active", self.num_experts if active_mask is None else int(active_mask.sum().item()))
        if self.training:
            last_logged = getattr(self, "_last_active_expert_count", None)
            if last_logged is None or base_active > last_logged:
                self._last_active_expert_count = base_active
                self._pending_active_count = (step, base_active)
        if freeze_router_params and not self._router_frozen_logged and self.extra_console_logging:
            self._print0(f"Routers frozen at step {step}", console=True)
            self._router_frozen_logged = True
        if freeze_ffn and not self._ffn_frozen_logged and self.extra_console_logging:
            self._print0(f"Shared FFN frozen at step {step}", console=True)
            self._ffn_frozen_logged = True
        T_cur = self.compute_router_temp(step, total_steps)
        logit_cap = self.compute_logit_cap(step)
        decay_scale = 1.0
        freeze_ema_alpha_fwd = True
        freeze_ema_alpha_rev = True
        use_gumbel_now = False
        if self.router_use_gumbel:
            for start, end in self.router_gumbel_schedule:
                end_eff = total_steps if end < 0 else end
                if start <= step < end_eff:
                    use_gumbel_now = True
                    break

        ve_tables = [value_embed(input_seq) for value_embed in self.value_embeds]
        L = len(self.blocks)
        if self.num_value_embeds == 3:
            ve = [ve_tables[0], ve_tables[1], ve_tables[2]] + [None] * max(L - 6, 0) + [ve_tables[0], ve_tables[1], ve_tables[2]]
        elif self.num_value_embeds == 2:
            ve = [ve_tables[0], ve_tables[1]] + [None] * max(L - 4, 0) + [ve_tables[0], ve_tables[1]]
        elif self.num_value_embeds == 1:
            ve = [ve_tables[0]] + [None] * max(L - 2, 0)
            if L >= 2:
                ve.append(ve_tables[0])
        else:
            ve = [None] * L
        if len(ve) < L:
            ve = ve + [None] * (L - len(ve))
        elif len(ve) > L:
            ve = ve[:L]

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        if L == 28:
            long_ids = {0, 4, 8, 12, 16, 20, 24}
        elif L == 32:
            long_ids = {0, 4, 8, 12, 16, 20, 24, 28}
        else:
            stride = max(L // 4, 1)
            long_ids = set(range(0, L, stride))
        block_masks = [long_bm if i in long_ids else short_bm for i in range(L)]

        x = x0 = norm(self.embed(input_seq)[None])
        flags = self._build_flags(input_seq)

        skip_connections = []
        skip_map = {9: 6, 10: 4, 11: 2}
        skip_weights = self.scalars[:L]
        lambdas = self.scalars[1 * L: 3 * L].view(-1, 2)
        sa_lambdas = self.scalars[3 * L: 5 * L].view(-1, 2)

        aux_loss = x.new_zeros(()).float()
        for i in range(L):
            if i in skip_map and skip_map[i] < len(skip_connections):
                x = x + skip_weights[skip_map[i]] * skip_connections[skip_map[i]]
            if freeze_ffn:
                with torch.no_grad():
                    y, aux = self.blocks[i](
                        x, ve[i], x0, block_masks[i], lambdas[i], sa_lambdas[i],
                        self.bank, i, flags, float(T_cur),
                        (float(logit_cap) if logit_cap is not None else None),
                        freeze_ema_alpha_fwd, use_gumbel_now, active_mask,
                        freeze_router_params=freeze_router_params,
                        freeze_adapter_params=freeze_adapter_params,
                        ema_limits_fwd=ema_limits_fwd,
                        ema_limits_rev=ema_limits_rev,
                        freeze_ema_alpha_rev=freeze_ema_alpha_rev,
                        decay_scale=decay_scale,
                    )
                y = y.detach()
                aux = aux.detach()
            else:
                y, aux = self.blocks[i](
                    x, ve[i], x0, block_masks[i], lambdas[i], sa_lambdas[i],
                    self.bank, i, flags, float(T_cur),
                    (float(logit_cap) if logit_cap is not None else None),
                    freeze_ema_alpha_fwd, use_gumbel_now, active_mask,
                    freeze_router_params=freeze_router_params,
                    freeze_adapter_params=freeze_adapter_params,
                    ema_limits_fwd=ema_limits_fwd,
                    ema_limits_rev=ema_limits_rev,
                    freeze_ema_alpha_rev=freeze_ema_alpha_rev,
                    decay_scale=decay_scale,
                )
            x = y
            aux_loss = aux_loss + aux
            skip_connections.append(x)

        x = norm(x)
        self.latest_router_metrics = self.bank.pop_router_metrics()
        if self.training:
            logits: Tensor = F.linear(x.flatten(end_dim=1), self._lm_head_weight()).float()
            loss_main = F.cross_entropy(15 * logits * torch.rsqrt(logits.square() + 225), target_seq)
            self.latest_loss_components = (loss_main.detach(), aux_loss.detach())
            return loss_main, aux_loss

        loss = 0
        for i in range(4):
            logits: Tensor = F.linear(x.flatten(end_dim=1).chunk(4)[i], self._lm_head_weight()).float()
            loss += F.cross_entropy(15 * logits * torch.rsqrt(logits.square() + 225), target_seq.chunk(4)[i]) / 4
        self.latest_loss_components = None
        return loss

    def _head_should_be_tied(self, step: int) -> bool:
        if not self.tie_lm_head:
            return False
        if self.untie_lm_head_after >= 0:
            return step < self.untie_lm_head_after
        return True

    def _lm_head_weight(self) -> Tensor:
        if self.lm_head is None or self._head_tied_runtime:
            return self.embed.weight.bfloat16()
        return self.lm_head.bfloat16()

    def _compute_full_activation_step(self) -> int:
        step_full = 0
        for step_v, count in self.expert_activation_schedule:
            if count >= self.num_experts:
                step_full = int(step_v)
                break
        return max(0, step_full)

    def _latest_activation(self, step: int) -> tuple[int, int]:
        last_step = 0
        last_count = 0
        for stage_step, count in self.expert_activation_schedule:
            if step >= stage_step:
                last_step = int(stage_step)
                last_count = int(count)
            else:
                break
        return last_step, last_count
\n\n===== switch_bank/data.py =====\nimport torch
from pathlib import Path
from torch import Tensor


def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32)
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2])
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True)
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy())
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens


def distributed_data_generator(filename_pattern: str, batch_size: int, rank: int, world_size: int, skip_batches: int = 0):
    files = sorted(Path.cwd().glob(filename_pattern))
    if not files:
        raise RuntimeError(f"No data files match pattern '{filename_pattern}' in {Path.cwd()}")
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files)
    try:
        tokens, pos = _load_data_shard(next(file_iter)), 0
    except StopIteration as exc:
        raise RuntimeError(f"No data files available for pattern '{filename_pattern}'") from exc
    # fast-forward if resuming
    while skip_batches > 0:
        if pos + batch_size + 1 >= len(tokens):
            try:
                tokens, pos = _load_data_shard(next(file_iter)), 0
            except StopIteration:
                raise RuntimeError(f"Ran out of data while skipping batches for '{filename_pattern}'")
        pos += batch_size
        skip_batches -= 1

    while True:
        if pos + batch_size + 1 >= len(tokens):
            try:
                tokens, pos = _load_data_shard(next(file_iter)), 0
            except StopIteration:
                return
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True)
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True)
        pos += batch_size
        yield inputs, targets


def summarize_router_metrics(metrics: list[dict[str, float] | None]) -> dict[str, float]:
    summary: dict[str, float] = {}
    counts: dict[str, int] = {}
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        for key, value in layer_stats.items():
            if isinstance(value, torch.Tensor):
                if value.numel() == 1:
                    value = float(value.item())
                else:
                    continue
            elif not isinstance(value, (int, float)):
                continue
            summary[key] = summary.get(key, 0.0) + float(value)
            counts[key] = counts.get(key, 0) + 1
    for key, total in list(summary.items()):
        summary[key] = total / max(counts.get(key, 1), 1)
    return summary


def summarize_expert_usage(metrics: list[dict[str, float] | None], num_experts: int) -> Tensor | None:
    accum: Tensor | None = None
    count = 0
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        load_vec = layer_stats.get("load_vector")
        if load_vec is None:
            continue
        load_vec = load_vec.to(torch.float32)
        if load_vec.numel() != num_experts:
            continue
        if accum is None:
            accum = load_vec.clone()
        else:
            accum += load_vec
        count += 1
    if accum is None or count == 0:
        return None
    return (accum / count).cpu()


def summarize_expert_activity(metrics: list[dict[str, float] | None], num_experts: int) -> Tensor | None:
    accum: Tensor | None = None
    count = 0
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        load_vec = layer_stats.get("load_vector")
        if load_vec is None:
            continue
        load_vec = load_vec.to(torch.float32)
        if load_vec.numel() != num_experts:
            continue
        active = (load_vec > 0).to(torch.float32)
        if accum is None:
            accum = active.clone()
        else:
            accum += active
        count += 1
    if accum is None or count == 0:
        return None
    return (accum / count).cpu()


def router_summary_str(summary: dict[str, float], enable_forward_ema: bool, enable_reverse_ema: bool) -> str:
    if not summary:
        return "router=NA"
    fragments = []
    extra_keys: list[str] = []
    if enable_forward_ema:
        extra_keys.append("ema_alpha_forward")
    if enable_reverse_ema:
        extra_keys.append("ema_alpha_reverse")
    keys = ("imp_cv2", "load_cv2", "usage_frac", "topk_prob_mean", *extra_keys, "max_logit")
    for key in keys:
        val = summary.get(key, float("nan"))
        fragments.append(f"{key}={val:.4f}")
    return " ".join(fragments)
\n\n===== switch_bank/trainer.py =====\nimport copy
import math
import time
import os
from functools import lru_cache
from collections import defaultdict, deque

import torch
import torch.distributed as dist
import torch.nn.functional as F
from torch import nn

from switch_bank.utils import next_multiple_of_n, rampdown_multiplier
from switch_bank.data import (
    distributed_data_generator,
    summarize_router_metrics,
    summarize_expert_usage,
    summarize_expert_activity,
    router_summary_str,
)
from switch_bank.model.gpt import _compute_router_temp, _second_expert_step
from switch_bank.model.components import CausalSelfAttention

def get_lr(args, step: int):
    freeze_last = max(int(getattr(args, "lr_freeze_last_steps", 0)), 0)
    schedule_step = min(step, max(args.num_iterations - freeze_last, 0))
    x = schedule_step / max(args.num_iterations, 1)
    x = min(max(x, 0.0), 1.0)
    if x < 1 - args.cooldown_frac:
        return 1.0
    cooldown = max(args.cooldown_frac, 1e-8)
    t = (x - (1 - cooldown)) / cooldown
    t = min(max(t, 0.0), 1.0)
    final_mult = float(getattr(args, "lr_final_mult", 0.0))
    return 1.0 - t * (1.0 - final_mult)


@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)


def get_window_size_blocks(args, step: int):
    x = step / args.num_iterations
    assert 0 <= x <= 1
    factor = 4 * x ** 3 - 6 * x ** 2 + 3 * x
    window_size = next_multiple_of_n(3456 * factor, n=128)
    return get_window_size_blocks_helper(window_size)


def get_router_temp(args, step: int):
    return _compute_router_temp(
        step, args.num_iterations, args.router_temp_init, args.router_temp_final,
        args.router_temp_power, args.router_temp_anchor_delta_steps, args.router_temp_anchor_ratio,
        start_step=_second_expert_step(tuple(args.expert_activation_schedule)))


def get_logit_cap(args, step: int):
    start_step = _second_expert_step(tuple(args.expert_activation_schedule))
    delta = max(int(args.router_logit_cap_delta_steps), 0)
    start = args.router_logit_cap_initial
    end = args.router_logit_cap_final
    if delta <= 0:
        return end if end > 0 else None
    if step < start_step:
        return start if start > 0 else None
    frac = min(max((step - start_step) / max(delta, 1), 0.0), 1.0)
    if start <= 0 and end <= 0:
        return None
    if start <= 0:
        return end
    if end <= 0:
        return max(start * (1.0 - frac), 0.0)
    shaped = frac ** 4.0
    return start * math.exp(math.log(end / start) * shaped)

def gumbel_active(args, step: int):
    if not args.router_use_gumbel:
        return False
    schedule = getattr(args, "router_gumbel_schedule", ())
    for start, end in schedule:
        end_eff = args.num_iterations if end < 0 else end
        if start <= step < end_eff:
            return True
    return False


def _update_logit_stats(logit_stats: dict[str, float], max_logit: float, logit_cap: float | None):
    if logit_cap is None or logit_cap <= 0 or math.isnan(logit_cap):
        return
    if math.isnan(max_logit) or math.isinf(max_logit):
        return
    ratio = max_logit / logit_cap if logit_cap > 0 else float("nan")
    if math.isnan(ratio) or math.isinf(ratio):
        return
    ratio = min(max(ratio, 0.0), 1.5)
    logit_stats["count"] += 1.0
    logit_stats["sum_ratio"] += ratio
    if ratio >= 0.98:
        logit_stats["cap_hits"] += 1.0
    if ratio > logit_stats["max_ratio"]:
        logit_stats["max_ratio"] = ratio


def _finalize_logit_stats(logit_stats: dict[str, float]) -> dict[str, float]:
    count = int(logit_stats.get("count", 0.0))
    if count <= 0:
        return {
            "logit_cap_steps": 0.0,
            "logit_cap_hit_rate": float("nan"),
            "logit_cap_ratio_mean": float("nan"),
            "logit_cap_ratio_max": float("nan"),
            "logit_headroom_mean": float("nan"),
            "logit_score": float("nan"),
        }
    mean_ratio = logit_stats.get("sum_ratio", 0.0) / max(count, 1)
    cap_hit_rate = logit_stats.get("cap_hits", 0.0) / max(count, 1)
    ratio_target = 0.85
    ratio_score = 1.0 - abs(mean_ratio - ratio_target) / max(ratio_target, 1e-8)
    ratio_score = min(max(ratio_score, 0.0), 1.0)
    logit_score = 0.7 * (1.0 - cap_hit_rate) + 0.3 * ratio_score
    logit_score = min(max(logit_score, 0.0), 1.0)
    return {
        "logit_cap_steps": float(count),
        "logit_cap_hit_rate": float(cap_hit_rate),
        "logit_cap_ratio_mean": float(mean_ratio),
        "logit_cap_ratio_max": float(logit_stats.get("max_ratio", 0.0)),
        "logit_headroom_mean": float(1.0 - mean_ratio),
        "logit_score": float(logit_score),
    }


def run_training(
    args,
    model: nn.Module,
    optimizers: list[torch.optim.Optimizer],
    opt2params: dict,
    train_micro_len: int,
    untie_lm_head_after: int,
    run_id_full: str | None,
    master_process: bool,
    print0,
    code: str,
    wandb_run,
    metrics_csv_writer,
    expert_usage_headers: list[str],
    expert_active_headers: list[str],
    world_size: int,
    rank: int,
    log_param_counts_fn=None,
    start_step: int = 0,
    checkpoint_save_step: int = -1,
    early_stop_step: int | None = None,
    early_stop_val_multiplier: int = 1,
    early_stop_as_final: bool = False,
):
    training_time_ms = 0
    log_dir = getattr(args, "log_dir", "logs")
    approx_step_time_ms_resume = getattr(args, "approx_step_time_ms", None)
    train_loader = distributed_data_generator(
        args.train_files,
        world_size * train_micro_len,
        rank,
        world_size,
        skip_batches=start_step * args.grad_accum_steps,
    )
    print0("Starting training.", console=True)
    dist.barrier()
    t0 = time.perf_counter()
    train_steps = args.num_iterations
    stop_step = train_steps if early_stop_step is None else min(train_steps, early_stop_step)
    last_val_loss: float | None = None
    gumbel_prev_state = gumbel_active(args, start_step - 1) if start_step > 0 else gumbel_active(args, 0)
    logit_cap_decay_logged = False
    lm_head_untie_step = untie_lm_head_after
    lm_head_untied_logged = lm_head_untie_step < 0
    turbo_muon_warmstart_prev: bool | None = None
    turbo_muon_warmstart_start_step: int | None = None
    warmstart_start_frac = float(getattr(args, "turbo_muon_warmstart_smax_start_frac", -1.0))
    if warmstart_start_frac >= 0:
        turbo_muon_warmstart_start_step = int(warmstart_start_frac * train_steps)
        turbo_muon_warmstart_start_step = min(max(turbo_muon_warmstart_start_step, 0), train_steps)

    logit_stats = {"count": 0.0, "sum_ratio": 0.0, "cap_hits": 0.0, "max_ratio": 0.0}

    def run_validation(val_steps_multiplier: float, log_val_loss: bool, extra_log: dict | None = None, log_to_wandb: bool = True):
        nonlocal training_time_ms, t0, last_val_loss
        dist.barrier()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        print0("Running validation...")
        model.eval()
        prev_k = model.bank.k
        model.bank.k = int(args.topk if args.topk_val is None else max(1, min(args.topk_val, args.num_experts)))
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        base_steps = args.val_tokens // val_batch_size
        val_steps = int(round(base_steps * float(val_steps_multiplier)))
        val_steps = max(val_steps, 1)
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, window_blocks, step, args.num_iterations)
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_scalar = float(val_loss.detach().item())
        last_val_loss = val_scalar
        print0(
            f"step:{step}/{train_steps} val_loss:{val_scalar:.6f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms / max(step, 1):.2f}ms",
            console=True)
        if wandb_run is not None and log_to_wandb:
            log_payload = {
                "val/step": step,
                "perf/approx_step_time_ms": training_time_ms,
            }
            if log_val_loss:
                log_payload["val/loss"] = val_scalar
            if extra_log:
                log_payload.update(extra_log)
            wandb_run.log(log_payload, step=step)
        model.train()
        model.bank.k = prev_k
        dist.barrier()
        t0 = time.perf_counter()
        return val_scalar

    if start_step == 0 and (early_stop_step is None or early_stop_step > 0):
        step = 0
        window_blocks = get_window_size_blocks(args, step)
        tokens_target = getattr(args, "val_tokens_intermediate", None)
        if tokens_target is None:
            tokens_target = args.val_tokens
        val_steps_multiplier = float(tokens_target) / float(args.val_tokens)
        run_validation(val_steps_multiplier, log_val_loss=True)

    router_clip_base = getattr(args, "router_grad_clip_norm", None)
    router_clip_base = float(router_clip_base) if router_clip_base is not None else None
    if router_clip_base is not None and router_clip_base <= 0:
        router_clip_base = None
    router_params_by_opt: dict[torch.optim.Optimizer, list[nn.Parameter]] = {}
    router_autoclip = bool(getattr(args, "router_autoclip", False))
    autoclip_window = 250
    router_autoclip_state: dict[torch.optim.Optimizer, dict[str, object]] = {}
    needs_router_clip = router_autoclip or (router_clip_base is not None)
    if needs_router_clip:
        for opt in optimizers:
            params = []
            for group in opt.param_groups:
                if group.get("component") == "router":
                    params.extend(group["params"])
            if params:
                router_params_by_opt[opt] = params
                if router_autoclip:
                    initial_clip = router_clip_base if router_clip_base is not None else None
                    router_autoclip_state[opt] = {
                        "history": deque(maxlen=autoclip_window),
                        "clip": (initial_clip if (initial_clip is not None and initial_clip > 0) else None),
                    }

    for step in range(start_step, train_steps + 1):
        final_step = (step == train_steps)
        last_step = (step == stop_step)
        finalize_now = final_step or (early_stop_as_final and last_step)
        turbo_muon_warmstart_now = (
            turbo_muon_warmstart_start_step is not None and step >= turbo_muon_warmstart_start_step
        )
        if turbo_muon_warmstart_prev is None or turbo_muon_warmstart_now != turbo_muon_warmstart_prev:
            for opt in optimizers:
                if hasattr(opt, "set_turbomuon_warmstart_smax"):
                    opt.set_turbomuon_warmstart_smax(turbo_muon_warmstart_now)
            turbo_muon_warmstart_prev = turbo_muon_warmstart_now
        window_blocks = get_window_size_blocks(args, step)
        progress = step / max(train_steps, 1)
        gumbel_now = gumbel_active(args, step)
        if args.enable_extra_logging and gumbel_now != gumbel_prev_state:
            status = "enabled" if gumbel_now else "disabled"
            print0(f"Gumbel router noise {status} at step {step}", console=True)
        gumbel_prev_state = gumbel_now
        current_logit_cap = get_logit_cap(args, step)
        cap_start_step = _second_expert_step(tuple(args.expert_activation_schedule))
        if not logit_cap_decay_logged and step >= cap_start_step:
            cap_str = f"{current_logit_cap:.4f}" if current_logit_cap is not None else "disabled"
            if args.enable_extra_logging:
                print0(f"Router logit cap entered ramp at step {step}: cap={cap_str}", console=True)
            logit_cap_decay_logged = True
        if (not lm_head_untied_logged) and lm_head_untie_step >= 0 and step >= lm_head_untie_step:
            if args.enable_extra_logging:
                print0(f"LM head untied at step {step}", console=True)
            if log_param_counts_fn:
                log_param_counts_fn(model)
            lm_head_untied_logged = True

        if last_step or (step > 0 and args.val_loss_every > 0 and step % args.val_loss_every == 0):
            extra_log = None
            if last_step:
                extra_log = _finalize_logit_stats(logit_stats)
            tokens_target = getattr(args, "val_tokens", None)
            if finalize_now:
                final_tokens = getattr(args, "val_tokens_final", None)
                if final_tokens is not None:
                    tokens_target = final_tokens
            else:
                intermediate_tokens = getattr(args, "val_tokens_intermediate", None)
                if intermediate_tokens is not None:
                    tokens_target = intermediate_tokens
            val_steps_multiplier = float(tokens_target) / float(args.val_tokens)
            run_validation(val_steps_multiplier, log_val_loss=True, extra_log=extra_log)
            if last_step and not finalize_now:
                result = {"val_loss": last_val_loss, "stop_step": step, "aborted": False}
                result.update(_finalize_logit_stats(logit_stats))
                return result

        if last_step and finalize_now:
            should_save = getattr(args, "save_final_checkpoint", getattr(args, "save_checkpoint", False))
            if should_save and getattr(args, "save_final_checkpoint_if_loss_below", False):
                max_loss = float(getattr(args, "save_final_checkpoint_max_loss", float("inf")))
                should_save = last_val_loss is not None and math.isfinite(last_val_loss) and last_val_loss < max_loss
            if master_process and should_save:
                model_to_save = getattr(model, "_orig_mod", model)
                log = dict(step=step, code=code, model=model_to_save.state_dict())
                run_dir = os.path.join(log_dir, run_id_full)
                os.makedirs(run_dir, exist_ok=True)
                torch.save(log, os.path.join(run_dir, f"final_model_step{step:06d}.pt"))
            break

        model.zero_grad(set_to_none=True)
        micro_losses: list[float] = []
        micro_main_losses: list[float] = []
        micro_aux_losses: list[float] = []
        router_metric_accum: list[dict[str, float]] = []
        router_layer_metric_sums = [defaultdict(float) for _ in range(model.num_layers)]
        router_layer_metric_counts = [defaultdict(int) for _ in range(model.num_layers)]
        expert_usage_accum: list[torch.Tensor] = []
        expert_active_accum: list[torch.Tensor] = []
        for micro in range(args.grad_accum_steps):
            inputs, targets = next(train_loader)
            outputs = model(inputs, targets, window_blocks, step, args.num_iterations)
            if isinstance(outputs, tuple):
                loss_main, loss_aux = outputs
                loss_main_v = float(loss_main.detach().item())
                loss_aux_v = float(loss_aux.detach().item())
                loss_val = loss_main_v + loss_aux_v
                micro_losses.append(loss_val)
                micro_main_losses.append(loss_main_v)
                micro_aux_losses.append(loss_aux_v)
                loss_total = (loss_main + loss_aux) / args.grad_accum_steps
                loss_total.backward()
                components = (loss_main.detach(), loss_aux.detach())
                main_loss = loss_main_v
                aux_loss = loss_aux_v
            else:
                loss = outputs
                loss_val = float(loss.detach().item())
                micro_losses.append(loss_val)
                (loss / args.grad_accum_steps).backward()
                components = model.latest_loss_components
                main_loss = float(components[0].item()) if components else float("nan")
                aux_loss = float(components[1].item()) if components else float("nan")
                if not math.isnan(main_loss):
                    micro_main_losses.append(main_loss)
                if not math.isnan(aux_loss):
                    micro_aux_losses.append(aux_loss)
            router_summary = summarize_router_metrics(model.latest_router_metrics or [])
            if router_summary:
                router_metric_accum.append(router_summary)
            layer_metrics = model.latest_router_metrics or []
            for layer_idx, stats in enumerate(layer_metrics):
                if not stats:
                    continue
                layer_sum = router_layer_metric_sums[layer_idx]
                layer_count = router_layer_metric_counts[layer_idx]
                for key, value in stats.items():
                    scalar_val = None
                    if isinstance(value, torch.Tensor):
                        if value.numel() == 1:
                            scalar_val = float(value.item())
                        else:
                            continue
                    elif isinstance(value, (int, float)):
                        scalar_val = float(value)
                    else:
                        continue
                    layer_sum[key] += scalar_val
                    layer_count[key] += 1
            usage = summarize_expert_usage(layer_metrics, args.num_experts)
            if usage is not None:
                expert_usage_accum.append(usage)
            active = summarize_expert_activity(layer_metrics, args.num_experts)
            if active is not None:
                expert_active_accum.append(active)
            if args.enable_extra_logging:
                print0(
                    f"[train step {step} micro {micro + 1}/{args.grad_accum_steps}] "
                    f"loss={loss_val:.6f} main={main_loss:.6f} aux={aux_loss:.6f} "
                    f"{router_summary_str(router_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
                    console=True)

        avg_loss = sum(micro_losses) / max(len(micro_losses), 1)
        avg_main_loss = sum(micro_main_losses) / max(len(micro_main_losses), 1) if micro_main_losses else float("nan")
        avg_aux_loss = sum(micro_aux_losses) / max(len(micro_aux_losses), 1) if micro_aux_losses else float("nan")
        router_step_summary = summarize_router_metrics(router_metric_accum)
        router_layer_avg: dict[int, dict[str, float]] = {}
        for layer_idx in range(model.num_layers):
            sums = router_layer_metric_sums[layer_idx]
            if not sums:
                continue
            counts = router_layer_metric_counts[layer_idx]
            router_layer_avg[layer_idx] = {key: sums[key] / max(counts[key], 1) for key in sums}
        expert_usage = torch.stack(expert_usage_accum).mean(0) if expert_usage_accum else None
        expert_active = torch.stack(expert_active_accum).mean(0) if expert_active_accum else None
        pending_event = getattr(model, "_pending_active_count", None)
        if pending_event is not None:
            event_step, active_count = pending_event
            if wandb_run is not None:
                wandb_run.log({"router/active_experts": active_count}, step=event_step)
                wandb_run.log({"router/active_total_ffn_dim": active_count * args.ffn_hidden}, step=event_step)
            model._pending_active_count = None

        abort_flag = False
        abort_reason = ""
        if math.isnan(avg_loss) or math.isinf(avg_loss):
            abort_flag = True
            abort_reason = "non-finite avg_loss"
        elif not math.isnan(avg_main_loss) and not math.isinf(avg_main_loss) and math.isnan(avg_main_loss):
            abort_flag = True
            abort_reason = "non-finite main loss"
        else:
            max_logit_val = router_step_summary.get("max_logit", float("nan")) if router_step_summary else float("nan")
            if (not math.isnan(max_logit_val)) and (max_logit_val == 0.0 or math.isinf(max_logit_val)):
                abort_flag = True
                abort_reason = f"router max_logit suspicious ({max_logit_val})"

        abort_tensor = torch.tensor(1 if abort_flag else 0, device="cuda", dtype=torch.int32)
        dist.all_reduce(abort_tensor, op=dist.ReduceOp.SUM)
        if abort_tensor.item() > 0:
            if abort_reason and master_process:
                print0(f"Aborting training at step {step} due to: {abort_reason}", console=True)
            result = {"val_loss": last_val_loss, "stop_step": step, "aborted": True, "abort_reason": abort_reason}
            result.update(_finalize_logit_stats(logit_stats))
            return result

        opt2futures = {
            opt: [dist.all_reduce(p.grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
                  for p in params if (p.grad is not None)]
            for opt, params in opt2params.items()
        }

        progress = step / max(args.num_iterations, 1)
        router_lr_mult = rampdown_multiplier(progress, args.router_lr_reduce_start_frac, model.router_freeze_frac)
        adapter_lr_mult = router_lr_mult if args.router_freeze_adapters else 1.0
        ffn_lr_mult = rampdown_multiplier(progress, args.shared_ffn_lr_reduce_start_frac, model.shared_ffn_freeze_frac)
        for opt in optimizers:
            for group in opt.param_groups:
                base_lr = group["initial_lr"] * get_lr(args, step)
                component = group.get("component")
                mult = 1.0
                if component == "router":
                    mult = router_lr_mult
                elif component == "adapter":
                    mult = adapter_lr_mult
                elif component == "shared_ffn":
                    mult = ffn_lr_mult
                group["lr"] = base_lr * mult
        # Muon-style momentum warmup for spectral groups.
        target_muon_momentum = float(getattr(args, "muon_momentum", getattr(args, "neomuon_muon_momentum", 0.95)))
        frac = min(step / 300, 1)
        warm_momentum = (1 - frac) * 0.85 + frac * target_muon_momentum
        for opt in optimizers:
            for group in opt.param_groups:
                if group.get("spectral", True):
                    group["momentum"] = warm_momentum
        for opt in optimizers:
            torch.futures.collect_all(opt2futures[opt]).wait()
            if opt in router_params_by_opt:
                state = router_autoclip_state.get(opt)
                clip_value = router_clip_base
                if state is not None and state.get("clip") is not None:
                    clip_value = float(state["clip"])
                max_norm = clip_value if (clip_value is not None and clip_value > 0) else float("inf")
                total_norm = float(torch.nn.utils.clip_grad_norm_(router_params_by_opt[opt], max_norm))
                if state is not None:
                    history: deque = state["history"]  # type: ignore[assignment]
                    history.append(total_norm)
                    if len(history) >= autoclip_window:
                        hist_tensor = torch.tensor(list(history), device="cpu")
                        new_clip = float(torch.quantile(hist_tensor, 0.10).item())
                        new_clip = max(new_clip, 1e-6)
                        if state.get("clip") is None or not math.isclose(state["clip"], new_clip):
                            state["clip"] = new_clip
                            if args.enable_extra_logging:
                                print0(
                                    f"[router grad clip auto] norm={total_norm:.4f} clip-> {new_clip:.4f}",
                                    console=True,
                                )
                elif clip_value is not None and clip_value > 0 and args.enable_extra_logging and total_norm > clip_value:
                    print0(
                        f"[router grad clip] norm={total_norm:.4f} clip={clip_value:.4f}",
                        console=True,
                    )
            # Feed last activations to Muon for spectral gating.
            if hasattr(opt, "set_last_activation") and bool(getattr(opt, "enable_spectral_gating", False)):
                for group in opt.param_groups:
                    if not group.get("spectral", True):
                        continue
                    for p in group.get("params", []):
                        act = getattr(p, "_neomuon_last_activation", None)
                        if act is not None:
                            opt.set_last_activation(p, act)
            opt.step()
        model.zero_grad(set_to_none=True)
        if args.enable_extra_logging and router_layer_avg:
            metric_keys = ["imp_cv2", "load_cv2", "usage_frac", "topk_prob_mean"]
            if args.router_enable_forward_ema:
                metric_keys.append("ema_alpha_forward")
            if args.router_enable_reverse_ema:
                metric_keys.append("ema_alpha_reverse")
            layer_fragments = []
            for layer_idx in sorted(router_layer_avg):
                stats = router_layer_avg[layer_idx]
                metrics = ", ".join(f"{key}={stats.get(key, float('nan')):.4f}" for key in metric_keys if key in stats)
                layer_fragments.append(f"L{layer_idx}: {metrics}")
            print0("[router layers] " + " | ".join(layer_fragments), console=True)
        print0(
            f"[train step {step}] avg_loss={avg_loss:.6f} main={avg_main_loss:.6f} aux={avg_aux_loss:.6f} "
            f"{router_summary_str(router_step_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
            console=True)
        approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
        if approx_step_time_ms_resume is not None:
            approx_training_time_ms = approx_step_time_ms_resume
            # reset base timer so subsequent steps are correct
            training_time_ms = approx_step_time_ms_resume
            t0 = time.perf_counter()
            approx_step_time_ms_resume = None
        print0(
            f"step:{step + 1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms / (step + 1):.2f}ms",
            console=True)
        current_logit_cap = get_logit_cap(args, step)
        current_router_temp = get_router_temp(args, step)
        max_logit_val = router_step_summary.get("max_logit", float("nan")) if router_step_summary else float("nan")
        _update_logit_stats(logit_stats, max_logit_val, current_logit_cap)
        active_count_val = None
        if expert_active is not None:
            active_count_val = float(expert_active.mean().item() * args.num_experts)
        if active_count_val is None or active_count_val <= 0:
            active_count_val = float(args.num_experts)
        active_count_val = max(active_count_val, 1.0)
        if wandb_run is not None and (step % max(args.wandb_log_every, 1) == 0):
            if args.enable_extra_wandb_logging:
                # Preserve historical lr keys by mapping to first non-spectral/spectral groups.
                adamw_lr = next(
                    (g["lr"] for g in optimizers[0].param_groups if not g.get("spectral", True)),
                    float("nan"),
                )
                muon_lr = next(
                    (g["lr"] for g in optimizers[0].param_groups if g.get("spectral", True)),
                    float("nan"),
                )
                log_data = {
                    "train/loss": avg_loss,
                    "train/loss_main": avg_main_loss,
                    "train/loss_aux": avg_aux_loss,
                    "perf/approx_step_time_ms": approx_training_time_ms,
                    "train/tokens_seen": float((step + 1) * args.train_seq_len * world_size),
                    "lr/adamw": adamw_lr,
                    "lr/muon": muon_lr,
                    "train/step": step,
                    "router/logit_cap": (current_logit_cap if current_logit_cap is not None else float("nan")),
                    "router/logit_cap_enabled": float(current_logit_cap is not None),
                    "router/temperature": current_router_temp,
                    "router/max_logit": router_step_summary.get("max_logit", float("nan")),
                }
                # feature weight percentages
                feat_keys_all = [k for k in router_step_summary.keys() if k.startswith("feat_w_")]
                feat_keys = [k for k in feat_keys_all if k in ("feat_w_tok", "feat_w_ema_fwd", "feat_w_ema_rev", "feat_w_flags")]
                if not feat_keys:
                    feat_keys = feat_keys_all
                feat_total = sum(router_step_summary[k] for k in feat_keys) if feat_keys else 0.0
                if feat_total and feat_total != 0:
                    for k in feat_keys:
                        pct = 100.0 * router_step_summary[k] / feat_total
                        log_data[f"router/feat_pct/{k.replace('feat_w_', '')}"] = pct
                # normalized CV metrics
                imp_cv2 = router_step_summary.get("imp_cv2", float("nan"))
                load_cv2 = router_step_summary.get("load_cv2", float("nan"))
                log_data["router/imp_cv2_norm"] = imp_cv2 / active_count_val if not math.isnan(imp_cv2) else float("nan")
                log_data["router/load_cv2_norm"] = load_cv2 / active_count_val if not math.isnan(load_cv2) else float("nan")
                # entropy gaps
                expected_entropy = math.log(active_count_val) if active_count_val > 0 else float("nan")
                load_entropy = router_step_summary.get("load_entropy", float("nan"))
                imp_entropy = router_step_summary.get("imp_entropy", float("nan"))
                def _entropy_gap(val):
                    if math.isnan(val) or math.isnan(expected_entropy) or expected_entropy <= 0:
                        return float("nan")
                    return max(0.0, abs(expected_entropy - val) / expected_entropy)
                load_entropy_gap = _entropy_gap(load_entropy)
                imp_entropy_gap = _entropy_gap(imp_entropy)
                log_data["router/load_entropy_gap"] = load_entropy_gap
                log_data["router/imp_entropy_gap"] = imp_entropy_gap
                # usage gap and health score
                usage_frac = router_step_summary.get("usage_frac", float("nan"))
                target_usage = min(1.0, active_count_val / max(args.num_experts, 1))
                usage_gap = abs(usage_frac - target_usage) if not math.isnan(usage_frac) else float("nan")
                weights = {
                    "imp_cv2_norm": 0.8,
                    "load_cv2_norm": 0.9,
                    "load_entropy_gap": 0.5,
                    "imp_entropy_gap": 0.2,
                    "usage_gap": 1.25,
                }
                components_weighted = []
                components_weighted.append(weights["imp_cv2_norm"] * log_data["router/imp_cv2_norm"] if not math.isnan(log_data["router/imp_cv2_norm"]) else float("nan"))
                components_weighted.append(weights["load_cv2_norm"] * log_data["router/load_cv2_norm"] if not math.isnan(log_data["router/load_cv2_norm"]) else float("nan"))
                components_weighted.append(weights["load_entropy_gap"] * load_entropy_gap if not math.isnan(load_entropy_gap) else float("nan"))
                components_weighted.append(weights["imp_entropy_gap"] * imp_entropy_gap if not math.isnan(imp_entropy_gap) else float("nan"))
                components_weighted.append(weights["usage_gap"] * usage_gap if not math.isnan(usage_gap) else float("nan"))
                health_terms = [v for v in components_weighted if not math.isnan(v)]
                if health_terms:
                    health_penalty = sum(health_terms)
                    log_data["router/health_score"] = 1.0 / (1.0 + health_penalty)
                    health_penalty = health_penalty
                    log_data["router/health_penalty"] = health_penalty
                # raw router stats (skip feat_w_*; percents already logged)
                for key, value in router_step_summary.items():
                    if key.startswith("feat_w_"):
                        continue
                    log_data[f"router/{key}"] = value
                for layer_idx, stats in router_layer_avg.items():
                    for key, value in stats.items():
                        log_data[f"router_layer/{layer_idx}/{key}"] = value
                if expert_usage is not None:
                    expert_list = expert_usage.tolist()
                    log_data["router_expert/min_usage"] = float(min(expert_list))
                    log_data["router_expert/max_usage"] = float(max(expert_list))
                    log_data["router_expert/mean_usage"] = float(sum(expert_list) / len(expert_list))
                    for idx, value in enumerate(expert_list):
                        log_data[f"router_expert/e{idx}"] = float(value)
                if expert_active is not None:
                    base_model = getattr(model, "_orig_mod", model)
                    scheduled_active = getattr(base_model, "_current_base_active", None)
                    active_count = args.num_experts
                    if isinstance(scheduled_active, int):
                        active_count = max(1, min(args.num_experts, scheduled_active))
                    inferred_active = expert_active.sum().item()
                    if inferred_active > 0:
                        active_count = max(1, min(active_count, int(round(inferred_active))))
                    source = expert_usage if expert_usage is not None else expert_active
                    active_list = source.tolist()
                    active_slice = active_list[:active_count] if active_list else []
                    if not active_slice:
                        active_slice = [0.0]
                    denom = sum(active_slice)
                    if denom > 0:
                        active_slice = [v / denom for v in active_slice]
                    log_data["router_expert_active/min"] = float(min(active_slice))
                    log_data["router_expert_active/max"] = float(max(active_slice))
                    log_data["router_expert_active/mean"] = float(sum(active_slice) / len(active_slice))
                    per_expert = []
                    for idx in range(args.num_experts):
                        if idx < active_count and idx < len(active_slice):
                            per_expert.append(float(active_slice[idx]))
                        else:
                            per_expert.append(0.0)
                    for idx, value in enumerate(per_expert):
                        log_data[f"router_expert_active/e{idx}"] = value
                wandb_run.log(log_data, step=step)
            else:
                wandb_run.log(
                    {
                        "train/loss": avg_loss,
                        "train/loss_main": avg_main_loss,
                        "train/loss_aux": avg_aux_loss,
                        "perf/approx_step_time_ms": approx_training_time_ms,
                        "train/tokens_seen": float((step + 1) * args.train_seq_len * world_size),
                        "train/step": step,
                        "router/logit_cap": (current_logit_cap if current_logit_cap is not None else float("nan")),
                        "router/temperature": current_router_temp,
                    },
                    step=step,
                )
        if master_process and metrics_csv_writer and (step % max(args.metrics_log_every, 1) == 0):
            expert_usage_list = []
            if expert_usage is not None:
                expert_usage_list = [float(x) for x in expert_usage.tolist()]
            else:
                expert_usage_list = [float("nan")] * len(expert_usage_headers)
            expert_active_list = []
            if expert_active is not None:
                expert_active_list = [float(x) for x in expert_active.tolist()]
            else:
                expert_active_list = [float("nan")] * len(expert_active_headers)
            router_ema_vals: list[float] = []
            if args.router_enable_forward_ema:
                router_ema_vals.append(router_step_summary.get("ema_alpha_forward", float("nan")))
            if args.router_enable_reverse_ema:
                router_ema_vals.append(router_step_summary.get("ema_alpha_reverse", float("nan")))
            row = [
                step,
                avg_loss,
                avg_main_loss,
                avg_aux_loss,
                router_step_summary.get("imp_cv2", float("nan")),
                router_step_summary.get("load_cv2", float("nan")),
                router_step_summary.get("usage_frac", float("nan")),
                router_step_summary.get("topk_prob_mean", float("nan")),
                *router_ema_vals,
                router_step_summary.get("max_logit", float("nan")),
                (current_logit_cap if current_logit_cap is not None else float("nan")),
                current_router_temp,
                int(window_blocks.item()),
                *expert_usage_list,
                *expert_active_list,
            ]
            metrics_csv_writer.writerow(row)
        if master_process and checkpoint_save_step >= 0 and step == checkpoint_save_step:
            run_dir = os.path.join(log_dir, run_id_full)
            os.makedirs(run_dir, exist_ok=True)
            model_to_save = getattr(model, "_orig_mod", model)
            checkpoint_payload = dict(
                step=step,
                code=code,
                model=model_to_save.state_dict(),
                optimizers=[opt.state_dict() for opt in optimizers],
                approx_step_time_ms=approx_training_time_ms,
                meta=dict(
                    model_dim=getattr(args, "model_dim", None),
                    num_layers=getattr(args, "num_layers", None),
                    num_heads=getattr(args, "num_heads", None),
                    num_experts=getattr(args, "num_experts", None),
                    ffn_hidden=getattr(args, "ffn_hidden", None),
                    vocab_size=getattr(args, "vocab_size", None),
                ),
            )
            torch.save(checkpoint_payload, os.path.join(run_dir, f"state_step{step:06d}.pt"))

    result = {"val_loss": last_val_loss, "stop_step": stop_step, "aborted": False}
    result.update(_finalize_logit_stats(logit_stats))
    return result

====================================================================================================
Running Python 3.10.12 (main, Nov  4 2025, 08:48:33) [GCC 11.4.0]
Running PyTorch 2.10.0.dev20251210+cu126 compiled for CUDA 12.6
Sat Dec 27 21:50:32 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          Off |   00000000:19:00.0 Off |                    0 |
| N/A   31C    P0            118W /  700W |    5858MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          Off |   00000000:3B:00.0 Off |                    0 |
| N/A   27C    P0            118W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          Off |   00000000:4C:00.0 Off |                    0 |
| N/A   24C    P0            117W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          Off |   00000000:5D:00.0 Off |                    0 |
| N/A   29C    P0            118W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          Off |   00000000:9B:00.0 Off |                    0 |
| N/A   29C    P0            120W /  700W |    2766MiB /  81559MiB |     12%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          Off |   00000000:BB:00.0 Off |                    0 |
| N/A   26C    P0            122W /  700W |    2766MiB /  81559MiB |     63%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          Off |   00000000:CB:00.0 Off |                    0 |
| N/A   58C    P0            145W /  700W |    2766MiB /  81559MiB |     52%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          Off |   00000000:DB:00.0 Off |                    0 |
| N/A   24C    P0            118W /  700W |    2766MiB /  81559MiB |     14%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    155062      C   /usr/bin/python3                             1510MiB |
|    0   N/A  N/A    155063      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    155064      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    155065      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    155066      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    155067      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    155068      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    155069      C   /usr/bin/python3                              614MiB |
|    1   N/A  N/A    155063      C   /usr/bin/python3                             1510MiB |
|    2   N/A  N/A    155064      C   /usr/bin/python3                             1510MiB |
|    3   N/A  N/A    155065      C   /usr/bin/python3                             1510MiB |
|    4   N/A  N/A    155066      C   /usr/bin/python3                             2756MiB |
|    5   N/A  N/A    155067      C   /usr/bin/python3                             2756MiB |
|    6   N/A  N/A    155068      C   /usr/bin/python3                             2756MiB |
|    7   N/A  N/A    155069      C   /usr/bin/python3                             2756MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
=== Parameter counts ===
model total:           282,395,148 (282.395M)
  attention stack (27 of 28 layers run attention): 86,704,128 (86.704M)
  FFN bank total:      15,084,160 (15.084M)
    ├─ experts W1/W2:  14,680,064 (14.680M)
    └─ routers:        404,096 (0.404M)
  embeddings (tok + 2× value): 135,132,928 (135.133M)
    └─ token embed:    45,072,384 (45.072M)
    └─ value embeds:   90,060,544 (90.061M)
  lm head (untied):   45,072,384 (45.072M)
  adapters:            401,408 (0.401M)
  scalars:             140 (0.000M)
====================================================================================================
Compiling model...
Compile complete.
Warming up kernels...
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/fq/cfqixvmxmiuyvximhm5cxovwynazccyxrjgpoqksbci2miqaptdo.py
inductor_output_code: /tmp/torchinductor_ubuntu/4l/c4ljprwocn4kfjpeoxx76qdg4kx3ryurg2ybcvofnmnpknnprl3n.py
inductor_output_code: /tmp/torchinductor_ubuntu/hb/chb2bnc3t74wttigx46vmvyli2swsbmgb3swroqvtdxwqgno3gef.py
inductor_output_code: /tmp/torchinductor_ubuntu/7m/c7mcceaqwhkxfo25gtt6z6deh5kc24e5larml3tir64zzlg7u2ls.py
inductor_output_code: /tmp/torchinductor_ubuntu/mr/cmrf5iwusj7ppaxt65o3cka54gvs3nskkxbibvcq2ec3flayler5.py
inductor_output_code: /tmp/torchinductor_ubuntu/y2/cy27xexdq3uy24qdnom66lejnydlviosxblbrahtgxlcjsn2nfcu.py
inductor_output_code: /tmp/torchinductor_ubuntu/kj/ckjscjlqwgbvzl5chr4w7asosnyptemylrorotmc5dafgo6mgdyg.py
inductor_output_code: /tmp/torchinductor_ubuntu/om/comnhqjt5ejns5cvw3lsgn6oofsjpbn2mc65likenpblbjttjr4k.py
inductor_output_code: /tmp/torchinductor_ubuntu/ic/cicajx3cn44vgfp2hj4yrxsu4zg55ao6s5tuuzf3gqynb4n5aei3.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/4g/c4g7sx7n5znkhhbc54uqvdxktlpbohoatd22todbxakltfuyq7xj.py
inductor_output_code: /tmp/torchinductor_ubuntu/vz/cvzmihtwtvc4z436rlwnps5vjvj3khdnsbx4fhlpaaoxcuxtxjjr.py
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/ei/ceihzmsbtrr2gp4tg4iqjfqdox5czomhvweztpj5b3c5y3wuf473.py
inductor_output_code: /tmp/torchinductor_ubuntu/27/c27xigeeuwotem6hlshv23nb7xvsj3zjrwayehurvqr4pri2hats.py
inductor_output_code: /tmp/torchinductor_ubuntu/44/c44gfjrynanau4olb5cxz6mvnnwlbo26bo4dvres3z3cq42scgkh.py
inductor_output_code: /tmp/torchinductor_ubuntu/ql/cqlbbiv4tnpmphfpqbquz37q4qqn767c5yjmdchujey6omwmvqqy.py
inductor_output_code: /tmp/torchinductor_ubuntu/xs/cxsnpngitcah7e2kduknn7ceti7je4v2j3yumztw47bcu6za6mcu.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vo/cvokruoazaxmhkd6d2kuiaagltu6u3rpovkqcrbndwwz3ltbk75q.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/nw/cnwmvztqrbjwoi473u5qitnxkngbgcuw5kcyf7re5yovaflz7lu2.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ea/ceaq2lx6uciw27w63cxgcnqqm5xteez6dezf5mx5sqok2gv4cg6l.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ps/cpsliltnujy72slrbeq44fp3oye3ldviqbljjv3inoa66dlmk5lg.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/7z/c7zihhtgrytywzcdhlvc2uyabsvsfqf3mzdih3d64vy3fjr2auvg.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vf/cvfa6qtw4adef6nklcpbiwjwtshopzljqwyglpakkzkfskqglq26.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/yy/cyyy3jozpp7o3m6jxcbmv5ytzhs2p2pszf4ryo5wjrtjur5wzwrn.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vn/cvnp3hye32d6gtum6ssg53ko23znadoaop747hdwkw7tlcar4dik.py
inductor_output_code: /tmp/torchinductor_ubuntu/qi/cqijmax67f7bnmnslxmq64yo422uqudtakvm7wifucvc4zt32h57.py
inductor_output_code: /tmp/torchinductor_ubuntu/rk/crk7su4b7xpejvheo5gz6rpdorzzgpth65exdwfvo7ezfgyzgqfh.py
inductor_output_code: /tmp/torchinductor_ubuntu/ha/chaulm7ltsokkarrumul5qjrnx4ahkimqhauxh26exd2hcuk3l7x.py
inductor_output_code: /tmp/torchinductor_ubuntu/xp/cxpgiz2wiajvso43kie77hcmxvtsiaqz2te7otoesquvdyoapxm6.py
inductor_output_code: /tmp/torchinductor_ubuntu/ry/crykauzc3oifekn667dgcyrf5bibnkbghoch5mqvljqasw2k7aqg.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/kl/ckllj5sjejqdb6ipkfp4m745swsno7n6gygf22clrcp74t3u3wti.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/z5/cz5f7iwr6al2eokhvc2i57wbq3sgdcans5vfvv6wx3fp5ammhigu.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/n4/cn4fwpvyaac5phl4qcqmrfwwi646mxowmyuqb57mj5mnnzskkapw.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/zd/czdr7mghhrcxjpxd4e7awowuyl4xv64mqklrxdzlbgmtg2ikmnlo.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ml/cml5y4cguscckibnxjkdkym25pt2fgjmvitan7zr4ybgrlraqps6.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/pe/cpeghbtcj37h3j2ztaq7llhet653sbihhvmnsvv7eqh6vopspdii.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/qg/cqgedru6kihsfgglrxbjmedufnrcaydomq3kwszain4vavckrgxu.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/r5/cr5klalefi6b6skemtsuq7frgj2ouai7ilonjkvwg5o574xtchjg.py
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/mc/cmcm6fww7tjiwmcvahcg4lzc7lyqpox2n56ccnewo33dhcin2knk.py
inductor_output_code: /tmp/torchinductor_ubuntu/p4/cp4fa4yeij2caf5yvvh2et4fngrovgk5x7w6srdh2i2o2bjjz6cb.py
inductor_output_code: /tmp/torchinductor_ubuntu/7c/c7ckg2hjgek3w2j6waxt5d5ffzdyeznjkhbqtrcmn42no6x5td3d.py
Kernel warmup complete.
Starting training.
Running validation...
step:0/1750 val_loss:10.962517 train_time:1ms step_avg:1.19ms
[train step 0] avg_loss=10.956215 main=10.956215 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:1/1750 train_time:280ms step_avg:280.22ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 1] avg_loss=10.054925 main=10.054925 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:2/1750 train_time:664ms step_avg:332.15ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 2] avg_loss=7.854772 main=7.854772 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:3/1750 train_time:1237ms step_avg:412.34ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 3] avg_loss=7.486156 main=7.486156 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:4/1750 train_time:1834ms step_avg:458.39ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 4] avg_loss=7.539331 main=7.539331 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:5/1750 train_time:2424ms step_avg:484.83ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 5] avg_loss=7.695577 main=7.695577 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:6/1750 train_time:2798ms step_avg:466.29ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 6] avg_loss=7.254884 main=7.254884 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:7/1750 train_time:3180ms step_avg:454.26ms
[train step 7] avg_loss=6.880267 main=6.880267 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:8/1750 train_time:3402ms step_avg:425.27ms
[train step 8] avg_loss=6.787970 main=6.787970 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:9/1750 train_time:3624ms step_avg:402.71ms
[train step 9] avg_loss=7.177587 main=7.177587 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:10/1750 train_time:3849ms step_avg:384.89ms
[train step 10] avg_loss=7.033590 main=7.033590 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:11/1750 train_time:4071ms step_avg:370.07ms
[train step 11] avg_loss=6.826678 main=6.826678 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:12/1750 train_time:4293ms step_avg:357.73ms
[train step 12] avg_loss=6.575514 main=6.575514 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:13/1750 train_time:4515ms step_avg:347.28ms
[train step 13] avg_loss=6.629575 main=6.629575 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:14/1750 train_time:4739ms step_avg:338.53ms
[train step 14] avg_loss=6.338338 main=6.338338 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:15/1750 train_time:4962ms step_avg:330.81ms
[train step 15] avg_loss=6.503412 main=6.503412 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:16/1750 train_time:5185ms step_avg:324.04ms
[train step 16] avg_loss=6.183414 main=6.183414 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:17/1750 train_time:5406ms step_avg:318.01ms
[train step 17] avg_loss=6.234867 main=6.234867 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:18/1750 train_time:5628ms step_avg:312.69ms
[train step 18] avg_loss=6.392015 main=6.392015 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:19/1750 train_time:5850ms step_avg:307.91ms
[train step 19] avg_loss=6.059268 main=6.059268 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:20/1750 train_time:6072ms step_avg:303.59ms
[train step 20] avg_loss=6.559835 main=6.559835 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:21/1750 train_time:6294ms step_avg:299.72ms
[train step 21] avg_loss=6.452090 main=6.452090 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:22/1750 train_time:6518ms step_avg:296.27ms
[train step 22] avg_loss=6.281377 main=6.281377 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:23/1750 train_time:6740ms step_avg:293.04ms
[train step 23] avg_loss=6.403629 main=6.403629 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:24/1750 train_time:6962ms step_avg:290.06ms
[train step 24] avg_loss=6.122774 main=6.122774 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:25/1750 train_time:7183ms step_avg:287.34ms
[train step 25] avg_loss=6.016309 main=6.016309 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:26/1750 train_time:7409ms step_avg:284.94ms
[train step 26] avg_loss=6.117702 main=6.117702 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:27/1750 train_time:7631ms step_avg:282.64ms
[train step 27] avg_loss=5.983810 main=5.983810 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:28/1750 train_time:7854ms step_avg:280.48ms
[train step 28] avg_loss=5.658779 main=5.658779 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:29/1750 train_time:8076ms step_avg:278.49ms
[train step 29] avg_loss=6.108765 main=6.108765 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:30/1750 train_time:8298ms step_avg:276.61ms
[train step 30] avg_loss=5.933627 main=5.933627 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:31/1750 train_time:8519ms step_avg:274.81ms
[train step 31] avg_loss=6.038960 main=6.038960 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:32/1750 train_time:8741ms step_avg:273.16ms
[train step 32] avg_loss=6.185732 main=6.185732 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:33/1750 train_time:8964ms step_avg:271.62ms
[train step 33] avg_loss=5.946993 main=5.946993 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:34/1750 train_time:9185ms step_avg:270.15ms
[train step 34] avg_loss=6.306381 main=6.306381 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:35/1750 train_time:9406ms step_avg:268.74ms
[train step 35] avg_loss=6.176973 main=6.176973 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:36/1750 train_time:9627ms step_avg:267.42ms
[train step 36] avg_loss=5.641267 main=5.641267 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:37/1750 train_time:9850ms step_avg:266.21ms
[train step 37] avg_loss=5.897591 main=5.897591 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:38/1750 train_time:10072ms step_avg:265.04ms
[train step 38] avg_loss=5.677560 main=5.677560 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:39/1750 train_time:10293ms step_avg:263.91ms
[train step 39] avg_loss=5.936029 main=5.936029 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:40/1750 train_time:10514ms step_avg:262.84ms
[train step 40] avg_loss=4.539646 main=4.539646 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:41/1750 train_time:10735ms step_avg:261.83ms
[train step 41] avg_loss=5.920931 main=5.920931 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:42/1750 train_time:10956ms step_avg:260.86ms
[train step 42] avg_loss=5.490255 main=5.490255 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:43/1750 train_time:11177ms step_avg:259.93ms
[train step 43] avg_loss=5.710445 main=5.710445 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:44/1750 train_time:11399ms step_avg:259.06ms
[train step 44] avg_loss=5.799790 main=5.799790 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:45/1750 train_time:11620ms step_avg:258.22ms
[train step 45] avg_loss=5.897076 main=5.897076 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:46/1750 train_time:11841ms step_avg:257.42ms
[train step 46] avg_loss=5.479433 main=5.479433 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:47/1750 train_time:12063ms step_avg:256.65ms
[train step 47] avg_loss=5.534564 main=5.534564 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:48/1750 train_time:12286ms step_avg:255.97ms
[train step 48] avg_loss=5.885702 main=5.885702 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:49/1750 train_time:12510ms step_avg:255.31ms
[train step 49] avg_loss=5.624354 main=5.624354 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:50/1750 train_time:12732ms step_avg:254.65ms
Running validation...
step:50/1750 val_loss:5.812558 train_time:12749ms step_avg:254.98ms
[train step 50] avg_loss=5.476431 main=5.476431 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:51/1750 train_time:12959ms step_avg:254.09ms
[train step 51] avg_loss=5.581049 main=5.581049 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:52/1750 train_time:13182ms step_avg:253.50ms
[train step 52] avg_loss=5.363063 main=5.363063 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:53/1750 train_time:13404ms step_avg:252.91ms
[train step 53] avg_loss=5.628702 main=5.628702 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:54/1750 train_time:13627ms step_avg:252.36ms
[train step 54] avg_loss=5.510568 main=5.510568 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:55/1750 train_time:13850ms step_avg:251.82ms
[train step 55] avg_loss=5.507931 main=5.507931 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:56/1750 train_time:14072ms step_avg:251.28ms
[train step 56] avg_loss=5.632442 main=5.632442 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:57/1750 train_time:14294ms step_avg:250.78ms
[train step 57] avg_loss=5.506054 main=5.506054 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:58/1750 train_time:14516ms step_avg:250.28ms
[train step 58] avg_loss=6.507961 main=6.507961 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:59/1750 train_time:14740ms step_avg:249.83ms
[train step 59] avg_loss=5.489821 main=5.489821 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:60/1750 train_time:14965ms step_avg:249.41ms
[train step 60] avg_loss=5.634947 main=5.634947 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:61/1750 train_time:15189ms step_avg:248.99ms
[train step 61] avg_loss=5.256911 main=5.256911 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:62/1750 train_time:15410ms step_avg:248.54ms
[train step 62] avg_loss=5.552986 main=5.552986 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:63/1750 train_time:15632ms step_avg:248.12ms
[train step 63] avg_loss=5.645599 main=5.645599 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:64/1750 train_time:15854ms step_avg:247.72ms
[train step 64] avg_loss=5.341741 main=5.341741 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:65/1750 train_time:16078ms step_avg:247.35ms
[train step 65] avg_loss=5.461320 main=5.461320 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:66/1750 train_time:16302ms step_avg:247.01ms
[train step 66] avg_loss=5.761693 main=5.761693 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:67/1750 train_time:16525ms step_avg:246.64ms
[train step 67] avg_loss=5.526010 main=5.526010 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:68/1750 train_time:16746ms step_avg:246.27ms
[train step 68] avg_loss=5.507306 main=5.507306 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:69/1750 train_time:16968ms step_avg:245.91ms
[train step 69] avg_loss=5.671314 main=5.671314 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:70/1750 train_time:17191ms step_avg:245.59ms
[train step 70] avg_loss=5.565769 main=5.565769 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:71/1750 train_time:17414ms step_avg:245.27ms
[train step 71] avg_loss=5.317229 main=5.317229 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:72/1750 train_time:17638ms step_avg:244.97ms
[train step 72] avg_loss=5.375507 main=5.375507 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:73/1750 train_time:17862ms step_avg:244.68ms
[train step 73] avg_loss=5.011714 main=5.011714 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:74/1750 train_time:18086ms step_avg:244.40ms
[train step 74] avg_loss=5.382265 main=5.382265 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:75/1750 train_time:18310ms step_avg:244.14ms
[train step 75] avg_loss=5.783189 main=5.331946 aux=0.451242 imp_cv2=3.0057 load_cv2=3.0294 usage_frac=0.2500 topk_prob_mean=0.6631 ema_alpha_reverse=nan max_logit=1.1660
step:76/1750 train_time:19185ms step_avg:252.44ms
[train step 76] avg_loss=6.561737 main=5.513874 aux=1.047863 imp_cv2=5.6043 load_cv2=6.9826 usage_frac=0.2500 topk_prob_mean=0.9011 ema_alpha_reverse=nan max_logit=1.1660
step:77/1750 train_time:19658ms step_avg:255.29ms
[train step 77] avg_loss=6.634197 main=5.597156 aux=1.037041 imp_cv2=5.5175 load_cv2=6.9525 usage_frac=0.2500 topk_prob_mean=0.8905 ema_alpha_reverse=nan max_logit=1.1660
step:78/1750 train_time:20118ms step_avg:257.92ms
[train step 78] avg_loss=6.617825 main=5.589665 aux=1.028160 imp_cv2=5.4549 load_cv2=6.9175 usage_frac=0.2500 topk_prob_mean=0.8824 ema_alpha_reverse=nan max_logit=1.1660
step:79/1750 train_time:20617ms step_avg:260.98ms
[train step 79] avg_loss=6.585146 main=5.561366 aux=1.023780 imp_cv2=5.4115 load_cv2=6.9146 usage_frac=0.2500 topk_prob_mean=0.8776 ema_alpha_reverse=nan max_logit=1.1660
step:80/1750 train_time:21083ms step_avg:263.53ms
[train step 80] avg_loss=6.714196 main=5.699505 aux=1.014691 imp_cv2=5.3396 load_cv2=6.8918 usage_frac=0.2500 topk_prob_mean=0.8686 ema_alpha_reverse=nan max_logit=1.1660
step:81/1750 train_time:21545ms step_avg:265.99ms
[train step 81] avg_loss=6.323717 main=5.314171 aux=1.009545 imp_cv2=5.3142 load_cv2=6.8607 usage_frac=0.2500 topk_prob_mean=0.8622 ema_alpha_reverse=nan max_logit=1.1660
step:82/1750 train_time:22111ms step_avg:269.64ms
[train step 82] avg_loss=6.182865 main=5.178554 aux=1.004310 imp_cv2=5.2951 load_cv2=6.8263 usage_frac=0.2500 topk_prob_mean=0.8577 ema_alpha_reverse=nan max_logit=1.1660
step:83/1750 train_time:22713ms step_avg:273.65ms
[train step 83] avg_loss=6.336399 main=5.355186 aux=0.981213 imp_cv2=5.2184 load_cv2=6.6720 usage_frac=0.2500 topk_prob_mean=0.8588 ema_alpha_reverse=nan max_logit=1.1660
step:84/1750 train_time:23344ms step_avg:277.90ms
[train step 84] avg_loss=6.558214 main=5.570301 aux=0.987913 imp_cv2=5.2309 load_cv2=6.7300 usage_frac=0.2500 topk_prob_mean=0.8570 ema_alpha_reverse=nan max_logit=1.1660
step:85/1750 train_time:24019ms step_avg:282.57ms
[train step 85] avg_loss=6.651001 main=5.704534 aux=0.946467 imp_cv2=5.0832 load_cv2=6.4416 usage_frac=0.2500 topk_prob_mean=0.8580 ema_alpha_reverse=nan max_logit=1.1660
step:86/1750 train_time:24745ms step_avg:287.73ms
[train step 86] avg_loss=6.124092 main=5.183194 aux=0.940897 imp_cv2=5.0361 load_cv2=6.4441 usage_frac=0.2500 topk_prob_mean=0.8566 ema_alpha_reverse=nan max_logit=1.1660
step:87/1750 train_time:25481ms step_avg:292.89ms
[train step 87] avg_loss=6.205158 main=5.300676 aux=0.904482 imp_cv2=4.8877 load_cv2=6.2076 usage_frac=0.2500 topk_prob_mean=0.8572 ema_alpha_reverse=nan max_logit=1.1660
step:88/1750 train_time:26213ms step_avg:297.88ms
[train step 88] avg_loss=5.847475 main=4.921048 aux=0.926426 imp_cv2=4.9688 load_cv2=6.3563 usage_frac=0.2500 topk_prob_mean=0.8555 ema_alpha_reverse=nan max_logit=1.1660
step:89/1750 train_time:26953ms step_avg:302.84ms
[train step 89] avg_loss=6.309107 main=5.494678 aux=0.814429 imp_cv2=4.5154 load_cv2=5.5914 usage_frac=0.2500 topk_prob_mean=0.8571 ema_alpha_reverse=nan max_logit=1.1660
step:90/1750 train_time:27688ms step_avg:307.64ms
[train step 90] avg_loss=6.054899 main=5.314629 aux=0.740270 imp_cv2=4.1947 load_cv2=5.1129 usage_frac=0.2500 topk_prob_mean=0.8560 ema_alpha_reverse=nan max_logit=1.1660
step:91/1750 train_time:28421ms step_avg:312.32ms
[train step 91] avg_loss=6.001366 main=5.367486 aux=0.633879 imp_cv2=3.7433 load_cv2=4.3836 usage_frac=0.2500 topk_prob_mean=0.8563 ema_alpha_reverse=nan max_logit=1.1661
step:92/1750 train_time:29157ms step_avg:316.92ms
[train step 92] avg_loss=6.116122 main=5.572260 aux=0.543862 imp_cv2=3.4069 load_cv2=3.7548 usage_frac=0.2500 topk_prob_mean=0.8597 ema_alpha_reverse=nan max_logit=1.1661
step:93/1750 train_time:29825ms step_avg:320.70ms
[train step 93] avg_loss=6.600364 main=6.015462 aux=0.584901 imp_cv2=3.6372 load_cv2=3.9714 usage_frac=0.2500 topk_prob_mean=0.8657 ema_alpha_reverse=nan max_logit=1.1661
step:94/1750 train_time:30480ms step_avg:324.26ms
[train step 94] avg_loss=5.762100 main=5.227018 aux=0.535082 imp_cv2=3.2885 load_cv2=3.7600 usage_frac=0.2500 topk_prob_mean=0.8520 ema_alpha_reverse=nan max_logit=1.1661
step:95/1750 train_time:31172ms step_avg:328.13ms
[train step 95] avg_loss=5.847011 main=5.326602 aux=0.520409 imp_cv2=3.2000 load_cv2=3.6694 usage_frac=0.2500 topk_prob_mean=0.8506 ema_alpha_reverse=nan max_logit=1.1661
step:96/1750 train_time:31818ms step_avg:331.44ms
[train step 96] avg_loss=5.780004 main=5.269621 aux=0.510382 imp_cv2=3.1424 load_cv2=3.6008 usage_frac=0.2500 topk_prob_mean=0.8498 ema_alpha_reverse=nan max_logit=1.1662
step:97/1750 train_time:32475ms step_avg:334.79ms
[train step 97] avg_loss=5.722434 main=5.199042 aux=0.523392 imp_cv2=3.1706 load_cv2=3.7215 usage_frac=0.2500 topk_prob_mean=0.8485 ema_alpha_reverse=nan max_logit=1.1662
step:98/1750 train_time:33120ms step_avg:337.96ms
[train step 98] avg_loss=5.979796 main=5.476659 aux=0.503137 imp_cv2=3.0738 load_cv2=3.5635 usage_frac=0.2500 topk_prob_mean=0.8462 ema_alpha_reverse=nan max_logit=1.1663
step:99/1750 train_time:33776ms step_avg:341.17ms
[train step 99] avg_loss=6.054096 main=5.549540 aux=0.504556 imp_cv2=3.0714 load_cv2=3.5820 usage_frac=0.2500 topk_prob_mean=0.8442 ema_alpha_reverse=nan max_logit=1.1663
step:100/1750 train_time:34413ms step_avg:344.13ms
Running validation...
step:100/1750 val_loss:5.363400 train_time:34425ms step_avg:344.25ms
[train step 100] avg_loss=5.519283 main=5.002980 aux=0.516303 imp_cv2=3.0987 load_cv2=3.6805 usage_frac=0.2500 topk_prob_mean=0.8438 ema_alpha_reverse=nan max_logit=1.1664
step:101/1750 train_time:35054ms step_avg:347.07ms
[train step 101] avg_loss=5.921255 main=5.425664 aux=0.495590 imp_cv2=3.0226 load_cv2=3.5087 usage_frac=0.2500 topk_prob_mean=0.8427 ema_alpha_reverse=nan max_logit=1.1664
step:102/1750 train_time:35654ms step_avg:349.55ms
[train step 102] avg_loss=5.614943 main=5.112751 aux=0.502192 imp_cv2=3.0267 load_cv2=3.5772 usage_frac=0.2500 topk_prob_mean=0.8418 ema_alpha_reverse=nan max_logit=1.1665
step:103/1750 train_time:36294ms step_avg:352.37ms
[train step 103] avg_loss=5.653855 main=5.156186 aux=0.497669 imp_cv2=3.0142 load_cv2=3.5379 usage_frac=0.2500 topk_prob_mean=0.8419 ema_alpha_reverse=nan max_logit=1.1666
step:104/1750 train_time:36907ms step_avg:354.88ms
[train step 104] avg_loss=5.735895 main=5.240294 aux=0.495601 imp_cv2=3.0075 load_cv2=3.5178 usage_frac=0.2500 topk_prob_mean=0.8409 ema_alpha_reverse=nan max_logit=1.1666
step:105/1750 train_time:37510ms step_avg:357.23ms
[train step 105] avg_loss=5.788740 main=5.290378 aux=0.498362 imp_cv2=3.0259 load_cv2=3.5286 usage_frac=0.2500 topk_prob_mean=0.8407 ema_alpha_reverse=nan max_logit=1.1667
step:106/1750 train_time:38108ms step_avg:359.51ms
[train step 106] avg_loss=5.940056 main=5.440192 aux=0.499864 imp_cv2=3.0131 load_cv2=3.5601 usage_frac=0.2500 topk_prob_mean=0.8407 ema_alpha_reverse=nan max_logit=1.1668
step:107/1750 train_time:38720ms step_avg:361.87ms
[train step 107] avg_loss=5.683745 main=5.188917 aux=0.494827 imp_cv2=3.0068 load_cv2=3.5119 usage_frac=0.2500 topk_prob_mean=0.8399 ema_alpha_reverse=nan max_logit=1.1670
step:108/1750 train_time:39304ms step_avg:363.93ms
[train step 108] avg_loss=5.801613 main=5.303655 aux=0.497958 imp_cv2=3.0070 load_cv2=3.5449 usage_frac=0.2500 topk_prob_mean=0.8377 ema_alpha_reverse=nan max_logit=1.1671
step:109/1750 train_time:39889ms step_avg:365.96ms
[train step 109] avg_loss=5.530936 main=5.034414 aux=0.496523 imp_cv2=3.0069 load_cv2=3.5262 usage_frac=0.2500 topk_prob_mean=0.8386 ema_alpha_reverse=nan max_logit=1.1672
step:110/1750 train_time:40449ms step_avg:367.72ms
[train step 110] avg_loss=5.609823 main=5.112915 aux=0.496908 imp_cv2=3.0095 load_cv2=3.5275 usage_frac=0.2500 topk_prob_mean=0.8342 ema_alpha_reverse=nan max_logit=1.1674
step:111/1750 train_time:41029ms step_avg:369.63ms
[train step 111] avg_loss=5.628768 main=5.131173 aux=0.497596 imp_cv2=3.0029 load_cv2=3.5436 usage_frac=0.2500 topk_prob_mean=0.8360 ema_alpha_reverse=nan max_logit=1.1675
step:112/1750 train_time:41595ms step_avg:371.39ms
[train step 112] avg_loss=6.082973 main=5.585403 aux=0.497570 imp_cv2=3.0047 load_cv2=3.5409 usage_frac=0.2500 topk_prob_mean=0.8326 ema_alpha_reverse=nan max_logit=1.1677
step:113/1750 train_time:42183ms step_avg:373.30ms
[train step 113] avg_loss=5.802360 main=5.306468 aux=0.495892 imp_cv2=3.0045 load_cv2=3.5218 usage_frac=0.2500 topk_prob_mean=0.8344 ema_alpha_reverse=nan max_logit=1.1679
step:114/1750 train_time:42763ms step_avg:375.11ms
[train step 114] avg_loss=6.224907 main=5.726404 aux=0.498503 imp_cv2=3.0040 load_cv2=3.5536 usage_frac=0.2500 topk_prob_mean=0.8296 ema_alpha_reverse=nan max_logit=1.1681
step:115/1750 train_time:43343ms step_avg:376.89ms
[train step 115] avg_loss=5.502161 main=5.006145 aux=0.496015 imp_cv2=3.0023 load_cv2=3.5255 usage_frac=0.2500 topk_prob_mean=0.8379 ema_alpha_reverse=nan max_logit=1.1683
step:116/1750 train_time:43893ms step_avg:378.39ms
[train step 116] avg_loss=5.882022 main=5.386079 aux=0.495942 imp_cv2=3.0024 load_cv2=3.5258 usage_frac=0.2500 topk_prob_mean=0.8321 ema_alpha_reverse=nan max_logit=1.1686
step:117/1750 train_time:44454ms step_avg:379.95ms
[train step 117] avg_loss=5.650568 main=5.150537 aux=0.500031 imp_cv2=3.0104 load_cv2=3.5673 usage_frac=0.2500 topk_prob_mean=0.8320 ema_alpha_reverse=nan max_logit=1.1688
step:118/1750 train_time:45015ms step_avg:381.49ms
[train step 118] avg_loss=5.581238 main=5.086931 aux=0.494307 imp_cv2=3.0013 load_cv2=3.5097 usage_frac=0.2500 topk_prob_mean=0.8298 ema_alpha_reverse=nan max_logit=1.1691
step:119/1750 train_time:45568ms step_avg:382.92ms
[train step 119] avg_loss=5.396633 main=4.902288 aux=0.494344 imp_cv2=3.0191 load_cv2=3.4897 usage_frac=0.2500 topk_prob_mean=0.8377 ema_alpha_reverse=nan max_logit=1.1694
step:120/1750 train_time:46152ms step_avg:384.60ms
[train step 120] avg_loss=5.601355 main=5.103334 aux=0.498021 imp_cv2=3.0005 load_cv2=3.5539 usage_frac=0.2500 topk_prob_mean=0.8249 ema_alpha_reverse=nan max_logit=1.1697
step:121/1750 train_time:46683ms step_avg:385.81ms
[train step 121] avg_loss=5.533739 main=5.032382 aux=0.501357 imp_cv2=3.0021 load_cv2=3.5896 usage_frac=0.2500 topk_prob_mean=0.8209 ema_alpha_reverse=nan max_logit=1.1701
step:122/1750 train_time:47257ms step_avg:387.35ms
[train step 122] avg_loss=5.295737 main=4.792013 aux=0.503724 imp_cv2=3.0082 load_cv2=3.6183 usage_frac=0.2500 topk_prob_mean=0.8187 ema_alpha_reverse=nan max_logit=1.1705
step:123/1750 train_time:47800ms step_avg:388.62ms
[train step 123] avg_loss=5.578724 main=5.078674 aux=0.500050 imp_cv2=3.0022 load_cv2=3.5736 usage_frac=0.2500 topk_prob_mean=0.8148 ema_alpha_reverse=nan max_logit=1.1709
step:124/1750 train_time:48370ms step_avg:390.08ms
[train step 124] avg_loss=5.450716 main=4.951972 aux=0.498744 imp_cv2=3.0022 load_cv2=3.5569 usage_frac=0.2500 topk_prob_mean=0.8205 ema_alpha_reverse=nan max_logit=1.1713
step:125/1750 train_time:48936ms step_avg:391.49ms
[train step 125] avg_loss=5.548159 main=5.042674 aux=0.505485 imp_cv2=3.0022 load_cv2=3.6435 usage_frac=0.2500 topk_prob_mean=0.8111 ema_alpha_reverse=nan max_logit=1.1717
step:126/1750 train_time:49509ms step_avg:392.92ms
[train step 126] avg_loss=5.706489 main=5.201197 aux=0.505292 imp_cv2=3.0047 load_cv2=3.6374 usage_frac=0.2500 topk_prob_mean=0.8024 ema_alpha_reverse=nan max_logit=1.1722
step:127/1750 train_time:50084ms step_avg:394.36ms
[train step 127] avg_loss=5.380441 main=4.881554 aux=0.498887 imp_cv2=3.0024 load_cv2=3.5603 usage_frac=0.2500 topk_prob_mean=0.8147 ema_alpha_reverse=nan max_logit=1.1727
step:128/1750 train_time:50676ms step_avg:395.91ms
[train step 128] avg_loss=5.278076 main=4.777262 aux=0.500814 imp_cv2=3.0054 load_cv2=3.5818 usage_frac=0.2500 topk_prob_mean=0.8082 ema_alpha_reverse=nan max_logit=1.1732
step:129/1750 train_time:51229ms step_avg:397.13ms
[train step 129] avg_loss=5.381807 main=4.879989 aux=0.501818 imp_cv2=3.0133 load_cv2=3.5818 usage_frac=0.2500 topk_prob_mean=0.8096 ema_alpha_reverse=nan max_logit=1.1738
step:130/1750 train_time:51792ms step_avg:398.40ms
[train step 130] avg_loss=5.482559 main=4.980018 aux=0.502541 imp_cv2=3.0046 load_cv2=3.6028 usage_frac=0.2500 topk_prob_mean=0.8037 ema_alpha_reverse=nan max_logit=1.1744
step:131/1750 train_time:52363ms step_avg:399.72ms
[train step 131] avg_loss=5.345543 main=4.836954 aux=0.508589 imp_cv2=3.0127 load_cv2=3.6809 usage_frac=0.2500 topk_prob_mean=0.8099 ema_alpha_reverse=nan max_logit=1.1750
step:132/1750 train_time:52926ms step_avg:400.96ms
[train step 132] avg_loss=5.503637 main=4.995474 aux=0.508162 imp_cv2=3.0033 load_cv2=3.6751 usage_frac=0.2500 topk_prob_mean=0.8008 ema_alpha_reverse=nan max_logit=1.1757
step:133/1750 train_time:53505ms step_avg:402.29ms
[train step 133] avg_loss=5.649393 main=5.145897 aux=0.503496 imp_cv2=3.0075 load_cv2=3.6122 usage_frac=0.2500 topk_prob_mean=0.7999 ema_alpha_reverse=nan max_logit=1.1764
step:134/1750 train_time:54297ms step_avg:405.20ms
[train step 134] avg_loss=5.675215 main=5.164980 aux=0.510235 imp_cv2=3.0203 load_cv2=3.6866 usage_frac=0.2500 topk_prob_mean=0.8046 ema_alpha_reverse=nan max_logit=1.1771
step:135/1750 train_time:54888ms step_avg:406.58ms
[train step 135] avg_loss=5.576534 main=5.068930 aux=0.507605 imp_cv2=3.0067 load_cv2=3.6634 usage_frac=0.2500 topk_prob_mean=0.8011 ema_alpha_reverse=nan max_logit=1.1779
step:136/1750 train_time:55487ms step_avg:408.00ms
[train step 136] avg_loss=5.332363 main=4.820487 aux=0.511876 imp_cv2=3.0092 load_cv2=3.7286 usage_frac=0.2500 topk_prob_mean=0.7875 ema_alpha_reverse=nan max_logit=1.1787
step:137/1750 train_time:56035ms step_avg:409.02ms
[train step 137] avg_loss=5.367891 main=4.857875 aux=0.510016 imp_cv2=3.0051 load_cv2=3.7047 usage_frac=0.2500 topk_prob_mean=0.7888 ema_alpha_reverse=nan max_logit=1.1796
step:138/1750 train_time:56600ms step_avg:410.14ms
[train step 138] avg_loss=5.451501 main=4.940681 aux=0.510820 imp_cv2=3.0157 load_cv2=3.7062 usage_frac=0.2500 topk_prob_mean=0.7922 ema_alpha_reverse=nan max_logit=1.1805
step:139/1750 train_time:57138ms step_avg:411.06ms
[train step 139] avg_loss=5.400030 main=4.889900 aux=0.510130 imp_cv2=3.0030 load_cv2=3.7046 usage_frac=0.2500 topk_prob_mean=0.7880 ema_alpha_reverse=nan max_logit=1.1814
step:140/1750 train_time:57711ms step_avg:412.22ms
[train step 140] avg_loss=5.330412 main=4.820491 aux=0.509921 imp_cv2=3.0078 load_cv2=3.6911 usage_frac=0.2500 topk_prob_mean=0.7949 ema_alpha_reverse=nan max_logit=1.1824
step:141/1750 train_time:58259ms step_avg:413.19ms
[train step 141] avg_loss=5.402168 main=5.058416 aux=0.343752 imp_cv2=1.8509 load_cv2=2.5460 usage_frac=0.3750 topk_prob_mean=0.6557 ema_alpha_reverse=nan max_logit=1.1834
step:142/1750 train_time:59019ms step_avg:415.63ms
[train step 142] avg_loss=5.155334 main=4.685200 aux=0.470134 imp_cv2=2.1233 load_cv2=3.7179 usage_frac=0.2902 topk_prob_mean=0.6641 ema_alpha_reverse=nan max_logit=1.1845
step:143/1750 train_time:59652ms step_avg:417.15ms
[train step 143] avg_loss=5.400342 main=4.936703 aux=0.463640 imp_cv2=1.9977 load_cv2=3.7561 usage_frac=0.2768 topk_prob_mean=0.6263 ema_alpha_reverse=nan max_logit=1.1857
step:144/1750 train_time:60289ms step_avg:418.67ms
[train step 144] avg_loss=5.197032 main=4.727925 aux=0.469107 imp_cv2=1.8941 load_cv2=3.9342 usage_frac=0.2857 topk_prob_mean=0.5830 ema_alpha_reverse=nan max_logit=1.1869
step:145/1750 train_time:60943ms step_avg:420.30ms
[train step 145] avg_loss=5.496159 main=5.022659 aux=0.473499 imp_cv2=1.7992 load_cv2=4.0914 usage_frac=0.2946 topk_prob_mean=0.5260 ema_alpha_reverse=nan max_logit=1.1881
step:146/1750 train_time:61602ms step_avg:421.93ms
[train step 146] avg_loss=5.438774 main=4.944795 aux=0.493979 imp_cv2=1.7664 load_cv2=4.3656 usage_frac=0.2902 topk_prob_mean=0.4968 ema_alpha_reverse=nan max_logit=1.1894
step:147/1750 train_time:62277ms step_avg:423.65ms
[train step 147] avg_loss=5.331470 main=4.798043 aux=0.533428 imp_cv2=1.7368 load_cv2=4.8590 usage_frac=0.2812 topk_prob_mean=0.4672 ema_alpha_reverse=nan max_logit=1.1908
step:148/1750 train_time:62961ms step_avg:425.41ms
[train step 148] avg_loss=5.389571 main=4.868451 aux=0.521120 imp_cv2=1.7414 load_cv2=4.7164 usage_frac=0.2991 topk_prob_mean=0.4686 ema_alpha_reverse=nan max_logit=1.1922
step:149/1750 train_time:63616ms step_avg:426.96ms
[train step 149] avg_loss=5.360537 main=4.810287 aux=0.550251 imp_cv2=1.7274 load_cv2=5.0695 usage_frac=0.2946 topk_prob_mean=0.4508 ema_alpha_reverse=nan max_logit=1.1937
step:150/1750 train_time:64322ms step_avg:428.81ms
Running validation...
step:150/1750 val_loss:4.938966 train_time:64334ms step_avg:428.89ms
[train step 150] avg_loss=5.521619 main=4.977941 aux=0.543678 imp_cv2=1.7292 load_cv2=5.0025 usage_frac=0.2902 topk_prob_mean=0.4513 ema_alpha_reverse=nan max_logit=1.1952
step:151/1750 train_time:64988ms step_avg:430.38ms
[train step 151] avg_loss=5.468913 main=4.912577 aux=0.556336 imp_cv2=1.7130 load_cv2=5.1533 usage_frac=0.3080 topk_prob_mean=0.4394 ema_alpha_reverse=nan max_logit=1.1968
step:152/1750 train_time:65666ms step_avg:432.01ms
[train step 152] avg_loss=5.671845 main=5.083159 aux=0.588686 imp_cv2=1.7521 load_cv2=5.5281 usage_frac=0.2991 topk_prob_mean=0.4426 ema_alpha_reverse=nan max_logit=1.1985
step:153/1750 train_time:66361ms step_avg:433.73ms
[train step 153] avg_loss=5.797051 main=5.211597 aux=0.585454 imp_cv2=1.6977 load_cv2=5.5137 usage_frac=0.3080 topk_prob_mean=0.4148 ema_alpha_reverse=nan max_logit=1.2003
step:154/1750 train_time:67033ms step_avg:435.28ms
[train step 154] avg_loss=5.080073 main=4.491434 aux=0.588639 imp_cv2=1.7104 load_cv2=5.5272 usage_frac=0.2902 topk_prob_mean=0.4233 ema_alpha_reverse=nan max_logit=1.2021
step:155/1750 train_time:67669ms step_avg:436.57ms
[train step 155] avg_loss=5.274704 main=4.674770 aux=0.599934 imp_cv2=1.7006 load_cv2=5.6801 usage_frac=0.2946 topk_prob_mean=0.4153 ema_alpha_reverse=nan max_logit=1.2040
step:156/1750 train_time:68316ms step_avg:437.92ms
[train step 156] avg_loss=5.316170 main=4.709943 aux=0.606227 imp_cv2=1.7001 load_cv2=5.7481 usage_frac=0.2946 topk_prob_mean=0.4112 ema_alpha_reverse=nan max_logit=1.2059
step:157/1750 train_time:68944ms step_avg:439.14ms
[train step 157] avg_loss=5.107256 main=4.507395 aux=0.599861 imp_cv2=1.6951 load_cv2=5.6824 usage_frac=0.2857 topk_prob_mean=0.4090 ema_alpha_reverse=nan max_logit=1.2080
step:158/1750 train_time:69712ms step_avg:441.21ms
[train step 158] avg_loss=5.389516 main=4.785622 aux=0.603894 imp_cv2=1.6879 load_cv2=5.7448 usage_frac=0.3170 topk_prob_mean=0.4068 ema_alpha_reverse=nan max_logit=1.2101
step:159/1750 train_time:70326ms step_avg:442.30ms
[train step 159] avg_loss=5.265221 main=4.658985 aux=0.606236 imp_cv2=1.6865 load_cv2=5.7896 usage_frac=0.3080 topk_prob_mean=0.4020 ema_alpha_reverse=nan max_logit=1.2123
step:160/1750 train_time:70939ms step_avg:443.37ms
[train step 160] avg_loss=5.118429 main=4.509991 aux=0.608438 imp_cv2=1.6970 load_cv2=5.7839 usage_frac=0.2857 topk_prob_mean=0.4073 ema_alpha_reverse=nan max_logit=1.2146
step:161/1750 train_time:71551ms step_avg:444.41ms
[train step 161] avg_loss=5.327264 main=4.714085 aux=0.613179 imp_cv2=1.7048 load_cv2=5.8163 usage_frac=0.2857 topk_prob_mean=0.4117 ema_alpha_reverse=nan max_logit=1.2170
step:162/1750 train_time:72375ms step_avg:446.76ms
[train step 162] avg_loss=5.264512 main=4.659969 aux=0.604543 imp_cv2=1.6997 load_cv2=5.7395 usage_frac=0.2812 topk_prob_mean=0.4085 ema_alpha_reverse=nan max_logit=1.2194
step:163/1750 train_time:72981ms step_avg:447.74ms
[train step 163] avg_loss=6.027754 main=5.411208 aux=0.616547 imp_cv2=1.6969 load_cv2=5.8965 usage_frac=0.2857 topk_prob_mean=0.4022 ema_alpha_reverse=nan max_logit=1.2220
step:164/1750 train_time:73546ms step_avg:448.45ms
[train step 164] avg_loss=5.207155 main=4.584782 aux=0.622373 imp_cv2=1.6976 load_cv2=5.9528 usage_frac=0.3036 topk_prob_mean=0.4028 ema_alpha_reverse=nan max_logit=1.2247
step:165/1750 train_time:74127ms step_avg:449.25ms
[train step 165] avg_loss=5.230756 main=4.608383 aux=0.622373 imp_cv2=1.6866 load_cv2=5.9641 usage_frac=0.2946 topk_prob_mean=0.3992 ema_alpha_reverse=nan max_logit=1.2274
step:166/1750 train_time:74680ms step_avg:449.88ms
[train step 166] avg_loss=5.086788 main=4.457527 aux=0.629261 imp_cv2=1.6854 load_cv2=6.0417 usage_frac=0.2902 topk_prob_mean=0.3940 ema_alpha_reverse=nan max_logit=1.2303
step:167/1750 train_time:75265ms step_avg:450.69ms
[train step 167] avg_loss=5.296876 main=4.676464 aux=0.620411 imp_cv2=1.7095 load_cv2=5.9059 usage_frac=0.2946 topk_prob_mean=0.4129 ema_alpha_reverse=nan max_logit=1.2332
step:168/1750 train_time:75815ms step_avg:451.28ms
[train step 168] avg_loss=5.232861 main=4.610343 aux=0.622518 imp_cv2=1.7056 load_cv2=5.9400 usage_frac=0.2946 topk_prob_mean=0.4104 ema_alpha_reverse=nan max_logit=1.2363
step:169/1750 train_time:76356ms step_avg:451.81ms
[train step 169] avg_loss=5.290186 main=4.668852 aux=0.621334 imp_cv2=1.7046 load_cv2=5.9227 usage_frac=0.3170 topk_prob_mean=0.4100 ema_alpha_reverse=nan max_logit=1.2394
step:170/1750 train_time:77139ms step_avg:453.76ms
[train step 170] avg_loss=5.224508 main=4.601841 aux=0.622667 imp_cv2=1.6978 load_cv2=5.9537 usage_frac=0.3036 topk_prob_mean=0.4066 ema_alpha_reverse=nan max_logit=1.2427
step:171/1750 train_time:77697ms step_avg:454.37ms
[train step 171] avg_loss=5.512474 main=4.890563 aux=0.621910 imp_cv2=1.6870 load_cv2=5.9792 usage_frac=0.3036 topk_prob_mean=0.3963 ema_alpha_reverse=nan max_logit=1.2461
step:172/1750 train_time:78241ms step_avg:454.89ms
[train step 172] avg_loss=5.273978 main=4.649266 aux=0.624713 imp_cv2=1.6967 load_cv2=5.9704 usage_frac=0.2902 topk_prob_mean=0.4027 ema_alpha_reverse=nan max_logit=1.2496
step:173/1750 train_time:78780ms step_avg:455.38ms
[train step 173] avg_loss=5.411850 main=4.794276 aux=0.617574 imp_cv2=1.6855 load_cv2=5.9198 usage_frac=0.2991 topk_prob_mean=0.3996 ema_alpha_reverse=nan max_logit=1.2532
step:174/1750 train_time:79456ms step_avg:456.64ms
[train step 174] avg_loss=5.537500 main=4.915960 aux=0.621540 imp_cv2=1.7022 load_cv2=5.9238 usage_frac=0.2902 topk_prob_mean=0.4077 ema_alpha_reverse=nan max_logit=1.2570
step:175/1750 train_time:80005ms step_avg:457.17ms
[train step 175] avg_loss=5.135544 main=4.509277 aux=0.626268 imp_cv2=1.7147 load_cv2=5.9597 usage_frac=0.2902 topk_prob_mean=0.4132 ema_alpha_reverse=nan max_logit=1.2609
step:176/1750 train_time:80533ms step_avg:457.57ms
[train step 176] avg_loss=5.421111 main=4.802160 aux=0.618951 imp_cv2=1.6939 load_cv2=5.9011 usage_frac=0.3125 topk_prob_mean=0.4055 ema_alpha_reverse=nan max_logit=1.2649
step:177/1750 train_time:81086ms step_avg:458.11ms
[train step 177] avg_loss=5.097102 main=4.478044 aux=0.619058 imp_cv2=1.6892 load_cv2=5.9353 usage_frac=0.2946 topk_prob_mean=0.4038 ema_alpha_reverse=nan max_logit=1.2690
step:178/1750 train_time:81596ms step_avg:458.40ms
[train step 178] avg_loss=5.164261 main=4.541197 aux=0.623064 imp_cv2=1.6910 load_cv2=5.9634 usage_frac=0.2946 topk_prob_mean=0.4045 ema_alpha_reverse=nan max_logit=1.2733
step:179/1750 train_time:82141ms step_avg:458.89ms
[train step 179] avg_loss=5.159241 main=4.535034 aux=0.624207 imp_cv2=1.7043 load_cv2=5.9539 usage_frac=0.2991 topk_prob_mean=0.4111 ema_alpha_reverse=nan max_logit=1.2777
step:180/1750 train_time:82677ms step_avg:459.32ms
[train step 180] avg_loss=5.416360 main=4.797659 aux=0.618702 imp_cv2=1.6914 load_cv2=5.9116 usage_frac=0.2991 topk_prob_mean=0.4028 ema_alpha_reverse=nan max_logit=1.2823
step:181/1750 train_time:83214ms step_avg:459.75ms
[train step 181] avg_loss=5.312260 main=4.693579 aux=0.618681 imp_cv2=1.7287 load_cv2=5.8859 usage_frac=0.3036 topk_prob_mean=0.4185 ema_alpha_reverse=nan max_logit=1.2870
step:182/1750 train_time:83758ms step_avg:460.21ms
[train step 182] avg_loss=5.411387 main=4.792982 aux=0.618405 imp_cv2=1.6840 load_cv2=5.9370 usage_frac=0.2946 topk_prob_mean=0.3902 ema_alpha_reverse=nan max_logit=1.2919
step:183/1750 train_time:84289ms step_avg:460.60ms
[train step 183] avg_loss=5.545161 main=4.926399 aux=0.618762 imp_cv2=1.7046 load_cv2=5.9115 usage_frac=0.2902 topk_prob_mean=0.4047 ema_alpha_reverse=nan max_logit=1.2969
step:184/1750 train_time:84815ms step_avg:460.95ms
[train step 184] avg_loss=5.365169 main=4.743761 aux=0.621409 imp_cv2=1.6944 load_cv2=5.9324 usage_frac=0.2946 topk_prob_mean=0.4020 ema_alpha_reverse=nan max_logit=1.3021
step:185/1750 train_time:85338ms step_avg:461.29ms
[train step 185] avg_loss=5.258857 main=4.642655 aux=0.616202 imp_cv2=1.6945 load_cv2=5.8668 usage_frac=0.3080 topk_prob_mean=0.4046 ema_alpha_reverse=nan max_logit=1.3075
step:186/1750 train_time:85865ms step_avg:461.64ms
[train step 186] avg_loss=5.248714 main=4.619684 aux=0.629030 imp_cv2=1.7134 load_cv2=5.9830 usage_frac=0.2857 topk_prob_mean=0.4082 ema_alpha_reverse=nan max_logit=1.3130
step:187/1750 train_time:86378ms step_avg:461.92ms
[train step 187] avg_loss=5.516322 main=4.883851 aux=0.632471 imp_cv2=1.6889 load_cv2=6.0695 usage_frac=0.2991 topk_prob_mean=0.3983 ema_alpha_reverse=nan max_logit=1.3187
step:188/1750 train_time:86897ms step_avg:462.22ms
[train step 188] avg_loss=5.229072 main=4.597940 aux=0.631131 imp_cv2=1.6937 load_cv2=6.0414 usage_frac=0.2768 topk_prob_mean=0.4027 ema_alpha_reverse=nan max_logit=1.2300
step:189/1750 train_time:87415ms step_avg:462.51ms
[train step 189] avg_loss=5.603645 main=4.964194 aux=0.639451 imp_cv2=1.6961 load_cv2=6.1466 usage_frac=0.2857 topk_prob_mean=0.3980 ema_alpha_reverse=nan max_logit=1.2356
step:190/1750 train_time:87896ms step_avg:462.61ms
[train step 190] avg_loss=5.004484 main=4.377462 aux=0.627021 imp_cv2=1.6915 load_cv2=6.0089 usage_frac=0.2812 topk_prob_mean=0.4013 ema_alpha_reverse=nan max_logit=1.3370
step:191/1750 train_time:88420ms step_avg:462.93ms
[train step 191] avg_loss=5.172388 main=4.535648 aux=0.636740 imp_cv2=1.7162 load_cv2=6.0942 usage_frac=0.2857 topk_prob_mean=0.4125 ema_alpha_reverse=nan max_logit=1.2475
step:192/1750 train_time:88919ms step_avg:463.12ms
[train step 192] avg_loss=5.258780 main=4.628399 aux=0.630381 imp_cv2=1.6922 load_cv2=6.0408 usage_frac=0.2812 topk_prob_mean=0.3978 ema_alpha_reverse=nan max_logit=1.3501
step:193/1750 train_time:89427ms step_avg:463.35ms
[train step 193] avg_loss=5.253914 main=4.625651 aux=0.628263 imp_cv2=1.6984 load_cv2=6.0163 usage_frac=0.2902 topk_prob_mean=0.4036 ema_alpha_reverse=nan max_logit=1.2600
step:194/1750 train_time:89971ms step_avg:463.77ms
[train step 194] avg_loss=5.436855 main=4.816155 aux=0.620700 imp_cv2=1.7129 load_cv2=5.9328 usage_frac=0.2634 topk_prob_mean=0.3938 ema_alpha_reverse=nan max_logit=1.2666
step:195/1750 train_time:90500ms step_avg:464.10ms
[train step 195] avg_loss=5.528353 main=4.897819 aux=0.630534 imp_cv2=1.6955 load_cv2=6.0428 usage_frac=0.2902 topk_prob_mean=0.4043 ema_alpha_reverse=nan max_logit=1.2734
step:196/1750 train_time:91019ms step_avg:464.38ms
[train step 196] avg_loss=4.965404 main=4.335893 aux=0.629511 imp_cv2=1.7031 load_cv2=6.0214 usage_frac=0.2902 topk_prob_mean=0.4040 ema_alpha_reverse=nan max_logit=1.3789
step:197/1750 train_time:91529ms step_avg:464.62ms
[train step 197] avg_loss=5.037593 main=4.404764 aux=0.632829 imp_cv2=1.7048 load_cv2=6.0575 usage_frac=0.2902 topk_prob_mean=0.4024 ema_alpha_reverse=nan max_logit=1.2876
step:198/1750 train_time:92044ms step_avg:464.87ms
[train step 198] avg_loss=5.298979 main=4.665731 aux=0.633248 imp_cv2=1.7048 load_cv2=6.0660 usage_frac=0.2902 topk_prob_mean=0.4027 ema_alpha_reverse=nan max_logit=1.2950
step:199/1750 train_time:92541ms step_avg:465.03ms
[train step 199] avg_loss=5.129155 main=4.493535 aux=0.635621 imp_cv2=1.6917 load_cv2=6.1061 usage_frac=0.2902 topk_prob_mean=0.3983 ema_alpha_reverse=nan max_logit=1.3027
step:200/1750 train_time:93022ms step_avg:465.11ms
Running validation...
step:200/1750 val_loss:4.591600 train_time:93034ms step_avg:465.17ms
[train step 200] avg_loss=5.493658 main=4.851900 aux=0.641758 imp_cv2=1.7173 load_cv2=6.1542 usage_frac=0.2946 topk_prob_mean=0.4081 ema_alpha_reverse=nan max_logit=1.3106
step:201/1750 train_time:93543ms step_avg:465.39ms
[train step 201] avg_loss=5.295247 main=4.658451 aux=0.636796 imp_cv2=1.7132 load_cv2=6.0912 usage_frac=0.2946 topk_prob_mean=0.4138 ema_alpha_reverse=nan max_logit=1.3187
step:202/1750 train_time:94035ms step_avg:465.52ms
[train step 202] avg_loss=5.336272 main=4.713022 aux=0.623250 imp_cv2=1.7530 load_cv2=5.9089 usage_frac=0.2902 topk_prob_mean=0.4208 ema_alpha_reverse=nan max_logit=1.3271
step:203/1750 train_time:94518ms step_avg:465.61ms
[train step 203] avg_loss=5.141147 main=4.505278 aux=0.635870 imp_cv2=1.7190 load_cv2=6.0658 usage_frac=0.2902 topk_prob_mean=0.4100 ema_alpha_reverse=nan max_logit=1.3357
step:204/1750 train_time:95007ms step_avg:465.72ms
[train step 204] avg_loss=5.007354 main=4.359718 aux=0.647636 imp_cv2=1.7227 load_cv2=6.2003 usage_frac=0.2902 topk_prob_mean=0.4103 ema_alpha_reverse=nan max_logit=1.3446
step:205/1750 train_time:95483ms step_avg:465.77ms
[train step 205] avg_loss=5.162284 main=4.516908 aux=0.645375 imp_cv2=1.7253 load_cv2=6.1701 usage_frac=0.2991 topk_prob_mean=0.4109 ema_alpha_reverse=nan max_logit=1.3538
step:206/1750 train_time:95976ms step_avg:465.91ms
[train step 206] avg_loss=5.077376 main=4.428577 aux=0.648799 imp_cv2=1.7254 load_cv2=6.2095 usage_frac=0.3036 topk_prob_mean=0.4069 ema_alpha_reverse=nan max_logit=1.3632
step:207/1750 train_time:96454ms step_avg:465.96ms
[train step 207] avg_loss=5.137354 main=4.486992 aux=0.650362 imp_cv2=1.7085 load_cv2=6.2499 usage_frac=0.2991 topk_prob_mean=0.4008 ema_alpha_reverse=nan max_logit=1.3729
step:208/1750 train_time:96923ms step_avg:465.98ms
[train step 208] avg_loss=5.167045 main=4.511425 aux=0.655621 imp_cv2=1.7037 load_cv2=6.3141 usage_frac=0.2946 topk_prob_mean=0.3963 ema_alpha_reverse=nan max_logit=1.3830
step:209/1750 train_time:97389ms step_avg:465.98ms
[train step 209] avg_loss=5.224686 main=4.577765 aux=0.646921 imp_cv2=1.6833 load_cv2=6.2428 usage_frac=0.2902 topk_prob_mean=0.3850 ema_alpha_reverse=nan max_logit=1.3933
step:210/1750 train_time:97863ms step_avg:466.01ms
[train step 210] avg_loss=5.177301 main=4.530064 aux=0.647237 imp_cv2=1.7062 load_cv2=6.2186 usage_frac=0.2902 topk_prob_mean=0.4032 ema_alpha_reverse=nan max_logit=1.4040
step:211/1750 train_time:98326ms step_avg:466.00ms
[train step 211] avg_loss=4.992746 main=4.348005 aux=0.644741 imp_cv2=1.7047 load_cv2=6.1965 usage_frac=0.2902 topk_prob_mean=0.4006 ema_alpha_reverse=nan max_logit=1.4149
step:212/1750 train_time:98803ms step_avg:466.05ms
[train step 212] avg_loss=5.170668 main=4.523836 aux=0.646833 imp_cv2=1.7147 load_cv2=6.2070 usage_frac=0.2902 topk_prob_mean=0.4084 ema_alpha_reverse=nan max_logit=1.4262
step:213/1750 train_time:99283ms step_avg:466.12ms
[train step 213] avg_loss=5.422773 main=4.776083 aux=0.646691 imp_cv2=1.6914 load_cv2=6.2428 usage_frac=0.2946 topk_prob_mean=0.3910 ema_alpha_reverse=nan max_logit=1.4379
step:214/1750 train_time:99787ms step_avg:466.29ms
[train step 214] avg_loss=5.087246 main=4.427538 aux=0.659709 imp_cv2=1.7326 load_cv2=6.3287 usage_frac=0.2991 topk_prob_mean=0.4129 ema_alpha_reverse=nan max_logit=1.4499
step:215/1750 train_time:100243ms step_avg:466.25ms
[train step 215] avg_loss=5.295989 main=4.638398 aux=0.657591 imp_cv2=1.7147 load_cv2=6.3212 usage_frac=0.3170 topk_prob_mean=0.4092 ema_alpha_reverse=nan max_logit=1.4623
step:216/1750 train_time:100720ms step_avg:466.30ms
[train step 216] avg_loss=5.108577 main=4.451669 aux=0.656907 imp_cv2=1.7273 load_cv2=6.3087 usage_frac=0.2991 topk_prob_mean=0.4097 ema_alpha_reverse=nan max_logit=1.4750
step:217/1750 train_time:101183ms step_avg:466.28ms
[train step 217] avg_loss=5.117319 main=4.466040 aux=0.651279 imp_cv2=1.7159 load_cv2=6.2594 usage_frac=0.2991 topk_prob_mean=0.4030 ema_alpha_reverse=nan max_logit=1.4881
step:218/1750 train_time:101676ms step_avg:466.40ms
[train step 218] avg_loss=5.298621 main=4.649267 aux=0.649354 imp_cv2=1.7061 load_cv2=6.2479 usage_frac=0.2991 topk_prob_mean=0.4018 ema_alpha_reverse=nan max_logit=1.5017
step:219/1750 train_time:102178ms step_avg:466.57ms
[train step 219] avg_loss=5.223446 main=4.579653 aux=0.643793 imp_cv2=1.6996 load_cv2=6.1970 usage_frac=0.2946 topk_prob_mean=0.3972 ema_alpha_reverse=nan max_logit=1.5156
step:220/1750 train_time:102658ms step_avg:466.63ms
[train step 220] avg_loss=4.945704 main=4.289247 aux=0.656457 imp_cv2=1.6967 load_cv2=6.3310 usage_frac=0.2946 topk_prob_mean=0.3925 ema_alpha_reverse=nan max_logit=1.5300
step:221/1750 train_time:103143ms step_avg:466.71ms
[train step 221] avg_loss=5.147079 main=4.498917 aux=0.648162 imp_cv2=1.7117 load_cv2=6.2241 usage_frac=0.2812 topk_prob_mean=0.4066 ema_alpha_reverse=nan max_logit=1.5448
step:222/1750 train_time:103615ms step_avg:466.73ms
[train step 222] avg_loss=5.074298 main=4.420101 aux=0.654198 imp_cv2=1.7014 load_cv2=6.3000 usage_frac=0.2991 topk_prob_mean=0.3958 ema_alpha_reverse=nan max_logit=1.5601
step:223/1750 train_time:104107ms step_avg:466.85ms
[train step 223] avg_loss=5.428032 main=4.783585 aux=0.644448 imp_cv2=1.7020 load_cv2=6.1882 usage_frac=0.2946 topk_prob_mean=0.4052 ema_alpha_reverse=nan max_logit=1.5758
step:224/1750 train_time:104581ms step_avg:466.88ms
[train step 224] avg_loss=5.230888 main=4.573669 aux=0.657218 imp_cv2=1.7197 load_cv2=6.3152 usage_frac=0.2946 topk_prob_mean=0.4074 ema_alpha_reverse=nan max_logit=1.5921
step:225/1750 train_time:105062ms step_avg:466.94ms
[train step 225] avg_loss=5.281570 main=4.622923 aux=0.658647 imp_cv2=1.7161 load_cv2=6.3361 usage_frac=0.2946 topk_prob_mean=0.4073 ema_alpha_reverse=nan max_logit=1.6088
step:226/1750 train_time:105547ms step_avg:467.02ms
[train step 226] avg_loss=5.838014 main=5.181036 aux=0.656978 imp_cv2=1.7079 load_cv2=6.3205 usage_frac=0.2991 topk_prob_mean=0.3990 ema_alpha_reverse=nan max_logit=1.6260
step:227/1750 train_time:106007ms step_avg:466.99ms
[train step 227] avg_loss=5.160602 main=4.508318 aux=0.652284 imp_cv2=1.7025 load_cv2=6.2627 usage_frac=0.2946 topk_prob_mean=0.4048 ema_alpha_reverse=nan max_logit=1.6438
step:228/1750 train_time:106470ms step_avg:466.98ms
[train step 228] avg_loss=5.153761 main=4.492279 aux=0.661482 imp_cv2=1.7087 load_cv2=6.3689 usage_frac=0.2946 topk_prob_mean=0.4016 ema_alpha_reverse=nan max_logit=1.6622
step:229/1750 train_time:106931ms step_avg:466.95ms
[train step 229] avg_loss=5.066278 main=4.416951 aux=0.649327 imp_cv2=1.7066 load_cv2=6.2332 usage_frac=0.2991 topk_prob_mean=0.4082 ema_alpha_reverse=nan max_logit=1.6811
step:230/1750 train_time:107400ms step_avg:466.96ms
[train step 230] avg_loss=5.163331 main=4.514727 aux=0.648604 imp_cv2=1.7231 load_cv2=6.2117 usage_frac=0.3214 topk_prob_mean=0.4132 ema_alpha_reverse=nan max_logit=1.8314
step:231/1750 train_time:107876ms step_avg:467.00ms
[train step 231] avg_loss=5.053839 main=4.401604 aux=0.652235 imp_cv2=1.6994 load_cv2=6.2758 usage_frac=0.2991 topk_prob_mean=0.4006 ema_alpha_reverse=nan max_logit=1.7207
step:232/1750 train_time:108334ms step_avg:466.96ms
[train step 232] avg_loss=5.036175 main=4.378860 aux=0.657316 imp_cv2=1.6985 load_cv2=6.3330 usage_frac=0.2991 topk_prob_mean=0.3984 ema_alpha_reverse=nan max_logit=1.7415
step:233/1750 train_time:108796ms step_avg:466.94ms
[train step 233] avg_loss=5.074618 main=4.412095 aux=0.662523 imp_cv2=1.7075 load_cv2=6.3769 usage_frac=0.3036 topk_prob_mean=0.3915 ema_alpha_reverse=nan max_logit=1.7629
step:234/1750 train_time:109260ms step_avg:466.92ms
[train step 234] avg_loss=5.185453 main=4.544913 aux=0.640540 imp_cv2=2.5586 load_cv2=5.1424 usage_frac=0.4241 topk_prob_mean=0.6764 ema_alpha_reverse=nan max_logit=1.9223
step:235/1750 train_time:109860ms step_avg:467.49ms
[train step 235] avg_loss=5.671340 main=5.060686 aux=0.610654 imp_cv2=1.1151 load_cv2=6.2698 usage_frac=0.3616 topk_prob_mean=0.3529 ema_alpha_reverse=nan max_logit=1.9469
step:236/1750 train_time:110342ms step_avg:467.55ms
[train step 236] avg_loss=4.878012 main=4.272046 aux=0.605967 imp_cv2=1.0803 load_cv2=6.2471 usage_frac=0.3259 topk_prob_mean=0.3459 ema_alpha_reverse=nan max_logit=1.9722
step:237/1750 train_time:110812ms step_avg:467.56ms
[train step 237] avg_loss=4.965758 main=4.367385 aux=0.598373 imp_cv2=1.0575 load_cv2=6.1858 usage_frac=0.3348 topk_prob_mean=0.3343 ema_alpha_reverse=nan max_logit=1.9984
step:238/1750 train_time:111315ms step_avg:467.71ms
[train step 238] avg_loss=4.892551 main=4.310195 aux=0.582356 imp_cv2=1.0569 load_cv2=5.9832 usage_frac=0.3482 topk_prob_mean=0.3435 ema_alpha_reverse=nan max_logit=2.0036
step:239/1750 train_time:111820ms step_avg:467.86ms
[train step 239] avg_loss=5.066967 main=4.470140 aux=0.596827 imp_cv2=1.0709 load_cv2=6.1576 usage_frac=0.3214 topk_prob_mean=0.3428 ema_alpha_reverse=nan max_logit=2.0050
step:240/1750 train_time:112309ms step_avg:467.95ms
[train step 240] avg_loss=5.240963 main=4.642336 aux=0.598627 imp_cv2=1.0639 load_cv2=6.1796 usage_frac=0.3214 topk_prob_mean=0.3377 ema_alpha_reverse=nan max_logit=2.0821
step:241/1750 train_time:112815ms step_avg:468.11ms
[train step 241] avg_loss=4.892555 main=4.300038 aux=0.592517 imp_cv2=1.1159 load_cv2=6.0656 usage_frac=0.3259 topk_prob_mean=0.3568 ema_alpha_reverse=nan max_logit=2.1007
step:242/1750 train_time:113279ms step_avg:468.10ms
[train step 242] avg_loss=4.982459 main=4.386581 aux=0.595878 imp_cv2=1.0613 load_cv2=6.1462 usage_frac=0.3259 topk_prob_mean=0.3391 ema_alpha_reverse=nan max_logit=2.1426
step:243/1750 train_time:113774ms step_avg:468.21ms
[train step 243] avg_loss=5.033895 main=4.433487 aux=0.600407 imp_cv2=1.0992 load_cv2=6.1688 usage_frac=0.3214 topk_prob_mean=0.3497 ema_alpha_reverse=nan max_logit=2.1586
step:244/1750 train_time:114261ms step_avg:468.28ms
[train step 244] avg_loss=5.112548 main=4.507333 aux=0.605214 imp_cv2=1.0899 load_cv2=6.2351 usage_frac=0.3259 topk_prob_mean=0.3430 ema_alpha_reverse=nan max_logit=2.1859
step:245/1750 train_time:114738ms step_avg:468.32ms
[train step 245] avg_loss=4.806729 main=4.205674 aux=0.601055 imp_cv2=1.0735 load_cv2=6.1946 usage_frac=0.3348 topk_prob_mean=0.3357 ema_alpha_reverse=nan max_logit=2.2318
step:246/1750 train_time:115207ms step_avg:468.32ms
[train step 246] avg_loss=5.080577 main=4.477907 aux=0.602670 imp_cv2=1.0581 load_cv2=6.2260 usage_frac=0.3304 topk_prob_mean=0.3325 ema_alpha_reverse=nan max_logit=2.2736
step:247/1750 train_time:115689ms step_avg:468.38ms
[train step 247] avg_loss=4.706558 main=4.101383 aux=0.605175 imp_cv2=1.0795 load_cv2=6.2348 usage_frac=0.3214 topk_prob_mean=0.3366 ema_alpha_reverse=nan max_logit=2.3122
step:248/1750 train_time:116180ms step_avg:468.47ms
[train step 248] avg_loss=5.016834 main=4.410465 aux=0.606370 imp_cv2=1.0681 load_cv2=6.2626 usage_frac=0.3259 topk_prob_mean=0.3321 ema_alpha_reverse=nan max_logit=2.3484
step:249/1750 train_time:116659ms step_avg:468.51ms
[train step 249] avg_loss=4.735214 main=4.120457 aux=0.614757 imp_cv2=1.0765 load_cv2=6.3557 usage_frac=0.3170 topk_prob_mean=0.3315 ema_alpha_reverse=nan max_logit=2.3381
step:250/1750 train_time:117118ms step_avg:468.47ms
Running validation...
step:250/1750 val_loss:4.367580 train_time:117130ms step_avg:468.52ms
[train step 250] avg_loss=4.874791 main=4.268923 aux=0.605868 imp_cv2=1.0645 load_cv2=6.2546 usage_frac=0.3304 topk_prob_mean=0.3307 ema_alpha_reverse=nan max_logit=2.3943
step:251/1750 train_time:117592ms step_avg:468.50ms
[train step 251] avg_loss=5.006620 main=4.401118 aux=0.605503 imp_cv2=1.0908 load_cv2=6.2363 usage_frac=0.3125 topk_prob_mean=0.3398 ema_alpha_reverse=nan max_logit=2.3547
step:252/1750 train_time:118048ms step_avg:468.45ms
[train step 252] avg_loss=5.397186 main=4.792195 aux=0.604991 imp_cv2=1.0617 load_cv2=6.2498 usage_frac=0.3125 topk_prob_mean=0.3254 ema_alpha_reverse=nan max_logit=2.3770
step:253/1750 train_time:118510ms step_avg:468.42ms
[train step 253] avg_loss=4.802711 main=4.197473 aux=0.605238 imp_cv2=1.1061 load_cv2=6.2055 usage_frac=0.3125 topk_prob_mean=0.3459 ema_alpha_reverse=nan max_logit=2.4778
step:254/1750 train_time:118987ms step_avg:468.45ms
[train step 254] avg_loss=4.913946 main=4.307545 aux=0.606401 imp_cv2=1.0812 load_cv2=6.2466 usage_frac=0.3259 topk_prob_mean=0.3395 ema_alpha_reverse=nan max_logit=2.5060
step:255/1750 train_time:119472ms step_avg:468.52ms
[train step 255] avg_loss=5.044206 main=4.437515 aux=0.606691 imp_cv2=1.0881 load_cv2=6.2457 usage_frac=0.3080 topk_prob_mean=0.3402 ema_alpha_reverse=nan max_logit=2.5681
step:256/1750 train_time:119944ms step_avg:468.53ms
[train step 256] avg_loss=4.752061 main=4.142162 aux=0.609899 imp_cv2=1.0830 load_cv2=6.2912 usage_frac=0.3170 topk_prob_mean=0.3348 ema_alpha_reverse=nan max_logit=2.5860
step:257/1750 train_time:120412ms step_avg:468.53ms
[train step 257] avg_loss=5.037678 main=4.428971 aux=0.608707 imp_cv2=1.0952 load_cv2=6.2637 usage_frac=0.3125 topk_prob_mean=0.3442 ema_alpha_reverse=nan max_logit=2.6466
step:258/1750 train_time:120879ms step_avg:468.52ms
[train step 258] avg_loss=5.094545 main=4.487487 aux=0.607058 imp_cv2=1.0633 load_cv2=6.2737 usage_frac=0.3259 topk_prob_mean=0.3329 ema_alpha_reverse=nan max_logit=2.6675
step:259/1750 train_time:121342ms step_avg:468.50ms
[train step 259] avg_loss=4.836738 main=4.228861 aux=0.607878 imp_cv2=1.0675 load_cv2=6.2759 usage_frac=0.3170 topk_prob_mean=0.3335 ema_alpha_reverse=nan max_logit=2.7231
step:260/1750 train_time:121823ms step_avg:468.55ms
[train step 260] avg_loss=5.039937 main=4.424139 aux=0.615799 imp_cv2=1.0671 load_cv2=6.3613 usage_frac=0.3170 topk_prob_mean=0.3291 ema_alpha_reverse=nan max_logit=2.7846
step:261/1750 train_time:122271ms step_avg:468.47ms
[train step 261] avg_loss=4.842774 main=4.230466 aux=0.612307 imp_cv2=1.0794 load_cv2=6.3109 usage_frac=0.3214 topk_prob_mean=0.3379 ema_alpha_reverse=nan max_logit=2.8997
step:262/1750 train_time:122739ms step_avg:468.47ms
[train step 262] avg_loss=4.942485 main=4.332970 aux=0.609515 imp_cv2=1.0529 load_cv2=6.3059 usage_frac=0.3080 topk_prob_mean=0.3206 ema_alpha_reverse=nan max_logit=2.9697
step:263/1750 train_time:123194ms step_avg:468.42ms
[train step 263] avg_loss=5.048764 main=4.439931 aux=0.608832 imp_cv2=1.0537 load_cv2=6.2958 usage_frac=0.3080 topk_prob_mean=0.3248 ema_alpha_reverse=nan max_logit=3.0980
step:264/1750 train_time:123659ms step_avg:468.41ms
[train step 264] avg_loss=4.758871 main=4.151263 aux=0.607608 imp_cv2=1.0688 load_cv2=6.2669 usage_frac=0.3170 topk_prob_mean=0.3335 ema_alpha_reverse=nan max_logit=3.1636
step:265/1750 train_time:124121ms step_avg:468.38ms
[train step 265] avg_loss=4.848123 main=4.247093 aux=0.601030 imp_cv2=1.0642 load_cv2=6.1814 usage_frac=0.3125 topk_prob_mean=0.3343 ema_alpha_reverse=nan max_logit=3.2317
step:266/1750 train_time:124579ms step_avg:468.34ms
[train step 266] avg_loss=4.797910 main=4.192717 aux=0.605193 imp_cv2=1.0898 load_cv2=6.2229 usage_frac=0.3214 topk_prob_mean=0.3439 ema_alpha_reverse=nan max_logit=3.3024
step:267/1750 train_time:125050ms step_avg:468.35ms
[train step 267] avg_loss=4.964455 main=4.355130 aux=0.609324 imp_cv2=1.0879 load_cv2=6.2632 usage_frac=0.3170 topk_prob_mean=0.3413 ema_alpha_reverse=nan max_logit=3.3758
step:268/1750 train_time:125497ms step_avg:468.27ms
[train step 268] avg_loss=4.668085 main=4.060834 aux=0.607251 imp_cv2=1.1056 load_cv2=6.2191 usage_frac=0.3214 topk_prob_mean=0.3504 ema_alpha_reverse=nan max_logit=3.4520
step:269/1750 train_time:125949ms step_avg:468.21ms
[train step 269] avg_loss=4.710139 main=4.099789 aux=0.610350 imp_cv2=1.0952 load_cv2=6.2666 usage_frac=0.3125 topk_prob_mean=0.3453 ema_alpha_reverse=nan max_logit=3.5311
step:270/1750 train_time:126392ms step_avg:468.12ms
[train step 270] avg_loss=4.532488 main=3.910200 aux=0.622287 imp_cv2=1.0456 load_cv2=6.4445 usage_frac=0.2589 topk_prob_mean=0.3008 ema_alpha_reverse=nan max_logit=2.3229
step:271/1750 train_time:126835ms step_avg:468.02ms
[train step 271] avg_loss=4.864439 main=4.240309 aux=0.624130 imp_cv2=1.0826 load_cv2=6.4496 usage_frac=0.3080 topk_prob_mean=0.3272 ema_alpha_reverse=nan max_logit=3.6864
step:272/1750 train_time:127283ms step_avg:467.95ms
[train step 272] avg_loss=4.717583 main=4.102579 aux=0.615003 imp_cv2=1.0940 load_cv2=6.3228 usage_frac=0.3125 topk_prob_mean=0.3428 ema_alpha_reverse=nan max_logit=3.7877
step:273/1750 train_time:127743ms step_avg:467.92ms
[train step 273] avg_loss=4.899616 main=4.292556 aux=0.607060 imp_cv2=1.1137 load_cv2=6.2136 usage_frac=0.3214 topk_prob_mean=0.3535 ema_alpha_reverse=nan max_logit=3.8801
step:274/1750 train_time:128197ms step_avg:467.87ms
[train step 274] avg_loss=4.803711 main=4.196209 aux=0.607501 imp_cv2=1.0464 load_cv2=6.2725 usage_frac=0.3259 topk_prob_mean=0.3242 ema_alpha_reverse=nan max_logit=3.9762
step:275/1750 train_time:128651ms step_avg:467.82ms
[train step 275] avg_loss=4.910809 main=4.299117 aux=0.611692 imp_cv2=1.0561 load_cv2=6.3174 usage_frac=0.3080 topk_prob_mean=0.3272 ema_alpha_reverse=nan max_logit=4.0763
step:276/1750 train_time:129099ms step_avg:467.75ms
[train step 276] avg_loss=4.959723 main=4.348009 aux=0.611715 imp_cv2=1.0450 load_cv2=6.3220 usage_frac=0.3080 topk_prob_mean=0.3181 ema_alpha_reverse=nan max_logit=4.1053
step:277/1750 train_time:129557ms step_avg:467.71ms
[train step 277] avg_loss=4.663307 main=4.052532 aux=0.610774 imp_cv2=1.1007 load_cv2=6.2703 usage_frac=0.3125 topk_prob_mean=0.3459 ema_alpha_reverse=nan max_logit=4.2888
step:278/1750 train_time:130007ms step_avg:467.65ms
[train step 278] avg_loss=4.721332 main=4.105502 aux=0.615830 imp_cv2=1.0522 load_cv2=6.3772 usage_frac=0.3170 topk_prob_mean=0.3206 ema_alpha_reverse=nan max_logit=4.4017
step:279/1750 train_time:130444ms step_avg:467.54ms
[train step 279] avg_loss=4.821266 main=4.209781 aux=0.611485 imp_cv2=1.0856 load_cv2=6.2882 usage_frac=0.3080 topk_prob_mean=0.3385 ema_alpha_reverse=nan max_logit=4.5193
step:280/1750 train_time:130894ms step_avg:467.48ms
[train step 280] avg_loss=4.775086 main=4.155674 aux=0.619412 imp_cv2=1.0782 load_cv2=6.3949 usage_frac=0.3080 topk_prob_mean=0.3290 ema_alpha_reverse=nan max_logit=4.6233
step:281/1750 train_time:131348ms step_avg:467.43ms
[train step 281] avg_loss=4.847856 main=4.234674 aux=0.613183 imp_cv2=1.0724 load_cv2=6.3167 usage_frac=0.3170 topk_prob_mean=0.3345 ema_alpha_reverse=nan max_logit=4.7696
step:282/1750 train_time:131810ms step_avg:467.41ms
[train step 282] avg_loss=4.678923 main=4.066504 aux=0.612419 imp_cv2=1.0905 load_cv2=6.2961 usage_frac=0.3259 topk_prob_mean=0.3432 ema_alpha_reverse=nan max_logit=4.9029
step:283/1750 train_time:132265ms step_avg:467.37ms
[train step 283] avg_loss=4.703316 main=4.084949 aux=0.618367 imp_cv2=1.0763 load_cv2=6.3826 usage_frac=0.3214 topk_prob_mean=0.3332 ema_alpha_reverse=nan max_logit=5.0120
step:284/1750 train_time:132713ms step_avg:467.30ms
[train step 284] avg_loss=4.837285 main=4.225211 aux=0.612074 imp_cv2=1.1115 load_cv2=6.2727 usage_frac=0.3125 topk_prob_mean=0.3496 ema_alpha_reverse=nan max_logit=5.1869
step:285/1750 train_time:133166ms step_avg:467.25ms
[train step 285] avg_loss=4.846605 main=4.238211 aux=0.608393 imp_cv2=1.1017 load_cv2=6.2422 usage_frac=0.3214 topk_prob_mean=0.3494 ema_alpha_reverse=nan max_logit=5.3359
step:286/1750 train_time:133617ms step_avg:467.19ms
[train step 286] avg_loss=4.857539 main=4.252837 aux=0.604702 imp_cv2=1.0918 load_cv2=6.2076 usage_frac=0.3170 topk_prob_mean=0.3417 ema_alpha_reverse=nan max_logit=5.4605
step:287/1750 train_time:134076ms step_avg:467.16ms
[train step 287] avg_loss=4.698603 main=4.088537 aux=0.610066 imp_cv2=1.0883 load_cv2=6.2686 usage_frac=0.3214 topk_prob_mean=0.3411 ema_alpha_reverse=nan max_logit=5.6182
step:288/1750 train_time:134515ms step_avg:467.07ms
[train step 288] avg_loss=4.829310 main=4.219536 aux=0.609773 imp_cv2=1.0707 load_cv2=6.2931 usage_frac=0.3125 topk_prob_mean=0.3348 ema_alpha_reverse=nan max_logit=5.8341
step:289/1750 train_time:134962ms step_avg:467.00ms
[train step 289] avg_loss=4.674478 main=4.068355 aux=0.606123 imp_cv2=1.1041 load_cv2=6.2176 usage_frac=0.3259 topk_prob_mean=0.3478 ema_alpha_reverse=nan max_logit=6.0145
step:290/1750 train_time:135412ms step_avg:466.94ms
[train step 290] avg_loss=4.643566 main=4.041754 aux=0.601812 imp_cv2=1.0648 load_cv2=6.2013 usage_frac=0.3259 topk_prob_mean=0.3342 ema_alpha_reverse=nan max_logit=6.1851
step:291/1750 train_time:135861ms step_avg:466.88ms
[train step 291] avg_loss=4.828747 main=4.227624 aux=0.601123 imp_cv2=1.0824 load_cv2=6.1813 usage_frac=0.3214 topk_prob_mean=0.3424 ema_alpha_reverse=nan max_logit=6.3585
step:292/1750 train_time:136318ms step_avg:466.84ms
[train step 292] avg_loss=4.616273 main=4.013481 aux=0.602792 imp_cv2=1.0769 load_cv2=6.2015 usage_frac=0.3214 topk_prob_mean=0.3410 ema_alpha_reverse=nan max_logit=6.5715
step:293/1750 train_time:136766ms step_avg:466.78ms
[train step 293] avg_loss=4.593084 main=3.971578 aux=0.621506 imp_cv2=1.0449 load_cv2=6.4333 usage_frac=0.2545 topk_prob_mean=0.3015 ema_alpha_reverse=nan max_logit=4.0088
step:294/1750 train_time:137249ms step_avg:466.83ms
[train step 294] avg_loss=5.063670 main=4.454647 aux=0.609024 imp_cv2=1.0635 load_cv2=6.2869 usage_frac=0.3214 topk_prob_mean=0.3267 ema_alpha_reverse=nan max_logit=6.9632
step:295/1750 train_time:137687ms step_avg:466.74ms
[train step 295] avg_loss=4.878915 main=4.278496 aux=0.600419 imp_cv2=1.0687 load_cv2=6.1775 usage_frac=0.3214 topk_prob_mean=0.3354 ema_alpha_reverse=nan max_logit=7.2380
step:296/1750 train_time:138135ms step_avg:466.67ms
[train step 296] avg_loss=4.725040 main=4.119354 aux=0.605686 imp_cv2=1.1206 load_cv2=6.1885 usage_frac=0.3170 topk_prob_mean=0.3509 ema_alpha_reverse=nan max_logit=7.4207
step:297/1750 train_time:138590ms step_avg:466.63ms
[train step 297] avg_loss=4.798574 main=4.194701 aux=0.603872 imp_cv2=1.1170 load_cv2=6.1707 usage_frac=0.3259 topk_prob_mean=0.3530 ema_alpha_reverse=nan max_logit=7.7298
step:298/1750 train_time:139065ms step_avg:466.66ms
[train step 298] avg_loss=4.919362 main=4.314474 aux=0.604888 imp_cv2=1.1521 load_cv2=6.1519 usage_frac=0.3482 topk_prob_mean=0.3627 ema_alpha_reverse=nan max_logit=7.9418
step:299/1750 train_time:139539ms step_avg:466.69ms
[train step 299] avg_loss=4.644461 main=4.042300 aux=0.602161 imp_cv2=1.1247 load_cv2=6.1501 usage_frac=0.3214 topk_prob_mean=0.3604 ema_alpha_reverse=nan max_logit=8.3466
step:300/1750 train_time:140003ms step_avg:466.68ms
Running validation...
step:300/1750 val_loss:4.210003 train_time:140014ms step_avg:466.71ms
[train step 300] avg_loss=5.045024 main=4.440821 aux=0.604203 imp_cv2=1.0673 load_cv2=6.2174 usage_frac=0.3393 topk_prob_mean=0.3414 ema_alpha_reverse=nan max_logit=8.4976
step:301/1750 train_time:140463ms step_avg:466.65ms
[train step 301] avg_loss=4.955477 main=4.349717 aux=0.605760 imp_cv2=1.1066 load_cv2=6.2098 usage_frac=0.3304 topk_prob_mean=0.3560 ema_alpha_reverse=nan max_logit=8.7619
step:302/1750 train_time:140920ms step_avg:466.62ms
[train step 302] avg_loss=4.782957 main=4.180403 aux=0.602554 imp_cv2=1.1056 load_cv2=6.1735 usage_frac=0.3393 topk_prob_mean=0.3542 ema_alpha_reverse=nan max_logit=9.1051
step:303/1750 train_time:141373ms step_avg:466.58ms
[train step 303] avg_loss=4.760916 main=4.155272 aux=0.605644 imp_cv2=1.0873 load_cv2=6.2248 usage_frac=0.3259 topk_prob_mean=0.3443 ema_alpha_reverse=nan max_logit=9.4528
step:304/1750 train_time:141824ms step_avg:466.53ms
[train step 304] avg_loss=4.573928 main=3.971816 aux=0.602112 imp_cv2=1.1145 load_cv2=6.1585 usage_frac=0.3259 topk_prob_mean=0.3588 ema_alpha_reverse=nan max_logit=9.7614
step:305/1750 train_time:142286ms step_avg:466.51ms
[train step 305] avg_loss=4.706142 main=4.102862 aux=0.603279 imp_cv2=1.0782 load_cv2=6.2049 usage_frac=0.3125 topk_prob_mean=0.3470 ema_alpha_reverse=nan max_logit=10.1474
step:306/1750 train_time:142736ms step_avg:466.46ms
[train step 306] avg_loss=5.077762 main=4.479991 aux=0.597771 imp_cv2=1.0700 load_cv2=6.1457 usage_frac=0.3348 topk_prob_mean=0.3423 ema_alpha_reverse=nan max_logit=10.6384
step:307/1750 train_time:143212ms step_avg:466.49ms
[train step 307] avg_loss=5.259559 main=4.648931 aux=0.610628 imp_cv2=1.0826 load_cv2=6.2865 usage_frac=0.3214 topk_prob_mean=0.3415 ema_alpha_reverse=nan max_logit=11.0408
step:308/1750 train_time:143667ms step_avg:466.45ms
[train step 308] avg_loss=4.290797 main=3.679384 aux=0.611412 imp_cv2=1.0490 load_cv2=6.3211 usage_frac=0.3125 topk_prob_mean=0.3268 ema_alpha_reverse=nan max_logit=11.0468
step:309/1750 train_time:144118ms step_avg:466.40ms
[train step 309] avg_loss=4.719328 main=4.107205 aux=0.612122 imp_cv2=1.0492 load_cv2=6.3236 usage_frac=0.3304 topk_prob_mean=0.3279 ema_alpha_reverse=nan max_logit=11.7467
step:310/1750 train_time:144564ms step_avg:466.34ms
[train step 310] avg_loss=4.612073 main=4.010070 aux=0.602003 imp_cv2=1.1257 load_cv2=6.1483 usage_frac=0.3438 topk_prob_mean=0.3642 ema_alpha_reverse=nan max_logit=12.2604
step:311/1750 train_time:145021ms step_avg:466.31ms
[train step 311] avg_loss=4.741896 main=4.137097 aux=0.604799 imp_cv2=1.0988 load_cv2=6.1975 usage_frac=0.3482 topk_prob_mean=0.3535 ema_alpha_reverse=nan max_logit=12.7874
step:312/1750 train_time:145478ms step_avg:466.28ms
[train step 312] avg_loss=4.734243 main=4.126883 aux=0.607360 imp_cv2=1.1339 load_cv2=6.2013 usage_frac=0.3304 topk_prob_mean=0.3600 ema_alpha_reverse=nan max_logit=13.2422
step:313/1750 train_time:145934ms step_avg:466.24ms
[train step 313] avg_loss=4.668442 main=4.070121 aux=0.598321 imp_cv2=1.0918 load_cv2=6.1310 usage_frac=0.3304 topk_prob_mean=0.3522 ema_alpha_reverse=nan max_logit=13.2820
step:314/1750 train_time:146393ms step_avg:466.22ms
[train step 314] avg_loss=4.559376 main=3.959746 aux=0.599630 imp_cv2=1.0992 load_cv2=6.1391 usage_frac=0.3393 topk_prob_mean=0.3551 ema_alpha_reverse=nan max_logit=13.4904
step:315/1750 train_time:146860ms step_avg:466.22ms
[train step 315] avg_loss=5.006167 main=4.403158 aux=0.603008 imp_cv2=1.0685 load_cv2=6.2013 usage_frac=0.3259 topk_prob_mean=0.3433 ema_alpha_reverse=nan max_logit=13.5790
step:316/1750 train_time:147330ms step_avg:466.24ms
[train step 316] avg_loss=4.668713 main=4.071448 aux=0.597265 imp_cv2=1.0644 load_cv2=6.1320 usage_frac=0.3348 topk_prob_mean=0.3427 ema_alpha_reverse=nan max_logit=13.6235
step:317/1750 train_time:147785ms step_avg:466.20ms
[train step 317] avg_loss=4.598639 main=4.001441 aux=0.597198 imp_cv2=1.0867 load_cv2=6.1209 usage_frac=0.3527 topk_prob_mean=0.3480 ema_alpha_reverse=nan max_logit=13.6769
step:318/1750 train_time:148245ms step_avg:466.18ms
[train step 318] avg_loss=4.946011 main=4.343769 aux=0.602242 imp_cv2=1.1091 load_cv2=6.1638 usage_frac=0.3348 topk_prob_mean=0.3527 ema_alpha_reverse=nan max_logit=13.6649
step:319/1750 train_time:148698ms step_avg:466.14ms
[train step 319] avg_loss=4.628316 main=4.029140 aux=0.599176 imp_cv2=1.1399 load_cv2=6.0986 usage_frac=0.3571 topk_prob_mean=0.3625 ema_alpha_reverse=nan max_logit=13.6752
step:320/1750 train_time:149170ms step_avg:466.16ms
[train step 320] avg_loss=4.585224 main=3.978996 aux=0.606227 imp_cv2=1.0844 load_cv2=6.2310 usage_frac=0.3482 topk_prob_mean=0.3414 ema_alpha_reverse=nan max_logit=13.6535
step:321/1750 train_time:149625ms step_avg:466.12ms
[train step 321] avg_loss=4.822288 main=4.223811 aux=0.598477 imp_cv2=1.0637 load_cv2=6.1519 usage_frac=0.3214 topk_prob_mean=0.3378 ema_alpha_reverse=nan max_logit=13.7570
step:322/1750 train_time:150091ms step_avg:466.12ms
[train step 322] avg_loss=4.605856 main=4.006854 aux=0.599002 imp_cv2=1.0611 load_cv2=6.1621 usage_frac=0.3438 topk_prob_mean=0.3398 ema_alpha_reverse=nan max_logit=13.6058
step:323/1750 train_time:150552ms step_avg:466.11ms
[train step 323] avg_loss=4.939294 main=4.318144 aux=0.621150 imp_cv2=1.1725 load_cv2=6.3350 usage_frac=0.2723 topk_prob_mean=0.3194 ema_alpha_reverse=nan max_logit=8.6187
step:324/1750 train_time:151019ms step_avg:466.11ms
[train step 324] avg_loss=4.770856 main=4.165745 aux=0.605111 imp_cv2=1.0460 load_cv2=6.2473 usage_frac=0.3527 topk_prob_mean=0.3307 ema_alpha_reverse=nan max_logit=13.5804
step:325/1750 train_time:151473ms step_avg:466.07ms
[train step 325] avg_loss=4.513718 main=3.919174 aux=0.594544 imp_cv2=1.0866 load_cv2=6.0815 usage_frac=0.3393 topk_prob_mean=0.3538 ema_alpha_reverse=nan max_logit=13.6593
step:326/1750 train_time:151934ms step_avg:466.06ms
[train step 326] avg_loss=4.705469 main=4.107661 aux=0.597808 imp_cv2=1.1013 load_cv2=6.1099 usage_frac=0.3482 topk_prob_mean=0.3586 ema_alpha_reverse=nan max_logit=13.6441
step:327/1750 train_time:152398ms step_avg:466.05ms
[train step 327] avg_loss=4.683162 main=4.077435 aux=0.605727 imp_cv2=1.0722 load_cv2=6.2305 usage_frac=0.3571 topk_prob_mean=0.3427 ema_alpha_reverse=nan max_logit=13.5294
step:328/1750 train_time:152857ms step_avg:466.03ms
[train step 328] avg_loss=4.817741 main=4.214959 aux=0.602783 imp_cv2=1.0519 load_cv2=6.2114 usage_frac=0.3393 topk_prob_mean=0.3364 ema_alpha_reverse=nan max_logit=13.4816
step:329/1750 train_time:153327ms step_avg:466.04ms
[train step 329] avg_loss=4.682003 main=4.066784 aux=0.615219 imp_cv2=1.0338 load_cv2=6.3694 usage_frac=0.3527 topk_prob_mean=0.3150 ema_alpha_reverse=nan max_logit=13.4330
step:330/1750 train_time:154003ms step_avg:466.67ms
[train step 330] avg_loss=4.559257 main=3.957021 aux=0.602236 imp_cv2=1.0723 load_cv2=6.1871 usage_frac=0.3482 topk_prob_mean=0.3467 ema_alpha_reverse=nan max_logit=13.4110
step:331/1750 train_time:154472ms step_avg:466.68ms
[train step 331] avg_loss=4.602587 main=3.998702 aux=0.603885 imp_cv2=1.0851 load_cv2=6.2028 usage_frac=0.3571 topk_prob_mean=0.3464 ema_alpha_reverse=nan max_logit=13.3557
step:332/1750 train_time:154928ms step_avg:466.65ms
[train step 332] avg_loss=4.727864 main=4.131681 aux=0.596183 imp_cv2=1.0503 load_cv2=6.1249 usage_frac=0.3616 topk_prob_mean=0.3377 ema_alpha_reverse=nan max_logit=13.3176
step:333/1750 train_time:155412ms step_avg:466.70ms
[train step 333] avg_loss=4.749927 main=4.139085 aux=0.610842 imp_cv2=1.0562 load_cv2=6.2968 usage_frac=0.3482 topk_prob_mean=0.3329 ema_alpha_reverse=nan max_logit=13.2736
step:334/1750 train_time:155866ms step_avg:466.67ms
[train step 334] avg_loss=4.674405 main=4.065033 aux=0.609372 imp_cv2=1.1033 load_cv2=6.2525 usage_frac=0.3482 topk_prob_mean=0.3467 ema_alpha_reverse=nan max_logit=13.3423
step:335/1750 train_time:156344ms step_avg:466.70ms
[train step 335] avg_loss=4.494368 main=3.902338 aux=0.592030 imp_cv2=1.1116 load_cv2=6.0327 usage_frac=0.3393 topk_prob_mean=0.3594 ema_alpha_reverse=nan max_logit=13.4969
step:336/1750 train_time:156820ms step_avg:466.73ms
[train step 336] avg_loss=4.015447 main=3.419615 aux=0.595832 imp_cv2=1.1065 load_cv2=6.0338 usage_frac=0.3304 topk_prob_mean=0.3308 ema_alpha_reverse=nan max_logit=10.1683
step:337/1750 train_time:157284ms step_avg:466.72ms
[train step 337] avg_loss=4.540964 main=3.937292 aux=0.603672 imp_cv2=1.0431 load_cv2=6.2170 usage_frac=0.3259 topk_prob_mean=0.3156 ema_alpha_reverse=nan max_logit=13.5423
step:338/1750 train_time:157741ms step_avg:466.69ms
[train step 338] avg_loss=5.202243 main=4.344622 aux=0.857621 imp_cv2=4.6862 load_cv2=5.5203 usage_frac=0.4286 topk_prob_mean=0.8887 ema_alpha_reverse=nan max_logit=13.7570
step:339/1750 train_time:158272ms step_avg:466.88ms
[train step 339] avg_loss=4.921237 main=4.395958 aux=0.525279 imp_cv2=2.0477 load_cv2=4.1678 usage_frac=0.4286 topk_prob_mean=0.5758 ema_alpha_reverse=nan max_logit=13.7570
step:340/1750 train_time:158853ms step_avg:467.21ms
[train step 340] avg_loss=5.276713 main=4.690760 aux=0.585953 imp_cv2=1.1975 load_cv2=5.7907 usage_frac=0.4464 topk_prob_mean=0.3731 ema_alpha_reverse=nan max_logit=13.7570
step:341/1750 train_time:159566ms step_avg:467.94ms
[train step 341] avg_loss=4.729289 main=4.190884 aux=0.538404 imp_cv2=0.8851 load_cv2=5.5457 usage_frac=0.4152 topk_prob_mean=0.3651 ema_alpha_reverse=nan max_logit=13.7570
step:342/1750 train_time:160093ms step_avg:468.11ms
[train step 342] avg_loss=4.482148 main=3.940239 aux=0.541909 imp_cv2=0.6968 load_cv2=5.7772 usage_frac=0.3750 topk_prob_mean=0.3202 ema_alpha_reverse=nan max_logit=13.7570
step:343/1750 train_time:160611ms step_avg:468.25ms
[train step 343] avg_loss=5.023571 main=4.472526 aux=0.551045 imp_cv2=0.6980 load_cv2=5.8936 usage_frac=0.3795 topk_prob_mean=0.3207 ema_alpha_reverse=nan max_logit=13.7570
step:344/1750 train_time:161093ms step_avg:468.29ms
[train step 344] avg_loss=4.785856 main=4.215471 aux=0.570385 imp_cv2=0.6769 load_cv2=6.1161 usage_frac=0.3527 topk_prob_mean=0.2952 ema_alpha_reverse=nan max_logit=13.7570
step:345/1750 train_time:161577ms step_avg:468.34ms
[train step 345] avg_loss=4.353221 main=3.799021 aux=0.554200 imp_cv2=0.6857 load_cv2=5.9312 usage_frac=0.3482 topk_prob_mean=0.3196 ema_alpha_reverse=nan max_logit=13.7570
step:346/1750 train_time:162063ms step_avg:468.39ms
[train step 346] avg_loss=4.704792 main=4.149990 aux=0.554802 imp_cv2=0.6755 load_cv2=5.9468 usage_frac=0.3795 topk_prob_mean=0.3134 ema_alpha_reverse=nan max_logit=13.7570
step:347/1750 train_time:162549ms step_avg:468.44ms
[train step 347] avg_loss=4.500686 main=3.942296 aux=0.558390 imp_cv2=0.7735 load_cv2=5.9072 usage_frac=0.3527 topk_prob_mean=0.3378 ema_alpha_reverse=nan max_logit=13.7570
step:348/1750 train_time:163024ms step_avg:468.46ms
[train step 348] avg_loss=4.489154 main=3.936038 aux=0.553116 imp_cv2=0.7090 load_cv2=5.8927 usage_frac=0.3661 topk_prob_mean=0.3256 ema_alpha_reverse=nan max_logit=13.7570
step:349/1750 train_time:163688ms step_avg:469.02ms
[train step 349] avg_loss=4.841683 main=4.278693 aux=0.562990 imp_cv2=0.6623 load_cv2=6.0467 usage_frac=0.3527 topk_prob_mean=0.3053 ema_alpha_reverse=nan max_logit=13.7570
step:350/1750 train_time:164170ms step_avg:469.06ms
Running validation...
step:350/1750 val_loss:4.117845 train_time:164181ms step_avg:469.09ms
[train step 350] avg_loss=4.660513 main=4.091241 aux=0.569272 imp_cv2=0.6917 load_cv2=6.0933 usage_frac=0.3393 topk_prob_mean=0.3138 ema_alpha_reverse=nan max_logit=13.7570
step:351/1750 train_time:164637ms step_avg:469.05ms
[train step 351] avg_loss=4.702115 main=4.136542 aux=0.565574 imp_cv2=0.6885 load_cv2=6.0523 usage_frac=0.3527 topk_prob_mean=0.3123 ema_alpha_reverse=nan max_logit=13.7570
step:352/1750 train_time:165105ms step_avg:469.05ms
[train step 352] avg_loss=4.542299 main=3.983273 aux=0.559026 imp_cv2=0.7198 load_cv2=5.9527 usage_frac=0.3527 topk_prob_mean=0.3213 ema_alpha_reverse=nan max_logit=13.7570
step:353/1750 train_time:165572ms step_avg:469.04ms
[train step 353] avg_loss=4.454571 main=3.893494 aux=0.561077 imp_cv2=0.7452 load_cv2=5.9551 usage_frac=0.3482 topk_prob_mean=0.3252 ema_alpha_reverse=nan max_logit=13.7570
step:354/1750 train_time:166052ms step_avg:469.07ms
[train step 354] avg_loss=4.725569 main=4.168280 aux=0.557289 imp_cv2=0.7205 load_cv2=5.9214 usage_frac=0.3482 topk_prob_mean=0.3225 ema_alpha_reverse=nan max_logit=13.7570
step:355/1750 train_time:166502ms step_avg:469.02ms
[train step 355] avg_loss=4.831500 main=4.273238 aux=0.558263 imp_cv2=0.7001 load_cv2=5.9539 usage_frac=0.3616 topk_prob_mean=0.3107 ema_alpha_reverse=nan max_logit=13.7570
step:356/1750 train_time:166970ms step_avg:469.02ms
[train step 356] avg_loss=4.422390 main=3.862624 aux=0.559766 imp_cv2=0.6892 load_cv2=5.9744 usage_frac=0.3482 topk_prob_mean=0.3094 ema_alpha_reverse=nan max_logit=13.7570
step:357/1750 train_time:167436ms step_avg:469.01ms
[train step 357] avg_loss=4.757434 main=4.192586 aux=0.564848 imp_cv2=0.6918 load_cv2=6.0384 usage_frac=0.3304 topk_prob_mean=0.3052 ema_alpha_reverse=nan max_logit=13.7570
step:358/1750 train_time:167899ms step_avg:468.99ms
[train step 358] avg_loss=5.076940 main=4.528199 aux=0.548741 imp_cv2=0.6761 load_cv2=5.8607 usage_frac=0.3482 topk_prob_mean=0.3138 ema_alpha_reverse=nan max_logit=13.7570
step:359/1750 train_time:168370ms step_avg:469.00ms
[train step 359] avg_loss=4.849471 main=4.276828 aux=0.572643 imp_cv2=0.6410 load_cv2=6.1673 usage_frac=0.3348 topk_prob_mean=0.2713 ema_alpha_reverse=nan max_logit=13.5149
step:360/1750 train_time:168849ms step_avg:469.02ms
[train step 360] avg_loss=4.528892 main=3.980783 aux=0.548108 imp_cv2=0.7578 load_cv2=5.7874 usage_frac=0.3661 topk_prob_mean=0.3392 ema_alpha_reverse=nan max_logit=13.7570
step:361/1750 train_time:169339ms step_avg:469.08ms
[train step 361] avg_loss=4.950572 main=4.392032 aux=0.558540 imp_cv2=0.6574 load_cv2=5.9928 usage_frac=0.3527 topk_prob_mean=0.2985 ema_alpha_reverse=nan max_logit=13.7570
step:362/1750 train_time:169823ms step_avg:469.12ms
[train step 362] avg_loss=4.938385 main=4.379298 aux=0.559087 imp_cv2=0.6880 load_cv2=5.9834 usage_frac=0.3661 topk_prob_mean=0.3093 ema_alpha_reverse=nan max_logit=13.7570
step:363/1750 train_time:170283ms step_avg:469.10ms
[train step 363] avg_loss=4.669187 main=4.106743 aux=0.562444 imp_cv2=0.6728 load_cv2=6.0305 usage_frac=0.3348 topk_prob_mean=0.3032 ema_alpha_reverse=nan max_logit=13.7570
step:364/1750 train_time:170741ms step_avg:469.07ms
[train step 364] avg_loss=5.089201 main=4.534316 aux=0.554886 imp_cv2=0.6795 load_cv2=5.9323 usage_frac=0.3438 topk_prob_mean=0.3096 ema_alpha_reverse=nan max_logit=13.7570
step:365/1750 train_time:171225ms step_avg:469.11ms
[train step 365] avg_loss=4.697475 main=4.148464 aux=0.549012 imp_cv2=0.6976 load_cv2=5.8412 usage_frac=0.3527 topk_prob_mean=0.3120 ema_alpha_reverse=nan max_logit=13.7570
step:366/1750 train_time:171692ms step_avg:469.10ms
[train step 366] avg_loss=4.482146 main=3.902555 aux=0.579591 imp_cv2=0.6945 load_cv2=6.2182 usage_frac=0.3393 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=13.7570
step:367/1750 train_time:172156ms step_avg:469.09ms
[train step 367] avg_loss=4.870437 main=4.304543 aux=0.565894 imp_cv2=0.6703 load_cv2=6.0741 usage_frac=0.3393 topk_prob_mean=0.3012 ema_alpha_reverse=nan max_logit=13.7570
step:368/1750 train_time:172630ms step_avg:469.10ms
[train step 368] avg_loss=4.813113 main=4.248292 aux=0.564821 imp_cv2=0.6706 load_cv2=6.0633 usage_frac=0.3259 topk_prob_mean=0.3006 ema_alpha_reverse=nan max_logit=13.7570
step:369/1750 train_time:173257ms step_avg:469.53ms
[train step 369] avg_loss=4.224796 main=3.666456 aux=0.558340 imp_cv2=0.7307 load_cv2=5.9394 usage_frac=0.3438 topk_prob_mean=0.3227 ema_alpha_reverse=nan max_logit=13.7570
step:370/1750 train_time:173732ms step_avg:469.55ms
[train step 370] avg_loss=4.489930 main=3.937876 aux=0.552054 imp_cv2=0.7569 load_cv2=5.8441 usage_frac=0.3527 topk_prob_mean=0.3358 ema_alpha_reverse=nan max_logit=13.7570
step:371/1750 train_time:174232ms step_avg:469.63ms
[train step 371] avg_loss=4.362615 main=3.804086 aux=0.558530 imp_cv2=0.7184 load_cv2=5.9556 usage_frac=0.3438 topk_prob_mean=0.3168 ema_alpha_reverse=nan max_logit=13.7570
step:372/1750 train_time:174717ms step_avg:469.67ms
[train step 372] avg_loss=4.564759 main=4.009306 aux=0.555453 imp_cv2=0.7916 load_cv2=5.8611 usage_frac=0.3527 topk_prob_mean=0.3376 ema_alpha_reverse=nan max_logit=13.7570
step:373/1750 train_time:175186ms step_avg:469.67ms
[train step 373] avg_loss=5.011794 main=4.445829 aux=0.565965 imp_cv2=0.6585 load_cv2=6.0874 usage_frac=0.3527 topk_prob_mean=0.2905 ema_alpha_reverse=nan max_logit=13.7005
step:374/1750 train_time:175642ms step_avg:469.63ms
[train step 374] avg_loss=4.402342 main=3.837609 aux=0.564733 imp_cv2=0.7036 load_cv2=6.0450 usage_frac=0.3348 topk_prob_mean=0.3113 ema_alpha_reverse=nan max_logit=13.7525
step:375/1750 train_time:176104ms step_avg:469.61ms
[train step 375] avg_loss=4.516542 main=3.957300 aux=0.559242 imp_cv2=0.6877 load_cv2=5.9868 usage_frac=0.3482 topk_prob_mean=0.3076 ema_alpha_reverse=nan max_logit=13.7570
step:376/1750 train_time:176578ms step_avg:469.62ms
[train step 376] avg_loss=4.528199 main=3.973063 aux=0.555136 imp_cv2=0.7224 load_cv2=5.9184 usage_frac=0.3393 topk_prob_mean=0.3229 ema_alpha_reverse=nan max_logit=13.7570
step:377/1750 train_time:177051ms step_avg:469.63ms
[train step 377] avg_loss=5.038452 main=4.450229 aux=0.588223 imp_cv2=0.6295 load_cv2=6.3458 usage_frac=0.2679 topk_prob_mean=0.2589 ema_alpha_reverse=nan max_logit=9.8264
step:378/1750 train_time:177507ms step_avg:469.59ms
[train step 378] avg_loss=4.561775 main=4.004966 aux=0.556810 imp_cv2=0.6890 load_cv2=5.9550 usage_frac=0.3438 topk_prob_mean=0.3126 ema_alpha_reverse=nan max_logit=13.7570
step:379/1750 train_time:177989ms step_avg:469.63ms
[train step 379] avg_loss=4.576854 main=4.021376 aux=0.555478 imp_cv2=0.6981 load_cv2=5.9305 usage_frac=0.3527 topk_prob_mean=0.3174 ema_alpha_reverse=nan max_logit=13.7394
step:380/1750 train_time:178449ms step_avg:469.60ms
[train step 380] avg_loss=4.548643 main=3.992517 aux=0.556125 imp_cv2=0.7036 load_cv2=5.9321 usage_frac=0.3438 topk_prob_mean=0.3184 ema_alpha_reverse=nan max_logit=13.6118
step:381/1750 train_time:178927ms step_avg:469.62ms
[train step 381] avg_loss=4.397484 main=3.835023 aux=0.562462 imp_cv2=0.6961 load_cv2=6.0225 usage_frac=0.3393 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=13.3938
step:382/1750 train_time:179402ms step_avg:469.64ms
[train step 382] avg_loss=4.485269 main=3.929844 aux=0.555425 imp_cv2=0.7061 load_cv2=5.9301 usage_frac=0.3438 topk_prob_mean=0.3162 ema_alpha_reverse=nan max_logit=13.2006
step:383/1750 train_time:179869ms step_avg:469.63ms
[train step 383] avg_loss=4.513052 main=3.969108 aux=0.543944 imp_cv2=0.7184 load_cv2=5.7814 usage_frac=0.3527 topk_prob_mean=0.3269 ema_alpha_reverse=nan max_logit=13.1111
step:384/1750 train_time:180368ms step_avg:469.71ms
[train step 384] avg_loss=4.506374 main=3.955990 aux=0.550384 imp_cv2=0.6783 load_cv2=5.8955 usage_frac=0.3527 topk_prob_mean=0.3118 ema_alpha_reverse=nan max_logit=12.9493
step:385/1750 train_time:180837ms step_avg:469.71ms
[train step 385] avg_loss=4.429330 main=3.886000 aux=0.543330 imp_cv2=0.7226 load_cv2=5.7810 usage_frac=0.3438 topk_prob_mean=0.3299 ema_alpha_reverse=nan max_logit=12.7744
step:386/1750 train_time:181310ms step_avg:469.72ms
[train step 386] avg_loss=4.843314 main=4.286232 aux=0.557082 imp_cv2=0.6543 load_cv2=5.9867 usage_frac=0.3661 topk_prob_mean=0.3026 ema_alpha_reverse=nan max_logit=12.7744
step:387/1750 train_time:181778ms step_avg:469.71ms
[train step 387] avg_loss=4.350548 main=3.799930 aux=0.550617 imp_cv2=0.6680 load_cv2=5.8979 usage_frac=0.3482 topk_prob_mean=0.3126 ema_alpha_reverse=nan max_logit=12.7744
step:388/1750 train_time:182240ms step_avg:469.69ms
[train step 388] avg_loss=4.192966 main=3.629142 aux=0.563824 imp_cv2=0.6445 load_cv2=6.0603 usage_frac=0.3348 topk_prob_mean=0.2883 ema_alpha_reverse=nan max_logit=12.7744
step:389/1750 train_time:182709ms step_avg:469.69ms
[train step 389] avg_loss=4.368819 main=3.821866 aux=0.546952 imp_cv2=0.6878 load_cv2=5.8501 usage_frac=0.3482 topk_prob_mean=0.3195 ema_alpha_reverse=nan max_logit=12.7744
step:390/1750 train_time:183176ms step_avg:469.68ms
[train step 390] avg_loss=4.479625 main=3.926996 aux=0.552630 imp_cv2=0.6624 load_cv2=5.9334 usage_frac=0.3304 topk_prob_mean=0.3073 ema_alpha_reverse=nan max_logit=12.7744
step:391/1750 train_time:183655ms step_avg:469.71ms
[train step 391] avg_loss=4.337505 main=3.759891 aux=0.577615 imp_cv2=0.7044 load_cv2=6.1992 usage_frac=0.3304 topk_prob_mean=0.2900 ema_alpha_reverse=nan max_logit=12.7744
step:392/1750 train_time:184136ms step_avg:469.73ms
[train step 392] avg_loss=4.334087 main=3.769835 aux=0.564253 imp_cv2=0.6436 load_cv2=6.0759 usage_frac=0.3438 topk_prob_mean=0.2895 ema_alpha_reverse=nan max_logit=12.7744
step:393/1750 train_time:184599ms step_avg:469.72ms
[train step 393] avg_loss=4.668330 main=4.128070 aux=0.540260 imp_cv2=0.6917 load_cv2=5.7600 usage_frac=0.3393 topk_prob_mean=0.3226 ema_alpha_reverse=nan max_logit=12.7744
step:394/1750 train_time:185068ms step_avg:469.72ms
[train step 394] avg_loss=4.394457 main=3.857127 aux=0.537330 imp_cv2=0.7319 load_cv2=5.6937 usage_frac=0.3438 topk_prob_mean=0.3354 ema_alpha_reverse=nan max_logit=12.7744
step:395/1750 train_time:185539ms step_avg:469.72ms
[train step 395] avg_loss=4.365557 main=3.815048 aux=0.550509 imp_cv2=0.6750 load_cv2=5.8966 usage_frac=0.3482 topk_prob_mean=0.3070 ema_alpha_reverse=nan max_logit=12.7744
step:396/1750 train_time:186008ms step_avg:469.72ms
[train step 396] avg_loss=4.510629 main=3.968164 aux=0.542464 imp_cv2=0.7257 load_cv2=5.7655 usage_frac=0.3393 topk_prob_mean=0.3258 ema_alpha_reverse=nan max_logit=12.7744
step:397/1750 train_time:186487ms step_avg:469.74ms
[train step 397] avg_loss=4.520212 main=3.963479 aux=0.556732 imp_cv2=0.6467 load_cv2=5.9994 usage_frac=0.3438 topk_prob_mean=0.2886 ema_alpha_reverse=nan max_logit=12.7744
step:398/1750 train_time:186949ms step_avg:469.72ms
[train step 398] avg_loss=4.073499 main=3.530700 aux=0.542799 imp_cv2=0.7120 load_cv2=5.7845 usage_frac=0.3438 topk_prob_mean=0.3186 ema_alpha_reverse=nan max_logit=12.7744
step:399/1750 train_time:187420ms step_avg:469.72ms
[train step 399] avg_loss=4.519618 main=3.973191 aux=0.546427 imp_cv2=0.6599 load_cv2=5.8580 usage_frac=0.3393 topk_prob_mean=0.3000 ema_alpha_reverse=nan max_logit=12.7744
step:400/1750 train_time:187894ms step_avg:469.73ms
Running validation...
step:400/1750 val_loss:3.991503 train_time:187906ms step_avg:469.76ms
[train step 400] avg_loss=4.496447 main=3.924461 aux=0.571986 imp_cv2=0.6306 load_cv2=6.1732 usage_frac=0.3438 topk_prob_mean=0.2693 ema_alpha_reverse=nan max_logit=12.7744
step:401/1750 train_time:188365ms step_avg:469.74ms
[train step 401] avg_loss=4.454823 main=3.896919 aux=0.557904 imp_cv2=0.6442 load_cv2=5.9973 usage_frac=0.3438 topk_prob_mean=0.2841 ema_alpha_reverse=nan max_logit=12.7744
step:402/1750 train_time:188824ms step_avg:469.71ms
[train step 402] avg_loss=4.786981 main=4.205769 aux=0.581212 imp_cv2=0.6470 load_cv2=6.2634 usage_frac=0.2857 topk_prob_mean=0.2600 ema_alpha_reverse=nan max_logit=9.3766
step:403/1750 train_time:189295ms step_avg:469.71ms
[train step 403] avg_loss=4.494430 main=3.940532 aux=0.553898 imp_cv2=0.6734 load_cv2=5.9417 usage_frac=0.3482 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=12.7744
step:404/1750 train_time:189755ms step_avg:469.69ms
[train step 404] avg_loss=4.194892 main=3.648474 aux=0.546418 imp_cv2=0.8018 load_cv2=5.7521 usage_frac=0.3393 topk_prob_mean=0.3384 ema_alpha_reverse=nan max_logit=12.7744
step:405/1750 train_time:190226ms step_avg:469.69ms
[train step 405] avg_loss=4.341034 main=3.788911 aux=0.552123 imp_cv2=0.7287 load_cv2=5.8864 usage_frac=0.3482 topk_prob_mean=0.3189 ema_alpha_reverse=nan max_logit=12.7744
step:406/1750 train_time:190695ms step_avg:469.69ms
[train step 406] avg_loss=4.807858 main=4.208972 aux=0.598887 imp_cv2=0.6426 load_cv2=6.4650 usage_frac=0.2723 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=9.6810
step:407/1750 train_time:191159ms step_avg:469.68ms
[train step 407] avg_loss=4.178314 main=3.602986 aux=0.575329 imp_cv2=0.6446 load_cv2=6.1919 usage_frac=0.3304 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=12.7744
step:408/1750 train_time:191636ms step_avg:469.70ms
[train step 408] avg_loss=4.545590 main=4.002348 aux=0.543242 imp_cv2=0.7074 load_cv2=5.8012 usage_frac=0.3527 topk_prob_mean=0.3182 ema_alpha_reverse=nan max_logit=12.7744
step:409/1750 train_time:192105ms step_avg:469.69ms
[train step 409] avg_loss=4.370524 main=3.814183 aux=0.556340 imp_cv2=0.6411 load_cv2=6.0004 usage_frac=0.3616 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=12.7744
step:410/1750 train_time:192556ms step_avg:469.65ms
[train step 410] avg_loss=4.574636 main=4.024815 aux=0.549822 imp_cv2=0.7039 load_cv2=5.8867 usage_frac=0.3527 topk_prob_mean=0.3135 ema_alpha_reverse=nan max_logit=12.7744
step:411/1750 train_time:193008ms step_avg:469.61ms
[train step 411] avg_loss=6.128032 main=5.568750 aux=0.559282 imp_cv2=0.6573 load_cv2=6.0035 usage_frac=0.3438 topk_prob_mean=0.2857 ema_alpha_reverse=nan max_logit=12.7744
step:412/1750 train_time:193462ms step_avg:469.57ms
[train step 412] avg_loss=4.475833 main=3.931470 aux=0.544363 imp_cv2=0.7067 load_cv2=5.8027 usage_frac=0.3438 topk_prob_mean=0.3174 ema_alpha_reverse=nan max_logit=12.7744
step:413/1750 train_time:193932ms step_avg:469.57ms
[train step 413] avg_loss=4.473400 main=3.929928 aux=0.543473 imp_cv2=0.7578 load_cv2=5.7469 usage_frac=0.3571 topk_prob_mean=0.3332 ema_alpha_reverse=nan max_logit=12.7744
step:414/1750 train_time:194392ms step_avg:469.55ms
[train step 414] avg_loss=4.224858 main=3.634742 aux=0.590117 imp_cv2=0.6370 load_cv2=6.3583 usage_frac=0.2723 topk_prob_mean=0.2554 ema_alpha_reverse=nan max_logit=9.5416
step:415/1750 train_time:194867ms step_avg:469.56ms
[train step 415] avg_loss=4.822512 main=4.279493 aux=0.543019 imp_cv2=0.7015 load_cv2=5.7858 usage_frac=0.3616 topk_prob_mean=0.3199 ema_alpha_reverse=nan max_logit=12.7744
step:416/1750 train_time:195340ms step_avg:469.57ms
[train step 416] avg_loss=4.314306 main=3.765736 aux=0.548569 imp_cv2=0.6707 load_cv2=5.8820 usage_frac=0.3527 topk_prob_mean=0.3047 ema_alpha_reverse=nan max_logit=12.7744
step:417/1750 train_time:195810ms step_avg:469.57ms
[train step 417] avg_loss=4.824888 main=4.252416 aux=0.572471 imp_cv2=0.6410 load_cv2=6.1479 usage_frac=0.2723 topk_prob_mean=0.2651 ema_alpha_reverse=nan max_logit=9.8264
step:418/1750 train_time:196283ms step_avg:469.58ms
[train step 418] avg_loss=4.282692 main=3.751861 aux=0.530831 imp_cv2=0.7407 load_cv2=5.6108 usage_frac=0.3482 topk_prob_mean=0.3353 ema_alpha_reverse=nan max_logit=12.7744
step:419/1750 train_time:196745ms step_avg:469.56ms
[train step 419] avg_loss=4.410884 main=3.835442 aux=0.575442 imp_cv2=0.6235 load_cv2=6.2068 usage_frac=0.3304 topk_prob_mean=0.2618 ema_alpha_reverse=nan max_logit=12.7744
step:420/1750 train_time:197223ms step_avg:469.58ms
[train step 420] avg_loss=4.559380 main=4.017753 aux=0.541627 imp_cv2=0.7085 load_cv2=5.7732 usage_frac=0.3482 topk_prob_mean=0.3199 ema_alpha_reverse=nan max_logit=12.7744
step:421/1750 train_time:197705ms step_avg:469.61ms
[train step 421] avg_loss=4.571303 main=3.994486 aux=0.576818 imp_cv2=0.6383 load_cv2=6.2225 usage_frac=0.2723 topk_prob_mean=0.2532 ema_alpha_reverse=nan max_logit=9.8264
step:422/1750 train_time:198195ms step_avg:469.66ms
[train step 422] avg_loss=4.335126 main=3.801081 aux=0.534044 imp_cv2=0.7009 load_cv2=5.6922 usage_frac=0.3571 topk_prob_mean=0.3202 ema_alpha_reverse=nan max_logit=12.7744
step:423/1750 train_time:198684ms step_avg:469.70ms
[train step 423] avg_loss=4.720524 main=4.176017 aux=0.544508 imp_cv2=0.6813 load_cv2=5.8315 usage_frac=0.3482 topk_prob_mean=0.3086 ema_alpha_reverse=nan max_logit=12.7744
step:424/1750 train_time:199135ms step_avg:469.66ms
[train step 424] avg_loss=4.437414 main=3.900759 aux=0.536655 imp_cv2=0.7202 load_cv2=5.7031 usage_frac=0.3571 topk_prob_mean=0.3255 ema_alpha_reverse=nan max_logit=12.7744
step:425/1750 train_time:199602ms step_avg:469.65ms
[train step 425] avg_loss=4.562929 main=4.024256 aux=0.538674 imp_cv2=0.7033 load_cv2=5.7462 usage_frac=0.3839 topk_prob_mean=0.3180 ema_alpha_reverse=nan max_logit=13.7570
step:426/1750 train_time:200076ms step_avg:469.66ms
[train step 426] avg_loss=4.509436 main=3.967271 aux=0.542165 imp_cv2=0.7038 load_cv2=5.7803 usage_frac=0.3527 topk_prob_mean=0.3181 ema_alpha_reverse=nan max_logit=12.7744
step:427/1750 train_time:200554ms step_avg:469.68ms
[train step 427] avg_loss=4.594389 main=4.050652 aux=0.543737 imp_cv2=0.6896 load_cv2=5.8104 usage_frac=0.3527 topk_prob_mean=0.3136 ema_alpha_reverse=nan max_logit=12.7744
step:428/1750 train_time:201049ms step_avg:469.74ms
[train step 428] avg_loss=4.115778 main=3.575870 aux=0.539908 imp_cv2=0.7891 load_cv2=5.6819 usage_frac=0.3616 topk_prob_mean=0.3404 ema_alpha_reverse=nan max_logit=12.7744
step:429/1750 train_time:201526ms step_avg:469.76ms
[train step 429] avg_loss=4.451886 main=3.904453 aux=0.547433 imp_cv2=0.7816 load_cv2=5.7696 usage_frac=0.3527 topk_prob_mean=0.3325 ema_alpha_reverse=nan max_logit=12.7744
step:430/1750 train_time:202000ms step_avg:469.77ms
[train step 430] avg_loss=4.556921 main=4.007561 aux=0.549360 imp_cv2=0.6859 load_cv2=5.8644 usage_frac=0.3482 topk_prob_mean=0.3089 ema_alpha_reverse=nan max_logit=12.7744
step:431/1750 train_time:202470ms step_avg:469.77ms
[train step 431] avg_loss=4.453756 main=3.909648 aux=0.544108 imp_cv2=0.7764 load_cv2=5.7287 usage_frac=0.3571 topk_prob_mean=0.3377 ema_alpha_reverse=nan max_logit=12.7744
step:432/1750 train_time:202942ms step_avg:469.77ms
[train step 432] avg_loss=4.308599 main=3.765409 aux=0.543190 imp_cv2=0.6893 load_cv2=5.7902 usage_frac=0.3571 topk_prob_mean=0.3156 ema_alpha_reverse=nan max_logit=12.7744
step:433/1750 train_time:203438ms step_avg:469.83ms
[train step 433] avg_loss=4.532489 main=3.987350 aux=0.545140 imp_cv2=0.6690 load_cv2=5.8277 usage_frac=0.3661 topk_prob_mean=0.3065 ema_alpha_reverse=nan max_logit=12.7744
step:434/1750 train_time:203905ms step_avg:469.83ms
[train step 434] avg_loss=4.900400 main=4.332890 aux=0.567509 imp_cv2=0.6302 load_cv2=6.1296 usage_frac=0.3527 topk_prob_mean=0.2755 ema_alpha_reverse=nan max_logit=12.7744
step:435/1750 train_time:204358ms step_avg:469.79ms
[train step 435] avg_loss=4.587932 main=4.037154 aux=0.550778 imp_cv2=0.6565 load_cv2=5.9075 usage_frac=0.3527 topk_prob_mean=0.2996 ema_alpha_reverse=nan max_logit=12.7744
step:436/1750 train_time:204837ms step_avg:469.81ms
[train step 436] avg_loss=4.084826 main=3.550090 aux=0.534737 imp_cv2=0.7486 load_cv2=5.6511 usage_frac=0.3616 topk_prob_mean=0.3363 ema_alpha_reverse=nan max_logit=12.7744
step:437/1750 train_time:205295ms step_avg:469.78ms
[train step 437] avg_loss=4.492785 main=3.958415 aux=0.534370 imp_cv2=0.7511 load_cv2=5.6447 usage_frac=0.3705 topk_prob_mean=0.3368 ema_alpha_reverse=nan max_logit=12.9584
step:438/1750 train_time:205765ms step_avg:469.78ms
[train step 438] avg_loss=4.126005 main=3.596260 aux=0.529745 imp_cv2=0.7813 load_cv2=5.5622 usage_frac=0.3616 topk_prob_mean=0.3452 ema_alpha_reverse=nan max_logit=12.7744
step:439/1750 train_time:206243ms step_avg:469.80ms
[train step 439] avg_loss=4.423182 main=3.885625 aux=0.537557 imp_cv2=0.7275 load_cv2=5.7032 usage_frac=0.3616 topk_prob_mean=0.3288 ema_alpha_reverse=nan max_logit=12.7744
step:440/1750 train_time:206731ms step_avg:469.84ms
[train step 440] avg_loss=4.435672 main=3.898573 aux=0.537099 imp_cv2=0.7589 load_cv2=5.6723 usage_frac=0.3705 topk_prob_mean=0.3360 ema_alpha_reverse=nan max_logit=12.7744
step:441/1750 train_time:207209ms step_avg:469.86ms
[train step 441] avg_loss=5.331079 main=4.464981 aux=0.866098 imp_cv2=4.6995 load_cv2=5.5318 usage_frac=0.4598 topk_prob_mean=0.8775 ema_alpha_reverse=nan max_logit=13.2903
step:442/1750 train_time:207769ms step_avg:470.07ms
[train step 442] avg_loss=4.405436 main=3.947685 aux=0.457752 imp_cv2=1.6501 load_cv2=3.7488 usage_frac=0.4732 topk_prob_mean=0.5796 ema_alpha_reverse=nan max_logit=13.2308
step:443/1750 train_time:208372ms step_avg:470.37ms
[train step 443] avg_loss=4.726176 main=4.211504 aux=0.514672 imp_cv2=0.6038 load_cv2=5.4566 usage_frac=0.4241 topk_prob_mean=0.3217 ema_alpha_reverse=nan max_logit=13.1431
step:444/1750 train_time:208898ms step_avg:470.49ms
[train step 444] avg_loss=4.317215 main=3.821369 aux=0.495846 imp_cv2=0.4367 load_cv2=5.3658 usage_frac=0.4062 topk_prob_mean=0.3059 ema_alpha_reverse=nan max_logit=12.7744
step:445/1750 train_time:209432ms step_avg:470.63ms
[train step 445] avg_loss=4.221199 main=3.735699 aux=0.485501 imp_cv2=0.4808 load_cv2=5.2473 usage_frac=0.4241 topk_prob_mean=0.3292 ema_alpha_reverse=nan max_logit=13.5201
step:446/1750 train_time:209949ms step_avg:470.74ms
[train step 446] avg_loss=4.690546 main=4.139357 aux=0.551189 imp_cv2=0.4411 load_cv2=6.0220 usage_frac=0.3393 topk_prob_mean=0.2612 ema_alpha_reverse=nan max_logit=12.7744
step:447/1750 train_time:210449ms step_avg:470.80ms
[train step 447] avg_loss=4.431839 main=3.921089 aux=0.510750 imp_cv2=0.4289 load_cv2=5.5879 usage_frac=0.3973 topk_prob_mean=0.3005 ema_alpha_reverse=nan max_logit=12.7744
step:448/1750 train_time:210945ms step_avg:470.86ms
[train step 448] avg_loss=4.286162 main=3.776307 aux=0.509855 imp_cv2=0.4621 load_cv2=5.5509 usage_frac=0.3839 topk_prob_mean=0.3103 ema_alpha_reverse=nan max_logit=12.7744
step:449/1750 train_time:211442ms step_avg:470.92ms
[train step 449] avg_loss=4.246398 main=3.731476 aux=0.514922 imp_cv2=0.4456 load_cv2=5.6252 usage_frac=0.3839 topk_prob_mean=0.3060 ema_alpha_reverse=nan max_logit=12.7744
step:450/1750 train_time:211943ms step_avg:470.98ms
Running validation...
step:450/1750 val_loss:3.896437 train_time:211955ms step_avg:471.01ms
[train step 450] avg_loss=4.512281 main=4.002247 aux=0.510034 imp_cv2=0.4436 load_cv2=5.5712 usage_frac=0.3929 topk_prob_mean=0.3072 ema_alpha_reverse=nan max_logit=12.7744
step:451/1750 train_time:212425ms step_avg:471.01ms
[train step 451] avg_loss=4.391397 main=3.856925 aux=0.534472 imp_cv2=0.3965 load_cv2=5.8859 usage_frac=0.3705 topk_prob_mean=0.2730 ema_alpha_reverse=nan max_logit=12.7744
step:452/1750 train_time:212914ms step_avg:471.05ms
[train step 452] avg_loss=4.527193 main=4.020617 aux=0.506577 imp_cv2=0.4473 load_cv2=5.5254 usage_frac=0.3973 topk_prob_mean=0.3121 ema_alpha_reverse=nan max_logit=12.7744
step:453/1750 train_time:213403ms step_avg:471.09ms
[train step 453] avg_loss=4.481635 main=3.964174 aux=0.517461 imp_cv2=0.4265 load_cv2=5.6767 usage_frac=0.3884 topk_prob_mean=0.2965 ema_alpha_reverse=nan max_logit=12.7744
step:454/1750 train_time:213898ms step_avg:471.14ms
[train step 454] avg_loss=4.150674 main=3.647060 aux=0.503614 imp_cv2=0.5320 load_cv2=5.4338 usage_frac=0.3929 topk_prob_mean=0.3326 ema_alpha_reverse=nan max_logit=12.7744
step:455/1750 train_time:214395ms step_avg:471.20ms
[train step 455] avg_loss=4.348709 main=3.836407 aux=0.512302 imp_cv2=0.4677 load_cv2=5.5884 usage_frac=0.3929 topk_prob_mean=0.3107 ema_alpha_reverse=nan max_logit=12.7744
step:456/1750 train_time:214875ms step_avg:471.22ms
[train step 456] avg_loss=4.312976 main=3.800852 aux=0.512124 imp_cv2=0.4865 load_cv2=5.5712 usage_frac=0.3884 topk_prob_mean=0.3136 ema_alpha_reverse=nan max_logit=12.7744
step:457/1750 train_time:215358ms step_avg:471.24ms
[train step 457] avg_loss=4.524042 main=4.015868 aux=0.508174 imp_cv2=0.4968 load_cv2=5.5194 usage_frac=0.3884 topk_prob_mean=0.3196 ema_alpha_reverse=nan max_logit=12.7744
step:458/1750 train_time:215852ms step_avg:471.29ms
[train step 458] avg_loss=4.416454 main=3.898977 aux=0.517477 imp_cv2=0.4272 load_cv2=5.6834 usage_frac=0.3839 topk_prob_mean=0.2949 ema_alpha_reverse=nan max_logit=12.7744
step:459/1750 train_time:216325ms step_avg:471.30ms
[train step 459] avg_loss=4.104820 main=3.599157 aux=0.505664 imp_cv2=0.4816 load_cv2=5.5015 usage_frac=0.3884 topk_prob_mean=0.3156 ema_alpha_reverse=nan max_logit=12.7744
step:460/1750 train_time:216809ms step_avg:471.32ms
[train step 460] avg_loss=4.045329 main=3.535769 aux=0.509560 imp_cv2=0.5321 load_cv2=5.5095 usage_frac=0.3973 topk_prob_mean=0.3271 ema_alpha_reverse=nan max_logit=12.7744
step:461/1750 train_time:217285ms step_avg:471.33ms
[train step 461] avg_loss=4.428939 main=3.911609 aux=0.517330 imp_cv2=0.4609 load_cv2=5.6564 usage_frac=0.3839 topk_prob_mean=0.3051 ema_alpha_reverse=nan max_logit=12.7744
step:462/1750 train_time:217772ms step_avg:471.37ms
[train step 462] avg_loss=4.635437 main=4.116773 aux=0.518664 imp_cv2=0.4181 load_cv2=5.7028 usage_frac=0.3929 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=12.7744
step:463/1750 train_time:218257ms step_avg:471.40ms
[train step 463] avg_loss=4.516774 main=4.002239 aux=0.514534 imp_cv2=0.4544 load_cv2=5.6291 usage_frac=0.3795 topk_prob_mean=0.3022 ema_alpha_reverse=nan max_logit=12.7744
step:464/1750 train_time:218741ms step_avg:471.42ms
[train step 464] avg_loss=4.466614 main=3.935377 aux=0.531237 imp_cv2=0.4049 load_cv2=5.8714 usage_frac=0.3750 topk_prob_mean=0.2746 ema_alpha_reverse=nan max_logit=12.7744
step:465/1750 train_time:219221ms step_avg:471.44ms
[train step 465] avg_loss=4.196642 main=3.688432 aux=0.508211 imp_cv2=0.4775 load_cv2=5.5495 usage_frac=0.3750 topk_prob_mean=0.3069 ema_alpha_reverse=nan max_logit=12.7744
step:466/1750 train_time:219725ms step_avg:471.51ms
[train step 466] avg_loss=4.357593 main=3.850222 aux=0.507371 imp_cv2=0.4781 load_cv2=5.5356 usage_frac=0.3929 topk_prob_mean=0.3090 ema_alpha_reverse=nan max_logit=13.7570
step:467/1750 train_time:220186ms step_avg:471.49ms
[train step 467] avg_loss=4.463829 main=3.953233 aux=0.510595 imp_cv2=0.4785 load_cv2=5.5666 usage_frac=0.3973 topk_prob_mean=0.3088 ema_alpha_reverse=nan max_logit=13.7570
step:468/1750 train_time:220672ms step_avg:471.52ms
[train step 468] avg_loss=4.746093 main=4.221761 aux=0.524332 imp_cv2=0.3991 load_cv2=5.7987 usage_frac=0.3929 topk_prob_mean=0.2752 ema_alpha_reverse=nan max_logit=13.7570
step:469/1750 train_time:221140ms step_avg:471.51ms
[train step 469] avg_loss=4.314472 main=3.797424 aux=0.517048 imp_cv2=0.4841 load_cv2=5.6414 usage_frac=0.3973 topk_prob_mean=0.3065 ema_alpha_reverse=nan max_logit=13.7570
step:470/1750 train_time:221619ms step_avg:471.53ms
[train step 470] avg_loss=4.543192 main=4.001161 aux=0.542032 imp_cv2=0.3895 load_cv2=5.9978 usage_frac=0.3884 topk_prob_mean=0.2624 ema_alpha_reverse=nan max_logit=13.7570
step:471/1750 train_time:222088ms step_avg:471.52ms
[train step 471] avg_loss=4.310336 main=3.790027 aux=0.520309 imp_cv2=0.4549 load_cv2=5.7104 usage_frac=0.4018 topk_prob_mean=0.2971 ema_alpha_reverse=nan max_logit=13.7570
step:472/1750 train_time:222554ms step_avg:471.51ms
[train step 472] avg_loss=4.251124 main=3.738153 aux=0.512971 imp_cv2=0.4736 load_cv2=5.5982 usage_frac=0.3839 topk_prob_mean=0.3056 ema_alpha_reverse=nan max_logit=13.7570
step:473/1750 train_time:223027ms step_avg:471.51ms
[train step 473] avg_loss=4.346736 main=3.834063 aux=0.512674 imp_cv2=0.4427 load_cv2=5.6253 usage_frac=0.3884 topk_prob_mean=0.2972 ema_alpha_reverse=nan max_logit=13.7570
step:474/1750 train_time:223489ms step_avg:471.50ms
[train step 474] avg_loss=4.264269 main=3.742438 aux=0.521832 imp_cv2=0.4108 load_cv2=5.7559 usage_frac=0.3839 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=13.7570
step:475/1750 train_time:223965ms step_avg:471.50ms
[train step 475] avg_loss=4.409935 main=3.897177 aux=0.512758 imp_cv2=0.4426 load_cv2=5.6234 usage_frac=0.3884 topk_prob_mean=0.2955 ema_alpha_reverse=nan max_logit=13.7570
step:476/1750 train_time:224441ms step_avg:471.51ms
[train step 476] avg_loss=4.182237 main=3.674550 aux=0.507687 imp_cv2=0.4316 load_cv2=5.5732 usage_frac=0.3839 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=13.7570
step:477/1750 train_time:224922ms step_avg:471.53ms
[train step 477] avg_loss=4.651992 main=4.121131 aux=0.530860 imp_cv2=0.3815 load_cv2=5.8758 usage_frac=0.3884 topk_prob_mean=0.2573 ema_alpha_reverse=nan max_logit=13.7570
step:478/1750 train_time:225398ms step_avg:471.54ms
[train step 478] avg_loss=4.277105 main=3.763721 aux=0.513384 imp_cv2=0.4240 load_cv2=5.6487 usage_frac=0.3839 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=13.7570
step:479/1750 train_time:225873ms step_avg:471.55ms
[train step 479] avg_loss=4.230997 main=3.713085 aux=0.517912 imp_cv2=0.4158 load_cv2=5.7064 usage_frac=0.3839 topk_prob_mean=0.2823 ema_alpha_reverse=nan max_logit=13.7570
step:480/1750 train_time:226375ms step_avg:471.62ms
[train step 480] avg_loss=4.659933 main=4.124540 aux=0.535393 imp_cv2=0.3786 load_cv2=5.9318 usage_frac=0.3795 topk_prob_mean=0.2564 ema_alpha_reverse=nan max_logit=13.7570
step:481/1750 train_time:226850ms step_avg:471.62ms
[train step 481] avg_loss=4.376903 main=3.867879 aux=0.509023 imp_cv2=0.4357 load_cv2=5.5863 usage_frac=0.3839 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=13.7570
step:482/1750 train_time:227330ms step_avg:471.64ms
[train step 482] avg_loss=4.224185 main=3.717470 aux=0.506715 imp_cv2=0.4641 load_cv2=5.5382 usage_frac=0.3839 topk_prob_mean=0.3059 ema_alpha_reverse=nan max_logit=13.7570
step:483/1750 train_time:227815ms step_avg:471.67ms
[train step 483] avg_loss=4.323744 main=3.813374 aux=0.510370 imp_cv2=0.4255 load_cv2=5.6170 usage_frac=0.3884 topk_prob_mean=0.2901 ema_alpha_reverse=nan max_logit=13.7570
step:484/1750 train_time:228310ms step_avg:471.71ms
[train step 484] avg_loss=4.114115 main=3.596841 aux=0.517274 imp_cv2=0.4160 load_cv2=5.7051 usage_frac=0.3884 topk_prob_mean=0.2816 ema_alpha_reverse=nan max_logit=13.7570
step:485/1750 train_time:228795ms step_avg:471.74ms
[train step 485] avg_loss=5.358376 main=4.827064 aux=0.531312 imp_cv2=0.3835 load_cv2=5.8861 usage_frac=0.3750 topk_prob_mean=0.2564 ema_alpha_reverse=nan max_logit=13.7570
step:486/1750 train_time:229272ms step_avg:471.75ms
[train step 486] avg_loss=4.203394 main=3.700259 aux=0.503134 imp_cv2=0.4792 load_cv2=5.4971 usage_frac=0.3795 topk_prob_mean=0.3063 ema_alpha_reverse=nan max_logit=13.7570
step:487/1750 train_time:229755ms step_avg:471.78ms
[train step 487] avg_loss=4.059007 main=3.555769 aux=0.503238 imp_cv2=0.4624 load_cv2=5.5080 usage_frac=0.3929 topk_prob_mean=0.3027 ema_alpha_reverse=nan max_logit=13.7570
step:488/1750 train_time:230236ms step_avg:471.80ms
[train step 488] avg_loss=4.213199 main=3.698839 aux=0.514360 imp_cv2=0.4120 load_cv2=5.6755 usage_frac=0.3750 topk_prob_mean=0.2785 ema_alpha_reverse=nan max_logit=13.7570
step:489/1750 train_time:230718ms step_avg:471.82ms
[train step 489] avg_loss=4.171459 main=3.666571 aux=0.504888 imp_cv2=0.4519 load_cv2=5.5326 usage_frac=0.3795 topk_prob_mean=0.2992 ema_alpha_reverse=nan max_logit=13.7570
step:490/1750 train_time:231191ms step_avg:471.82ms
[train step 490] avg_loss=4.579030 main=4.052433 aux=0.526596 imp_cv2=0.4080 load_cv2=5.8201 usage_frac=0.3839 topk_prob_mean=0.2709 ema_alpha_reverse=nan max_logit=13.7570
step:491/1750 train_time:231663ms step_avg:471.82ms
[train step 491] avg_loss=4.359483 main=3.842062 aux=0.517421 imp_cv2=0.4245 load_cv2=5.7091 usage_frac=0.3884 topk_prob_mean=0.2829 ema_alpha_reverse=nan max_logit=13.7570
step:492/1750 train_time:232135ms step_avg:471.82ms
[train step 492] avg_loss=4.167796 main=3.656159 aux=0.511637 imp_cv2=0.4527 load_cv2=5.6104 usage_frac=0.3795 topk_prob_mean=0.2965 ema_alpha_reverse=nan max_logit=13.7570
step:493/1750 train_time:232610ms step_avg:471.83ms
[train step 493] avg_loss=4.338440 main=3.827106 aux=0.511333 imp_cv2=0.4630 load_cv2=5.5854 usage_frac=0.3795 topk_prob_mean=0.3021 ema_alpha_reverse=nan max_logit=13.7570
step:494/1750 train_time:233091ms step_avg:471.84ms
[train step 494] avg_loss=4.387571 main=3.860919 aux=0.526652 imp_cv2=0.3924 load_cv2=5.8094 usage_frac=0.3795 topk_prob_mean=0.2683 ema_alpha_reverse=nan max_logit=13.7570
step:495/1750 train_time:233561ms step_avg:471.84ms
[train step 495] avg_loss=4.331634 main=3.797087 aux=0.534546 imp_cv2=0.3875 load_cv2=5.9363 usage_frac=0.3795 topk_prob_mean=0.2586 ema_alpha_reverse=nan max_logit=13.7570
step:496/1750 train_time:234022ms step_avg:471.82ms
[train step 496] avg_loss=4.486525 main=3.950947 aux=0.535578 imp_cv2=0.3794 load_cv2=5.9304 usage_frac=0.3795 topk_prob_mean=0.2598 ema_alpha_reverse=nan max_logit=13.7570
step:497/1750 train_time:234485ms step_avg:471.80ms
[train step 497] avg_loss=4.180130 main=3.661226 aux=0.518903 imp_cv2=0.4372 load_cv2=5.7001 usage_frac=0.3973 topk_prob_mean=0.2946 ema_alpha_reverse=nan max_logit=13.7570
step:498/1750 train_time:234948ms step_avg:471.78ms
[train step 498] avg_loss=4.411683 main=3.872199 aux=0.539483 imp_cv2=0.3947 load_cv2=5.9561 usage_frac=0.3705 topk_prob_mean=0.2658 ema_alpha_reverse=nan max_logit=13.7570
step:499/1750 train_time:235408ms step_avg:471.76ms
[train step 499] avg_loss=5.793276 main=5.211721 aux=0.581555 imp_cv2=0.3953 load_cv2=6.4783 usage_frac=0.3527 topk_prob_mean=0.2185 ema_alpha_reverse=nan max_logit=12.3311
step:500/1750 train_time:235882ms step_avg:471.76ms
Running validation...
step:500/1750 val_loss:3.797127 train_time:235894ms step_avg:471.79ms
[train step 500] avg_loss=4.217278 main=3.692528 aux=0.524750 imp_cv2=0.4108 load_cv2=5.7867 usage_frac=0.3795 topk_prob_mean=0.2860 ema_alpha_reverse=nan max_logit=13.7530
step:501/1750 train_time:236536ms step_avg:472.13ms
[train step 501] avg_loss=4.234361 main=3.708089 aux=0.526272 imp_cv2=0.4018 load_cv2=5.8136 usage_frac=0.3750 topk_prob_mean=0.2812 ema_alpha_reverse=nan max_logit=13.7570
step:502/1750 train_time:237000ms step_avg:472.11ms
[train step 502] avg_loss=4.282604 main=3.763347 aux=0.519257 imp_cv2=0.4486 load_cv2=5.7021 usage_frac=0.3839 topk_prob_mean=0.2988 ema_alpha_reverse=nan max_logit=13.7570
step:503/1750 train_time:237456ms step_avg:472.08ms
[train step 503] avg_loss=4.186675 main=3.671059 aux=0.515616 imp_cv2=0.4453 load_cv2=5.6572 usage_frac=0.3839 topk_prob_mean=0.2986 ema_alpha_reverse=nan max_logit=13.7570
step:504/1750 train_time:237941ms step_avg:472.10ms
[train step 504] avg_loss=4.207148 main=3.684996 aux=0.522153 imp_cv2=0.3917 load_cv2=5.7789 usage_frac=0.3884 topk_prob_mean=0.2761 ema_alpha_reverse=nan max_logit=13.7570
step:505/1750 train_time:238401ms step_avg:472.08ms
[train step 505] avg_loss=4.134058 main=3.623437 aux=0.510621 imp_cv2=0.4328 load_cv2=5.6128 usage_frac=0.3705 topk_prob_mean=0.2976 ema_alpha_reverse=nan max_logit=13.7570
step:506/1750 train_time:238866ms step_avg:472.07ms
[train step 506] avg_loss=4.051823 main=3.540559 aux=0.511265 imp_cv2=0.4867 load_cv2=5.5765 usage_frac=0.3705 topk_prob_mean=0.3126 ema_alpha_reverse=nan max_logit=13.7570
step:507/1750 train_time:239332ms step_avg:472.06ms
[train step 507] avg_loss=4.246984 main=3.718916 aux=0.528068 imp_cv2=0.4033 load_cv2=5.8499 usage_frac=0.3661 topk_prob_mean=0.2761 ema_alpha_reverse=nan max_logit=13.7570
step:508/1750 train_time:239807ms step_avg:472.06ms
[train step 508] avg_loss=4.483243 main=3.956294 aux=0.526950 imp_cv2=0.4129 load_cv2=5.8184 usage_frac=0.3661 topk_prob_mean=0.2835 ema_alpha_reverse=nan max_logit=13.7570
step:509/1750 train_time:240276ms step_avg:472.05ms
[train step 509] avg_loss=4.193417 main=3.677495 aux=0.515922 imp_cv2=0.5279 load_cv2=5.6017 usage_frac=0.3661 topk_prob_mean=0.3186 ema_alpha_reverse=nan max_logit=13.7570
step:510/1750 train_time:240744ms step_avg:472.05ms
[train step 510] avg_loss=4.084832 main=3.564781 aux=0.520051 imp_cv2=0.4490 load_cv2=5.7148 usage_frac=0.3661 topk_prob_mean=0.2972 ema_alpha_reverse=nan max_logit=13.7570
step:511/1750 train_time:241206ms step_avg:472.03ms
[train step 511] avg_loss=4.106400 main=3.588032 aux=0.518368 imp_cv2=0.4451 load_cv2=5.6928 usage_frac=0.3661 topk_prob_mean=0.2971 ema_alpha_reverse=nan max_logit=13.7570
step:512/1750 train_time:241659ms step_avg:471.99ms
[train step 512] avg_loss=4.224714 main=3.698519 aux=0.526195 imp_cv2=0.4134 load_cv2=5.8085 usage_frac=0.3661 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=13.7570
step:513/1750 train_time:242105ms step_avg:471.94ms
[train step 513] avg_loss=4.207186 main=3.697475 aux=0.509711 imp_cv2=0.5072 load_cv2=5.5377 usage_frac=0.3705 topk_prob_mean=0.3186 ema_alpha_reverse=nan max_logit=13.7570
step:514/1750 train_time:242583ms step_avg:471.95ms
[train step 514] avg_loss=4.245373 main=3.722036 aux=0.523337 imp_cv2=0.4231 load_cv2=5.7599 usage_frac=0.3661 topk_prob_mean=0.2879 ema_alpha_reverse=nan max_logit=13.7570
step:515/1750 train_time:243266ms step_avg:472.36ms
[train step 515] avg_loss=4.186045 main=3.665735 aux=0.520309 imp_cv2=0.4318 load_cv2=5.7263 usage_frac=0.3661 topk_prob_mean=0.2936 ema_alpha_reverse=nan max_logit=13.7570
step:516/1750 train_time:243719ms step_avg:472.32ms
[train step 516] avg_loss=4.338103 main=3.818774 aux=0.519328 imp_cv2=0.4441 load_cv2=5.7018 usage_frac=0.3661 topk_prob_mean=0.2987 ema_alpha_reverse=nan max_logit=13.7570
step:517/1750 train_time:244168ms step_avg:472.28ms
[train step 517] avg_loss=5.423933 main=4.889349 aux=0.534583 imp_cv2=0.3808 load_cv2=5.9322 usage_frac=0.3661 topk_prob_mean=0.2658 ema_alpha_reverse=nan max_logit=13.7570
step:518/1750 train_time:244619ms step_avg:472.24ms
[train step 518] avg_loss=4.911243 main=4.362684 aux=0.548559 imp_cv2=0.3958 load_cv2=6.0906 usage_frac=0.3661 topk_prob_mean=0.2557 ema_alpha_reverse=nan max_logit=13.7570
step:519/1750 train_time:245069ms step_avg:472.20ms
[train step 519] avg_loss=4.153235 main=3.634727 aux=0.518508 imp_cv2=0.4561 load_cv2=5.6769 usage_frac=0.3750 topk_prob_mean=0.3045 ema_alpha_reverse=nan max_logit=13.7570
step:520/1750 train_time:245527ms step_avg:472.17ms
[train step 520] avg_loss=4.241498 main=3.718360 aux=0.523138 imp_cv2=0.4164 load_cv2=5.7738 usage_frac=0.3884 topk_prob_mean=0.2871 ema_alpha_reverse=nan max_logit=13.7570
step:521/1750 train_time:245990ms step_avg:472.15ms
[train step 521] avg_loss=4.026063 main=3.511139 aux=0.514924 imp_cv2=0.4768 load_cv2=5.6224 usage_frac=0.3661 topk_prob_mean=0.3083 ema_alpha_reverse=nan max_logit=13.7570
step:522/1750 train_time:246462ms step_avg:472.15ms
[train step 522] avg_loss=4.921362 main=4.362230 aux=0.559132 imp_cv2=0.3637 load_cv2=6.2111 usage_frac=0.3438 topk_prob_mean=0.2356 ema_alpha_reverse=nan max_logit=13.3861
step:523/1750 train_time:246914ms step_avg:472.11ms
[train step 523] avg_loss=4.247115 main=3.731543 aux=0.515573 imp_cv2=0.4704 load_cv2=5.6363 usage_frac=0.3616 topk_prob_mean=0.3070 ema_alpha_reverse=nan max_logit=13.7570
step:524/1750 train_time:247369ms step_avg:472.08ms
[train step 524] avg_loss=4.601272 main=4.075680 aux=0.525593 imp_cv2=0.4115 load_cv2=5.7914 usage_frac=0.3661 topk_prob_mean=0.2769 ema_alpha_reverse=nan max_logit=13.7570
step:525/1750 train_time:247810ms step_avg:472.02ms
[train step 525] avg_loss=4.519332 main=3.969024 aux=0.550308 imp_cv2=0.3743 load_cv2=6.1021 usage_frac=0.3571 topk_prob_mean=0.2444 ema_alpha_reverse=nan max_logit=13.7570
step:526/1750 train_time:248278ms step_avg:472.01ms
[train step 526] avg_loss=4.322098 main=3.801014 aux=0.521084 imp_cv2=0.3960 load_cv2=5.7524 usage_frac=0.3661 topk_prob_mean=0.2812 ema_alpha_reverse=nan max_logit=13.7570
step:527/1750 train_time:248944ms step_avg:472.38ms
[train step 527] avg_loss=3.940026 main=3.434856 aux=0.505170 imp_cv2=0.5034 load_cv2=5.4771 usage_frac=0.3661 topk_prob_mean=0.3212 ema_alpha_reverse=nan max_logit=13.7570
step:528/1750 train_time:249412ms step_avg:472.37ms
[train step 528] avg_loss=4.524244 main=4.012016 aux=0.512228 imp_cv2=0.4018 load_cv2=5.6461 usage_frac=0.3571 topk_prob_mean=0.2879 ema_alpha_reverse=nan max_logit=13.7570
step:529/1750 train_time:249878ms step_avg:472.36ms
[train step 529] avg_loss=4.187911 main=3.675371 aux=0.512540 imp_cv2=0.4192 load_cv2=5.6398 usage_frac=0.3571 topk_prob_mean=0.2909 ema_alpha_reverse=nan max_logit=13.7570
step:530/1750 train_time:250336ms step_avg:472.33ms
[train step 530] avg_loss=4.250988 main=3.744996 aux=0.505992 imp_cv2=0.4442 load_cv2=5.5423 usage_frac=0.3571 topk_prob_mean=0.3055 ema_alpha_reverse=nan max_logit=13.7570
step:531/1750 train_time:250785ms step_avg:472.29ms
[train step 531] avg_loss=4.304822 main=3.793044 aux=0.511777 imp_cv2=0.4085 load_cv2=5.6454 usage_frac=0.3527 topk_prob_mean=0.2871 ema_alpha_reverse=nan max_logit=13.7570
step:532/1750 train_time:251244ms step_avg:472.26ms
[train step 532] avg_loss=4.599611 main=4.022972 aux=0.576639 imp_cv2=0.4210 load_cv2=6.3692 usage_frac=0.3125 topk_prob_mean=0.2171 ema_alpha_reverse=nan max_logit=8.8456
step:533/1750 train_time:251691ms step_avg:472.22ms
[train step 533] avg_loss=4.597102 main=4.035272 aux=0.561830 imp_cv2=0.3893 load_cv2=6.2174 usage_frac=0.3080 topk_prob_mean=0.2418 ema_alpha_reverse=nan max_logit=9.8264
step:534/1750 train_time:252187ms step_avg:472.26ms
[train step 534] avg_loss=4.256668 main=3.748371 aux=0.508297 imp_cv2=0.4740 load_cv2=5.5554 usage_frac=0.3527 topk_prob_mean=0.3088 ema_alpha_reverse=nan max_logit=13.7570
step:535/1750 train_time:252659ms step_avg:472.26ms
[train step 535] avg_loss=4.334248 main=3.829652 aux=0.504596 imp_cv2=0.4451 load_cv2=5.5359 usage_frac=0.3571 topk_prob_mean=0.3019 ema_alpha_reverse=nan max_logit=13.7570
step:536/1750 train_time:253110ms step_avg:472.22ms
[train step 536] avg_loss=4.155538 main=3.651925 aux=0.503613 imp_cv2=0.4141 load_cv2=5.5429 usage_frac=0.3527 topk_prob_mean=0.2918 ema_alpha_reverse=nan max_logit=13.7570
step:537/1750 train_time:253555ms step_avg:472.17ms
[train step 537] avg_loss=3.902179 main=3.405169 aux=0.497010 imp_cv2=0.5478 load_cv2=5.3602 usage_frac=0.3571 topk_prob_mean=0.3294 ema_alpha_reverse=nan max_logit=13.7570
step:538/1750 train_time:254025ms step_avg:472.17ms
[train step 538] avg_loss=4.080327 main=3.575679 aux=0.504648 imp_cv2=0.4247 load_cv2=5.5544 usage_frac=0.3527 topk_prob_mean=0.2916 ema_alpha_reverse=nan max_logit=12.7744
step:539/1750 train_time:254499ms step_avg:472.17ms
[train step 539] avg_loss=4.432904 main=3.923056 aux=0.509849 imp_cv2=0.4018 load_cv2=5.6230 usage_frac=0.3661 topk_prob_mean=0.2803 ema_alpha_reverse=nan max_logit=13.4572
step:540/1750 train_time:254979ms step_avg:472.18ms
[train step 540] avg_loss=4.392212 main=3.889268 aux=0.502944 imp_cv2=0.4334 load_cv2=5.5279 usage_frac=0.3705 topk_prob_mean=0.2943 ema_alpha_reverse=nan max_logit=13.1377
step:541/1750 train_time:255443ms step_avg:472.17ms
[train step 541] avg_loss=4.069378 main=3.568417 aux=0.500962 imp_cv2=0.4282 load_cv2=5.4956 usage_frac=0.3571 topk_prob_mean=0.2950 ema_alpha_reverse=nan max_logit=13.2727
step:542/1750 train_time:255921ms step_avg:472.18ms
[train step 542] avg_loss=4.414195 main=3.869069 aux=0.545125 imp_cv2=0.3753 load_cv2=6.0491 usage_frac=0.3527 topk_prob_mean=0.2348 ema_alpha_reverse=nan max_logit=12.7744
step:543/1750 train_time:256380ms step_avg:472.15ms
[train step 543] avg_loss=4.404247 main=3.889747 aux=0.514500 imp_cv2=0.4132 load_cv2=5.6741 usage_frac=0.3616 topk_prob_mean=0.2841 ema_alpha_reverse=nan max_logit=13.5064
step:544/1750 train_time:256843ms step_avg:472.14ms
[train step 544] avg_loss=4.383381 main=3.864147 aux=0.519234 imp_cv2=0.4086 load_cv2=5.7347 usage_frac=0.3527 topk_prob_mean=0.2778 ema_alpha_reverse=nan max_logit=12.7744
step:545/1750 train_time:257292ms step_avg:472.09ms
[train step 545] avg_loss=4.174394 main=3.659382 aux=0.515012 imp_cv2=0.4202 load_cv2=5.6719 usage_frac=0.3527 topk_prob_mean=0.2862 ema_alpha_reverse=nan max_logit=12.7744
step:546/1750 train_time:257749ms step_avg:472.07ms
[train step 546] avg_loss=4.352109 main=3.843167 aux=0.508942 imp_cv2=0.4235 load_cv2=5.5792 usage_frac=0.3527 topk_prob_mean=0.2879 ema_alpha_reverse=nan max_logit=12.7744
step:547/1750 train_time:258208ms step_avg:472.04ms
[train step 547] avg_loss=4.765310 main=4.222249 aux=0.543061 imp_cv2=0.3752 load_cv2=6.0204 usage_frac=0.3571 topk_prob_mean=0.2462 ema_alpha_reverse=nan max_logit=13.2562
step:548/1750 train_time:258665ms step_avg:472.02ms
[train step 548] avg_loss=4.759091 main=4.227759 aux=0.531333 imp_cv2=0.3789 load_cv2=5.8845 usage_frac=0.3616 topk_prob_mean=0.2623 ema_alpha_reverse=nan max_logit=13.1484
step:549/1750 train_time:259120ms step_avg:471.99ms
[train step 549] avg_loss=4.212096 main=3.685371 aux=0.526725 imp_cv2=0.3835 load_cv2=5.8337 usage_frac=0.3661 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=13.7570
step:550/1750 train_time:259564ms step_avg:471.94ms
Running validation...
step:550/1750 val_loss:3.729948 train_time:259576ms step_avg:471.96ms
[train step 550] avg_loss=4.688496 main=4.158066 aux=0.530430 imp_cv2=0.3825 load_cv2=5.8793 usage_frac=0.3571 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=12.7744
step:551/1750 train_time:260024ms step_avg:471.91ms
[train step 551] avg_loss=6.604158 main=6.039059 aux=0.565100 imp_cv2=0.3878 load_cv2=6.2676 usage_frac=0.3170 topk_prob_mean=0.2299 ema_alpha_reverse=nan max_logit=10.8091
step:552/1750 train_time:260470ms step_avg:471.87ms
[train step 552] avg_loss=3.853839 main=3.339317 aux=0.514522 imp_cv2=0.4763 load_cv2=5.6140 usage_frac=0.3527 topk_prob_mean=0.3063 ema_alpha_reverse=nan max_logit=12.7744
step:553/1750 train_time:260930ms step_avg:471.84ms
[train step 553] avg_loss=4.376009 main=3.843571 aux=0.532438 imp_cv2=0.3782 load_cv2=5.8979 usage_frac=0.3482 topk_prob_mean=0.2610 ema_alpha_reverse=nan max_logit=12.7744
step:554/1750 train_time:261368ms step_avg:471.78ms
[train step 554] avg_loss=4.325807 main=3.804795 aux=0.521012 imp_cv2=0.4074 load_cv2=5.7483 usage_frac=0.3571 topk_prob_mean=0.2796 ema_alpha_reverse=nan max_logit=13.7570
step:555/1750 train_time:261828ms step_avg:471.76ms
[train step 555] avg_loss=4.190754 main=3.670299 aux=0.520456 imp_cv2=0.4137 load_cv2=5.7331 usage_frac=0.3571 topk_prob_mean=0.2870 ema_alpha_reverse=nan max_logit=12.9421
step:556/1750 train_time:262289ms step_avg:471.74ms
[train step 556] avg_loss=4.440405 main=3.917933 aux=0.522472 imp_cv2=0.4053 load_cv2=5.7409 usage_frac=0.3482 topk_prob_mean=0.2756 ema_alpha_reverse=nan max_logit=12.7744
step:557/1750 train_time:262751ms step_avg:471.73ms
[train step 557] avg_loss=3.894853 main=3.385107 aux=0.509746 imp_cv2=0.4544 load_cv2=5.5748 usage_frac=0.3571 topk_prob_mean=0.3044 ema_alpha_reverse=nan max_logit=12.7744
step:558/1750 train_time:263234ms step_avg:471.75ms
[train step 558] avg_loss=4.932272 main=4.410940 aux=0.521332 imp_cv2=0.4526 load_cv2=5.6917 usage_frac=0.3571 topk_prob_mean=0.2851 ema_alpha_reverse=nan max_logit=12.8824
step:559/1750 train_time:263711ms step_avg:471.76ms
[train step 559] avg_loss=3.905926 main=3.400828 aux=0.505098 imp_cv2=0.4671 load_cv2=5.5176 usage_frac=0.3527 topk_prob_mean=0.3092 ema_alpha_reverse=nan max_logit=12.7744
step:560/1750 train_time:264178ms step_avg:471.75ms
[train step 560] avg_loss=4.106293 main=3.587186 aux=0.519107 imp_cv2=0.4140 load_cv2=5.7319 usage_frac=0.3527 topk_prob_mean=0.2847 ema_alpha_reverse=nan max_logit=12.7744
step:561/1750 train_time:264650ms step_avg:471.75ms
[train step 561] avg_loss=4.121721 main=3.599464 aux=0.522258 imp_cv2=0.3991 load_cv2=5.7819 usage_frac=0.3527 topk_prob_mean=0.2746 ema_alpha_reverse=nan max_logit=12.7744
step:562/1750 train_time:265096ms step_avg:471.70ms
[train step 562] avg_loss=4.009930 main=3.506551 aux=0.503379 imp_cv2=0.4397 load_cv2=5.5169 usage_frac=0.3571 topk_prob_mean=0.3003 ema_alpha_reverse=nan max_logit=12.7744
step:563/1750 train_time:265584ms step_avg:471.73ms
[train step 563] avg_loss=4.237770 main=3.734005 aux=0.503765 imp_cv2=0.4462 load_cv2=5.5170 usage_frac=0.3527 topk_prob_mean=0.3021 ema_alpha_reverse=nan max_logit=12.7744
step:564/1750 train_time:266038ms step_avg:471.70ms
[train step 564] avg_loss=4.348899 main=3.842190 aux=0.506709 imp_cv2=0.4450 load_cv2=5.5517 usage_frac=0.3616 topk_prob_mean=0.3014 ema_alpha_reverse=nan max_logit=13.6690
step:565/1750 train_time:266503ms step_avg:471.69ms
[train step 565] avg_loss=4.086835 main=3.583384 aux=0.503452 imp_cv2=0.4704 load_cv2=5.4852 usage_frac=0.3571 topk_prob_mean=0.3132 ema_alpha_reverse=nan max_logit=12.7744
step:566/1750 train_time:266978ms step_avg:471.69ms
[train step 566] avg_loss=4.069036 main=3.561300 aux=0.507736 imp_cv2=0.4347 load_cv2=5.5668 usage_frac=0.3661 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=13.3859
step:567/1750 train_time:267450ms step_avg:471.69ms
[train step 567] avg_loss=4.738058 main=4.192933 aux=0.545126 imp_cv2=0.3922 load_cv2=6.0285 usage_frac=0.3705 topk_prob_mean=0.2432 ema_alpha_reverse=nan max_logit=12.9081
step:568/1750 train_time:267906ms step_avg:471.67ms
[train step 568] avg_loss=4.057304 main=3.551209 aux=0.506095 imp_cv2=0.4810 load_cv2=5.5037 usage_frac=0.3705 topk_prob_mean=0.3135 ema_alpha_reverse=nan max_logit=12.7744
step:569/1750 train_time:268390ms step_avg:471.69ms
[train step 569] avg_loss=4.190742 main=3.687311 aux=0.503431 imp_cv2=0.4722 load_cv2=5.4811 usage_frac=0.3750 topk_prob_mean=0.3122 ema_alpha_reverse=nan max_logit=12.7744
step:570/1750 train_time:268853ms step_avg:471.67ms
[train step 570] avg_loss=3.948264 main=3.428394 aux=0.519870 imp_cv2=0.4073 load_cv2=5.7261 usage_frac=0.3705 topk_prob_mean=0.2878 ema_alpha_reverse=nan max_logit=12.7744
step:571/1750 train_time:269301ms step_avg:471.63ms
[train step 571] avg_loss=4.199637 main=3.672374 aux=0.527264 imp_cv2=0.3916 load_cv2=5.8311 usage_frac=0.3616 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=12.7744
step:572/1750 train_time:269758ms step_avg:471.61ms
[train step 572] avg_loss=3.916202 main=3.402673 aux=0.513530 imp_cv2=0.4577 load_cv2=5.6152 usage_frac=0.3705 topk_prob_mean=0.3000 ema_alpha_reverse=nan max_logit=12.7744
step:573/1750 train_time:270214ms step_avg:471.58ms
[train step 573] avg_loss=4.220786 main=3.708371 aux=0.512415 imp_cv2=0.4135 load_cv2=5.6323 usage_frac=0.3750 topk_prob_mean=0.2921 ema_alpha_reverse=nan max_logit=12.8818
step:574/1750 train_time:270665ms step_avg:471.54ms
[train step 574] avg_loss=4.140284 main=3.632267 aux=0.508017 imp_cv2=0.4155 load_cv2=5.5694 usage_frac=0.3616 topk_prob_mean=0.2945 ema_alpha_reverse=nan max_logit=12.7744
step:575/1750 train_time:271137ms step_avg:471.54ms
[train step 575] avg_loss=4.236498 main=3.733247 aux=0.503251 imp_cv2=0.4359 load_cv2=5.5046 usage_frac=0.3661 topk_prob_mean=0.3014 ema_alpha_reverse=nan max_logit=12.7744
step:576/1750 train_time:271604ms step_avg:471.53ms
[train step 576] avg_loss=4.396853 main=3.873566 aux=0.523287 imp_cv2=0.3801 load_cv2=5.7761 usage_frac=0.3527 topk_prob_mean=0.2692 ema_alpha_reverse=nan max_logit=12.7744
step:577/1750 train_time:272071ms step_avg:471.53ms
[train step 577] avg_loss=4.083714 main=3.574052 aux=0.509662 imp_cv2=0.3988 load_cv2=5.6112 usage_frac=0.3571 topk_prob_mean=0.2844 ema_alpha_reverse=nan max_logit=13.7570
step:578/1750 train_time:272531ms step_avg:471.51ms
[train step 578] avg_loss=4.437880 main=3.937412 aux=0.500468 imp_cv2=0.4529 load_cv2=5.4582 usage_frac=0.3616 topk_prob_mean=0.3075 ema_alpha_reverse=nan max_logit=13.2171
step:579/1750 train_time:273012ms step_avg:471.52ms
[train step 579] avg_loss=4.617360 main=4.096332 aux=0.521028 imp_cv2=0.3880 load_cv2=5.7528 usage_frac=0.3482 topk_prob_mean=0.2703 ema_alpha_reverse=nan max_logit=12.7744
step:580/1750 train_time:273471ms step_avg:471.50ms
[train step 580] avg_loss=3.920977 main=3.422626 aux=0.498352 imp_cv2=0.4726 load_cv2=5.4250 usage_frac=0.3616 topk_prob_mean=0.3120 ema_alpha_reverse=nan max_logit=12.7744
step:581/1750 train_time:273944ms step_avg:471.50ms
[train step 581] avg_loss=4.371141 main=3.868585 aux=0.502556 imp_cv2=0.4661 load_cv2=5.4823 usage_frac=0.3571 topk_prob_mean=0.3076 ema_alpha_reverse=nan max_logit=12.7744
step:582/1750 train_time:274417ms step_avg:471.51ms
[train step 582] avg_loss=4.461950 main=3.952454 aux=0.509496 imp_cv2=0.4233 load_cv2=5.5868 usage_frac=0.3571 topk_prob_mean=0.2927 ema_alpha_reverse=nan max_logit=13.7570
step:583/1750 train_time:274889ms step_avg:471.51ms
[train step 583] avg_loss=4.209294 main=3.696779 aux=0.512514 imp_cv2=0.3933 load_cv2=5.6509 usage_frac=0.3527 topk_prob_mean=0.2810 ema_alpha_reverse=nan max_logit=12.8427
step:584/1750 train_time:275352ms step_avg:471.49ms
[train step 584] avg_loss=4.318914 main=3.816544 aux=0.502370 imp_cv2=0.4275 load_cv2=5.5119 usage_frac=0.3616 topk_prob_mean=0.2990 ema_alpha_reverse=nan max_logit=13.7570
step:585/1750 train_time:275830ms step_avg:471.50ms
[train step 585] avg_loss=4.130597 main=3.629268 aux=0.501329 imp_cv2=0.4432 load_cv2=5.4852 usage_frac=0.3482 topk_prob_mean=0.3064 ema_alpha_reverse=nan max_logit=12.7744
step:586/1750 train_time:276284ms step_avg:471.48ms
[train step 586] avg_loss=4.039768 main=3.517339 aux=0.522429 imp_cv2=0.3728 load_cv2=5.7658 usage_frac=0.3482 topk_prob_mean=0.2673 ema_alpha_reverse=nan max_logit=12.7744
step:587/1750 train_time:276736ms step_avg:471.44ms
[train step 587] avg_loss=3.960946 main=3.454020 aux=0.506926 imp_cv2=0.4485 load_cv2=5.5437 usage_frac=0.3661 topk_prob_mean=0.3065 ema_alpha_reverse=nan max_logit=13.5753
step:588/1750 train_time:277189ms step_avg:471.41ms
[train step 588] avg_loss=4.187675 main=3.673354 aux=0.514321 imp_cv2=0.4212 load_cv2=5.6625 usage_frac=0.3482 topk_prob_mean=0.2914 ema_alpha_reverse=nan max_logit=12.7744
step:589/1750 train_time:277642ms step_avg:471.38ms
[train step 589] avg_loss=4.083323 main=3.565576 aux=0.517746 imp_cv2=0.4252 load_cv2=5.6894 usage_frac=0.3527 topk_prob_mean=0.2908 ema_alpha_reverse=nan max_logit=12.9123
step:590/1750 train_time:278083ms step_avg:471.33ms
[train step 590] avg_loss=4.081274 main=3.571290 aux=0.509984 imp_cv2=0.4355 load_cv2=5.5806 usage_frac=0.3527 topk_prob_mean=0.2964 ema_alpha_reverse=nan max_logit=13.7570
step:591/1750 train_time:278542ms step_avg:471.31ms
[train step 591] avg_loss=4.440714 main=3.678682 aux=0.762032 imp_cv2=3.9879 load_cv2=4.9466 usage_frac=0.4509 topk_prob_mean=0.8572 ema_alpha_reverse=nan max_logit=13.5430
step:592/1750 train_time:279076ms step_avg:471.41ms
[train step 592] avg_loss=4.781544 main=4.288490 aux=0.493054 imp_cv2=1.2941 load_cv2=4.4436 usage_frac=0.4509 topk_prob_mean=0.4773 ema_alpha_reverse=nan max_logit=13.2921
step:593/1750 train_time:279636ms step_avg:471.56ms
[train step 593] avg_loss=4.125891 main=3.649160 aux=0.476732 imp_cv2=0.3767 load_cv2=5.1579 usage_frac=0.4643 topk_prob_mean=0.3229 ema_alpha_reverse=nan max_logit=13.7570
step:594/1750 train_time:280129ms step_avg:471.60ms
[train step 594] avg_loss=4.130431 main=3.642234 aux=0.488197 imp_cv2=0.2456 load_cv2=5.4747 usage_frac=0.3929 topk_prob_mean=0.2857 ema_alpha_reverse=nan max_logit=13.7074
step:595/1750 train_time:280618ms step_avg:471.63ms
[train step 595] avg_loss=4.099017 main=3.618989 aux=0.480028 imp_cv2=0.2969 load_cv2=5.3287 usage_frac=0.3929 topk_prob_mean=0.3074 ema_alpha_reverse=nan max_logit=13.7570
step:596/1750 train_time:281096ms step_avg:471.64ms
[train step 596] avg_loss=3.840282 main=3.349421 aux=0.490861 imp_cv2=0.3447 load_cv2=5.4176 usage_frac=0.3839 topk_prob_mean=0.3079 ema_alpha_reverse=nan max_logit=13.7570
step:597/1750 train_time:281572ms step_avg:471.64ms
[train step 597] avg_loss=4.077196 main=3.581070 aux=0.496126 imp_cv2=0.2932 load_cv2=5.5279 usage_frac=0.3973 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=13.7570
step:598/1750 train_time:282045ms step_avg:471.65ms
[train step 598] avg_loss=4.354515 main=3.861354 aux=0.493161 imp_cv2=0.2764 load_cv2=5.5025 usage_frac=0.3750 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=13.7570
step:599/1750 train_time:282520ms step_avg:471.65ms
[train step 599] avg_loss=3.941488 main=3.450730 aux=0.490758 imp_cv2=0.2778 load_cv2=5.4779 usage_frac=0.3839 topk_prob_mean=0.2974 ema_alpha_reverse=nan max_logit=13.7570
step:600/1750 train_time:282999ms step_avg:471.66ms
Running validation...
step:600/1750 val_loss:3.652303 train_time:283010ms step_avg:471.68ms
[train step 600] avg_loss=4.072904 main=3.563392 aux=0.509513 imp_cv2=0.2100 load_cv2=5.7366 usage_frac=0.3750 topk_prob_mean=0.2583 ema_alpha_reverse=nan max_logit=12.8151
step:601/1750 train_time:283459ms step_avg:471.65ms
[train step 601] avg_loss=3.961223 main=3.468419 aux=0.492803 imp_cv2=0.2905 load_cv2=5.4943 usage_frac=0.3929 topk_prob_mean=0.2959 ema_alpha_reverse=nan max_logit=13.7570
step:602/1750 train_time:283947ms step_avg:471.67ms
[train step 602] avg_loss=4.311672 main=3.816811 aux=0.494861 imp_cv2=0.2477 load_cv2=5.5564 usage_frac=0.3929 topk_prob_mean=0.2791 ema_alpha_reverse=nan max_logit=13.7570
step:603/1750 train_time:284412ms step_avg:471.66ms
[train step 603] avg_loss=3.975866 main=3.482018 aux=0.493848 imp_cv2=0.2525 load_cv2=5.5389 usage_frac=0.3929 topk_prob_mean=0.2805 ema_alpha_reverse=nan max_logit=13.7570
step:604/1750 train_time:284881ms step_avg:471.66ms
[train step 604] avg_loss=4.361457 main=3.850516 aux=0.510941 imp_cv2=0.2081 load_cv2=5.7735 usage_frac=0.3839 topk_prob_mean=0.2538 ema_alpha_reverse=nan max_logit=13.7570
step:605/1750 train_time:285373ms step_avg:471.69ms
[train step 605] avg_loss=4.014296 main=3.522954 aux=0.491342 imp_cv2=0.2725 load_cv2=5.4975 usage_frac=0.3839 topk_prob_mean=0.2895 ema_alpha_reverse=nan max_logit=13.7570
step:606/1750 train_time:285840ms step_avg:471.68ms
[train step 606] avg_loss=4.153919 main=3.656008 aux=0.497910 imp_cv2=0.2569 load_cv2=5.5856 usage_frac=0.3839 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=13.7570
step:607/1750 train_time:286311ms step_avg:471.68ms
[train step 607] avg_loss=4.184826 main=3.678353 aux=0.506473 imp_cv2=0.2126 load_cv2=5.7188 usage_frac=0.4196 topk_prob_mean=0.2592 ema_alpha_reverse=nan max_logit=13.7570
step:608/1750 train_time:286805ms step_avg:471.72ms
[train step 608] avg_loss=3.775828 main=3.277999 aux=0.497829 imp_cv2=0.3458 load_cv2=5.5074 usage_frac=0.3795 topk_prob_mean=0.3019 ema_alpha_reverse=nan max_logit=13.7570
step:609/1750 train_time:287272ms step_avg:471.71ms
[train step 609] avg_loss=4.166673 main=3.661571 aux=0.505102 imp_cv2=0.2354 load_cv2=5.6874 usage_frac=0.3750 topk_prob_mean=0.2699 ema_alpha_reverse=nan max_logit=13.7078
step:610/1750 train_time:287737ms step_avg:471.70ms
[train step 610] avg_loss=4.283431 main=3.775296 aux=0.508135 imp_cv2=0.2171 load_cv2=5.7325 usage_frac=0.3884 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=13.7570
step:611/1750 train_time:288194ms step_avg:471.68ms
[train step 611] avg_loss=3.951215 main=3.455811 aux=0.495404 imp_cv2=0.2691 load_cv2=5.5438 usage_frac=0.3750 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=13.7570
step:612/1750 train_time:288665ms step_avg:471.68ms
[train step 612] avg_loss=4.166958 main=3.668833 aux=0.498126 imp_cv2=0.2591 load_cv2=5.5849 usage_frac=0.3973 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=13.7570
step:613/1750 train_time:289133ms step_avg:471.67ms
[train step 613] avg_loss=4.009786 main=3.507887 aux=0.501899 imp_cv2=0.2681 load_cv2=5.6211 usage_frac=0.3839 topk_prob_mean=0.2784 ema_alpha_reverse=nan max_logit=13.7570
step:614/1750 train_time:289605ms step_avg:471.67ms
[train step 614] avg_loss=4.100245 main=3.592510 aux=0.507735 imp_cv2=0.2259 load_cv2=5.7250 usage_frac=0.3929 topk_prob_mean=0.2562 ema_alpha_reverse=nan max_logit=13.7570
step:615/1750 train_time:290078ms step_avg:471.67ms
[train step 615] avg_loss=4.435547 main=3.924536 aux=0.511011 imp_cv2=0.2320 load_cv2=5.7748 usage_frac=0.3884 topk_prob_mean=0.2579 ema_alpha_reverse=nan max_logit=13.7570
step:616/1750 train_time:290566ms step_avg:471.70ms
[train step 616] avg_loss=4.189939 main=3.650886 aux=0.539053 imp_cv2=0.2217 load_cv2=6.0901 usage_frac=0.3750 topk_prob_mean=0.2283 ema_alpha_reverse=nan max_logit=13.7570
step:617/1750 train_time:291023ms step_avg:471.67ms
[train step 617] avg_loss=3.753119 main=3.259829 aux=0.493290 imp_cv2=0.4018 load_cv2=5.4158 usage_frac=0.3884 topk_prob_mean=0.3136 ema_alpha_reverse=nan max_logit=13.7570
step:618/1750 train_time:291512ms step_avg:471.70ms
[train step 618] avg_loss=4.309400 main=3.814252 aux=0.495148 imp_cv2=0.2680 load_cv2=5.5520 usage_frac=0.3795 topk_prob_mean=0.2809 ema_alpha_reverse=nan max_logit=13.7570
step:619/1750 train_time:291978ms step_avg:471.69ms
[train step 619] avg_loss=4.241217 main=3.742820 aux=0.498397 imp_cv2=0.2513 load_cv2=5.6050 usage_frac=0.3884 topk_prob_mean=0.2727 ema_alpha_reverse=nan max_logit=13.7570
step:620/1750 train_time:292439ms step_avg:471.68ms
[train step 620] avg_loss=3.944363 main=3.436146 aux=0.508217 imp_cv2=0.2060 load_cv2=5.7492 usage_frac=0.3750 topk_prob_mean=0.2543 ema_alpha_reverse=nan max_logit=13.7570
step:621/1750 train_time:292904ms step_avg:471.67ms
[train step 621] avg_loss=3.909982 main=3.411937 aux=0.498045 imp_cv2=0.2701 load_cv2=5.5805 usage_frac=0.3929 topk_prob_mean=0.2782 ema_alpha_reverse=nan max_logit=13.7570
step:622/1750 train_time:293381ms step_avg:471.67ms
[train step 622] avg_loss=3.971704 main=3.466283 aux=0.505421 imp_cv2=0.2576 load_cv2=5.6826 usage_frac=0.3929 topk_prob_mean=0.2707 ema_alpha_reverse=nan max_logit=13.7570
step:623/1750 train_time:293837ms step_avg:471.65ms
[train step 623] avg_loss=4.511396 main=3.981943 aux=0.529453 imp_cv2=0.1862 load_cv2=6.0094 usage_frac=0.3795 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=13.7570
step:624/1750 train_time:294287ms step_avg:471.61ms
[train step 624] avg_loss=4.342406 main=3.837774 aux=0.504632 imp_cv2=0.2304 load_cv2=5.6812 usage_frac=0.3929 topk_prob_mean=0.2620 ema_alpha_reverse=nan max_logit=13.7570
step:625/1750 train_time:294756ms step_avg:471.61ms
[train step 625] avg_loss=4.104247 main=3.597141 aux=0.507107 imp_cv2=0.2272 load_cv2=5.7166 usage_frac=0.3750 topk_prob_mean=0.2636 ema_alpha_reverse=nan max_logit=13.7570
step:626/1750 train_time:295215ms step_avg:471.59ms
[train step 626] avg_loss=4.100538 main=3.600065 aux=0.500472 imp_cv2=0.2701 load_cv2=5.6045 usage_frac=0.3839 topk_prob_mean=0.2803 ema_alpha_reverse=nan max_logit=13.7570
step:627/1750 train_time:295680ms step_avg:471.58ms
[train step 627] avg_loss=3.606158 main=3.106976 aux=0.499182 imp_cv2=0.3938 load_cv2=5.4740 usage_frac=0.3884 topk_prob_mean=0.3132 ema_alpha_reverse=nan max_logit=13.7570
step:628/1750 train_time:296177ms step_avg:471.62ms
[train step 628] avg_loss=4.130841 main=3.623183 aux=0.507659 imp_cv2=0.2227 load_cv2=5.7294 usage_frac=0.3973 topk_prob_mean=0.2618 ema_alpha_reverse=nan max_logit=13.7570
step:629/1750 train_time:296637ms step_avg:471.60ms
[train step 629] avg_loss=3.861998 main=3.360819 aux=0.501179 imp_cv2=0.2510 load_cv2=5.6296 usage_frac=0.3839 topk_prob_mean=0.2740 ema_alpha_reverse=nan max_logit=13.7570
step:630/1750 train_time:297094ms step_avg:471.58ms
[train step 630] avg_loss=3.738236 main=3.242821 aux=0.495415 imp_cv2=0.3045 load_cv2=5.5188 usage_frac=0.3929 topk_prob_mean=0.2920 ema_alpha_reverse=nan max_logit=13.7570
step:631/1750 train_time:297567ms step_avg:471.58ms
[train step 631] avg_loss=4.416651 main=3.909058 aux=0.507593 imp_cv2=0.2026 load_cv2=5.7431 usage_frac=0.4018 topk_prob_mean=0.2503 ema_alpha_reverse=nan max_logit=13.7570
step:632/1750 train_time:298031ms step_avg:471.57ms
[train step 632] avg_loss=3.903861 main=3.390600 aux=0.513261 imp_cv2=0.2006 load_cv2=5.8159 usage_frac=0.3973 topk_prob_mean=0.2484 ema_alpha_reverse=nan max_logit=13.7570
step:633/1750 train_time:298503ms step_avg:471.57ms
[train step 633] avg_loss=4.119146 main=3.615503 aux=0.503644 imp_cv2=0.2321 load_cv2=5.6769 usage_frac=0.3973 topk_prob_mean=0.2624 ema_alpha_reverse=nan max_logit=13.7570
step:634/1750 train_time:298962ms step_avg:471.55ms
[train step 634] avg_loss=3.889919 main=3.386432 aux=0.503487 imp_cv2=0.2443 load_cv2=5.6706 usage_frac=0.3929 topk_prob_mean=0.2686 ema_alpha_reverse=nan max_logit=13.7570
step:635/1750 train_time:299428ms step_avg:471.54ms
[train step 635] avg_loss=4.224481 main=3.685706 aux=0.538775 imp_cv2=0.1872 load_cv2=6.1152 usage_frac=0.3705 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=12.7744
step:636/1750 train_time:299892ms step_avg:471.53ms
[train step 636] avg_loss=4.129142 main=3.631969 aux=0.497172 imp_cv2=0.2431 load_cv2=5.5876 usage_frac=0.3884 topk_prob_mean=0.2725 ema_alpha_reverse=nan max_logit=13.4555
step:637/1750 train_time:300372ms step_avg:471.54ms
[train step 637] avg_loss=4.220867 main=3.720025 aux=0.500841 imp_cv2=0.2678 load_cv2=5.6199 usage_frac=0.3929 topk_prob_mean=0.2762 ema_alpha_reverse=nan max_logit=13.7570
step:638/1750 train_time:300848ms step_avg:471.55ms
[train step 638] avg_loss=3.874241 main=3.378119 aux=0.496121 imp_cv2=0.3538 load_cv2=5.4947 usage_frac=0.3929 topk_prob_mean=0.3023 ema_alpha_reverse=nan max_logit=13.7570
step:639/1750 train_time:301312ms step_avg:471.54ms
[train step 639] avg_loss=4.086620 main=3.581297 aux=0.505324 imp_cv2=0.2220 load_cv2=5.7137 usage_frac=0.3929 topk_prob_mean=0.2600 ema_alpha_reverse=nan max_logit=12.9489
step:640/1750 train_time:301770ms step_avg:471.52ms
[train step 640] avg_loss=3.821904 main=3.326480 aux=0.495424 imp_cv2=0.2969 load_cv2=5.5380 usage_frac=0.3929 topk_prob_mean=0.2865 ema_alpha_reverse=nan max_logit=12.7744
step:641/1750 train_time:302227ms step_avg:471.49ms
[train step 641] avg_loss=3.952868 main=3.460908 aux=0.491960 imp_cv2=0.2825 load_cv2=5.5061 usage_frac=0.3929 topk_prob_mean=0.2854 ema_alpha_reverse=nan max_logit=13.1662
step:642/1750 train_time:302696ms step_avg:471.49ms
[train step 642] avg_loss=4.306135 main=3.804899 aux=0.501237 imp_cv2=0.2219 load_cv2=5.6670 usage_frac=0.3750 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=12.7744
step:643/1750 train_time:303162ms step_avg:471.48ms
[train step 643] avg_loss=3.765434 main=3.274766 aux=0.490668 imp_cv2=0.3461 load_cv2=5.4445 usage_frac=0.3839 topk_prob_mean=0.3036 ema_alpha_reverse=nan max_logit=13.7570
step:644/1750 train_time:303636ms step_avg:471.48ms
[train step 644] avg_loss=4.166838 main=3.667987 aux=0.498851 imp_cv2=0.2333 load_cv2=5.6213 usage_frac=0.3929 topk_prob_mean=0.2656 ema_alpha_reverse=nan max_logit=12.7744
step:645/1750 train_time:304124ms step_avg:471.51ms
[train step 645] avg_loss=4.184025 main=3.680457 aux=0.503568 imp_cv2=0.2442 load_cv2=5.6799 usage_frac=0.3795 topk_prob_mean=0.2669 ema_alpha_reverse=nan max_logit=13.7570
step:646/1750 train_time:304605ms step_avg:471.53ms
[train step 646] avg_loss=4.031098 main=3.540606 aux=0.490492 imp_cv2=0.2872 load_cv2=5.4919 usage_frac=0.4018 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=12.8853
step:647/1750 train_time:305085ms step_avg:471.54ms
[train step 647] avg_loss=4.229042 main=3.731094 aux=0.497948 imp_cv2=0.2237 load_cv2=5.6272 usage_frac=0.4018 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=13.7570
step:648/1750 train_time:305549ms step_avg:471.53ms
[train step 648] avg_loss=3.665070 main=3.176322 aux=0.488748 imp_cv2=0.3217 load_cv2=5.4380 usage_frac=0.3973 topk_prob_mean=0.2989 ema_alpha_reverse=nan max_logit=13.7570
step:649/1750 train_time:306026ms step_avg:471.54ms
[train step 649] avg_loss=4.845117 main=4.334143 aux=0.510975 imp_cv2=0.1983 load_cv2=5.7872 usage_frac=0.3929 topk_prob_mean=0.2408 ema_alpha_reverse=nan max_logit=13.1453
step:650/1750 train_time:306482ms step_avg:471.51ms
Running validation...
step:650/1750 val_loss:3.576404 train_time:306494ms step_avg:471.53ms
[train step 650] avg_loss=4.122174 main=3.586100 aux=0.536073 imp_cv2=0.1900 load_cv2=6.0619 usage_frac=0.3482 topk_prob_mean=0.2161 ema_alpha_reverse=nan max_logit=11.7634
step:651/1750 train_time:306951ms step_avg:471.51ms
[train step 651] avg_loss=4.181477 main=3.681781 aux=0.499696 imp_cv2=0.2187 load_cv2=5.6561 usage_frac=0.3929 topk_prob_mean=0.2622 ema_alpha_reverse=nan max_logit=13.6062
step:652/1750 train_time:307398ms step_avg:471.47ms
[train step 652] avg_loss=3.758385 main=3.277272 aux=0.481114 imp_cv2=0.3307 load_cv2=5.3472 usage_frac=0.3929 topk_prob_mean=0.3053 ema_alpha_reverse=nan max_logit=12.7744
step:653/1750 train_time:307870ms step_avg:471.47ms
[train step 653] avg_loss=3.904197 main=3.410493 aux=0.493704 imp_cv2=0.2664 load_cv2=5.5555 usage_frac=0.3973 topk_prob_mean=0.2798 ema_alpha_reverse=nan max_logit=13.7570
step:654/1750 train_time:308354ms step_avg:471.49ms
[train step 654] avg_loss=5.033276 main=4.541626 aux=0.491650 imp_cv2=0.2258 load_cv2=5.5309 usage_frac=0.3884 topk_prob_mean=0.2665 ema_alpha_reverse=nan max_logit=12.7744
step:655/1750 train_time:308822ms step_avg:471.48ms
[train step 655] avg_loss=3.889107 main=3.409832 aux=0.479275 imp_cv2=0.3340 load_cv2=5.3206 usage_frac=0.4018 topk_prob_mean=0.3074 ema_alpha_reverse=nan max_logit=13.7570
step:656/1750 train_time:309315ms step_avg:471.52ms
[train step 656] avg_loss=3.902099 main=3.421199 aux=0.480899 imp_cv2=0.3459 load_cv2=5.3293 usage_frac=0.4018 topk_prob_mean=0.3125 ema_alpha_reverse=nan max_logit=13.7570
step:657/1750 train_time:309782ms step_avg:471.51ms
[train step 657] avg_loss=4.579600 main=4.073619 aux=0.505981 imp_cv2=0.2110 load_cv2=5.7323 usage_frac=0.3884 topk_prob_mean=0.2530 ema_alpha_reverse=nan max_logit=13.7570
step:658/1750 train_time:310254ms step_avg:471.51ms
[train step 658] avg_loss=3.834455 main=3.345988 aux=0.488466 imp_cv2=0.3030 load_cv2=5.4444 usage_frac=0.4062 topk_prob_mean=0.2973 ema_alpha_reverse=nan max_logit=13.7570
step:659/1750 train_time:310727ms step_avg:471.51ms
[train step 659] avg_loss=3.797158 main=3.310018 aux=0.487140 imp_cv2=0.3222 load_cv2=5.4136 usage_frac=0.3973 topk_prob_mean=0.3029 ema_alpha_reverse=nan max_logit=13.7570
step:660/1750 train_time:311190ms step_avg:471.50ms
[train step 660] avg_loss=3.990261 main=3.502333 aux=0.487928 imp_cv2=0.2967 load_cv2=5.4462 usage_frac=0.4152 topk_prob_mean=0.2942 ema_alpha_reverse=nan max_logit=13.7570
step:661/1750 train_time:311663ms step_avg:471.50ms
[train step 661] avg_loss=3.886138 main=3.397840 aux=0.488298 imp_cv2=0.3090 load_cv2=5.4430 usage_frac=0.4062 topk_prob_mean=0.2966 ema_alpha_reverse=nan max_logit=13.7570
step:662/1750 train_time:312139ms step_avg:471.51ms
[train step 662] avg_loss=4.169553 main=3.677777 aux=0.491776 imp_cv2=0.2531 load_cv2=5.5381 usage_frac=0.4018 topk_prob_mean=0.2770 ema_alpha_reverse=nan max_logit=13.7570
step:663/1750 train_time:312598ms step_avg:471.49ms
[train step 663] avg_loss=4.080099 main=3.592859 aux=0.487240 imp_cv2=0.2230 load_cv2=5.4870 usage_frac=0.3973 topk_prob_mean=0.2693 ema_alpha_reverse=nan max_logit=13.7570
step:664/1750 train_time:313072ms step_avg:471.49ms
[train step 664] avg_loss=4.095951 main=3.603153 aux=0.492798 imp_cv2=0.2117 load_cv2=5.5711 usage_frac=0.3973 topk_prob_mean=0.2593 ema_alpha_reverse=nan max_logit=13.7570
step:665/1750 train_time:313731ms step_avg:471.78ms
[train step 665] avg_loss=3.934117 main=3.446643 aux=0.487474 imp_cv2=0.2423 load_cv2=5.4862 usage_frac=0.3973 topk_prob_mean=0.2741 ema_alpha_reverse=nan max_logit=13.7570
step:666/1750 train_time:314213ms step_avg:471.79ms
[train step 666] avg_loss=4.111125 main=3.623162 aux=0.487964 imp_cv2=0.2604 load_cv2=5.4774 usage_frac=0.4062 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=13.7570
step:667/1750 train_time:314699ms step_avg:471.81ms
[train step 667] avg_loss=3.959172 main=3.472566 aux=0.486606 imp_cv2=0.2337 load_cv2=5.4771 usage_frac=0.4018 topk_prob_mean=0.2746 ema_alpha_reverse=nan max_logit=13.7570
step:668/1750 train_time:315166ms step_avg:471.81ms
[train step 668] avg_loss=4.499396 main=4.005372 aux=0.494024 imp_cv2=0.2203 load_cv2=5.5780 usage_frac=0.3973 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=13.5259
step:669/1750 train_time:315653ms step_avg:471.83ms
[train step 669] avg_loss=3.852967 main=3.379972 aux=0.472994 imp_cv2=0.3743 load_cv2=5.1939 usage_frac=0.4062 topk_prob_mean=0.3211 ema_alpha_reverse=nan max_logit=13.7570
step:670/1750 train_time:316122ms step_avg:471.82ms
[train step 670] avg_loss=4.426989 main=3.923019 aux=0.503970 imp_cv2=0.1892 load_cv2=5.7110 usage_frac=0.3973 topk_prob_mean=0.2416 ema_alpha_reverse=nan max_logit=12.7744
step:671/1750 train_time:316600ms step_avg:471.83ms
[train step 671] avg_loss=3.774311 main=3.292876 aux=0.481435 imp_cv2=0.3231 load_cv2=5.3418 usage_frac=0.3973 topk_prob_mean=0.3005 ema_alpha_reverse=nan max_logit=13.7570
step:672/1750 train_time:317091ms step_avg:471.86ms
[train step 672] avg_loss=3.703333 main=3.223445 aux=0.479888 imp_cv2=0.3290 load_cv2=5.3081 usage_frac=0.4062 topk_prob_mean=0.3083 ema_alpha_reverse=nan max_logit=13.7570
step:673/1750 train_time:317559ms step_avg:471.86ms
[train step 673] avg_loss=3.852481 main=3.367099 aux=0.485382 imp_cv2=0.2863 load_cv2=5.4162 usage_frac=0.4018 topk_prob_mean=0.2903 ema_alpha_reverse=nan max_logit=13.7570
step:674/1750 train_time:318049ms step_avg:471.88ms
[train step 674] avg_loss=4.252613 main=3.759901 aux=0.492712 imp_cv2=0.2346 load_cv2=5.5422 usage_frac=0.3929 topk_prob_mean=0.2714 ema_alpha_reverse=nan max_logit=12.9028
step:675/1750 train_time:318514ms step_avg:471.87ms
[train step 675] avg_loss=3.918760 main=3.433306 aux=0.485455 imp_cv2=0.2955 load_cv2=5.4100 usage_frac=0.4107 topk_prob_mean=0.2916 ema_alpha_reverse=nan max_logit=13.7570
step:676/1750 train_time:319004ms step_avg:471.90ms
[train step 676] avg_loss=4.950416 main=4.452080 aux=0.498336 imp_cv2=0.2107 load_cv2=5.6331 usage_frac=0.4018 topk_prob_mean=0.2575 ema_alpha_reverse=nan max_logit=12.7744
step:677/1750 train_time:319473ms step_avg:471.90ms
[train step 677] avg_loss=4.143759 main=3.650552 aux=0.493207 imp_cv2=0.2217 load_cv2=5.5611 usage_frac=0.3929 topk_prob_mean=0.2631 ema_alpha_reverse=nan max_logit=12.7744
step:678/1750 train_time:319939ms step_avg:471.89ms
[train step 678] avg_loss=4.036538 main=3.537341 aux=0.499197 imp_cv2=0.2133 load_cv2=5.6360 usage_frac=0.3973 topk_prob_mean=0.2568 ema_alpha_reverse=nan max_logit=13.7570
step:679/1750 train_time:320401ms step_avg:471.87ms
[train step 679] avg_loss=3.971250 main=3.477674 aux=0.493576 imp_cv2=0.2344 load_cv2=5.5475 usage_frac=0.4018 topk_prob_mean=0.2699 ema_alpha_reverse=nan max_logit=13.7570
step:680/1750 train_time:320885ms step_avg:471.89ms
[train step 680] avg_loss=3.876562 main=3.394845 aux=0.481717 imp_cv2=0.3391 load_cv2=5.3376 usage_frac=0.4018 topk_prob_mean=0.3015 ema_alpha_reverse=nan max_logit=12.7744
step:681/1750 train_time:321367ms step_avg:471.90ms
[train step 681] avg_loss=4.555931 main=4.056495 aux=0.499436 imp_cv2=0.2262 load_cv2=5.6311 usage_frac=0.3884 topk_prob_mean=0.2558 ema_alpha_reverse=nan max_logit=12.7744
step:682/1750 train_time:321843ms step_avg:471.91ms
[train step 682] avg_loss=4.370465 main=3.879404 aux=0.491061 imp_cv2=0.2406 load_cv2=5.5180 usage_frac=0.3973 topk_prob_mean=0.2646 ema_alpha_reverse=nan max_logit=12.9192
step:683/1750 train_time:322315ms step_avg:471.91ms
[train step 683] avg_loss=4.562585 main=4.059819 aux=0.502767 imp_cv2=0.1966 load_cv2=5.6909 usage_frac=0.3929 topk_prob_mean=0.2441 ema_alpha_reverse=nan max_logit=12.8752
step:684/1750 train_time:322769ms step_avg:471.88ms
[train step 684] avg_loss=3.678939 main=3.197034 aux=0.481905 imp_cv2=0.3367 load_cv2=5.3396 usage_frac=0.3973 topk_prob_mean=0.2966 ema_alpha_reverse=nan max_logit=12.7744
step:685/1750 train_time:323244ms step_avg:471.89ms
[train step 685] avg_loss=4.277350 main=3.775198 aux=0.502152 imp_cv2=0.2102 load_cv2=5.6791 usage_frac=0.3929 topk_prob_mean=0.2545 ema_alpha_reverse=nan max_logit=12.7744
step:686/1750 train_time:323718ms step_avg:471.89ms
[train step 686] avg_loss=3.934166 main=3.448948 aux=0.485219 imp_cv2=0.2869 load_cv2=5.4234 usage_frac=0.3973 topk_prob_mean=0.2871 ema_alpha_reverse=nan max_logit=12.7744
step:687/1750 train_time:324207ms step_avg:471.92ms
[train step 687] avg_loss=4.083270 main=3.596963 aux=0.486307 imp_cv2=0.2666 load_cv2=5.4448 usage_frac=0.3884 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=12.7744
step:688/1750 train_time:324672ms step_avg:471.91ms
[train step 688] avg_loss=4.435799 main=3.924885 aux=0.510914 imp_cv2=0.2018 load_cv2=5.7816 usage_frac=0.3884 topk_prob_mean=0.2398 ema_alpha_reverse=nan max_logit=12.7744
step:689/1750 train_time:325334ms step_avg:472.18ms
[train step 689] avg_loss=3.785360 main=3.305322 aux=0.480038 imp_cv2=0.3255 load_cv2=5.3168 usage_frac=0.3929 topk_prob_mean=0.3038 ema_alpha_reverse=nan max_logit=12.7744
step:690/1750 train_time:325812ms step_avg:472.19ms
[train step 690] avg_loss=3.755090 main=3.269751 aux=0.485338 imp_cv2=0.2598 load_cv2=5.4322 usage_frac=0.3884 topk_prob_mean=0.2815 ema_alpha_reverse=nan max_logit=12.7744
step:691/1750 train_time:326269ms step_avg:472.17ms
[train step 691] avg_loss=3.914231 main=3.439939 aux=0.474291 imp_cv2=0.2988 load_cv2=5.2630 usage_frac=0.4018 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=12.8939
step:692/1750 train_time:326736ms step_avg:472.16ms
[train step 692] avg_loss=3.467214 main=2.990141 aux=0.477073 imp_cv2=0.4068 load_cv2=5.2154 usage_frac=0.3929 topk_prob_mean=0.3221 ema_alpha_reverse=nan max_logit=13.7570
step:693/1750 train_time:327234ms step_avg:472.20ms
[train step 693] avg_loss=4.070552 main=3.576436 aux=0.494116 imp_cv2=0.2198 load_cv2=5.5809 usage_frac=0.3884 topk_prob_mean=0.2612 ema_alpha_reverse=nan max_logit=12.7744
step:694/1750 train_time:327705ms step_avg:472.20ms
[train step 694] avg_loss=3.911984 main=3.432410 aux=0.479574 imp_cv2=0.3246 load_cv2=5.3151 usage_frac=0.3973 topk_prob_mean=0.3032 ema_alpha_reverse=nan max_logit=13.5412
step:695/1750 train_time:328190ms step_avg:472.22ms
[train step 695] avg_loss=4.219941 main=3.466838 aux=0.753103 imp_cv2=3.9012 load_cv2=4.9242 usage_frac=0.4911 topk_prob_mean=0.8363 ema_alpha_reverse=nan max_logit=13.5380
step:696/1750 train_time:328713ms step_avg:472.29ms
[train step 696] avg_loss=3.755969 main=3.334872 aux=0.421097 imp_cv2=1.1576 load_cv2=3.7010 usage_frac=0.5134 topk_prob_mean=0.5004 ema_alpha_reverse=nan max_logit=13.7570
step:697/1750 train_time:329548ms step_avg:472.81ms
[train step 697] avg_loss=3.944847 main=3.452562 aux=0.492285 imp_cv2=0.6023 load_cv2=5.1775 usage_frac=0.4598 topk_prob_mean=0.3459 ema_alpha_reverse=nan max_logit=12.8229
step:698/1750 train_time:330055ms step_avg:472.86ms
[train step 698] avg_loss=4.194617 main=3.720172 aux=0.474445 imp_cv2=0.4071 load_cv2=5.1517 usage_frac=0.4643 topk_prob_mean=0.3185 ema_alpha_reverse=nan max_logit=13.2330
step:699/1750 train_time:330541ms step_avg:472.88ms
[train step 699] avg_loss=4.107417 main=3.635389 aux=0.472028 imp_cv2=0.2259 load_cv2=5.2569 usage_frac=0.4286 topk_prob_mean=0.2860 ema_alpha_reverse=nan max_logit=12.7744
step:700/1750 train_time:331034ms step_avg:472.91ms
Running validation...
step:700/1750 val_loss:3.595076 train_time:331046ms step_avg:472.92ms
[train step 700] avg_loss=3.850747 main=3.393000 aux=0.457747 imp_cv2=0.2426 load_cv2=5.0809 usage_frac=0.4152 topk_prob_mean=0.3054 ema_alpha_reverse=nan max_logit=12.7744
step:701/1750 train_time:331513ms step_avg:472.91ms
[train step 701] avg_loss=3.888993 main=3.432301 aux=0.456692 imp_cv2=0.2319 load_cv2=5.0856 usage_frac=0.4152 topk_prob_mean=0.3029 ema_alpha_reverse=nan max_logit=13.7570
step:702/1750 train_time:331992ms step_avg:472.92ms
[train step 702] avg_loss=3.852253 main=3.401272 aux=0.450982 imp_cv2=0.2946 load_cv2=4.9557 usage_frac=0.4330 topk_prob_mean=0.3166 ema_alpha_reverse=nan max_logit=13.7570
step:703/1750 train_time:332507ms step_avg:472.98ms
[train step 703] avg_loss=4.018564 main=3.565536 aux=0.453028 imp_cv2=0.2009 load_cv2=5.0634 usage_frac=0.4286 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=13.7570
step:704/1750 train_time:333001ms step_avg:473.01ms
[train step 704] avg_loss=3.957937 main=3.510796 aux=0.447142 imp_cv2=0.2351 load_cv2=4.9654 usage_frac=0.4241 topk_prob_mean=0.3047 ema_alpha_reverse=nan max_logit=12.7744
step:705/1750 train_time:333513ms step_avg:473.07ms
[train step 705] avg_loss=3.747515 main=3.298512 aux=0.449003 imp_cv2=0.2505 load_cv2=4.9794 usage_frac=0.4196 topk_prob_mean=0.3085 ema_alpha_reverse=nan max_logit=13.7570
step:706/1750 train_time:334206ms step_avg:473.38ms
[train step 706] avg_loss=3.802557 main=3.353285 aux=0.449273 imp_cv2=0.2374 load_cv2=4.9988 usage_frac=0.4107 topk_prob_mean=0.3046 ema_alpha_reverse=nan max_logit=12.7744
step:707/1750 train_time:334691ms step_avg:473.40ms
[train step 707] avg_loss=3.868551 main=3.406064 aux=0.462486 imp_cv2=0.1582 load_cv2=5.2335 usage_frac=0.4152 topk_prob_mean=0.2726 ema_alpha_reverse=nan max_logit=12.7744
step:708/1750 train_time:335171ms step_avg:473.41ms
[train step 708] avg_loss=4.137480 main=3.668913 aux=0.468568 imp_cv2=0.1348 load_cv2=5.3269 usage_frac=0.4196 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=13.3714
step:709/1750 train_time:335661ms step_avg:473.43ms
[train step 709] avg_loss=3.876130 main=3.418003 aux=0.458127 imp_cv2=0.1634 load_cv2=5.1801 usage_frac=0.4241 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=12.7744
step:710/1750 train_time:336136ms step_avg:473.43ms
[train step 710] avg_loss=4.025083 main=3.560088 aux=0.464995 imp_cv2=0.1247 load_cv2=5.2931 usage_frac=0.4107 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=12.7744
step:711/1750 train_time:336608ms step_avg:473.43ms
[train step 711] avg_loss=3.868933 main=3.404275 aux=0.464658 imp_cv2=0.1377 load_cv2=5.2783 usage_frac=0.4062 topk_prob_mean=0.2723 ema_alpha_reverse=nan max_logit=12.7744
step:712/1750 train_time:337102ms step_avg:473.46ms
[train step 712] avg_loss=4.564820 main=4.050022 aux=0.514798 imp_cv2=0.0942 load_cv2=5.8755 usage_frac=0.4152 topk_prob_mean=0.2141 ema_alpha_reverse=nan max_logit=12.7744
step:713/1750 train_time:337598ms step_avg:473.49ms
[train step 713] avg_loss=3.676876 main=3.218069 aux=0.458807 imp_cv2=0.1874 load_cv2=5.1670 usage_frac=0.4152 topk_prob_mean=0.2881 ema_alpha_reverse=nan max_logit=12.7744
step:714/1750 train_time:338084ms step_avg:473.51ms
[train step 714] avg_loss=3.628168 main=3.167436 aux=0.460732 imp_cv2=0.2616 load_cv2=5.1282 usage_frac=0.4196 topk_prob_mean=0.3063 ema_alpha_reverse=nan max_logit=12.7744
step:715/1750 train_time:338574ms step_avg:473.53ms
[train step 715] avg_loss=4.063971 main=3.600314 aux=0.463657 imp_cv2=0.1616 load_cv2=5.2525 usage_frac=0.4152 topk_prob_mean=0.2769 ema_alpha_reverse=nan max_logit=12.7744
step:716/1750 train_time:339247ms step_avg:473.81ms
[train step 716] avg_loss=3.651359 main=3.171594 aux=0.479765 imp_cv2=0.0887 load_cv2=5.5127 usage_frac=0.4152 topk_prob_mean=0.2477 ema_alpha_reverse=nan max_logit=12.7744
step:717/1750 train_time:339729ms step_avg:473.82ms
[train step 717] avg_loss=4.702822 main=4.215372 aux=0.487451 imp_cv2=0.0709 load_cv2=5.6055 usage_frac=0.4107 topk_prob_mean=0.2374 ema_alpha_reverse=nan max_logit=12.7744
step:718/1750 train_time:340207ms step_avg:473.83ms
[train step 718] avg_loss=3.938614 main=3.463400 aux=0.475214 imp_cv2=0.1015 load_cv2=5.4418 usage_frac=0.4107 topk_prob_mean=0.2558 ema_alpha_reverse=nan max_logit=12.7744
step:719/1750 train_time:340693ms step_avg:473.84ms
[train step 719] avg_loss=3.975346 main=3.502620 aux=0.472726 imp_cv2=0.1141 load_cv2=5.4064 usage_frac=0.4241 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=12.7744
step:720/1750 train_time:341166ms step_avg:473.84ms
[train step 720] avg_loss=3.838929 main=3.365469 aux=0.473460 imp_cv2=0.1033 load_cv2=5.4262 usage_frac=0.4152 topk_prob_mean=0.2535 ema_alpha_reverse=nan max_logit=12.7744
step:721/1750 train_time:341639ms step_avg:473.84ms
[train step 721] avg_loss=3.784212 main=3.308505 aux=0.475707 imp_cv2=0.1002 load_cv2=5.4444 usage_frac=0.4018 topk_prob_mean=0.2558 ema_alpha_reverse=nan max_logit=12.7744
step:722/1750 train_time:342097ms step_avg:473.82ms
[train step 722] avg_loss=3.835562 main=3.369474 aux=0.466088 imp_cv2=0.1542 load_cv2=5.2892 usage_frac=0.4152 topk_prob_mean=0.2798 ema_alpha_reverse=nan max_logit=12.7744
step:723/1750 train_time:342566ms step_avg:473.81ms
[train step 723] avg_loss=4.305257 main=3.802778 aux=0.502480 imp_cv2=0.0576 load_cv2=5.7923 usage_frac=0.4062 topk_prob_mean=0.2131 ema_alpha_reverse=nan max_logit=12.7744
step:724/1750 train_time:343040ms step_avg:473.81ms
[train step 724] avg_loss=3.727460 main=3.259513 aux=0.467947 imp_cv2=0.1544 load_cv2=5.3150 usage_frac=0.4241 topk_prob_mean=0.2778 ema_alpha_reverse=nan max_logit=12.7744
step:725/1750 train_time:343506ms step_avg:473.80ms
[train step 725] avg_loss=4.219604 main=3.735310 aux=0.484294 imp_cv2=0.0780 load_cv2=5.5755 usage_frac=0.4062 topk_prob_mean=0.2453 ema_alpha_reverse=nan max_logit=12.7744
step:726/1750 train_time:343982ms step_avg:473.80ms
[train step 726] avg_loss=4.127307 main=3.655358 aux=0.471949 imp_cv2=0.1105 load_cv2=5.4058 usage_frac=0.4152 topk_prob_mean=0.2641 ema_alpha_reverse=nan max_logit=12.7744
step:727/1750 train_time:344447ms step_avg:473.79ms
[train step 727] avg_loss=3.868157 main=3.402031 aux=0.466126 imp_cv2=0.1659 load_cv2=5.2877 usage_frac=0.4107 topk_prob_mean=0.2832 ema_alpha_reverse=nan max_logit=12.7744
step:728/1750 train_time:344916ms step_avg:473.79ms
[train step 728] avg_loss=4.504674 main=3.991549 aux=0.513125 imp_cv2=0.0711 load_cv2=5.8914 usage_frac=0.3884 topk_prob_mean=0.2050 ema_alpha_reverse=nan max_logit=10.0135
step:729/1750 train_time:345384ms step_avg:473.78ms
[train step 729] avg_loss=4.170009 main=3.689656 aux=0.480353 imp_cv2=0.0893 load_cv2=5.5187 usage_frac=0.4241 topk_prob_mean=0.2513 ema_alpha_reverse=nan max_logit=12.7744
step:730/1750 train_time:345870ms step_avg:473.79ms
[train step 730] avg_loss=3.845973 main=3.373561 aux=0.472412 imp_cv2=0.1195 load_cv2=5.4021 usage_frac=0.4152 topk_prob_mean=0.2657 ema_alpha_reverse=nan max_logit=12.7744
step:731/1750 train_time:346325ms step_avg:473.77ms
[train step 731] avg_loss=3.890924 main=3.424723 aux=0.466201 imp_cv2=0.1355 load_cv2=5.3158 usage_frac=0.4062 topk_prob_mean=0.2729 ema_alpha_reverse=nan max_logit=12.7744
step:732/1750 train_time:346805ms step_avg:473.78ms
[train step 732] avg_loss=4.257217 main=3.780887 aux=0.476331 imp_cv2=0.0861 load_cv2=5.4739 usage_frac=0.4152 topk_prob_mean=0.2505 ema_alpha_reverse=nan max_logit=12.7744
step:733/1750 train_time:347274ms step_avg:473.77ms
[train step 733] avg_loss=4.035603 main=3.559037 aux=0.476566 imp_cv2=0.0948 load_cv2=5.4732 usage_frac=0.3929 topk_prob_mean=0.2523 ema_alpha_reverse=nan max_logit=12.7744
step:734/1750 train_time:347749ms step_avg:473.77ms
[train step 734] avg_loss=3.733207 main=3.275370 aux=0.457838 imp_cv2=0.2049 load_cv2=5.1569 usage_frac=0.4152 topk_prob_mean=0.2980 ema_alpha_reverse=nan max_logit=12.7744
step:735/1750 train_time:348248ms step_avg:473.81ms
[train step 735] avg_loss=4.244503 main=3.769593 aux=0.474910 imp_cv2=0.0885 load_cv2=5.4565 usage_frac=0.4107 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=12.7744
step:736/1750 train_time:348725ms step_avg:473.81ms
[train step 736] avg_loss=4.277097 main=3.793587 aux=0.483510 imp_cv2=0.0726 load_cv2=5.5748 usage_frac=0.4152 topk_prob_mean=0.2386 ema_alpha_reverse=nan max_logit=12.7744
step:737/1750 train_time:349202ms step_avg:473.81ms
[train step 737] avg_loss=3.767344 main=3.303370 aux=0.463974 imp_cv2=0.1489 load_cv2=5.2752 usage_frac=0.4196 topk_prob_mean=0.2793 ema_alpha_reverse=nan max_logit=12.7744
step:738/1750 train_time:349673ms step_avg:473.81ms
[train step 738] avg_loss=4.098276 main=3.627728 aux=0.470548 imp_cv2=0.1148 load_cv2=5.3876 usage_frac=0.4062 topk_prob_mean=0.2656 ema_alpha_reverse=nan max_logit=12.7744
step:739/1750 train_time:350129ms step_avg:473.79ms
[train step 739] avg_loss=4.245803 main=3.765741 aux=0.480063 imp_cv2=0.0874 load_cv2=5.5189 usage_frac=0.4062 topk_prob_mean=0.2490 ema_alpha_reverse=nan max_logit=12.7744
step:740/1750 train_time:350585ms step_avg:473.76ms
[train step 740] avg_loss=4.240138 main=3.761853 aux=0.478284 imp_cv2=0.0881 load_cv2=5.4948 usage_frac=0.4062 topk_prob_mean=0.2516 ema_alpha_reverse=nan max_logit=12.7744
step:741/1750 train_time:351058ms step_avg:473.76ms
[train step 741] avg_loss=4.180762 main=3.703393 aux=0.477369 imp_cv2=0.1018 load_cv2=5.4750 usage_frac=0.4196 topk_prob_mean=0.2549 ema_alpha_reverse=nan max_logit=12.7744
step:742/1750 train_time:351529ms step_avg:473.76ms
[train step 742] avg_loss=4.104001 main=3.620733 aux=0.483268 imp_cv2=0.0822 load_cv2=5.5583 usage_frac=0.4062 topk_prob_mean=0.2437 ema_alpha_reverse=nan max_logit=12.7744
step:743/1750 train_time:352019ms step_avg:473.78ms
[train step 743] avg_loss=3.833471 main=3.364658 aux=0.468813 imp_cv2=0.1606 load_cv2=5.3209 usage_frac=0.4107 topk_prob_mean=0.2815 ema_alpha_reverse=nan max_logit=12.7744
step:744/1750 train_time:352484ms step_avg:473.77ms
[train step 744] avg_loss=3.981853 main=3.508418 aux=0.473435 imp_cv2=0.1402 load_cv2=5.3996 usage_frac=0.4107 topk_prob_mean=0.2686 ema_alpha_reverse=nan max_logit=12.7744
step:745/1750 train_time:352974ms step_avg:473.79ms
[train step 745] avg_loss=4.298123 main=3.822662 aux=0.475462 imp_cv2=0.1292 load_cv2=5.4324 usage_frac=0.4196 topk_prob_mean=0.2646 ema_alpha_reverse=nan max_logit=12.7744
step:746/1750 train_time:353457ms step_avg:473.80ms
[train step 746] avg_loss=3.856625 main=3.383207 aux=0.473418 imp_cv2=0.1548 load_cv2=5.3874 usage_frac=0.4152 topk_prob_mean=0.2727 ema_alpha_reverse=nan max_logit=12.7744
step:747/1750 train_time:353935ms step_avg:473.81ms
[train step 747] avg_loss=3.795701 main=3.317134 aux=0.478567 imp_cv2=0.1334 load_cv2=5.4672 usage_frac=0.4018 topk_prob_mean=0.2627 ema_alpha_reverse=nan max_logit=12.7744
step:748/1750 train_time:354408ms step_avg:473.81ms
[train step 748] avg_loss=4.105941 main=3.626889 aux=0.479052 imp_cv2=0.1213 load_cv2=5.4828 usage_frac=0.4196 topk_prob_mean=0.2592 ema_alpha_reverse=nan max_logit=12.7744
step:749/1750 train_time:354881ms step_avg:473.81ms
[train step 749] avg_loss=4.447461 main=3.922990 aux=0.524471 imp_cv2=0.0387 load_cv2=6.0717 usage_frac=0.3973 topk_prob_mean=0.1867 ema_alpha_reverse=nan max_logit=12.3212
step:750/1750 train_time:355336ms step_avg:473.78ms
Running validation...
step:750/1750 val_loss:3.455575 train_time:355348ms step_avg:473.80ms
[train step 750] avg_loss=4.455532 main=3.952139 aux=0.503393 imp_cv2=0.0569 load_cv2=5.8135 usage_frac=0.4196 topk_prob_mean=0.2136 ema_alpha_reverse=nan max_logit=12.7868
step:751/1750 train_time:355819ms step_avg:473.79ms
[train step 751] avg_loss=4.326283 main=3.819782 aux=0.506502 imp_cv2=0.0585 load_cv2=5.8550 usage_frac=0.4107 topk_prob_mean=0.2126 ema_alpha_reverse=nan max_logit=12.7744
step:752/1750 train_time:356267ms step_avg:473.76ms
[train step 752] avg_loss=3.952933 main=3.457718 aux=0.495215 imp_cv2=0.0670 load_cv2=5.7156 usage_frac=0.4062 topk_prob_mean=0.2277 ema_alpha_reverse=nan max_logit=12.7744
step:753/1750 train_time:356743ms step_avg:473.76ms
[train step 753] avg_loss=3.932448 main=3.450967 aux=0.481481 imp_cv2=0.1126 load_cv2=5.5191 usage_frac=0.4062 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=12.7744
step:754/1750 train_time:357198ms step_avg:473.74ms
[train step 754] avg_loss=4.147414 main=3.668337 aux=0.479077 imp_cv2=0.1171 load_cv2=5.4794 usage_frac=0.4107 topk_prob_mean=0.2549 ema_alpha_reverse=nan max_logit=12.7744
step:755/1750 train_time:357659ms step_avg:473.72ms
[train step 755] avg_loss=4.775394 main=4.237142 aux=0.538252 imp_cv2=0.0722 load_cv2=6.2123 usage_frac=0.3571 topk_prob_mean=0.1846 ema_alpha_reverse=nan max_logit=12.2424
step:756/1750 train_time:358114ms step_avg:473.70ms
[train step 756] avg_loss=4.377545 main=3.894283 aux=0.483262 imp_cv2=0.0933 load_cv2=5.5480 usage_frac=0.4107 topk_prob_mean=0.2418 ema_alpha_reverse=nan max_logit=12.7744
step:757/1750 train_time:358583ms step_avg:473.69ms
[train step 757] avg_loss=4.205990 main=3.712498 aux=0.493492 imp_cv2=0.0684 load_cv2=5.7003 usage_frac=0.4152 topk_prob_mean=0.2287 ema_alpha_reverse=nan max_logit=12.7744
step:758/1750 train_time:359043ms step_avg:473.67ms
[train step 758] avg_loss=3.359528 main=2.890944 aux=0.468584 imp_cv2=0.2515 load_cv2=5.2485 usage_frac=0.4196 topk_prob_mean=0.3018 ema_alpha_reverse=nan max_logit=13.2888
step:759/1750 train_time:359533ms step_avg:473.69ms
[train step 759] avg_loss=3.639229 main=3.168262 aux=0.470966 imp_cv2=0.1688 load_cv2=5.3505 usage_frac=0.4330 topk_prob_mean=0.2789 ema_alpha_reverse=nan max_logit=12.7744
step:760/1750 train_time:359993ms step_avg:473.68ms
[train step 760] avg_loss=4.198894 main=3.716801 aux=0.482093 imp_cv2=0.0847 load_cv2=5.5431 usage_frac=0.4286 topk_prob_mean=0.2441 ema_alpha_reverse=nan max_logit=12.7744
step:761/1750 train_time:360458ms step_avg:473.66ms
[train step 761] avg_loss=3.957870 main=3.482229 aux=0.475641 imp_cv2=0.1468 load_cv2=5.4274 usage_frac=0.4152 topk_prob_mean=0.2679 ema_alpha_reverse=nan max_logit=12.7744
step:762/1750 train_time:360919ms step_avg:473.65ms
[train step 762] avg_loss=3.860150 main=3.381359 aux=0.478792 imp_cv2=0.1033 load_cv2=5.4988 usage_frac=0.4241 topk_prob_mean=0.2542 ema_alpha_reverse=nan max_logit=12.7744
step:763/1750 train_time:361374ms step_avg:473.62ms
[train step 763] avg_loss=3.745673 main=3.278132 aux=0.467540 imp_cv2=0.1549 load_cv2=5.3269 usage_frac=0.4286 topk_prob_mean=0.2755 ema_alpha_reverse=nan max_logit=12.7744
step:764/1750 train_time:361867ms step_avg:473.65ms
[train step 764] avg_loss=4.274628 main=3.799969 aux=0.474660 imp_cv2=0.1020 load_cv2=5.4481 usage_frac=0.4196 topk_prob_mean=0.2478 ema_alpha_reverse=nan max_logit=12.7744
step:765/1750 train_time:362322ms step_avg:473.62ms
[train step 765] avg_loss=3.701533 main=3.236425 aux=0.465108 imp_cv2=0.1806 load_cv2=5.2764 usage_frac=0.4152 topk_prob_mean=0.2850 ema_alpha_reverse=nan max_logit=12.7744
step:766/1750 train_time:362804ms step_avg:473.63ms
[train step 766] avg_loss=4.033406 main=3.558634 aux=0.474772 imp_cv2=0.0854 load_cv2=5.4635 usage_frac=0.4330 topk_prob_mean=0.2459 ema_alpha_reverse=nan max_logit=12.7744
step:767/1750 train_time:363280ms step_avg:473.64ms
[train step 767] avg_loss=3.707952 main=3.215891 aux=0.492061 imp_cv2=0.0689 load_cv2=5.6922 usage_frac=0.4330 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=12.7744
step:768/1750 train_time:363761ms step_avg:473.65ms
[train step 768] avg_loss=3.633838 main=3.162555 aux=0.471283 imp_cv2=0.1334 load_cv2=5.3954 usage_frac=0.4107 topk_prob_mean=0.2667 ema_alpha_reverse=nan max_logit=12.7744
step:769/1750 train_time:364223ms step_avg:473.63ms
[train step 769] avg_loss=3.580290 main=3.115870 aux=0.464420 imp_cv2=0.1585 load_cv2=5.2841 usage_frac=0.4286 topk_prob_mean=0.2783 ema_alpha_reverse=nan max_logit=12.7744
step:770/1750 train_time:364697ms step_avg:473.63ms
[train step 770] avg_loss=4.099114 main=3.601010 aux=0.498104 imp_cv2=0.0518 load_cv2=5.7678 usage_frac=0.4152 topk_prob_mean=0.2177 ema_alpha_reverse=nan max_logit=12.7744
step:771/1750 train_time:365188ms step_avg:473.65ms
[train step 771] avg_loss=3.701373 main=3.227020 aux=0.474353 imp_cv2=0.1202 load_cv2=5.4332 usage_frac=0.4152 topk_prob_mean=0.2620 ema_alpha_reverse=nan max_logit=12.7744
step:772/1750 train_time:365673ms step_avg:473.67ms
[train step 772] avg_loss=3.682069 main=3.218226 aux=0.463843 imp_cv2=0.1606 load_cv2=5.2622 usage_frac=0.4286 topk_prob_mean=0.2798 ema_alpha_reverse=nan max_logit=12.7744
step:773/1750 train_time:366148ms step_avg:473.67ms
[train step 773] avg_loss=3.845349 main=3.372848 aux=0.472501 imp_cv2=0.1443 load_cv2=5.3944 usage_frac=0.4286 topk_prob_mean=0.2713 ema_alpha_reverse=nan max_logit=12.7744
step:774/1750 train_time:366625ms step_avg:473.68ms
[train step 774] avg_loss=3.555543 main=3.053391 aux=0.502153 imp_cv2=0.0590 load_cv2=5.8076 usage_frac=0.4152 topk_prob_mean=0.2134 ema_alpha_reverse=nan max_logit=12.7744
step:775/1750 train_time:367083ms step_avg:473.66ms
[train step 775] avg_loss=3.979072 main=3.498398 aux=0.480675 imp_cv2=0.0930 load_cv2=5.5349 usage_frac=0.4018 topk_prob_mean=0.2481 ema_alpha_reverse=nan max_logit=12.7744
step:776/1750 train_time:367537ms step_avg:473.63ms
[train step 776] avg_loss=3.889386 main=3.423243 aux=0.466142 imp_cv2=0.1544 load_cv2=5.3015 usage_frac=0.4196 topk_prob_mean=0.2777 ema_alpha_reverse=nan max_logit=12.7744
step:777/1750 train_time:368020ms step_avg:473.64ms
[train step 777] avg_loss=3.680069 main=3.206416 aux=0.473653 imp_cv2=0.1033 load_cv2=5.4336 usage_frac=0.4062 topk_prob_mean=0.2556 ema_alpha_reverse=nan max_logit=12.7744
step:778/1750 train_time:368490ms step_avg:473.64ms
[train step 778] avg_loss=3.692062 main=3.224312 aux=0.467750 imp_cv2=0.1376 load_cv2=5.3422 usage_frac=0.4286 topk_prob_mean=0.2716 ema_alpha_reverse=nan max_logit=12.7744
step:779/1750 train_time:368954ms step_avg:473.63ms
[train step 779] avg_loss=4.446299 main=3.950089 aux=0.496210 imp_cv2=0.0535 load_cv2=5.7340 usage_frac=0.4152 topk_prob_mean=0.2208 ema_alpha_reverse=nan max_logit=12.7744
step:780/1750 train_time:369426ms step_avg:473.62ms
[train step 780] avg_loss=3.631890 main=3.160954 aux=0.470937 imp_cv2=0.1345 load_cv2=5.3706 usage_frac=0.4152 topk_prob_mean=0.2681 ema_alpha_reverse=nan max_logit=12.7744
step:781/1750 train_time:369896ms step_avg:473.62ms
[train step 781] avg_loss=3.810277 main=3.342976 aux=0.467301 imp_cv2=0.1609 load_cv2=5.3071 usage_frac=0.4196 topk_prob_mean=0.2782 ema_alpha_reverse=nan max_logit=12.7744
step:782/1750 train_time:370374ms step_avg:473.62ms
[train step 782] avg_loss=3.716240 main=3.246561 aux=0.469680 imp_cv2=0.1386 load_cv2=5.3599 usage_frac=0.4196 topk_prob_mean=0.2718 ema_alpha_reverse=nan max_logit=12.7744
step:783/1750 train_time:370854ms step_avg:473.63ms
[train step 783] avg_loss=3.735161 main=3.263271 aux=0.471890 imp_cv2=0.1343 load_cv2=5.3917 usage_frac=0.4286 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=12.7744
step:784/1750 train_time:371337ms step_avg:473.64ms
[train step 784] avg_loss=4.011176 main=3.534478 aux=0.476697 imp_cv2=0.1097 load_cv2=5.4625 usage_frac=0.4241 topk_prob_mean=0.2571 ema_alpha_reverse=nan max_logit=12.7744
step:785/1750 train_time:371793ms step_avg:473.62ms
[train step 785] avg_loss=4.093377 main=3.614099 aux=0.479278 imp_cv2=0.0931 load_cv2=5.5062 usage_frac=0.4196 topk_prob_mean=0.2487 ema_alpha_reverse=nan max_logit=12.7744
step:786/1750 train_time:372263ms step_avg:473.62ms
[train step 786] avg_loss=3.483567 main=3.015780 aux=0.467787 imp_cv2=0.2514 load_cv2=5.2450 usage_frac=0.4196 topk_prob_mean=0.3028 ema_alpha_reverse=nan max_logit=12.7744
step:787/1750 train_time:372730ms step_avg:473.61ms
[train step 787] avg_loss=3.977058 main=3.487689 aux=0.489370 imp_cv2=0.0904 load_cv2=5.6514 usage_frac=0.4286 topk_prob_mean=0.2418 ema_alpha_reverse=nan max_logit=12.7744
step:788/1750 train_time:373208ms step_avg:473.61ms
[train step 788] avg_loss=4.186614 main=3.680778 aux=0.505836 imp_cv2=0.1157 load_cv2=5.7828 usage_frac=0.4107 topk_prob_mean=0.2254 ema_alpha_reverse=nan max_logit=12.7744
step:789/1750 train_time:373667ms step_avg:473.60ms
[train step 789] avg_loss=4.773739 main=4.245805 aux=0.527934 imp_cv2=0.1245 load_cv2=6.0404 usage_frac=0.4241 topk_prob_mean=0.2054 ema_alpha_reverse=nan max_logit=12.7744
step:790/1750 train_time:374133ms step_avg:473.59ms
[train step 790] avg_loss=3.663926 main=3.201680 aux=0.462245 imp_cv2=0.2442 load_cv2=5.1783 usage_frac=0.4375 topk_prob_mean=0.3048 ema_alpha_reverse=nan max_logit=12.7744
step:791/1750 train_time:374615ms step_avg:473.60ms
[train step 791] avg_loss=3.975752 main=3.497561 aux=0.478190 imp_cv2=0.0998 load_cv2=5.4878 usage_frac=0.4196 topk_prob_mean=0.2481 ema_alpha_reverse=nan max_logit=12.7744
step:792/1750 train_time:375075ms step_avg:473.58ms
[train step 792] avg_loss=3.778971 main=3.307437 aux=0.471534 imp_cv2=0.1555 load_cv2=5.3700 usage_frac=0.4196 topk_prob_mean=0.2754 ema_alpha_reverse=nan max_logit=12.7744
step:793/1750 train_time:375547ms step_avg:473.58ms
[train step 793] avg_loss=3.648779 main=3.183788 aux=0.464991 imp_cv2=0.1918 load_cv2=5.2529 usage_frac=0.4196 topk_prob_mean=0.2874 ema_alpha_reverse=nan max_logit=12.7744
step:794/1750 train_time:376022ms step_avg:473.58ms
[train step 794] avg_loss=4.723401 main=4.203930 aux=0.519471 imp_cv2=0.0441 load_cv2=6.0045 usage_frac=0.4286 topk_prob_mean=0.1896 ema_alpha_reverse=nan max_logit=12.7744
step:795/1750 train_time:376500ms step_avg:473.58ms
[train step 795] avg_loss=4.090868 main=3.620412 aux=0.470457 imp_cv2=0.1237 load_cv2=5.3694 usage_frac=0.4375 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=12.7744
step:796/1750 train_time:376972ms step_avg:473.58ms
[train step 796] avg_loss=5.610301 main=5.102400 aux=0.507901 imp_cv2=0.0601 load_cv2=5.8678 usage_frac=0.4330 topk_prob_mean=0.2086 ema_alpha_reverse=nan max_logit=12.7744
step:797/1750 train_time:377461ms step_avg:473.60ms
[train step 797] avg_loss=3.901668 main=3.401600 aux=0.500068 imp_cv2=0.0617 load_cv2=5.7713 usage_frac=0.4330 topk_prob_mean=0.2215 ema_alpha_reverse=nan max_logit=12.7744
step:798/1750 train_time:377933ms step_avg:473.60ms
[train step 798] avg_loss=3.587395 main=3.119015 aux=0.468380 imp_cv2=0.1732 load_cv2=5.3005 usage_frac=0.4241 topk_prob_mean=0.2839 ema_alpha_reverse=nan max_logit=12.7744
step:799/1750 train_time:378400ms step_avg:473.59ms
[train step 799] avg_loss=3.955126 main=3.477111 aux=0.478015 imp_cv2=0.0956 load_cv2=5.4859 usage_frac=0.4241 topk_prob_mean=0.2523 ema_alpha_reverse=nan max_logit=12.7744
step:800/1750 train_time:378877ms step_avg:473.60ms
Running validation...
step:800/1750 val_loss:3.404493 train_time:378889ms step_avg:473.61ms
[train step 800] avg_loss=3.629425 main=3.161228 aux=0.468197 imp_cv2=0.1494 load_cv2=5.3235 usage_frac=0.4286 topk_prob_mean=0.2773 ema_alpha_reverse=nan max_logit=12.7744
step:801/1750 train_time:379355ms step_avg:473.60ms
[train step 801] avg_loss=3.526165 main=3.056427 aux=0.469738 imp_cv2=0.1721 load_cv2=5.3195 usage_frac=0.4241 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=12.7744
step:802/1750 train_time:379827ms step_avg:473.60ms
[train step 802] avg_loss=3.629295 main=3.159843 aux=0.469452 imp_cv2=0.1531 load_cv2=5.3299 usage_frac=0.4241 topk_prob_mean=0.2793 ema_alpha_reverse=nan max_logit=12.7744
step:803/1750 train_time:380307ms step_avg:473.61ms
[train step 803] avg_loss=3.815962 main=3.342862 aux=0.473100 imp_cv2=0.1456 load_cv2=5.3871 usage_frac=0.4286 topk_prob_mean=0.2721 ema_alpha_reverse=nan max_logit=12.7744
step:804/1750 train_time:380781ms step_avg:473.61ms
[train step 804] avg_loss=4.449455 main=3.920668 aux=0.528787 imp_cv2=0.0558 load_cv2=6.1015 usage_frac=0.4107 topk_prob_mean=0.1867 ema_alpha_reverse=nan max_logit=11.7917
step:805/1750 train_time:381253ms step_avg:473.61ms
[train step 805] avg_loss=3.948679 main=3.479334 aux=0.469345 imp_cv2=0.1524 load_cv2=5.3326 usage_frac=0.4241 topk_prob_mean=0.2779 ema_alpha_reverse=nan max_logit=12.7744
step:806/1750 train_time:381712ms step_avg:473.59ms
[train step 806] avg_loss=4.131283 main=3.630131 aux=0.501152 imp_cv2=0.0611 load_cv2=5.7627 usage_frac=0.4286 topk_prob_mean=0.2153 ema_alpha_reverse=nan max_logit=12.7744
step:807/1750 train_time:382175ms step_avg:473.57ms
[train step 807] avg_loss=3.631389 main=3.153881 aux=0.477508 imp_cv2=0.0977 load_cv2=5.4688 usage_frac=0.4286 topk_prob_mean=0.2537 ema_alpha_reverse=nan max_logit=12.7744
step:808/1750 train_time:382638ms step_avg:473.56ms
[train step 808] avg_loss=4.246755 main=3.738220 aux=0.508535 imp_cv2=0.0611 load_cv2=5.8616 usage_frac=0.3884 topk_prob_mean=0.1972 ema_alpha_reverse=nan max_logit=11.7917
step:809/1750 train_time:383287ms step_avg:473.78ms
[train step 809] avg_loss=3.524120 main=3.057965 aux=0.466155 imp_cv2=0.1921 load_cv2=5.2644 usage_frac=0.4286 topk_prob_mean=0.2902 ema_alpha_reverse=nan max_logit=12.7744
step:810/1750 train_time:383761ms step_avg:473.78ms
[train step 810] avg_loss=3.972430 main=3.503747 aux=0.468683 imp_cv2=0.1100 load_cv2=5.3551 usage_frac=0.4286 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=12.7744
step:811/1750 train_time:384224ms step_avg:473.77ms
[train step 811] avg_loss=3.800069 main=3.346020 aux=0.454048 imp_cv2=0.1737 load_cv2=5.1172 usage_frac=0.4286 topk_prob_mean=0.2914 ema_alpha_reverse=nan max_logit=12.7744
step:812/1750 train_time:384695ms step_avg:473.76ms
[train step 812] avg_loss=3.726356 main=3.273746 aux=0.452610 imp_cv2=0.1570 load_cv2=5.1142 usage_frac=0.4241 topk_prob_mean=0.2861 ema_alpha_reverse=nan max_logit=12.7744
step:813/1750 train_time:385170ms step_avg:473.76ms
[train step 813] avg_loss=3.637195 main=3.177818 aux=0.459377 imp_cv2=0.1100 load_cv2=5.2397 usage_frac=0.4688 topk_prob_mean=0.2635 ema_alpha_reverse=nan max_logit=12.7744
step:814/1750 train_time:385653ms step_avg:473.78ms
[train step 814] avg_loss=3.922518 main=3.463887 aux=0.458631 imp_cv2=0.1274 load_cv2=5.2203 usage_frac=0.4286 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=12.7744
step:815/1750 train_time:386129ms step_avg:473.78ms
[train step 815] avg_loss=3.957856 main=3.496377 aux=0.461480 imp_cv2=0.1174 load_cv2=5.2636 usage_frac=0.4286 topk_prob_mean=0.2646 ema_alpha_reverse=nan max_logit=12.7744
step:816/1750 train_time:386613ms step_avg:473.79ms
[train step 816] avg_loss=3.688078 main=3.234819 aux=0.453259 imp_cv2=0.1985 load_cv2=5.0976 usage_frac=0.4286 topk_prob_mean=0.2963 ema_alpha_reverse=nan max_logit=12.7744
step:817/1750 train_time:387094ms step_avg:473.80ms
[train step 817] avg_loss=4.038230 main=3.559849 aux=0.478381 imp_cv2=0.0817 load_cv2=5.4970 usage_frac=0.4196 topk_prob_mean=0.2405 ema_alpha_reverse=nan max_logit=12.7744
step:818/1750 train_time:387561ms step_avg:473.79ms
[train step 818] avg_loss=4.465083 main=3.989873 aux=0.475211 imp_cv2=0.0796 load_cv2=5.4525 usage_frac=0.4241 topk_prob_mean=0.2395 ema_alpha_reverse=nan max_logit=12.7744
step:819/1750 train_time:388038ms step_avg:473.79ms
[train step 819] avg_loss=3.975156 main=3.481497 aux=0.493659 imp_cv2=0.0612 load_cv2=5.6807 usage_frac=0.4241 topk_prob_mean=0.2184 ema_alpha_reverse=nan max_logit=12.7744
step:820/1750 train_time:388503ms step_avg:473.78ms
[train step 820] avg_loss=4.054732 main=3.573272 aux=0.481460 imp_cv2=0.0810 load_cv2=5.5430 usage_frac=0.4375 topk_prob_mean=0.2415 ema_alpha_reverse=nan max_logit=12.7744
step:821/1750 train_time:388969ms step_avg:473.77ms
[train step 821] avg_loss=3.769861 main=3.309763 aux=0.460098 imp_cv2=0.1642 load_cv2=5.2152 usage_frac=0.4375 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=12.7744
step:822/1750 train_time:389440ms step_avg:473.77ms
[train step 822] avg_loss=4.182232 main=3.699133 aux=0.483099 imp_cv2=0.0731 load_cv2=5.5742 usage_frac=0.4375 topk_prob_mean=0.2337 ema_alpha_reverse=nan max_logit=12.7744
step:823/1750 train_time:389900ms step_avg:473.75ms
[train step 823] avg_loss=3.800017 main=3.330676 aux=0.469341 imp_cv2=0.1359 load_cv2=5.3541 usage_frac=0.4375 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=12.7744
step:824/1750 train_time:390379ms step_avg:473.76ms
[train step 824] avg_loss=3.330056 main=2.859437 aux=0.470619 imp_cv2=0.1149 load_cv2=5.3794 usage_frac=0.4286 topk_prob_mean=0.2610 ema_alpha_reverse=nan max_logit=12.7744
step:825/1750 train_time:391039ms step_avg:473.99ms
[train step 825] avg_loss=4.753520 main=4.269229 aux=0.484291 imp_cv2=0.0768 load_cv2=5.5657 usage_frac=0.4375 topk_prob_mean=0.2364 ema_alpha_reverse=nan max_logit=12.7744
step:826/1750 train_time:391507ms step_avg:473.98ms
[train step 826] avg_loss=3.454223 main=2.988508 aux=0.465714 imp_cv2=0.2002 load_cv2=5.2459 usage_frac=0.4330 topk_prob_mean=0.2930 ema_alpha_reverse=nan max_logit=12.7744
step:827/1750 train_time:391989ms step_avg:473.99ms
[train step 827] avg_loss=3.582955 main=3.115687 aux=0.467268 imp_cv2=0.1795 load_cv2=5.2791 usage_frac=0.4286 topk_prob_mean=0.2852 ema_alpha_reverse=nan max_logit=12.7744
step:828/1750 train_time:392458ms step_avg:473.98ms
[train step 828] avg_loss=4.067885 main=3.588763 aux=0.479122 imp_cv2=0.0940 load_cv2=5.4930 usage_frac=0.4330 topk_prob_mean=0.2503 ema_alpha_reverse=nan max_logit=12.7744
step:829/1750 train_time:392917ms step_avg:473.97ms
[train step 829] avg_loss=4.044291 main=3.565296 aux=0.478995 imp_cv2=0.0840 load_cv2=5.4970 usage_frac=0.4286 topk_prob_mean=0.2464 ema_alpha_reverse=nan max_logit=12.7744
step:830/1750 train_time:393379ms step_avg:473.95ms
[train step 830] avg_loss=3.952521 main=3.478855 aux=0.473666 imp_cv2=0.0906 load_cv2=5.4227 usage_frac=0.4286 topk_prob_mean=0.2521 ema_alpha_reverse=nan max_logit=12.7744
step:831/1750 train_time:393856ms step_avg:473.95ms
[train step 831] avg_loss=3.594581 main=3.132966 aux=0.461615 imp_cv2=0.1433 load_cv2=5.2326 usage_frac=0.4330 topk_prob_mean=0.2772 ema_alpha_reverse=nan max_logit=12.7744
step:832/1750 train_time:394333ms step_avg:473.96ms
[train step 832] avg_loss=4.198562 main=3.734386 aux=0.464176 imp_cv2=0.1279 load_cv2=5.2825 usage_frac=0.4241 topk_prob_mean=0.2724 ema_alpha_reverse=nan max_logit=12.7744
step:833/1750 train_time:394796ms step_avg:473.94ms
[train step 833] avg_loss=4.087329 main=3.621624 aux=0.465705 imp_cv2=0.1168 load_cv2=5.3120 usage_frac=0.4330 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=12.7744
step:834/1750 train_time:395275ms step_avg:473.95ms
[train step 834] avg_loss=3.575349 main=3.118993 aux=0.456356 imp_cv2=0.1889 load_cv2=5.1398 usage_frac=0.4286 topk_prob_mean=0.2944 ema_alpha_reverse=nan max_logit=12.7744
step:835/1750 train_time:395761ms step_avg:473.97ms
[train step 835] avg_loss=3.764227 main=3.295984 aux=0.468243 imp_cv2=0.1341 load_cv2=5.3320 usage_frac=0.4286 topk_prob_mean=0.2710 ema_alpha_reverse=nan max_logit=12.7744
step:836/1750 train_time:396253ms step_avg:473.99ms
[train step 836] avg_loss=3.925720 main=3.452609 aux=0.473111 imp_cv2=0.1055 load_cv2=5.4110 usage_frac=0.4286 topk_prob_mean=0.2579 ema_alpha_reverse=nan max_logit=12.7744
step:837/1750 train_time:396729ms step_avg:473.99ms
[train step 837] avg_loss=3.878978 main=3.410082 aux=0.468896 imp_cv2=0.1223 load_cv2=5.3466 usage_frac=0.4286 topk_prob_mean=0.2695 ema_alpha_reverse=nan max_logit=12.7744
step:838/1750 train_time:397389ms step_avg:474.21ms
[train step 838] avg_loss=3.881100 main=3.409537 aux=0.471563 imp_cv2=0.1149 load_cv2=5.3821 usage_frac=0.4330 topk_prob_mean=0.2622 ema_alpha_reverse=nan max_logit=12.7744
step:839/1750 train_time:397868ms step_avg:474.22ms
[train step 839] avg_loss=3.877703 main=3.406654 aux=0.471048 imp_cv2=0.1127 load_cv2=5.3835 usage_frac=0.4375 topk_prob_mean=0.2612 ema_alpha_reverse=nan max_logit=12.7744
step:840/1750 train_time:398339ms step_avg:474.21ms
[train step 840] avg_loss=3.582542 main=3.115701 aux=0.466840 imp_cv2=0.1723 load_cv2=5.2840 usage_frac=0.4375 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=12.7744
step:841/1750 train_time:398817ms step_avg:474.22ms
[train step 841] avg_loss=4.087313 main=3.610978 aux=0.476335 imp_cv2=0.1029 load_cv2=5.4566 usage_frac=0.4286 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=12.7744
step:842/1750 train_time:399285ms step_avg:474.21ms
[train step 842] avg_loss=4.323988 main=3.840037 aux=0.483951 imp_cv2=0.0721 load_cv2=5.5560 usage_frac=0.4330 topk_prob_mean=0.2316 ema_alpha_reverse=nan max_logit=12.7744
step:843/1750 train_time:399753ms step_avg:474.20ms
[train step 843] avg_loss=3.711638 main=3.234167 aux=0.477471 imp_cv2=0.1202 load_cv2=5.4509 usage_frac=0.4330 topk_prob_mean=0.2611 ema_alpha_reverse=nan max_logit=12.7744
step:844/1750 train_time:400223ms step_avg:474.20ms
[train step 844] avg_loss=3.738140 main=3.276873 aux=0.461267 imp_cv2=0.1734 load_cv2=5.2157 usage_frac=0.4286 topk_prob_mean=0.2861 ema_alpha_reverse=nan max_logit=12.7744
step:845/1750 train_time:400699ms step_avg:474.20ms
[train step 845] avg_loss=4.074735 main=3.607294 aux=0.467441 imp_cv2=0.0943 load_cv2=5.3489 usage_frac=0.4375 topk_prob_mean=0.2564 ema_alpha_reverse=nan max_logit=12.7744
step:846/1750 train_time:401165ms step_avg:474.19ms
[train step 846] avg_loss=3.474435 main=3.012047 aux=0.462388 imp_cv2=0.1807 load_cv2=5.2240 usage_frac=0.4286 topk_prob_mean=0.2905 ema_alpha_reverse=nan max_logit=12.7744
step:847/1750 train_time:401643ms step_avg:474.20ms
[train step 847] avg_loss=4.011733 main=3.533175 aux=0.478557 imp_cv2=0.0845 load_cv2=5.5032 usage_frac=0.4330 topk_prob_mean=0.2449 ema_alpha_reverse=nan max_logit=12.7744
step:848/1750 train_time:402105ms step_avg:474.18ms
[train step 848] avg_loss=3.661075 main=3.194667 aux=0.466408 imp_cv2=0.1322 load_cv2=5.3180 usage_frac=0.4420 topk_prob_mean=0.2681 ema_alpha_reverse=nan max_logit=12.7744
step:849/1750 train_time:402579ms step_avg:474.18ms
[train step 849] avg_loss=3.863133 main=3.403249 aux=0.459885 imp_cv2=0.1220 load_cv2=5.2385 usage_frac=0.4286 topk_prob_mean=0.2691 ema_alpha_reverse=nan max_logit=12.7744
step:850/1750 train_time:403052ms step_avg:474.18ms
Running validation...
step:850/1750 val_loss:3.341188 train_time:403064ms step_avg:474.19ms
[train step 850] avg_loss=3.791022 main=3.337380 aux=0.453642 imp_cv2=0.1670 load_cv2=5.1250 usage_frac=0.4286 topk_prob_mean=0.2867 ema_alpha_reverse=nan max_logit=12.7744
step:851/1750 train_time:403531ms step_avg:474.18ms
[train step 851] avg_loss=3.738625 main=3.286467 aux=0.452157 imp_cv2=0.1761 load_cv2=5.1006 usage_frac=0.4286 topk_prob_mean=0.2886 ema_alpha_reverse=nan max_logit=12.7744
step:852/1750 train_time:404023ms step_avg:474.21ms
[train step 852] avg_loss=3.815610 main=3.349209 aux=0.466401 imp_cv2=0.0989 load_cv2=5.3434 usage_frac=0.4286 topk_prob_mean=0.2571 ema_alpha_reverse=nan max_logit=12.7744
step:853/1750 train_time:404496ms step_avg:474.20ms
[train step 853] avg_loss=4.330534 main=3.844300 aux=0.486235 imp_cv2=0.0630 load_cv2=5.6061 usage_frac=0.4286 topk_prob_mean=0.2287 ema_alpha_reverse=nan max_logit=12.7744
step:854/1750 train_time:404958ms step_avg:474.19ms
[train step 854] avg_loss=4.053437 main=3.595178 aux=0.458259 imp_cv2=0.1333 load_cv2=5.2146 usage_frac=0.4286 topk_prob_mean=0.2724 ema_alpha_reverse=nan max_logit=12.7744
step:855/1750 train_time:405429ms step_avg:474.19ms
[train step 855] avg_loss=4.611979 main=4.117662 aux=0.494317 imp_cv2=0.0657 load_cv2=5.6994 usage_frac=0.4241 topk_prob_mean=0.2214 ema_alpha_reverse=nan max_logit=12.7744
step:856/1750 train_time:405899ms step_avg:474.18ms
[train step 856] avg_loss=4.085603 main=3.580653 aux=0.504950 imp_cv2=0.1380 load_cv2=5.7360 usage_frac=0.4152 topk_prob_mean=0.2266 ema_alpha_reverse=nan max_logit=12.7744
step:857/1750 train_time:406380ms step_avg:474.19ms
[train step 857] avg_loss=3.493878 main=3.035695 aux=0.458183 imp_cv2=0.1540 load_cv2=5.1972 usage_frac=0.4196 topk_prob_mean=0.2802 ema_alpha_reverse=nan max_logit=12.7744
step:858/1750 train_time:406853ms step_avg:474.19ms
[train step 858] avg_loss=3.827528 main=3.339153 aux=0.488374 imp_cv2=0.0729 load_cv2=5.6302 usage_frac=0.4152 topk_prob_mean=0.2353 ema_alpha_reverse=nan max_logit=12.7744
step:859/1750 train_time:407309ms step_avg:474.17ms
[train step 859] avg_loss=4.083913 main=3.618764 aux=0.465149 imp_cv2=0.1162 load_cv2=5.3020 usage_frac=0.4241 topk_prob_mean=0.2625 ema_alpha_reverse=nan max_logit=12.7744
step:860/1750 train_time:407979ms step_avg:474.39ms
[train step 860] avg_loss=4.046077 main=3.575830 aux=0.470246 imp_cv2=0.0955 load_cv2=5.3791 usage_frac=0.4196 topk_prob_mean=0.2501 ema_alpha_reverse=nan max_logit=12.7744
step:861/1750 train_time:408458ms step_avg:474.40ms
[train step 861] avg_loss=3.823362 main=3.361429 aux=0.461932 imp_cv2=0.1509 load_cv2=5.2415 usage_frac=0.4241 topk_prob_mean=0.2793 ema_alpha_reverse=nan max_logit=12.7744
step:862/1750 train_time:408935ms step_avg:474.40ms
[train step 862] avg_loss=3.754019 main=3.292184 aux=0.461835 imp_cv2=0.1469 load_cv2=5.2459 usage_frac=0.4152 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=12.7744
step:863/1750 train_time:409404ms step_avg:474.40ms
[train step 863] avg_loss=3.641793 main=3.177262 aux=0.464532 imp_cv2=0.1616 load_cv2=5.2663 usage_frac=0.4152 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=12.7744
step:864/1750 train_time:409878ms step_avg:474.40ms
[train step 864] avg_loss=3.798347 main=3.329530 aux=0.468818 imp_cv2=0.1187 load_cv2=5.3439 usage_frac=0.4286 topk_prob_mean=0.2643 ema_alpha_reverse=nan max_logit=12.7744
step:865/1750 train_time:410348ms step_avg:474.39ms
[train step 865] avg_loss=3.836116 main=3.368267 aux=0.467849 imp_cv2=0.1450 load_cv2=5.3211 usage_frac=0.4196 topk_prob_mean=0.2743 ema_alpha_reverse=nan max_logit=12.7744
step:866/1750 train_time:410822ms step_avg:474.39ms
[train step 866] avg_loss=3.976488 main=3.506455 aux=0.470034 imp_cv2=0.1212 load_cv2=5.3627 usage_frac=0.4286 topk_prob_mean=0.2664 ema_alpha_reverse=nan max_logit=12.7744
step:867/1750 train_time:411285ms step_avg:474.38ms
[train step 867] avg_loss=3.541369 main=3.077936 aux=0.463433 imp_cv2=0.1931 load_cv2=5.2253 usage_frac=0.4241 topk_prob_mean=0.2921 ema_alpha_reverse=nan max_logit=12.7744
step:868/1750 train_time:411766ms step_avg:474.38ms
[train step 868] avg_loss=3.839410 main=3.363236 aux=0.476174 imp_cv2=0.1159 load_cv2=5.4401 usage_frac=0.4196 topk_prob_mean=0.2584 ema_alpha_reverse=nan max_logit=12.7744
step:869/1750 train_time:412238ms step_avg:474.38ms
[train step 869] avg_loss=3.689760 main=3.220399 aux=0.469361 imp_cv2=0.1680 load_cv2=5.3076 usage_frac=0.4241 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=12.7744
step:870/1750 train_time:412709ms step_avg:474.38ms
[train step 870] avg_loss=3.648931 main=3.189898 aux=0.459033 imp_cv2=0.2205 load_cv2=5.1387 usage_frac=0.4241 topk_prob_mean=0.3026 ema_alpha_reverse=nan max_logit=12.7744
step:871/1750 train_time:413183ms step_avg:474.38ms
[train step 871] avg_loss=3.432516 main=2.970423 aux=0.462092 imp_cv2=0.2582 load_cv2=5.1423 usage_frac=0.4241 topk_prob_mean=0.3098 ema_alpha_reverse=nan max_logit=12.7744
step:872/1750 train_time:413668ms step_avg:474.39ms
[train step 872] avg_loss=3.685694 main=3.218071 aux=0.467623 imp_cv2=0.1260 load_cv2=5.3181 usage_frac=0.4286 topk_prob_mean=0.2684 ema_alpha_reverse=nan max_logit=12.7744
step:873/1750 train_time:414130ms step_avg:474.38ms
[train step 873] avg_loss=4.114707 main=3.638088 aux=0.476618 imp_cv2=0.1238 load_cv2=5.4321 usage_frac=0.4152 topk_prob_mean=0.2619 ema_alpha_reverse=nan max_logit=12.7744
step:874/1750 train_time:414600ms step_avg:474.37ms
[train step 874] avg_loss=3.962677 main=3.476461 aux=0.486216 imp_cv2=0.1011 load_cv2=5.5719 usage_frac=0.4152 topk_prob_mean=0.2459 ema_alpha_reverse=nan max_logit=12.7744
step:875/1750 train_time:415053ms step_avg:474.35ms
[train step 875] avg_loss=3.915780 main=3.439175 aux=0.476606 imp_cv2=0.1127 load_cv2=5.4439 usage_frac=0.4241 topk_prob_mean=0.2582 ema_alpha_reverse=nan max_logit=12.7744
step:876/1750 train_time:415514ms step_avg:474.33ms
[train step 876] avg_loss=3.419864 main=2.957817 aux=0.462047 imp_cv2=0.1936 load_cv2=5.2006 usage_frac=0.4196 topk_prob_mean=0.2963 ema_alpha_reverse=nan max_logit=12.7744
step:877/1750 train_time:415980ms step_avg:474.32ms
[train step 877] avg_loss=3.665539 main=3.197623 aux=0.467916 imp_cv2=0.1492 load_cv2=5.3134 usage_frac=0.4196 topk_prob_mean=0.2773 ema_alpha_reverse=nan max_logit=12.7744
step:878/1750 train_time:416445ms step_avg:474.31ms
[train step 878] avg_loss=3.775247 main=3.316832 aux=0.458416 imp_cv2=0.1452 load_cv2=5.1935 usage_frac=0.4241 topk_prob_mean=0.2824 ema_alpha_reverse=nan max_logit=12.7744
step:879/1750 train_time:416920ms step_avg:474.31ms
[train step 879] avg_loss=3.863710 main=3.374033 aux=0.489676 imp_cv2=0.0636 load_cv2=5.6469 usage_frac=0.4196 topk_prob_mean=0.2218 ema_alpha_reverse=nan max_logit=12.7744
step:880/1750 train_time:417385ms step_avg:474.30ms
[train step 880] avg_loss=3.891974 main=3.430470 aux=0.461504 imp_cv2=0.1275 load_cv2=5.2492 usage_frac=0.4196 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=12.7744
step:881/1750 train_time:417854ms step_avg:474.30ms
[train step 881] avg_loss=4.070696 main=3.592330 aux=0.478366 imp_cv2=0.0951 load_cv2=5.4859 usage_frac=0.4152 topk_prob_mean=0.2472 ema_alpha_reverse=nan max_logit=12.7744
step:882/1750 train_time:418335ms step_avg:474.30ms
[train step 882] avg_loss=4.096539 main=3.612649 aux=0.483890 imp_cv2=0.0781 load_cv2=5.5410 usage_frac=0.4286 topk_prob_mean=0.2268 ema_alpha_reverse=nan max_logit=12.2975
step:883/1750 train_time:418796ms step_avg:474.29ms
[train step 883] avg_loss=3.916301 main=3.450522 aux=0.465779 imp_cv2=0.1134 load_cv2=5.3213 usage_frac=0.4196 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=12.7744
step:884/1750 train_time:419262ms step_avg:474.28ms
[train step 884] avg_loss=3.678395 main=3.217703 aux=0.460691 imp_cv2=0.1357 load_cv2=5.2440 usage_frac=0.4196 topk_prob_mean=0.2745 ema_alpha_reverse=nan max_logit=12.7744
step:885/1750 train_time:419727ms step_avg:474.27ms
[train step 885] avg_loss=3.592671 main=3.121892 aux=0.470778 imp_cv2=0.0967 load_cv2=5.3851 usage_frac=0.4241 topk_prob_mean=0.2529 ema_alpha_reverse=nan max_logit=12.7744
step:886/1750 train_time:420201ms step_avg:474.27ms
[train step 886] avg_loss=3.705963 main=3.236559 aux=0.469404 imp_cv2=0.0999 load_cv2=5.3784 usage_frac=0.4196 topk_prob_mean=0.2567 ema_alpha_reverse=nan max_logit=12.7744
step:887/1750 train_time:420667ms step_avg:474.26ms
[train step 887] avg_loss=3.922818 main=3.437009 aux=0.485809 imp_cv2=0.0603 load_cv2=5.5987 usage_frac=0.4241 topk_prob_mean=0.2237 ema_alpha_reverse=nan max_logit=12.7744
step:888/1750 train_time:421144ms step_avg:474.26ms
[train step 888] avg_loss=4.005492 main=3.541617 aux=0.463875 imp_cv2=0.1182 load_cv2=5.2962 usage_frac=0.4196 topk_prob_mean=0.2631 ema_alpha_reverse=nan max_logit=12.7744
step:889/1750 train_time:421619ms step_avg:474.26ms
[train step 889] avg_loss=3.897876 main=3.433916 aux=0.463960 imp_cv2=0.1286 load_cv2=5.2830 usage_frac=0.4107 topk_prob_mean=0.2667 ema_alpha_reverse=nan max_logit=12.7744
step:890/1750 train_time:422093ms step_avg:474.26ms
[train step 890] avg_loss=3.652609 main=3.189433 aux=0.463175 imp_cv2=0.1354 load_cv2=5.2700 usage_frac=0.4196 topk_prob_mean=0.2710 ema_alpha_reverse=nan max_logit=12.7744
step:891/1750 train_time:422553ms step_avg:474.25ms
[train step 891] avg_loss=3.404345 main=2.944828 aux=0.459517 imp_cv2=0.1861 load_cv2=5.1786 usage_frac=0.4241 topk_prob_mean=0.2902 ema_alpha_reverse=nan max_logit=12.7744
step:892/1750 train_time:423028ms step_avg:474.25ms
[train step 892] avg_loss=4.091110 main=3.609154 aux=0.481956 imp_cv2=0.0740 load_cv2=5.5373 usage_frac=0.4152 topk_prob_mean=0.2358 ema_alpha_reverse=nan max_logit=12.7744
step:893/1750 train_time:423503ms step_avg:474.25ms
[train step 893] avg_loss=3.490168 main=3.012934 aux=0.477233 imp_cv2=0.0976 load_cv2=5.4672 usage_frac=0.4196 topk_prob_mean=0.2524 ema_alpha_reverse=nan max_logit=12.7744
step:894/1750 train_time:423966ms step_avg:474.24ms
[train step 894] avg_loss=4.553336 main=4.052766 aux=0.500570 imp_cv2=0.0572 load_cv2=5.7528 usage_frac=0.4241 topk_prob_mean=0.2123 ema_alpha_reverse=nan max_logit=12.7744
step:895/1750 train_time:424419ms step_avg:474.21ms
[train step 895] avg_loss=3.629012 main=3.160273 aux=0.468739 imp_cv2=0.1299 load_cv2=5.3215 usage_frac=0.4152 topk_prob_mean=0.2683 ema_alpha_reverse=nan max_logit=12.7744
step:896/1750 train_time:424872ms step_avg:474.19ms
[train step 896] avg_loss=3.772953 main=3.298969 aux=0.473983 imp_cv2=0.1239 load_cv2=5.4003 usage_frac=0.4152 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=12.7744
step:897/1750 train_time:425334ms step_avg:474.17ms
[train step 897] avg_loss=3.807174 main=3.340936 aux=0.466238 imp_cv2=0.1106 load_cv2=5.3028 usage_frac=0.4196 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=12.7744
step:898/1750 train_time:425809ms step_avg:474.17ms
[train step 898] avg_loss=3.882107 main=3.411311 aux=0.470796 imp_cv2=0.1381 load_cv2=5.3530 usage_frac=0.4196 topk_prob_mean=0.2699 ema_alpha_reverse=nan max_logit=12.7744
step:899/1750 train_time:426262ms step_avg:474.15ms
[train step 899] avg_loss=4.074729 main=3.588592 aux=0.486138 imp_cv2=0.0729 load_cv2=5.5831 usage_frac=0.4196 topk_prob_mean=0.2331 ema_alpha_reverse=nan max_logit=12.7744
step:900/1750 train_time:426723ms step_avg:474.14ms
Running validation...
step:900/1750 val_loss:3.299165 train_time:426735ms step_avg:474.15ms
[train step 900] avg_loss=4.025231 main=3.556138 aux=0.469093 imp_cv2=0.1086 load_cv2=5.3338 usage_frac=0.4241 topk_prob_mean=0.2541 ema_alpha_reverse=nan max_logit=12.7744
step:901/1750 train_time:427193ms step_avg:474.13ms
[train step 901] avg_loss=3.644976 main=3.191227 aux=0.453749 imp_cv2=0.1945 load_cv2=5.0840 usage_frac=0.4241 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=12.7744
step:902/1750 train_time:427678ms step_avg:474.14ms
[train step 902] avg_loss=4.171852 main=3.660671 aux=0.511181 imp_cv2=0.0512 load_cv2=5.9016 usage_frac=0.4196 topk_prob_mean=0.2014 ema_alpha_reverse=nan max_logit=11.8684
step:903/1750 train_time:428152ms step_avg:474.14ms
[train step 903] avg_loss=3.627103 main=3.170435 aux=0.456668 imp_cv2=0.1378 load_cv2=5.1674 usage_frac=0.4152 topk_prob_mean=0.2768 ema_alpha_reverse=nan max_logit=12.7744
step:904/1750 train_time:428620ms step_avg:474.14ms
[train step 904] avg_loss=4.081717 main=3.601558 aux=0.480159 imp_cv2=0.0734 load_cv2=5.5056 usage_frac=0.4107 topk_prob_mean=0.2384 ema_alpha_reverse=nan max_logit=12.7744
step:905/1750 train_time:429077ms step_avg:474.12ms
[train step 905] avg_loss=3.473536 main=3.013599 aux=0.459937 imp_cv2=0.2097 load_cv2=5.1543 usage_frac=0.4196 topk_prob_mean=0.2979 ema_alpha_reverse=nan max_logit=12.7744
step:906/1750 train_time:429546ms step_avg:474.11ms
[train step 906] avg_loss=4.029412 main=3.523401 aux=0.506011 imp_cv2=0.0678 load_cv2=5.8013 usage_frac=0.4107 topk_prob_mean=0.2015 ema_alpha_reverse=nan max_logit=11.7917
step:907/1750 train_time:429997ms step_avg:474.09ms
[train step 907] avg_loss=3.935785 main=3.454392 aux=0.481393 imp_cv2=0.0906 load_cv2=5.4939 usage_frac=0.4152 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=12.7744
step:908/1750 train_time:430456ms step_avg:474.07ms
[train step 908] avg_loss=4.178435 main=3.706897 aux=0.471538 imp_cv2=0.0922 load_cv2=5.3796 usage_frac=0.4152 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=12.7744
step:909/1750 train_time:430925ms step_avg:474.06ms
[train step 909] avg_loss=3.573044 main=3.118008 aux=0.455036 imp_cv2=0.1870 load_cv2=5.1061 usage_frac=0.4152 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=12.7744
step:910/1750 train_time:431395ms step_avg:474.06ms
[train step 910] avg_loss=3.955274 main=3.483303 aux=0.471970 imp_cv2=0.1054 load_cv2=5.3841 usage_frac=0.4107 topk_prob_mean=0.2575 ema_alpha_reverse=nan max_logit=12.7744
step:911/1750 train_time:431866ms step_avg:474.06ms
[train step 911] avg_loss=3.690252 main=3.231743 aux=0.458509 imp_cv2=0.1613 load_cv2=5.1815 usage_frac=0.4107 topk_prob_mean=0.2843 ema_alpha_reverse=nan max_logit=12.7744
step:912/1750 train_time:432329ms step_avg:474.04ms
[train step 912] avg_loss=3.768421 main=3.305248 aux=0.463173 imp_cv2=0.1427 load_cv2=5.2504 usage_frac=0.4196 topk_prob_mean=0.2771 ema_alpha_reverse=nan max_logit=12.7744
step:913/1750 train_time:432796ms step_avg:474.04ms
[train step 913] avg_loss=4.274395 main=3.769976 aux=0.504419 imp_cv2=0.0648 load_cv2=5.7846 usage_frac=0.4062 topk_prob_mean=0.2065 ema_alpha_reverse=nan max_logit=12.0285
step:914/1750 train_time:433271ms step_avg:474.04ms
[train step 914] avg_loss=4.021024 main=3.532067 aux=0.488957 imp_cv2=0.0641 load_cv2=5.6182 usage_frac=0.4241 topk_prob_mean=0.2221 ema_alpha_reverse=nan max_logit=12.7744
step:915/1750 train_time:433736ms step_avg:474.03ms
[train step 915] avg_loss=3.632421 main=3.171738 aux=0.460684 imp_cv2=0.1365 load_cv2=5.2319 usage_frac=0.4196 topk_prob_mean=0.2733 ema_alpha_reverse=nan max_logit=12.7744
step:916/1750 train_time:434195ms step_avg:474.01ms
[train step 916] avg_loss=4.183263 main=3.710821 aux=0.472442 imp_cv2=0.0771 load_cv2=5.4082 usage_frac=0.4196 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=12.7744
step:917/1750 train_time:434657ms step_avg:474.00ms
[train step 917] avg_loss=3.355860 main=2.899397 aux=0.456464 imp_cv2=0.1798 load_cv2=5.1446 usage_frac=0.4152 topk_prob_mean=0.2906 ema_alpha_reverse=nan max_logit=12.7744
step:918/1750 train_time:435121ms step_avg:473.99ms
[train step 918] avg_loss=3.521909 main=3.062971 aux=0.458939 imp_cv2=0.1377 load_cv2=5.2085 usage_frac=0.4196 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=12.7744
step:919/1750 train_time:435598ms step_avg:473.99ms
[train step 919] avg_loss=3.499069 main=3.041965 aux=0.457103 imp_cv2=0.2248 load_cv2=5.1182 usage_frac=0.4241 topk_prob_mean=0.3031 ema_alpha_reverse=nan max_logit=12.7744
step:920/1750 train_time:436076ms step_avg:474.00ms
[train step 920] avg_loss=3.935656 main=3.453912 aux=0.481744 imp_cv2=0.0673 load_cv2=5.5415 usage_frac=0.4152 topk_prob_mean=0.2346 ema_alpha_reverse=nan max_logit=12.7744
step:921/1750 train_time:436538ms step_avg:473.98ms
[train step 921] avg_loss=3.718261 main=3.247319 aux=0.470942 imp_cv2=0.0976 load_cv2=5.3941 usage_frac=0.4152 topk_prob_mean=0.2539 ema_alpha_reverse=nan max_logit=12.7744
step:922/1750 train_time:437001ms step_avg:473.97ms
[train step 922] avg_loss=3.888801 main=3.408543 aux=0.480258 imp_cv2=0.0806 load_cv2=5.5108 usage_frac=0.4196 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=12.7744
step:923/1750 train_time:437472ms step_avg:473.97ms
[train step 923] avg_loss=4.079738 main=3.611653 aux=0.468085 imp_cv2=0.1324 load_cv2=5.3197 usage_frac=0.4152 topk_prob_mean=0.2703 ema_alpha_reverse=nan max_logit=12.7744
step:924/1750 train_time:437926ms step_avg:473.95ms
[train step 924] avg_loss=4.288831 main=3.776982 aux=0.511849 imp_cv2=0.0574 load_cv2=5.8917 usage_frac=0.4152 topk_prob_mean=0.1977 ema_alpha_reverse=nan max_logit=12.7744
step:925/1750 train_time:438381ms step_avg:473.93ms
[train step 925] avg_loss=3.430324 main=2.966263 aux=0.464061 imp_cv2=0.2133 load_cv2=5.1994 usage_frac=0.4152 topk_prob_mean=0.2973 ema_alpha_reverse=nan max_logit=12.7744
step:926/1750 train_time:438844ms step_avg:473.91ms
[train step 926] avg_loss=3.471590 main=2.998865 aux=0.472724 imp_cv2=0.1656 load_cv2=5.3485 usage_frac=0.4196 topk_prob_mean=0.2785 ema_alpha_reverse=nan max_logit=12.7744
step:927/1750 train_time:439297ms step_avg:473.89ms
[train step 927] avg_loss=3.655814 main=3.175836 aux=0.479978 imp_cv2=0.1034 load_cv2=5.4863 usage_frac=0.4152 topk_prob_mean=0.2524 ema_alpha_reverse=nan max_logit=12.7744
step:928/1750 train_time:439787ms step_avg:473.91ms
[train step 928] avg_loss=4.141428 main=3.651445 aux=0.489982 imp_cv2=0.0830 load_cv2=5.6190 usage_frac=0.4241 topk_prob_mean=0.2376 ema_alpha_reverse=nan max_logit=12.7744
step:929/1750 train_time:440245ms step_avg:473.89ms
[train step 929] avg_loss=3.220168 main=2.758525 aux=0.461643 imp_cv2=0.2706 load_cv2=5.1201 usage_frac=0.4107 topk_prob_mean=0.3147 ema_alpha_reverse=nan max_logit=12.7744
step:930/1750 train_time:440718ms step_avg:473.89ms
[train step 930] avg_loss=3.712620 main=3.250989 aux=0.461631 imp_cv2=0.2024 load_cv2=5.1818 usage_frac=0.4286 topk_prob_mean=0.2965 ema_alpha_reverse=nan max_logit=12.7744
step:931/1750 train_time:441191ms step_avg:473.89ms
[train step 931] avg_loss=3.741786 main=3.239607 aux=0.502179 imp_cv2=0.0590 load_cv2=5.7765 usage_frac=0.4196 topk_prob_mean=0.2143 ema_alpha_reverse=nan max_logit=12.7744
step:932/1750 train_time:441660ms step_avg:473.88ms
[train step 932] avg_loss=3.497213 main=3.038942 aux=0.458271 imp_cv2=0.1584 load_cv2=5.1818 usage_frac=0.4196 topk_prob_mean=0.2845 ema_alpha_reverse=nan max_logit=12.7744
step:933/1750 train_time:442137ms step_avg:473.89ms
[train step 933] avg_loss=3.909032 main=3.430597 aux=0.478435 imp_cv2=0.0986 load_cv2=5.4833 usage_frac=0.4196 topk_prob_mean=0.2508 ema_alpha_reverse=nan max_logit=12.7744
step:934/1750 train_time:442610ms step_avg:473.89ms
[train step 934] avg_loss=4.013402 main=3.530978 aux=0.482423 imp_cv2=0.0782 load_cv2=5.5438 usage_frac=0.4241 topk_prob_mean=0.2380 ema_alpha_reverse=nan max_logit=12.7744
step:935/1750 train_time:443074ms step_avg:473.88ms
[train step 935] avg_loss=3.611417 main=3.141899 aux=0.469517 imp_cv2=0.1047 load_cv2=5.3539 usage_frac=0.4152 topk_prob_mean=0.2583 ema_alpha_reverse=nan max_logit=12.7744
step:936/1750 train_time:443535ms step_avg:473.86ms
[train step 936] avg_loss=3.699006 main=3.229582 aux=0.469424 imp_cv2=0.1256 load_cv2=5.3392 usage_frac=0.4196 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=12.7744
step:937/1750 train_time:443998ms step_avg:473.85ms
[train step 937] avg_loss=4.388805 main=3.881525 aux=0.507280 imp_cv2=0.0676 load_cv2=5.8070 usage_frac=0.4152 topk_prob_mean=0.1989 ema_alpha_reverse=nan max_logit=12.7744
step:938/1750 train_time:444466ms step_avg:473.84ms
[train step 938] avg_loss=3.956702 main=3.482348 aux=0.474354 imp_cv2=0.1123 load_cv2=5.4091 usage_frac=0.4152 topk_prob_mean=0.2605 ema_alpha_reverse=nan max_logit=12.7744
step:939/1750 train_time:444933ms step_avg:473.84ms
[train step 939] avg_loss=3.372361 main=2.902769 aux=0.469592 imp_cv2=0.1559 load_cv2=5.3127 usage_frac=0.4241 topk_prob_mean=0.2804 ema_alpha_reverse=nan max_logit=12.7744
step:940/1750 train_time:445399ms step_avg:473.83ms
[train step 940] avg_loss=3.449581 main=2.987305 aux=0.462276 imp_cv2=0.1987 load_cv2=5.1872 usage_frac=0.4241 topk_prob_mean=0.2948 ema_alpha_reverse=nan max_logit=12.7744
step:941/1750 train_time:445870ms step_avg:473.83ms
[train step 941] avg_loss=3.405371 main=2.933892 aux=0.471480 imp_cv2=0.1703 load_cv2=5.3285 usage_frac=0.4286 topk_prob_mean=0.2835 ema_alpha_reverse=nan max_logit=13.6635
step:942/1750 train_time:446337ms step_avg:473.82ms
[train step 942] avg_loss=4.099879 main=3.608147 aux=0.491731 imp_cv2=0.0747 load_cv2=5.6526 usage_frac=0.4107 topk_prob_mean=0.2320 ema_alpha_reverse=nan max_logit=12.7744
step:943/1750 train_time:446799ms step_avg:473.81ms
[train step 943] avg_loss=3.996785 main=3.516885 aux=0.479900 imp_cv2=0.1115 load_cv2=5.4780 usage_frac=0.4196 topk_prob_mean=0.2555 ema_alpha_reverse=nan max_logit=12.7744
step:944/1750 train_time:447256ms step_avg:473.79ms
[train step 944] avg_loss=3.678856 main=3.204274 aux=0.474582 imp_cv2=0.1427 load_cv2=5.3766 usage_frac=0.4196 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=12.7744
step:945/1750 train_time:447714ms step_avg:473.77ms
[train step 945] avg_loss=3.977188 main=3.483049 aux=0.494138 imp_cv2=0.0697 load_cv2=5.6789 usage_frac=0.4286 topk_prob_mean=0.2265 ema_alpha_reverse=nan max_logit=13.7570
step:946/1750 train_time:448161ms step_avg:473.74ms
[train step 946] avg_loss=3.382966 main=2.920417 aux=0.462550 imp_cv2=0.2129 load_cv2=5.1826 usage_frac=0.4241 topk_prob_mean=0.2982 ema_alpha_reverse=nan max_logit=12.7744
step:947/1750 train_time:448638ms step_avg:473.75ms
[train step 947] avg_loss=3.971077 main=3.491233 aux=0.479844 imp_cv2=0.0886 load_cv2=5.4972 usage_frac=0.4196 topk_prob_mean=0.2440 ema_alpha_reverse=nan max_logit=12.8063
step:948/1750 train_time:449296ms step_avg:473.94ms
[train step 948] avg_loss=3.819076 main=3.347319 aux=0.471758 imp_cv2=0.1337 load_cv2=5.3653 usage_frac=0.4241 topk_prob_mean=0.2681 ema_alpha_reverse=nan max_logit=12.7744
step:949/1750 train_time:449763ms step_avg:473.93ms
[train step 949] avg_loss=3.886582 main=3.411043 aux=0.475539 imp_cv2=0.1218 load_cv2=5.4200 usage_frac=0.4286 topk_prob_mean=0.2570 ema_alpha_reverse=nan max_logit=13.7570
step:950/1750 train_time:450229ms step_avg:473.93ms
Running validation...
step:950/1750 val_loss:3.251149 train_time:450241ms step_avg:473.94ms
[train step 950] avg_loss=3.838190 main=3.339454 aux=0.498736 imp_cv2=0.0540 load_cv2=5.7452 usage_frac=0.4152 topk_prob_mean=0.2116 ema_alpha_reverse=nan max_logit=12.7744
step:951/1750 train_time:450698ms step_avg:473.92ms
[train step 951] avg_loss=3.571392 main=3.107354 aux=0.464039 imp_cv2=0.1726 load_cv2=5.2455 usage_frac=0.4196 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=12.7744
step:952/1750 train_time:451166ms step_avg:473.91ms
[train step 952] avg_loss=3.683701 main=3.215904 aux=0.467797 imp_cv2=0.1443 load_cv2=5.3053 usage_frac=0.4152 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=12.7744
step:953/1750 train_time:451624ms step_avg:473.90ms
[train step 953] avg_loss=3.723974 main=3.254377 aux=0.469597 imp_cv2=0.1308 load_cv2=5.3337 usage_frac=0.4196 topk_prob_mean=0.2672 ema_alpha_reverse=nan max_logit=12.7744
step:954/1750 train_time:452092ms step_avg:473.89ms
[train step 954] avg_loss=4.431534 main=3.924120 aux=0.507414 imp_cv2=0.0634 load_cv2=5.8487 usage_frac=0.4196 topk_prob_mean=0.2085 ema_alpha_reverse=nan max_logit=12.7744
step:955/1750 train_time:452547ms step_avg:473.87ms
[train step 955] avg_loss=3.494078 main=3.025097 aux=0.468981 imp_cv2=0.1307 load_cv2=5.3281 usage_frac=0.4196 topk_prob_mean=0.2709 ema_alpha_reverse=nan max_logit=12.7744
step:956/1750 train_time:453209ms step_avg:474.07ms
[train step 956] avg_loss=3.878107 main=3.404675 aux=0.473432 imp_cv2=0.1203 load_cv2=5.3862 usage_frac=0.4286 topk_prob_mean=0.2661 ema_alpha_reverse=nan max_logit=12.7744
step:957/1750 train_time:453677ms step_avg:474.06ms
[train step 957] avg_loss=3.626712 main=3.158003 aux=0.468709 imp_cv2=0.1519 load_cv2=5.3076 usage_frac=0.4241 topk_prob_mean=0.2794 ema_alpha_reverse=nan max_logit=12.7744
step:958/1750 train_time:454141ms step_avg:474.05ms
[train step 958] avg_loss=3.757390 main=3.281500 aux=0.475891 imp_cv2=0.1096 load_cv2=5.4253 usage_frac=0.4241 topk_prob_mean=0.2596 ema_alpha_reverse=nan max_logit=13.7570
step:959/1750 train_time:454790ms step_avg:474.23ms
[train step 959] avg_loss=3.412976 main=2.946496 aux=0.466480 imp_cv2=0.1717 load_cv2=5.2581 usage_frac=0.4286 topk_prob_mean=0.2883 ema_alpha_reverse=nan max_logit=13.7570
step:960/1750 train_time:455269ms step_avg:474.24ms
[train step 960] avg_loss=3.336268 main=2.867939 aux=0.468329 imp_cv2=0.1598 load_cv2=5.2896 usage_frac=0.4241 topk_prob_mean=0.2843 ema_alpha_reverse=nan max_logit=12.7744
step:961/1750 train_time:455733ms step_avg:474.23ms
[train step 961] avg_loss=3.672295 main=3.196721 aux=0.475573 imp_cv2=0.1114 load_cv2=5.4244 usage_frac=0.4286 topk_prob_mean=0.2617 ema_alpha_reverse=nan max_logit=12.7744
step:962/1750 train_time:456192ms step_avg:474.21ms
[train step 962] avg_loss=3.507177 main=3.032537 aux=0.474639 imp_cv2=0.1465 load_cv2=5.3833 usage_frac=0.4241 topk_prob_mean=0.2752 ema_alpha_reverse=nan max_logit=12.7744
step:963/1750 train_time:456660ms step_avg:474.21ms
[train step 963] avg_loss=3.406679 main=2.939045 aux=0.467634 imp_cv2=0.1668 load_cv2=5.2724 usage_frac=0.4330 topk_prob_mean=0.2877 ema_alpha_reverse=nan max_logit=12.7744
step:964/1750 train_time:457111ms step_avg:474.18ms
[train step 964] avg_loss=4.010812 main=3.535994 aux=0.474818 imp_cv2=0.1056 load_cv2=5.4049 usage_frac=0.4286 topk_prob_mean=0.2584 ema_alpha_reverse=nan max_logit=12.7744
step:965/1750 train_time:457571ms step_avg:474.17ms
[train step 965] avg_loss=4.232688 main=3.734575 aux=0.498113 imp_cv2=0.0805 load_cv2=5.7329 usage_frac=0.4286 topk_prob_mean=0.2345 ema_alpha_reverse=nan max_logit=12.7744
step:966/1750 train_time:458038ms step_avg:474.16ms
[train step 966] avg_loss=3.886616 main=3.404250 aux=0.482366 imp_cv2=0.1013 load_cv2=5.5093 usage_frac=0.4241 topk_prob_mean=0.2531 ema_alpha_reverse=nan max_logit=12.7744
step:967/1750 train_time:458495ms step_avg:474.14ms
[train step 967] avg_loss=3.598223 main=3.125676 aux=0.472547 imp_cv2=0.1503 load_cv2=5.3463 usage_frac=0.4241 topk_prob_mean=0.2782 ema_alpha_reverse=nan max_logit=12.7744
step:968/1750 train_time:458959ms step_avg:474.13ms
[train step 968] avg_loss=3.520848 main=3.046606 aux=0.474242 imp_cv2=0.1523 load_cv2=5.3767 usage_frac=0.4241 topk_prob_mean=0.2754 ema_alpha_reverse=nan max_logit=12.7744
step:969/1750 train_time:459429ms step_avg:474.13ms
[train step 969] avg_loss=4.511856 main=4.025194 aux=0.486662 imp_cv2=0.1039 load_cv2=5.5612 usage_frac=0.4196 topk_prob_mean=0.2468 ema_alpha_reverse=nan max_logit=12.7744
step:970/1750 train_time:459890ms step_avg:474.11ms
[train step 970] avg_loss=4.332223 main=3.850927 aux=0.481296 imp_cv2=0.0870 load_cv2=5.5074 usage_frac=0.4241 topk_prob_mean=0.2429 ema_alpha_reverse=nan max_logit=12.7744
step:971/1750 train_time:460351ms step_avg:474.10ms
[train step 971] avg_loss=3.949720 main=3.463058 aux=0.486662 imp_cv2=0.0691 load_cv2=5.5981 usage_frac=0.4196 topk_prob_mean=0.2315 ema_alpha_reverse=nan max_logit=12.7744
step:972/1750 train_time:460807ms step_avg:474.08ms
[train step 972] avg_loss=3.482526 main=3.021175 aux=0.461351 imp_cv2=0.1380 load_cv2=5.2301 usage_frac=0.4241 topk_prob_mean=0.2788 ema_alpha_reverse=nan max_logit=12.7744
step:973/1750 train_time:461280ms step_avg:474.08ms
[train step 973] avg_loss=3.166860 main=2.706021 aux=0.460839 imp_cv2=0.1946 load_cv2=5.1836 usage_frac=0.4241 topk_prob_mean=0.2935 ema_alpha_reverse=nan max_logit=12.7744
step:974/1750 train_time:461742ms step_avg:474.07ms
[train step 974] avg_loss=3.606304 main=3.136874 aux=0.469430 imp_cv2=0.1312 load_cv2=5.3498 usage_frac=0.4286 topk_prob_mean=0.2672 ema_alpha_reverse=nan max_logit=12.7744
step:975/1750 train_time:462204ms step_avg:474.06ms
[train step 975] avg_loss=4.005246 main=3.484969 aux=0.520277 imp_cv2=0.0507 load_cv2=6.0277 usage_frac=0.4196 topk_prob_mean=0.1959 ema_alpha_reverse=nan max_logit=12.7744
step:976/1750 train_time:462677ms step_avg:474.05ms
[train step 976] avg_loss=3.589303 main=3.128358 aux=0.460945 imp_cv2=0.1349 load_cv2=5.2316 usage_frac=0.4241 topk_prob_mean=0.2755 ema_alpha_reverse=nan max_logit=12.7744
step:977/1750 train_time:463151ms step_avg:474.05ms
[train step 977] avg_loss=4.497553 main=3.976735 aux=0.520818 imp_cv2=0.0560 load_cv2=6.0056 usage_frac=0.4196 topk_prob_mean=0.1950 ema_alpha_reverse=nan max_logit=12.7744
step:978/1750 train_time:463622ms step_avg:474.05ms
[train step 978] avg_loss=3.468561 main=3.003341 aux=0.465220 imp_cv2=0.1378 load_cv2=5.2926 usage_frac=0.4196 topk_prob_mean=0.2715 ema_alpha_reverse=nan max_logit=12.7744
step:979/1750 train_time:464075ms step_avg:474.03ms
[train step 979] avg_loss=3.962197 main=3.491221 aux=0.470975 imp_cv2=0.0862 load_cv2=5.3943 usage_frac=0.4241 topk_prob_mean=0.2482 ema_alpha_reverse=nan max_logit=12.7744
step:980/1750 train_time:464534ms step_avg:474.01ms
[train step 980] avg_loss=3.678618 main=3.204885 aux=0.473733 imp_cv2=0.0911 load_cv2=5.4283 usage_frac=0.4286 topk_prob_mean=0.2500 ema_alpha_reverse=nan max_logit=12.7744
step:981/1750 train_time:464988ms step_avg:473.99ms
[train step 981] avg_loss=3.321682 main=2.844081 aux=0.477601 imp_cv2=0.0837 load_cv2=5.4738 usage_frac=0.4241 topk_prob_mean=0.2450 ema_alpha_reverse=nan max_logit=12.7744
step:982/1750 train_time:465454ms step_avg:473.99ms
[train step 982] avg_loss=3.773842 main=3.298917 aux=0.474925 imp_cv2=0.0779 load_cv2=5.4472 usage_frac=0.4330 topk_prob_mean=0.2443 ema_alpha_reverse=nan max_logit=12.7744
step:983/1750 train_time:466101ms step_avg:474.16ms
[train step 983] avg_loss=3.662697 main=3.186826 aux=0.475871 imp_cv2=0.0824 load_cv2=5.4613 usage_frac=0.4330 topk_prob_mean=0.2452 ema_alpha_reverse=nan max_logit=12.7744
step:984/1750 train_time:466559ms step_avg:474.15ms
[train step 984] avg_loss=3.252550 main=2.800110 aux=0.452440 imp_cv2=0.2988 load_cv2=4.9880 usage_frac=0.4330 topk_prob_mean=0.3245 ema_alpha_reverse=nan max_logit=12.7744
step:985/1750 train_time:467037ms step_avg:474.15ms
[train step 985] avg_loss=3.977332 main=3.499956 aux=0.477375 imp_cv2=0.0690 load_cv2=5.4849 usage_frac=0.4330 topk_prob_mean=0.2345 ema_alpha_reverse=nan max_logit=12.7744
step:986/1750 train_time:467509ms step_avg:474.15ms
[train step 986] avg_loss=3.683173 main=3.220487 aux=0.462686 imp_cv2=0.1002 load_cv2=5.2915 usage_frac=0.4330 topk_prob_mean=0.2581 ema_alpha_reverse=nan max_logit=12.7744
step:987/1750 train_time:467976ms step_avg:474.14ms
[train step 987] avg_loss=3.430786 main=2.974830 aux=0.455956 imp_cv2=0.1710 load_cv2=5.1497 usage_frac=0.4330 topk_prob_mean=0.2863 ema_alpha_reverse=nan max_logit=12.7744
step:988/1750 train_time:468445ms step_avg:474.13ms
[train step 988] avg_loss=3.574212 main=3.119223 aux=0.454989 imp_cv2=0.1512 load_cv2=5.1553 usage_frac=0.4286 topk_prob_mean=0.2788 ema_alpha_reverse=nan max_logit=12.7744
step:989/1750 train_time:468926ms step_avg:474.14ms
[train step 989] avg_loss=3.451672 main=3.003196 aux=0.448476 imp_cv2=0.1749 load_cv2=5.0596 usage_frac=0.4286 topk_prob_mean=0.2895 ema_alpha_reverse=nan max_logit=12.7744
step:990/1750 train_time:469392ms step_avg:474.13ms
[train step 990] avg_loss=3.610130 main=3.154631 aux=0.455499 imp_cv2=0.1182 load_cv2=5.1888 usage_frac=0.4375 topk_prob_mean=0.2652 ema_alpha_reverse=nan max_logit=12.7744
step:991/1750 train_time:470060ms step_avg:474.33ms
[train step 991] avg_loss=3.429494 main=2.982037 aux=0.447458 imp_cv2=0.2008 load_cv2=5.0311 usage_frac=0.4286 topk_prob_mean=0.2995 ema_alpha_reverse=nan max_logit=12.7744
step:992/1750 train_time:470540ms step_avg:474.33ms
[train step 992] avg_loss=4.012419 main=3.551751 aux=0.460667 imp_cv2=0.1041 load_cv2=5.2645 usage_frac=0.4375 topk_prob_mean=0.2541 ema_alpha_reverse=nan max_logit=12.7744
step:993/1750 train_time:471015ms step_avg:474.34ms
[train step 993] avg_loss=4.190875 main=3.684895 aux=0.505980 imp_cv2=0.0868 load_cv2=5.7753 usage_frac=0.4241 topk_prob_mean=0.1998 ema_alpha_reverse=nan max_logit=12.7744
step:994/1750 train_time:471491ms step_avg:474.34ms
[train step 994] avg_loss=3.851815 main=3.391604 aux=0.460210 imp_cv2=0.0963 load_cv2=5.2709 usage_frac=0.4286 topk_prob_mean=0.2550 ema_alpha_reverse=nan max_logit=12.7744
step:995/1750 train_time:471960ms step_avg:474.33ms
[train step 995] avg_loss=3.208037 main=2.770479 aux=0.437558 imp_cv2=0.2372 load_cv2=4.8778 usage_frac=0.4286 topk_prob_mean=0.3140 ema_alpha_reverse=nan max_logit=12.7744
step:996/1750 train_time:472438ms step_avg:474.33ms
[train step 996] avg_loss=3.430423 main=2.982642 aux=0.447780 imp_cv2=0.1487 load_cv2=5.0831 usage_frac=0.4330 topk_prob_mean=0.2802 ema_alpha_reverse=nan max_logit=12.7744
step:997/1750 train_time:473054ms step_avg:474.48ms
[train step 997] avg_loss=3.658593 main=3.211442 aux=0.447151 imp_cv2=0.1363 load_cv2=5.0850 usage_frac=0.4286 topk_prob_mean=0.2789 ema_alpha_reverse=nan max_logit=12.7744
step:998/1750 train_time:473526ms step_avg:474.48ms
[train step 998] avg_loss=3.306233 main=2.871098 aux=0.435135 imp_cv2=0.2287 load_cv2=4.8650 usage_frac=0.4375 topk_prob_mean=0.3125 ema_alpha_reverse=nan max_logit=12.7744
step:999/1750 train_time:474004ms step_avg:474.48ms
[train step 999] avg_loss=3.743685 main=3.295085 aux=0.448601 imp_cv2=0.1346 load_cv2=5.1105 usage_frac=0.4330 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=12.7744
step:1000/1750 train_time:474475ms step_avg:474.47ms
Running validation...
step:1000/1750 val_loss:3.239673 train_time:474487ms step_avg:474.49ms
[train step 1000] avg_loss=3.780320 main=3.318004 aux=0.462317 imp_cv2=0.0882 load_cv2=5.3056 usage_frac=0.4330 topk_prob_mean=0.2485 ema_alpha_reverse=nan max_logit=12.7744
step:1001/1750 train_time:474951ms step_avg:474.48ms
[train step 1001] avg_loss=3.357544 main=2.906932 aux=0.450612 imp_cv2=0.1400 load_cv2=5.1282 usage_frac=0.4286 topk_prob_mean=0.2773 ema_alpha_reverse=nan max_logit=12.7744
step:1002/1750 train_time:475419ms step_avg:474.47ms
[train step 1002] avg_loss=3.543937 main=3.077955 aux=0.465981 imp_cv2=0.0931 load_cv2=5.3488 usage_frac=0.4286 topk_prob_mean=0.2510 ema_alpha_reverse=nan max_logit=12.7744
step:1003/1750 train_time:475876ms step_avg:474.45ms
[train step 1003] avg_loss=3.549366 main=3.094867 aux=0.454499 imp_cv2=0.1237 load_cv2=5.1852 usage_frac=0.4330 topk_prob_mean=0.2683 ema_alpha_reverse=nan max_logit=12.7744
step:1004/1750 train_time:476350ms step_avg:474.45ms
[train step 1004] avg_loss=3.733535 main=3.273048 aux=0.460487 imp_cv2=0.1093 load_cv2=5.2620 usage_frac=0.4330 topk_prob_mean=0.2599 ema_alpha_reverse=nan max_logit=12.7744
step:1005/1750 train_time:476815ms step_avg:474.44ms
[train step 1005] avg_loss=3.311305 main=2.861775 aux=0.449529 imp_cv2=0.2030 load_cv2=5.0561 usage_frac=0.4330 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=12.7744
step:1006/1750 train_time:477297ms step_avg:474.45ms
[train step 1006] avg_loss=3.738790 main=3.283103 aux=0.455687 imp_cv2=0.1452 load_cv2=5.1778 usage_frac=0.4286 topk_prob_mean=0.2755 ema_alpha_reverse=nan max_logit=12.7744
step:1007/1750 train_time:477779ms step_avg:474.46ms
[train step 1007] avg_loss=4.014157 main=3.468534 aux=0.545623 imp_cv2=0.0516 load_cv2=6.3370 usage_frac=0.3795 topk_prob_mean=0.1709 ema_alpha_reverse=nan max_logit=11.7917
step:1008/1750 train_time:478256ms step_avg:474.46ms
[train step 1008] avg_loss=3.564285 main=3.109792 aux=0.454493 imp_cv2=0.1335 load_cv2=5.1695 usage_frac=0.4241 topk_prob_mean=0.2723 ema_alpha_reverse=nan max_logit=12.7744
step:1009/1750 train_time:478744ms step_avg:474.47ms
[train step 1009] avg_loss=3.904497 main=3.449371 aux=0.455126 imp_cv2=0.1362 load_cv2=5.1784 usage_frac=0.4420 topk_prob_mean=0.2716 ema_alpha_reverse=nan max_logit=12.7744
step:1010/1750 train_time:479224ms step_avg:474.48ms
[train step 1010] avg_loss=4.013064 main=3.535978 aux=0.477086 imp_cv2=0.0843 load_cv2=5.4831 usage_frac=0.4375 topk_prob_mean=0.2407 ema_alpha_reverse=nan max_logit=12.7744
step:1011/1750 train_time:479916ms step_avg:474.69ms
[train step 1011] avg_loss=3.335655 main=2.887261 aux=0.448393 imp_cv2=0.2357 load_cv2=5.0097 usage_frac=0.4286 topk_prob_mean=0.3074 ema_alpha_reverse=nan max_logit=12.7744
step:1012/1750 train_time:480403ms step_avg:474.71ms
[train step 1012] avg_loss=3.887638 main=3.415792 aux=0.471847 imp_cv2=0.0949 load_cv2=5.4015 usage_frac=0.4375 topk_prob_mean=0.2400 ema_alpha_reverse=nan max_logit=12.7744
step:1013/1750 train_time:480873ms step_avg:474.70ms
[train step 1013] avg_loss=3.681518 main=3.228896 aux=0.452622 imp_cv2=0.1692 load_cv2=5.1252 usage_frac=0.4375 topk_prob_mean=0.2844 ema_alpha_reverse=nan max_logit=12.7744
step:1014/1750 train_time:481346ms step_avg:474.70ms
[train step 1014] avg_loss=3.984211 main=3.536386 aux=0.447825 imp_cv2=0.1419 load_cv2=5.0661 usage_frac=0.4420 topk_prob_mean=0.2787 ema_alpha_reverse=nan max_logit=12.7744
step:1015/1750 train_time:481826ms step_avg:474.71ms
[train step 1015] avg_loss=3.621824 main=3.113710 aux=0.508115 imp_cv2=0.0472 load_cv2=5.8784 usage_frac=0.4286 topk_prob_mean=0.1976 ema_alpha_reverse=nan max_logit=12.7744
step:1016/1750 train_time:482302ms step_avg:474.71ms
[train step 1016] avg_loss=3.873249 main=3.381113 aux=0.492136 imp_cv2=0.0673 load_cv2=5.6737 usage_frac=0.4375 topk_prob_mean=0.2188 ema_alpha_reverse=nan max_logit=12.7744
step:1017/1750 train_time:482769ms step_avg:474.70ms
[train step 1017] avg_loss=3.558148 main=3.100374 aux=0.457774 imp_cv2=0.1263 load_cv2=5.2158 usage_frac=0.4420 topk_prob_mean=0.2663 ema_alpha_reverse=nan max_logit=12.7744
step:1018/1750 train_time:483287ms step_avg:474.74ms
[train step 1018] avg_loss=3.276185 main=2.829414 aux=0.446770 imp_cv2=0.1997 load_cv2=5.0267 usage_frac=0.4420 topk_prob_mean=0.2990 ema_alpha_reverse=nan max_logit=12.7744
step:1019/1750 train_time:483778ms step_avg:474.76ms
[train step 1019] avg_loss=3.521731 main=3.071383 aux=0.450348 imp_cv2=0.1641 load_cv2=5.0955 usage_frac=0.4330 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=12.7744
step:1020/1750 train_time:484257ms step_avg:474.76ms
[train step 1020] avg_loss=3.566187 main=3.103196 aux=0.462991 imp_cv2=0.1183 load_cv2=5.2895 usage_frac=0.4330 topk_prob_mean=0.2617 ema_alpha_reverse=nan max_logit=12.7744
step:1021/1750 train_time:484726ms step_avg:474.76ms
[train step 1021] avg_loss=3.401420 main=2.931297 aux=0.470124 imp_cv2=0.1020 load_cv2=5.3840 usage_frac=0.4330 topk_prob_mean=0.2515 ema_alpha_reverse=nan max_logit=12.7744
step:1022/1750 train_time:485179ms step_avg:474.74ms
[train step 1022] avg_loss=4.078858 main=3.566865 aux=0.511993 imp_cv2=0.0645 load_cv2=5.8826 usage_frac=0.4375 topk_prob_mean=0.1960 ema_alpha_reverse=nan max_logit=12.7744
step:1023/1750 train_time:485635ms step_avg:474.72ms
[train step 1023] avg_loss=4.198400 main=3.701459 aux=0.496942 imp_cv2=0.0642 load_cv2=5.7568 usage_frac=0.4420 topk_prob_mean=0.2189 ema_alpha_reverse=nan max_logit=12.7744
step:1024/1750 train_time:486098ms step_avg:474.70ms
[train step 1024] avg_loss=3.465784 main=3.009784 aux=0.456000 imp_cv2=0.1866 load_cv2=5.1385 usage_frac=0.4375 topk_prob_mean=0.2904 ema_alpha_reverse=nan max_logit=12.7744
step:1025/1750 train_time:486581ms step_avg:474.71ms
[train step 1025] avg_loss=3.506401 main=3.046036 aux=0.460366 imp_cv2=0.1424 load_cv2=5.2268 usage_frac=0.4420 topk_prob_mean=0.2738 ema_alpha_reverse=nan max_logit=12.7744
step:1026/1750 train_time:487053ms step_avg:474.71ms
[train step 1026] avg_loss=3.501284 main=3.049737 aux=0.451547 imp_cv2=0.1701 load_cv2=5.1018 usage_frac=0.4375 topk_prob_mean=0.2859 ema_alpha_reverse=nan max_logit=12.7744
step:1027/1750 train_time:487529ms step_avg:474.71ms
[train step 1027] avg_loss=3.701280 main=3.235638 aux=0.465642 imp_cv2=0.1124 load_cv2=5.3255 usage_frac=0.4375 topk_prob_mean=0.2573 ema_alpha_reverse=nan max_logit=12.7744
step:1028/1750 train_time:488010ms step_avg:474.72ms
[train step 1028] avg_loss=3.509513 main=3.060139 aux=0.449374 imp_cv2=0.2073 load_cv2=5.0476 usage_frac=0.4420 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=12.7744
step:1029/1750 train_time:488481ms step_avg:474.71ms
[train step 1029] avg_loss=4.249679 main=3.706374 aux=0.543305 imp_cv2=0.0495 load_cv2=6.2940 usage_frac=0.3705 topk_prob_mean=0.1700 ema_alpha_reverse=nan max_logit=10.8091
step:1030/1750 train_time:488944ms step_avg:474.70ms
[train step 1030] avg_loss=3.815187 main=3.353157 aux=0.462030 imp_cv2=0.1213 load_cv2=5.2692 usage_frac=0.4375 topk_prob_mean=0.2648 ema_alpha_reverse=nan max_logit=12.7744
step:1031/1750 train_time:489426ms step_avg:474.71ms
[train step 1031] avg_loss=3.507314 main=3.054434 aux=0.452880 imp_cv2=0.1345 load_cv2=5.1518 usage_frac=0.4464 topk_prob_mean=0.2738 ema_alpha_reverse=nan max_logit=12.7744
step:1032/1750 train_time:489905ms step_avg:474.71ms
[train step 1032] avg_loss=3.296859 main=2.850074 aux=0.446785 imp_cv2=0.1687 load_cv2=5.0429 usage_frac=0.4420 topk_prob_mean=0.2901 ema_alpha_reverse=nan max_logit=12.7744
step:1033/1750 train_time:490381ms step_avg:474.72ms
[train step 1033] avg_loss=3.609454 main=3.149714 aux=0.459740 imp_cv2=0.1123 load_cv2=5.2531 usage_frac=0.4420 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=12.7744
step:1034/1750 train_time:490860ms step_avg:474.72ms
[train step 1034] avg_loss=3.587739 main=3.134059 aux=0.453680 imp_cv2=0.1605 load_cv2=5.1407 usage_frac=0.4330 topk_prob_mean=0.2823 ema_alpha_reverse=nan max_logit=12.7744
step:1035/1750 train_time:491325ms step_avg:474.71ms
[train step 1035] avg_loss=3.340658 main=2.884339 aux=0.456319 imp_cv2=0.1468 load_cv2=5.1810 usage_frac=0.4375 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=12.7744
step:1036/1750 train_time:491796ms step_avg:474.71ms
[train step 1036] avg_loss=3.413909 main=2.968809 aux=0.445100 imp_cv2=0.1904 load_cv2=5.0054 usage_frac=0.4375 topk_prob_mean=0.2986 ema_alpha_reverse=nan max_logit=12.7744
step:1037/1750 train_time:492279ms step_avg:474.71ms
[train step 1037] avg_loss=4.562390 main=4.093291 aux=0.469099 imp_cv2=0.0918 load_cv2=5.3731 usage_frac=0.4375 topk_prob_mean=0.2476 ema_alpha_reverse=nan max_logit=12.7744
step:1038/1750 train_time:492750ms step_avg:474.71ms
[train step 1038] avg_loss=4.215314 main=3.737761 aux=0.477553 imp_cv2=0.0698 load_cv2=5.4973 usage_frac=0.4330 topk_prob_mean=0.2275 ema_alpha_reverse=nan max_logit=12.7744
step:1039/1750 train_time:493221ms step_avg:474.71ms
[train step 1039] avg_loss=3.427040 main=2.979339 aux=0.447701 imp_cv2=0.1531 load_cv2=5.0801 usage_frac=0.4420 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=12.7744
step:1040/1750 train_time:493698ms step_avg:474.71ms
[train step 1040] avg_loss=3.687960 main=3.240024 aux=0.447936 imp_cv2=0.1243 load_cv2=5.0973 usage_frac=0.4420 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=12.7744
step:1041/1750 train_time:494177ms step_avg:474.71ms
[train step 1041] avg_loss=4.402301 main=3.908247 aux=0.494054 imp_cv2=0.0803 load_cv2=5.6698 usage_frac=0.4241 topk_prob_mean=0.2125 ema_alpha_reverse=nan max_logit=12.7744
step:1042/1750 train_time:494642ms step_avg:474.70ms
[train step 1042] avg_loss=3.564302 main=3.084236 aux=0.480065 imp_cv2=0.0640 load_cv2=5.5346 usage_frac=0.4375 topk_prob_mean=0.2245 ema_alpha_reverse=nan max_logit=12.7744
step:1043/1750 train_time:495128ms step_avg:474.72ms
[train step 1043] avg_loss=3.494168 main=3.051009 aux=0.443159 imp_cv2=0.1730 load_cv2=5.0023 usage_frac=0.4420 topk_prob_mean=0.2897 ema_alpha_reverse=nan max_logit=12.7744
step:1044/1750 train_time:495616ms step_avg:474.73ms
[train step 1044] avg_loss=3.498070 main=3.059067 aux=0.439002 imp_cv2=0.1601 load_cv2=4.9564 usage_frac=0.4420 topk_prob_mean=0.2902 ema_alpha_reverse=nan max_logit=12.7744
step:1045/1750 train_time:496087ms step_avg:474.72ms
[train step 1045] avg_loss=4.656791 main=4.132133 aux=0.524658 imp_cv2=0.0502 load_cv2=6.0520 usage_frac=0.3973 topk_prob_mean=0.1756 ema_alpha_reverse=nan max_logit=10.8091
step:1046/1750 train_time:496552ms step_avg:474.72ms
[train step 1046] avg_loss=3.777076 main=3.318191 aux=0.458885 imp_cv2=0.1165 load_cv2=5.2384 usage_frac=0.4375 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=12.7744
step:1047/1750 train_time:497028ms step_avg:474.72ms
[train step 1047] avg_loss=4.009897 main=3.533942 aux=0.475956 imp_cv2=0.0748 load_cv2=5.4735 usage_frac=0.4420 topk_prob_mean=0.2324 ema_alpha_reverse=nan max_logit=12.7744
step:1048/1750 train_time:497498ms step_avg:474.71ms
[train step 1048] avg_loss=3.346486 main=2.900749 aux=0.445737 imp_cv2=0.2018 load_cv2=5.0066 usage_frac=0.4420 topk_prob_mean=0.2992 ema_alpha_reverse=nan max_logit=12.7744
step:1049/1750 train_time:497960ms step_avg:474.70ms
[train step 1049] avg_loss=3.611442 main=3.144207 aux=0.467235 imp_cv2=0.0917 load_cv2=5.3535 usage_frac=0.4375 topk_prob_mean=0.2489 ema_alpha_reverse=nan max_logit=12.7744
step:1050/1750 train_time:498416ms step_avg:474.68ms
Running validation...
step:1050/1750 val_loss:3.195953 train_time:498427ms step_avg:474.69ms
[train step 1050] avg_loss=3.428128 main=2.969229 aux=0.458899 imp_cv2=0.1493 load_cv2=5.2170 usage_frac=0.4420 topk_prob_mean=0.2757 ema_alpha_reverse=nan max_logit=12.7744
step:1051/1750 train_time:498880ms step_avg:474.67ms
[train step 1051] avg_loss=4.513749 main=4.014966 aux=0.498783 imp_cv2=0.0621 load_cv2=5.7424 usage_frac=0.4330 topk_prob_mean=0.2087 ema_alpha_reverse=nan max_logit=12.7744
step:1052/1750 train_time:499351ms step_avg:474.67ms
[train step 1052] avg_loss=3.680374 main=3.222839 aux=0.457535 imp_cv2=0.1212 load_cv2=5.2204 usage_frac=0.4375 topk_prob_mean=0.2655 ema_alpha_reverse=nan max_logit=12.7744
step:1053/1750 train_time:499831ms step_avg:474.67ms
[train step 1053] avg_loss=3.992537 main=3.506907 aux=0.485630 imp_cv2=0.0621 load_cv2=5.5925 usage_frac=0.4330 topk_prob_mean=0.2205 ema_alpha_reverse=nan max_logit=12.7744
step:1054/1750 train_time:500294ms step_avg:474.66ms
[train step 1054] avg_loss=3.448294 main=2.995144 aux=0.453150 imp_cv2=0.1554 load_cv2=5.1356 usage_frac=0.4330 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=12.7744
step:1055/1750 train_time:500756ms step_avg:474.65ms
[train step 1055] avg_loss=4.268044 main=3.761806 aux=0.506239 imp_cv2=0.0599 load_cv2=5.8388 usage_frac=0.4330 topk_prob_mean=0.2011 ema_alpha_reverse=nan max_logit=12.7744
step:1056/1750 train_time:501206ms step_avg:474.63ms
[train step 1056] avg_loss=3.500362 main=3.048210 aux=0.452152 imp_cv2=0.1767 load_cv2=5.1020 usage_frac=0.4375 topk_prob_mean=0.2899 ema_alpha_reverse=nan max_logit=12.7744
step:1057/1750 train_time:501683ms step_avg:474.63ms
[train step 1057] avg_loss=3.367376 main=2.911475 aux=0.455900 imp_cv2=0.1780 load_cv2=5.1494 usage_frac=0.4420 topk_prob_mean=0.2904 ema_alpha_reverse=nan max_logit=12.7744
step:1058/1750 train_time:502154ms step_avg:474.63ms
[train step 1058] avg_loss=3.997775 main=3.521529 aux=0.476246 imp_cv2=0.0863 load_cv2=5.4719 usage_frac=0.4286 topk_prob_mean=0.2398 ema_alpha_reverse=nan max_logit=12.7744
step:1059/1750 train_time:502613ms step_avg:474.61ms
[train step 1059] avg_loss=4.461481 main=3.968214 aux=0.493267 imp_cv2=0.0552 load_cv2=5.6744 usage_frac=0.4330 topk_prob_mean=0.2120 ema_alpha_reverse=nan max_logit=12.7744
step:1060/1750 train_time:503066ms step_avg:474.59ms
[train step 1060] avg_loss=3.561375 main=3.098668 aux=0.462707 imp_cv2=0.1118 load_cv2=5.2806 usage_frac=0.4420 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=12.7744
step:1061/1750 train_time:503533ms step_avg:474.58ms
[train step 1061] avg_loss=3.686081 main=3.219336 aux=0.466746 imp_cv2=0.1194 load_cv2=5.3305 usage_frac=0.4330 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=12.7744
step:1062/1750 train_time:503998ms step_avg:474.57ms
[train step 1062] avg_loss=3.818459 main=3.351293 aux=0.467167 imp_cv2=0.0967 load_cv2=5.3457 usage_frac=0.4330 topk_prob_mean=0.2539 ema_alpha_reverse=nan max_logit=12.7744
step:1063/1750 train_time:504464ms step_avg:474.57ms
[train step 1063] avg_loss=3.322201 main=2.874480 aux=0.447721 imp_cv2=0.2364 load_cv2=4.9972 usage_frac=0.4286 topk_prob_mean=0.3126 ema_alpha_reverse=nan max_logit=12.7744
step:1064/1750 train_time:504951ms step_avg:474.58ms
[train step 1064] avg_loss=3.744539 main=3.260869 aux=0.483670 imp_cv2=0.0687 load_cv2=5.5580 usage_frac=0.4286 topk_prob_mean=0.2279 ema_alpha_reverse=nan max_logit=12.7744
step:1065/1750 train_time:505419ms step_avg:474.57ms
[train step 1065] avg_loss=3.453924 main=2.998769 aux=0.455155 imp_cv2=0.1695 load_cv2=5.1495 usage_frac=0.4330 topk_prob_mean=0.2886 ema_alpha_reverse=nan max_logit=12.7744
step:1066/1750 train_time:505888ms step_avg:474.57ms
[train step 1066] avg_loss=4.179052 main=3.710690 aux=0.468361 imp_cv2=0.1064 load_cv2=5.3619 usage_frac=0.4375 topk_prob_mean=0.2592 ema_alpha_reverse=nan max_logit=12.7744
step:1067/1750 train_time:506360ms step_avg:474.56ms
[train step 1067] avg_loss=3.500641 main=3.037717 aux=0.462924 imp_cv2=0.1106 load_cv2=5.2937 usage_frac=0.4330 topk_prob_mean=0.2617 ema_alpha_reverse=nan max_logit=12.7744
step:1068/1750 train_time:506818ms step_avg:474.55ms
[train step 1068] avg_loss=3.972644 main=3.515592 aux=0.457052 imp_cv2=0.1386 load_cv2=5.1967 usage_frac=0.4330 topk_prob_mean=0.2724 ema_alpha_reverse=nan max_logit=12.7744
step:1069/1750 train_time:507290ms step_avg:474.55ms
[train step 1069] avg_loss=3.543335 main=3.085300 aux=0.458034 imp_cv2=0.1095 load_cv2=5.2399 usage_frac=0.4330 topk_prob_mean=0.2645 ema_alpha_reverse=nan max_logit=12.7744
step:1070/1750 train_time:507762ms step_avg:474.54ms
[train step 1070] avg_loss=3.797488 main=3.320372 aux=0.477117 imp_cv2=0.0737 load_cv2=5.5065 usage_frac=0.4196 topk_prob_mean=0.2387 ema_alpha_reverse=nan max_logit=12.7744
step:1071/1750 train_time:508235ms step_avg:474.54ms
[train step 1071] avg_loss=3.418089 main=2.965401 aux=0.452688 imp_cv2=0.1943 load_cv2=5.1056 usage_frac=0.4241 topk_prob_mean=0.2949 ema_alpha_reverse=nan max_logit=12.7744
step:1072/1750 train_time:508702ms step_avg:474.54ms
[train step 1072] avg_loss=4.131204 main=3.666942 aux=0.464262 imp_cv2=0.1089 load_cv2=5.3112 usage_frac=0.4286 topk_prob_mean=0.2582 ema_alpha_reverse=nan max_logit=12.7744
step:1073/1750 train_time:509162ms step_avg:474.52ms
[train step 1073] avg_loss=5.713348 main=5.212180 aux=0.501168 imp_cv2=0.1430 load_cv2=5.6733 usage_frac=0.4152 topk_prob_mean=0.2195 ema_alpha_reverse=nan max_logit=12.7744
step:1074/1750 train_time:509635ms step_avg:474.52ms
[train step 1074] avg_loss=3.604989 main=3.138165 aux=0.466824 imp_cv2=0.0948 load_cv2=5.3453 usage_frac=0.4241 topk_prob_mean=0.2515 ema_alpha_reverse=nan max_logit=12.7744
step:1075/1750 train_time:510112ms step_avg:474.52ms
[train step 1075] avg_loss=3.389825 main=2.940298 aux=0.449527 imp_cv2=0.1643 load_cv2=5.0792 usage_frac=0.4241 topk_prob_mean=0.2885 ema_alpha_reverse=nan max_logit=12.7744
step:1076/1750 train_time:510587ms step_avg:474.52ms
[train step 1076] avg_loss=3.804672 main=3.332803 aux=0.471870 imp_cv2=0.1030 load_cv2=5.4020 usage_frac=0.4196 topk_prob_mean=0.2539 ema_alpha_reverse=nan max_logit=12.7744
step:1077/1750 train_time:511049ms step_avg:474.51ms
[train step 1077] avg_loss=3.932930 main=3.478057 aux=0.454873 imp_cv2=0.1388 load_cv2=5.1603 usage_frac=0.4241 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=12.7744
step:1078/1750 train_time:511516ms step_avg:474.50ms
[train step 1078] avg_loss=3.499171 main=3.030825 aux=0.468347 imp_cv2=0.1276 load_cv2=5.3442 usage_frac=0.4241 topk_prob_mean=0.2655 ema_alpha_reverse=nan max_logit=12.7744
step:1079/1750 train_time:511979ms step_avg:474.49ms
[train step 1079] avg_loss=3.499517 main=3.039595 aux=0.459922 imp_cv2=0.1413 load_cv2=5.2233 usage_frac=0.4286 topk_prob_mean=0.2779 ema_alpha_reverse=nan max_logit=12.7744
step:1080/1750 train_time:512436ms step_avg:474.48ms
[train step 1080] avg_loss=3.349877 main=2.884761 aux=0.465116 imp_cv2=0.1396 load_cv2=5.2904 usage_frac=0.4286 topk_prob_mean=0.2738 ema_alpha_reverse=nan max_logit=12.7744
step:1081/1750 train_time:512902ms step_avg:474.47ms
[train step 1081] avg_loss=3.475843 main=3.017195 aux=0.458649 imp_cv2=0.1312 load_cv2=5.2140 usage_frac=0.4196 topk_prob_mean=0.2770 ema_alpha_reverse=nan max_logit=12.7744
step:1082/1750 train_time:513391ms step_avg:474.48ms
[train step 1082] avg_loss=3.746116 main=3.284590 aux=0.461525 imp_cv2=0.1665 load_cv2=5.2218 usage_frac=0.4241 topk_prob_mean=0.2864 ema_alpha_reverse=nan max_logit=12.7744
step:1083/1750 train_time:513859ms step_avg:474.48ms
[train step 1083] avg_loss=3.775243 main=3.303045 aux=0.472198 imp_cv2=0.1191 load_cv2=5.3917 usage_frac=0.4241 topk_prob_mean=0.2626 ema_alpha_reverse=nan max_logit=12.7744
step:1084/1750 train_time:514310ms step_avg:474.46ms
[train step 1084] avg_loss=3.476531 main=3.015846 aux=0.460686 imp_cv2=0.1613 load_cv2=5.2139 usage_frac=0.4196 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=12.7744
step:1085/1750 train_time:514783ms step_avg:474.45ms
[train step 1085] avg_loss=3.530789 main=3.066882 aux=0.463906 imp_cv2=0.1789 load_cv2=5.2443 usage_frac=0.4286 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=12.7744
step:1086/1750 train_time:515261ms step_avg:474.46ms
[train step 1086] avg_loss=3.500791 main=3.029391 aux=0.471400 imp_cv2=0.1408 load_cv2=5.3746 usage_frac=0.4286 topk_prob_mean=0.2714 ema_alpha_reverse=nan max_logit=12.7744
step:1087/1750 train_time:515724ms step_avg:474.45ms
[train step 1087] avg_loss=3.698783 main=3.237416 aux=0.461367 imp_cv2=0.1279 load_cv2=5.2650 usage_frac=0.4196 topk_prob_mean=0.2699 ema_alpha_reverse=nan max_logit=12.7744
step:1088/1750 train_time:516183ms step_avg:474.43ms
[train step 1088] avg_loss=3.432036 main=2.964448 aux=0.467588 imp_cv2=0.1317 load_cv2=5.3385 usage_frac=0.4330 topk_prob_mean=0.2696 ema_alpha_reverse=nan max_logit=12.7744
step:1089/1750 train_time:516644ms step_avg:474.42ms
[train step 1089] avg_loss=3.582440 main=3.119702 aux=0.462738 imp_cv2=0.1326 load_cv2=5.2774 usage_frac=0.4286 topk_prob_mean=0.2722 ema_alpha_reverse=nan max_logit=12.7744
step:1090/1750 train_time:517109ms step_avg:474.41ms
[train step 1090] avg_loss=3.528307 main=3.073417 aux=0.454891 imp_cv2=0.1817 load_cv2=5.1378 usage_frac=0.4286 topk_prob_mean=0.2925 ema_alpha_reverse=nan max_logit=12.7744
step:1091/1750 train_time:517581ms step_avg:474.41ms
[train step 1091] avg_loss=3.461906 main=3.004598 aux=0.457309 imp_cv2=0.1192 load_cv2=5.2190 usage_frac=0.4286 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=12.7744
step:1092/1750 train_time:518061ms step_avg:474.42ms
[train step 1092] avg_loss=4.642409 main=4.134672 aux=0.507737 imp_cv2=0.1206 load_cv2=5.7836 usage_frac=0.4241 topk_prob_mean=0.2139 ema_alpha_reverse=nan max_logit=12.7744
step:1093/1750 train_time:518707ms step_avg:474.57ms
[train step 1093] avg_loss=3.520673 main=3.056834 aux=0.463839 imp_cv2=0.1165 load_cv2=5.3006 usage_frac=0.4330 topk_prob_mean=0.2629 ema_alpha_reverse=nan max_logit=12.7744
step:1094/1750 train_time:519170ms step_avg:474.56ms
[train step 1094] avg_loss=3.575420 main=3.110403 aux=0.465017 imp_cv2=0.1424 load_cv2=5.3038 usage_frac=0.4286 topk_prob_mean=0.2707 ema_alpha_reverse=nan max_logit=12.7744
step:1095/1750 train_time:519647ms step_avg:474.56ms
[train step 1095] avg_loss=3.467687 main=3.002952 aux=0.464736 imp_cv2=0.1292 load_cv2=5.3140 usage_frac=0.4241 topk_prob_mean=0.2650 ema_alpha_reverse=nan max_logit=12.7744
step:1096/1750 train_time:520100ms step_avg:474.54ms
[train step 1096] avg_loss=3.801856 main=3.341483 aux=0.460372 imp_cv2=0.1329 load_cv2=5.2477 usage_frac=0.4241 topk_prob_mean=0.2704 ema_alpha_reverse=nan max_logit=12.7744
step:1097/1750 train_time:520578ms step_avg:474.55ms
[train step 1097] avg_loss=3.418182 main=2.955220 aux=0.462962 imp_cv2=0.1482 load_cv2=5.2693 usage_frac=0.4286 topk_prob_mean=0.2723 ema_alpha_reverse=nan max_logit=12.7744
step:1098/1750 train_time:521050ms step_avg:474.55ms
[train step 1098] avg_loss=3.622621 main=3.152591 aux=0.470030 imp_cv2=0.0905 load_cv2=5.3963 usage_frac=0.4286 topk_prob_mean=0.2484 ema_alpha_reverse=nan max_logit=12.7744
step:1099/1750 train_time:521510ms step_avg:474.53ms
[train step 1099] avg_loss=3.384584 main=2.929010 aux=0.455574 imp_cv2=0.1520 load_cv2=5.1794 usage_frac=0.4241 topk_prob_mean=0.2786 ema_alpha_reverse=nan max_logit=12.7744
step:1100/1750 train_time:521988ms step_avg:474.53ms
Running validation...
step:1100/1750 val_loss:3.161235 train_time:522000ms step_avg:474.55ms
[train step 1100] avg_loss=3.494596 main=3.038680 aux=0.455916 imp_cv2=0.1371 load_cv2=5.1943 usage_frac=0.4375 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=12.7744
step:1101/1750 train_time:522457ms step_avg:474.53ms
[train step 1101] avg_loss=3.724466 main=3.265971 aux=0.458495 imp_cv2=0.1211 load_cv2=5.2387 usage_frac=0.4286 topk_prob_mean=0.2662 ema_alpha_reverse=nan max_logit=12.7744
step:1102/1750 train_time:522926ms step_avg:474.52ms
[train step 1102] avg_loss=3.642648 main=3.179961 aux=0.462687 imp_cv2=0.0880 load_cv2=5.3078 usage_frac=0.4241 topk_prob_mean=0.2490 ema_alpha_reverse=nan max_logit=12.7744
step:1103/1750 train_time:523393ms step_avg:474.52ms
[train step 1103] avg_loss=3.796920 main=3.331907 aux=0.465013 imp_cv2=0.1003 load_cv2=5.3367 usage_frac=0.4330 topk_prob_mean=0.2538 ema_alpha_reverse=nan max_logit=12.7744
step:1104/1750 train_time:523863ms step_avg:474.51ms
[train step 1104] avg_loss=3.720736 main=3.253011 aux=0.467724 imp_cv2=0.0950 load_cv2=5.3717 usage_frac=0.4241 topk_prob_mean=0.2517 ema_alpha_reverse=nan max_logit=12.7744
step:1105/1750 train_time:524326ms step_avg:474.50ms
[train step 1105] avg_loss=3.566266 main=3.110713 aux=0.455553 imp_cv2=0.1355 load_cv2=5.1814 usage_frac=0.4330 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=12.7744
step:1106/1750 train_time:524794ms step_avg:474.50ms
[train step 1106] avg_loss=3.110297 main=2.660014 aux=0.450283 imp_cv2=0.2149 load_cv2=5.0534 usage_frac=0.4330 topk_prob_mean=0.3023 ema_alpha_reverse=nan max_logit=12.7744
step:1107/1750 train_time:525261ms step_avg:474.49ms
[train step 1107] avg_loss=3.415756 main=2.956965 aux=0.458791 imp_cv2=0.1814 load_cv2=5.1894 usage_frac=0.4286 topk_prob_mean=0.2885 ema_alpha_reverse=nan max_logit=12.7744
step:1108/1750 train_time:525735ms step_avg:474.49ms
[train step 1108] avg_loss=3.444589 main=2.982402 aux=0.462188 imp_cv2=0.1185 load_cv2=5.2839 usage_frac=0.4330 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=12.7744
step:1109/1750 train_time:526192ms step_avg:474.47ms
[train step 1109] avg_loss=3.988554 main=3.510509 aux=0.478045 imp_cv2=0.0839 load_cv2=5.4984 usage_frac=0.4375 topk_prob_mean=0.2411 ema_alpha_reverse=nan max_logit=12.7744
step:1110/1750 train_time:526648ms step_avg:474.46ms
[train step 1110] avg_loss=3.777032 main=3.304386 aux=0.472646 imp_cv2=0.1063 load_cv2=5.4110 usage_frac=0.4286 topk_prob_mean=0.2570 ema_alpha_reverse=nan max_logit=12.7744
step:1111/1750 train_time:527105ms step_avg:474.44ms
[train step 1111] avg_loss=3.345783 main=2.884192 aux=0.461592 imp_cv2=0.1449 load_cv2=5.2445 usage_frac=0.4286 topk_prob_mean=0.2754 ema_alpha_reverse=nan max_logit=12.7744
step:1112/1750 train_time:527586ms step_avg:474.45ms
[train step 1112] avg_loss=3.757117 main=3.262515 aux=0.494601 imp_cv2=0.0653 load_cv2=5.7085 usage_frac=0.4286 topk_prob_mean=0.2218 ema_alpha_reverse=nan max_logit=12.7744
step:1113/1750 train_time:528057ms step_avg:474.44ms
[train step 1113] avg_loss=3.720477 main=3.255774 aux=0.464703 imp_cv2=0.1367 load_cv2=5.2906 usage_frac=0.4330 topk_prob_mean=0.2743 ema_alpha_reverse=nan max_logit=12.7744
step:1114/1750 train_time:528521ms step_avg:474.44ms
[train step 1114] avg_loss=3.895111 main=3.412610 aux=0.482500 imp_cv2=0.0855 load_cv2=5.5206 usage_frac=0.4241 topk_prob_mean=0.2336 ema_alpha_reverse=nan max_logit=12.7744
step:1115/1750 train_time:528983ms step_avg:474.42ms
[train step 1115] avg_loss=3.789114 main=3.314744 aux=0.474370 imp_cv2=0.0845 load_cv2=5.4337 usage_frac=0.4286 topk_prob_mean=0.2500 ema_alpha_reverse=nan max_logit=12.7744
step:1116/1750 train_time:529449ms step_avg:474.42ms
[train step 1116] avg_loss=3.721167 main=3.246986 aux=0.474181 imp_cv2=0.0925 load_cv2=5.4319 usage_frac=0.4330 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=12.7744
step:1117/1750 train_time:530101ms step_avg:474.58ms
[train step 1117] avg_loss=3.597089 main=3.134064 aux=0.463025 imp_cv2=0.1432 load_cv2=5.2646 usage_frac=0.4241 topk_prob_mean=0.2765 ema_alpha_reverse=nan max_logit=12.7744
step:1118/1750 train_time:530561ms step_avg:474.56ms
[train step 1118] avg_loss=3.591900 main=3.106303 aux=0.485597 imp_cv2=0.0802 load_cv2=5.5797 usage_frac=0.4286 topk_prob_mean=0.2358 ema_alpha_reverse=nan max_logit=12.7744
step:1119/1750 train_time:531018ms step_avg:474.55ms
[train step 1119] avg_loss=3.278886 main=2.821778 aux=0.457108 imp_cv2=0.1752 load_cv2=5.1654 usage_frac=0.4330 topk_prob_mean=0.2900 ema_alpha_reverse=nan max_logit=12.7744
step:1120/1750 train_time:531503ms step_avg:474.56ms
[train step 1120] avg_loss=4.328215 main=3.840295 aux=0.487921 imp_cv2=0.0635 load_cv2=5.6206 usage_frac=0.4330 topk_prob_mean=0.2229 ema_alpha_reverse=nan max_logit=12.7744
step:1121/1750 train_time:531968ms step_avg:474.55ms
[train step 1121] avg_loss=3.665617 main=3.198890 aux=0.466727 imp_cv2=0.1244 load_cv2=5.3247 usage_frac=0.4330 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=12.7744
step:1122/1750 train_time:532428ms step_avg:474.53ms
[train step 1122] avg_loss=3.638534 main=3.166527 aux=0.472007 imp_cv2=0.0947 load_cv2=5.4008 usage_frac=0.4241 topk_prob_mean=0.2511 ema_alpha_reverse=nan max_logit=12.7744
step:1123/1750 train_time:532883ms step_avg:474.52ms
[train step 1123] avg_loss=3.327076 main=2.857769 aux=0.469307 imp_cv2=0.1588 load_cv2=5.3384 usage_frac=0.4286 topk_prob_mean=0.2786 ema_alpha_reverse=nan max_logit=12.7744
step:1124/1750 train_time:533348ms step_avg:474.51ms
[train step 1124] avg_loss=3.309592 main=2.848214 aux=0.461378 imp_cv2=0.1378 load_cv2=5.2548 usage_frac=0.4241 topk_prob_mean=0.2748 ema_alpha_reverse=nan max_logit=12.7744
step:1125/1750 train_time:533802ms step_avg:474.49ms
[train step 1125] avg_loss=3.465036 main=3.005964 aux=0.459072 imp_cv2=0.1450 load_cv2=5.2185 usage_frac=0.4330 topk_prob_mean=0.2781 ema_alpha_reverse=nan max_logit=12.7744
step:1126/1750 train_time:534261ms step_avg:474.48ms
[train step 1126] avg_loss=3.633635 main=3.169287 aux=0.464348 imp_cv2=0.0977 load_cv2=5.3208 usage_frac=0.4330 topk_prob_mean=0.2570 ema_alpha_reverse=nan max_logit=12.7744
step:1127/1750 train_time:534727ms step_avg:474.47ms
[train step 1127] avg_loss=3.756560 main=3.284878 aux=0.471681 imp_cv2=0.0877 load_cv2=5.4221 usage_frac=0.4286 topk_prob_mean=0.2482 ema_alpha_reverse=nan max_logit=12.7744
step:1128/1750 train_time:535179ms step_avg:474.45ms
[train step 1128] avg_loss=3.255399 main=2.793874 aux=0.461526 imp_cv2=0.1447 load_cv2=5.2436 usage_frac=0.4241 topk_prob_mean=0.2766 ema_alpha_reverse=nan max_logit=12.7744
step:1129/1750 train_time:535639ms step_avg:474.44ms
[train step 1129] avg_loss=3.605043 main=3.145700 aux=0.459343 imp_cv2=0.1830 load_cv2=5.1918 usage_frac=0.4286 topk_prob_mean=0.2880 ema_alpha_reverse=nan max_logit=12.7744
step:1130/1750 train_time:536120ms step_avg:474.44ms
[train step 1130] avg_loss=3.537599 main=3.075741 aux=0.461858 imp_cv2=0.1319 load_cv2=5.2629 usage_frac=0.4241 topk_prob_mean=0.2703 ema_alpha_reverse=nan max_logit=12.7744
step:1131/1750 train_time:536577ms step_avg:474.43ms
[train step 1131] avg_loss=3.521311 main=3.066816 aux=0.454494 imp_cv2=0.1719 load_cv2=5.1408 usage_frac=0.4286 topk_prob_mean=0.2852 ema_alpha_reverse=nan max_logit=12.7744
step:1132/1750 train_time:537046ms step_avg:474.42ms
[train step 1132] avg_loss=3.486200 main=3.028376 aux=0.457824 imp_cv2=0.1452 load_cv2=5.2079 usage_frac=0.4196 topk_prob_mean=0.2774 ema_alpha_reverse=nan max_logit=12.7744
step:1133/1750 train_time:537510ms step_avg:474.41ms
[train step 1133] avg_loss=3.939275 main=3.485000 aux=0.454275 imp_cv2=0.1661 load_cv2=5.1475 usage_frac=0.4286 topk_prob_mean=0.2853 ema_alpha_reverse=nan max_logit=12.7744
step:1134/1750 train_time:538170ms step_avg:474.58ms
[train step 1134] avg_loss=3.850076 main=3.376833 aux=0.473243 imp_cv2=0.0760 load_cv2=5.4575 usage_frac=0.4152 topk_prob_mean=0.2373 ema_alpha_reverse=nan max_logit=12.7744
step:1135/1750 train_time:538628ms step_avg:474.56ms
[train step 1135] avg_loss=3.708635 main=3.240433 aux=0.468202 imp_cv2=0.0929 load_cv2=5.3700 usage_frac=0.4196 topk_prob_mean=0.2508 ema_alpha_reverse=nan max_logit=12.7744
step:1136/1750 train_time:539093ms step_avg:474.55ms
[train step 1136] avg_loss=3.845034 main=3.375275 aux=0.469759 imp_cv2=0.0814 load_cv2=5.4117 usage_frac=0.4330 topk_prob_mean=0.2404 ema_alpha_reverse=nan max_logit=12.7744
step:1137/1750 train_time:539553ms step_avg:474.54ms
[train step 1137] avg_loss=3.272737 main=2.818362 aux=0.454376 imp_cv2=0.1268 load_cv2=5.1909 usage_frac=0.4241 topk_prob_mean=0.2704 ema_alpha_reverse=nan max_logit=12.7744
step:1138/1750 train_time:540030ms step_avg:474.54ms
[train step 1138] avg_loss=4.008325 main=3.514813 aux=0.493511 imp_cv2=0.0543 load_cv2=5.7090 usage_frac=0.4286 topk_prob_mean=0.2107 ema_alpha_reverse=nan max_logit=12.7744
step:1139/1750 train_time:540675ms step_avg:474.69ms
[train step 1139] avg_loss=3.922123 main=3.448493 aux=0.473630 imp_cv2=0.0645 load_cv2=5.4525 usage_frac=0.4196 topk_prob_mean=0.2276 ema_alpha_reverse=nan max_logit=12.7744
step:1140/1750 train_time:541132ms step_avg:474.68ms
[train step 1140] avg_loss=3.555797 main=3.089746 aux=0.466052 imp_cv2=0.0912 load_cv2=5.3570 usage_frac=0.4241 topk_prob_mean=0.2516 ema_alpha_reverse=nan max_logit=12.7744
step:1141/1750 train_time:541600ms step_avg:474.67ms
[train step 1141] avg_loss=3.572696 main=3.101935 aux=0.470762 imp_cv2=0.0801 load_cv2=5.4226 usage_frac=0.4330 topk_prob_mean=0.2415 ema_alpha_reverse=nan max_logit=12.7744
step:1142/1750 train_time:542069ms step_avg:474.67ms
[train step 1142] avg_loss=3.323607 main=2.873679 aux=0.449927 imp_cv2=0.1548 load_cv2=5.1091 usage_frac=0.4286 topk_prob_mean=0.2837 ema_alpha_reverse=nan max_logit=12.7744
step:1143/1750 train_time:542529ms step_avg:474.65ms
[train step 1143] avg_loss=3.704290 main=3.239845 aux=0.464446 imp_cv2=0.0768 load_cv2=5.3415 usage_frac=0.4241 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=12.7744
step:1144/1750 train_time:542984ms step_avg:474.64ms
[train step 1144] avg_loss=4.154137 main=3.680789 aux=0.473348 imp_cv2=0.0764 load_cv2=5.4521 usage_frac=0.4286 topk_prob_mean=0.2360 ema_alpha_reverse=nan max_logit=12.7744
step:1145/1750 train_time:543457ms step_avg:474.63ms
[train step 1145] avg_loss=3.525257 main=3.052655 aux=0.472602 imp_cv2=0.0702 load_cv2=5.4357 usage_frac=0.4286 topk_prob_mean=0.2346 ema_alpha_reverse=nan max_logit=12.7744
step:1146/1750 train_time:543914ms step_avg:474.62ms
[train step 1146] avg_loss=3.676230 main=3.222850 aux=0.453380 imp_cv2=0.1286 load_cv2=5.1726 usage_frac=0.4241 topk_prob_mean=0.2720 ema_alpha_reverse=nan max_logit=12.7744
step:1147/1750 train_time:544384ms step_avg:474.62ms
[train step 1147] avg_loss=3.665537 main=3.215944 aux=0.449593 imp_cv2=0.1378 load_cv2=5.1085 usage_frac=0.4241 topk_prob_mean=0.2768 ema_alpha_reverse=nan max_logit=12.7744
step:1148/1750 train_time:544847ms step_avg:474.61ms
[train step 1148] avg_loss=3.695361 main=3.227844 aux=0.467518 imp_cv2=0.0774 load_cv2=5.3615 usage_frac=0.4330 topk_prob_mean=0.2390 ema_alpha_reverse=nan max_logit=12.7744
step:1149/1750 train_time:545312ms step_avg:474.60ms
[train step 1149] avg_loss=3.331809 main=2.880639 aux=0.451170 imp_cv2=0.1313 load_cv2=5.1414 usage_frac=0.4286 topk_prob_mean=0.2744 ema_alpha_reverse=nan max_logit=12.7744
step:1150/1750 train_time:545770ms step_avg:474.58ms
Running validation...
step:1150/1750 val_loss:3.124033 train_time:545782ms step_avg:474.59ms
[train step 1150] avg_loss=3.490325 main=2.988734 aux=0.501591 imp_cv2=0.0733 load_cv2=5.7667 usage_frac=0.4152 topk_prob_mean=0.2008 ema_alpha_reverse=nan max_logit=12.5534
step:1151/1750 train_time:546238ms step_avg:474.58ms
[train step 1151] avg_loss=3.149735 main=2.705111 aux=0.444624 imp_cv2=0.2376 load_cv2=4.9664 usage_frac=0.4241 topk_prob_mean=0.3121 ema_alpha_reverse=nan max_logit=12.7744
step:1152/1750 train_time:546713ms step_avg:474.58ms
[train step 1152] avg_loss=3.577416 main=3.131018 aux=0.446397 imp_cv2=0.1609 load_cv2=5.0500 usage_frac=0.4241 topk_prob_mean=0.2855 ema_alpha_reverse=nan max_logit=12.7744
step:1153/1750 train_time:547188ms step_avg:474.58ms
[train step 1153] avg_loss=3.498979 main=3.054860 aux=0.444119 imp_cv2=0.1573 load_cv2=5.0249 usage_frac=0.4152 topk_prob_mean=0.2878 ema_alpha_reverse=nan max_logit=12.7744
step:1154/1750 train_time:547656ms step_avg:474.57ms
[train step 1154] avg_loss=3.604605 main=3.146021 aux=0.458585 imp_cv2=0.1107 load_cv2=5.2427 usage_frac=0.4286 topk_prob_mean=0.2634 ema_alpha_reverse=nan max_logit=12.7744
step:1155/1750 train_time:548120ms step_avg:474.56ms
[train step 1155] avg_loss=3.384026 main=2.934856 aux=0.449169 imp_cv2=0.1315 load_cv2=5.1140 usage_frac=0.4196 topk_prob_mean=0.2772 ema_alpha_reverse=nan max_logit=12.7744
step:1156/1750 train_time:548582ms step_avg:474.55ms
[train step 1156] avg_loss=3.725730 main=3.261259 aux=0.464471 imp_cv2=0.0828 load_cv2=5.3292 usage_frac=0.4196 topk_prob_mean=0.2488 ema_alpha_reverse=nan max_logit=12.7744
step:1157/1750 train_time:549036ms step_avg:474.53ms
[train step 1157] avg_loss=3.253497 main=2.808166 aux=0.445331 imp_cv2=0.1723 load_cv2=5.0308 usage_frac=0.4241 topk_prob_mean=0.2919 ema_alpha_reverse=nan max_logit=12.7744
step:1158/1750 train_time:549504ms step_avg:474.53ms
[train step 1158] avg_loss=3.863365 main=3.389854 aux=0.473510 imp_cv2=0.0723 load_cv2=5.4458 usage_frac=0.4196 topk_prob_mean=0.2376 ema_alpha_reverse=nan max_logit=12.7744
step:1159/1750 train_time:549973ms step_avg:474.52ms
[train step 1159] avg_loss=3.909781 main=3.436054 aux=0.473727 imp_cv2=0.0666 load_cv2=5.4628 usage_frac=0.4196 topk_prob_mean=0.2326 ema_alpha_reverse=nan max_logit=12.7744
step:1160/1750 train_time:550433ms step_avg:474.51ms
[train step 1160] avg_loss=3.418166 main=2.963125 aux=0.455041 imp_cv2=0.1520 load_cv2=5.1674 usage_frac=0.4241 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=12.7744
step:1161/1750 train_time:550896ms step_avg:474.50ms
[train step 1161] avg_loss=3.191603 main=2.739126 aux=0.452477 imp_cv2=0.1893 load_cv2=5.1098 usage_frac=0.4196 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=12.7744
step:1162/1750 train_time:551363ms step_avg:474.49ms
[train step 1162] avg_loss=3.501605 main=3.048811 aux=0.452794 imp_cv2=0.1519 load_cv2=5.1406 usage_frac=0.4196 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=12.7744
step:1163/1750 train_time:551826ms step_avg:474.48ms
[train step 1163] avg_loss=3.456746 main=2.997958 aux=0.458788 imp_cv2=0.1391 load_cv2=5.2261 usage_frac=0.4241 topk_prob_mean=0.2769 ema_alpha_reverse=nan max_logit=12.7744
step:1164/1750 train_time:552283ms step_avg:474.47ms
[train step 1164] avg_loss=3.567513 main=3.085988 aux=0.481525 imp_cv2=0.0820 load_cv2=5.5412 usage_frac=0.4286 topk_prob_mean=0.2408 ema_alpha_reverse=nan max_logit=12.7744
step:1165/1750 train_time:552756ms step_avg:474.47ms
[train step 1165] avg_loss=3.372602 main=2.913406 aux=0.459196 imp_cv2=0.1552 load_cv2=5.2097 usage_frac=0.4241 topk_prob_mean=0.2815 ema_alpha_reverse=nan max_logit=12.7744
step:1166/1750 train_time:553215ms step_avg:474.46ms
[train step 1166] avg_loss=3.365030 main=2.902395 aux=0.462636 imp_cv2=0.0989 load_cv2=5.2874 usage_frac=0.4196 topk_prob_mean=0.2537 ema_alpha_reverse=nan max_logit=12.7744
step:1167/1750 train_time:553672ms step_avg:474.44ms
[train step 1167] avg_loss=3.749473 main=3.285341 aux=0.464132 imp_cv2=0.1172 load_cv2=5.2994 usage_frac=0.4152 topk_prob_mean=0.2658 ema_alpha_reverse=nan max_logit=12.7744
step:1168/1750 train_time:554142ms step_avg:474.44ms
[train step 1168] avg_loss=3.498860 main=3.051430 aux=0.447429 imp_cv2=0.1392 load_cv2=5.0737 usage_frac=0.4241 topk_prob_mean=0.2818 ema_alpha_reverse=nan max_logit=12.7744
step:1169/1750 train_time:554604ms step_avg:474.43ms
[train step 1169] avg_loss=3.456024 main=3.001706 aux=0.454318 imp_cv2=0.1330 load_cv2=5.1737 usage_frac=0.4196 topk_prob_mean=0.2716 ema_alpha_reverse=nan max_logit=12.7744
step:1170/1750 train_time:555066ms step_avg:474.42ms
[train step 1170] avg_loss=4.577915 main=4.092600 aux=0.485315 imp_cv2=0.0947 load_cv2=5.5596 usage_frac=0.4196 topk_prob_mean=0.2262 ema_alpha_reverse=nan max_logit=12.7744
step:1171/1750 train_time:555526ms step_avg:474.40ms
[train step 1171] avg_loss=3.230331 main=2.791809 aux=0.438522 imp_cv2=0.2345 load_cv2=4.8886 usage_frac=0.4241 topk_prob_mean=0.3151 ema_alpha_reverse=nan max_logit=12.7744
step:1172/1750 train_time:556005ms step_avg:474.41ms
[train step 1172] avg_loss=3.303759 main=2.860574 aux=0.443185 imp_cv2=0.1976 load_cv2=4.9818 usage_frac=0.4196 topk_prob_mean=0.2988 ema_alpha_reverse=nan max_logit=12.7744
step:1173/1750 train_time:556471ms step_avg:474.40ms
[train step 1173] avg_loss=3.584877 main=3.131219 aux=0.453658 imp_cv2=0.1014 load_cv2=5.1933 usage_frac=0.4241 topk_prob_mean=0.2593 ema_alpha_reverse=nan max_logit=12.7744
step:1174/1750 train_time:556934ms step_avg:474.39ms
[train step 1174] avg_loss=3.283867 main=2.845282 aux=0.438585 imp_cv2=0.1731 load_cv2=4.9549 usage_frac=0.4196 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=12.7744
step:1175/1750 train_time:557400ms step_avg:474.38ms
[train step 1175] avg_loss=3.532564 main=3.082645 aux=0.449918 imp_cv2=0.1215 load_cv2=5.1225 usage_frac=0.4152 topk_prob_mean=0.2708 ema_alpha_reverse=nan max_logit=12.7744
step:1176/1750 train_time:557851ms step_avg:474.36ms
[train step 1176] avg_loss=3.562073 main=3.114182 aux=0.447891 imp_cv2=0.1203 load_cv2=5.0992 usage_frac=0.4241 topk_prob_mean=0.2731 ema_alpha_reverse=nan max_logit=12.7744
step:1177/1750 train_time:558319ms step_avg:474.36ms
[train step 1177] avg_loss=3.454798 main=3.005012 aux=0.449786 imp_cv2=0.1392 load_cv2=5.1157 usage_frac=0.4196 topk_prob_mean=0.2790 ema_alpha_reverse=nan max_logit=12.7744
step:1178/1750 train_time:558775ms step_avg:474.34ms
[train step 1178] avg_loss=3.816824 main=3.308923 aux=0.507901 imp_cv2=0.0503 load_cv2=5.8841 usage_frac=0.4196 topk_prob_mean=0.1981 ema_alpha_reverse=nan max_logit=12.7744
step:1179/1750 train_time:559226ms step_avg:474.32ms
[train step 1179] avg_loss=3.553177 main=3.102920 aux=0.450257 imp_cv2=0.1359 load_cv2=5.1222 usage_frac=0.4241 topk_prob_mean=0.2778 ema_alpha_reverse=nan max_logit=12.7744
step:1180/1750 train_time:559684ms step_avg:474.31ms
[train step 1180] avg_loss=4.011432 main=3.548732 aux=0.462700 imp_cv2=0.0970 load_cv2=5.2920 usage_frac=0.4241 topk_prob_mean=0.2557 ema_alpha_reverse=nan max_logit=12.7744
step:1181/1750 train_time:560142ms step_avg:474.29ms
[train step 1181] avg_loss=3.482674 main=3.034611 aux=0.448063 imp_cv2=0.1514 load_cv2=5.0739 usage_frac=0.4241 topk_prob_mean=0.2860 ema_alpha_reverse=nan max_logit=12.7744
step:1182/1750 train_time:560604ms step_avg:474.28ms
[train step 1182] avg_loss=3.631709 main=3.170669 aux=0.461039 imp_cv2=0.1064 load_cv2=5.2735 usage_frac=0.4196 topk_prob_mean=0.2620 ema_alpha_reverse=nan max_logit=12.7744
step:1183/1750 train_time:561065ms step_avg:474.27ms
[train step 1183] avg_loss=3.607792 main=3.149094 aux=0.458698 imp_cv2=0.1031 load_cv2=5.2478 usage_frac=0.4196 topk_prob_mean=0.2634 ema_alpha_reverse=nan max_logit=12.7744
step:1184/1750 train_time:561520ms step_avg:474.26ms
[train step 1184] avg_loss=3.514684 main=3.065728 aux=0.448956 imp_cv2=0.1399 load_cv2=5.1036 usage_frac=0.4152 topk_prob_mean=0.2827 ema_alpha_reverse=nan max_logit=12.7744
step:1185/1750 train_time:561977ms step_avg:474.24ms
[train step 1185] avg_loss=4.288857 main=3.786942 aux=0.501915 imp_cv2=0.0749 load_cv2=5.7744 usage_frac=0.4196 topk_prob_mean=0.2042 ema_alpha_reverse=nan max_logit=12.7744
step:1186/1750 train_time:562446ms step_avg:474.24ms
[train step 1186] avg_loss=4.298971 main=3.824006 aux=0.474965 imp_cv2=0.0748 load_cv2=5.4815 usage_frac=0.4152 topk_prob_mean=0.2318 ema_alpha_reverse=nan max_logit=12.7744
step:1187/1750 train_time:562909ms step_avg:474.23ms
[train step 1187] avg_loss=3.858750 main=3.389694 aux=0.469056 imp_cv2=0.0775 load_cv2=5.3983 usage_frac=0.4241 topk_prob_mean=0.2413 ema_alpha_reverse=nan max_logit=12.7744
step:1188/1750 train_time:563370ms step_avg:474.22ms
[train step 1188] avg_loss=3.492898 main=3.051997 aux=0.440901 imp_cv2=0.1526 load_cv2=4.9968 usage_frac=0.4196 topk_prob_mean=0.2891 ema_alpha_reverse=nan max_logit=12.7744
step:1189/1750 train_time:563837ms step_avg:474.21ms
[train step 1189] avg_loss=3.194663 main=2.745638 aux=0.449025 imp_cv2=0.1464 load_cv2=5.1042 usage_frac=0.4196 topk_prob_mean=0.2829 ema_alpha_reverse=nan max_logit=12.7744
step:1190/1750 train_time:564309ms step_avg:474.21ms
[train step 1190] avg_loss=3.120415 main=2.682454 aux=0.437961 imp_cv2=0.2152 load_cv2=4.9054 usage_frac=0.4152 topk_prob_mean=0.3088 ema_alpha_reverse=nan max_logit=12.7744
step:1191/1750 train_time:564785ms step_avg:474.21ms
[train step 1191] avg_loss=3.889009 main=3.422817 aux=0.466193 imp_cv2=0.0676 load_cv2=5.3749 usage_frac=0.4107 topk_prob_mean=0.2337 ema_alpha_reverse=nan max_logit=12.7744
step:1192/1750 train_time:565247ms step_avg:474.20ms
[train step 1192] avg_loss=4.407422 main=3.950597 aux=0.456825 imp_cv2=0.1093 load_cv2=5.2182 usage_frac=0.4196 topk_prob_mean=0.2645 ema_alpha_reverse=nan max_logit=12.7744
step:1193/1750 train_time:565719ms step_avg:474.20ms
[train step 1193] avg_loss=4.677222 main=4.195417 aux=0.481805 imp_cv2=0.0580 load_cv2=5.5678 usage_frac=0.4152 topk_prob_mean=0.2159 ema_alpha_reverse=nan max_logit=12.7744
step:1194/1750 train_time:566180ms step_avg:474.19ms
[train step 1194] avg_loss=3.702992 main=3.243702 aux=0.459290 imp_cv2=0.1046 load_cv2=5.2606 usage_frac=0.4152 topk_prob_mean=0.2600 ema_alpha_reverse=nan max_logit=12.7744
step:1195/1750 train_time:566636ms step_avg:474.17ms
[train step 1195] avg_loss=4.127830 main=3.635253 aux=0.492577 imp_cv2=0.0540 load_cv2=5.6912 usage_frac=0.4152 topk_prob_mean=0.2129 ema_alpha_reverse=nan max_logit=12.7744
step:1196/1750 train_time:567101ms step_avg:474.16ms
[train step 1196] avg_loss=3.353027 main=2.890486 aux=0.462541 imp_cv2=0.0969 load_cv2=5.3088 usage_frac=0.4196 topk_prob_mean=0.2548 ema_alpha_reverse=nan max_logit=12.7744
step:1197/1750 train_time:567553ms step_avg:474.15ms
[train step 1197] avg_loss=3.289039 main=2.840101 aux=0.448938 imp_cv2=0.1720 load_cv2=5.0783 usage_frac=0.4196 topk_prob_mean=0.2909 ema_alpha_reverse=nan max_logit=12.7744
step:1198/1750 train_time:568025ms step_avg:474.14ms
[train step 1198] avg_loss=2.988612 main=2.543564 aux=0.445048 imp_cv2=0.2437 load_cv2=4.9694 usage_frac=0.4196 topk_prob_mean=0.3160 ema_alpha_reverse=nan max_logit=12.7744
step:1199/1750 train_time:568489ms step_avg:474.14ms
[train step 1199] avg_loss=3.558293 main=3.095722 aux=0.462571 imp_cv2=0.1142 load_cv2=5.2921 usage_frac=0.4107 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=12.7744
step:1200/1750 train_time:568950ms step_avg:474.12ms
Running validation...
step:1200/1750 val_loss:3.089749 train_time:568962ms step_avg:474.13ms
[train step 1200] avg_loss=3.211553 main=2.764336 aux=0.447217 imp_cv2=0.1929 load_cv2=5.0370 usage_frac=0.4241 topk_prob_mean=0.2987 ema_alpha_reverse=nan max_logit=12.7744
step:1201/1750 train_time:569412ms step_avg:474.11ms
[train step 1201] avg_loss=3.488377 main=3.031529 aux=0.456848 imp_cv2=0.1467 load_cv2=5.1960 usage_frac=0.4196 topk_prob_mean=0.2790 ema_alpha_reverse=nan max_logit=12.7744
step:1202/1750 train_time:569874ms step_avg:474.10ms
[train step 1202] avg_loss=3.075900 main=2.630072 aux=0.445828 imp_cv2=0.2152 load_cv2=4.9988 usage_frac=0.4196 topk_prob_mean=0.3081 ema_alpha_reverse=nan max_logit=12.7744
step:1203/1750 train_time:570352ms step_avg:474.11ms
[train step 1203] avg_loss=3.250813 main=2.797480 aux=0.453332 imp_cv2=0.1375 load_cv2=5.1547 usage_frac=0.4152 topk_prob_mean=0.2790 ema_alpha_reverse=nan max_logit=12.7744
step:1204/1750 train_time:570820ms step_avg:474.10ms
[train step 1204] avg_loss=3.102373 main=2.659095 aux=0.443279 imp_cv2=0.2276 load_cv2=4.9534 usage_frac=0.4241 topk_prob_mean=0.3143 ema_alpha_reverse=nan max_logit=12.7744
step:1205/1750 train_time:571290ms step_avg:474.10ms
[train step 1205] avg_loss=3.925128 main=3.459677 aux=0.465451 imp_cv2=0.0906 load_cv2=5.3446 usage_frac=0.4286 topk_prob_mean=0.2531 ema_alpha_reverse=nan max_logit=12.7744
step:1206/1750 train_time:571750ms step_avg:474.09ms
[train step 1206] avg_loss=3.584224 main=3.122925 aux=0.461300 imp_cv2=0.0985 load_cv2=5.2841 usage_frac=0.4196 topk_prob_mean=0.2583 ema_alpha_reverse=nan max_logit=12.7744
step:1207/1750 train_time:572204ms step_avg:474.07ms
[train step 1207] avg_loss=3.437550 main=2.980788 aux=0.456762 imp_cv2=0.1070 load_cv2=5.2078 usage_frac=0.4241 topk_prob_mean=0.2591 ema_alpha_reverse=nan max_logit=12.7744
step:1208/1750 train_time:572663ms step_avg:474.06ms
[train step 1208] avg_loss=3.675337 main=3.221455 aux=0.453883 imp_cv2=0.1285 load_cv2=5.1649 usage_frac=0.4196 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=12.7744
step:1209/1750 train_time:573130ms step_avg:474.05ms
[train step 1209] avg_loss=3.538619 main=3.082409 aux=0.456210 imp_cv2=0.1061 load_cv2=5.2124 usage_frac=0.4241 topk_prob_mean=0.2615 ema_alpha_reverse=nan max_logit=12.7744
step:1210/1750 train_time:573594ms step_avg:474.04ms
[train step 1210] avg_loss=3.091318 main=2.648729 aux=0.442590 imp_cv2=0.1896 load_cv2=4.9849 usage_frac=0.4196 topk_prob_mean=0.2999 ema_alpha_reverse=nan max_logit=12.7744
step:1211/1750 train_time:574073ms step_avg:474.05ms
[train step 1211] avg_loss=4.039930 main=3.558022 aux=0.481909 imp_cv2=0.0953 load_cv2=5.5105 usage_frac=0.4196 topk_prob_mean=0.2282 ema_alpha_reverse=nan max_logit=12.7744
step:1212/1750 train_time:574544ms step_avg:474.05ms
[train step 1212] avg_loss=3.694318 main=3.238116 aux=0.456202 imp_cv2=0.1087 load_cv2=5.2221 usage_frac=0.4286 topk_prob_mean=0.2641 ema_alpha_reverse=nan max_logit=12.7744
step:1213/1750 train_time:575005ms step_avg:474.04ms
[train step 1213] avg_loss=3.253349 main=2.804559 aux=0.448791 imp_cv2=0.1703 load_cv2=5.0830 usage_frac=0.4241 topk_prob_mean=0.2897 ema_alpha_reverse=nan max_logit=12.7744
step:1214/1750 train_time:575469ms step_avg:474.03ms
[train step 1214] avg_loss=3.391743 main=2.943024 aux=0.448719 imp_cv2=0.1286 load_cv2=5.1118 usage_frac=0.4241 topk_prob_mean=0.2753 ema_alpha_reverse=nan max_logit=12.7744
step:1215/1750 train_time:575938ms step_avg:474.02ms
[train step 1215] avg_loss=3.451990 main=3.003727 aux=0.448262 imp_cv2=0.1281 load_cv2=5.1133 usage_frac=0.4286 topk_prob_mean=0.2732 ema_alpha_reverse=nan max_logit=12.7744
step:1216/1750 train_time:576393ms step_avg:474.01ms
[train step 1216] avg_loss=3.305389 main=2.865038 aux=0.440352 imp_cv2=0.1638 load_cv2=4.9820 usage_frac=0.4241 topk_prob_mean=0.2944 ema_alpha_reverse=nan max_logit=12.7744
step:1217/1750 train_time:576861ms step_avg:474.00ms
[train step 1217] avg_loss=3.203227 main=2.760944 aux=0.442282 imp_cv2=0.2126 load_cv2=4.9682 usage_frac=0.4196 topk_prob_mean=0.3074 ema_alpha_reverse=nan max_logit=12.7744
step:1218/1750 train_time:577326ms step_avg:473.99ms
[train step 1218] avg_loss=3.810161 main=3.354437 aux=0.455724 imp_cv2=0.1159 load_cv2=5.2093 usage_frac=0.4196 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=12.7744
step:1219/1750 train_time:577797ms step_avg:473.99ms
[train step 1219] avg_loss=3.544881 main=3.089136 aux=0.455745 imp_cv2=0.1149 load_cv2=5.2089 usage_frac=0.4241 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=12.7744
step:1220/1750 train_time:578249ms step_avg:473.97ms
[train step 1220] avg_loss=3.499166 main=3.045575 aux=0.453591 imp_cv2=0.1032 load_cv2=5.1818 usage_frac=0.4286 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=12.7744
step:1221/1750 train_time:578709ms step_avg:473.96ms
[train step 1221] avg_loss=3.498403 main=3.043484 aux=0.454919 imp_cv2=0.1306 load_cv2=5.1914 usage_frac=0.4241 topk_prob_mean=0.2733 ema_alpha_reverse=nan max_logit=12.7744
step:1222/1750 train_time:579176ms step_avg:473.96ms
[train step 1222] avg_loss=3.025472 main=2.585788 aux=0.439683 imp_cv2=0.2230 load_cv2=4.9276 usage_frac=0.4196 topk_prob_mean=0.3122 ema_alpha_reverse=nan max_logit=12.7744
step:1223/1750 train_time:579650ms step_avg:473.96ms
[train step 1223] avg_loss=3.650951 main=3.186275 aux=0.464676 imp_cv2=0.0817 load_cv2=5.3407 usage_frac=0.4196 topk_prob_mean=0.2441 ema_alpha_reverse=nan max_logit=12.7744
step:1224/1750 train_time:580106ms step_avg:473.94ms
[train step 1224] avg_loss=3.806713 main=3.336272 aux=0.470442 imp_cv2=0.0747 load_cv2=5.4109 usage_frac=0.4152 topk_prob_mean=0.2398 ema_alpha_reverse=nan max_logit=12.7744
step:1225/1750 train_time:580571ms step_avg:473.94ms
[train step 1225] avg_loss=3.107529 main=2.664465 aux=0.443064 imp_cv2=0.1900 load_cv2=4.9950 usage_frac=0.4241 topk_prob_mean=0.2997 ema_alpha_reverse=nan max_logit=12.7744
step:1226/1750 train_time:581032ms step_avg:473.92ms
[train step 1226] avg_loss=3.166861 main=2.726429 aux=0.440432 imp_cv2=0.2193 load_cv2=4.9396 usage_frac=0.4286 topk_prob_mean=0.3102 ema_alpha_reverse=nan max_logit=12.7744
step:1227/1750 train_time:581509ms step_avg:473.93ms
[train step 1227] avg_loss=4.667933 main=4.160690 aux=0.507243 imp_cv2=0.0472 load_cv2=5.8556 usage_frac=0.4152 topk_prob_mean=0.1941 ema_alpha_reverse=nan max_logit=12.7744
step:1228/1750 train_time:581965ms step_avg:473.91ms
[train step 1228] avg_loss=3.640797 main=3.188006 aux=0.452791 imp_cv2=0.1300 load_cv2=5.1652 usage_frac=0.4152 topk_prob_mean=0.2752 ema_alpha_reverse=nan max_logit=12.7744
step:1229/1750 train_time:582430ms step_avg:473.91ms
[train step 1229] avg_loss=3.605661 main=3.114382 aux=0.491280 imp_cv2=0.0504 load_cv2=5.6803 usage_frac=0.4107 topk_prob_mean=0.2168 ema_alpha_reverse=nan max_logit=11.9296
step:1230/1750 train_time:582898ms step_avg:473.90ms
[train step 1230] avg_loss=3.767935 main=3.295926 aux=0.472009 imp_cv2=0.0691 load_cv2=5.4457 usage_frac=0.4152 topk_prob_mean=0.2336 ema_alpha_reverse=nan max_logit=12.7744
step:1231/1750 train_time:583363ms step_avg:473.89ms
[train step 1231] avg_loss=3.761139 main=3.305264 aux=0.455875 imp_cv2=0.0937 load_cv2=5.2367 usage_frac=0.4196 topk_prob_mean=0.2554 ema_alpha_reverse=nan max_logit=12.7744
step:1232/1750 train_time:583826ms step_avg:473.88ms
[train step 1232] avg_loss=3.617565 main=3.152532 aux=0.465033 imp_cv2=0.0956 load_cv2=5.3560 usage_frac=0.4286 topk_prob_mean=0.2524 ema_alpha_reverse=nan max_logit=12.7744
step:1233/1750 train_time:584286ms step_avg:473.87ms
[train step 1233] avg_loss=3.543575 main=3.093000 aux=0.450575 imp_cv2=0.1093 load_cv2=5.1606 usage_frac=0.4241 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=12.7744
step:1234/1750 train_time:584753ms step_avg:473.87ms
[train step 1234] avg_loss=3.278018 main=2.837102 aux=0.440916 imp_cv2=0.1725 load_cv2=4.9955 usage_frac=0.4196 topk_prob_mean=0.2926 ema_alpha_reverse=nan max_logit=12.7744
step:1235/1750 train_time:585231ms step_avg:473.87ms
[train step 1235] avg_loss=3.193086 main=2.751153 aux=0.441933 imp_cv2=0.1957 load_cv2=4.9859 usage_frac=0.4241 topk_prob_mean=0.3018 ema_alpha_reverse=nan max_logit=12.7744
step:1236/1750 train_time:585693ms step_avg:473.86ms
[train step 1236] avg_loss=3.609366 main=3.155439 aux=0.453927 imp_cv2=0.1099 load_cv2=5.2021 usage_frac=0.4241 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=12.7744
step:1237/1750 train_time:586150ms step_avg:473.85ms
[train step 1237] avg_loss=3.310900 main=2.868255 aux=0.442645 imp_cv2=0.1669 load_cv2=5.0162 usage_frac=0.4286 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=12.7744
step:1238/1750 train_time:586618ms step_avg:473.84ms
[train step 1238] avg_loss=3.842809 main=3.379023 aux=0.463786 imp_cv2=0.0881 load_cv2=5.3355 usage_frac=0.4286 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=12.7744
step:1239/1750 train_time:587081ms step_avg:473.83ms
[train step 1239] avg_loss=3.418925 main=2.954000 aux=0.464925 imp_cv2=0.0939 load_cv2=5.3515 usage_frac=0.4241 topk_prob_mean=0.2519 ema_alpha_reverse=nan max_logit=12.7744
step:1240/1750 train_time:587545ms step_avg:473.83ms
[train step 1240] avg_loss=3.735983 main=3.268583 aux=0.467401 imp_cv2=0.0838 load_cv2=5.3713 usage_frac=0.4241 topk_prob_mean=0.2457 ema_alpha_reverse=nan max_logit=12.7744
step:1241/1750 train_time:588003ms step_avg:473.81ms
[train step 1241] avg_loss=4.525100 main=4.014802 aux=0.510299 imp_cv2=0.0691 load_cv2=5.8673 usage_frac=0.4196 topk_prob_mean=0.1969 ema_alpha_reverse=nan max_logit=12.7744
step:1242/1750 train_time:588462ms step_avg:473.80ms
[train step 1242] avg_loss=3.252092 main=2.803642 aux=0.448450 imp_cv2=0.1565 load_cv2=5.0934 usage_frac=0.4241 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=12.7744
step:1243/1750 train_time:588933ms step_avg:473.80ms
[train step 1243] avg_loss=3.961905 main=3.490118 aux=0.471787 imp_cv2=0.0873 load_cv2=5.4157 usage_frac=0.4241 topk_prob_mean=0.2389 ema_alpha_reverse=nan max_logit=12.7744
step:1244/1750 train_time:589407ms step_avg:473.80ms
[train step 1244] avg_loss=3.221366 main=2.774078 aux=0.447288 imp_cv2=0.2082 load_cv2=5.0354 usage_frac=0.4196 topk_prob_mean=0.3014 ema_alpha_reverse=nan max_logit=12.7744
step:1245/1750 train_time:589871ms step_avg:473.79ms
[train step 1245] avg_loss=3.707639 main=3.241923 aux=0.465716 imp_cv2=0.0913 load_cv2=5.3369 usage_frac=0.4107 topk_prob_mean=0.2472 ema_alpha_reverse=nan max_logit=12.7744
step:1246/1750 train_time:590336ms step_avg:473.78ms
[train step 1246] avg_loss=3.740436 main=3.291369 aux=0.449067 imp_cv2=0.1529 load_cv2=5.1003 usage_frac=0.4241 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=12.7744
step:1247/1750 train_time:590990ms step_avg:473.93ms
[train step 1247] avg_loss=3.546538 main=3.079655 aux=0.466883 imp_cv2=0.0881 load_cv2=5.3737 usage_frac=0.4241 topk_prob_mean=0.2477 ema_alpha_reverse=nan max_logit=12.7744
step:1248/1750 train_time:591460ms step_avg:473.93ms
[train step 1248] avg_loss=4.595773 main=4.070275 aux=0.525499 imp_cv2=0.0664 load_cv2=6.0454 usage_frac=0.3884 topk_prob_mean=0.1815 ema_alpha_reverse=nan max_logit=10.8091
step:1249/1750 train_time:591911ms step_avg:473.91ms
[train step 1249] avg_loss=3.907743 main=3.425650 aux=0.482094 imp_cv2=0.0626 load_cv2=5.5599 usage_frac=0.4241 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=12.7744
step:1250/1750 train_time:592381ms step_avg:473.90ms
Running validation...
step:1250/1750 val_loss:3.068704 train_time:592393ms step_avg:473.91ms
[train step 1250] avg_loss=3.310478 main=2.861315 aux=0.449164 imp_cv2=0.1487 load_cv2=5.1088 usage_frac=0.4241 topk_prob_mean=0.2820 ema_alpha_reverse=nan max_logit=12.7744
step:1251/1750 train_time:592859ms step_avg:473.91ms
[train step 1251] avg_loss=3.791152 main=3.328421 aux=0.462731 imp_cv2=0.0939 load_cv2=5.3171 usage_frac=0.4241 topk_prob_mean=0.2540 ema_alpha_reverse=nan max_logit=12.7744
step:1252/1750 train_time:593308ms step_avg:473.89ms
[train step 1252] avg_loss=3.657861 main=3.200489 aux=0.457371 imp_cv2=0.1133 load_cv2=5.2327 usage_frac=0.4196 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=12.7744
step:1253/1750 train_time:593767ms step_avg:473.88ms
[train step 1253] avg_loss=3.767739 main=3.295379 aux=0.472360 imp_cv2=0.0753 load_cv2=5.4406 usage_frac=0.4241 topk_prob_mean=0.2370 ema_alpha_reverse=nan max_logit=12.7744
step:1254/1750 train_time:594230ms step_avg:473.87ms
[train step 1254] avg_loss=4.134729 main=3.650532 aux=0.484197 imp_cv2=0.0590 load_cv2=5.5892 usage_frac=0.4241 topk_prob_mean=0.2206 ema_alpha_reverse=nan max_logit=12.7744
step:1255/1750 train_time:594698ms step_avg:473.86ms
[train step 1255] avg_loss=3.397145 main=2.945949 aux=0.451196 imp_cv2=0.1761 load_cv2=5.1085 usage_frac=0.4241 topk_prob_mean=0.2908 ema_alpha_reverse=nan max_logit=12.7744
step:1256/1750 train_time:595171ms step_avg:473.86ms
[train step 1256] avg_loss=4.484970 main=3.972102 aux=0.512867 imp_cv2=0.0597 load_cv2=5.9009 usage_frac=0.3884 topk_prob_mean=0.1838 ema_alpha_reverse=nan max_logit=9.8264
step:1257/1750 train_time:595626ms step_avg:473.85ms
[train step 1257] avg_loss=3.333406 main=2.883050 aux=0.450356 imp_cv2=0.1818 load_cv2=5.0975 usage_frac=0.4241 topk_prob_mean=0.2940 ema_alpha_reverse=nan max_logit=12.7744
step:1258/1750 train_time:596087ms step_avg:473.84ms
[train step 1258] avg_loss=3.522083 main=3.070658 aux=0.451425 imp_cv2=0.1458 load_cv2=5.1347 usage_frac=0.4241 topk_prob_mean=0.2808 ema_alpha_reverse=nan max_logit=12.7744
step:1259/1750 train_time:596546ms step_avg:473.83ms
[train step 1259] avg_loss=3.382746 main=2.933270 aux=0.449476 imp_cv2=0.1787 load_cv2=5.0867 usage_frac=0.4286 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=12.7744
step:1260/1750 train_time:597009ms step_avg:473.82ms
[train step 1260] avg_loss=3.284133 main=2.819130 aux=0.465003 imp_cv2=0.1065 load_cv2=5.3377 usage_frac=0.4241 topk_prob_mean=0.2574 ema_alpha_reverse=nan max_logit=12.7744
step:1261/1750 train_time:597478ms step_avg:473.81ms
[train step 1261] avg_loss=3.933363 main=3.465310 aux=0.468053 imp_cv2=0.1044 load_cv2=5.3663 usage_frac=0.4286 topk_prob_mean=0.2561 ema_alpha_reverse=nan max_logit=12.7744
step:1262/1750 train_time:597944ms step_avg:473.81ms
[train step 1262] avg_loss=3.149175 main=2.700911 aux=0.448265 imp_cv2=0.2248 load_cv2=5.0293 usage_frac=0.4241 topk_prob_mean=0.3086 ema_alpha_reverse=nan max_logit=12.7744
step:1263/1750 train_time:598409ms step_avg:473.80ms
[train step 1263] avg_loss=3.371022 main=2.905330 aux=0.465692 imp_cv2=0.1006 load_cv2=5.3543 usage_frac=0.4241 topk_prob_mean=0.2559 ema_alpha_reverse=nan max_logit=12.7744
step:1264/1750 train_time:598877ms step_avg:473.80ms
[train step 1264] avg_loss=4.207955 main=3.668622 aux=0.539334 imp_cv2=0.0815 load_cv2=6.1901 usage_frac=0.3973 topk_prob_mean=0.1825 ema_alpha_reverse=nan max_logit=10.8091
step:1265/1750 train_time:599338ms step_avg:473.78ms
[train step 1265] avg_loss=3.330683 main=2.878477 aux=0.452206 imp_cv2=0.1399 load_cv2=5.1593 usage_frac=0.4241 topk_prob_mean=0.2802 ema_alpha_reverse=nan max_logit=12.7744
step:1266/1750 train_time:599798ms step_avg:473.77ms
[train step 1266] avg_loss=3.436483 main=2.987258 aux=0.449225 imp_cv2=0.1420 load_cv2=5.1173 usage_frac=0.4196 topk_prob_mean=0.2796 ema_alpha_reverse=nan max_logit=12.7744
step:1267/1750 train_time:600259ms step_avg:473.76ms
[train step 1267] avg_loss=3.513962 main=3.046378 aux=0.467584 imp_cv2=0.0817 load_cv2=5.3846 usage_frac=0.4286 topk_prob_mean=0.2428 ema_alpha_reverse=nan max_logit=12.7744
step:1268/1750 train_time:600709ms step_avg:473.75ms
[train step 1268] avg_loss=3.535774 main=3.077589 aux=0.458185 imp_cv2=0.1090 load_cv2=5.2352 usage_frac=0.4241 topk_prob_mean=0.2594 ema_alpha_reverse=nan max_logit=12.7744
step:1269/1750 train_time:601354ms step_avg:473.88ms
[train step 1269] avg_loss=3.498394 main=3.040398 aux=0.457996 imp_cv2=0.1128 load_cv2=5.2452 usage_frac=0.4241 topk_prob_mean=0.2638 ema_alpha_reverse=nan max_logit=12.7744
step:1270/1750 train_time:601817ms step_avg:473.87ms
[train step 1270] avg_loss=3.549613 main=3.096804 aux=0.452809 imp_cv2=0.1207 load_cv2=5.1806 usage_frac=0.4241 topk_prob_mean=0.2699 ema_alpha_reverse=nan max_logit=12.7744
step:1271/1750 train_time:602281ms step_avg:473.86ms
[train step 1271] avg_loss=3.320970 main=2.877423 aux=0.443547 imp_cv2=0.1809 load_cv2=5.0209 usage_frac=0.4241 topk_prob_mean=0.2936 ema_alpha_reverse=nan max_logit=12.7744
step:1272/1750 train_time:602746ms step_avg:473.86ms
[train step 1272] avg_loss=3.720824 main=3.253118 aux=0.467705 imp_cv2=0.0824 load_cv2=5.3889 usage_frac=0.4241 topk_prob_mean=0.2419 ema_alpha_reverse=nan max_logit=12.7744
step:1273/1750 train_time:603203ms step_avg:473.84ms
[train step 1273] avg_loss=3.153077 main=2.718585 aux=0.434492 imp_cv2=0.1882 load_cv2=4.8985 usage_frac=0.4241 topk_prob_mean=0.3031 ema_alpha_reverse=nan max_logit=12.7744
step:1274/1750 train_time:603664ms step_avg:473.83ms
[train step 1274] avg_loss=3.127356 main=2.686491 aux=0.440865 imp_cv2=0.2153 load_cv2=4.9582 usage_frac=0.4196 topk_prob_mean=0.3086 ema_alpha_reverse=nan max_logit=12.7744
step:1275/1750 train_time:604128ms step_avg:473.83ms
[train step 1275] avg_loss=3.101547 main=2.664658 aux=0.436889 imp_cv2=0.1832 load_cv2=4.9303 usage_frac=0.4241 topk_prob_mean=0.3008 ema_alpha_reverse=nan max_logit=12.7744
step:1276/1750 train_time:604584ms step_avg:473.81ms
[train step 1276] avg_loss=3.102719 main=2.661156 aux=0.441563 imp_cv2=0.2046 load_cv2=4.9717 usage_frac=0.4286 topk_prob_mean=0.3058 ema_alpha_reverse=nan max_logit=12.7744
step:1277/1750 train_time:605062ms step_avg:473.82ms
[train step 1277] avg_loss=3.820099 main=3.344908 aux=0.475191 imp_cv2=0.0730 load_cv2=5.4792 usage_frac=0.4286 topk_prob_mean=0.2359 ema_alpha_reverse=nan max_logit=12.7744
step:1278/1750 train_time:605706ms step_avg:473.95ms
[train step 1278] avg_loss=3.224124 main=2.772765 aux=0.451359 imp_cv2=0.1573 load_cv2=5.1270 usage_frac=0.4241 topk_prob_mean=0.2847 ema_alpha_reverse=nan max_logit=12.7744
step:1279/1750 train_time:606168ms step_avg:473.94ms
[train step 1279] avg_loss=3.725082 main=3.226704 aux=0.498378 imp_cv2=0.0582 load_cv2=5.7736 usage_frac=0.4241 topk_prob_mean=0.2127 ema_alpha_reverse=nan max_logit=12.7744
step:1280/1750 train_time:606624ms step_avg:473.93ms
[train step 1280] avg_loss=3.685549 main=3.206829 aux=0.478720 imp_cv2=0.0789 load_cv2=5.5093 usage_frac=0.4241 topk_prob_mean=0.2381 ema_alpha_reverse=nan max_logit=12.7744
step:1281/1750 train_time:607082ms step_avg:473.91ms
[train step 1281] avg_loss=3.966643 main=3.485373 aux=0.481270 imp_cv2=0.0640 load_cv2=5.5574 usage_frac=0.4241 topk_prob_mean=0.2275 ema_alpha_reverse=nan max_logit=12.7744
step:1282/1750 train_time:607528ms step_avg:473.89ms
[train step 1282] avg_loss=4.081795 main=3.588465 aux=0.493330 imp_cv2=0.0920 load_cv2=5.6615 usage_frac=0.4241 topk_prob_mean=0.2202 ema_alpha_reverse=nan max_logit=12.7744
step:1283/1750 train_time:607981ms step_avg:473.87ms
[train step 1283] avg_loss=3.365768 main=2.903569 aux=0.462200 imp_cv2=0.1141 load_cv2=5.2866 usage_frac=0.4241 topk_prob_mean=0.2636 ema_alpha_reverse=nan max_logit=12.7744
step:1284/1750 train_time:608432ms step_avg:473.86ms
[train step 1284] avg_loss=3.264142 main=2.806452 aux=0.457690 imp_cv2=0.1315 load_cv2=5.2259 usage_frac=0.4241 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=12.7744
step:1285/1750 train_time:608898ms step_avg:473.85ms
[train step 1285] avg_loss=3.497665 main=3.044104 aux=0.453562 imp_cv2=0.1486 load_cv2=5.1618 usage_frac=0.4241 topk_prob_mean=0.2819 ema_alpha_reverse=nan max_logit=12.7744
step:1286/1750 train_time:609362ms step_avg:473.84ms
[train step 1286] avg_loss=3.578856 main=3.116947 aux=0.461909 imp_cv2=0.1211 load_cv2=5.2844 usage_frac=0.4196 topk_prob_mean=0.2665 ema_alpha_reverse=nan max_logit=12.7744
step:1287/1750 train_time:609819ms step_avg:473.83ms
[train step 1287] avg_loss=5.723197 main=5.203709 aux=0.519488 imp_cv2=0.0734 load_cv2=5.9879 usage_frac=0.4196 topk_prob_mean=0.1947 ema_alpha_reverse=nan max_logit=12.7744
step:1288/1750 train_time:610277ms step_avg:473.82ms
[train step 1288] avg_loss=5.180817 main=4.694521 aux=0.486296 imp_cv2=0.0777 load_cv2=5.6008 usage_frac=0.4241 topk_prob_mean=0.2250 ema_alpha_reverse=nan max_logit=12.7744
step:1289/1750 train_time:610744ms step_avg:473.81ms
[train step 1289] avg_loss=3.527084 main=3.048359 aux=0.478725 imp_cv2=0.0656 load_cv2=5.5263 usage_frac=0.4286 topk_prob_mean=0.2295 ema_alpha_reverse=nan max_logit=12.7744
step:1290/1750 train_time:611204ms step_avg:473.80ms
[train step 1290] avg_loss=3.462094 main=3.003000 aux=0.459094 imp_cv2=0.0954 load_cv2=5.2613 usage_frac=0.4286 topk_prob_mean=0.2546 ema_alpha_reverse=nan max_logit=12.7744
step:1291/1750 train_time:611670ms step_avg:473.80ms
[train step 1291] avg_loss=3.083761 main=2.641493 aux=0.442268 imp_cv2=0.1959 load_cv2=4.9914 usage_frac=0.4241 topk_prob_mean=0.3033 ema_alpha_reverse=nan max_logit=12.7744
step:1292/1750 train_time:612132ms step_avg:473.79ms
[train step 1292] avg_loss=3.461064 main=3.018934 aux=0.442130 imp_cv2=0.1642 load_cv2=5.0109 usage_frac=0.4286 topk_prob_mean=0.2925 ema_alpha_reverse=nan max_logit=12.7744
step:1293/1750 train_time:612596ms step_avg:473.78ms
[train step 1293] avg_loss=3.384083 main=2.942368 aux=0.441715 imp_cv2=0.1715 load_cv2=5.0024 usage_frac=0.4241 topk_prob_mean=0.2946 ema_alpha_reverse=nan max_logit=12.7744
step:1294/1750 train_time:613065ms step_avg:473.77ms
[train step 1294] avg_loss=3.153504 main=2.712571 aux=0.440933 imp_cv2=0.2344 load_cv2=4.9365 usage_frac=0.4241 topk_prob_mean=0.3161 ema_alpha_reverse=nan max_logit=12.7744
step:1295/1750 train_time:613537ms step_avg:473.77ms
[train step 1295] avg_loss=3.764796 main=3.298443 aux=0.466354 imp_cv2=0.0813 load_cv2=5.3761 usage_frac=0.4286 topk_prob_mean=0.2435 ema_alpha_reverse=nan max_logit=12.7744
step:1296/1750 train_time:614011ms step_avg:473.77ms
[train step 1296] avg_loss=3.242330 main=2.794964 aux=0.447366 imp_cv2=0.1415 load_cv2=5.0970 usage_frac=0.4241 topk_prob_mean=0.2821 ema_alpha_reverse=nan max_logit=12.7744
step:1297/1750 train_time:614472ms step_avg:473.76ms
[train step 1297] avg_loss=3.558666 main=3.111581 aux=0.447085 imp_cv2=0.1366 load_cv2=5.0955 usage_frac=0.4286 topk_prob_mean=0.2793 ema_alpha_reverse=nan max_logit=12.7744
step:1298/1750 train_time:614935ms step_avg:473.76ms
[train step 1298] avg_loss=4.005753 main=3.541472 aux=0.464280 imp_cv2=0.0862 load_cv2=5.3469 usage_frac=0.4241 topk_prob_mean=0.2467 ema_alpha_reverse=nan max_logit=12.7744
step:1299/1750 train_time:615389ms step_avg:473.74ms
[train step 1299] avg_loss=3.610619 main=3.142389 aux=0.468229 imp_cv2=0.0765 load_cv2=5.3992 usage_frac=0.4286 topk_prob_mean=0.2400 ema_alpha_reverse=nan max_logit=12.7744
step:1300/1750 train_time:615854ms step_avg:473.73ms
Running validation...
step:1300/1750 val_loss:3.031437 train_time:615866ms step_avg:473.74ms
[train step 1300] avg_loss=3.582074 main=3.132703 aux=0.449371 imp_cv2=0.1310 load_cv2=5.1290 usage_frac=0.4241 topk_prob_mean=0.2744 ema_alpha_reverse=nan max_logit=12.7744
step:1301/1750 train_time:616325ms step_avg:473.73ms
[train step 1301] avg_loss=4.533957 main=4.057343 aux=0.476614 imp_cv2=0.0688 load_cv2=5.4895 usage_frac=0.4241 topk_prob_mean=0.2249 ema_alpha_reverse=nan max_logit=12.7744
step:1302/1750 train_time:616778ms step_avg:473.72ms
[train step 1302] avg_loss=3.707177 main=3.244248 aux=0.462929 imp_cv2=0.0810 load_cv2=5.3225 usage_frac=0.4241 topk_prob_mean=0.2449 ema_alpha_reverse=nan max_logit=12.7744
step:1303/1750 train_time:617243ms step_avg:473.71ms
[train step 1303] avg_loss=2.900308 main=2.457860 aux=0.442447 imp_cv2=0.2376 load_cv2=4.9557 usage_frac=0.4196 topk_prob_mean=0.3154 ema_alpha_reverse=nan max_logit=12.7744
step:1304/1750 train_time:617720ms step_avg:473.71ms
[train step 1304] avg_loss=4.072360 main=3.598430 aux=0.473930 imp_cv2=0.0696 load_cv2=5.4688 usage_frac=0.4241 topk_prob_mean=0.2315 ema_alpha_reverse=nan max_logit=12.7744
step:1305/1750 train_time:618181ms step_avg:473.70ms
[train step 1305] avg_loss=4.001592 main=3.536759 aux=0.464833 imp_cv2=0.0878 load_cv2=5.3407 usage_frac=0.4241 topk_prob_mean=0.2489 ema_alpha_reverse=nan max_logit=12.7744
step:1306/1750 train_time:618636ms step_avg:473.69ms
[train step 1306] avg_loss=3.206355 main=2.758504 aux=0.447851 imp_cv2=0.2212 load_cv2=5.0342 usage_frac=0.4241 topk_prob_mean=0.3059 ema_alpha_reverse=nan max_logit=12.7744
step:1307/1750 train_time:619115ms step_avg:473.69ms
[train step 1307] avg_loss=3.793956 main=3.316116 aux=0.477839 imp_cv2=0.0757 load_cv2=5.5122 usage_frac=0.4241 topk_prob_mean=0.2381 ema_alpha_reverse=nan max_logit=12.7744
step:1308/1750 train_time:619585ms step_avg:473.69ms
[train step 1308] avg_loss=3.749787 main=3.287690 aux=0.462097 imp_cv2=0.0968 load_cv2=5.3055 usage_frac=0.4286 topk_prob_mean=0.2555 ema_alpha_reverse=nan max_logit=12.7744
step:1309/1750 train_time:620043ms step_avg:473.68ms
[train step 1309] avg_loss=3.064822 main=2.618882 aux=0.445940 imp_cv2=0.1753 load_cv2=5.0387 usage_frac=0.4241 topk_prob_mean=0.2937 ema_alpha_reverse=nan max_logit=12.7744
step:1310/1750 train_time:620503ms step_avg:473.67ms
[train step 1310] avg_loss=3.624095 main=3.163354 aux=0.460742 imp_cv2=0.1045 load_cv2=5.2772 usage_frac=0.4241 topk_prob_mean=0.2599 ema_alpha_reverse=nan max_logit=12.7744
step:1311/1750 train_time:620960ms step_avg:473.65ms
[train step 1311] avg_loss=3.759731 main=3.270366 aux=0.489365 imp_cv2=0.0718 load_cv2=5.6394 usage_frac=0.4241 topk_prob_mean=0.2252 ema_alpha_reverse=nan max_logit=12.7744
step:1312/1750 train_time:621412ms step_avg:473.64ms
[train step 1312] avg_loss=3.212385 main=2.755579 aux=0.456806 imp_cv2=0.1264 load_cv2=5.2038 usage_frac=0.4241 topk_prob_mean=0.2710 ema_alpha_reverse=nan max_logit=12.7744
step:1313/1750 train_time:621874ms step_avg:473.63ms
[train step 1313] avg_loss=3.260085 main=2.801373 aux=0.458712 imp_cv2=0.1268 load_cv2=5.2387 usage_frac=0.4196 topk_prob_mean=0.2715 ema_alpha_reverse=nan max_logit=12.7744
step:1314/1750 train_time:622328ms step_avg:473.61ms
[train step 1314] avg_loss=3.239623 main=2.780066 aux=0.459558 imp_cv2=0.1576 load_cv2=5.2265 usage_frac=0.4286 topk_prob_mean=0.2820 ema_alpha_reverse=nan max_logit=12.7744
step:1315/1750 train_time:622788ms step_avg:473.60ms
[train step 1315] avg_loss=3.485032 main=2.998731 aux=0.486301 imp_cv2=0.0658 load_cv2=5.6238 usage_frac=0.4286 topk_prob_mean=0.2288 ema_alpha_reverse=nan max_logit=12.7744
step:1316/1750 train_time:623241ms step_avg:473.59ms
[train step 1316] avg_loss=3.312442 main=2.844976 aux=0.467466 imp_cv2=0.1032 load_cv2=5.3689 usage_frac=0.4241 topk_prob_mean=0.2581 ema_alpha_reverse=nan max_logit=12.7744
step:1317/1750 train_time:623693ms step_avg:473.57ms
[train step 1317] avg_loss=3.080012 main=2.622486 aux=0.457526 imp_cv2=0.1604 load_cv2=5.1988 usage_frac=0.4286 topk_prob_mean=0.2835 ema_alpha_reverse=nan max_logit=12.7744
step:1318/1750 train_time:624152ms step_avg:473.56ms
[train step 1318] avg_loss=3.595642 main=3.124291 aux=0.471350 imp_cv2=0.0901 load_cv2=5.4153 usage_frac=0.4286 topk_prob_mean=0.2491 ema_alpha_reverse=nan max_logit=12.7744
step:1319/1750 train_time:624611ms step_avg:473.55ms
[train step 1319] avg_loss=3.361625 main=2.888146 aux=0.473479 imp_cv2=0.0950 load_cv2=5.4442 usage_frac=0.4286 topk_prob_mean=0.2481 ema_alpha_reverse=nan max_logit=12.7744
step:1320/1750 train_time:625064ms step_avg:473.53ms
[train step 1320] avg_loss=3.902076 main=3.413205 aux=0.488871 imp_cv2=0.0694 load_cv2=5.6321 usage_frac=0.4196 topk_prob_mean=0.2243 ema_alpha_reverse=nan max_logit=12.7744
step:1321/1750 train_time:625524ms step_avg:473.52ms
[train step 1321] avg_loss=3.856670 main=3.364649 aux=0.492021 imp_cv2=0.0680 load_cv2=5.6816 usage_frac=0.4241 topk_prob_mean=0.2256 ema_alpha_reverse=nan max_logit=12.7744
step:1322/1750 train_time:625983ms step_avg:473.51ms
[train step 1322] avg_loss=3.714877 main=3.256322 aux=0.458556 imp_cv2=0.1371 load_cv2=5.2254 usage_frac=0.4241 topk_prob_mean=0.2778 ema_alpha_reverse=nan max_logit=12.7744
step:1323/1750 train_time:626457ms step_avg:473.51ms
[train step 1323] avg_loss=4.257866 main=3.758242 aux=0.499624 imp_cv2=0.0639 load_cv2=5.7647 usage_frac=0.4196 topk_prob_mean=0.2070 ema_alpha_reverse=nan max_logit=12.7744
step:1324/1750 train_time:626911ms step_avg:473.50ms
[train step 1324] avg_loss=3.293663 main=2.836096 aux=0.457567 imp_cv2=0.1842 load_cv2=5.1770 usage_frac=0.4286 topk_prob_mean=0.2925 ema_alpha_reverse=nan max_logit=12.7744
step:1325/1750 train_time:627375ms step_avg:473.49ms
[train step 1325] avg_loss=3.368812 main=2.904442 aux=0.464370 imp_cv2=0.1390 load_cv2=5.3085 usage_frac=0.4241 topk_prob_mean=0.2729 ema_alpha_reverse=nan max_logit=12.7744
step:1326/1750 train_time:628061ms step_avg:473.65ms
[train step 1326] avg_loss=3.139362 main=2.668593 aux=0.470769 imp_cv2=0.1003 load_cv2=5.4066 usage_frac=0.4196 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=12.7744
step:1327/1750 train_time:628520ms step_avg:473.64ms
[train step 1327] avg_loss=3.541497 main=3.062785 aux=0.478711 imp_cv2=0.0806 load_cv2=5.5082 usage_frac=0.4241 topk_prob_mean=0.2384 ema_alpha_reverse=nan max_logit=12.7744
step:1328/1750 train_time:628974ms step_avg:473.63ms
[train step 1328] avg_loss=3.625037 main=3.158005 aux=0.467032 imp_cv2=0.0858 load_cv2=5.3639 usage_frac=0.4196 topk_prob_mean=0.2473 ema_alpha_reverse=nan max_logit=12.7744
step:1329/1750 train_time:629432ms step_avg:473.61ms
[train step 1329] avg_loss=3.267226 main=2.817978 aux=0.449248 imp_cv2=0.1811 load_cv2=5.0804 usage_frac=0.4241 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=12.7744
step:1330/1750 train_time:629910ms step_avg:473.62ms
[train step 1330] avg_loss=3.431582 main=2.971088 aux=0.460494 imp_cv2=0.1082 load_cv2=5.2690 usage_frac=0.4241 topk_prob_mean=0.2624 ema_alpha_reverse=nan max_logit=12.7744
step:1331/1750 train_time:630374ms step_avg:473.61ms
[train step 1331] avg_loss=4.009006 main=3.524566 aux=0.484440 imp_cv2=0.0702 load_cv2=5.5884 usage_frac=0.4241 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=12.7744
step:1332/1750 train_time:630842ms step_avg:473.61ms
[train step 1332] avg_loss=3.291940 main=2.835546 aux=0.456394 imp_cv2=0.1444 load_cv2=5.1939 usage_frac=0.4241 topk_prob_mean=0.2784 ema_alpha_reverse=nan max_logit=12.7744
step:1333/1750 train_time:631315ms step_avg:473.60ms
[train step 1333] avg_loss=3.579009 main=3.116134 aux=0.462875 imp_cv2=0.1165 load_cv2=5.2913 usage_frac=0.4241 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=12.7744
step:1334/1750 train_time:631765ms step_avg:473.59ms
[train step 1334] avg_loss=3.199738 main=2.746964 aux=0.452774 imp_cv2=0.1750 load_cv2=5.1305 usage_frac=0.4241 topk_prob_mean=0.2919 ema_alpha_reverse=nan max_logit=12.7744
step:1335/1750 train_time:632232ms step_avg:473.58ms
[train step 1335] avg_loss=4.141865 main=3.660925 aux=0.480940 imp_cv2=0.1134 load_cv2=5.5017 usage_frac=0.4241 topk_prob_mean=0.2411 ema_alpha_reverse=nan max_logit=12.7744
step:1336/1750 train_time:632687ms step_avg:473.57ms
[train step 1336] avg_loss=3.231765 main=2.759875 aux=0.471890 imp_cv2=0.0803 load_cv2=5.4257 usage_frac=0.4286 topk_prob_mean=0.2429 ema_alpha_reverse=nan max_logit=12.7744
step:1337/1750 train_time:633147ms step_avg:473.56ms
[train step 1337] avg_loss=3.260402 main=2.803874 aux=0.456529 imp_cv2=0.1741 load_cv2=5.1729 usage_frac=0.4241 topk_prob_mean=0.2887 ema_alpha_reverse=nan max_logit=12.7744
step:1338/1750 train_time:633610ms step_avg:473.55ms
[train step 1338] avg_loss=3.379137 main=2.906108 aux=0.473029 imp_cv2=0.1004 load_cv2=5.4338 usage_frac=0.4196 topk_prob_mean=0.2516 ema_alpha_reverse=nan max_logit=12.7744
step:1339/1750 train_time:634061ms step_avg:473.53ms
[train step 1339] avg_loss=3.180128 main=2.720136 aux=0.459991 imp_cv2=0.1733 load_cv2=5.2169 usage_frac=0.4241 topk_prob_mean=0.2876 ema_alpha_reverse=nan max_logit=12.7744
step:1340/1750 train_time:634520ms step_avg:473.52ms
[train step 1340] avg_loss=3.801941 main=3.296053 aux=0.505888 imp_cv2=0.0605 load_cv2=5.8527 usage_frac=0.4196 topk_prob_mean=0.2099 ema_alpha_reverse=nan max_logit=12.7744
step:1341/1750 train_time:634986ms step_avg:473.52ms
[train step 1341] avg_loss=3.668321 main=3.197252 aux=0.471069 imp_cv2=0.0906 load_cv2=5.4138 usage_frac=0.4241 topk_prob_mean=0.2490 ema_alpha_reverse=nan max_logit=12.7744
step:1342/1750 train_time:635439ms step_avg:473.50ms
[train step 1342] avg_loss=3.068859 main=2.619176 aux=0.449683 imp_cv2=0.2312 load_cv2=5.0421 usage_frac=0.4152 topk_prob_mean=0.3068 ema_alpha_reverse=nan max_logit=12.7744
step:1343/1750 train_time:635904ms step_avg:473.49ms
[train step 1343] avg_loss=3.089043 main=2.638169 aux=0.450874 imp_cv2=0.1913 load_cv2=5.0937 usage_frac=0.4241 topk_prob_mean=0.2944 ema_alpha_reverse=nan max_logit=12.7744
step:1344/1750 train_time:636366ms step_avg:473.49ms
[train step 1344] avg_loss=3.182511 main=2.725460 aux=0.457051 imp_cv2=0.1574 load_cv2=5.2056 usage_frac=0.4241 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=12.7744
step:1345/1750 train_time:636825ms step_avg:473.48ms
[train step 1345] avg_loss=3.652205 main=3.180038 aux=0.472168 imp_cv2=0.0829 load_cv2=5.4365 usage_frac=0.4241 topk_prob_mean=0.2411 ema_alpha_reverse=nan max_logit=12.7744
step:1346/1750 train_time:637280ms step_avg:473.46ms
[train step 1346] avg_loss=3.836436 main=3.369245 aux=0.467191 imp_cv2=0.0965 load_cv2=5.3607 usage_frac=0.4196 topk_prob_mean=0.2494 ema_alpha_reverse=nan max_logit=12.7744
step:1347/1750 train_time:637734ms step_avg:473.45ms
[train step 1347] avg_loss=2.976629 main=2.522567 aux=0.454062 imp_cv2=0.1935 load_cv2=5.1306 usage_frac=0.4196 topk_prob_mean=0.2944 ema_alpha_reverse=nan max_logit=12.7744
step:1348/1750 train_time:638197ms step_avg:473.44ms
[train step 1348] avg_loss=3.767224 main=3.301098 aux=0.466126 imp_cv2=0.0968 load_cv2=5.3569 usage_frac=0.4196 topk_prob_mean=0.2515 ema_alpha_reverse=nan max_logit=12.7744
step:1349/1750 train_time:638659ms step_avg:473.43ms
[train step 1349] avg_loss=3.636605 main=3.146199 aux=0.490406 imp_cv2=0.0579 load_cv2=5.6784 usage_frac=0.4196 topk_prob_mean=0.2062 ema_alpha_reverse=nan max_logit=12.7744
step:1350/1750 train_time:639109ms step_avg:473.41ms
Running validation...
step:1350/1750 val_loss:3.002814 train_time:639121ms step_avg:473.42ms
[train step 1350] avg_loss=3.251696 main=2.806643 aux=0.445052 imp_cv2=0.1672 load_cv2=5.0376 usage_frac=0.4152 topk_prob_mean=0.2918 ema_alpha_reverse=nan max_logit=12.7744
step:1351/1750 train_time:639572ms step_avg:473.41ms
[train step 1351] avg_loss=3.869483 main=3.403090 aux=0.466393 imp_cv2=0.0877 load_cv2=5.3496 usage_frac=0.4196 topk_prob_mean=0.2447 ema_alpha_reverse=nan max_logit=12.7744
step:1352/1750 train_time:640034ms step_avg:473.40ms
[train step 1352] avg_loss=3.407814 main=2.940965 aux=0.466849 imp_cv2=0.1118 load_cv2=5.3568 usage_frac=0.4196 topk_prob_mean=0.2584 ema_alpha_reverse=nan max_logit=12.7744
step:1353/1750 train_time:640488ms step_avg:473.38ms
[train step 1353] avg_loss=3.638236 main=3.168346 aux=0.469890 imp_cv2=0.1084 load_cv2=5.3999 usage_frac=0.4241 topk_prob_mean=0.2567 ema_alpha_reverse=nan max_logit=12.7744
step:1354/1750 train_time:640942ms step_avg:473.37ms
[train step 1354] avg_loss=2.848220 main=2.401320 aux=0.446901 imp_cv2=0.2391 load_cv2=5.0042 usage_frac=0.4196 topk_prob_mean=0.3129 ema_alpha_reverse=nan max_logit=12.7744
step:1355/1750 train_time:641395ms step_avg:473.35ms
[train step 1355] avg_loss=3.026542 main=2.576176 aux=0.450366 imp_cv2=0.1942 load_cv2=5.0886 usage_frac=0.4241 topk_prob_mean=0.2970 ema_alpha_reverse=nan max_logit=12.7744
step:1356/1750 train_time:641867ms step_avg:473.35ms
[train step 1356] avg_loss=3.367713 main=2.894307 aux=0.473406 imp_cv2=0.0814 load_cv2=5.4482 usage_frac=0.4196 topk_prob_mean=0.2393 ema_alpha_reverse=nan max_logit=12.7744
step:1357/1750 train_time:642327ms step_avg:473.34ms
[train step 1357] avg_loss=4.151650 main=3.622545 aux=0.529105 imp_cv2=0.0529 load_cv2=6.1055 usage_frac=0.4196 topk_prob_mean=0.1804 ema_alpha_reverse=nan max_logit=12.7744
step:1358/1750 train_time:642782ms step_avg:473.33ms
[train step 1358] avg_loss=3.384764 main=2.931869 aux=0.452895 imp_cv2=0.1789 load_cv2=5.1269 usage_frac=0.4196 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=12.7744
step:1359/1750 train_time:643256ms step_avg:473.33ms
[train step 1359] avg_loss=3.989809 main=3.519344 aux=0.470465 imp_cv2=0.0909 load_cv2=5.4035 usage_frac=0.4241 topk_prob_mean=0.2463 ema_alpha_reverse=nan max_logit=12.7744
step:1360/1750 train_time:643724ms step_avg:473.33ms
[train step 1360] avg_loss=3.442753 main=2.990058 aux=0.452695 imp_cv2=0.1500 load_cv2=5.1458 usage_frac=0.4196 topk_prob_mean=0.2813 ema_alpha_reverse=nan max_logit=12.7744
step:1361/1750 train_time:644188ms step_avg:473.32ms
[train step 1361] avg_loss=3.445281 main=2.990627 aux=0.454654 imp_cv2=0.1396 load_cv2=5.1885 usage_frac=0.4196 topk_prob_mean=0.2767 ema_alpha_reverse=nan max_logit=12.7744
step:1362/1750 train_time:644641ms step_avg:473.30ms
[train step 1362] avg_loss=3.396094 main=2.944394 aux=0.451700 imp_cv2=0.1229 load_cv2=5.1534 usage_frac=0.4241 topk_prob_mean=0.2748 ema_alpha_reverse=nan max_logit=12.7744
step:1363/1750 train_time:645108ms step_avg:473.30ms
[train step 1363] avg_loss=3.104982 main=2.648857 aux=0.456125 imp_cv2=0.1502 load_cv2=5.1960 usage_frac=0.4286 topk_prob_mean=0.2820 ema_alpha_reverse=nan max_logit=12.7744
step:1364/1750 train_time:645570ms step_avg:473.29ms
[train step 1364] avg_loss=2.999682 main=2.547574 aux=0.452108 imp_cv2=0.1573 load_cv2=5.1290 usage_frac=0.4196 topk_prob_mean=0.2840 ema_alpha_reverse=nan max_logit=12.7744
step:1365/1750 train_time:646021ms step_avg:473.28ms
[train step 1365] avg_loss=3.725971 main=3.246085 aux=0.479886 imp_cv2=0.0780 load_cv2=5.5259 usage_frac=0.4196 topk_prob_mean=0.2343 ema_alpha_reverse=nan max_logit=12.7744
step:1366/1750 train_time:646490ms step_avg:473.27ms
[train step 1366] avg_loss=3.167175 main=2.712361 aux=0.454814 imp_cv2=0.1807 load_cv2=5.1408 usage_frac=0.4241 topk_prob_mean=0.2931 ema_alpha_reverse=nan max_logit=12.7744
step:1367/1750 train_time:646949ms step_avg:473.26ms
[train step 1367] avg_loss=3.747407 main=3.237715 aux=0.509692 imp_cv2=0.0647 load_cv2=5.8594 usage_frac=0.4152 topk_prob_mean=0.1958 ema_alpha_reverse=nan max_logit=12.7744
step:1368/1750 train_time:647412ms step_avg:473.25ms
[train step 1368] avg_loss=3.496258 main=3.034863 aux=0.461395 imp_cv2=0.1207 load_cv2=5.2723 usage_frac=0.4241 topk_prob_mean=0.2666 ema_alpha_reverse=nan max_logit=12.7744
step:1369/1750 train_time:647874ms step_avg:473.25ms
[train step 1369] avg_loss=3.238689 main=2.781175 aux=0.457514 imp_cv2=0.1502 load_cv2=5.2071 usage_frac=0.4196 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=12.7744
step:1370/1750 train_time:648333ms step_avg:473.24ms
[train step 1370] avg_loss=3.523897 main=3.059438 aux=0.464460 imp_cv2=0.0942 load_cv2=5.3247 usage_frac=0.4196 topk_prob_mean=0.2545 ema_alpha_reverse=nan max_logit=12.7744
step:1371/1750 train_time:648788ms step_avg:473.22ms
[train step 1371] avg_loss=3.017037 main=2.571195 aux=0.445842 imp_cv2=0.1844 load_cv2=5.0329 usage_frac=0.4241 topk_prob_mean=0.2976 ema_alpha_reverse=nan max_logit=12.7744
step:1372/1750 train_time:649245ms step_avg:473.21ms
[train step 1372] avg_loss=3.409200 main=2.955165 aux=0.454035 imp_cv2=0.1253 load_cv2=5.1801 usage_frac=0.4241 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=12.7744
step:1373/1750 train_time:649700ms step_avg:473.20ms
[train step 1373] avg_loss=3.231521 main=2.780500 aux=0.451022 imp_cv2=0.1385 load_cv2=5.1387 usage_frac=0.4241 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=12.7744
step:1374/1750 train_time:650162ms step_avg:473.19ms
[train step 1374] avg_loss=3.495677 main=3.045303 aux=0.450375 imp_cv2=0.1122 load_cv2=5.1500 usage_frac=0.4241 topk_prob_mean=0.2677 ema_alpha_reverse=nan max_logit=12.7744
step:1375/1750 train_time:650611ms step_avg:473.17ms
[train step 1375] avg_loss=3.926291 main=3.453384 aux=0.472907 imp_cv2=0.0778 load_cv2=5.4439 usage_frac=0.4196 topk_prob_mean=0.2393 ema_alpha_reverse=nan max_logit=12.7744
step:1376/1750 train_time:651065ms step_avg:473.16ms
[train step 1376] avg_loss=4.298000 main=3.821407 aux=0.476593 imp_cv2=0.0739 load_cv2=5.4743 usage_frac=0.4152 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=12.7744
step:1377/1750 train_time:651528ms step_avg:473.15ms
[train step 1377] avg_loss=3.182835 main=2.736581 aux=0.446254 imp_cv2=0.1369 load_cv2=5.0764 usage_frac=0.4241 topk_prob_mean=0.2820 ema_alpha_reverse=nan max_logit=12.7744
step:1378/1750 train_time:651995ms step_avg:473.15ms
[train step 1378] avg_loss=4.366133 main=3.848614 aux=0.517519 imp_cv2=0.0538 load_cv2=5.9916 usage_frac=0.4196 topk_prob_mean=0.1955 ema_alpha_reverse=nan max_logit=12.7744
step:1379/1750 train_time:652451ms step_avg:473.13ms
[train step 1379] avg_loss=3.570748 main=3.110033 aux=0.460715 imp_cv2=0.1208 load_cv2=5.2699 usage_frac=0.4241 topk_prob_mean=0.2671 ema_alpha_reverse=nan max_logit=12.7744
step:1380/1750 train_time:652908ms step_avg:473.12ms
[train step 1380] avg_loss=3.506878 main=3.052939 aux=0.453939 imp_cv2=0.1464 load_cv2=5.1628 usage_frac=0.4241 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=12.7744
step:1381/1750 train_time:653361ms step_avg:473.11ms
[train step 1381] avg_loss=3.119382 main=2.663849 aux=0.455533 imp_cv2=0.1716 load_cv2=5.1640 usage_frac=0.4196 topk_prob_mean=0.2889 ema_alpha_reverse=nan max_logit=12.7744
step:1382/1750 train_time:653817ms step_avg:473.09ms
[train step 1382] avg_loss=3.383887 main=2.927571 aux=0.456316 imp_cv2=0.1439 load_cv2=5.1973 usage_frac=0.4241 topk_prob_mean=0.2785 ema_alpha_reverse=nan max_logit=12.7744
step:1383/1750 train_time:654271ms step_avg:473.08ms
[train step 1383] avg_loss=3.309597 main=2.839293 aux=0.470304 imp_cv2=0.1262 load_cv2=5.3848 usage_frac=0.4196 topk_prob_mean=0.2629 ema_alpha_reverse=nan max_logit=12.7744
step:1384/1750 train_time:654718ms step_avg:473.06ms
[train step 1384] avg_loss=3.889703 main=3.405690 aux=0.484012 imp_cv2=0.0698 load_cv2=5.5771 usage_frac=0.4241 topk_prob_mean=0.2300 ema_alpha_reverse=nan max_logit=12.7744
step:1385/1750 train_time:655176ms step_avg:473.05ms
[train step 1385] avg_loss=4.504529 main=3.961640 aux=0.542888 imp_cv2=0.0623 load_cv2=6.2693 usage_frac=0.3973 topk_prob_mean=0.1742 ema_alpha_reverse=nan max_logit=10.8091
step:1386/1750 train_time:655627ms step_avg:473.04ms
[train step 1386] avg_loss=3.019435 main=2.570096 aux=0.449339 imp_cv2=0.1937 load_cv2=5.0658 usage_frac=0.4107 topk_prob_mean=0.3008 ema_alpha_reverse=nan max_logit=12.7744
step:1387/1750 train_time:656086ms step_avg:473.02ms
[train step 1387] avg_loss=3.109433 main=2.651582 aux=0.457851 imp_cv2=0.1278 load_cv2=5.2237 usage_frac=0.4196 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=12.7744
step:1388/1750 train_time:656541ms step_avg:473.01ms
[train step 1388] avg_loss=3.716900 main=3.240089 aux=0.476811 imp_cv2=0.0747 load_cv2=5.4883 usage_frac=0.4241 topk_prob_mean=0.2361 ema_alpha_reverse=nan max_logit=12.7744
step:1389/1750 train_time:656998ms step_avg:473.00ms
[train step 1389] avg_loss=3.459257 main=2.985202 aux=0.474055 imp_cv2=0.0841 load_cv2=5.4479 usage_frac=0.4241 topk_prob_mean=0.2437 ema_alpha_reverse=nan max_logit=12.7744
step:1390/1750 train_time:657450ms step_avg:472.99ms
[train step 1390] avg_loss=3.568473 main=3.091760 aux=0.476714 imp_cv2=0.0807 load_cv2=5.4924 usage_frac=0.4196 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=12.7744
step:1391/1750 train_time:657897ms step_avg:472.97ms
[train step 1391] avg_loss=3.215855 main=2.756024 aux=0.459831 imp_cv2=0.1257 load_cv2=5.2525 usage_frac=0.4196 topk_prob_mean=0.2707 ema_alpha_reverse=nan max_logit=12.7744
step:1392/1750 train_time:658343ms step_avg:472.95ms
[train step 1392] avg_loss=3.714617 main=3.236374 aux=0.478243 imp_cv2=0.0822 load_cv2=5.5166 usage_frac=0.4152 topk_prob_mean=0.2434 ema_alpha_reverse=nan max_logit=12.7744
step:1393/1750 train_time:658800ms step_avg:472.94ms
[train step 1393] avg_loss=3.196001 main=2.739369 aux=0.456632 imp_cv2=0.1310 load_cv2=5.2065 usage_frac=0.4241 topk_prob_mean=0.2735 ema_alpha_reverse=nan max_logit=12.7744
step:1394/1750 train_time:659248ms step_avg:472.92ms
[train step 1394] avg_loss=3.621037 main=3.148720 aux=0.472317 imp_cv2=0.0872 load_cv2=5.4360 usage_frac=0.4196 topk_prob_mean=0.2478 ema_alpha_reverse=nan max_logit=12.7744
step:1395/1750 train_time:659681ms step_avg:472.89ms
[train step 1395] avg_loss=4.106417 main=3.578728 aux=0.527689 imp_cv2=0.0672 load_cv2=6.0662 usage_frac=0.3929 topk_prob_mean=0.1778 ema_alpha_reverse=nan max_logit=10.3146
step:1396/1750 train_time:660130ms step_avg:472.87ms
[train step 1396] avg_loss=3.793964 main=3.320155 aux=0.473808 imp_cv2=0.0830 load_cv2=5.4404 usage_frac=0.4152 topk_prob_mean=0.2448 ema_alpha_reverse=nan max_logit=12.7744
step:1397/1750 train_time:660583ms step_avg:472.86ms
[train step 1397] avg_loss=3.941591 main=3.471530 aux=0.470062 imp_cv2=0.0820 load_cv2=5.3956 usage_frac=0.4196 topk_prob_mean=0.2469 ema_alpha_reverse=nan max_logit=12.7744
step:1398/1750 train_time:661030ms step_avg:472.84ms
[train step 1398] avg_loss=3.807757 main=3.343173 aux=0.464583 imp_cv2=0.0995 load_cv2=5.3271 usage_frac=0.4196 topk_prob_mean=0.2567 ema_alpha_reverse=nan max_logit=12.7744
step:1399/1750 train_time:661493ms step_avg:472.83ms
[train step 1399] avg_loss=3.741272 main=3.275285 aux=0.465987 imp_cv2=0.0967 load_cv2=5.3393 usage_frac=0.4241 topk_prob_mean=0.2532 ema_alpha_reverse=nan max_logit=12.7744
step:1400/1750 train_time:661942ms step_avg:472.82ms
Running validation...
step:1400/1750 val_loss:2.972735 train_time:661954ms step_avg:472.82ms
[train step 1400] avg_loss=3.360947 main=2.897103 aux=0.463843 imp_cv2=0.1271 load_cv2=5.2967 usage_frac=0.4241 topk_prob_mean=0.2679 ema_alpha_reverse=nan max_logit=12.7744
step:1401/1750 train_time:662400ms step_avg:472.80ms
[train step 1401] avg_loss=3.412237 main=2.948877 aux=0.463360 imp_cv2=0.1295 load_cv2=5.2825 usage_frac=0.4241 topk_prob_mean=0.2697 ema_alpha_reverse=nan max_logit=12.7744
step:1402/1750 train_time:662853ms step_avg:472.79ms
[train step 1402] avg_loss=4.101958 main=3.590175 aux=0.511783 imp_cv2=0.0551 load_cv2=5.9062 usage_frac=0.4196 topk_prob_mean=0.1991 ema_alpha_reverse=nan max_logit=12.7744
step:1403/1750 train_time:663306ms step_avg:472.78ms
[train step 1403] avg_loss=3.427820 main=2.960506 aux=0.467314 imp_cv2=0.0976 load_cv2=5.3593 usage_frac=0.4196 topk_prob_mean=0.2543 ema_alpha_reverse=nan max_logit=12.7744
step:1404/1750 train_time:663963ms step_avg:472.91ms
[train step 1404] avg_loss=3.035390 main=2.585681 aux=0.449708 imp_cv2=0.2079 load_cv2=5.0544 usage_frac=0.4241 topk_prob_mean=0.3032 ema_alpha_reverse=nan max_logit=12.7744
step:1405/1750 train_time:664422ms step_avg:472.90ms
[train step 1405] avg_loss=3.078952 main=2.626495 aux=0.452457 imp_cv2=0.1959 load_cv2=5.1011 usage_frac=0.4241 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=12.7744
step:1406/1750 train_time:664889ms step_avg:472.89ms
[train step 1406] avg_loss=4.195267 main=3.705746 aux=0.489521 imp_cv2=0.0578 load_cv2=5.6454 usage_frac=0.4241 topk_prob_mean=0.2168 ema_alpha_reverse=nan max_logit=12.7744
step:1407/1750 train_time:665343ms step_avg:472.88ms
[train step 1407] avg_loss=3.939002 main=3.446873 aux=0.492130 imp_cv2=0.0607 load_cv2=5.6801 usage_frac=0.4196 topk_prob_mean=0.2157 ema_alpha_reverse=nan max_logit=12.7744
step:1408/1750 train_time:665801ms step_avg:472.87ms
[train step 1408] avg_loss=3.522832 main=3.059031 aux=0.463801 imp_cv2=0.1201 load_cv2=5.3005 usage_frac=0.4152 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=12.7744
step:1409/1750 train_time:666256ms step_avg:472.86ms
[train step 1409] avg_loss=3.784777 main=3.318094 aux=0.466682 imp_cv2=0.0931 load_cv2=5.3586 usage_frac=0.4241 topk_prob_mean=0.2488 ema_alpha_reverse=nan max_logit=12.7744
step:1410/1750 train_time:666714ms step_avg:472.85ms
[train step 1410] avg_loss=4.483064 main=3.959862 aux=0.523202 imp_cv2=0.0520 load_cv2=6.0615 usage_frac=0.4241 topk_prob_mean=0.1844 ema_alpha_reverse=nan max_logit=12.7744
step:1411/1750 train_time:667171ms step_avg:472.84ms
[train step 1411] avg_loss=3.335646 main=2.875152 aux=0.460495 imp_cv2=0.1201 load_cv2=5.2659 usage_frac=0.4196 topk_prob_mean=0.2685 ema_alpha_reverse=nan max_logit=12.7744
step:1412/1750 train_time:667624ms step_avg:472.82ms
[train step 1412] avg_loss=3.102594 main=2.646354 aux=0.456240 imp_cv2=0.1689 load_cv2=5.1789 usage_frac=0.4196 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=12.7744
step:1413/1750 train_time:668080ms step_avg:472.81ms
[train step 1413] avg_loss=3.668078 main=3.166396 aux=0.501682 imp_cv2=0.0573 load_cv2=5.8073 usage_frac=0.4241 topk_prob_mean=0.2081 ema_alpha_reverse=nan max_logit=12.7744
step:1414/1750 train_time:668539ms step_avg:472.80ms
[train step 1414] avg_loss=3.449191 main=2.993304 aux=0.455887 imp_cv2=0.1068 load_cv2=5.2166 usage_frac=0.4241 topk_prob_mean=0.2640 ema_alpha_reverse=nan max_logit=12.7744
step:1415/1750 train_time:668992ms step_avg:472.79ms
[train step 1415] avg_loss=3.176568 main=2.724258 aux=0.452310 imp_cv2=0.1327 load_cv2=5.1552 usage_frac=0.4241 topk_prob_mean=0.2771 ema_alpha_reverse=nan max_logit=12.7744
step:1416/1750 train_time:669441ms step_avg:472.77ms
[train step 1416] avg_loss=3.523665 main=3.038967 aux=0.484698 imp_cv2=0.0587 load_cv2=5.5965 usage_frac=0.4196 topk_prob_mean=0.2191 ema_alpha_reverse=nan max_logit=12.7744
step:1417/1750 train_time:669899ms step_avg:472.76ms
[train step 1417] avg_loss=3.894585 main=3.408534 aux=0.486051 imp_cv2=0.0555 load_cv2=5.6109 usage_frac=0.4152 topk_prob_mean=0.2203 ema_alpha_reverse=nan max_logit=12.7744
step:1418/1750 train_time:670352ms step_avg:472.74ms
[train step 1418] avg_loss=3.274112 main=2.821640 aux=0.452472 imp_cv2=0.1611 load_cv2=5.1336 usage_frac=0.4196 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=12.7744
step:1419/1750 train_time:670999ms step_avg:472.87ms
[train step 1419] avg_loss=3.724426 main=3.256472 aux=0.467954 imp_cv2=0.0861 load_cv2=5.3783 usage_frac=0.4196 topk_prob_mean=0.2488 ema_alpha_reverse=nan max_logit=12.7744
step:1420/1750 train_time:671467ms step_avg:472.86ms
[train step 1420] avg_loss=3.117446 main=2.664362 aux=0.453084 imp_cv2=0.1586 load_cv2=5.1411 usage_frac=0.4152 topk_prob_mean=0.2872 ema_alpha_reverse=nan max_logit=12.7744
step:1421/1750 train_time:671917ms step_avg:472.85ms
[train step 1421] avg_loss=3.506525 main=2.998902 aux=0.507623 imp_cv2=0.0566 load_cv2=5.8533 usage_frac=0.4196 topk_prob_mean=0.1986 ema_alpha_reverse=nan max_logit=12.7744
step:1422/1750 train_time:672378ms step_avg:472.84ms
[train step 1422] avg_loss=3.459827 main=2.984789 aux=0.475039 imp_cv2=0.0785 load_cv2=5.4652 usage_frac=0.4152 topk_prob_mean=0.2419 ema_alpha_reverse=nan max_logit=12.7744
step:1423/1750 train_time:672826ms step_avg:472.82ms
[train step 1423] avg_loss=3.731753 main=3.263314 aux=0.468439 imp_cv2=0.0953 load_cv2=5.3725 usage_frac=0.4241 topk_prob_mean=0.2518 ema_alpha_reverse=nan max_logit=12.7744
step:1424/1750 train_time:673284ms step_avg:472.81ms
[train step 1424] avg_loss=3.623672 main=3.147674 aux=0.475998 imp_cv2=0.0733 load_cv2=5.4649 usage_frac=0.4152 topk_prob_mean=0.2358 ema_alpha_reverse=nan max_logit=12.7744
step:1425/1750 train_time:673736ms step_avg:472.80ms
[train step 1425] avg_loss=4.304543 main=3.767002 aux=0.537541 imp_cv2=0.0563 load_cv2=6.2141 usage_frac=0.3884 topk_prob_mean=0.1717 ema_alpha_reverse=nan max_logit=10.8091
step:1426/1750 train_time:674190ms step_avg:472.78ms
[train step 1426] avg_loss=3.325331 main=2.874580 aux=0.450751 imp_cv2=0.1564 load_cv2=5.1009 usage_frac=0.4241 topk_prob_mean=0.2889 ema_alpha_reverse=nan max_logit=12.7744
step:1427/1750 train_time:674644ms step_avg:472.77ms
[train step 1427] avg_loss=3.428752 main=2.931279 aux=0.497472 imp_cv2=0.0652 load_cv2=5.7512 usage_frac=0.4196 topk_prob_mean=0.2194 ema_alpha_reverse=nan max_logit=12.7744
step:1428/1750 train_time:675099ms step_avg:472.76ms
[train step 1428] avg_loss=3.059561 main=2.595860 aux=0.463702 imp_cv2=0.1551 load_cv2=5.2585 usage_frac=0.4241 topk_prob_mean=0.2815 ema_alpha_reverse=nan max_logit=12.7744
step:1429/1750 train_time:675564ms step_avg:472.75ms
[train step 1429] avg_loss=3.429229 main=2.964684 aux=0.464545 imp_cv2=0.1120 load_cv2=5.3108 usage_frac=0.4152 topk_prob_mean=0.2640 ema_alpha_reverse=nan max_logit=12.7744
step:1430/1750 train_time:676026ms step_avg:472.75ms
[train step 1430] avg_loss=3.801411 main=3.313242 aux=0.488169 imp_cv2=0.0675 load_cv2=5.6094 usage_frac=0.4196 topk_prob_mean=0.2164 ema_alpha_reverse=nan max_logit=12.7744
step:1431/1750 train_time:676478ms step_avg:472.73ms
[train step 1431] avg_loss=3.236321 main=2.761819 aux=0.474502 imp_cv2=0.0926 load_cv2=5.4483 usage_frac=0.4241 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=12.7744
step:1432/1750 train_time:676936ms step_avg:472.72ms
[train step 1432] avg_loss=3.292172 main=2.832877 aux=0.459295 imp_cv2=0.1283 load_cv2=5.2361 usage_frac=0.4241 topk_prob_mean=0.2748 ema_alpha_reverse=nan max_logit=12.7744
step:1433/1750 train_time:677387ms step_avg:472.71ms
[train step 1433] avg_loss=3.021953 main=2.563971 aux=0.457983 imp_cv2=0.1526 load_cv2=5.1961 usage_frac=0.4241 topk_prob_mean=0.2847 ema_alpha_reverse=nan max_logit=12.7744
step:1434/1750 train_time:677850ms step_avg:472.70ms
[train step 1434] avg_loss=3.511310 main=3.052134 aux=0.459177 imp_cv2=0.1461 load_cv2=5.2200 usage_frac=0.4196 topk_prob_mean=0.2805 ema_alpha_reverse=nan max_logit=12.7744
step:1435/1750 train_time:678494ms step_avg:472.82ms
[train step 1435] avg_loss=3.357625 main=2.895159 aux=0.462465 imp_cv2=0.1103 load_cv2=5.2928 usage_frac=0.4241 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=12.7744
step:1436/1750 train_time:678955ms step_avg:472.81ms
[train step 1436] avg_loss=3.524422 main=3.060527 aux=0.463895 imp_cv2=0.1161 load_cv2=5.3015 usage_frac=0.4196 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=12.7744
step:1437/1750 train_time:679415ms step_avg:472.80ms
[train step 1437] avg_loss=3.522811 main=3.051816 aux=0.470995 imp_cv2=0.0942 load_cv2=5.4044 usage_frac=0.4241 topk_prob_mean=0.2501 ema_alpha_reverse=nan max_logit=12.7744
step:1438/1750 train_time:679875ms step_avg:472.79ms
[train step 1438] avg_loss=3.374481 main=2.923445 aux=0.451036 imp_cv2=0.1483 load_cv2=5.1235 usage_frac=0.4241 topk_prob_mean=0.2836 ema_alpha_reverse=nan max_logit=12.7744
step:1439/1750 train_time:680336ms step_avg:472.78ms
[train step 1439] avg_loss=3.224729 main=2.760774 aux=0.463955 imp_cv2=0.1140 load_cv2=5.3085 usage_frac=0.4196 topk_prob_mean=0.2626 ema_alpha_reverse=nan max_logit=12.7744
step:1440/1750 train_time:680795ms step_avg:472.77ms
[train step 1440] avg_loss=3.061259 main=2.612099 aux=0.449160 imp_cv2=0.1601 load_cv2=5.0930 usage_frac=0.4196 topk_prob_mean=0.2873 ema_alpha_reverse=nan max_logit=12.7744
step:1441/1750 train_time:681250ms step_avg:472.76ms
[train step 1441] avg_loss=3.477007 main=3.017785 aux=0.459222 imp_cv2=0.1057 load_cv2=5.2628 usage_frac=0.4241 topk_prob_mean=0.2606 ema_alpha_reverse=nan max_logit=12.7744
step:1442/1750 train_time:681699ms step_avg:472.75ms
[train step 1442] avg_loss=3.151999 main=2.706339 aux=0.445660 imp_cv2=0.1827 load_cv2=5.0337 usage_frac=0.4196 topk_prob_mean=0.2970 ema_alpha_reverse=nan max_logit=12.7744
step:1443/1750 train_time:682162ms step_avg:472.74ms
[train step 1443] avg_loss=3.153111 main=2.699871 aux=0.453240 imp_cv2=0.1396 load_cv2=5.1597 usage_frac=0.4196 topk_prob_mean=0.2788 ema_alpha_reverse=nan max_logit=12.7744
step:1444/1750 train_time:682630ms step_avg:472.74ms
[train step 1444] avg_loss=3.166073 main=2.712751 aux=0.453323 imp_cv2=0.1417 load_cv2=5.1593 usage_frac=0.4241 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=12.7744
step:1445/1750 train_time:683087ms step_avg:472.72ms
[train step 1445] avg_loss=3.271554 main=2.818740 aux=0.452814 imp_cv2=0.1418 load_cv2=5.1569 usage_frac=0.4196 topk_prob_mean=0.2804 ema_alpha_reverse=nan max_logit=12.7744
step:1446/1750 train_time:683574ms step_avg:472.73ms
[train step 1446] avg_loss=3.676595 main=3.210518 aux=0.466077 imp_cv2=0.0951 load_cv2=5.3471 usage_frac=0.4196 topk_prob_mean=0.2508 ema_alpha_reverse=nan max_logit=12.7744
step:1447/1750 train_time:684029ms step_avg:472.72ms
[train step 1447] avg_loss=3.411345 main=2.953326 aux=0.458019 imp_cv2=0.1156 load_cv2=5.2318 usage_frac=0.4196 topk_prob_mean=0.2678 ema_alpha_reverse=nan max_logit=12.7744
step:1448/1750 train_time:684485ms step_avg:472.71ms
[train step 1448] avg_loss=3.220876 main=2.767779 aux=0.453097 imp_cv2=0.1715 load_cv2=5.1317 usage_frac=0.4196 topk_prob_mean=0.2912 ema_alpha_reverse=nan max_logit=12.7744
step:1449/1750 train_time:684936ms step_avg:472.70ms
[train step 1449] avg_loss=3.235850 main=2.775980 aux=0.459870 imp_cv2=0.1045 load_cv2=5.2619 usage_frac=0.4196 topk_prob_mean=0.2619 ema_alpha_reverse=nan max_logit=12.7744
step:1450/1750 train_time:685396ms step_avg:472.69ms
Running validation...
step:1450/1750 val_loss:2.946621 train_time:685408ms step_avg:472.69ms
[train step 1450] avg_loss=3.686373 main=3.213517 aux=0.472856 imp_cv2=0.1002 load_cv2=5.4248 usage_frac=0.4241 topk_prob_mean=0.2531 ema_alpha_reverse=nan max_logit=12.7744
step:1451/1750 train_time:685857ms step_avg:472.68ms
[train step 1451] avg_loss=3.621047 main=3.144523 aux=0.476524 imp_cv2=0.0763 load_cv2=5.4831 usage_frac=0.4196 topk_prob_mean=0.2388 ema_alpha_reverse=nan max_logit=12.7744
step:1452/1750 train_time:686319ms step_avg:472.67ms
[train step 1452] avg_loss=3.427490 main=2.963409 aux=0.464081 imp_cv2=0.0995 load_cv2=5.3138 usage_frac=0.4196 topk_prob_mean=0.2578 ema_alpha_reverse=nan max_logit=12.7744
step:1453/1750 train_time:686776ms step_avg:472.66ms
[train step 1453] avg_loss=3.199505 main=2.750526 aux=0.448979 imp_cv2=0.1638 load_cv2=5.0850 usage_frac=0.4241 topk_prob_mean=0.2909 ema_alpha_reverse=nan max_logit=12.7744
step:1454/1750 train_time:687233ms step_avg:472.65ms
[train step 1454] avg_loss=3.449194 main=2.987756 aux=0.461438 imp_cv2=0.1230 load_cv2=5.2699 usage_frac=0.4152 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=12.7744
step:1455/1750 train_time:687696ms step_avg:472.64ms
[train step 1455] avg_loss=3.221337 main=2.769199 aux=0.452138 imp_cv2=0.1742 load_cv2=5.1143 usage_frac=0.4152 topk_prob_mean=0.2922 ema_alpha_reverse=nan max_logit=12.7744
step:1456/1750 train_time:688151ms step_avg:472.63ms
[train step 1456] avg_loss=3.214387 main=2.760124 aux=0.454263 imp_cv2=0.1493 load_cv2=5.1622 usage_frac=0.4196 topk_prob_mean=0.2819 ema_alpha_reverse=nan max_logit=12.7744
step:1457/1750 train_time:688618ms step_avg:472.63ms
[train step 1457] avg_loss=4.108362 main=3.584021 aux=0.524340 imp_cv2=0.0863 load_cv2=6.0045 usage_frac=0.3929 topk_prob_mean=0.1867 ema_alpha_reverse=nan max_logit=10.8091
step:1458/1750 train_time:689070ms step_avg:472.61ms
[train step 1458] avg_loss=4.022215 main=3.549495 aux=0.472720 imp_cv2=0.0706 load_cv2=5.4499 usage_frac=0.4152 topk_prob_mean=0.2364 ema_alpha_reverse=nan max_logit=12.7744
step:1459/1750 train_time:689517ms step_avg:472.60ms
[train step 1459] avg_loss=3.178069 main=2.727358 aux=0.450712 imp_cv2=0.1800 load_cv2=5.0930 usage_frac=0.4241 topk_prob_mean=0.2960 ema_alpha_reverse=nan max_logit=12.7744
step:1460/1750 train_time:689968ms step_avg:472.58ms
[train step 1460] avg_loss=3.272663 main=2.825038 aux=0.447625 imp_cv2=0.1725 load_cv2=5.0615 usage_frac=0.4152 topk_prob_mean=0.2948 ema_alpha_reverse=nan max_logit=12.7744
step:1461/1750 train_time:690422ms step_avg:472.57ms
[train step 1461] avg_loss=2.981264 main=2.535637 aux=0.445628 imp_cv2=0.1966 load_cv2=5.0158 usage_frac=0.4241 topk_prob_mean=0.3051 ema_alpha_reverse=nan max_logit=12.7744
step:1462/1750 train_time:690880ms step_avg:472.56ms
[train step 1462] avg_loss=3.375051 main=2.915535 aux=0.459515 imp_cv2=0.1105 load_cv2=5.2517 usage_frac=0.4196 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=12.7744
step:1463/1750 train_time:691331ms step_avg:472.54ms
[train step 1463] avg_loss=3.667142 main=3.193027 aux=0.474116 imp_cv2=0.0852 load_cv2=5.4423 usage_frac=0.4241 topk_prob_mean=0.2432 ema_alpha_reverse=nan max_logit=12.7744
step:1464/1750 train_time:691784ms step_avg:472.53ms
[train step 1464] avg_loss=3.617772 main=3.144263 aux=0.473509 imp_cv2=0.0793 load_cv2=5.4427 usage_frac=0.4241 topk_prob_mean=0.2393 ema_alpha_reverse=nan max_logit=12.7744
step:1465/1750 train_time:692237ms step_avg:472.52ms
[train step 1465] avg_loss=3.814914 main=3.340432 aux=0.474482 imp_cv2=0.0799 load_cv2=5.4619 usage_frac=0.4196 topk_prob_mean=0.2409 ema_alpha_reverse=nan max_logit=12.7744
step:1466/1750 train_time:692685ms step_avg:472.50ms
[train step 1466] avg_loss=3.429572 main=2.974100 aux=0.455472 imp_cv2=0.1298 load_cv2=5.1952 usage_frac=0.4241 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=12.7744
step:1467/1750 train_time:693138ms step_avg:472.49ms
[train step 1467] avg_loss=3.205994 main=2.749048 aux=0.456945 imp_cv2=0.1520 load_cv2=5.1940 usage_frac=0.4196 topk_prob_mean=0.2807 ema_alpha_reverse=nan max_logit=12.7744
step:1468/1750 train_time:693588ms step_avg:472.47ms
[train step 1468] avg_loss=3.115537 main=2.656778 aux=0.458759 imp_cv2=0.1498 load_cv2=5.2318 usage_frac=0.4241 topk_prob_mean=0.2795 ema_alpha_reverse=nan max_logit=12.7744
step:1469/1750 train_time:694038ms step_avg:472.46ms
[train step 1469] avg_loss=3.269577 main=2.824330 aux=0.445246 imp_cv2=0.1802 load_cv2=5.0249 usage_frac=0.4196 topk_prob_mean=0.2973 ema_alpha_reverse=nan max_logit=12.7744
step:1470/1750 train_time:694500ms step_avg:472.45ms
[train step 1470] avg_loss=2.806980 main=2.363614 aux=0.443366 imp_cv2=0.2199 load_cv2=4.9659 usage_frac=0.4196 topk_prob_mean=0.3106 ema_alpha_reverse=nan max_logit=12.7744
step:1471/1750 train_time:694965ms step_avg:472.44ms
[train step 1471] avg_loss=4.290151 main=3.814703 aux=0.475448 imp_cv2=0.1059 load_cv2=5.4190 usage_frac=0.4241 topk_prob_mean=0.2412 ema_alpha_reverse=nan max_logit=12.7744
step:1472/1750 train_time:695428ms step_avg:472.44ms
[train step 1472] avg_loss=3.587636 main=3.124838 aux=0.462798 imp_cv2=0.1133 load_cv2=5.2980 usage_frac=0.4196 topk_prob_mean=0.2611 ema_alpha_reverse=nan max_logit=12.7744
step:1473/1750 train_time:695878ms step_avg:472.42ms
[train step 1473] avg_loss=4.112638 main=3.629493 aux=0.483145 imp_cv2=0.0827 load_cv2=5.5575 usage_frac=0.4196 topk_prob_mean=0.2344 ema_alpha_reverse=nan max_logit=12.7744
step:1474/1750 train_time:696345ms step_avg:472.42ms
[train step 1474] avg_loss=3.441132 main=2.984421 aux=0.456711 imp_cv2=0.1341 load_cv2=5.2015 usage_frac=0.4241 topk_prob_mean=0.2753 ema_alpha_reverse=nan max_logit=12.7744
step:1475/1750 train_time:696801ms step_avg:472.41ms
[train step 1475] avg_loss=4.149029 main=3.617049 aux=0.531980 imp_cv2=0.0612 load_cv2=6.1375 usage_frac=0.3929 topk_prob_mean=0.1752 ema_alpha_reverse=nan max_logit=11.7917
step:1476/1750 train_time:697259ms step_avg:472.40ms
[train step 1476] avg_loss=3.804172 main=3.345277 aux=0.458895 imp_cv2=0.1149 load_cv2=5.2422 usage_frac=0.4241 topk_prob_mean=0.2665 ema_alpha_reverse=nan max_logit=12.7744
step:1477/1750 train_time:697717ms step_avg:472.39ms
[train step 1477] avg_loss=3.261226 main=2.802166 aux=0.459060 imp_cv2=0.1202 load_cv2=5.2409 usage_frac=0.4196 topk_prob_mean=0.2675 ema_alpha_reverse=nan max_logit=12.7744
step:1478/1750 train_time:698176ms step_avg:472.38ms
[train step 1478] avg_loss=3.749016 main=3.283451 aux=0.465565 imp_cv2=0.1049 load_cv2=5.3292 usage_frac=0.4241 topk_prob_mean=0.2576 ema_alpha_reverse=nan max_logit=12.7744
step:1479/1750 train_time:698625ms step_avg:472.36ms
[train step 1479] avg_loss=3.103622 main=2.650168 aux=0.453454 imp_cv2=0.1769 load_cv2=5.1281 usage_frac=0.4241 topk_prob_mean=0.2936 ema_alpha_reverse=nan max_logit=12.7744
step:1480/1750 train_time:699084ms step_avg:472.35ms
[train step 1480] avg_loss=3.149392 main=2.699251 aux=0.450141 imp_cv2=0.1732 load_cv2=5.0821 usage_frac=0.4152 topk_prob_mean=0.2946 ema_alpha_reverse=nan max_logit=12.7744
step:1481/1750 train_time:699535ms step_avg:472.34ms
[train step 1481] avg_loss=3.534394 main=3.061128 aux=0.473266 imp_cv2=0.0805 load_cv2=5.4415 usage_frac=0.4196 topk_prob_mean=0.2436 ema_alpha_reverse=nan max_logit=12.7744
step:1482/1750 train_time:699990ms step_avg:472.33ms
[train step 1482] avg_loss=2.992803 main=2.541431 aux=0.451372 imp_cv2=0.2197 load_cv2=5.0577 usage_frac=0.4196 topk_prob_mean=0.3097 ema_alpha_reverse=nan max_logit=12.7744
step:1483/1750 train_time:700450ms step_avg:472.32ms
[train step 1483] avg_loss=3.445376 main=2.978606 aux=0.466770 imp_cv2=0.0929 load_cv2=5.3494 usage_frac=0.4196 topk_prob_mean=0.2539 ema_alpha_reverse=nan max_logit=12.7744
step:1484/1750 train_time:700908ms step_avg:472.31ms
[train step 1484] avg_loss=3.347038 main=2.891492 aux=0.455546 imp_cv2=0.1405 load_cv2=5.1821 usage_frac=0.4241 topk_prob_mean=0.2803 ema_alpha_reverse=nan max_logit=12.7744
step:1485/1750 train_time:701372ms step_avg:472.30ms
[train step 1485] avg_loss=2.948041 main=2.498894 aux=0.449146 imp_cv2=0.1979 load_cv2=5.0499 usage_frac=0.4241 topk_prob_mean=0.3042 ema_alpha_reverse=nan max_logit=12.7744
step:1486/1750 train_time:701836ms step_avg:472.30ms
[train step 1486] avg_loss=3.136536 main=2.690622 aux=0.445914 imp_cv2=0.1774 load_cv2=5.0223 usage_frac=0.4241 topk_prob_mean=0.2993 ema_alpha_reverse=nan max_logit=12.7744
step:1487/1750 train_time:702306ms step_avg:472.30ms
[train step 1487] avg_loss=3.258698 main=2.799020 aux=0.459678 imp_cv2=0.1404 load_cv2=5.2320 usage_frac=0.4196 topk_prob_mean=0.2798 ema_alpha_reverse=nan max_logit=12.7744
step:1488/1750 train_time:702769ms step_avg:472.29ms
[train step 1488] avg_loss=3.178563 main=2.723305 aux=0.455257 imp_cv2=0.1419 load_cv2=5.1731 usage_frac=0.4241 topk_prob_mean=0.2813 ema_alpha_reverse=nan max_logit=12.7744
step:1489/1750 train_time:703230ms step_avg:472.28ms
[train step 1489] avg_loss=3.498161 main=3.036058 aux=0.462103 imp_cv2=0.1122 load_cv2=5.2804 usage_frac=0.4196 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=12.7744
step:1490/1750 train_time:703683ms step_avg:472.27ms
[train step 1490] avg_loss=3.354923 main=2.899904 aux=0.455020 imp_cv2=0.1149 load_cv2=5.1815 usage_frac=0.4241 topk_prob_mean=0.2655 ema_alpha_reverse=nan max_logit=12.7744
step:1491/1750 train_time:704142ms step_avg:472.26ms
[train step 1491] avg_loss=3.504956 main=3.046148 aux=0.458808 imp_cv2=0.1180 load_cv2=5.2436 usage_frac=0.4196 topk_prob_mean=0.2679 ema_alpha_reverse=nan max_logit=12.7744
step:1492/1750 train_time:704605ms step_avg:472.26ms
[train step 1492] avg_loss=3.803187 main=3.320730 aux=0.482456 imp_cv2=0.0642 load_cv2=5.5641 usage_frac=0.4196 topk_prob_mean=0.2289 ema_alpha_reverse=nan max_logit=12.7744
step:1493/1750 train_time:705058ms step_avg:472.24ms
[train step 1493] avg_loss=3.047989 main=2.603206 aux=0.444783 imp_cv2=0.1834 load_cv2=5.0168 usage_frac=0.4152 topk_prob_mean=0.2986 ema_alpha_reverse=nan max_logit=12.7744
step:1494/1750 train_time:705519ms step_avg:472.23ms
[train step 1494] avg_loss=3.436770 main=2.976405 aux=0.460365 imp_cv2=0.1079 load_cv2=5.2661 usage_frac=0.4152 topk_prob_mean=0.2635 ema_alpha_reverse=nan max_logit=12.7744
step:1495/1750 train_time:706213ms step_avg:472.38ms
[train step 1495] avg_loss=3.385868 main=2.930338 aux=0.455530 imp_cv2=0.1226 load_cv2=5.1951 usage_frac=0.4241 topk_prob_mean=0.2713 ema_alpha_reverse=nan max_logit=12.7744
step:1496/1750 train_time:706668ms step_avg:472.37ms
[train step 1496] avg_loss=3.115086 main=2.657096 aux=0.457990 imp_cv2=0.1163 load_cv2=5.2295 usage_frac=0.4241 topk_prob_mean=0.2673 ema_alpha_reverse=nan max_logit=12.7744
step:1497/1750 train_time:707120ms step_avg:472.36ms
[train step 1497] avg_loss=3.269109 main=2.814258 aux=0.454851 imp_cv2=0.1333 load_cv2=5.1836 usage_frac=0.4241 topk_prob_mean=0.2744 ema_alpha_reverse=nan max_logit=12.7744
step:1498/1750 train_time:707578ms step_avg:472.35ms
[train step 1498] avg_loss=3.814040 main=3.358099 aux=0.455941 imp_cv2=0.1009 load_cv2=5.2143 usage_frac=0.4241 topk_prob_mean=0.2609 ema_alpha_reverse=nan max_logit=12.7744
step:1499/1750 train_time:708038ms step_avg:472.34ms
[train step 1499] avg_loss=3.377485 main=2.916332 aux=0.461153 imp_cv2=0.0976 load_cv2=5.2822 usage_frac=0.4241 topk_prob_mean=0.2543 ema_alpha_reverse=nan max_logit=12.7744
step:1500/1750 train_time:708502ms step_avg:472.33ms
Running validation...
step:1500/1750 val_loss:2.922481 train_time:708514ms step_avg:472.34ms
[train step 1500] avg_loss=3.306812 main=2.838704 aux=0.468107 imp_cv2=0.0930 load_cv2=5.3716 usage_frac=0.4241 topk_prob_mean=0.2496 ema_alpha_reverse=nan max_logit=12.7744
step:1501/1750 train_time:708959ms step_avg:472.32ms
[train step 1501] avg_loss=3.162649 main=2.716870 aux=0.445780 imp_cv2=0.1769 load_cv2=5.0351 usage_frac=0.4286 topk_prob_mean=0.2927 ema_alpha_reverse=nan max_logit=12.7744
step:1502/1750 train_time:709413ms step_avg:472.31ms
[train step 1502] avg_loss=3.954064 main=3.415831 aux=0.538234 imp_cv2=0.0634 load_cv2=6.2085 usage_frac=0.3929 topk_prob_mean=0.1735 ema_alpha_reverse=nan max_logit=10.5943
step:1503/1750 train_time:709869ms step_avg:472.30ms
[train step 1503] avg_loss=4.647521 main=4.120633 aux=0.526888 imp_cv2=0.0678 load_cv2=6.0817 usage_frac=0.3973 topk_prob_mean=0.1822 ema_alpha_reverse=nan max_logit=10.8091
step:1504/1750 train_time:710345ms step_avg:472.30ms
[train step 1504] avg_loss=3.003280 main=2.555310 aux=0.447970 imp_cv2=0.1874 load_cv2=5.0543 usage_frac=0.4241 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=12.7744
step:1505/1750 train_time:710807ms step_avg:472.30ms
[train step 1505] avg_loss=3.800369 main=3.297086 aux=0.503283 imp_cv2=0.0518 load_cv2=5.8323 usage_frac=0.4241 topk_prob_mean=0.2023 ema_alpha_reverse=nan max_logit=12.7744
step:1506/1750 train_time:711256ms step_avg:472.28ms
[train step 1506] avg_loss=3.081816 main=2.634103 aux=0.447714 imp_cv2=0.1551 load_cv2=5.0769 usage_frac=0.4241 topk_prob_mean=0.2862 ema_alpha_reverse=nan max_logit=12.7744
step:1507/1750 train_time:711704ms step_avg:472.27ms
[train step 1507] avg_loss=3.284073 main=2.824116 aux=0.459957 imp_cv2=0.1133 load_cv2=5.2622 usage_frac=0.4196 topk_prob_mean=0.2621 ema_alpha_reverse=nan max_logit=12.7744
step:1508/1750 train_time:712156ms step_avg:472.25ms
[train step 1508] avg_loss=3.515741 main=3.057487 aux=0.458254 imp_cv2=0.1102 load_cv2=5.2406 usage_frac=0.4241 topk_prob_mean=0.2637 ema_alpha_reverse=nan max_logit=12.7744
step:1509/1750 train_time:712608ms step_avg:472.24ms
[train step 1509] avg_loss=3.157025 main=2.707376 aux=0.449648 imp_cv2=0.1531 load_cv2=5.1064 usage_frac=0.4241 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=12.7744
step:1510/1750 train_time:713071ms step_avg:472.23ms
[train step 1510] avg_loss=3.153960 main=2.711255 aux=0.442705 imp_cv2=0.2054 load_cv2=4.9745 usage_frac=0.4241 topk_prob_mean=0.3044 ema_alpha_reverse=nan max_logit=12.7744
step:1511/1750 train_time:713529ms step_avg:472.22ms
[train step 1511] avg_loss=3.536730 main=3.063893 aux=0.472837 imp_cv2=0.0804 load_cv2=5.4390 usage_frac=0.4241 topk_prob_mean=0.2378 ema_alpha_reverse=nan max_logit=12.7744
step:1512/1750 train_time:713984ms step_avg:472.21ms
[train step 1512] avg_loss=2.917392 main=2.470666 aux=0.446726 imp_cv2=0.1627 load_cv2=5.0629 usage_frac=0.4241 topk_prob_mean=0.2895 ema_alpha_reverse=nan max_logit=12.7744
step:1513/1750 train_time:714445ms step_avg:472.20ms
[train step 1513] avg_loss=3.965721 main=3.458557 aux=0.507164 imp_cv2=0.0525 load_cv2=5.8664 usage_frac=0.4196 topk_prob_mean=0.1879 ema_alpha_reverse=nan max_logit=12.7744
step:1514/1750 train_time:714903ms step_avg:472.19ms
[train step 1514] avg_loss=3.287543 main=2.838872 aux=0.448671 imp_cv2=0.1328 load_cv2=5.1072 usage_frac=0.4286 topk_prob_mean=0.2791 ema_alpha_reverse=nan max_logit=12.7744
step:1515/1750 train_time:715390ms step_avg:472.20ms
[train step 1515] avg_loss=3.246536 main=2.791553 aux=0.454983 imp_cv2=0.1186 load_cv2=5.2006 usage_frac=0.4241 topk_prob_mean=0.2692 ema_alpha_reverse=nan max_logit=12.7744
step:1516/1750 train_time:715849ms step_avg:472.20ms
[train step 1516] avg_loss=3.693137 main=3.222486 aux=0.470650 imp_cv2=0.0740 load_cv2=5.4202 usage_frac=0.4241 topk_prob_mean=0.2382 ema_alpha_reverse=nan max_logit=12.7744
step:1517/1750 train_time:716303ms step_avg:472.18ms
[train step 1517] avg_loss=3.471818 main=3.010207 aux=0.461611 imp_cv2=0.0992 load_cv2=5.2903 usage_frac=0.4241 topk_prob_mean=0.2559 ema_alpha_reverse=nan max_logit=12.7744
step:1518/1750 train_time:716765ms step_avg:472.18ms
[train step 1518] avg_loss=3.336502 main=2.873461 aux=0.463040 imp_cv2=0.0914 load_cv2=5.3138 usage_frac=0.4241 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=12.7744
step:1519/1750 train_time:717222ms step_avg:472.17ms
[train step 1519] avg_loss=3.203362 main=2.756209 aux=0.447154 imp_cv2=0.1451 load_cv2=5.0845 usage_frac=0.4241 topk_prob_mean=0.2828 ema_alpha_reverse=nan max_logit=12.7744
step:1520/1750 train_time:717676ms step_avg:472.16ms
[train step 1520] avg_loss=3.928821 main=3.457304 aux=0.471517 imp_cv2=0.0770 load_cv2=5.4054 usage_frac=0.4241 topk_prob_mean=0.2331 ema_alpha_reverse=nan max_logit=12.7744
step:1521/1750 train_time:718125ms step_avg:472.14ms
[train step 1521] avg_loss=3.295084 main=2.851292 aux=0.443792 imp_cv2=0.1537 load_cv2=5.0336 usage_frac=0.4241 topk_prob_mean=0.2877 ema_alpha_reverse=nan max_logit=12.7744
step:1522/1750 train_time:718579ms step_avg:472.13ms
[train step 1522] avg_loss=4.027897 main=3.514261 aux=0.513636 imp_cv2=0.0492 load_cv2=5.9552 usage_frac=0.4241 topk_prob_mean=0.1967 ema_alpha_reverse=nan max_logit=12.7744
step:1523/1750 train_time:719047ms step_avg:472.13ms
[train step 1523] avg_loss=3.417610 main=2.963775 aux=0.453835 imp_cv2=0.1089 load_cv2=5.1894 usage_frac=0.4241 topk_prob_mean=0.2626 ema_alpha_reverse=nan max_logit=12.7744
step:1524/1750 train_time:719507ms step_avg:472.12ms
[train step 1524] avg_loss=3.448401 main=2.994225 aux=0.454176 imp_cv2=0.1205 load_cv2=5.1882 usage_frac=0.4241 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=12.7744
step:1525/1750 train_time:719965ms step_avg:472.11ms
[train step 1525] avg_loss=2.960596 main=2.519060 aux=0.441536 imp_cv2=0.1979 load_cv2=4.9687 usage_frac=0.4241 topk_prob_mean=0.3026 ema_alpha_reverse=nan max_logit=12.7744
step:1526/1750 train_time:720416ms step_avg:472.09ms
[train step 1526] avg_loss=2.762746 main=2.322664 aux=0.440082 imp_cv2=0.2599 load_cv2=4.8994 usage_frac=0.4241 topk_prob_mean=0.3206 ema_alpha_reverse=nan max_logit=12.7744
step:1527/1750 train_time:720877ms step_avg:472.09ms
[train step 1527] avg_loss=3.369310 main=2.910276 aux=0.459034 imp_cv2=0.1131 load_cv2=5.2564 usage_frac=0.4241 topk_prob_mean=0.2631 ema_alpha_reverse=nan max_logit=12.7744
step:1528/1750 train_time:721331ms step_avg:472.08ms
[train step 1528] avg_loss=3.251778 main=2.795907 aux=0.455871 imp_cv2=0.1230 load_cv2=5.2064 usage_frac=0.4241 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=12.7744
step:1529/1750 train_time:721790ms step_avg:472.07ms
[train step 1529] avg_loss=3.288134 main=2.840525 aux=0.447609 imp_cv2=0.1249 load_cv2=5.1011 usage_frac=0.4241 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=12.7744
step:1530/1750 train_time:722238ms step_avg:472.05ms
[train step 1530] avg_loss=3.108780 main=2.661135 aux=0.447645 imp_cv2=0.1601 load_cv2=5.0789 usage_frac=0.4196 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=12.7744
step:1531/1750 train_time:722699ms step_avg:472.04ms
[train step 1531] avg_loss=3.484102 main=3.025982 aux=0.458119 imp_cv2=0.1088 load_cv2=5.2456 usage_frac=0.4241 topk_prob_mean=0.2600 ema_alpha_reverse=nan max_logit=12.7744
step:1532/1750 train_time:723156ms step_avg:472.03ms
[train step 1532] avg_loss=3.501694 main=3.043664 aux=0.458030 imp_cv2=0.1247 load_cv2=5.2320 usage_frac=0.4241 topk_prob_mean=0.2675 ema_alpha_reverse=nan max_logit=12.7744
step:1533/1750 train_time:723613ms step_avg:472.02ms
[train step 1533] avg_loss=3.010458 main=2.565528 aux=0.444930 imp_cv2=0.1790 load_cv2=5.0286 usage_frac=0.4196 topk_prob_mean=0.2952 ema_alpha_reverse=nan max_logit=12.7744
step:1534/1750 train_time:724068ms step_avg:472.01ms
[train step 1534] avg_loss=3.486995 main=3.010618 aux=0.476377 imp_cv2=0.0733 load_cv2=5.4794 usage_frac=0.4241 topk_prob_mean=0.2320 ema_alpha_reverse=nan max_logit=12.7744
step:1535/1750 train_time:724524ms step_avg:472.00ms
[train step 1535] avg_loss=3.065524 main=2.619690 aux=0.445834 imp_cv2=0.1563 load_cv2=5.0598 usage_frac=0.4286 topk_prob_mean=0.2866 ema_alpha_reverse=nan max_logit=12.7744
step:1536/1750 train_time:724991ms step_avg:472.00ms
[train step 1536] avg_loss=3.217261 main=2.765278 aux=0.451983 imp_cv2=0.1238 load_cv2=5.1574 usage_frac=0.4241 topk_prob_mean=0.2717 ema_alpha_reverse=nan max_logit=12.7744
step:1537/1750 train_time:725456ms step_avg:471.99ms
[train step 1537] avg_loss=2.868937 main=2.431015 aux=0.437922 imp_cv2=0.2116 load_cv2=4.9158 usage_frac=0.4241 topk_prob_mean=0.3085 ema_alpha_reverse=nan max_logit=12.7744
step:1538/1750 train_time:725932ms step_avg:472.00ms
[train step 1538] avg_loss=3.242204 main=2.789048 aux=0.453156 imp_cv2=0.1393 load_cv2=5.1697 usage_frac=0.4241 topk_prob_mean=0.2765 ema_alpha_reverse=nan max_logit=12.7744
step:1539/1750 train_time:726392ms step_avg:471.99ms
[train step 1539] avg_loss=4.020474 main=3.530668 aux=0.489807 imp_cv2=0.0614 load_cv2=5.6603 usage_frac=0.4241 topk_prob_mean=0.2169 ema_alpha_reverse=nan max_logit=12.7744
step:1540/1750 train_time:726843ms step_avg:471.98ms
[train step 1540] avg_loss=3.442362 main=2.961472 aux=0.480890 imp_cv2=0.0669 load_cv2=5.5422 usage_frac=0.4241 topk_prob_mean=0.2242 ema_alpha_reverse=nan max_logit=12.7744
step:1541/1750 train_time:727297ms step_avg:471.96ms
[train step 1541] avg_loss=2.986697 main=2.536568 aux=0.450129 imp_cv2=0.1456 load_cv2=5.1232 usage_frac=0.4241 topk_prob_mean=0.2800 ema_alpha_reverse=nan max_logit=12.7744
step:1542/1750 train_time:727754ms step_avg:471.95ms
[train step 1542] avg_loss=3.232473 main=2.773017 aux=0.459456 imp_cv2=0.1074 load_cv2=5.2691 usage_frac=0.4241 topk_prob_mean=0.2578 ema_alpha_reverse=nan max_logit=12.7744
step:1543/1750 train_time:728199ms step_avg:471.94ms
[train step 1543] avg_loss=3.515144 main=3.045739 aux=0.469405 imp_cv2=0.0832 load_cv2=5.4068 usage_frac=0.4241 topk_prob_mean=0.2435 ema_alpha_reverse=nan max_logit=12.7744
step:1544/1750 train_time:728665ms step_avg:471.93ms
[train step 1544] avg_loss=3.155754 main=2.702671 aux=0.453083 imp_cv2=0.1282 load_cv2=5.1724 usage_frac=0.4241 topk_prob_mean=0.2732 ema_alpha_reverse=nan max_logit=12.7744
step:1545/1750 train_time:729121ms step_avg:471.92ms
[train step 1545] avg_loss=2.921669 main=2.478617 aux=0.443052 imp_cv2=0.2169 load_cv2=4.9744 usage_frac=0.4241 topk_prob_mean=0.3093 ema_alpha_reverse=nan max_logit=12.7744
step:1546/1750 train_time:729585ms step_avg:471.92ms
[train step 1546] avg_loss=3.102233 main=2.635241 aux=0.466993 imp_cv2=0.0893 load_cv2=5.3563 usage_frac=0.4196 topk_prob_mean=0.2484 ema_alpha_reverse=nan max_logit=12.7744
step:1547/1750 train_time:730037ms step_avg:471.91ms
[train step 1547] avg_loss=3.166933 main=2.708822 aux=0.458111 imp_cv2=0.1129 load_cv2=5.2434 usage_frac=0.4241 topk_prob_mean=0.2651 ema_alpha_reverse=nan max_logit=12.7744
step:1548/1750 train_time:730497ms step_avg:471.90ms
[train step 1548] avg_loss=2.949758 main=2.510106 aux=0.439652 imp_cv2=0.2242 load_cv2=4.9244 usage_frac=0.4241 topk_prob_mean=0.3118 ema_alpha_reverse=nan max_logit=12.7744
step:1549/1750 train_time:730959ms step_avg:471.89ms
[train step 1549] avg_loss=2.970114 main=2.531452 aux=0.438662 imp_cv2=0.1820 load_cv2=4.9478 usage_frac=0.4241 topk_prob_mean=0.3012 ema_alpha_reverse=nan max_logit=12.7744
step:1550/1750 train_time:731417ms step_avg:471.88ms
Running validation...
step:1550/1750 val_loss:2.894742 train_time:731429ms step_avg:471.89ms
[train step 1550] avg_loss=2.727974 main=2.287580 aux=0.440394 imp_cv2=0.2638 load_cv2=4.9013 usage_frac=0.4241 topk_prob_mean=0.3251 ema_alpha_reverse=nan max_logit=12.7744
step:1551/1750 train_time:731889ms step_avg:471.88ms
[train step 1551] avg_loss=3.078972 main=2.635666 aux=0.443306 imp_cv2=0.1941 load_cv2=4.9872 usage_frac=0.4241 topk_prob_mean=0.3026 ema_alpha_reverse=nan max_logit=12.7744
step:1552/1750 train_time:732363ms step_avg:471.88ms
[train step 1552] avg_loss=3.375759 main=2.918597 aux=0.457162 imp_cv2=0.1162 load_cv2=5.2285 usage_frac=0.4241 topk_prob_mean=0.2664 ema_alpha_reverse=nan max_logit=12.7744
step:1553/1750 train_time:732819ms step_avg:471.87ms
[train step 1553] avg_loss=3.138964 main=2.687543 aux=0.451421 imp_cv2=0.1351 load_cv2=5.1484 usage_frac=0.4241 topk_prob_mean=0.2757 ema_alpha_reverse=nan max_logit=12.7744
step:1554/1750 train_time:733478ms step_avg:471.99ms
[train step 1554] avg_loss=2.997507 main=2.552262 aux=0.445245 imp_cv2=0.1949 load_cv2=5.0242 usage_frac=0.4196 topk_prob_mean=0.3001 ema_alpha_reverse=nan max_logit=12.7744
step:1555/1750 train_time:733939ms step_avg:471.99ms
[train step 1555] avg_loss=3.268314 main=2.810271 aux=0.458043 imp_cv2=0.1072 load_cv2=5.2375 usage_frac=0.4241 topk_prob_mean=0.2585 ema_alpha_reverse=nan max_logit=12.7744
step:1556/1750 train_time:734405ms step_avg:471.98ms
[train step 1556] avg_loss=3.227244 main=2.768059 aux=0.459185 imp_cv2=0.1257 load_cv2=5.2516 usage_frac=0.4241 topk_prob_mean=0.2695 ema_alpha_reverse=nan max_logit=12.7744
step:1557/1750 train_time:734870ms step_avg:471.98ms
[train step 1557] avg_loss=3.659768 main=3.201759 aux=0.458009 imp_cv2=0.1093 load_cv2=5.2366 usage_frac=0.4241 topk_prob_mean=0.2585 ema_alpha_reverse=nan max_logit=12.7744
step:1558/1750 train_time:735330ms step_avg:471.97ms
[train step 1558] avg_loss=3.454055 main=2.986970 aux=0.467085 imp_cv2=0.0983 load_cv2=5.3675 usage_frac=0.4241 topk_prob_mean=0.2519 ema_alpha_reverse=nan max_logit=12.7744
step:1559/1750 train_time:735796ms step_avg:471.97ms
[train step 1559] avg_loss=3.575081 main=3.118095 aux=0.456986 imp_cv2=0.1222 load_cv2=5.2163 usage_frac=0.4241 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=12.7744
step:1560/1750 train_time:736258ms step_avg:471.96ms
[train step 1560] avg_loss=3.520895 main=3.069724 aux=0.451171 imp_cv2=0.1135 load_cv2=5.1587 usage_frac=0.4241 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=12.7744
step:1561/1750 train_time:736712ms step_avg:471.95ms
[train step 1561] avg_loss=2.896216 main=2.454158 aux=0.442058 imp_cv2=0.1607 load_cv2=5.0114 usage_frac=0.4286 topk_prob_mean=0.2910 ema_alpha_reverse=nan max_logit=12.7744
step:1562/1750 train_time:737173ms step_avg:471.94ms
[train step 1562] avg_loss=3.150004 main=2.695272 aux=0.454732 imp_cv2=0.1052 load_cv2=5.2124 usage_frac=0.4241 topk_prob_mean=0.2623 ema_alpha_reverse=nan max_logit=12.7744
step:1563/1750 train_time:737627ms step_avg:471.93ms
[train step 1563] avg_loss=3.548276 main=3.079702 aux=0.468573 imp_cv2=0.0720 load_cv2=5.4015 usage_frac=0.4241 topk_prob_mean=0.2371 ema_alpha_reverse=nan max_logit=12.7744
step:1564/1750 train_time:738087ms step_avg:471.92ms
[train step 1564] avg_loss=3.047435 main=2.600051 aux=0.447384 imp_cv2=0.1251 load_cv2=5.1059 usage_frac=0.4241 topk_prob_mean=0.2747 ema_alpha_reverse=nan max_logit=12.7744
step:1565/1750 train_time:738550ms step_avg:471.92ms
[train step 1565] avg_loss=3.113867 main=2.660504 aux=0.453362 imp_cv2=0.1170 load_cv2=5.1876 usage_frac=0.4241 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=12.7744
step:1566/1750 train_time:739200ms step_avg:472.03ms
[train step 1566] avg_loss=3.424813 main=2.969220 aux=0.455593 imp_cv2=0.0923 load_cv2=5.2201 usage_frac=0.4241 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=12.7744
step:1567/1750 train_time:739662ms step_avg:472.02ms
[train step 1567] avg_loss=3.179800 main=2.731049 aux=0.448751 imp_cv2=0.1076 load_cv2=5.1339 usage_frac=0.4241 topk_prob_mean=0.2661 ema_alpha_reverse=nan max_logit=12.7744
step:1568/1750 train_time:740121ms step_avg:472.02ms
[train step 1568] avg_loss=3.286869 main=2.837963 aux=0.448906 imp_cv2=0.1364 load_cv2=5.1173 usage_frac=0.4241 topk_prob_mean=0.2767 ema_alpha_reverse=nan max_logit=12.7744
step:1569/1750 train_time:740581ms step_avg:472.01ms
[train step 1569] avg_loss=3.245177 main=2.801132 aux=0.444045 imp_cv2=0.1332 load_cv2=5.0579 usage_frac=0.4196 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=12.7744
step:1570/1750 train_time:741033ms step_avg:472.00ms
[train step 1570] avg_loss=3.935154 main=3.468114 aux=0.467040 imp_cv2=0.0762 load_cv2=5.3721 usage_frac=0.4241 topk_prob_mean=0.2411 ema_alpha_reverse=nan max_logit=12.7744
step:1571/1750 train_time:741496ms step_avg:471.99ms
[train step 1571] avg_loss=3.253474 main=2.808456 aux=0.445019 imp_cv2=0.1322 load_cv2=5.0695 usage_frac=0.4241 topk_prob_mean=0.2788 ema_alpha_reverse=nan max_logit=12.7744
step:1572/1750 train_time:741962ms step_avg:471.99ms
[train step 1572] avg_loss=3.036171 main=2.592231 aux=0.443940 imp_cv2=0.1587 load_cv2=5.0390 usage_frac=0.4241 topk_prob_mean=0.2899 ema_alpha_reverse=nan max_logit=12.7744
step:1573/1750 train_time:742418ms step_avg:471.98ms
[train step 1573] avg_loss=3.158304 main=2.707455 aux=0.450849 imp_cv2=0.1277 load_cv2=5.1501 usage_frac=0.4241 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=12.7744
step:1574/1750 train_time:742868ms step_avg:471.96ms
[train step 1574] avg_loss=3.738383 main=3.214049 aux=0.524333 imp_cv2=0.0549 load_cv2=6.0602 usage_frac=0.4152 topk_prob_mean=0.1814 ema_alpha_reverse=nan max_logit=12.7744
step:1575/1750 train_time:743326ms step_avg:471.95ms
[train step 1575] avg_loss=3.314740 main=2.871203 aux=0.443537 imp_cv2=0.1435 load_cv2=5.0381 usage_frac=0.4241 topk_prob_mean=0.2841 ema_alpha_reverse=nan max_logit=12.7744
step:1576/1750 train_time:743788ms step_avg:471.95ms
[train step 1576] avg_loss=3.856167 main=3.376564 aux=0.479602 imp_cv2=0.0609 load_cv2=5.5475 usage_frac=0.4286 topk_prob_mean=0.2237 ema_alpha_reverse=nan max_logit=12.7744
step:1577/1750 train_time:744259ms step_avg:471.95ms
[train step 1577] avg_loss=3.216975 main=2.771460 aux=0.445515 imp_cv2=0.1266 load_cv2=5.0854 usage_frac=0.4241 topk_prob_mean=0.2761 ema_alpha_reverse=nan max_logit=12.7744
step:1578/1750 train_time:744712ms step_avg:471.93ms
[train step 1578] avg_loss=3.407532 main=2.959450 aux=0.448082 imp_cv2=0.1381 load_cv2=5.1074 usage_frac=0.4196 topk_prob_mean=0.2786 ema_alpha_reverse=nan max_logit=12.7744
step:1579/1750 train_time:745164ms step_avg:471.92ms
[train step 1579] avg_loss=3.302790 main=2.831793 aux=0.470997 imp_cv2=0.0733 load_cv2=5.4289 usage_frac=0.4241 topk_prob_mean=0.2377 ema_alpha_reverse=nan max_logit=12.7744
step:1580/1750 train_time:745614ms step_avg:471.91ms
[train step 1580] avg_loss=3.124995 main=2.672575 aux=0.452420 imp_cv2=0.1244 load_cv2=5.1654 usage_frac=0.4241 topk_prob_mean=0.2711 ema_alpha_reverse=nan max_logit=12.7744
step:1581/1750 train_time:746089ms step_avg:471.91ms
[train step 1581] avg_loss=3.879413 main=3.404298 aux=0.475115 imp_cv2=0.0766 load_cv2=5.4794 usage_frac=0.4286 topk_prob_mean=0.2359 ema_alpha_reverse=nan max_logit=12.7744
step:1582/1750 train_time:746545ms step_avg:471.90ms
[train step 1582] avg_loss=4.121309 main=3.618692 aux=0.502617 imp_cv2=0.0673 load_cv2=5.7879 usage_frac=0.4286 topk_prob_mean=0.2068 ema_alpha_reverse=nan max_logit=12.7744
step:1583/1750 train_time:746997ms step_avg:471.89ms
[train step 1583] avg_loss=3.835184 main=3.354968 aux=0.480215 imp_cv2=0.0689 load_cv2=5.5346 usage_frac=0.4241 topk_prob_mean=0.2271 ema_alpha_reverse=nan max_logit=12.7744
step:1584/1750 train_time:747453ms step_avg:471.88ms
[train step 1584] avg_loss=3.482989 main=3.010709 aux=0.472280 imp_cv2=0.0829 load_cv2=5.4272 usage_frac=0.4241 topk_prob_mean=0.2385 ema_alpha_reverse=nan max_logit=12.7744
step:1585/1750 train_time:747914ms step_avg:471.87ms
[train step 1585] avg_loss=3.134733 main=2.687173 aux=0.447560 imp_cv2=0.1502 load_cv2=5.0867 usage_frac=0.4286 topk_prob_mean=0.2846 ema_alpha_reverse=nan max_logit=12.7744
step:1586/1750 train_time:748377ms step_avg:471.86ms
[train step 1586] avg_loss=3.583546 main=3.119956 aux=0.463590 imp_cv2=0.0914 load_cv2=5.3222 usage_frac=0.4196 topk_prob_mean=0.2502 ema_alpha_reverse=nan max_logit=12.7744
step:1587/1750 train_time:748835ms step_avg:471.86ms
[train step 1587] avg_loss=3.008698 main=2.559155 aux=0.449543 imp_cv2=0.1642 load_cv2=5.1014 usage_frac=0.4241 topk_prob_mean=0.2879 ema_alpha_reverse=nan max_logit=12.7744
step:1588/1750 train_time:749299ms step_avg:471.85ms
[train step 1588] avg_loss=3.016128 main=2.568291 aux=0.447837 imp_cv2=0.1578 load_cv2=5.0783 usage_frac=0.4241 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=12.7744
step:1589/1750 train_time:749758ms step_avg:471.84ms
[train step 1589] avg_loss=3.231308 main=2.782273 aux=0.449035 imp_cv2=0.1337 load_cv2=5.1173 usage_frac=0.4196 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=12.7744
step:1590/1750 train_time:750213ms step_avg:471.83ms
[train step 1590] avg_loss=3.392076 main=2.942742 aux=0.449334 imp_cv2=0.1313 load_cv2=5.1177 usage_frac=0.4241 topk_prob_mean=0.2761 ema_alpha_reverse=nan max_logit=12.7744
step:1591/1750 train_time:750672ms step_avg:471.82ms
[train step 1591] avg_loss=3.074761 main=2.616698 aux=0.458063 imp_cv2=0.1198 load_cv2=5.2425 usage_frac=0.4241 topk_prob_mean=0.2665 ema_alpha_reverse=nan max_logit=12.7744
step:1592/1750 train_time:751123ms step_avg:471.81ms
[train step 1592] avg_loss=3.348304 main=2.877294 aux=0.471010 imp_cv2=0.0900 load_cv2=5.4161 usage_frac=0.4241 topk_prob_mean=0.2469 ema_alpha_reverse=nan max_logit=12.7744
step:1593/1750 train_time:751577ms step_avg:471.80ms
[train step 1593] avg_loss=3.359384 main=2.903111 aux=0.456272 imp_cv2=0.1057 load_cv2=5.2237 usage_frac=0.4196 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=12.7744
step:1594/1750 train_time:752037ms step_avg:471.79ms
[train step 1594] avg_loss=3.323084 main=2.816312 aux=0.506772 imp_cv2=0.0567 load_cv2=5.8586 usage_frac=0.4241 topk_prob_mean=0.1990 ema_alpha_reverse=nan max_logit=12.7744
step:1595/1750 train_time:752494ms step_avg:471.78ms
[train step 1595] avg_loss=3.783094 main=3.285989 aux=0.497105 imp_cv2=0.0622 load_cv2=5.7343 usage_frac=0.4241 topk_prob_mean=0.2137 ema_alpha_reverse=nan max_logit=12.7744
step:1596/1750 train_time:752947ms step_avg:471.77ms
[train step 1596] avg_loss=3.324517 main=2.853546 aux=0.470971 imp_cv2=0.0869 load_cv2=5.4104 usage_frac=0.4241 topk_prob_mean=0.2449 ema_alpha_reverse=nan max_logit=12.7744
step:1597/1750 train_time:753403ms step_avg:471.76ms
[train step 1597] avg_loss=3.092360 main=2.645652 aux=0.446708 imp_cv2=0.1747 load_cv2=5.0563 usage_frac=0.4241 topk_prob_mean=0.2932 ema_alpha_reverse=nan max_logit=12.7744
step:1598/1750 train_time:753858ms step_avg:471.75ms
[train step 1598] avg_loss=2.955066 main=2.507963 aux=0.447104 imp_cv2=0.1801 load_cv2=5.0574 usage_frac=0.4241 topk_prob_mean=0.2951 ema_alpha_reverse=nan max_logit=12.7744
step:1599/1750 train_time:754316ms step_avg:471.74ms
[train step 1599] avg_loss=2.877381 main=2.429032 aux=0.448350 imp_cv2=0.1870 load_cv2=5.0642 usage_frac=0.4286 topk_prob_mean=0.2977 ema_alpha_reverse=nan max_logit=12.7744
step:1600/1750 train_time:754974ms step_avg:471.86ms
Running validation...
step:1600/1750 val_loss:2.874102 train_time:754986ms step_avg:471.87ms
[train step 1600] avg_loss=3.745577 main=3.272914 aux=0.472663 imp_cv2=0.0781 load_cv2=5.4433 usage_frac=0.4241 topk_prob_mean=0.2388 ema_alpha_reverse=nan max_logit=12.7744
step:1601/1750 train_time:755430ms step_avg:471.85ms
[train step 1601] avg_loss=3.443051 main=2.981647 aux=0.461403 imp_cv2=0.1061 load_cv2=5.2850 usage_frac=0.4196 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=12.7744
step:1602/1750 train_time:755891ms step_avg:471.84ms
[train step 1602] avg_loss=3.497340 main=3.017814 aux=0.479526 imp_cv2=0.0716 load_cv2=5.5368 usage_frac=0.4241 topk_prob_mean=0.2331 ema_alpha_reverse=nan max_logit=12.7744
step:1603/1750 train_time:756341ms step_avg:471.83ms
[train step 1603] avg_loss=2.954534 main=2.504074 aux=0.450460 imp_cv2=0.2064 load_cv2=5.0737 usage_frac=0.4241 topk_prob_mean=0.2999 ema_alpha_reverse=nan max_logit=12.7744
step:1604/1750 train_time:756796ms step_avg:471.82ms
[train step 1604] avg_loss=3.600063 main=3.135229 aux=0.464834 imp_cv2=0.1018 load_cv2=5.3326 usage_frac=0.4330 topk_prob_mean=0.2545 ema_alpha_reverse=nan max_logit=12.7744
step:1605/1750 train_time:757259ms step_avg:471.81ms
[train step 1605] avg_loss=3.349570 main=2.885118 aux=0.464453 imp_cv2=0.1003 load_cv2=5.3306 usage_frac=0.4241 topk_prob_mean=0.2562 ema_alpha_reverse=nan max_logit=12.7744
step:1606/1750 train_time:757725ms step_avg:471.81ms
[train step 1606] avg_loss=3.294884 main=2.833222 aux=0.461662 imp_cv2=0.1023 load_cv2=5.2976 usage_frac=0.4241 topk_prob_mean=0.2573 ema_alpha_reverse=nan max_logit=12.7744
step:1607/1750 train_time:758188ms step_avg:471.80ms
[train step 1607] avg_loss=3.214871 main=2.756779 aux=0.458092 imp_cv2=0.1247 load_cv2=5.2384 usage_frac=0.4241 topk_prob_mean=0.2687 ema_alpha_reverse=nan max_logit=12.7744
step:1608/1750 train_time:758850ms step_avg:471.92ms
[train step 1608] avg_loss=3.281034 main=2.808569 aux=0.472465 imp_cv2=0.0984 load_cv2=5.4434 usage_frac=0.4196 topk_prob_mean=0.2525 ema_alpha_reverse=nan max_logit=12.7744
step:1609/1750 train_time:759300ms step_avg:471.91ms
[train step 1609] avg_loss=3.033007 main=2.581602 aux=0.451404 imp_cv2=0.1498 load_cv2=5.1290 usage_frac=0.4241 topk_prob_mean=0.2836 ema_alpha_reverse=nan max_logit=12.7744
step:1610/1750 train_time:759758ms step_avg:471.90ms
[train step 1610] avg_loss=3.881679 main=3.371427 aux=0.510252 imp_cv2=0.0770 load_cv2=5.8882 usage_frac=0.4241 topk_prob_mean=0.2056 ema_alpha_reverse=nan max_logit=12.7744
step:1611/1750 train_time:760212ms step_avg:471.89ms
[train step 1611] avg_loss=2.983832 main=2.540890 aux=0.442941 imp_cv2=0.1900 load_cv2=4.9976 usage_frac=0.4241 topk_prob_mean=0.3008 ema_alpha_reverse=nan max_logit=12.7744
step:1612/1750 train_time:760674ms step_avg:471.88ms
[train step 1612] avg_loss=3.403391 main=2.936523 aux=0.466868 imp_cv2=0.0827 load_cv2=5.3707 usage_frac=0.4196 topk_prob_mean=0.2465 ema_alpha_reverse=nan max_logit=12.7744
step:1613/1750 train_time:761137ms step_avg:471.88ms
[train step 1613] avg_loss=3.438814 main=2.983906 aux=0.454908 imp_cv2=0.1099 load_cv2=5.2045 usage_frac=0.4241 topk_prob_mean=0.2651 ema_alpha_reverse=nan max_logit=12.7744
step:1614/1750 train_time:761590ms step_avg:471.87ms
[train step 1614] avg_loss=3.489715 main=3.040282 aux=0.449432 imp_cv2=0.1201 load_cv2=5.1289 usage_frac=0.4241 topk_prob_mean=0.2726 ema_alpha_reverse=nan max_logit=12.7744
step:1615/1750 train_time:762051ms step_avg:471.86ms
[train step 1615] avg_loss=3.421013 main=2.963453 aux=0.457561 imp_cv2=0.1114 load_cv2=5.2395 usage_frac=0.4241 topk_prob_mean=0.2627 ema_alpha_reverse=nan max_logit=12.7744
step:1616/1750 train_time:762507ms step_avg:471.85ms
[train step 1616] avg_loss=3.181083 main=2.735527 aux=0.445556 imp_cv2=0.1469 load_cv2=5.0632 usage_frac=0.4241 topk_prob_mean=0.2839 ema_alpha_reverse=nan max_logit=12.7744
step:1617/1750 train_time:762974ms step_avg:471.85ms
[train step 1617] avg_loss=3.165332 main=2.720465 aux=0.444867 imp_cv2=0.1440 load_cv2=5.0566 usage_frac=0.4286 topk_prob_mean=0.2831 ema_alpha_reverse=nan max_logit=12.7744
step:1618/1750 train_time:763438ms step_avg:471.84ms
[train step 1618] avg_loss=3.450894 main=2.993417 aux=0.457477 imp_cv2=0.0979 load_cv2=5.2414 usage_frac=0.4196 topk_prob_mean=0.2555 ema_alpha_reverse=nan max_logit=12.7744
step:1619/1750 train_time:763899ms step_avg:471.83ms
[train step 1619] avg_loss=2.872577 main=2.435854 aux=0.436723 imp_cv2=0.1754 load_cv2=4.9341 usage_frac=0.4196 topk_prob_mean=0.2990 ema_alpha_reverse=nan max_logit=12.7744
step:1620/1750 train_time:764361ms step_avg:471.83ms
[train step 1620] avg_loss=3.550222 main=3.084335 aux=0.465888 imp_cv2=0.0722 load_cv2=5.3663 usage_frac=0.4196 topk_prob_mean=0.2390 ema_alpha_reverse=nan max_logit=12.7744
step:1621/1750 train_time:764821ms step_avg:471.82ms
[train step 1621] avg_loss=3.175211 main=2.732657 aux=0.442553 imp_cv2=0.1301 load_cv2=5.0415 usage_frac=0.4196 topk_prob_mean=0.2796 ema_alpha_reverse=nan max_logit=12.7744
step:1622/1750 train_time:765278ms step_avg:471.81ms
[train step 1622] avg_loss=3.514191 main=3.047831 aux=0.466360 imp_cv2=0.0770 load_cv2=5.3848 usage_frac=0.4152 topk_prob_mean=0.2440 ema_alpha_reverse=nan max_logit=12.7744
step:1623/1750 train_time:765731ms step_avg:471.80ms
[train step 1623] avg_loss=3.211450 main=2.766847 aux=0.444603 imp_cv2=0.1306 load_cv2=5.0680 usage_frac=0.4241 topk_prob_mean=0.2793 ema_alpha_reverse=nan max_logit=12.7744
step:1624/1750 train_time:766190ms step_avg:471.79ms
[train step 1624] avg_loss=3.352304 main=2.875174 aux=0.477131 imp_cv2=0.0694 load_cv2=5.4850 usage_frac=0.4241 topk_prob_mean=0.2299 ema_alpha_reverse=nan max_logit=12.7744
step:1625/1750 train_time:766649ms step_avg:471.78ms
[train step 1625] avg_loss=6.187532 main=5.678402 aux=0.509130 imp_cv2=0.1062 load_cv2=5.8344 usage_frac=0.3884 topk_prob_mean=0.2001 ema_alpha_reverse=nan max_logit=10.8091
step:1626/1750 train_time:767113ms step_avg:471.78ms
[train step 1626] avg_loss=3.207173 main=2.752473 aux=0.454700 imp_cv2=0.0885 load_cv2=5.2154 usage_frac=0.4196 topk_prob_mean=0.2536 ema_alpha_reverse=nan max_logit=12.7744
step:1627/1750 train_time:767567ms step_avg:471.77ms
[train step 1627] avg_loss=3.247536 main=2.799542 aux=0.447994 imp_cv2=0.1064 load_cv2=5.1290 usage_frac=0.4241 topk_prob_mean=0.2684 ema_alpha_reverse=nan max_logit=12.7744
step:1628/1750 train_time:768031ms step_avg:471.76ms
[train step 1628] avg_loss=3.237762 main=2.801294 aux=0.436468 imp_cv2=0.1609 load_cv2=4.9378 usage_frac=0.4286 topk_prob_mean=0.2950 ema_alpha_reverse=nan max_logit=12.7744
step:1629/1750 train_time:768494ms step_avg:471.76ms
[train step 1629] avg_loss=3.815303 main=3.274771 aux=0.540533 imp_cv2=0.0476 load_cv2=6.2596 usage_frac=0.3884 topk_prob_mean=0.1655 ema_alpha_reverse=nan max_logit=11.1676
step:1630/1750 train_time:768956ms step_avg:471.75ms
[train step 1630] avg_loss=3.052498 main=2.608609 aux=0.443889 imp_cv2=0.1409 load_cv2=5.0581 usage_frac=0.4196 topk_prob_mean=0.2854 ema_alpha_reverse=nan max_logit=12.7744
step:1631/1750 train_time:769420ms step_avg:471.75ms
[train step 1631] avg_loss=4.015286 main=3.501811 aux=0.513475 imp_cv2=0.0473 load_cv2=5.9520 usage_frac=0.4196 topk_prob_mean=0.1935 ema_alpha_reverse=nan max_logit=12.7744
step:1632/1750 train_time:769867ms step_avg:471.73ms
[train step 1632] avg_loss=3.157821 main=2.718183 aux=0.439638 imp_cv2=0.1221 load_cv2=5.0092 usage_frac=0.4241 topk_prob_mean=0.2797 ema_alpha_reverse=nan max_logit=12.7744
step:1633/1750 train_time:770322ms step_avg:471.72ms
[train step 1633] avg_loss=2.952604 main=2.518598 aux=0.434005 imp_cv2=0.2175 load_cv2=4.8654 usage_frac=0.4241 topk_prob_mean=0.3152 ema_alpha_reverse=nan max_logit=12.7744
step:1634/1750 train_time:770804ms step_avg:471.73ms
[train step 1634] avg_loss=3.317872 main=2.878112 aux=0.439760 imp_cv2=0.1282 load_cv2=5.0112 usage_frac=0.4196 topk_prob_mean=0.2808 ema_alpha_reverse=nan max_logit=12.7744
step:1635/1750 train_time:771262ms step_avg:471.72ms
[train step 1635] avg_loss=3.107706 main=2.665418 aux=0.442288 imp_cv2=0.1473 load_cv2=5.0283 usage_frac=0.4286 topk_prob_mean=0.2894 ema_alpha_reverse=nan max_logit=12.7744
step:1636/1750 train_time:771721ms step_avg:471.71ms
[train step 1636] avg_loss=3.349306 main=2.896537 aux=0.452770 imp_cv2=0.0933 load_cv2=5.1946 usage_frac=0.4241 topk_prob_mean=0.2588 ema_alpha_reverse=nan max_logit=12.7744
step:1637/1750 train_time:772171ms step_avg:471.70ms
[train step 1637] avg_loss=4.962525 main=4.440586 aux=0.521940 imp_cv2=0.0853 load_cv2=5.9886 usage_frac=0.3929 topk_prob_mean=0.1857 ema_alpha_reverse=nan max_logit=11.7917
step:1638/1750 train_time:772633ms step_avg:471.69ms
[train step 1638] avg_loss=3.231820 main=2.760841 aux=0.470979 imp_cv2=0.0676 load_cv2=5.4331 usage_frac=0.4196 topk_prob_mean=0.2352 ema_alpha_reverse=nan max_logit=12.7744
step:1639/1750 train_time:773094ms step_avg:471.69ms
[train step 1639] avg_loss=3.206153 main=2.754021 aux=0.452131 imp_cv2=0.1218 load_cv2=5.1623 usage_frac=0.4241 topk_prob_mean=0.2704 ema_alpha_reverse=nan max_logit=12.7744
step:1640/1750 train_time:773555ms step_avg:471.68ms
[train step 1640] avg_loss=3.180653 main=2.729512 aux=0.451140 imp_cv2=0.1083 load_cv2=5.1707 usage_frac=0.4241 topk_prob_mean=0.2668 ema_alpha_reverse=nan max_logit=12.7744
step:1641/1750 train_time:774010ms step_avg:471.67ms
[train step 1641] avg_loss=3.735009 main=3.282779 aux=0.452230 imp_cv2=0.0878 load_cv2=5.1897 usage_frac=0.4241 topk_prob_mean=0.2579 ema_alpha_reverse=nan max_logit=12.7744
step:1642/1750 train_time:774469ms step_avg:471.66ms
[train step 1642] avg_loss=3.425364 main=2.965202 aux=0.460162 imp_cv2=0.0911 load_cv2=5.2800 usage_frac=0.4241 topk_prob_mean=0.2473 ema_alpha_reverse=nan max_logit=12.7744
step:1643/1750 train_time:774930ms step_avg:471.66ms
[train step 1643] avg_loss=3.230831 main=2.789192 aux=0.441639 imp_cv2=0.1482 load_cv2=5.0263 usage_frac=0.4241 topk_prob_mean=0.2854 ema_alpha_reverse=nan max_logit=12.7744
step:1644/1750 train_time:775391ms step_avg:471.65ms
[train step 1644] avg_loss=2.865124 main=2.430125 aux=0.434999 imp_cv2=0.1852 load_cv2=4.9081 usage_frac=0.4196 topk_prob_mean=0.3045 ema_alpha_reverse=nan max_logit=12.7744
step:1645/1750 train_time:775857ms step_avg:471.65ms
[train step 1645] avg_loss=3.855692 main=3.356702 aux=0.498990 imp_cv2=0.0470 load_cv2=5.7799 usage_frac=0.4241 topk_prob_mean=0.2003 ema_alpha_reverse=nan max_logit=12.7744
step:1646/1750 train_time:776318ms step_avg:471.64ms
[train step 1646] avg_loss=2.857105 main=2.421010 aux=0.436096 imp_cv2=0.1684 load_cv2=4.9295 usage_frac=0.4241 topk_prob_mean=0.2979 ema_alpha_reverse=nan max_logit=12.7744
step:1647/1750 train_time:776784ms step_avg:471.64ms
[train step 1647] avg_loss=2.998562 main=2.560197 aux=0.438366 imp_cv2=0.1694 load_cv2=4.9604 usage_frac=0.4152 topk_prob_mean=0.2975 ema_alpha_reverse=nan max_logit=12.7744
step:1648/1750 train_time:777252ms step_avg:471.63ms
[train step 1648] avg_loss=3.141638 main=2.699193 aux=0.442445 imp_cv2=0.1324 load_cv2=5.0426 usage_frac=0.4241 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=12.7744
step:1649/1750 train_time:777720ms step_avg:471.63ms
[train step 1649] avg_loss=3.202547 main=2.754229 aux=0.448318 imp_cv2=0.1103 load_cv2=5.1306 usage_frac=0.4196 topk_prob_mean=0.2704 ema_alpha_reverse=nan max_logit=12.7744
step:1650/1750 train_time:778175ms step_avg:471.62ms
Running validation...
step:1650/1750 val_loss:2.857809 train_time:778187ms step_avg:471.63ms
[train step 1650] avg_loss=2.749662 main=2.310608 aux=0.439054 imp_cv2=0.1580 load_cv2=4.9789 usage_frac=0.4241 topk_prob_mean=0.2910 ema_alpha_reverse=nan max_logit=12.7744
step:1651/1750 train_time:778642ms step_avg:471.62ms
[train step 1651] avg_loss=3.562656 main=3.100710 aux=0.461946 imp_cv2=0.0889 load_cv2=5.3181 usage_frac=0.4196 topk_prob_mean=0.2513 ema_alpha_reverse=nan max_logit=12.7744
step:1652/1750 train_time:779105ms step_avg:471.61ms
[train step 1652] avg_loss=3.379567 main=2.925165 aux=0.454402 imp_cv2=0.1115 load_cv2=5.2084 usage_frac=0.4241 topk_prob_mean=0.2662 ema_alpha_reverse=nan max_logit=12.7744
step:1653/1750 train_time:779568ms step_avg:471.61ms
[train step 1653] avg_loss=3.283739 main=2.837137 aux=0.446602 imp_cv2=0.1290 load_cv2=5.0944 usage_frac=0.4196 topk_prob_mean=0.2781 ema_alpha_reverse=nan max_logit=12.7744
step:1654/1750 train_time:780022ms step_avg:471.60ms
[train step 1654] avg_loss=3.132879 main=2.682475 aux=0.450403 imp_cv2=0.1150 load_cv2=5.1512 usage_frac=0.4241 topk_prob_mean=0.2707 ema_alpha_reverse=nan max_logit=12.7744
step:1655/1750 train_time:780478ms step_avg:471.59ms
[train step 1655] avg_loss=4.371169 main=3.906079 aux=0.465090 imp_cv2=0.0744 load_cv2=5.3566 usage_frac=0.4152 topk_prob_mean=0.2445 ema_alpha_reverse=nan max_logit=12.7744
step:1656/1750 train_time:780930ms step_avg:471.58ms
[train step 1656] avg_loss=3.243935 main=2.791179 aux=0.452757 imp_cv2=0.1055 load_cv2=5.1859 usage_frac=0.4286 topk_prob_mean=0.2666 ema_alpha_reverse=nan max_logit=12.7744
step:1657/1750 train_time:781383ms step_avg:471.57ms
[train step 1657] avg_loss=3.361394 main=2.884342 aux=0.477052 imp_cv2=0.0679 load_cv2=5.5071 usage_frac=0.4196 topk_prob_mean=0.2341 ema_alpha_reverse=nan max_logit=12.7744
step:1658/1750 train_time:781841ms step_avg:471.56ms
[train step 1658] avg_loss=3.387348 main=2.925942 aux=0.461406 imp_cv2=0.1002 load_cv2=5.2961 usage_frac=0.4286 topk_prob_mean=0.2576 ema_alpha_reverse=nan max_logit=12.7744
step:1659/1750 train_time:782312ms step_avg:471.56ms
[train step 1659] avg_loss=2.999059 main=2.558273 aux=0.440786 imp_cv2=0.2082 load_cv2=4.9575 usage_frac=0.4241 topk_prob_mean=0.3082 ema_alpha_reverse=nan max_logit=12.7744
step:1660/1750 train_time:782778ms step_avg:471.55ms
[train step 1660] avg_loss=3.310218 main=2.853500 aux=0.456718 imp_cv2=0.1117 load_cv2=5.2368 usage_frac=0.4286 topk_prob_mean=0.2648 ema_alpha_reverse=nan max_logit=12.7744
step:1661/1750 train_time:783241ms step_avg:471.55ms
[train step 1661] avg_loss=2.880165 main=2.439201 aux=0.440964 imp_cv2=0.2027 load_cv2=4.9654 usage_frac=0.4196 topk_prob_mean=0.3066 ema_alpha_reverse=nan max_logit=12.7744
step:1662/1750 train_time:783699ms step_avg:471.54ms
[train step 1662] avg_loss=3.208960 main=2.750991 aux=0.457969 imp_cv2=0.1057 load_cv2=5.2553 usage_frac=0.4241 topk_prob_mean=0.2615 ema_alpha_reverse=nan max_logit=12.7744
step:1663/1750 train_time:784153ms step_avg:471.53ms
[train step 1663] avg_loss=3.684516 main=3.206158 aux=0.478358 imp_cv2=0.0634 load_cv2=5.5338 usage_frac=0.4286 topk_prob_mean=0.2281 ema_alpha_reverse=nan max_logit=12.7744
step:1664/1750 train_time:784607ms step_avg:471.52ms
[train step 1664] avg_loss=3.438136 main=2.971992 aux=0.466144 imp_cv2=0.0708 load_cv2=5.3734 usage_frac=0.4241 topk_prob_mean=0.2418 ema_alpha_reverse=nan max_logit=12.7744
step:1665/1750 train_time:785061ms step_avg:471.51ms
[train step 1665] avg_loss=3.496365 main=3.025127 aux=0.471238 imp_cv2=0.0741 load_cv2=5.4290 usage_frac=0.4241 topk_prob_mean=0.2422 ema_alpha_reverse=nan max_logit=12.7744
step:1666/1750 train_time:785516ms step_avg:471.50ms
[train step 1666] avg_loss=4.450702 main=3.919035 aux=0.531667 imp_cv2=0.0750 load_cv2=6.1119 usage_frac=0.3795 topk_prob_mean=0.1811 ema_alpha_reverse=nan max_logit=10.8091
step:1667/1750 train_time:785979ms step_avg:471.49ms
[train step 1667] avg_loss=3.262420 main=2.803706 aux=0.458714 imp_cv2=0.1022 load_cv2=5.2612 usage_frac=0.4241 topk_prob_mean=0.2612 ema_alpha_reverse=nan max_logit=12.7744
step:1668/1750 train_time:786431ms step_avg:471.48ms
[train step 1668] avg_loss=4.112246 main=3.568655 aux=0.543591 imp_cv2=0.0655 load_cv2=6.2716 usage_frac=0.3884 topk_prob_mean=0.1711 ema_alpha_reverse=nan max_logit=11.7917
step:1669/1750 train_time:786892ms step_avg:471.48ms
[train step 1669] avg_loss=3.519155 main=3.056750 aux=0.462406 imp_cv2=0.0981 load_cv2=5.3174 usage_frac=0.4196 topk_prob_mean=0.2557 ema_alpha_reverse=nan max_logit=12.7744
step:1670/1750 train_time:787347ms step_avg:471.47ms
[train step 1670] avg_loss=3.385048 main=2.933882 aux=0.451166 imp_cv2=0.1147 load_cv2=5.1657 usage_frac=0.4241 topk_prob_mean=0.2692 ema_alpha_reverse=nan max_logit=12.7744
step:1671/1750 train_time:787805ms step_avg:471.46ms
[train step 1671] avg_loss=3.285511 main=2.840780 aux=0.444731 imp_cv2=0.1431 load_cv2=5.0547 usage_frac=0.4241 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=12.7744
step:1672/1750 train_time:788270ms step_avg:471.45ms
[train step 1672] avg_loss=3.356784 main=2.899378 aux=0.457407 imp_cv2=0.1009 load_cv2=5.2501 usage_frac=0.4241 topk_prob_mean=0.2592 ema_alpha_reverse=nan max_logit=12.7744
step:1673/1750 train_time:788729ms step_avg:471.45ms
[train step 1673] avg_loss=3.077030 main=2.635358 aux=0.441672 imp_cv2=0.1628 load_cv2=5.0049 usage_frac=0.4152 topk_prob_mean=0.2904 ema_alpha_reverse=nan max_logit=12.7744
step:1674/1750 train_time:789188ms step_avg:471.44ms
[train step 1674] avg_loss=2.950086 main=2.513596 aux=0.436490 imp_cv2=0.1627 load_cv2=4.9414 usage_frac=0.4286 topk_prob_mean=0.2947 ema_alpha_reverse=nan max_logit=12.7744
step:1675/1750 train_time:789650ms step_avg:471.43ms
[train step 1675] avg_loss=3.134186 main=2.683612 aux=0.450574 imp_cv2=0.1091 load_cv2=5.1569 usage_frac=0.4241 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=12.7744
step:1676/1750 train_time:790103ms step_avg:471.42ms
[train step 1676] avg_loss=3.549117 main=3.093545 aux=0.455573 imp_cv2=0.0852 load_cv2=5.2278 usage_frac=0.4241 topk_prob_mean=0.2527 ema_alpha_reverse=nan max_logit=12.7744
step:1677/1750 train_time:790556ms step_avg:471.41ms
[train step 1677] avg_loss=4.019532 main=3.549423 aux=0.470108 imp_cv2=0.0663 load_cv2=5.4113 usage_frac=0.4241 topk_prob_mean=0.2345 ema_alpha_reverse=nan max_logit=12.7744
step:1678/1750 train_time:791005ms step_avg:471.40ms
[train step 1678] avg_loss=4.196234 main=3.687272 aux=0.508962 imp_cv2=0.0528 load_cv2=5.8862 usage_frac=0.4196 topk_prob_mean=0.1917 ema_alpha_reverse=nan max_logit=12.7744
step:1679/1750 train_time:791460ms step_avg:471.39ms
[train step 1679] avg_loss=3.086482 main=2.641691 aux=0.444791 imp_cv2=0.1466 load_cv2=5.0532 usage_frac=0.4241 topk_prob_mean=0.2824 ema_alpha_reverse=nan max_logit=12.7744
step:1680/1750 train_time:791912ms step_avg:471.38ms
[train step 1680] avg_loss=3.828101 main=3.366163 aux=0.461938 imp_cv2=0.0876 load_cv2=5.2966 usage_frac=0.4152 topk_prob_mean=0.2488 ema_alpha_reverse=nan max_logit=12.7744
step:1681/1750 train_time:792370ms step_avg:471.37ms
[train step 1681] avg_loss=3.179163 main=2.732183 aux=0.446980 imp_cv2=0.1347 load_cv2=5.0813 usage_frac=0.4241 topk_prob_mean=0.2761 ema_alpha_reverse=nan max_logit=12.7744
step:1682/1750 train_time:792834ms step_avg:471.36ms
[train step 1682] avg_loss=3.170660 main=2.718981 aux=0.451679 imp_cv2=0.1236 load_cv2=5.1673 usage_frac=0.4241 topk_prob_mean=0.2718 ema_alpha_reverse=nan max_logit=12.7744
step:1683/1750 train_time:793294ms step_avg:471.36ms
[train step 1683] avg_loss=2.948777 main=2.513557 aux=0.435220 imp_cv2=0.1928 load_cv2=4.8997 usage_frac=0.4241 topk_prob_mean=0.3031 ema_alpha_reverse=nan max_logit=12.7744
step:1684/1750 train_time:793752ms step_avg:471.35ms
[train step 1684] avg_loss=3.693072 main=3.213200 aux=0.479871 imp_cv2=0.0600 load_cv2=5.5369 usage_frac=0.4241 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=12.7744
step:1685/1750 train_time:794208ms step_avg:471.34ms
[train step 1685] avg_loss=3.134359 main=2.685898 aux=0.448461 imp_cv2=0.1303 load_cv2=5.1172 usage_frac=0.4241 topk_prob_mean=0.2757 ema_alpha_reverse=nan max_logit=12.7744
step:1686/1750 train_time:794677ms step_avg:471.34ms
[train step 1686] avg_loss=3.287124 main=2.839793 aux=0.447331 imp_cv2=0.1130 load_cv2=5.1189 usage_frac=0.4241 topk_prob_mean=0.2705 ema_alpha_reverse=nan max_logit=12.7744
step:1687/1750 train_time:795132ms step_avg:471.33ms
[train step 1687] avg_loss=3.177967 main=2.739152 aux=0.438815 imp_cv2=0.1671 load_cv2=4.9660 usage_frac=0.4286 topk_prob_mean=0.2950 ema_alpha_reverse=nan max_logit=12.7744
step:1688/1750 train_time:795590ms step_avg:471.32ms
[train step 1688] avg_loss=2.581476 main=2.144718 aux=0.436758 imp_cv2=0.2787 load_cv2=4.8462 usage_frac=0.4241 topk_prob_mean=0.3278 ema_alpha_reverse=nan max_logit=12.7744
step:1689/1750 train_time:796063ms step_avg:471.32ms
[train step 1689] avg_loss=4.273156 main=3.755844 aux=0.517312 imp_cv2=0.0522 load_cv2=5.9852 usage_frac=0.4196 topk_prob_mean=0.1894 ema_alpha_reverse=nan max_logit=12.7744
step:1690/1750 train_time:796521ms step_avg:471.31ms
[train step 1690] avg_loss=3.096521 main=2.653875 aux=0.442645 imp_cv2=0.1576 load_cv2=5.0237 usage_frac=0.4241 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=12.7744
step:1691/1750 train_time:796971ms step_avg:471.30ms
[train step 1691] avg_loss=3.332385 main=2.872815 aux=0.459570 imp_cv2=0.0898 load_cv2=5.2851 usage_frac=0.4196 topk_prob_mean=0.2527 ema_alpha_reverse=nan max_logit=12.7744
step:1692/1750 train_time:797431ms step_avg:471.29ms
[train step 1692] avg_loss=3.368395 main=2.913929 aux=0.454466 imp_cv2=0.1055 load_cv2=5.2049 usage_frac=0.4241 topk_prob_mean=0.2630 ema_alpha_reverse=nan max_logit=12.7744
step:1693/1750 train_time:797881ms step_avg:471.28ms
[train step 1693] avg_loss=3.296184 main=2.839813 aux=0.456371 imp_cv2=0.1086 load_cv2=5.2353 usage_frac=0.4241 topk_prob_mean=0.2643 ema_alpha_reverse=nan max_logit=12.7744
step:1694/1750 train_time:798331ms step_avg:471.27ms
[train step 1694] avg_loss=3.736074 main=3.262084 aux=0.473990 imp_cv2=0.0643 load_cv2=5.4680 usage_frac=0.4241 topk_prob_mean=0.2323 ema_alpha_reverse=nan max_logit=12.7744
step:1695/1750 train_time:798784ms step_avg:471.26ms
[train step 1695] avg_loss=4.151305 main=3.646647 aux=0.504658 imp_cv2=0.0424 load_cv2=5.8458 usage_frac=0.4152 topk_prob_mean=0.1971 ema_alpha_reverse=nan max_logit=12.7744
step:1696/1750 train_time:799241ms step_avg:471.25ms
[train step 1696] avg_loss=3.817608 main=3.294838 aux=0.522770 imp_cv2=0.0422 load_cv2=6.0649 usage_frac=0.4196 topk_prob_mean=0.1809 ema_alpha_reverse=nan max_logit=12.7744
step:1697/1750 train_time:799695ms step_avg:471.24ms
[train step 1697] avg_loss=2.951839 main=2.510949 aux=0.440890 imp_cv2=0.1576 load_cv2=4.9946 usage_frac=0.4196 topk_prob_mean=0.2923 ema_alpha_reverse=nan max_logit=12.7744
step:1698/1750 train_time:800156ms step_avg:471.23ms
[train step 1698] avg_loss=3.043507 main=2.601873 aux=0.441634 imp_cv2=0.1614 load_cv2=5.0020 usage_frac=0.4196 topk_prob_mean=0.2925 ema_alpha_reverse=nan max_logit=12.7744
step:1699/1750 train_time:800618ms step_avg:471.23ms
[train step 1699] avg_loss=2.957149 main=2.515661 aux=0.441488 imp_cv2=0.1839 load_cv2=4.9795 usage_frac=0.4241 topk_prob_mean=0.3001 ema_alpha_reverse=nan max_logit=12.7744
step:1700/1750 train_time:801085ms step_avg:471.23ms
Running validation...
step:1700/1750 val_loss:2.849817 train_time:801097ms step_avg:471.23ms
[train step 1700] avg_loss=3.585526 main=3.102109 aux=0.483417 imp_cv2=0.0604 load_cv2=5.5971 usage_frac=0.4241 topk_prob_mean=0.2263 ema_alpha_reverse=nan max_logit=12.7744
step:1701/1750 train_time:801552ms step_avg:471.22ms
[train step 1701] avg_loss=3.567295 main=3.111511 aux=0.455785 imp_cv2=0.1057 load_cv2=5.2070 usage_frac=0.4241 topk_prob_mean=0.2606 ema_alpha_reverse=nan max_logit=12.7744
step:1702/1750 train_time:802004ms step_avg:471.21ms
[train step 1702] avg_loss=3.103248 main=2.653740 aux=0.449508 imp_cv2=0.1371 load_cv2=5.1198 usage_frac=0.4241 topk_prob_mean=0.2794 ema_alpha_reverse=nan max_logit=12.7744
step:1703/1750 train_time:802461ms step_avg:471.20ms
[train step 1703] avg_loss=2.906574 main=2.464551 aux=0.442024 imp_cv2=0.1773 load_cv2=4.9931 usage_frac=0.4241 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=12.7744
step:1704/1750 train_time:802928ms step_avg:471.20ms
[train step 1704] avg_loss=2.978724 main=2.532029 aux=0.446695 imp_cv2=0.1568 load_cv2=5.0706 usage_frac=0.4241 topk_prob_mean=0.2874 ema_alpha_reverse=nan max_logit=12.7744
step:1705/1750 train_time:803383ms step_avg:471.19ms
[train step 1705] avg_loss=4.876060 main=4.336486 aux=0.539574 imp_cv2=0.1056 load_cv2=6.1926 usage_frac=0.3884 topk_prob_mean=0.1751 ema_alpha_reverse=nan max_logit=11.7917
step:1706/1750 train_time:804055ms step_avg:471.31ms
[train step 1706] avg_loss=3.180547 main=2.735758 aux=0.444790 imp_cv2=0.1522 load_cv2=5.0490 usage_frac=0.4241 topk_prob_mean=0.2855 ema_alpha_reverse=nan max_logit=12.7744
step:1707/1750 train_time:804513ms step_avg:471.30ms
[train step 1707] avg_loss=3.348444 main=2.890873 aux=0.457571 imp_cv2=0.0978 load_cv2=5.2428 usage_frac=0.4241 topk_prob_mean=0.2590 ema_alpha_reverse=nan max_logit=12.7744
step:1708/1750 train_time:804979ms step_avg:471.30ms
[train step 1708] avg_loss=3.309457 main=2.854658 aux=0.454799 imp_cv2=0.1030 load_cv2=5.2073 usage_frac=0.4241 topk_prob_mean=0.2614 ema_alpha_reverse=nan max_logit=12.7744
step:1709/1750 train_time:805437ms step_avg:471.29ms
[train step 1709] avg_loss=3.243690 main=2.789141 aux=0.454550 imp_cv2=0.1252 load_cv2=5.1906 usage_frac=0.4196 topk_prob_mean=0.2712 ema_alpha_reverse=nan max_logit=12.7744
step:1710/1750 train_time:805891ms step_avg:471.28ms
[train step 1710] avg_loss=3.386484 main=2.935721 aux=0.450763 imp_cv2=0.1341 load_cv2=5.1346 usage_frac=0.4286 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=12.7744
step:1711/1750 train_time:806349ms step_avg:471.27ms
[train step 1711] avg_loss=3.480872 main=3.002984 aux=0.477888 imp_cv2=0.0656 load_cv2=5.5223 usage_frac=0.4286 topk_prob_mean=0.2333 ema_alpha_reverse=nan max_logit=12.7744
step:1712/1750 train_time:806804ms step_avg:471.26ms
[train step 1712] avg_loss=2.967764 main=2.526991 aux=0.440773 imp_cv2=0.1885 load_cv2=4.9694 usage_frac=0.4241 topk_prob_mean=0.3014 ema_alpha_reverse=nan max_logit=12.7744
step:1713/1750 train_time:807257ms step_avg:471.25ms
[train step 1713] avg_loss=4.069672 main=3.580130 aux=0.489541 imp_cv2=0.0654 load_cv2=5.6422 usage_frac=0.4241 topk_prob_mean=0.2139 ema_alpha_reverse=nan max_logit=12.7744
step:1714/1750 train_time:807721ms step_avg:471.25ms
[train step 1714] avg_loss=3.274652 main=2.826300 aux=0.448351 imp_cv2=0.1063 load_cv2=5.1281 usage_frac=0.4196 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=12.7744
step:1715/1750 train_time:808186ms step_avg:471.25ms
[train step 1715] avg_loss=3.676198 main=3.199702 aux=0.476496 imp_cv2=0.0656 load_cv2=5.5036 usage_frac=0.4286 topk_prob_mean=0.2302 ema_alpha_reverse=nan max_logit=12.7744
step:1716/1750 train_time:808639ms step_avg:471.24ms
[train step 1716] avg_loss=3.361467 main=2.909588 aux=0.451879 imp_cv2=0.1268 load_cv2=5.1648 usage_frac=0.4241 topk_prob_mean=0.2739 ema_alpha_reverse=nan max_logit=12.7744
step:1717/1750 train_time:809102ms step_avg:471.23ms
[train step 1717] avg_loss=3.132770 main=2.688207 aux=0.444563 imp_cv2=0.1391 load_cv2=5.0557 usage_frac=0.4241 topk_prob_mean=0.2813 ema_alpha_reverse=nan max_logit=12.7744
step:1718/1750 train_time:809559ms step_avg:471.22ms
[train step 1718] avg_loss=3.048829 main=2.610381 aux=0.438448 imp_cv2=0.1852 load_cv2=4.9516 usage_frac=0.4196 topk_prob_mean=0.3024 ema_alpha_reverse=nan max_logit=12.7744
step:1719/1750 train_time:810025ms step_avg:471.22ms
[train step 1719] avg_loss=3.149808 main=2.693663 aux=0.456145 imp_cv2=0.0871 load_cv2=5.2435 usage_frac=0.4286 topk_prob_mean=0.2552 ema_alpha_reverse=nan max_logit=12.7744
step:1720/1750 train_time:810481ms step_avg:471.21ms
[train step 1720] avg_loss=2.987022 main=2.546010 aux=0.441012 imp_cv2=0.1718 load_cv2=4.9960 usage_frac=0.4241 topk_prob_mean=0.2962 ema_alpha_reverse=nan max_logit=12.7744
step:1721/1750 train_time:811124ms step_avg:471.31ms
[train step 1721] avg_loss=3.948540 main=3.487996 aux=0.460544 imp_cv2=0.0856 load_cv2=5.2945 usage_frac=0.4241 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=12.7744
step:1722/1750 train_time:811590ms step_avg:471.31ms
[train step 1722] avg_loss=3.033574 main=2.584121 aux=0.449453 imp_cv2=0.1115 load_cv2=5.1390 usage_frac=0.4241 topk_prob_mean=0.2700 ema_alpha_reverse=nan max_logit=12.7744
step:1723/1750 train_time:812048ms step_avg:471.30ms
[train step 1723] avg_loss=3.845615 main=3.321696 aux=0.523919 imp_cv2=0.0701 load_cv2=6.0252 usage_frac=0.4152 topk_prob_mean=0.1843 ema_alpha_reverse=nan max_logit=12.7744
step:1724/1750 train_time:812506ms step_avg:471.29ms
[train step 1724] avg_loss=3.362315 main=2.894933 aux=0.467382 imp_cv2=0.0719 load_cv2=5.3861 usage_frac=0.4196 topk_prob_mean=0.2404 ema_alpha_reverse=nan max_logit=12.7744
step:1725/1750 train_time:812964ms step_avg:471.28ms
[train step 1725] avg_loss=3.214242 main=2.772471 aux=0.441770 imp_cv2=0.1629 load_cv2=5.0132 usage_frac=0.4241 topk_prob_mean=0.2905 ema_alpha_reverse=nan max_logit=12.7744
step:1726/1750 train_time:813422ms step_avg:471.28ms
[train step 1726] avg_loss=3.156143 main=2.707791 aux=0.448352 imp_cv2=0.1442 load_cv2=5.1062 usage_frac=0.4196 topk_prob_mean=0.2825 ema_alpha_reverse=nan max_logit=12.7744
step:1727/1750 train_time:813871ms step_avg:471.26ms
[train step 1727] avg_loss=3.594844 main=3.139420 aux=0.455424 imp_cv2=0.0934 load_cv2=5.2262 usage_frac=0.4196 topk_prob_mean=0.2571 ema_alpha_reverse=nan max_logit=12.7744
step:1728/1750 train_time:814328ms step_avg:471.25ms
[train step 1728] avg_loss=3.125399 main=2.680663 aux=0.444736 imp_cv2=0.1447 load_cv2=5.0559 usage_frac=0.4286 topk_prob_mean=0.2832 ema_alpha_reverse=nan max_logit=12.7744
step:1729/1750 train_time:814801ms step_avg:471.26ms
[train step 1729] avg_loss=3.155304 main=2.705991 aux=0.449313 imp_cv2=0.1231 load_cv2=5.1374 usage_frac=0.4241 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=12.7744
step:1730/1750 train_time:815255ms step_avg:471.25ms
[train step 1730] avg_loss=3.180987 main=2.713249 aux=0.467737 imp_cv2=0.0795 load_cv2=5.3955 usage_frac=0.4196 topk_prob_mean=0.2448 ema_alpha_reverse=nan max_logit=12.7744
step:1731/1750 train_time:815717ms step_avg:471.24ms
[train step 1731] avg_loss=2.688677 main=2.251331 aux=0.437346 imp_cv2=0.1853 load_cv2=4.9354 usage_frac=0.4286 topk_prob_mean=0.3017 ema_alpha_reverse=nan max_logit=12.7744
step:1732/1750 train_time:816185ms step_avg:471.24ms
[train step 1732] avg_loss=4.015766 main=3.555260 aux=0.460506 imp_cv2=0.0799 load_cv2=5.2981 usage_frac=0.4196 topk_prob_mean=0.2484 ema_alpha_reverse=nan max_logit=12.7744
step:1733/1750 train_time:816637ms step_avg:471.23ms
[train step 1733] avg_loss=4.280483 main=3.781927 aux=0.498556 imp_cv2=0.0544 load_cv2=5.7800 usage_frac=0.4196 topk_prob_mean=0.2052 ema_alpha_reverse=nan max_logit=12.7744
step:1734/1750 train_time:817091ms step_avg:471.22ms
[train step 1734] avg_loss=4.069625 main=3.595520 aux=0.474105 imp_cv2=0.0638 load_cv2=5.4663 usage_frac=0.4152 topk_prob_mean=0.2325 ema_alpha_reverse=nan max_logit=12.7744
step:1735/1750 train_time:817560ms step_avg:471.22ms
[train step 1735] avg_loss=3.041574 main=2.604159 aux=0.437415 imp_cv2=0.1682 load_cv2=4.9418 usage_frac=0.4241 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=12.7744
step:1736/1750 train_time:818024ms step_avg:471.21ms
[train step 1736] avg_loss=3.254916 main=2.795897 aux=0.459019 imp_cv2=0.0937 load_cv2=5.2750 usage_frac=0.4196 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=12.7744
step:1737/1750 train_time:818492ms step_avg:471.21ms
[train step 1737] avg_loss=3.312228 main=2.839862 aux=0.472366 imp_cv2=0.0682 load_cv2=5.4504 usage_frac=0.4196 topk_prob_mean=0.2331 ema_alpha_reverse=nan max_logit=12.7744
step:1738/1750 train_time:818947ms step_avg:471.20ms
[train step 1738] avg_loss=3.166909 main=2.713910 aux=0.452999 imp_cv2=0.1041 load_cv2=5.1866 usage_frac=0.4286 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=12.7744
step:1739/1750 train_time:819399ms step_avg:471.19ms
[train step 1739] avg_loss=3.926044 main=3.419547 aux=0.506497 imp_cv2=0.0456 load_cv2=5.8676 usage_frac=0.4196 topk_prob_mean=0.1973 ema_alpha_reverse=nan max_logit=12.7744
step:1740/1750 train_time:819853ms step_avg:471.18ms
[train step 1740] avg_loss=3.228845 main=2.773698 aux=0.455148 imp_cv2=0.0885 load_cv2=5.2228 usage_frac=0.4196 topk_prob_mean=0.2547 ema_alpha_reverse=nan max_logit=12.7744
step:1741/1750 train_time:820303ms step_avg:471.17ms
[train step 1741] avg_loss=4.257074 main=3.747786 aux=0.509288 imp_cv2=0.0553 load_cv2=5.9012 usage_frac=0.4152 topk_prob_mean=0.1995 ema_alpha_reverse=nan max_logit=12.7744
step:1742/1750 train_time:820758ms step_avg:471.16ms
[train step 1742] avg_loss=2.833572 main=2.399650 aux=0.433922 imp_cv2=0.1806 load_cv2=4.8956 usage_frac=0.4241 topk_prob_mean=0.3030 ema_alpha_reverse=nan max_logit=12.7744
step:1743/1750 train_time:821212ms step_avg:471.15ms
[train step 1743] avg_loss=3.088020 main=2.645608 aux=0.442411 imp_cv2=0.1541 load_cv2=5.0218 usage_frac=0.4241 topk_prob_mean=0.2880 ema_alpha_reverse=nan max_logit=12.7744
step:1744/1750 train_time:821674ms step_avg:471.14ms
[train step 1744] avg_loss=3.964817 main=3.495034 aux=0.469783 imp_cv2=0.0729 load_cv2=5.4079 usage_frac=0.4241 topk_prob_mean=0.2377 ema_alpha_reverse=nan max_logit=12.7744
step:1745/1750 train_time:822125ms step_avg:471.13ms
[train step 1745] avg_loss=3.432989 main=2.966766 aux=0.466222 imp_cv2=0.0760 load_cv2=5.3603 usage_frac=0.4241 topk_prob_mean=0.2415 ema_alpha_reverse=nan max_logit=12.7744
step:1746/1750 train_time:822579ms step_avg:471.12ms
[train step 1746] avg_loss=3.402550 main=2.939919 aux=0.462632 imp_cv2=0.0843 load_cv2=5.3166 usage_frac=0.4241 topk_prob_mean=0.2511 ema_alpha_reverse=nan max_logit=12.7744
step:1747/1750 train_time:823028ms step_avg:471.11ms
[train step 1747] avg_loss=3.480295 main=3.011825 aux=0.468470 imp_cv2=0.0700 load_cv2=5.4014 usage_frac=0.4241 topk_prob_mean=0.2382 ema_alpha_reverse=nan max_logit=12.7744
step:1748/1750 train_time:823489ms step_avg:471.10ms
[train step 1748] avg_loss=3.266967 main=2.818174 aux=0.448793 imp_cv2=0.1197 load_cv2=5.1306 usage_frac=0.4196 topk_prob_mean=0.2723 ema_alpha_reverse=nan max_logit=12.7744
step:1749/1750 train_time:823943ms step_avg:471.09ms
[train step 1749] avg_loss=3.648836 main=3.169390 aux=0.479446 imp_cv2=0.0709 load_cv2=5.5149 usage_frac=0.4196 topk_prob_mean=0.2255 ema_alpha_reverse=nan max_logit=12.7744
step:1750/1750 train_time:824396ms step_avg:471.08ms
Running validation...
step:1750/1750 val_loss:2.870304 train_time:824408ms step_avg:471.09ms
peak memory allocated: 29973 MiB reserved: 33170 MiB
