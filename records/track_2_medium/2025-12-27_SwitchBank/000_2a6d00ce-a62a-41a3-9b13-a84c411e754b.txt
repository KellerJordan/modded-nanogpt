wandb logging enabled.
===== /home/ubuntu/switch-bank/train_switch_bank.py =====\n# ========== train_switch_bank.py ==========

import csv
import json
import os
import sys
from pathlib import Path

def _read_text(path: Path) -> str:
    try:
        return path.read_text()
    except Exception:
        return ""

def _build_code() -> str:
    code_paths = [
        Path(__file__).resolve(),
        Path("switch_bank/utils.py"),
        Path("switch_bank/optim/muon.py"),
        Path("switch_bank/model/components.py"),
        Path("switch_bank/model/gpt.py"),
        Path("switch_bank/data.py"),
        Path("switch_bank/trainer.py"),
    ]
    code_parts = []
    for p in code_paths:
        if p.exists():
            code_parts.append(f"===== {p} =====\\n{_read_text(p)}")
    return "\\n\\n".join(code_parts)

code = _build_code()
import uuid
import copy
from dataclasses import dataclass
from switch_bank.utils import compute_train_micro_len
from switch_bank.optim.muon import Muon
from switch_bank.model.components import CausalSelfAttention
from switch_bank.model.gpt import GPT
from switch_bank.data import summarize_router_metrics, summarize_expert_usage, summarize_expert_activity, \
    router_summary_str, distributed_data_generator
from switch_bank import trainer

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
import torch._functorch.config
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import nn
import torch.distributed as dist
torch._inductor.config.coordinate_descent_tuning = True   # allowed for medium track; false for rocm / single-GPU
torch._functorch.config.donated_buffer = False
torch._dynamo.config.compiled_autograd = False  # torch nightly build issue??


#
# -----------------------------------------------------------------------------
# The main model
# -----------------------------------------------------------------------------

# ----- Parameter accounting / logging -----
def _num_params(tensors_iter):
    return sum(p.numel() for p in tensors_iter)

def _unique_params(params):
    seen = set()
    unique = []
    for p in params:
        pid = id(p)
        if pid in seen:
            continue
        seen.add(pid)
        unique.append(p)
    return unique

def _fmt(n: int) -> str:
    return f"{n:,} ({n/1e6:.3f}M)"

@torch.no_grad()
def log_param_counts(model: nn.Module, args, print_fn) -> None:
    #if not args.enable_extra_logging:
    #    return
    # totals
    total = _num_params(model.parameters())

    # attention stack: merged QKV/out per block that has attention
    attn_params = []
    attn_layers = 0
    for b in model.blocks:
        if isinstance(b.attn, CausalSelfAttention):
            attn_params.append(b.attn.qkvo_w)
            attn_layers += 1
    attn_total = _num_params(_unique_params(attn_params))

    # FFN bank: experts + routers
    bank_expert_params = list(model.bank.W1) + list(model.bank.W2)
    bank_router_params = list(model.bank.router_w) + list(model.bank.router_b)
    bank_expert_total = _num_params(bank_expert_params)
    bank_router_total = _num_params(bank_router_params)
    bank_total = bank_expert_total + bank_router_total

    # embeddings: tied token embedding + N value-embedding tables
    tok_embed_total = _num_params(model.embed.parameters())
    ve_total = sum(_num_params(ve.parameters()) for ve in model.value_embeds)
    embeds_total = tok_embed_total + ve_total

    # lm head (if untied / instantiated)
    head_total = _num_params([model.lm_head]) if model.lm_head is not None else 0

    # scalars (skip lambdas / SA lambdas / skip weights)
    scalars_total = model.scalars.numel()

    adapter_total = 0
    if getattr(model.bank, "use_adapters", False):
        adapter_total = model.bank.adapter_scale.numel() + model.bank.adapter_bias.numel()

    # anything unaccounted (should be ~0; keeps us honest)
    accounted = attn_total + bank_total + embeds_total + head_total + scalars_total + adapter_total
    other_total = total - accounted

    # pretty print
    print_fn("=== Parameter counts ===", console=True)
    print_fn(f"model total:           {_fmt(total)}", console=True)
    print_fn(f"  attention stack ({attn_layers} of {args.num_layers} layers run attention): {_fmt(attn_total)}", console=True)
    print_fn(f"  FFN bank total:      {_fmt(bank_total)}", console=True)
    print_fn(f"    ├─ experts W1/W2:  {_fmt(bank_expert_total)}", console=True)
    print_fn(f"    └─ routers:        {_fmt(bank_router_total)}", console=True)
    print_fn(f"  embeddings (tok + {model.num_value_embeds}× value): {_fmt(embeds_total)}", console=True)
    print_fn(f"    └─ token embed:    {_fmt(tok_embed_total)}", console=True)
    print_fn(f"    └─ value embeds:   {_fmt(ve_total)}", console=True)
    if head_total:
        tied_state = "tied" if model._head_tied_runtime else "untied"
        print_fn(f"  lm head ({tied_state}):   {_fmt(head_total)}", console=True)
    if adapter_total:
        print_fn(f"  adapters:            {_fmt(adapter_total)}", console=True)
    print_fn(f"  scalars:             {_fmt(scalars_total)}", console=True)
    if other_total != 0:
        print_fn(f"  other (unclassified): {_fmt(other_total)}", console=True)
    print_fn("="*100, console=False)

# -----------------------------------------------------------------------------
# int main
# -----------------------------------------------------------------------------

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin"
    val_files = "data/fineweb10B/fineweb_val_*.bin"
    val_tokens = 10485760
    val_tokens_intermediate: int | None = 32768 * 7
    val_tokens_final: int | None = 10485760
    train_seq_len = 12*1024 #64*1024          # effective tokens per optimizer step per rank
    val_seq_len = 8192 #4*64*1024
    # minibatch / gradient accumulation
    grad_accum_steps = 1 # default=1 keeps original, multi-GPU behavior
    train_micro_seq_len: int | None = None  # if None, computed as train_seq_len // grad_accum_steps
    # optimization
    num_iterations = 1750
    early_stop_step: int | None = None
    cooldown_frac = 0.65  #0.7
    lr_final_mult = 0.0  # decay to this % of original lr at final iteration
    lr_freeze_last_steps = 0 # decay toward lr_final_mult at final step, but freeze lr at num_iterations-lr_freeze_last_steps
    lr_embed = 0.3
    lr_scalar = 0.015
    lr_head = 1/320
    lr_router = 0.095
    lr_adapter = 0.03
    lr_muon = 0.025
    router_grad_clip_norm = 0.0
    router_autoclip = True
    # Muon optimizer parameters (see switch_bank/optim/muon.py)
    muon_betas: tuple[float, float] = (0.8, 0.95)
    muon_eps: float = 1e-10
    muon_weight_decay: float = 0.0
    muon_momentum: float = 0.95
    muon_ns_iters: int = 4
    use_turbo_muon: bool = True
    turbo_muon_warmstart_smax_start_frac: float = -1 #0.725  # <0 disables; >=0 enables warm-started sigma-max (near end)
    # architecture
    vocab_size = 50257
    model_dim = 896
    num_layers = 28
    # Layer weight tying (attention + router adapters). Set to () to disable. Avoid tying layers with different attention types (short/long).
    layer_tie_groups: tuple[tuple[int, ...], ...] = (
        #(9, 10), (13, 14), (17, 18), (21, 22), (25, 26),  # Add 5,6 if need more. Remove from the beginning for fewer.
        #(17, 18), (21, 22), (25, 26),
    )
    head_dim = 128
    num_heads = model_dim // head_dim #7
    # value-embeddings integer count: 0, 1, 2, or 3 supported.
    num_value_embeds = 2
    tie_lm_head = False
    untie_lm_head_frac = -1.0
    # Bank / routing
    num_experts = 8 #9
    ffn_hidden = 1024
    topk = 1
    topk_val: int | None = None
    lb_coeff = 2.15e-3
    router_entropy_coeff = 2.5e-3  # coefficient for router entropy aux loss component
    use_router_adapters = True
    router_block_pos_bins = 8  # 4 / 8 / 16
    first_doc_tokens_N = 64
    router_enable_forward_ema = False
    router_enable_reverse_ema = True
    ema_alpha_fwd = 0.80
    ema_alpha_rev = 0.85
    ema_window_size_fwd = 128  # <=0 means full sequence
    ema_block_size_fwd = 128
    ema_window_size_rev = 384
    ema_block_size_rev = 384
    router_ema_layer_stride = -1  # How often to calculate fresh EMAs (which are then used by the next N-1 layers).  N < 0 -> num_layers (one shared EMA calculation for all layers).
    # Parameter freezing
    router_freeze_frac = 1.0
    router_freeze_adapters = False
    router_lr_reduce_start_frac = -1.0
    shared_ffn_freeze_frac = 1.0
    shared_ffn_lr_reduce_start_frac = -1.0
    # skip-attention layers (short-SWA) — exactly two
    skip_attn_layers = (11,)  # (7,)
    expert_activation_schedule: tuple[tuple[int, int], ...] = ((0, 1), (75, 2), (141, 3), (234, 4), (338, 5), (441, 6), (591, 7), (695, 8),)     #((0, 1), (200, 2), (375, 3), (625, 4), (900, 5), (1175, 6), (1575, 7), (1850, 8),) # (2175, 9))
    router_temp_init = 1.464
    router_temp_final = 0.93744
    router_temp_power = 1.5  # fallback if anchor disabled
    router_temp_anchor_delta_steps = 284 #756  # steps after 2nd expert activation to hit anchor ratio
    router_temp_anchor_ratio = 0.49  # temp curve hits this ratio at anchor delta
    router_logit_cap_initial = 1.166
    router_logit_cap_final = 13.757
    router_logit_cap_delta_steps = 237 #632  # ramp length after second expert activation
    # Optional Gumbel exploration (off by default)
    router_use_gumbel = True
    router_gumbel_schedule: tuple[tuple[int, int], ...] = ((75, 441), (459, 488), (534, 722), (900, 909), (1004, 1022), (1097, 1107), (1200, 1209), (1284, 1313), (1472, 1500))       #((200, 1175), (1225, 1300), (1425, 1925),) # (2400, 2425), (2675, 2725), (2925, 2950), (3200, 3225), ) #(3425, 3500), (3925, -1))
    # Layerwise router temp & lb boosts.
    router_boost_shape = "peak"  # options: peak (default), valley, linear_start, linear_end
    router_temp_boost = 0.2
    router_lb_boost = 0.5
    router_layer_peak_frac = 0.475  # only used for peak or valley shapes. boosts are calculated continuously
    # evaluation and logging
    val_loss_every = 50  # 0 for only at end
    save_final_checkpoint = True
    save_final_checkpoint_if_loss_below: bool = True
    save_final_checkpoint_max_loss: float = 2.92
    checkpoint_save_step: int = -1  # -1 disables mid-training save
    resume_checkpoint: str | None = None
    log_dir: str = "records/track_2_medium/2025-12-27_SwitchBank"
    use_wandb = True
    wandb_project = "switch-bank-final"
    wandb_run_name = ""
    wandb_log_every = 1
    enable_extra_logging = False
    enable_extra_wandb_logging = False
    do_model_warmup = True
    metrics_log_every = 25


def _coerce_override(value, current):
    if current is None:
        return value
    if isinstance(current, bool):
        return bool(value)
    if isinstance(current, int) and not isinstance(current, bool):
        return int(value)
    if isinstance(current, float):
        return float(value)
    if isinstance(current, tuple):
        if isinstance(value, (list, tuple)):
            return tuple(value)
    return value


def _apply_overrides(args, overrides: dict, source: str) -> None:
    for key, value in overrides.items():
        if not hasattr(args, key):
            raise KeyError(f"Unknown Hyperparameters override '{key}' from {source}")
        current = getattr(args, key)
        coerced = _coerce_override(value, current)
        setattr(args, key, coerced)


def _parse_overrides_env() -> dict:
    raw = os.environ.get("SWB_OVERRIDES_JSON") or os.environ.get("SWITCH_BANK_OVERRIDES_JSON")
    if not raw:
        return {}
    try:
        data = json.loads(raw)
    except json.JSONDecodeError as exc:
        raise ValueError(f"Failed to parse overrides JSON: {exc}") from exc
    if not isinstance(data, dict):
        raise ValueError("Overrides JSON must be an object/dict")
    return data


def _reset_runtime_state(model: nn.Module) -> None:
    base_model = getattr(model, "_orig_mod", model)
    for name, value in (
        ("_router_frozen_logged", False),
        ("_ffn_frozen_logged", False),
        ("_last_active_expert_count", None),
        ("_pending_active_count", None),
    ):
        if hasattr(base_model, name):
            setattr(base_model, name, value)


def _set_seed(seed: int | None) -> None:
    if seed is None:
        return
    import random
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def run_training(
    overrides: dict | None = None,
    single_gpu: bool = False,
    early_stop_step: int | None = None,
    early_stop_val_multiplier: int = 1,
    reuse_state: dict | None = None,
    results_path: str | None = None,
    destroy_process_group: bool = True,
    seed: int | None = None,
):
    args = Hyperparameters()
    env_overrides = _parse_overrides_env()
    if env_overrides:
        _apply_overrides(args, env_overrides, "env")
    if overrides:
        _apply_overrides(args, overrides, "call")
    if args.router_ema_layer_stride < 0:
        args.router_ema_layer_stride = args.num_layers
    _set_seed(seed)
    early_stop_is_final = False
    if early_stop_step is None:
        early_stop_step = getattr(args, "early_stop_step", None)
        if early_stop_step is not None:
            early_stop_is_final = True

    def hyperparams_to_config(h: Hyperparameters) -> dict:
        cfg: dict[str, object] = {}
        for name in dir(h):
            if name.startswith("_"):
                continue
            value = getattr(h, name)
            if callable(value):
                continue
            cfg[name] = value
        return cfg

    untie_lm_head_after = -1
    if args.tie_lm_head and args.untie_lm_head_frac is not None and args.untie_lm_head_frac >= 0:
        untie_lm_head_after = int(args.untie_lm_head_frac * args.num_iterations)
        untie_lm_head_after = min(max(untie_lm_head_after, 0), args.num_iterations)

    if single_gpu:
        os.environ.setdefault("RANK", "0")
        os.environ.setdefault("WORLD_SIZE", "1")
        os.environ.setdefault("LOCAL_RANK", "0")
        os.environ.setdefault("MASTER_ADDR", "127.0.0.1")
        os.environ.setdefault("MASTER_PORT", "29500")
    run_id = int(os.environ.get("RUN_ID", 0))
    import torch
    assert torch.cuda.is_available()
    if dist.is_initialized():
        rank = dist.get_rank()
        world_size = dist.get_world_size()
    else:
        rank = int(os.environ.get("RANK", "0"))
        world_size = int(os.environ.get("WORLD_SIZE", "1"))
        device = torch.device("cuda", int(os.environ.get("LOCAL_RANK", "0")))
        torch.cuda.set_device(device)
        dist.init_process_group(backend="nccl", device_id=device)
    device = torch.device("cuda", int(os.environ.get("LOCAL_RANK", "0")))
    torch.cuda.set_device(device)
    dist.barrier()
    master_process = (rank == 0)
    run_id_full: str | None = None

    if master_process:
        run_id_full = f"{run_id:03d}_{uuid.uuid4()}"
        log_dir = args.log_dir
        os.makedirs(log_dir, exist_ok=True)
        logfile = os.path.join(log_dir, f"{run_id_full}.txt")
        print(logfile)
    def print0(s, console=False):
        if master_process:
            with open(logfile, "a") as f:
                if console:
                    print(s)
                print(s, file=f)

    # --- Robust Inductor trace hook (compatible with callsites with/without metadata_fn) ---
    from torch._logging._internal import trace_structured as _orig_trace_structured  # keep original
    import torch._inductor.codecache  # noqa: E402
    import torch._inductor.graph      # noqa: E402

    def _patched_trace_structured(name, *args, **kwargs):
        """
        Torch Inductor sometimes calls trace_structured(name, metadata_fn, **kwargs),
        and other times as trace_structured(name, **kwargs) with metadata_fn omitted.
        Be permissive and forward both forms. Also print compiled filename when available.
        """
        metadata_fn = kwargs.get("metadata_fn", None)
        if metadata_fn is None and len(args) > 0 and callable(args[0]):
            # first positional could be metadata_fn
            metadata_fn = args[0]
        try:
            if name == "inductor_output_code" and callable(metadata_fn):
                md = metadata_fn()
                filename = (md.get("filename", "Unknown") if isinstance(md, dict) else "Unknown")
                print0(f"inductor_output_code: {filename}")
        except Exception:
            # never let logging break compilation
            pass
        return _orig_trace_structured(name, *args, **kwargs)

    torch._inductor.codecache.trace_structured = _patched_trace_structured
    torch._inductor.graph.trace_structured = _patched_trace_structured
    # --- end robust hook ---

    wandb_run = None
    if args.use_wandb and os.environ.get("WANDB_DISABLED", "0").lower() not in ("1", "true", "yes") and master_process:
        wandb_reinit = os.environ.get("WANDB_REINIT", "0").lower() in ("1", "true", "yes")
        try:
            import wandb  # type: ignore
            wandb_run = wandb.init(
                project=args.wandb_project,
                config=hyperparams_to_config(args),
                reinit=wandb_reinit,
                #name=args.wandb_run_name or run_id_full or f"rank{rank}",
            )
            print0("wandb logging enabled.", console=True)
        except Exception as err:
            print0(f"wandb init failed ({err}); disabling wandb.", console=True)
            wandb_run = None

    metrics_csv_file = None
    metrics_csv_writer = None
    expert_usage_headers: list[str] = []
    expert_active_headers: list[str] = []
    if master_process and run_id_full is not None and args.enable_extra_logging:
        metrics_csv_path = os.path.join(args.log_dir, f"{run_id_full}_metrics.csv")
        metrics_csv_file = open(metrics_csv_path, "w", newline="")
        metrics_csv_writer = csv.writer(metrics_csv_file)
        expert_usage_headers = [f"expert_usage_e{i}" for i in range(args.num_experts)]
        expert_active_headers = [f"expert_active_e{i}" for i in range(args.num_experts)]
        router_ema_headers: list[str] = []
        if args.router_enable_forward_ema:
            router_ema_headers.append("router_ema_alpha_forward")
        if args.router_enable_reverse_ema:
            router_ema_headers.append("router_ema_alpha_reverse")
        metrics_csv_writer.writerow([
            "step", "loss", "loss_main", "loss_aux",
            "router_imp_cv2", "router_load_cv2", "router_usage_frac",
            "router_topk_prob_mean", *router_ema_headers, "router_max_logit",
            "logit_cap", "router_temp", "window_blocks", *expert_usage_headers, *expert_active_headers
        ])

    def log_metrics_row(step_value: int, avg_loss: float, avg_main: float, avg_aux: float,
                        router_summary: dict[str, float], logit_cap_value: float | None,
                        router_temp_value: float, window_blocks_value: int,
                        expert_usage: torch.Tensor | None,
                        expert_active: torch.Tensor | None):
        if metrics_csv_writer is None:
            return
        expert_usage_list = []
        if expert_usage is not None:
            expert_usage_list = [float(x) for x in expert_usage.tolist()]
        else:
            expert_usage_list = [float("nan")] * len(expert_usage_headers)
        expert_active_list = []
        if expert_active is not None:
            expert_active_list = [float(x) for x in expert_active.tolist()]
        else:
            expert_active_list = [float("nan")] * len(expert_active_headers)
        row = [
            step_value,
            avg_loss,
            avg_main,
            avg_aux,
            router_summary.get("imp_cv2", float("nan")),
            router_summary.get("load_cv2", float("nan")),
            router_summary.get("usage_frac", float("nan")),
            router_summary.get("topk_prob_mean", float("nan")),
        ]
        if args.router_enable_forward_ema:
            row.append(router_summary.get("ema_alpha_forward", float("nan")))
        if args.router_enable_reverse_ema:
            row.append(router_summary.get("ema_alpha_reverse", float("nan")))
        row.extend([
            router_summary.get("max_logit", float("nan")),
            (logit_cap_value if logit_cap_value is not None else float("nan")),
            router_temp_value,
            window_blocks_value,
        ])
        row.extend(expert_usage_list)
        row.extend(expert_active_list)
        metrics_csv_writer.writerow(row)

    print0(code)
    print0("="*100)
    print0(f"Running Python {sys.version}")
    print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
    def nvidia_smi():
        import subprocess
        try:
            return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
        except FileNotFoundError:
            return "nvidia-smi not available."
    print0(nvidia_smi())
    print0("="*100)

    shared_state = reuse_state if reuse_state is not None else {}
    model: nn.Module | None = shared_state.get("model")
    optimizers: list[torch.optim.Optimizer] | None = shared_state.get("optimizers")
    opt2params: dict | None = shared_state.get("opt2params")
    using_cached = model is not None and optimizers is not None and opt2params is not None

    ########################################
    #    Construct model and optimizer     #
    ########################################

    if not using_cached:
        model: nn.Module = GPT(
            vocab_size=args.vocab_size,
            num_layers=args.num_layers,
            num_heads=args.num_heads,
            model_dim=args.model_dim,
            max_seq_len=max(args.train_seq_len, args.val_seq_len),
            skip_attn_layers=set(args.skip_attn_layers),
            layer_tie_groups=tuple(args.layer_tie_groups) if args.layer_tie_groups is not None else tuple(),
            E=args.num_experts,
            h=args.ffn_hidden,
            lb_coeff=args.lb_coeff,
            ent_coeff=args.router_entropy_coeff,
            k=args.topk,
            num_value_embeds=args.num_value_embeds,
            tie_lm_head=args.tie_lm_head,
            untie_lm_head_after=untie_lm_head_after,
            ema_alpha_fwd=args.ema_alpha_fwd,
            ema_alpha_rev=args.ema_alpha_rev,
            router_temp_init=args.router_temp_init,
            router_temp_final=args.router_temp_final,
            router_temp_power=args.router_temp_power,
            router_temp_anchor_delta_steps=args.router_temp_anchor_delta_steps,
            router_temp_anchor_ratio=args.router_temp_anchor_ratio,
            router_logit_cap_initial=args.router_logit_cap_initial,
            router_logit_cap_final=args.router_logit_cap_final,
            router_logit_cap_delta_steps=args.router_logit_cap_delta_steps,
            router_layer_peak_frac=args.router_layer_peak_frac,
            router_temp_boost=args.router_temp_boost,
            router_lb_boost=args.router_lb_boost,
            router_boost_shape=args.router_boost_shape,
            use_router_adapters=args.use_router_adapters,
            expert_activation_schedule=args.expert_activation_schedule,
            router_freeze_frac=args.router_freeze_frac,
            router_freeze_adapters=args.router_freeze_adapters,
            ema_block_size_fwd=args.ema_block_size_fwd,
            ema_block_size_rev=args.ema_block_size_rev,
            ema_window_size_fwd=args.ema_window_size_fwd,
            ema_window_size_rev=args.ema_window_size_rev,
            ema_layer_stride=args.router_ema_layer_stride,
            shared_ffn_freeze_frac=args.shared_ffn_freeze_frac,
            router_use_gumbel=args.router_use_gumbel,
            router_gumbel_schedule=args.router_gumbel_schedule,
            router_block_pos_bins=args.router_block_pos_bins,
            first_doc_tokens_N=args.first_doc_tokens_N,
            router_enable_forward_ema=args.router_enable_forward_ema,
            router_enable_reverse_ema=args.router_enable_reverse_ema,
            extra_console_logging=args.enable_extra_logging,
            extra_wandb_logging=args.enable_extra_wandb_logging,
            print_fn=print0,
        ).cuda()

        for m in model.modules():
            if isinstance(m, nn.Embedding):
                m.bfloat16()
        for param in model.parameters():
            dist.broadcast(param.detach(), 0)

        log_param_counts(model, args, print0)

        # collect the parameters to optimize
        # ### FFNBANK MOD: include bank expert matrices in Muon spectral groups;
        # non-spectral params (routers/embeds/scalars/head/adapters) use AdamW branch.
        def is_2d(p: nn.Parameter) -> bool:
            return p.ndim >= 2

        attn_2d_params = []
        for b in model.blocks:
            if isinstance(b.attn, CausalSelfAttention):
                attn_2d_params.append(b.attn.qkvo_w)
        attn_2d_params = _unique_params(attn_2d_params)
        ffn_matrix_params = [*model.bank.W1, *model.bank.W2]
        hidden_matrix_params = attn_2d_params + ffn_matrix_params

        embed_params = [*model.embed.parameters(), *model.value_embeds.parameters()]
        head_params: list[nn.Parameter] = [model.lm_head] if model.lm_head is not None else []
        adapter_params = []
        if model.bank.use_adapters:
            adapter_params.extend([model.bank.adapter_scale, model.bank.adapter_bias])
        scalar_params = [model.scalars]
        router_params = list(model.bank.router_w) + list(model.bank.router_b)

        # sanity / completeness checks
        params_collections = [hidden_matrix_params, embed_params, head_params, adapter_params, scalar_params, router_params]
        optimized_parameters_set = {p for params in params_collections for p in params}
        assert optimized_parameters_set == {*model.parameters()}
        assert len(optimized_parameters_set) == sum(len(lst) for lst in params_collections)

        # init the optimizer(s)
        muon_param_groups: list[dict] = [
            dict(params=embed_params, lr=args.lr_embed, component="embed", spectral=False),
            dict(params=scalar_params, lr=args.lr_scalar, component="scalar", spectral=False),
            dict(params=router_params, lr=args.lr_router, component="router", spectral=False),
        ]
        if adapter_params:
            muon_param_groups.append(dict(params=adapter_params, lr=args.lr_adapter, component="adapter", spectral=False))
        if head_params:
            muon_param_groups.append(dict(params=head_params, lr=args.lr_head, component="head", spectral=False))
        if attn_2d_params:
            muon_param_groups.append(dict(params=attn_2d_params, lr=args.lr_muon, component="attention", spectral=True))
        if ffn_matrix_params:
            muon_param_groups.append(dict(params=ffn_matrix_params, lr=args.lr_muon, component="shared_ffn", spectral=True))

        optimizer = Muon(
            muon_param_groups,
            lr=args.lr_muon,  # default lr for spectral groups; overridden per-group above
            betas=tuple(args.muon_betas),
            eps=float(args.muon_eps),
            weight_decay=float(args.muon_weight_decay),
            muon_momentum=float(args.muon_momentum),
            lr_spec=None,
            ns_iters=int(args.muon_ns_iters),
            rank=rank,
            world_size=world_size,
            enable_turbomuon=bool(args.use_turbo_muon),
        )
        optimizers: list[torch.optim.Optimizer] = [optimizer]
        def opt_params(opt: torch.optim.Optimizer) -> list[nn.Parameter]:
            return [p for group in opt.param_groups for p in group["params"]]
        opt2params = {opt: opt_params(opt) for opt in optimizers}
        for opt in optimizers:
            for group in opt.param_groups:
                group["initial_lr"] = group["lr"]

    if not using_cached and reuse_state is not None:
        shared_state["model"] = model
        shared_state["optimizers"] = optimizers
        shared_state["opt2params"] = opt2params
    if using_cached:
        model = shared_state["model"]
        optimizers = shared_state["optimizers"]
        opt2params = shared_state["opt2params"]
        base_model = getattr(model, "_orig_mod", model)
        for key in (
            "router_temp_init",
            "router_temp_final",
            "router_temp_power",
            "router_temp_anchor_delta_steps",
            "router_temp_anchor_ratio",
            "router_logit_cap_initial",
            "router_logit_cap_final",
            "router_logit_cap_delta_steps",
            "router_use_gumbel",
            "router_gumbel_schedule",
            "router_temp_boost",
            "router_lb_boost",
            "router_layer_peak_frac",
            "router_boost_shape",
        ):
            if hasattr(base_model, key):
                setattr(base_model, key, getattr(args, key))
        if hasattr(base_model, "extra_console_logging"):
            base_model.extra_console_logging = bool(args.enable_extra_logging)
        if hasattr(base_model, "extra_wandb_logging"):
            base_model.extra_wandb_logging = bool(args.enable_extra_wandb_logging)
        if hasattr(base_model, "_print0"):
            base_model._print0 = print0
        if hasattr(base_model, "bank") and hasattr(base_model.bank, "enable_extra_wandb_logging"):
            base_model.bank.enable_extra_wandb_logging = bool(args.enable_extra_wandb_logging)
        _reset_runtime_state(model)
    start_step = 0
    resume_path = args.resume_checkpoint
    if resume_path:
        print0(f"Loading checkpoint from {resume_path}", console=True)
        checkpoint = torch.load(resume_path, map_location="cuda")
        model_state = checkpoint.get("model", {})
        if all(k.startswith("_orig_mod.") for k in model_state.keys()):
            model_state = {k.removeprefix("_orig_mod."): v for k, v in model_state.items()}
        args.approx_step_time_ms = float(checkpoint.get("approx_step_time_ms", 0))
        meta = checkpoint.get("meta", {}) or {}
        meta_checks = {
            "model_dim": args.model_dim,
            "num_layers": args.num_layers,
            "num_heads": args.num_heads,
            "num_experts": args.num_experts,
            "ffn_hidden": args.ffn_hidden,
            "vocab_size": args.vocab_size,
        }
        for key, current_val in meta_checks.items():
            saved_val = meta.get(key, current_val)
            assert saved_val == current_val, f"Checkpoint {key}={saved_val} does not match current args ({current_val})"
        model.load_state_dict(model_state)
        ckpt_opts = checkpoint.get("optimizers", [])
        assert len(ckpt_opts) == len(optimizers), "Optimizer count mismatch in checkpoint."
        for opt, state in zip(optimizers, ckpt_opts):
            opt.load_state_dict(state)
            for group in opt.param_groups:
                group.setdefault("initial_lr", group.get("lr", 0.0))
            # ensure Muon state dtypes survive checkpoint reload
            if isinstance(opt, Muon):
                for p, st in opt.state.items():
                    if not st:
                        continue
                    if "mantissa" in st and st["mantissa"].dtype != torch.uint16:
                        st["mantissa"] = st["mantissa"].to(dtype=torch.uint16)
                    if "momentum_buffer" in st and st["momentum_buffer"].dtype != torch.float32:
                        st["momentum_buffer"] = st["momentum_buffer"].to(dtype=torch.float32)
        start_step = int(checkpoint.get("step", -1)) + 1
        assert start_step >= 0, "Invalid checkpoint step."
        assert start_step <= args.num_iterations, "Checkpoint step exceeds configured num_iterations."
        print0(f"Resumed from checkpoint at step {start_step - 1}. Continuing from step {start_step}.", console=True)
        dist.barrier()

    if using_cached and shared_state.get("base_state") is not None and not resume_path:
        base_state = shared_state["base_state"]
        model.load_state_dict(base_state["model"])
        for opt, opt_state in zip(optimizers, base_state["optimizers"]):
            opt.load_state_dict(opt_state)
        _reset_runtime_state(model)

    for param in model.parameters():
        dist.broadcast(param.detach(), 0)

    if not using_cached:
        if not shared_state.get("compiled", False):
            print0("Compiling model...", console=True)
            model = torch.compile(model, dynamic=False)
            print0("Compile complete.", console=True)
        if reuse_state is not None:
            shared_state["model"] = model
            shared_state["compiled"] = True

    ########################################
    #            Warmup kernels            #
    ########################################

    train_micro_len = compute_train_micro_len(args.train_seq_len, args.grad_accum_steps, args.train_micro_seq_len)
    effective_train_tokens = train_micro_len * args.grad_accum_steps
    if effective_train_tokens != args.train_seq_len:
        print0(
            f"Adjusted train_micro_seq_len to {train_micro_len} (block-aligned). "
            f"Effective tokens per step: {effective_train_tokens} (requested {args.train_seq_len}).",
            console=True)

    warmup_needed = bool(args.do_model_warmup) and not shared_state.get("warmup_done", False)
    if warmup_needed and not using_cached:
        print0("Warming up kernels...", console=True)
        warmup_steps = 10
        initial_state = copy.deepcopy(dict(model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers]))
        warmup_loader = distributed_data_generator(
            args.train_files,
            world_size * train_micro_len,
            rank,
            world_size,
        )
        for warm_step in range(warmup_steps):
            model.zero_grad(set_to_none=True)
            for micro in range(args.grad_accum_steps):
                if micro == 0:
                    inputs, targets = next(warmup_loader)
                else:
                    inputs = targets = torch.randint(0, args.vocab_size, size=(train_micro_len,), device="cuda")
                outputs = model(inputs.to(torch.int32), targets, trainer.get_window_size_blocks(args, 0), 0, args.num_iterations)
                if isinstance(outputs, tuple):
                    loss_main, loss_aux = outputs
                    loss_val = float((loss_main + loss_aux).detach().item())
                    main_loss = float(loss_main.detach().item())
                    aux_loss = float(loss_aux.detach().item())
                    loss_total = (loss_main + loss_aux) / args.grad_accum_steps
                    loss_total.backward()
                else:
                    loss = outputs
                    loss_val = float(loss.detach().item())
                    components = model.latest_loss_components
                    main_loss = float(components[0].item()) if components else float("nan")
                    aux_loss = float(components[1].item()) if components else float("nan")
                    (loss / args.grad_accum_steps).backward()
                router_summary = summarize_router_metrics(model.latest_router_metrics or [])
                if args.enable_extra_logging:
                    print0(
                        f"[warmup {warm_step + 1}/{warmup_steps} micro {micro + 1}/{args.grad_accum_steps}] "
                        f"loss={loss_val:.6f} main={main_loss:.6f} aux={aux_loss:.6f} "
                        f"{router_summary_str(router_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
                        console=True)
            opt2futures = {
                opt: [dist.all_reduce(p.grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
                      for p in params if (p.grad is not None)]
                for opt, params in opt2params.items()
            }
            for opt in optimizers:
                torch.futures.collect_all(opt2futures[opt]).wait()
                opt.step()
            model.zero_grad(set_to_none=True)

        with torch.no_grad():
            model.bank.compile_warm_all_experts(d=args.model_dim, T_warm=128)

        with torch.no_grad():
            model.eval()
            val_inputs = torch.randint(0, args.vocab_size, size=(args.val_seq_len,), device="cuda")
            val_targets = torch.randint(0, args.vocab_size, size=(args.val_seq_len,), device="cuda")
            model(val_inputs.to(torch.int32), val_targets, trainer.get_window_size_blocks(args, 0), 0, args.num_iterations)
            model.train()


        model.load_state_dict(initial_state["model"])
        for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
            opt.load_state_dict(opt_state)
        if reuse_state is not None:
            shared_state["base_state"] = initial_state
            shared_state["warmup_done"] = True
        else:
            del initial_state
        print0("Kernel warmup complete.", console=True)

    if reuse_state is not None and shared_state.get("base_state") is None and not resume_path:
        shared_state["base_state"] = copy.deepcopy(
            dict(model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        )

    ########################################
    #        Training and validation       #
    ########################################

    torch.cuda.reset_peak_memory_stats()
    result = trainer.run_training(
        args=args,
        model=model,
        optimizers=optimizers,
        opt2params=opt2params,
        train_micro_len=train_micro_len,
        untie_lm_head_after=untie_lm_head_after,
        run_id_full=run_id_full,
        master_process=master_process,
        print0=print0,
        code=code,
        wandb_run=wandb_run,
        metrics_csv_writer=metrics_csv_writer,
        expert_usage_headers=expert_usage_headers,
        expert_active_headers=expert_active_headers,
        world_size=world_size,
        rank=rank,
        log_param_counts_fn=(lambda m: log_param_counts(m, args, print0)),
        start_step=start_step,
        checkpoint_save_step=args.checkpoint_save_step,
        early_stop_step=early_stop_step,
        early_stop_val_multiplier=early_stop_val_multiplier,
        early_stop_as_final=early_stop_is_final,
    )

    print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
        f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
    if master_process and results_path:
        payload = {"run_id": run_id_full}
        if isinstance(result, dict):
            payload.update(result)
        try:
            with open(results_path, "w") as f:
                json.dump(payload, f, indent=2, sort_keys=True)
        except Exception as err:
            print0(f"Failed to write results to {results_path}: {err}", console=True)
    if destroy_process_group and dist.is_initialized():
        dist.destroy_process_group()
    if wandb_run is not None:
        wandb_run.finish()
    if metrics_csv_file is not None:
        metrics_csv_file.close()
    return result

if __name__ == '__main__':
    run_training()
\n\n===== switch_bank/utils.py =====\nimport math
from functools import lru_cache
from typing import Iterable

import torch
from torch import Tensor
import torch.nn.functional as F


def _sanitize(t: Tensor, *, value: float = 0.0) -> Tensor:
    if torch.isfinite(t).all():
        return t
    return torch.nan_to_num(t, nan=value, posinf=value, neginf=value)


def _safe_softmax(logits: Tensor, dim: int) -> Tensor:
    logits = torch.nan_to_num(logits, nan=0.0, posinf=0.0)
    probs = logits.softmax(dim=dim)
    probs = _sanitize(probs)
    denom = probs.sum(dim=dim, keepdim=True).clamp_min(1e-6)
    return probs / denom


def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)


def rampdown_multiplier(progress: float, start_frac: float, end_frac: float) -> float:
    if end_frac < 0:
        return 1.0
    if progress >= end_frac:
        return 0.0
    if start_frac < 0 or start_frac >= end_frac:
        return 1.0
    if progress <= start_frac:
        return 1.0
    span = max(end_frac - start_frac, 1e-6)
    frac = 1.0 - (progress - start_frac) / span
    return min(max(frac, 0.0), 1.0)


def compute_train_micro_len(train_seq_len: int, grad_accum_steps: int, train_micro_seq_len: int | None) -> int:
    if train_micro_seq_len is not None:
        micro = train_micro_seq_len
    else:
        approx = max(train_seq_len // grad_accum_steps, 128)
        approx = (approx // 128) * 128
        if approx == 0:
            approx = 128
        micro = approx
    assert micro % 128 == 0, "train_micro_seq_len must be a multiple of 128 tokens (block size)"
    return micro


def summarize(values: Iterable[Tensor | float], reducer) -> dict:
    # Placeholder utility for potential future reductions; kept for parity with planned structure.
    return {}
\n\n===== switch_bank/optim/muon.py =====\nimport math
from typing import Any, Dict, Iterable, List, Optional, Tuple

import torch
import torch.distributed as dist
from torch import Tensor
from torch.optim import Optimizer

# Optional torch.compile compatibility
if hasattr(torch, "compile"):
    _compile = torch.compile
else:  # pragma: no cover
    def _compile(f):
        return f


def _as_full_prec_tensor(val: float, device: torch.device) -> Tensor:
    """
    Helper that mimics torch._as_tensor_fullprec where available, but safely
    falls back to a standard float32 tensor otherwise.
    """
    if hasattr(torch, "_as_tensor_fullprec"):
        # type: ignore[attr-defined]
        return torch._as_tensor_fullprec(val)  # pragma: no cover
    return torch.tensor(val, dtype=torch.float32, device=device)


def zeropower_via_newtonschulz5(G: Tensor) -> Tensor:
    """
    Reference Muon Newton–Schulz quintic iteration (unchanged).
    """
    assert G.ndim >= 2
    X = G.bfloat16()
    transposed = False
    if G.size(-2) > G.size(-1):
        X = X.mT
        transposed = True

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)

    # Quintic NS iterations
    for a, b, c in [
        (4.0848, -6.8946, 2.9270),
        (3.9505, -6.3029, 2.6377),
        (3.7418, -5.5913, 2.3037),
        (2.8769, -3.1427, 1.2046),
        (2.8366, -3.0525, 1.2012),
    ]:
        A = X @ X.mT
        B = b * A + c * (A @ A)
        X = a * X + B @ X

    if transposed:
        X = X.mT
    return X


@_compile
def _muon_update_kernel(
    acc_bf16_view_u16: Tensor,
    mantissa: Tensor,
    momentum_buffer: Tensor,
    grad: Tensor,
    momentum: Tensor,
    eff_lr: Tensor,
    eff_weight_decay: Tensor,
) -> None:
    """
    Bit-for-bit equivalent to the reference Muon update (kept intact).
    """
    assert acc_bf16_view_u16.dtype == mantissa.dtype == torch.uint16
    grad = grad.float()
    # Same two-step use of momentum as in the reference implementation
    momentum_buffer.copy_(momentum * momentum_buffer + (1 - momentum) * grad)
    v = zeropower_via_newtonschulz5(momentum * momentum_buffer + (1 - momentum) * grad)

    acc_m_u32 = (acc_bf16_view_u16.to(torch.uint32) << 16) | mantissa.to(torch.uint32)
    acc_view_f32 = acc_m_u32.view(torch.float32)
    acc_view_f32.mul_(1 - eff_weight_decay)
    acc_view_f32.add_(other=v, alpha=-eff_lr)
    acc_m_u32 = acc_view_f32.view(torch.uint32)
    acc_bf16_view_u16.copy_((acc_m_u32 >> 16).to(torch.uint16))
    mantissa.copy_(acc_m_u32.to(torch.uint16))


def power_iteration_smax(
    A: Tensor,
    iters: int = 2,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Approximate largest singular value of a (batched) 2D tensor via power iteration.
    """
    A = A.float()
    if A.ndim == 2:
        m, n = A.shape
        if (
            v_buf is not None
            and (v_buf.shape != (n,) or v_buf.device != A.device or v_buf.dtype != A.dtype)
        ):
            v_buf = None

        if v_buf is None:
            v = torch.randn(n, device=A.device, dtype=A.dtype, generator=generator)
        else:
            v = v_buf

        v.div_(v.norm() + 1e-8)
        for _ in range(iters):
            u = A @ v
            u = u / (u.norm() + 1e-8)
            v_new = A.mT @ u
            v_new = v_new / (v_new.norm() + 1e-8)
            if v_buf is None:
                v = v_new
            else:
                v.copy_(v_new)
        sigma = (A @ v).norm()
        return sigma

    # Batched matrices: treat leading dims as batch.
    m, n = int(A.size(-2)), int(A.size(-1))
    lead_shape = A.shape[:-2]
    A_flat = A.reshape(-1, m, n)
    batch = A_flat.size(0)

    if (
        v_buf is not None
        and (
            v_buf.shape != (*lead_shape, n)
            or v_buf.device != A.device
            or v_buf.dtype != A.dtype
        )
    ):
        v_buf = None

    if v_buf is None:
        v = torch.randn(batch, n, device=A.device, dtype=A.dtype, generator=generator)
    else:
        v = v_buf.reshape(batch, n)

    v.div_(v.norm(dim=1, keepdim=True) + 1e-8)
    for _ in range(iters):
        u = torch.bmm(A_flat, v.unsqueeze(-1)).squeeze(-1)
        u = u / (u.norm(dim=1, keepdim=True) + 1e-8)
        v_new = torch.bmm(A_flat.mT, u.unsqueeze(-1)).squeeze(-1)
        v_new = v_new / (v_new.norm(dim=1, keepdim=True) + 1e-8)
        if v_buf is None:
            v = v_new
        else:
            v.copy_(v_new)
    sigma = torch.bmm(A_flat, v.unsqueeze(-1)).squeeze(-1).norm(dim=1)
    return sigma.view(*lead_shape)


# ---- Turbo-Muon-style polar approximations ----

_ADANEWTON_COEFF_TABLE: Dict[Tuple[int, int], Tuple[float, float, float]] = {
    (2048, 2048): (3.3, -4.6, 2.0),
    (4096, 4096): (3.37, -4.9, 2.31),
    (3072, 2048): (2.9, -3.8, 1.86),
    (4096, 2048): (2.78, -3.49, 1.70),
}


def _get_adanewton_coeffs(m: int, n: int) -> Tuple[float, float, float]:
    if (m, n) in _ADANEWTON_COEFF_TABLE:
        return _ADANEWTON_COEFF_TABLE[(m, n)]
    if (n, m) in _ADANEWTON_COEFF_TABLE:
        return _ADANEWTON_COEFF_TABLE[(n, m)]
    # Default Muon-like coefficients
    return (3.44, -4.78, 2.03)


def _turbo_muon_polar(B: Tensor, ns_iters: int = 4) -> Tensor:
    """
    Turbo-Muon-inspired polar approximation:
    - Column-wise RMS preconditioning + few NS steps.
    """
    X = B.float()
    transposed = False
    if X.size(-2) > X.size(-1):
        X = X.mT
        transposed = True

    # Column-wise RMS preconditioning (per matrix, no batch mixing)
    col_rms = X.pow(2).mean(dim=-2, keepdim=True).sqrt().clamp_min(1e-6)
    X = X / col_rms

    # Normalize spectral norm
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)

    m, n = int(X.size(-2)), int(X.size(-1))
    a, b, c = _get_adanewton_coeffs(m, n)
    for _ in range(ns_iters):
        A = X @ X.mT
        X = a * X + b * (A @ X) + c * (A @ (A @ X))

    if transposed:
        X = X.mT
    return X


def approx_polar(
    B: Tensor,
    backend: str = "baseline",
    ns_iters: int = 4,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Approximate polar factor U for B ≈ U H with ||U||_op ≈ 1.
    backend:
      - "baseline": Muon zeropower_via_newtonschulz5
      - "turbo":    Turbo-Muon-style preconditioned NS
    """
    if backend == "turbo":
        U = _turbo_muon_polar(B, ns_iters=ns_iters)
    elif backend == "baseline":
        U = zeropower_via_newtonschulz5(B)
    else:
        raise ValueError(f"Unknown polar backend: {backend}")

    U = U.float()
    sigma_max = power_iteration_smax(U, iters=1, generator=generator, v_buf=v_buf)
    U = U / (sigma_max[..., None, None] + 1e-8)
    return U


def muon_like_spectral_update(
    B: Tensor,
    lr_spec_base: float,
    backend: str = "baseline",
    ns_iters: int = 4,
    generator: Optional[torch.Generator] = None,
    v_buf: Optional[Tensor] = None,
) -> Tensor:
    """
    Plain Muon-style spectral update.
    """
    U = approx_polar(B, backend=backend, ns_iters=ns_iters, generator=generator, v_buf=v_buf)
    m, n = int(U.size(-2)), int(U.size(-1))
    shape_scale = math.sqrt(max(1.0, float(m) / max(1.0, float(n))))
    return -lr_spec_base * shape_scale * U


def _adamw_update_param(
    p: Tensor,
    state: Dict[str, Any],
    lr: float,
    betas: Tuple[float, float],
    eps: float,
    weight_decay: float,
) -> None:
    """
    Full AdamW update for non-spectral (AdamW-only) parameters.
    """
    if p.grad is None:
        return
    g = p.grad
    if g.is_sparse:  # pragma: no cover
        raise RuntimeError("Muon does not support sparse gradients")

    g32 = g.detach().to(torch.float32)

    exp_avg = state.get("exp_avg")
    exp_avg_sq = state.get("exp_avg_sq")
    if exp_avg is None:
        exp_avg = torch.zeros_like(p, dtype=torch.float32)
        exp_avg_sq = torch.zeros_like(p, dtype=torch.float32)
        state["exp_avg"] = exp_avg
        state["exp_avg_sq"] = exp_avg_sq
        state["adam_step"] = 0

    beta1, beta2 = betas
    t = int(state.get("adam_step", 0)) + 1
    state["adam_step"] = t

    exp_avg.mul_(beta1).add_(g32, alpha=1.0 - beta1)
    exp_avg_sq.mul_(beta2).addcmul_(g32, g32, value=1.0 - beta2)

    bias_correction1 = 1.0 - beta1**t
    bias_correction2 = 1.0 - beta2**t

    m_hat = exp_avg / bias_correction1
    v_hat = exp_avg_sq / bias_correction2

    denom = v_hat.sqrt().add_(eps)
    step_dir = -lr * (m_hat / denom)

    # Decoupled weight decay
    if weight_decay != 0.0:
        p.mul_(1.0 - lr * weight_decay)

    p.add_(step_dir.to(p.dtype))


class Muon(Optimizer):
    """
    Muon: hybrid optimizer for switch-bank.

    - Muon mode is based on Keller Jordan's Muon (MomentUm Orthogonalized by Newton–Schulz):
      https://kellerjordan.github.io/posts/muon/
    - TurboMuon mode is a faster Muon-inspired approximate-polar update (see `_turbo_muon_polar`
      and `approx_polar`).

    Param groups:
      - spectral=True  (default): 2D+ bfloat16 matrices updated via Muon (Turbo off)
        or TurboMuon-style spectral updates (Turbo on).
      - spectral=False: AdamW-only parameters (embeddings, heads, biases, norms, etc).
    """

    def __init__(
        self,
        params: Iterable[Tensor] | Iterable[Dict[str, Any]],
        # AdamW / Euclidean hyperparams
        lr: float = 1e-3,
        betas: Tuple[float, float] = (0.9, 0.95),
        eps: float = 1e-8,
        weight_decay: float = 0.01,
        # Muon spectral hyperparams
        muon_momentum: float = 0.95,
        lr_spec: Optional[float] = None,
        ns_iters: int = 4,
        rank: int = 0,
        world_size: int = 1,
        enable_turbomuon: bool = True,
    ) -> None:
        if lr_spec is None:
            lr_spec = lr

        defaults: Dict[str, Any] = dict(
            lr=lr,
            betas=betas,
            eps=eps,
            weight_decay=weight_decay,
            momentum=muon_momentum,
            lr_spec=lr_spec,
            spectral=True,  # default; can be overridden per param-group
        )
        super().__init__(params, defaults)

        self.rank = int(rank)
        self.world_size = int(world_size)
        self.enable_turbomuon = bool(enable_turbomuon)
        self.ns_iters = int(ns_iters)

        self._step_count: int = 0
        self._turbo_rng: Optional[torch.Generator] = None
        self._turbo_rng_state: Optional[Tensor] = None
        self._turbomuon_warmstart_smax: bool = False

        # Muon constraint: spectral parameters must be bfloat16
        for group in self.param_groups:
            if group.get("spectral", True):
                for p in group["params"]:
                    if not isinstance(p, Tensor):
                        continue
                    # Only enforce for >=2D tensors; 0/1D will usually go to AdamW or be ignored.
                    if p.ndim >= 2 and p.dtype != torch.bfloat16:
                        raise ValueError(
                            "Muon spectral parameters (2D) must be torch.bfloat16 "
                            f"(got dtype={p.dtype} for param shape {tuple(p.shape)}). "
                            "Put non-bfloat16 or non-2D parameters into a param group "
                            "with spectral=False to use pure AdamW."
                        )

    def _get_turbo_rng(self, device: torch.device) -> torch.Generator:
        if self._turbo_rng is not None:
            return self._turbo_rng

        gen = torch.Generator(device=device)
        base_seed = int(torch.initial_seed())
        seed = (base_seed + 1000003 * int(self.rank)) & 0xFFFFFFFFFFFFFFFF
        gen.manual_seed(seed)

        if self._turbo_rng_state is not None:
            state_cpu = self._turbo_rng_state.detach().to(device="cpu")
            gen.set_state(state_cpu)
            self._turbo_rng_state = None

        self._turbo_rng = gen
        return gen

    def set_turbomuon_warmstart_smax(self, enabled: bool) -> None:
        self._turbomuon_warmstart_smax = bool(enabled)

    def state_dict(self) -> Dict[str, Any]:
        out = super().state_dict()
        if not out.get("param_groups"):
            return out

        turbo_state: Optional[Tensor] = None
        if self._turbo_rng is not None:
            turbo_state = self._turbo_rng.get_state()
        elif self._turbo_rng_state is not None:
            turbo_state = self._turbo_rng_state

        if turbo_state is not None:
            out["param_groups"][0]["turbo_rng_state"] = turbo_state.detach().to(device="cpu")

        return out

    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:
        turbo_state: Optional[Tensor] = None
        try:
            param_groups = state_dict.get("param_groups", [])
            if param_groups:
                turbo_state = param_groups[0].get("turbo_rng_state")
        except Exception:
            turbo_state = None

        super().load_state_dict(state_dict)
        self._turbo_rng = None
        self._turbo_rng_state = turbo_state

    @torch.no_grad()
    def step(self, closure: Optional[Any] = None) -> Optional[Tensor]:
        loss = None
        if closure is not None:
            with torch.enable_grad():
                loss = closure()

        self._step_count += 1
        global_step = self._step_count

        # 1) AdamW-only param groups (spectral=False) – always AdamW.
        for group in self.param_groups:
            if group.get("spectral", True):
                continue  # handled in spectral pass

            lr: float = float(group["lr"])
            betas: Tuple[float, float] = tuple(group["betas"])  # type: ignore[arg-type]
            eps: float = float(group["eps"])
            weight_decay: float = float(group["weight_decay"])

            for p in group["params"]:
                if not isinstance(p, Tensor):
                    continue
                if p.grad is None:
                    continue
                state = self.state[p]
                _adamw_update_param(p, state, lr, betas, eps, weight_decay)

        # If no spectral groups, we're done.
        has_spectral = any(group.get("spectral", True) for group in self.param_groups)
        if not has_spectral:
            return loss

        use_dist = (
            self.world_size > 1 and dist.is_available() and dist.is_initialized()
        )

        # 2) Spectral groups.
        if not self.enable_turbomuon:
            # --- Pure Muon mode for spectral groups (reference behaviour) ---
            futures: List[torch.futures.Future] = []

            for group in self.param_groups:
                if not group.get("spectral", True):
                    continue

                params: List[Tensor] = [p for p in group["params"] if isinstance(p, Tensor)]
                if not params:
                    continue

                if use_dist:
                    params_pad = params + [torch.empty_like(params[-1])] * self.world_size
                    momentum_t: Optional[Tensor] = None

                    for base_i in range(0, len(params), self.world_size):
                        idx = base_i + self.rank
                        if idx < len(params):
                            p = params[idx]
                            if p.grad is not None:
                                state = self.state[p]
                                if "mantissa" not in state:
                                    state["mantissa"] = torch.zeros_like(p, dtype=torch.uint16)
                                    state["momentum_buffer"] = torch.zeros_like(p, dtype=torch.float32)
                                if momentum_t is None:
                                    momentum_t = _as_full_prec_tensor(
                                        float(group["momentum"]), device=p.device
                                    )

                                eff_lr = float(group["lr"]) * math.sqrt(
                                    max(
                                        1.0,
                                        float(p.size(-2))
                                        / max(1.0, float(p.size(-1))),
                                    )
                                )
                                eff_lr_t = _as_full_prec_tensor(eff_lr, device=p.device)

                                eff_wd = float(group["lr"]) * float(group["weight_decay"]) * float(
                                    getattr(p, "wd_mul", 1.0)
                                )
                                eff_wd_t = _as_full_prec_tensor(eff_wd, device=p.device)

                                _muon_update_kernel(
                                    p.view(torch.uint16),
                                    state["mantissa"],
                                    state["momentum_buffer"],
                                    p.grad,
                                    momentum_t,
                                    eff_lr_t,
                                    eff_wd_t,
                                )
                            src = params_pad[idx]
                        else:
                            src = params_pad[-1]

                        out_list = params_pad[base_i : base_i + self.world_size]
                        work = dist.all_gather(out_list, src, async_op=True)
                        futures.append(work.get_future())

                    torch.futures.collect_all(futures).wait()

                else:
                    momentum_t: Optional[Tensor] = None
                    for p in params:
                        if p.grad is None:
                            continue
                        state = self.state[p]
                        if "mantissa" not in state:
                            state["mantissa"] = torch.zeros_like(p, dtype=torch.uint16)
                            state["momentum_buffer"] = torch.zeros_like(p, dtype=torch.float32)
                        if momentum_t is None:
                            momentum_t = _as_full_prec_tensor(
                                float(group["momentum"]), device=p.device
                            )

                        eff_lr = float(group["lr"]) * math.sqrt(
                            max(
                                1.0,
                                float(p.size(-2)) / max(1.0, float(p.size(-1))),
                            )
                        )
                        eff_lr_t = _as_full_prec_tensor(eff_lr, device=p.device)

                        eff_wd = float(group["lr"]) * float(group["weight_decay"]) * float(
                            getattr(p, "wd_mul", 1.0)
                        )
                        eff_wd_t = _as_full_prec_tensor(eff_wd, device=p.device)

                        _muon_update_kernel(
                            p.view(torch.uint16),
                            state["mantissa"],
                            state["momentum_buffer"],
                            p.grad,
                            momentum_t,
                            eff_lr_t,
                            eff_wd_t,
                        )

            return loss

        # --- TurboMuon mode for spectral groups ---
        for group in self.param_groups:
            if not group.get("spectral", True):
                continue

            params: List[Tensor] = [p for p in group["params"] if isinstance(p, Tensor)]
            if not params:
                continue

            lr: float = float(group["lr"])
            betas: Tuple[float, float] = tuple(group["betas"])  # type: ignore[arg-type]
            eps: float = float(group["eps"])
            weight_decay: float = float(group["weight_decay"])
            lr_spec: float = float(group.get("lr_spec", lr))

            if use_dist:
                params_pad = params + [torch.empty_like(params[-1])] * self.world_size

                for base_i in range(0, len(params), self.world_size):
                    idx = base_i + self.rank
                    if idx < len(params):
                        p = params[idx]
                        if p.grad is not None:
                            self._update_spectral_param_turbomuon(
                                p=p,
                                group_lr=lr,
                                lr_spec=lr_spec,
                                betas=betas,
                                eps=eps,
                                weight_decay=weight_decay,
                                global_step=global_step,
                            )
                        src = params_pad[idx]
                    else:
                        src = params_pad[-1]

                    out_list = params_pad[base_i : base_i + self.world_size]
                    dist.all_gather(out_list, src, async_op=False)

            else:
                for p in params:
                    if p.grad is None:
                        continue
                    self._update_spectral_param_turbomuon(
                        p=p,
                        group_lr=lr,
                        lr_spec=lr_spec,
                        betas=betas,
                        eps=eps,
                        weight_decay=weight_decay,
                        global_step=global_step,
                    )

        return loss

    @torch.no_grad()
    def _update_spectral_param_turbomuon(
        self,
        p: Tensor,
        group_lr: float,
        lr_spec: float,
        betas: Tuple[float, float],
        eps: float,
        weight_decay: float,
        global_step: int,
    ) -> None:
        state = self.state[p]
        g = p.grad
        if g is None:
            return

        # 0/1D in spectral groups → treat as AdamW for robustness.
        if p.ndim < 2:
            _adamw_update_param(p, state, group_lr, betas, eps, weight_decay)
            return

        g32 = g.detach().to(torch.float32)

        M = state.get("M")
        if M is None:
            M = torch.zeros_like(p, dtype=torch.float32)
        beta1_spec = betas[0]
        M.mul_(beta1_spec).add_(g32, alpha=1.0 - beta1_spec)
        state["M"] = M

        turbo_gen = self._get_turbo_rng(device=p.device)
        v_buf = None
        if self._turbomuon_warmstart_smax:
            v_buf = state.get("pi_v")
            if v_buf is None:
                v_shape = (*p.shape[:-2], int(p.size(-1)))
                v_buf = torch.randn(v_shape, device=p.device, dtype=torch.float32, generator=turbo_gen)
                state["pi_v"] = v_buf

        spec_dir = muon_like_spectral_update(
            M,
            lr_spec_base=lr_spec,
            backend="turbo",
            ns_iters=self.ns_iters,
            generator=turbo_gen,
            v_buf=v_buf,
        )

        if weight_decay != 0.0:
            p.mul_(1.0 - group_lr * weight_decay)

        p.add_(spec_dir.to(p.dtype))
\n\n===== switch_bank/model/components.py =====\nimport math
from collections import defaultdict
from typing import Any

import torch
from torch import Tensor, nn
import torch.nn.functional as F
from torch.nn.attention.flex_attention import BlockMask, flex_attention

from switch_bank.utils import _sanitize, _safe_softmax


def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))


@torch.no_grad()
def init_linear(w: Tensor):
    std = 0.5 * (w.size(-1) ** -0.5)
    bound = (3 ** 0.5) * std
    return w.uniform_(-bound, bound)


class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)


class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        self.qkvo_w = nn.Parameter(init_linear(torch.empty(4, hdim, dim)).bfloat16())
        self.qkvo_w.detach()[3].zero_()  # out zero init
        self.rotary = Rotary(head_dim, max_seq_len)
        self.attn_scale = 0.12

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask, lambdas: Tensor):
        B, T = x.size(0), x.size(1)
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        # Record input activations for Muon spectral gating.
        # This is a detached side-channel only; it does not affect numerics.
        self.qkvo_w._neomuon_last_activation = x.detach()
        q, k, v = F.linear(x, self.qkvo_w[:3].flatten(end_dim=1))\
                   .view(B, T, 3 * self.num_heads, self.head_dim)\
                   .chunk(3, dim=-2)
        q, k = norm(q), norm(k)
        q, k = self.rotary(q), self.rotary(k)
        v = norm(v)
        if ve is not None:
            v = lambdas[0] * v + lambdas[1] * ve.view_as(v)
        else:
            v = lambdas[0] * v
        q = _sanitize(q)
        k = _sanitize(k)
        v = _sanitize(v)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2),
                           block_mask=block_mask, scale=self.attn_scale).transpose(1, 2)
        y = _sanitize(y)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim)
        y = F.linear(y, self.qkvo_w[3])
        return _sanitize(y)


class SharedFFNBank(nn.Module):
    def __init__(self, d: int, h: int, E: int, L: int, flags_dim: int,
                 lb_coeff: float = 1e-3, ent_coeff: float = 0.0, k: int = 1,
                 use_adapters: bool = False,
                 ema_alpha_fwd: float = 0.80, ema_alpha_rev: float | None = None,
                 use_forward_ema: bool = True, use_reverse_ema: bool = False,
                 ema_block_size_fwd: int = 128, ema_block_size_rev: int = 128,
                 ema_window_size_fwd: int = -1, ema_window_size_rev: int = 128,
                 ema_layer_stride: int = 1,
                 extra_wandb_logging: bool = True,
                 adapter_layer_tie_map: list[int] | tuple[int, ...] | None = None):
        super().__init__()
        self.d, self.h, self.E, self.L = d, h, E, L
        self.flags_dim = flags_dim
        self.lb_coeff = lb_coeff
        self.ent_coeff = ent_coeff
        self.k = int(k)
        alpha_fwd_val = float(ema_alpha_fwd)
        alpha_rev_val = float(ema_alpha_rev if ema_alpha_rev is not None else ema_alpha_fwd)
        self.ema_alpha_min_fwd = alpha_fwd_val
        self.ema_alpha_max_fwd = alpha_fwd_val
        self.ema_alpha_min_rev = alpha_rev_val
        self.ema_alpha_max_rev = alpha_rev_val
        self.use_adapters = bool(use_adapters)
        self.use_forward_ema = bool(use_forward_ema)
        self.use_reverse_ema = bool(use_reverse_ema)
        self.enable_extra_wandb_logging = bool(extra_wandb_logging)
        self.ema_block_size_fwd = int(ema_block_size_fwd)
        self.ema_block_size_rev = int(ema_block_size_rev)
        self.ema_window_size_fwd = int(ema_window_size_fwd)
        self.ema_window_size_rev = int(ema_window_size_rev)
        self.ema_layer_stride = max(int(ema_layer_stride), 1)
        assert self.ema_layer_stride <= L, "ema_layer_stride must be <= number of layers"
        self._ema_cache_fwd: dict[int, Tensor] | None = None
        self._ema_cache_rev: dict[int, Tensor] | None = None
        if adapter_layer_tie_map is not None:
            if len(adapter_layer_tie_map) != L:
                raise ValueError("adapter_layer_tie_map must match number of layers")
            tie_map = [int(idx) for idx in adapter_layer_tie_map]
            for idx in tie_map:
                if idx < 0 or idx >= L:
                    raise ValueError("adapter_layer_tie_map contains out-of-range indices")
            self.adapter_layer_tie_map = tie_map
        else:
            self.adapter_layer_tie_map = None
        if self.use_adapters:
            self.adapter_scale = nn.Parameter(torch.ones(L, E, d).bfloat16())
            self.adapter_bias = nn.Parameter(torch.zeros(L, E, d).bfloat16())
            self.register_buffer("adapter_initialized", torch.zeros(L, E, dtype=torch.bool), persistent=False)
        else:
            self.adapter_scale = None
            self.adapter_bias = None
            self.adapter_initialized = None
        self.register_buffer("pruned_experts", torch.zeros(E, dtype=torch.bool), persistent=False)
        self.W1 = nn.ParameterList([nn.Parameter(init_linear(torch.empty(h, d)).bfloat16()) for _ in range(E)])
        self.W2 = nn.ParameterList([nn.Parameter(torch.zeros(d, h).bfloat16()) for _ in range(E)])
        for w in list(self.W1) + list(self.W2):
            w.wd_mul = 2.0
        feat_multiplier = 1 + int(self.use_forward_ema) + int(self.use_reverse_ema)
        in_dim = feat_multiplier * d + flags_dim
        self.router_w = nn.ParameterList([nn.Parameter(init_linear(torch.empty(E, in_dim)).bfloat16()) for _ in range(L)])
        self.router_b = nn.ParameterList([nn.Parameter(torch.zeros(E).bfloat16()) for _ in range(L)])
        if self.use_forward_ema:
            alpha_fwd = torch.full((L,), alpha_fwd_val, dtype=torch.bfloat16)
            self.register_buffer("ema_alpha", alpha_fwd)
        else:
            self.ema_alpha = None
        if self.use_reverse_ema:
            alpha_rev = torch.full((L,), alpha_rev_val, dtype=torch.bfloat16)
            self.register_buffer("ema_alpha_rev", alpha_rev)
        else:
            self.ema_alpha_rev = None
        self._router_metrics_buffer: list[dict[str, float] | None] | None = None

    def _adapter_layer_idx(self, layer_idx: int) -> int:
        if self.adapter_layer_tie_map is None:
            return layer_idx
        return int(self.adapter_layer_tie_map[layer_idx])

    @torch.no_grad()
    @torch._dynamo.disable
    def maybe_init_adapters(self, active_mask: torch.Tensor | None):
        if not (self.use_adapters and self.adapter_initialized is not None):
            return
        if active_mask is None:
            init_mask = torch.ones(self.E, dtype=torch.bool, device=self.adapter_initialized.device)
        else:
            init_mask = active_mask.to(device=self.adapter_initialized.device, dtype=torch.bool)
        if self.pruned_experts.any():
            init_mask = init_mask & (~self.pruned_experts.to(device=init_mask.device))
        if not init_mask.any():
            return
        seen_layers = set()
        for layer_idx in range(self.L):
            adapter_layer = self._adapter_layer_idx(layer_idx)
            if adapter_layer in seen_layers:
                continue
            seen_layers.add(adapter_layer)
            init_flags = self.adapter_initialized[adapter_layer]
            to_init = init_mask & (~init_flags)
            if not to_init.any():
                continue
            src_mask = init_mask & init_flags
            if src_mask.any():
                scale_mean = self.adapter_scale[adapter_layer, src_mask].mean(dim=0, keepdim=True)
                bias_mean = self.adapter_bias[adapter_layer, src_mask].mean(dim=0, keepdim=True)
            else:
                scale_mean = None
                bias_mean = None
            if scale_mean is not None:
                self.adapter_scale[adapter_layer, to_init] = scale_mean
                self.adapter_bias[adapter_layer, to_init] = bias_mean
            self.adapter_initialized[adapter_layer, to_init] = True

    @staticmethod
    def _ema_blockwise(x: Tensor, alpha: Tensor, block_size: int = 128) -> Tensor:
        B, T, D = x.shape
        assert B == 1
        a = _sanitize(alpha.float(), value=0.8).clamp(1e-4, 0.9999)
        one_minus = (1.0 - a)
        assert T % block_size == 0, "Sequence length must be a multiple of 128."
        nb = T // block_size
        x_blk = x.view(1, nb, block_size, D).float()
        ar = torch.arange(block_size, device=x.device, dtype=torch.float32)
        pow_a = a.pow(ar)
        pow_a_p1 = a.pow(ar + 1.0)
        pow_a_inv = a.pow(-ar)
        y = torch.empty_like(x_blk)
        carry = torch.zeros(1, 1, D, device=x.device, dtype=torch.float32)
        for b in range(nb):
            xb = x_blk[:, b]
            u = xb * pow_a_inv.view(1, -1, 1)
            prefix = torch.cumsum(u, dim=1)
            yb = pow_a_p1.view(1, -1, 1) * carry + (one_minus * (pow_a.view(1, -1, 1) * prefix))
            y[:, b] = yb
            carry = yb[:, -1:, :]
        out = y.view(1, T, D).to(dtype=x.dtype)
        return _sanitize(out)

    @staticmethod
    @torch._dynamo.disable
    def _ema_reverse_since_doc_start(x: Tensor, alpha: Tensor, doc_starts: torch.Tensor, window: int = 128, block_size: int = 128) -> Tensor:
        B, T, D = x.shape
        assert B == 1
        doc_starts = doc_starts.to(dtype=torch.bool, device=x.device)
        if not bool(doc_starts[0]):
            doc_starts[0] = True
        doc_bounds = torch.nonzero(doc_starts, as_tuple=True)[0]
        if doc_bounds.numel() == 0 or doc_bounds[0].item() != 0:
            doc_bounds = torch.cat([doc_bounds.new_tensor([0]), doc_bounds])
        doc_bounds = torch.cat([doc_bounds, doc_bounds.new_tensor([T])])
        out = torch.empty_like(x, dtype=torch.float32)
        a = _sanitize(alpha.float(), value=0.8).clamp(1e-4, 0.9999)
        for idx in range(doc_bounds.numel() - 1):
            start = int(doc_bounds[idx].item())
            end = int(doc_bounds[idx + 1].item())
            if end <= start:
                continue
            seg = x[:, start:end, :]
            length = end - start
            limit = min(window, length)
            if limit > 0:
                head = seg[:, :limit, :]
                rev = torch.flip(head, dims=(1,))
                pad = (-limit) % block_size
                if pad:
                    zero_pad = torch.zeros(1, pad, D, device=x.device, dtype=rev.dtype)
                    rev = torch.cat([rev, zero_pad], dim=1)
                ema = SharedFFNBank._ema_blockwise(rev, a, block_size=block_size)
                ema = ema[:, :limit]
                ema = torch.flip(ema, dims=(1,))
                out[:, start:start + limit] = ema
                if length > limit:
                    out[:, start + limit:end] = ema[:, -1:].expand(1, length - limit, D)
            else:
                out[:, start:end] = 0
        return _sanitize(out.to(dtype=x.dtype))

    def forward(self, x_norm: Tensor, layer_idx: int, flags: Tensor, temperature: float,
                logit_cap: float | None, freeze_ema_alpha: bool, use_gumbel: bool,
                lb_multiplier: float = 1.0, active_mask: Tensor | None = None,
                freeze_router_params: bool = False, freeze_adapter_params: bool = False,
                ema_limits_fwd: tuple[float, float] | None = None,
                ema_limits_rev: tuple[float, float] | None = None,
                freeze_ema_alpha_rev: bool = False) -> tuple[Tensor, Tensor]:
        assert x_norm.size(0) == 1
        deterministic_topk = False
        base_mask = torch.ones(self.E, dtype=torch.bool, device=x_norm.device)
        if active_mask is not None:
            base_mask &= active_mask.to(device=x_norm.device, dtype=torch.bool)
        if self.pruned_experts.any():
            base_mask &= (~self.pruned_experts.to(device=x_norm.device))
        if not base_mask.any():
            base_mask = torch.ones(self.E, dtype=torch.bool, device=x_norm.device)
        regular_active_count = int(base_mask.sum().item())
        if (regular_active_count == 1):
            deterministic_topk = True
            active_idx = int(base_mask.nonzero(as_tuple=True)[0].item())
        features: list[Tensor] = [x_norm]
        feat_names: list[str] = ["tok"]
        feat_sizes: list[int] = [self.d]
        alpha_use_rev = None
        alpha_use = None
        group_stride = max(self.ema_layer_stride, 1)
        base_layer = (layer_idx // group_stride) * group_stride
        if (not deterministic_topk) and self.use_forward_ema and self.ema_alpha is not None:
            min_alpha, max_alpha = (ema_limits_fwd if ema_limits_fwd is not None else (self.ema_alpha_min_fwd, self.ema_alpha_max_fwd))
            alpha_raw = self.ema_alpha[base_layer].float()
            alpha_clip = _sanitize(alpha_raw).clamp(min_alpha, max_alpha)
            alpha_use = alpha_clip.detach() if freeze_ema_alpha else alpha_clip
            cache_fwd = self._ema_cache_fwd if isinstance(self._ema_cache_fwd, dict) else None
            if cache_fwd is not None and base_layer in cache_fwd:
                ema_feat = cache_fwd[base_layer]
            else:
                if 0 < self.ema_window_size_fwd < x_norm.size(1):
                    head_len = min(self.ema_window_size_fwd, x_norm.size(1))
                    pad = (-head_len) % self.ema_block_size_fwd
                    head = x_norm[:, :head_len]
                    if pad:
                        head = torch.cat([head, torch.zeros(1, pad, self.d, device=head.device, dtype=head.dtype)], dim=1)
                    ema_head = self._ema_blockwise(head, alpha_use, block_size=self.ema_block_size_fwd)[:, :head_len]
                    ema_feat = x_norm.new_empty(x_norm.shape)
                    ema_feat[:, :head_len] = ema_head
                    ema_feat[:, head_len:] = ema_head[:, -1:].expand(1, x_norm.size(1) - head_len, self.d)
                else:
                    ema_feat = self._ema_blockwise(x_norm, alpha_use, block_size=self.ema_block_size_fwd)
                if cache_fwd is not None:
                    cache_fwd[base_layer] = ema_feat
            features.append(ema_feat)
            feat_names.append("ema_fwd")
            feat_sizes.append(self.d)
        if (not deterministic_topk) and self.use_reverse_ema and self.ema_alpha_rev is not None:
            min_alpha_rev, max_alpha_rev = (ema_limits_rev if ema_limits_rev is not None else (self.ema_alpha_min_rev, self.ema_alpha_max_rev))
            alpha_raw_rev = self.ema_alpha_rev[base_layer].float()
            alpha_clip_rev = _sanitize(alpha_raw_rev).clamp(min_alpha_rev, max_alpha_rev)
            alpha_use_rev = alpha_clip_rev.detach() if freeze_ema_alpha_rev else alpha_clip_rev
            cache_rev = self._ema_cache_rev if isinstance(self._ema_cache_rev, dict) else None
            if cache_rev is not None and base_layer in cache_rev:
                ema_rev = cache_rev[base_layer]
            else:
                doc_starts = (flags[0, :, 1].float() > 0.5)
                ema_rev = self._ema_reverse_since_doc_start(
                    x_norm, alpha_use_rev, doc_starts,
                    window=self.ema_window_size_rev, block_size=self.ema_block_size_rev,
                )
                if cache_rev is not None:
                    cache_rev[base_layer] = ema_rev
            features.append(ema_rev)
            feat_names.append("ema_rev")
            feat_sizes.append(self.d)
        feat_names.append("flags")
        feat_sizes.append(self.flags_dim)
        if deterministic_topk:
            effective_mask = base_mask
            probs = torch.zeros((1, x_norm.size(1), self.E), device=x_norm.device, dtype=x_norm.dtype)
            probs[..., active_idx] = 1.0
            topk_idx = torch.full((1, x_norm.size(1), 1), active_idx, device=x_norm.device, dtype=torch.int64)
            topk_prob = torch.ones_like(topk_idx, dtype=x_norm.dtype)
            max_logit = float("nan")
            imp = torch.zeros(self.E, device=x_norm.device, dtype=x_norm.dtype)
            imp[active_idx] = 1.0
            load = imp.clone()
            k = 1
        else:
            rin = _sanitize(torch.cat([*features, flags], dim=-1))
            logits = F.linear(rin, self.router_w[layer_idx], self.router_b[layer_idx]).float()
            if use_gumbel:
                u = torch.rand_like(logits).clamp_(1e-6, 1 - 1e-6)
                g = -torch.log(-torch.log(u))
                logits = logits + g
            logits = logits / max(temperature, 1e-6)
            if logit_cap is not None and logit_cap > 0:
                logits = logits.clamp(-logit_cap, logit_cap)
            logits = _sanitize(logits)
            if freeze_router_params:
                logits = logits.detach()
            effective_mask = None
            if base_mask is not None:
                effective_mask = base_mask.to(device=logits.device, dtype=torch.bool)
            if effective_mask is not None:
                if not effective_mask.any():
                    fallback = (~self.pruned_experts).to(device=logits.device)
                    if not fallback.any():
                        fallback = torch.ones(self.E, dtype=torch.bool, device=logits.device)
                    effective_mask = fallback
                logits = logits.masked_fill(~effective_mask.view(1, 1, -1), float("-inf"))
            probs = _safe_softmax(logits, dim=-1)
            max_logit = logits.max().item() if logits.numel() > 0 else float("nan")

            active_count = int(effective_mask.sum().item()) if effective_mask is not None else self.E
            k = max(1, min(self.k, active_count))
            topk_prob, topk_idx = probs.topk(k, dim=-1)
            if torch.isnan(topk_prob).any():
                probs = _safe_softmax(torch.zeros_like(logits), dim=-1)
                topk_prob, topk_idx = probs.topk(k, dim=-1)

            imp = _sanitize(probs.mean(dim=(0, 1)))
            top1 = topk_idx[..., 0]
            one_hot = F.one_hot(top1.view(-1), num_classes=self.E).float()
            load = _sanitize(one_hot.mean(dim=0))

        def cv2(v: Tensor):
            m = v.mean()
            return v.var(unbiased=False) / (m * m + 1e-6)

        imp_f = imp.float()
        load_f = load.float()
        single_active = (regular_active_count <= 1)

        imp_entropy = (-(imp_f + 1e-6).log().mul(imp_f)).sum()
        load_entropy = (-(load_f + 1e-6).log().mul(load_f)).sum()

        lb_term = (self.lb_coeff * lb_multiplier) * (cv2(imp_f) + cv2(load_f))
        #entropy_term = -self.ent_coeff * (load_entropy + imp_entropy)

        ############# Test
        expected_entropy = math.log(regular_active_count) if regular_active_count > 0 else float("nan")

        def _entropy_gap(val):
            if math.isnan(val) or math.isnan(expected_entropy) or expected_entropy <= 0:
                return float("nan")
            return max(0.0, abs(expected_entropy - val) / expected_entropy)

        load_entropy_gap = _entropy_gap(load_entropy)
        imp_entropy_gap = _entropy_gap(imp_entropy)
        entropy_term = self.ent_coeff * (load_entropy_gap + imp_entropy_gap)
        ############

        router_aux = lb_term + entropy_term

        if single_active:
            router_aux = router_aux.new_zeros(())

        other_aux = router_aux.new_zeros(())
        aux = router_aux + other_aux
        if freeze_router_params:
            if freeze_adapter_params:
                aux = x_norm.new_zeros(())
            else:
                aux = other_aux

        y = torch.zeros_like(x_norm)
        pruned_flags = self.pruned_experts.to(dtype=torch.bool, device=x_norm.device)
        for e in range(self.E):
            if pruned_flags[e]:
                continue
            union_mask = torch.zeros(topk_idx.size(1), dtype=torch.bool, device=x_norm.device)
            per_rank_masks = []
            for r in range(k):
                mr = (topk_idx[0, :, r] == e)
                per_rank_masks.append(mr)
                union_mask |= mr
            if not union_mask.any():
                continue
            x_e = x_norm[:, union_mask]
            if self.use_adapters:
                adapter_layer = self._adapter_layer_idx(layer_idx)
                scale = self.adapter_scale[adapter_layer, e]
                bias = self.adapter_bias[adapter_layer, e]
                if freeze_adapter_params:
                    scale = scale.detach()
                    bias = bias.detach()
                x_e = x_e * scale.to(x_e.dtype) + bias.to(x_e.dtype)
            # Record activations for Muon spectral gating.
            self.W1[e]._neomuon_last_activation = x_e.detach()
            h1 = F.linear(x_e, self.W1[e])
            h1 = F.relu(h1).square()
            self.W2[e]._neomuon_last_activation = h1.detach()
            out_e = F.linear(h1, self.W2[e])
            idx_union = union_mask.nonzero(as_tuple=True)[0]
            accum = torch.zeros_like(out_e)
            for r in range(k):
                mr = per_rank_masks[r]
                if not mr.any():
                    continue
                rel = torch.nonzero(mr[union_mask], as_tuple=True)[0]
                scales = topk_prob[0, mr, r].unsqueeze(-1)
                accum[:, rel] += scales * out_e[:, rel]
            y[:, idx_union] += accum

        stats: dict[str, Any] = dict(
            imp_cv2=float(cv2(_sanitize(imp_f)).item()),
            load_cv2=float(cv2(_sanitize(load_f)).item()),
            usage_frac=float(((load_f > 0).float().mean()).item()),
            topk_prob_mean=float(_sanitize(topk_prob).mean().item()),
            imp_entropy=float(imp_entropy.item()),
            load_entropy=float(load_entropy.item()),
        )
        if self.enable_extra_wandb_logging:
            if self.use_forward_ema and self.ema_alpha is not None and alpha_use is not None:
                stats["ema_alpha_forward"] = float(alpha_use.float().item())
            if self.use_reverse_ema and self.ema_alpha_rev is not None and alpha_use_rev is not None:
                stats["ema_alpha_reverse"] = float(alpha_use_rev.float().item())
            start_idx = 0
            for name, size in zip(feat_names, feat_sizes):
                end_idx = start_idx + size
                if end_idx > self.router_w[layer_idx].size(1):
                    break
                w_slice = self.router_w[layer_idx][:, start_idx:end_idx].float()
                stats[f"feat_w_{name}"] = float(w_slice.abs().mean().item())
                start_idx = end_idx
        stats["load_vector"] = _sanitize(load_f).detach().float().cpu()
        self._record_router_metrics(layer_idx, stats, max_logit)

        return y, aux

    @torch.no_grad()
    def compile_warm_all_experts(self, d: int, T_warm: int = 128):
        x = torch.randn(1, T_warm, d, device=self.W1[0].device, dtype=torch.bfloat16)
        for e in range(self.E):
            h1 = F.linear(x, self.W1[e]); h1 = F.relu(h1).square(); _ = F.linear(h1, self.W2[e])

    def begin_router_metrics(self):
        self._router_metrics_buffer = [None] * self.L
        self._ema_cache_fwd = {}
        self._ema_cache_rev = {}

    def _record_router_metrics(self, layer_idx: int, stats: dict[str, float], max_logit: float):
        if self._router_metrics_buffer is not None:
            stats = dict(stats)
            stats["max_logit"] = max_logit
            self._router_metrics_buffer[layer_idx] = stats

    def pop_router_metrics(self):
        metrics = self._router_metrics_buffer
        self._router_metrics_buffer = None
        return metrics or []

    @torch.no_grad()
    def prune_inactive_experts(self, activity: torch.Tensor, threshold: float) -> list[int]:
        if activity is None:
            return []
        if activity.numel() != self.E:
            return []
        device = self.pruned_experts.device
        activity = activity.to(device=device, dtype=torch.float32)
        available = (~self.pruned_experts)
        if not available.any():
            return []
        keep = (activity >= threshold) & available
        if not keep.any():
            masked_activity = activity.clone()
            masked_activity[~available] = float("-inf")
            best_idx = int(torch.argmax(masked_activity).item())
            keep[best_idx] = True
        pruned_mask = available & (~keep)
        new_pruned = pruned_mask.nonzero(as_tuple=True)[0].tolist()
        if not new_pruned:
            return []
        self.pruned_experts |= pruned_mask
        for idx in new_pruned:
            self.W1[idx].zero_()
            self.W2[idx].zero_()
        if self.use_adapters:
            mask = self.pruned_experts
            self.adapter_scale[:, mask] = 0
            self.adapter_bias[:, mask] = 0
        return new_pruned


class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int, skip_attn_layers: set[int],
                 peak_frac: float, temp_boost: float, lb_boost: float, boost_shape: str = "peak"):
        super().__init__()
        self.attn = None if layer_idx in skip_attn_layers else CausalSelfAttention(dim, num_heads, max_seq_len)
        self.layer_idx = layer_idx
        self.total_layers = None
        self.layer_peak_frac = float(peak_frac)
        self.temp_boost = float(temp_boost)
        self.lb_boost = float(lb_boost)
        self.boost_shape = (boost_shape or "peak").lower()

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask,
                lambdas: Tensor, sa_lambdas: Tensor, bank: SharedFFNBank, layer_idx: int,
                flags: Tensor, temperature: float, logit_cap: float | None,
                freeze_ema_alpha: bool, use_gumbel: bool, active_mask: Tensor | None,
                freeze_router_params: bool, freeze_adapter_params: bool,
                ema_limits_fwd: tuple[float, float] | None,
                ema_limits_rev: tuple[float, float] | None,
                freeze_ema_alpha_rev: bool, decay_scale: float) -> tuple[Tensor, Tensor]:
        if self.total_layers is None:
            self.total_layers = getattr(bank, "L", layer_idx + 1)
        layer_frac = layer_idx / max(self.total_layers - 1, 1)
        x = lambdas[0] * x + lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(x, ve, block_mask, sa_lambdas)
        peak = self.layer_peak_frac
        dist = abs(layer_frac - peak)
        denom = peak if layer_frac <= peak else max(1.0 - peak, 1e-6)
        shape_peak = max(0.0, 1.0 - dist / denom)
        if self.boost_shape == "valley":
            shape = 1.0 - shape_peak
        elif self.boost_shape == "linear_start":
            shape = max(0.0, min(1.0, 1.0 - layer_frac))
        elif self.boost_shape == "linear_end":
            shape = max(0.0, min(1.0, layer_frac))
        else:
            shape = shape_peak
        decay_scale = float(decay_scale)
        temp_multiplier = 1.0 + decay_scale * self.temp_boost * shape
        lb_multiplier = 1.0 + decay_scale * self.lb_boost * shape
        y, aux = bank(
            norm(x),
            layer_idx,
            flags,
            temperature * temp_multiplier,
            logit_cap,
            freeze_ema_alpha,
            use_gumbel,
            lb_multiplier,
            active_mask,
            freeze_router_params=freeze_router_params,
            freeze_adapter_params=freeze_adapter_params,
            ema_limits_fwd=ema_limits_fwd,
            ema_limits_rev=ema_limits_rev,
            freeze_ema_alpha_rev=freeze_ema_alpha_rev,
        )
        x = x + y
        return x, aux
\n\n===== switch_bank/model/gpt.py =====\nimport math
import os
from functools import lru_cache

import torch
from torch import Tensor, nn
import torch.nn.functional as F
from torch.nn.attention.flex_attention import BlockMask

from switch_bank.model.components import Block, SharedFFNBank, norm, init_linear
from switch_bank.utils import next_multiple_of_n


def _compute_router_temp(step: int, total_steps: int, t_init: float, t_final: float,
                         power: float, anchor_delta_steps: int, anchor_ratio: float | None,
                         start_step: int) -> float:
    if step <= start_step:
        return t_init
    effective_total = max(total_steps - start_step, 1)
    progress = (step - start_step) / effective_total
    power_use = power
    if anchor_delta_steps > 0 and anchor_ratio is not None and 0 < anchor_ratio < 1:
        anchor_progress = min(max(anchor_delta_steps / effective_total, 1e-6), 0.999999)
        power_use = math.log(anchor_ratio) / math.log(1.0 - anchor_progress)
    return t_final + (t_init - t_final) * (1.0 - progress) ** power_use


@lru_cache(None)
def _second_expert_step(expert_activation_schedule: tuple[tuple[int, int], ...]) -> int:
    if len(expert_activation_schedule) >= 2:
        return max(0, int(expert_activation_schedule[1][0]))
    if len(expert_activation_schedule) == 1:
        return max(0, int(expert_activation_schedule[0][0]))
    return 0


def _normalize_layer_tie_groups(
    tie_groups: tuple[tuple[int, ...], ...] | None,
    num_layers: int,
    skip_attn_layers: set[int],
) -> tuple[int, ...]:
    tie_map = list(range(num_layers))
    if not tie_groups:
        return tuple(tie_map)
    if not isinstance(tie_groups, (list, tuple)):
        raise ValueError("layer_tie_groups must be a sequence of layer index groups")
    tie_groups = tuple(tie_groups)
    if (
        len(tie_groups) == 1
        and isinstance(tie_groups[0], (list, tuple))
        and tie_groups[0]
        and all(isinstance(entry, (list, tuple)) for entry in tie_groups[0])
    ):
        tie_groups = tuple(tie_groups[0])
    used = set()
    for group in tie_groups:
        if not group:
            continue
        group_layers = []
        for idx in group:
            if isinstance(idx, (list, tuple)):
                raise ValueError("layer_tie_groups should be a sequence of layer indices; remove extra nesting")
            idx_i = int(idx)
            if idx_i < 0 or idx_i >= num_layers:
                raise ValueError(f"Layer tie index {idx_i} out of range for num_layers={num_layers}")
            if idx_i in used or idx_i in group_layers:
                raise ValueError(f"Layer {idx_i} appears multiple times in layer_tie_groups")
            if idx_i in skip_attn_layers:
                raise ValueError(f"Layer tie groups cannot include skip-attn layer {idx_i}")
            group_layers.append(idx_i)
        if len(group_layers) < 2:
            continue
        base = group_layers[0]
        for idx_i in group_layers:
            used.add(idx_i)
            tie_map[idx_i] = base
    return tuple(tie_map)


class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int,
                 skip_attn_layers: set[int], layer_tie_groups: tuple[tuple[int, ...], ...],
                 E: int, h: int, lb_coeff: float, ent_coeff: float, k: int,
                 num_value_embeds: int,
                 tie_lm_head: bool, untie_lm_head_after: int,
                 ema_alpha_fwd: float, ema_alpha_rev: float,
                 router_temp_init: float, router_temp_final: float, router_temp_power: float,
                 router_temp_anchor_delta_steps: int | None, router_temp_anchor_ratio: float | None,
                 router_logit_cap_initial: float, router_logit_cap_final: float, router_logit_cap_delta_steps: int,
                 router_layer_peak_frac: float, router_temp_boost: float, router_lb_boost: float, router_boost_shape: str,
                 use_router_adapters: bool, expert_activation_schedule: tuple[tuple[int, int], ...],
                 router_freeze_frac: float, router_freeze_adapters: bool,
                 ema_block_size_fwd: int, ema_block_size_rev: int,
                 ema_window_size_fwd: int, ema_window_size_rev: int,
                 ema_layer_stride: int,
                 shared_ffn_freeze_frac: float,
                 router_use_gumbel: bool, router_gumbel_schedule: tuple[tuple[int, int], ...],
                 router_block_pos_bins: int, first_doc_tokens_N: int,
                 router_enable_forward_ema: bool, router_enable_reverse_ema: bool,
                 extra_console_logging: bool, extra_wandb_logging: bool,
                 print_fn=None):
        super().__init__()
        self.vocab_size = vocab_size
        self.vocab_size_padded = next_multiple_of_n(vocab_size, n=128)
        self.embed = nn.Embedding(self.vocab_size_padded, model_dim)

        assert 0 <= num_value_embeds <= 3
        self.num_value_embeds = int(num_value_embeds)
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(self.num_value_embeds)])
        self.enable_forward_ema = bool(router_enable_forward_ema)
        self.enable_reverse_ema = bool(router_enable_reverse_ema)
        self.extra_console_logging = bool(extra_console_logging)
        self.extra_wandb_logging = bool(extra_wandb_logging)

        self.num_layers = num_layers
        self.layer_tie_map = _normalize_layer_tie_groups(layer_tie_groups, num_layers, skip_attn_layers)
        self.blocks = nn.ModuleList([
            Block(model_dim, num_heads, max_seq_len, i, skip_attn_layers,
                  router_layer_peak_frac, router_temp_boost, router_lb_boost, boost_shape=router_boost_shape)
            for i in range(num_layers)
        ])
        for idx, base in enumerate(self.layer_tie_map):
            if idx == base:
                continue
            base_attn = self.blocks[base].attn
            if base_attn is None:
                raise ValueError(f"Layer {base} has no attention but is used as a tie base")
            self.blocks[idx].attn = base_attn
        self.router_temp_boost = float(router_temp_boost)
        self.router_lb_boost = float(router_lb_boost)
        self.tie_lm_head = bool(tie_lm_head)
        self.untie_lm_head_after = int(untie_lm_head_after)
        needs_lm_head = (not self.tie_lm_head) or (self.untie_lm_head_after >= 0)
        self.lm_head = nn.Parameter(init_linear(torch.empty(self.vocab_size_padded, model_dim)).bfloat16()) if needs_lm_head else None
        self._head_tied_runtime = True
        if not self.tie_lm_head:
            self._head_tied_runtime = False

        assert 1 <= ema_layer_stride <= self.num_layers, "ema_layer_stride must be between 1 and num_layers"
        self.scalars = nn.Parameter(torch.cat([
            torch.ones(num_layers),
            *[torch.tensor([1.0, 0.0]) for _ in range(num_layers)],
            *[torch.tensor([0.5, 0.5]) for _ in range(num_layers)],
        ]))
        self.router_temp_init = float(router_temp_init)
        self.router_temp_final = float(router_temp_final)
        self.router_temp_power = float(router_temp_power)
        self.router_temp_anchor_delta_steps = (int(router_temp_anchor_delta_steps) if router_temp_anchor_delta_steps is not None else -1)
        self.router_temp_anchor_ratio = (float(router_temp_anchor_ratio) if router_temp_anchor_ratio is not None else None)
        self.router_logit_cap_delta_steps = int(router_logit_cap_delta_steps)
        self.router_logit_cap_initial = float(router_logit_cap_initial)
        self.router_logit_cap_final = float(router_logit_cap_final)
        self.router_use_gumbel = bool(router_use_gumbel)
        schedule: list[tuple[int, int]] = []
        for entry in router_gumbel_schedule:
            if len(entry) < 2:
                continue
            start, end = entry
            schedule.append((max(0, int(start)), int(end)))
        schedule.sort(key=lambda x: x[0])
        self.router_gumbel_schedule: tuple[tuple[int, int], ...] = tuple(schedule)
        self.second_expert_step_const = _second_expert_step(expert_activation_schedule)
        self.router_freeze_frac = float(router_freeze_frac)
        self.router_freeze_adapters = bool(router_freeze_adapters)
        self.shared_ffn_freeze_frac = float(shared_ffn_freeze_frac)
        self._router_frozen_logged = False
        self._ffn_frozen_logged = False

        assert router_block_pos_bins in (4, 8, 16), "router_block_pos_bins must be 4, 8, or 16"
        self.router_block_pos_bins = int(router_block_pos_bins)
        self.first_doc_tokens_N = int(first_doc_tokens_N)
        self.use_router_adapters = bool(use_router_adapters)
        self.num_experts = E
        schedule: list[tuple[int, int]] = []
        for entry in expert_activation_schedule:
            if len(entry) < 2:
                continue
            step_v, count = entry[0], entry[1]
            step_i = max(0, int(step_v))
            count_i = max(1, min(self.num_experts, int(count)))
            schedule.append((step_i, count_i))
        schedule.sort(key=lambda x: x[0])
        self.expert_activation_schedule: list[tuple[int, int]] = []
        for step_v, count in schedule:
            if self.expert_activation_schedule and step_v == self.expert_activation_schedule[-1][0]:
                self.expert_activation_schedule[-1] = (step_v, count)
            else:
                self.expert_activation_schedule.append((step_v, count))
        mask_needed = any(count < self.num_experts for _, count in self.expert_activation_schedule)
        if mask_needed:
            if not self.expert_activation_schedule:
                self.expert_activation_schedule = [(0, self.num_experts)]
            elif self.expert_activation_schedule[0][0] > 0:
                first = self.expert_activation_schedule[0][1]
                self.expert_activation_schedule.insert(0, (0, first))
            last_step, last_count = self.expert_activation_schedule[-1]
            if last_count < self.num_experts:
                self.expert_activation_schedule.append((last_step, self.num_experts))
        self._expert_schedule_requires_mask = mask_needed
        self._full_activation_step = self._compute_full_activation_step()
        self._full_activation_step = self._compute_full_activation_step()

        flags_dim = 3 + self.router_block_pos_bins

        self.bank = SharedFFNBank(
            d=model_dim, h=h, E=E, L=num_layers, flags_dim=flags_dim,
            lb_coeff=lb_coeff, ent_coeff=ent_coeff, k=k,
            use_adapters=use_router_adapters,
            ema_alpha_fwd=ema_alpha_fwd, ema_alpha_rev=ema_alpha_rev,
            use_forward_ema=self.enable_forward_ema, use_reverse_ema=self.enable_reverse_ema,
            ema_block_size_fwd=ema_block_size_fwd, ema_block_size_rev=ema_block_size_rev,
            ema_window_size_fwd=ema_window_size_fwd, ema_window_size_rev=ema_window_size_rev,
            ema_layer_stride=ema_layer_stride,
            extra_wandb_logging=self.extra_wandb_logging,
            adapter_layer_tie_map=self.layer_tie_map,
        )
        self.latest_router_metrics: list[dict[str, float] | None] | None = None
        self.latest_loss_components: tuple[Tensor, Tensor] | None = None
        self._last_active_expert_count: int | None = None
        self._current_base_active: int = self.num_experts
        self._pending_active_count: tuple[int, int] | None = None
        self._print0 = print_fn or (lambda *args, **kwargs: None)

    def _build_flags(self, input_seq: Tensor) -> Tensor:
        T = input_seq.size(0)
        device = input_seq.device
        is_eod_bool = (input_seq == 50256)
        is_eod = is_eod_bool.float().unsqueeze(0).unsqueeze(-1)
        start_flags = torch.zeros(T, dtype=torch.bool, device=device)
        start_flags[0] = True
        if T > 1:
            start_flags[1:] = is_eod_bool[:-1]
        is_after_eod = start_flags.float().unsqueeze(0).unsqueeze(-1)
        idx = torch.arange(T, device=device, dtype=torch.int64)
        start_idx = torch.where(start_flags, idx, torch.zeros_like(idx))
        last_start = torch.cummax(start_idx, dim=0)[0]
        dist_since_start = (idx - last_start).to(torch.int64)
        N = max(self.first_doc_tokens_N, 0)
        is_first_docN = (dist_since_start < N).float().unsqueeze(0).unsqueeze(-1)
        bins = self.router_block_pos_bins
        pos128 = idx % 128
        bin_idx = torch.clamp((pos128 * bins) // 128, max=bins - 1)
        onehot_bins = F.one_hot(bin_idx, num_classes=bins).float().unsqueeze(0)
        flags = torch.cat([is_eod, is_after_eod, is_first_docN, onehot_bins], dim=-1).to(dtype=torch.bfloat16)
        return flags

    def _ema_limits_for_progress(self, progress: float, reverse: bool = False) -> tuple[float, float]:
        if reverse:
            return (float(self.bank.ema_alpha_min_rev), float(self.bank.ema_alpha_max_rev))
        return (float(self.bank.ema_alpha_min_fwd), float(self.bank.ema_alpha_max_fwd))

    @torch._dynamo.disable
    def _active_expert_mask(self, step: int, device: torch.device) -> torch.Tensor | None:
        if not self._expert_schedule_requires_mask or not self.expert_activation_schedule:
            self._current_base_active = self.num_experts
            return None
        current = self.expert_activation_schedule[0]
        for stage in self.expert_activation_schedule:
            if step >= stage[0]:
                current = stage
            else:
                break
        active_count = max(1, min(self.num_experts, int(current[1])))
        self._current_base_active = active_count
        if active_count >= self.num_experts:
            self._expert_schedule_requires_mask = False
            self._mask_for_runtime = None
            return None
        mask = torch.zeros(self.num_experts, dtype=torch.bool, device=device)
        mask[:active_count] = True
        if mask.all():
            self._mask_for_runtime = None
            return None
        self._mask_for_runtime = mask
        return mask

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx

        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)

        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all

        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)

        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def compute_router_temp(self, step: int, total_steps: int) -> float:
        return _compute_router_temp(
            step, total_steps, self.router_temp_init, self.router_temp_final,
            self.router_temp_power, self.router_temp_anchor_delta_steps, self.router_temp_anchor_ratio,
            start_step=self.second_expert_step_const)

    def compute_logit_cap(self, step: int) -> float | None:
        start_step = self.second_expert_step_const
        delta = max(int(self.router_logit_cap_delta_steps), 0)
        start = self.router_logit_cap_initial
        end = self.router_logit_cap_final
        if delta <= 0:
            return end if end > 0 else None
        if step < start_step:
            return start if start > 0 else None
        frac = min(max((step - start_step) / max(delta, 1), 0.0), 1.0)
        if start <= 0 and end <= 0:
            return None
        if start <= 0:
            return end
        if end <= 0:
            return max(start * (1.0 - frac), 0.0)
        shaped = frac ** 4.0
        return start * math.exp(math.log(end / start) * shaped)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor,
                step: int, total_steps: int):
        assert input_seq.ndim == 1
        self.bank.begin_router_metrics()
        self.latest_loss_components = None
        head_should_be_tied = self._head_should_be_tied(step)
        if self.lm_head is not None and self._head_tied_runtime and not head_should_be_tied:
            self.lm_head.data.copy_(self.embed.weight.data)
        self._head_tied_runtime = head_should_be_tied

        progress = step / max(total_steps, 1)
        active_mask = self._active_expert_mask(step, input_seq.device)
        self.bank.maybe_init_adapters(active_mask)
        ema_limits_fwd = self._ema_limits_for_progress(progress, reverse=False)
        ema_limits_rev = self._ema_limits_for_progress(progress, reverse=True)
        freeze_router_params = (progress >= self.router_freeze_frac)
        freeze_adapter_params = (freeze_router_params and self.router_freeze_adapters)
        freeze_ffn = (progress >= self.shared_ffn_freeze_frac)
        base_active = getattr(self, "_current_base_active", self.num_experts if active_mask is None else int(active_mask.sum().item()))
        if self.training:
            last_logged = getattr(self, "_last_active_expert_count", None)
            if last_logged is None or base_active > last_logged:
                self._last_active_expert_count = base_active
                self._pending_active_count = (step, base_active)
        if freeze_router_params and not self._router_frozen_logged and self.extra_console_logging:
            self._print0(f"Routers frozen at step {step}", console=True)
            self._router_frozen_logged = True
        if freeze_ffn and not self._ffn_frozen_logged and self.extra_console_logging:
            self._print0(f"Shared FFN frozen at step {step}", console=True)
            self._ffn_frozen_logged = True
        T_cur = self.compute_router_temp(step, total_steps)
        logit_cap = self.compute_logit_cap(step)
        decay_scale = 1.0
        freeze_ema_alpha_fwd = True
        freeze_ema_alpha_rev = True
        use_gumbel_now = False
        if self.router_use_gumbel:
            for start, end in self.router_gumbel_schedule:
                end_eff = total_steps if end < 0 else end
                if start <= step < end_eff:
                    use_gumbel_now = True
                    break

        ve_tables = [value_embed(input_seq) for value_embed in self.value_embeds]
        L = len(self.blocks)
        if self.num_value_embeds == 3:
            ve = [ve_tables[0], ve_tables[1], ve_tables[2]] + [None] * max(L - 6, 0) + [ve_tables[0], ve_tables[1], ve_tables[2]]
        elif self.num_value_embeds == 2:
            ve = [ve_tables[0], ve_tables[1]] + [None] * max(L - 4, 0) + [ve_tables[0], ve_tables[1]]
        elif self.num_value_embeds == 1:
            ve = [ve_tables[0]] + [None] * max(L - 2, 0)
            if L >= 2:
                ve.append(ve_tables[0])
        else:
            ve = [None] * L
        if len(ve) < L:
            ve = ve + [None] * (L - len(ve))
        elif len(ve) > L:
            ve = ve[:L]

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        if L == 28:
            long_ids = {0, 4, 8, 12, 16, 20, 24}
        elif L == 32:
            long_ids = {0, 4, 8, 12, 16, 20, 24, 28}
        else:
            stride = max(L // 4, 1)
            long_ids = set(range(0, L, stride))
        block_masks = [long_bm if i in long_ids else short_bm for i in range(L)]

        x = x0 = norm(self.embed(input_seq)[None])
        flags = self._build_flags(input_seq)

        skip_connections = []
        skip_map = {9: 6, 10: 4, 11: 2}
        skip_weights = self.scalars[:L]
        lambdas = self.scalars[1 * L: 3 * L].view(-1, 2)
        sa_lambdas = self.scalars[3 * L: 5 * L].view(-1, 2)

        aux_loss = x.new_zeros(()).float()
        for i in range(L):
            if i in skip_map and skip_map[i] < len(skip_connections):
                x = x + skip_weights[skip_map[i]] * skip_connections[skip_map[i]]
            if freeze_ffn:
                with torch.no_grad():
                    y, aux = self.blocks[i](
                        x, ve[i], x0, block_masks[i], lambdas[i], sa_lambdas[i],
                        self.bank, i, flags, float(T_cur),
                        (float(logit_cap) if logit_cap is not None else None),
                        freeze_ema_alpha_fwd, use_gumbel_now, active_mask,
                        freeze_router_params=freeze_router_params,
                        freeze_adapter_params=freeze_adapter_params,
                        ema_limits_fwd=ema_limits_fwd,
                        ema_limits_rev=ema_limits_rev,
                        freeze_ema_alpha_rev=freeze_ema_alpha_rev,
                        decay_scale=decay_scale,
                    )
                y = y.detach()
                aux = aux.detach()
            else:
                y, aux = self.blocks[i](
                    x, ve[i], x0, block_masks[i], lambdas[i], sa_lambdas[i],
                    self.bank, i, flags, float(T_cur),
                    (float(logit_cap) if logit_cap is not None else None),
                    freeze_ema_alpha_fwd, use_gumbel_now, active_mask,
                    freeze_router_params=freeze_router_params,
                    freeze_adapter_params=freeze_adapter_params,
                    ema_limits_fwd=ema_limits_fwd,
                    ema_limits_rev=ema_limits_rev,
                    freeze_ema_alpha_rev=freeze_ema_alpha_rev,
                    decay_scale=decay_scale,
                )
            x = y
            aux_loss = aux_loss + aux
            skip_connections.append(x)

        x = norm(x)
        self.latest_router_metrics = self.bank.pop_router_metrics()
        if self.training:
            logits: Tensor = F.linear(x.flatten(end_dim=1), self._lm_head_weight()).float()
            loss_main = F.cross_entropy(15 * logits * torch.rsqrt(logits.square() + 225), target_seq)
            self.latest_loss_components = (loss_main.detach(), aux_loss.detach())
            return loss_main, aux_loss

        loss = 0
        for i in range(4):
            logits: Tensor = F.linear(x.flatten(end_dim=1).chunk(4)[i], self._lm_head_weight()).float()
            loss += F.cross_entropy(15 * logits * torch.rsqrt(logits.square() + 225), target_seq.chunk(4)[i]) / 4
        self.latest_loss_components = None
        return loss

    def _head_should_be_tied(self, step: int) -> bool:
        if not self.tie_lm_head:
            return False
        if self.untie_lm_head_after >= 0:
            return step < self.untie_lm_head_after
        return True

    def _lm_head_weight(self) -> Tensor:
        if self.lm_head is None or self._head_tied_runtime:
            return self.embed.weight.bfloat16()
        return self.lm_head.bfloat16()

    def _compute_full_activation_step(self) -> int:
        step_full = 0
        for step_v, count in self.expert_activation_schedule:
            if count >= self.num_experts:
                step_full = int(step_v)
                break
        return max(0, step_full)

    def _latest_activation(self, step: int) -> tuple[int, int]:
        last_step = 0
        last_count = 0
        for stage_step, count in self.expert_activation_schedule:
            if step >= stage_step:
                last_step = int(stage_step)
                last_count = int(count)
            else:
                break
        return last_step, last_count
\n\n===== switch_bank/data.py =====\nimport torch
from pathlib import Path
from torch import Tensor


def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32)
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2])
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True)
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy())
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens


def distributed_data_generator(filename_pattern: str, batch_size: int, rank: int, world_size: int, skip_batches: int = 0):
    files = sorted(Path.cwd().glob(filename_pattern))
    if not files:
        raise RuntimeError(f"No data files match pattern '{filename_pattern}' in {Path.cwd()}")
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files)
    try:
        tokens, pos = _load_data_shard(next(file_iter)), 0
    except StopIteration as exc:
        raise RuntimeError(f"No data files available for pattern '{filename_pattern}'") from exc
    # fast-forward if resuming
    while skip_batches > 0:
        if pos + batch_size + 1 >= len(tokens):
            try:
                tokens, pos = _load_data_shard(next(file_iter)), 0
            except StopIteration:
                raise RuntimeError(f"Ran out of data while skipping batches for '{filename_pattern}'")
        pos += batch_size
        skip_batches -= 1

    while True:
        if pos + batch_size + 1 >= len(tokens):
            try:
                tokens, pos = _load_data_shard(next(file_iter)), 0
            except StopIteration:
                return
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True)
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True)
        pos += batch_size
        yield inputs, targets


def summarize_router_metrics(metrics: list[dict[str, float] | None]) -> dict[str, float]:
    summary: dict[str, float] = {}
    counts: dict[str, int] = {}
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        for key, value in layer_stats.items():
            if isinstance(value, torch.Tensor):
                if value.numel() == 1:
                    value = float(value.item())
                else:
                    continue
            elif not isinstance(value, (int, float)):
                continue
            summary[key] = summary.get(key, 0.0) + float(value)
            counts[key] = counts.get(key, 0) + 1
    for key, total in list(summary.items()):
        summary[key] = total / max(counts.get(key, 1), 1)
    return summary


def summarize_expert_usage(metrics: list[dict[str, float] | None], num_experts: int) -> Tensor | None:
    accum: Tensor | None = None
    count = 0
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        load_vec = layer_stats.get("load_vector")
        if load_vec is None:
            continue
        load_vec = load_vec.to(torch.float32)
        if load_vec.numel() != num_experts:
            continue
        if accum is None:
            accum = load_vec.clone()
        else:
            accum += load_vec
        count += 1
    if accum is None or count == 0:
        return None
    return (accum / count).cpu()


def summarize_expert_activity(metrics: list[dict[str, float] | None], num_experts: int) -> Tensor | None:
    accum: Tensor | None = None
    count = 0
    for layer_stats in metrics or []:
        if not layer_stats:
            continue
        load_vec = layer_stats.get("load_vector")
        if load_vec is None:
            continue
        load_vec = load_vec.to(torch.float32)
        if load_vec.numel() != num_experts:
            continue
        active = (load_vec > 0).to(torch.float32)
        if accum is None:
            accum = active.clone()
        else:
            accum += active
        count += 1
    if accum is None or count == 0:
        return None
    return (accum / count).cpu()


def router_summary_str(summary: dict[str, float], enable_forward_ema: bool, enable_reverse_ema: bool) -> str:
    if not summary:
        return "router=NA"
    fragments = []
    extra_keys: list[str] = []
    if enable_forward_ema:
        extra_keys.append("ema_alpha_forward")
    if enable_reverse_ema:
        extra_keys.append("ema_alpha_reverse")
    keys = ("imp_cv2", "load_cv2", "usage_frac", "topk_prob_mean", *extra_keys, "max_logit")
    for key in keys:
        val = summary.get(key, float("nan"))
        fragments.append(f"{key}={val:.4f}")
    return " ".join(fragments)
\n\n===== switch_bank/trainer.py =====\nimport copy
import math
import time
import os
from functools import lru_cache
from collections import defaultdict, deque

import torch
import torch.distributed as dist
import torch.nn.functional as F
from torch import nn

from switch_bank.utils import next_multiple_of_n, rampdown_multiplier
from switch_bank.data import (
    distributed_data_generator,
    summarize_router_metrics,
    summarize_expert_usage,
    summarize_expert_activity,
    router_summary_str,
)
from switch_bank.model.gpt import _compute_router_temp, _second_expert_step
from switch_bank.model.components import CausalSelfAttention

def get_lr(args, step: int):
    freeze_last = max(int(getattr(args, "lr_freeze_last_steps", 0)), 0)
    schedule_step = min(step, max(args.num_iterations - freeze_last, 0))
    x = schedule_step / max(args.num_iterations, 1)
    x = min(max(x, 0.0), 1.0)
    if x < 1 - args.cooldown_frac:
        return 1.0
    cooldown = max(args.cooldown_frac, 1e-8)
    t = (x - (1 - cooldown)) / cooldown
    t = min(max(t, 0.0), 1.0)
    final_mult = float(getattr(args, "lr_final_mult", 0.0))
    return 1.0 - t * (1.0 - final_mult)


@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)


def get_window_size_blocks(args, step: int):
    x = step / args.num_iterations
    assert 0 <= x <= 1
    factor = 4 * x ** 3 - 6 * x ** 2 + 3 * x
    window_size = next_multiple_of_n(3456 * factor, n=128)
    return get_window_size_blocks_helper(window_size)


def get_router_temp(args, step: int):
    return _compute_router_temp(
        step, args.num_iterations, args.router_temp_init, args.router_temp_final,
        args.router_temp_power, args.router_temp_anchor_delta_steps, args.router_temp_anchor_ratio,
        start_step=_second_expert_step(tuple(args.expert_activation_schedule)))


def get_logit_cap(args, step: int):
    start_step = _second_expert_step(tuple(args.expert_activation_schedule))
    delta = max(int(args.router_logit_cap_delta_steps), 0)
    start = args.router_logit_cap_initial
    end = args.router_logit_cap_final
    if delta <= 0:
        return end if end > 0 else None
    if step < start_step:
        return start if start > 0 else None
    frac = min(max((step - start_step) / max(delta, 1), 0.0), 1.0)
    if start <= 0 and end <= 0:
        return None
    if start <= 0:
        return end
    if end <= 0:
        return max(start * (1.0 - frac), 0.0)
    shaped = frac ** 4.0
    return start * math.exp(math.log(end / start) * shaped)

def gumbel_active(args, step: int):
    if not args.router_use_gumbel:
        return False
    schedule = getattr(args, "router_gumbel_schedule", ())
    for start, end in schedule:
        end_eff = args.num_iterations if end < 0 else end
        if start <= step < end_eff:
            return True
    return False


def _update_logit_stats(logit_stats: dict[str, float], max_logit: float, logit_cap: float | None):
    if logit_cap is None or logit_cap <= 0 or math.isnan(logit_cap):
        return
    if math.isnan(max_logit) or math.isinf(max_logit):
        return
    ratio = max_logit / logit_cap if logit_cap > 0 else float("nan")
    if math.isnan(ratio) or math.isinf(ratio):
        return
    ratio = min(max(ratio, 0.0), 1.5)
    logit_stats["count"] += 1.0
    logit_stats["sum_ratio"] += ratio
    if ratio >= 0.98:
        logit_stats["cap_hits"] += 1.0
    if ratio > logit_stats["max_ratio"]:
        logit_stats["max_ratio"] = ratio


def _finalize_logit_stats(logit_stats: dict[str, float]) -> dict[str, float]:
    count = int(logit_stats.get("count", 0.0))
    if count <= 0:
        return {
            "logit_cap_steps": 0.0,
            "logit_cap_hit_rate": float("nan"),
            "logit_cap_ratio_mean": float("nan"),
            "logit_cap_ratio_max": float("nan"),
            "logit_headroom_mean": float("nan"),
            "logit_score": float("nan"),
        }
    mean_ratio = logit_stats.get("sum_ratio", 0.0) / max(count, 1)
    cap_hit_rate = logit_stats.get("cap_hits", 0.0) / max(count, 1)
    ratio_target = 0.85
    ratio_score = 1.0 - abs(mean_ratio - ratio_target) / max(ratio_target, 1e-8)
    ratio_score = min(max(ratio_score, 0.0), 1.0)
    logit_score = 0.7 * (1.0 - cap_hit_rate) + 0.3 * ratio_score
    logit_score = min(max(logit_score, 0.0), 1.0)
    return {
        "logit_cap_steps": float(count),
        "logit_cap_hit_rate": float(cap_hit_rate),
        "logit_cap_ratio_mean": float(mean_ratio),
        "logit_cap_ratio_max": float(logit_stats.get("max_ratio", 0.0)),
        "logit_headroom_mean": float(1.0 - mean_ratio),
        "logit_score": float(logit_score),
    }


def run_training(
    args,
    model: nn.Module,
    optimizers: list[torch.optim.Optimizer],
    opt2params: dict,
    train_micro_len: int,
    untie_lm_head_after: int,
    run_id_full: str | None,
    master_process: bool,
    print0,
    code: str,
    wandb_run,
    metrics_csv_writer,
    expert_usage_headers: list[str],
    expert_active_headers: list[str],
    world_size: int,
    rank: int,
    log_param_counts_fn=None,
    start_step: int = 0,
    checkpoint_save_step: int = -1,
    early_stop_step: int | None = None,
    early_stop_val_multiplier: int = 1,
    early_stop_as_final: bool = False,
):
    training_time_ms = 0
    log_dir = getattr(args, "log_dir", "logs")
    approx_step_time_ms_resume = getattr(args, "approx_step_time_ms", None)
    train_loader = distributed_data_generator(
        args.train_files,
        world_size * train_micro_len,
        rank,
        world_size,
        skip_batches=start_step * args.grad_accum_steps,
    )
    print0("Starting training.", console=True)
    dist.barrier()
    t0 = time.perf_counter()
    train_steps = args.num_iterations
    stop_step = train_steps if early_stop_step is None else min(train_steps, early_stop_step)
    last_val_loss: float | None = None
    gumbel_prev_state = gumbel_active(args, start_step - 1) if start_step > 0 else gumbel_active(args, 0)
    logit_cap_decay_logged = False
    lm_head_untie_step = untie_lm_head_after
    lm_head_untied_logged = lm_head_untie_step < 0
    turbo_muon_warmstart_prev: bool | None = None
    turbo_muon_warmstart_start_step: int | None = None
    warmstart_start_frac = float(getattr(args, "turbo_muon_warmstart_smax_start_frac", -1.0))
    if warmstart_start_frac >= 0:
        turbo_muon_warmstart_start_step = int(warmstart_start_frac * train_steps)
        turbo_muon_warmstart_start_step = min(max(turbo_muon_warmstart_start_step, 0), train_steps)

    logit_stats = {"count": 0.0, "sum_ratio": 0.0, "cap_hits": 0.0, "max_ratio": 0.0}

    def run_validation(val_steps_multiplier: float, log_val_loss: bool, extra_log: dict | None = None, log_to_wandb: bool = True):
        nonlocal training_time_ms, t0, last_val_loss
        dist.barrier()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        print0("Running validation...")
        model.eval()
        prev_k = model.bank.k
        model.bank.k = int(args.topk if args.topk_val is None else max(1, min(args.topk_val, args.num_experts)))
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        base_steps = args.val_tokens // val_batch_size
        val_steps = int(round(base_steps * float(val_steps_multiplier)))
        val_steps = max(val_steps, 1)
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, window_blocks, step, args.num_iterations)
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_scalar = float(val_loss.detach().item())
        last_val_loss = val_scalar
        print0(
            f"step:{step}/{train_steps} val_loss:{val_scalar:.6f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms / max(step, 1):.2f}ms",
            console=True)
        if wandb_run is not None and log_to_wandb:
            log_payload = {
                "val/step": step,
                "perf/approx_step_time_ms": training_time_ms,
            }
            if log_val_loss:
                log_payload["val/loss"] = val_scalar
            if extra_log:
                log_payload.update(extra_log)
            wandb_run.log(log_payload, step=step)
        model.train()
        model.bank.k = prev_k
        dist.barrier()
        t0 = time.perf_counter()
        return val_scalar

    if start_step == 0 and (early_stop_step is None or early_stop_step > 0):
        step = 0
        window_blocks = get_window_size_blocks(args, step)
        tokens_target = getattr(args, "val_tokens_intermediate", None)
        if tokens_target is None:
            tokens_target = args.val_tokens
        val_steps_multiplier = float(tokens_target) / float(args.val_tokens)
        run_validation(val_steps_multiplier, log_val_loss=True)

    router_clip_base = getattr(args, "router_grad_clip_norm", None)
    router_clip_base = float(router_clip_base) if router_clip_base is not None else None
    if router_clip_base is not None and router_clip_base <= 0:
        router_clip_base = None
    router_params_by_opt: dict[torch.optim.Optimizer, list[nn.Parameter]] = {}
    router_autoclip = bool(getattr(args, "router_autoclip", False))
    autoclip_window = 250
    router_autoclip_state: dict[torch.optim.Optimizer, dict[str, object]] = {}
    needs_router_clip = router_autoclip or (router_clip_base is not None)
    if needs_router_clip:
        for opt in optimizers:
            params = []
            for group in opt.param_groups:
                if group.get("component") == "router":
                    params.extend(group["params"])
            if params:
                router_params_by_opt[opt] = params
                if router_autoclip:
                    initial_clip = router_clip_base if router_clip_base is not None else None
                    router_autoclip_state[opt] = {
                        "history": deque(maxlen=autoclip_window),
                        "clip": (initial_clip if (initial_clip is not None and initial_clip > 0) else None),
                    }

    for step in range(start_step, train_steps + 1):
        final_step = (step == train_steps)
        last_step = (step == stop_step)
        finalize_now = final_step or (early_stop_as_final and last_step)
        turbo_muon_warmstart_now = (
            turbo_muon_warmstart_start_step is not None and step >= turbo_muon_warmstart_start_step
        )
        if turbo_muon_warmstart_prev is None or turbo_muon_warmstart_now != turbo_muon_warmstart_prev:
            for opt in optimizers:
                if hasattr(opt, "set_turbomuon_warmstart_smax"):
                    opt.set_turbomuon_warmstart_smax(turbo_muon_warmstart_now)
            turbo_muon_warmstart_prev = turbo_muon_warmstart_now
        window_blocks = get_window_size_blocks(args, step)
        progress = step / max(train_steps, 1)
        gumbel_now = gumbel_active(args, step)
        if args.enable_extra_logging and gumbel_now != gumbel_prev_state:
            status = "enabled" if gumbel_now else "disabled"
            print0(f"Gumbel router noise {status} at step {step}", console=True)
        gumbel_prev_state = gumbel_now
        current_logit_cap = get_logit_cap(args, step)
        cap_start_step = _second_expert_step(tuple(args.expert_activation_schedule))
        if not logit_cap_decay_logged and step >= cap_start_step:
            cap_str = f"{current_logit_cap:.4f}" if current_logit_cap is not None else "disabled"
            if args.enable_extra_logging:
                print0(f"Router logit cap entered ramp at step {step}: cap={cap_str}", console=True)
            logit_cap_decay_logged = True
        if (not lm_head_untied_logged) and lm_head_untie_step >= 0 and step >= lm_head_untie_step:
            if args.enable_extra_logging:
                print0(f"LM head untied at step {step}", console=True)
            if log_param_counts_fn:
                log_param_counts_fn(model)
            lm_head_untied_logged = True

        if last_step or (step > 0 and args.val_loss_every > 0 and step % args.val_loss_every == 0):
            extra_log = None
            if last_step:
                extra_log = _finalize_logit_stats(logit_stats)
            tokens_target = getattr(args, "val_tokens", None)
            if finalize_now:
                final_tokens = getattr(args, "val_tokens_final", None)
                if final_tokens is not None:
                    tokens_target = final_tokens
            else:
                intermediate_tokens = getattr(args, "val_tokens_intermediate", None)
                if intermediate_tokens is not None:
                    tokens_target = intermediate_tokens
            val_steps_multiplier = float(tokens_target) / float(args.val_tokens)
            run_validation(val_steps_multiplier, log_val_loss=True, extra_log=extra_log)
            if last_step and not finalize_now:
                result = {"val_loss": last_val_loss, "stop_step": step, "aborted": False}
                result.update(_finalize_logit_stats(logit_stats))
                return result

        if last_step and finalize_now:
            should_save = getattr(args, "save_final_checkpoint", getattr(args, "save_checkpoint", False))
            if should_save and getattr(args, "save_final_checkpoint_if_loss_below", False):
                max_loss = float(getattr(args, "save_final_checkpoint_max_loss", float("inf")))
                should_save = last_val_loss is not None and math.isfinite(last_val_loss) and last_val_loss < max_loss
            if master_process and should_save:
                model_to_save = getattr(model, "_orig_mod", model)
                log = dict(step=step, code=code, model=model_to_save.state_dict())
                run_dir = os.path.join(log_dir, run_id_full)
                os.makedirs(run_dir, exist_ok=True)
                torch.save(log, os.path.join(run_dir, f"final_model_step{step:06d}.pt"))
            break

        model.zero_grad(set_to_none=True)
        micro_losses: list[float] = []
        micro_main_losses: list[float] = []
        micro_aux_losses: list[float] = []
        router_metric_accum: list[dict[str, float]] = []
        router_layer_metric_sums = [defaultdict(float) for _ in range(model.num_layers)]
        router_layer_metric_counts = [defaultdict(int) for _ in range(model.num_layers)]
        expert_usage_accum: list[torch.Tensor] = []
        expert_active_accum: list[torch.Tensor] = []
        for micro in range(args.grad_accum_steps):
            inputs, targets = next(train_loader)
            outputs = model(inputs, targets, window_blocks, step, args.num_iterations)
            if isinstance(outputs, tuple):
                loss_main, loss_aux = outputs
                loss_main_v = float(loss_main.detach().item())
                loss_aux_v = float(loss_aux.detach().item())
                loss_val = loss_main_v + loss_aux_v
                micro_losses.append(loss_val)
                micro_main_losses.append(loss_main_v)
                micro_aux_losses.append(loss_aux_v)
                loss_total = (loss_main + loss_aux) / args.grad_accum_steps
                loss_total.backward()
                components = (loss_main.detach(), loss_aux.detach())
                main_loss = loss_main_v
                aux_loss = loss_aux_v
            else:
                loss = outputs
                loss_val = float(loss.detach().item())
                micro_losses.append(loss_val)
                (loss / args.grad_accum_steps).backward()
                components = model.latest_loss_components
                main_loss = float(components[0].item()) if components else float("nan")
                aux_loss = float(components[1].item()) if components else float("nan")
                if not math.isnan(main_loss):
                    micro_main_losses.append(main_loss)
                if not math.isnan(aux_loss):
                    micro_aux_losses.append(aux_loss)
            router_summary = summarize_router_metrics(model.latest_router_metrics or [])
            if router_summary:
                router_metric_accum.append(router_summary)
            layer_metrics = model.latest_router_metrics or []
            for layer_idx, stats in enumerate(layer_metrics):
                if not stats:
                    continue
                layer_sum = router_layer_metric_sums[layer_idx]
                layer_count = router_layer_metric_counts[layer_idx]
                for key, value in stats.items():
                    scalar_val = None
                    if isinstance(value, torch.Tensor):
                        if value.numel() == 1:
                            scalar_val = float(value.item())
                        else:
                            continue
                    elif isinstance(value, (int, float)):
                        scalar_val = float(value)
                    else:
                        continue
                    layer_sum[key] += scalar_val
                    layer_count[key] += 1
            usage = summarize_expert_usage(layer_metrics, args.num_experts)
            if usage is not None:
                expert_usage_accum.append(usage)
            active = summarize_expert_activity(layer_metrics, args.num_experts)
            if active is not None:
                expert_active_accum.append(active)
            if args.enable_extra_logging:
                print0(
                    f"[train step {step} micro {micro + 1}/{args.grad_accum_steps}] "
                    f"loss={loss_val:.6f} main={main_loss:.6f} aux={aux_loss:.6f} "
                    f"{router_summary_str(router_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
                    console=True)

        avg_loss = sum(micro_losses) / max(len(micro_losses), 1)
        avg_main_loss = sum(micro_main_losses) / max(len(micro_main_losses), 1) if micro_main_losses else float("nan")
        avg_aux_loss = sum(micro_aux_losses) / max(len(micro_aux_losses), 1) if micro_aux_losses else float("nan")
        router_step_summary = summarize_router_metrics(router_metric_accum)
        router_layer_avg: dict[int, dict[str, float]] = {}
        for layer_idx in range(model.num_layers):
            sums = router_layer_metric_sums[layer_idx]
            if not sums:
                continue
            counts = router_layer_metric_counts[layer_idx]
            router_layer_avg[layer_idx] = {key: sums[key] / max(counts[key], 1) for key in sums}
        expert_usage = torch.stack(expert_usage_accum).mean(0) if expert_usage_accum else None
        expert_active = torch.stack(expert_active_accum).mean(0) if expert_active_accum else None
        pending_event = getattr(model, "_pending_active_count", None)
        if pending_event is not None:
            event_step, active_count = pending_event
            if wandb_run is not None:
                wandb_run.log({"router/active_experts": active_count}, step=event_step)
                wandb_run.log({"router/active_total_ffn_dim": active_count * args.ffn_hidden}, step=event_step)
            model._pending_active_count = None

        abort_flag = False
        abort_reason = ""
        if math.isnan(avg_loss) or math.isinf(avg_loss):
            abort_flag = True
            abort_reason = "non-finite avg_loss"
        elif not math.isnan(avg_main_loss) and not math.isinf(avg_main_loss) and math.isnan(avg_main_loss):
            abort_flag = True
            abort_reason = "non-finite main loss"
        else:
            max_logit_val = router_step_summary.get("max_logit", float("nan")) if router_step_summary else float("nan")
            if (not math.isnan(max_logit_val)) and (max_logit_val == 0.0 or math.isinf(max_logit_val)):
                abort_flag = True
                abort_reason = f"router max_logit suspicious ({max_logit_val})"

        abort_tensor = torch.tensor(1 if abort_flag else 0, device="cuda", dtype=torch.int32)
        dist.all_reduce(abort_tensor, op=dist.ReduceOp.SUM)
        if abort_tensor.item() > 0:
            if abort_reason and master_process:
                print0(f"Aborting training at step {step} due to: {abort_reason}", console=True)
            result = {"val_loss": last_val_loss, "stop_step": step, "aborted": True, "abort_reason": abort_reason}
            result.update(_finalize_logit_stats(logit_stats))
            return result

        opt2futures = {
            opt: [dist.all_reduce(p.grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
                  for p in params if (p.grad is not None)]
            for opt, params in opt2params.items()
        }

        progress = step / max(args.num_iterations, 1)
        router_lr_mult = rampdown_multiplier(progress, args.router_lr_reduce_start_frac, model.router_freeze_frac)
        adapter_lr_mult = router_lr_mult if args.router_freeze_adapters else 1.0
        ffn_lr_mult = rampdown_multiplier(progress, args.shared_ffn_lr_reduce_start_frac, model.shared_ffn_freeze_frac)
        for opt in optimizers:
            for group in opt.param_groups:
                base_lr = group["initial_lr"] * get_lr(args, step)
                component = group.get("component")
                mult = 1.0
                if component == "router":
                    mult = router_lr_mult
                elif component == "adapter":
                    mult = adapter_lr_mult
                elif component == "shared_ffn":
                    mult = ffn_lr_mult
                group["lr"] = base_lr * mult
        # Muon-style momentum warmup for spectral groups.
        target_muon_momentum = float(getattr(args, "muon_momentum", getattr(args, "neomuon_muon_momentum", 0.95)))
        frac = min(step / 300, 1)
        warm_momentum = (1 - frac) * 0.85 + frac * target_muon_momentum
        for opt in optimizers:
            for group in opt.param_groups:
                if group.get("spectral", True):
                    group["momentum"] = warm_momentum
        for opt in optimizers:
            torch.futures.collect_all(opt2futures[opt]).wait()
            if opt in router_params_by_opt:
                state = router_autoclip_state.get(opt)
                clip_value = router_clip_base
                if state is not None and state.get("clip") is not None:
                    clip_value = float(state["clip"])
                max_norm = clip_value if (clip_value is not None and clip_value > 0) else float("inf")
                total_norm = float(torch.nn.utils.clip_grad_norm_(router_params_by_opt[opt], max_norm))
                if state is not None:
                    history: deque = state["history"]  # type: ignore[assignment]
                    history.append(total_norm)
                    if len(history) >= autoclip_window:
                        hist_tensor = torch.tensor(list(history), device="cpu")
                        new_clip = float(torch.quantile(hist_tensor, 0.10).item())
                        new_clip = max(new_clip, 1e-6)
                        if state.get("clip") is None or not math.isclose(state["clip"], new_clip):
                            state["clip"] = new_clip
                            if args.enable_extra_logging:
                                print0(
                                    f"[router grad clip auto] norm={total_norm:.4f} clip-> {new_clip:.4f}",
                                    console=True,
                                )
                elif clip_value is not None and clip_value > 0 and args.enable_extra_logging and total_norm > clip_value:
                    print0(
                        f"[router grad clip] norm={total_norm:.4f} clip={clip_value:.4f}",
                        console=True,
                    )
            # Feed last activations to Muon for spectral gating.
            if hasattr(opt, "set_last_activation") and bool(getattr(opt, "enable_spectral_gating", False)):
                for group in opt.param_groups:
                    if not group.get("spectral", True):
                        continue
                    for p in group.get("params", []):
                        act = getattr(p, "_neomuon_last_activation", None)
                        if act is not None:
                            opt.set_last_activation(p, act)
            opt.step()
        model.zero_grad(set_to_none=True)
        if args.enable_extra_logging and router_layer_avg:
            metric_keys = ["imp_cv2", "load_cv2", "usage_frac", "topk_prob_mean"]
            if args.router_enable_forward_ema:
                metric_keys.append("ema_alpha_forward")
            if args.router_enable_reverse_ema:
                metric_keys.append("ema_alpha_reverse")
            layer_fragments = []
            for layer_idx in sorted(router_layer_avg):
                stats = router_layer_avg[layer_idx]
                metrics = ", ".join(f"{key}={stats.get(key, float('nan')):.4f}" for key in metric_keys if key in stats)
                layer_fragments.append(f"L{layer_idx}: {metrics}")
            print0("[router layers] " + " | ".join(layer_fragments), console=True)
        print0(
            f"[train step {step}] avg_loss={avg_loss:.6f} main={avg_main_loss:.6f} aux={avg_aux_loss:.6f} "
            f"{router_summary_str(router_step_summary, args.router_enable_forward_ema, args.router_enable_reverse_ema)}",
            console=True)
        approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
        if approx_step_time_ms_resume is not None:
            approx_training_time_ms = approx_step_time_ms_resume
            # reset base timer so subsequent steps are correct
            training_time_ms = approx_step_time_ms_resume
            t0 = time.perf_counter()
            approx_step_time_ms_resume = None
        print0(
            f"step:{step + 1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms / (step + 1):.2f}ms",
            console=True)
        current_logit_cap = get_logit_cap(args, step)
        current_router_temp = get_router_temp(args, step)
        max_logit_val = router_step_summary.get("max_logit", float("nan")) if router_step_summary else float("nan")
        _update_logit_stats(logit_stats, max_logit_val, current_logit_cap)
        active_count_val = None
        if expert_active is not None:
            active_count_val = float(expert_active.mean().item() * args.num_experts)
        if active_count_val is None or active_count_val <= 0:
            active_count_val = float(args.num_experts)
        active_count_val = max(active_count_val, 1.0)
        if wandb_run is not None and (step % max(args.wandb_log_every, 1) == 0):
            if args.enable_extra_wandb_logging:
                # Preserve historical lr keys by mapping to first non-spectral/spectral groups.
                adamw_lr = next(
                    (g["lr"] for g in optimizers[0].param_groups if not g.get("spectral", True)),
                    float("nan"),
                )
                muon_lr = next(
                    (g["lr"] for g in optimizers[0].param_groups if g.get("spectral", True)),
                    float("nan"),
                )
                log_data = {
                    "train/loss": avg_loss,
                    "train/loss_main": avg_main_loss,
                    "train/loss_aux": avg_aux_loss,
                    "perf/approx_step_time_ms": approx_training_time_ms,
                    "train/tokens_seen": float((step + 1) * args.train_seq_len * world_size),
                    "lr/adamw": adamw_lr,
                    "lr/muon": muon_lr,
                    "train/step": step,
                    "router/logit_cap": (current_logit_cap if current_logit_cap is not None else float("nan")),
                    "router/logit_cap_enabled": float(current_logit_cap is not None),
                    "router/temperature": current_router_temp,
                    "router/max_logit": router_step_summary.get("max_logit", float("nan")),
                }
                # feature weight percentages
                feat_keys_all = [k for k in router_step_summary.keys() if k.startswith("feat_w_")]
                feat_keys = [k for k in feat_keys_all if k in ("feat_w_tok", "feat_w_ema_fwd", "feat_w_ema_rev", "feat_w_flags")]
                if not feat_keys:
                    feat_keys = feat_keys_all
                feat_total = sum(router_step_summary[k] for k in feat_keys) if feat_keys else 0.0
                if feat_total and feat_total != 0:
                    for k in feat_keys:
                        pct = 100.0 * router_step_summary[k] / feat_total
                        log_data[f"router/feat_pct/{k.replace('feat_w_', '')}"] = pct
                # normalized CV metrics
                imp_cv2 = router_step_summary.get("imp_cv2", float("nan"))
                load_cv2 = router_step_summary.get("load_cv2", float("nan"))
                log_data["router/imp_cv2_norm"] = imp_cv2 / active_count_val if not math.isnan(imp_cv2) else float("nan")
                log_data["router/load_cv2_norm"] = load_cv2 / active_count_val if not math.isnan(load_cv2) else float("nan")
                # entropy gaps
                expected_entropy = math.log(active_count_val) if active_count_val > 0 else float("nan")
                load_entropy = router_step_summary.get("load_entropy", float("nan"))
                imp_entropy = router_step_summary.get("imp_entropy", float("nan"))
                def _entropy_gap(val):
                    if math.isnan(val) or math.isnan(expected_entropy) or expected_entropy <= 0:
                        return float("nan")
                    return max(0.0, abs(expected_entropy - val) / expected_entropy)
                load_entropy_gap = _entropy_gap(load_entropy)
                imp_entropy_gap = _entropy_gap(imp_entropy)
                log_data["router/load_entropy_gap"] = load_entropy_gap
                log_data["router/imp_entropy_gap"] = imp_entropy_gap
                # usage gap and health score
                usage_frac = router_step_summary.get("usage_frac", float("nan"))
                target_usage = min(1.0, active_count_val / max(args.num_experts, 1))
                usage_gap = abs(usage_frac - target_usage) if not math.isnan(usage_frac) else float("nan")
                weights = {
                    "imp_cv2_norm": 0.8,
                    "load_cv2_norm": 0.9,
                    "load_entropy_gap": 0.5,
                    "imp_entropy_gap": 0.2,
                    "usage_gap": 1.25,
                }
                components_weighted = []
                components_weighted.append(weights["imp_cv2_norm"] * log_data["router/imp_cv2_norm"] if not math.isnan(log_data["router/imp_cv2_norm"]) else float("nan"))
                components_weighted.append(weights["load_cv2_norm"] * log_data["router/load_cv2_norm"] if not math.isnan(log_data["router/load_cv2_norm"]) else float("nan"))
                components_weighted.append(weights["load_entropy_gap"] * load_entropy_gap if not math.isnan(load_entropy_gap) else float("nan"))
                components_weighted.append(weights["imp_entropy_gap"] * imp_entropy_gap if not math.isnan(imp_entropy_gap) else float("nan"))
                components_weighted.append(weights["usage_gap"] * usage_gap if not math.isnan(usage_gap) else float("nan"))
                health_terms = [v for v in components_weighted if not math.isnan(v)]
                if health_terms:
                    health_penalty = sum(health_terms)
                    log_data["router/health_score"] = 1.0 / (1.0 + health_penalty)
                    health_penalty = health_penalty
                    log_data["router/health_penalty"] = health_penalty
                # raw router stats (skip feat_w_*; percents already logged)
                for key, value in router_step_summary.items():
                    if key.startswith("feat_w_"):
                        continue
                    log_data[f"router/{key}"] = value
                for layer_idx, stats in router_layer_avg.items():
                    for key, value in stats.items():
                        log_data[f"router_layer/{layer_idx}/{key}"] = value
                if expert_usage is not None:
                    expert_list = expert_usage.tolist()
                    log_data["router_expert/min_usage"] = float(min(expert_list))
                    log_data["router_expert/max_usage"] = float(max(expert_list))
                    log_data["router_expert/mean_usage"] = float(sum(expert_list) / len(expert_list))
                    for idx, value in enumerate(expert_list):
                        log_data[f"router_expert/e{idx}"] = float(value)
                if expert_active is not None:
                    base_model = getattr(model, "_orig_mod", model)
                    scheduled_active = getattr(base_model, "_current_base_active", None)
                    active_count = args.num_experts
                    if isinstance(scheduled_active, int):
                        active_count = max(1, min(args.num_experts, scheduled_active))
                    inferred_active = expert_active.sum().item()
                    if inferred_active > 0:
                        active_count = max(1, min(active_count, int(round(inferred_active))))
                    source = expert_usage if expert_usage is not None else expert_active
                    active_list = source.tolist()
                    active_slice = active_list[:active_count] if active_list else []
                    if not active_slice:
                        active_slice = [0.0]
                    denom = sum(active_slice)
                    if denom > 0:
                        active_slice = [v / denom for v in active_slice]
                    log_data["router_expert_active/min"] = float(min(active_slice))
                    log_data["router_expert_active/max"] = float(max(active_slice))
                    log_data["router_expert_active/mean"] = float(sum(active_slice) / len(active_slice))
                    per_expert = []
                    for idx in range(args.num_experts):
                        if idx < active_count and idx < len(active_slice):
                            per_expert.append(float(active_slice[idx]))
                        else:
                            per_expert.append(0.0)
                    for idx, value in enumerate(per_expert):
                        log_data[f"router_expert_active/e{idx}"] = value
                wandb_run.log(log_data, step=step)
            else:
                wandb_run.log(
                    {
                        "train/loss": avg_loss,
                        "train/loss_main": avg_main_loss,
                        "train/loss_aux": avg_aux_loss,
                        "perf/approx_step_time_ms": approx_training_time_ms,
                        "train/tokens_seen": float((step + 1) * args.train_seq_len * world_size),
                        "train/step": step,
                        "router/logit_cap": (current_logit_cap if current_logit_cap is not None else float("nan")),
                        "router/temperature": current_router_temp,
                    },
                    step=step,
                )
        if master_process and metrics_csv_writer and (step % max(args.metrics_log_every, 1) == 0):
            expert_usage_list = []
            if expert_usage is not None:
                expert_usage_list = [float(x) for x in expert_usage.tolist()]
            else:
                expert_usage_list = [float("nan")] * len(expert_usage_headers)
            expert_active_list = []
            if expert_active is not None:
                expert_active_list = [float(x) for x in expert_active.tolist()]
            else:
                expert_active_list = [float("nan")] * len(expert_active_headers)
            router_ema_vals: list[float] = []
            if args.router_enable_forward_ema:
                router_ema_vals.append(router_step_summary.get("ema_alpha_forward", float("nan")))
            if args.router_enable_reverse_ema:
                router_ema_vals.append(router_step_summary.get("ema_alpha_reverse", float("nan")))
            row = [
                step,
                avg_loss,
                avg_main_loss,
                avg_aux_loss,
                router_step_summary.get("imp_cv2", float("nan")),
                router_step_summary.get("load_cv2", float("nan")),
                router_step_summary.get("usage_frac", float("nan")),
                router_step_summary.get("topk_prob_mean", float("nan")),
                *router_ema_vals,
                router_step_summary.get("max_logit", float("nan")),
                (current_logit_cap if current_logit_cap is not None else float("nan")),
                current_router_temp,
                int(window_blocks.item()),
                *expert_usage_list,
                *expert_active_list,
            ]
            metrics_csv_writer.writerow(row)
        if master_process and checkpoint_save_step >= 0 and step == checkpoint_save_step:
            run_dir = os.path.join(log_dir, run_id_full)
            os.makedirs(run_dir, exist_ok=True)
            model_to_save = getattr(model, "_orig_mod", model)
            checkpoint_payload = dict(
                step=step,
                code=code,
                model=model_to_save.state_dict(),
                optimizers=[opt.state_dict() for opt in optimizers],
                approx_step_time_ms=approx_training_time_ms,
                meta=dict(
                    model_dim=getattr(args, "model_dim", None),
                    num_layers=getattr(args, "num_layers", None),
                    num_heads=getattr(args, "num_heads", None),
                    num_experts=getattr(args, "num_experts", None),
                    ffn_hidden=getattr(args, "ffn_hidden", None),
                    vocab_size=getattr(args, "vocab_size", None),
                ),
            )
            torch.save(checkpoint_payload, os.path.join(run_dir, f"state_step{step:06d}.pt"))

    result = {"val_loss": last_val_loss, "stop_step": stop_step, "aborted": False}
    result.update(_finalize_logit_stats(logit_stats))
    return result

====================================================================================================
Running Python 3.10.12 (main, Nov  4 2025, 08:48:33) [GCC 11.4.0]
Running PyTorch 2.10.0.dev20251210+cu126 compiled for CUDA 12.6
Sat Dec 27 21:12:06 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          Off |   00000000:19:00.0 Off |                    0 |
| N/A   29C    P0            117W /  700W |    5858MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          Off |   00000000:3B:00.0 Off |                    0 |
| N/A   26C    P0            117W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          Off |   00000000:4C:00.0 Off |                    0 |
| N/A   23C    P0            115W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          Off |   00000000:5D:00.0 Off |                    0 |
| N/A   27C    P0            115W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          Off |   00000000:9B:00.0 Off |                    0 |
| N/A   26C    P0            116W /  700W |    1700MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          Off |   00000000:BB:00.0 Off |                    0 |
| N/A   25C    P0            118W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          Off |   00000000:CB:00.0 Off |                    0 |
| N/A   54C    P0            139W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          Off |   00000000:DB:00.0 Off |                    0 |
| N/A   23C    P0            116W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    148111      C   /usr/bin/python3                             1510MiB |
|    0   N/A  N/A    148112      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    148113      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    148114      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    148115      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    148116      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    148117      C   /usr/bin/python3                              614MiB |
|    0   N/A  N/A    148118      C   /usr/bin/python3                              614MiB |
|    1   N/A  N/A    148112      C   /usr/bin/python3                             1510MiB |
|    2   N/A  N/A    148113      C   /usr/bin/python3                             1510MiB |
|    3   N/A  N/A    148114      C   /usr/bin/python3                             1510MiB |
|    4   N/A  N/A    148115      C   /usr/bin/python3                             1870MiB |
|    5   N/A  N/A    148116      C   /usr/bin/python3                             1510MiB |
|    6   N/A  N/A    148117      C   /usr/bin/python3                             1510MiB |
|    7   N/A  N/A    148118      C   /usr/bin/python3                             1510MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
=== Parameter counts ===
model total:           282,395,148 (282.395M)
  attention stack (27 of 28 layers run attention): 86,704,128 (86.704M)
  FFN bank total:      15,084,160 (15.084M)
    ├─ experts W1/W2:  14,680,064 (14.680M)
    └─ routers:        404,096 (0.404M)
  embeddings (tok + 2× value): 135,132,928 (135.133M)
    └─ token embed:    45,072,384 (45.072M)
    └─ value embeds:   90,060,544 (90.061M)
  lm head (untied):   45,072,384 (45.072M)
  adapters:            401,408 (0.401M)
  scalars:             140 (0.000M)
====================================================================================================
Compiling model...
Compile complete.
Warming up kernels...
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/fq/cfqixvmxmiuyvximhm5cxovwynazccyxrjgpoqksbci2miqaptdo.py
inductor_output_code: /tmp/torchinductor_ubuntu/4l/c4ljprwocn4kfjpeoxx76qdg4kx3ryurg2ybcvofnmnpknnprl3n.py
inductor_output_code: /tmp/torchinductor_ubuntu/hb/chb2bnc3t74wttigx46vmvyli2swsbmgb3swroqvtdxwqgno3gef.py
inductor_output_code: /tmp/torchinductor_ubuntu/7m/c7mcceaqwhkxfo25gtt6z6deh5kc24e5larml3tir64zzlg7u2ls.py
inductor_output_code: /tmp/torchinductor_ubuntu/mr/cmrf5iwusj7ppaxt65o3cka54gvs3nskkxbibvcq2ec3flayler5.py
inductor_output_code: /tmp/torchinductor_ubuntu/y2/cy27xexdq3uy24qdnom66lejnydlviosxblbrahtgxlcjsn2nfcu.py
inductor_output_code: /tmp/torchinductor_ubuntu/kj/ckjscjlqwgbvzl5chr4w7asosnyptemylrorotmc5dafgo6mgdyg.py
inductor_output_code: /tmp/torchinductor_ubuntu/om/comnhqjt5ejns5cvw3lsgn6oofsjpbn2mc65likenpblbjttjr4k.py
inductor_output_code: /tmp/torchinductor_ubuntu/ic/cicajx3cn44vgfp2hj4yrxsu4zg55ao6s5tuuzf3gqynb4n5aei3.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/4g/c4g7sx7n5znkhhbc54uqvdxktlpbohoatd22todbxakltfuyq7xj.py
inductor_output_code: /tmp/torchinductor_ubuntu/vz/cvzmihtwtvc4z436rlwnps5vjvj3khdnsbx4fhlpaaoxcuxtxjjr.py
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/ei/ceihzmsbtrr2gp4tg4iqjfqdox5czomhvweztpj5b3c5y3wuf473.py
inductor_output_code: /tmp/torchinductor_ubuntu/27/c27xigeeuwotem6hlshv23nb7xvsj3zjrwayehurvqr4pri2hats.py
inductor_output_code: /tmp/torchinductor_ubuntu/44/c44gfjrynanau4olb5cxz6mvnnwlbo26bo4dvres3z3cq42scgkh.py
inductor_output_code: /tmp/torchinductor_ubuntu/ql/cqlbbiv4tnpmphfpqbquz37q4qqn767c5yjmdchujey6omwmvqqy.py
inductor_output_code: /tmp/torchinductor_ubuntu/xs/cxsnpngitcah7e2kduknn7ceti7je4v2j3yumztw47bcu6za6mcu.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vo/cvokruoazaxmhkd6d2kuiaagltu6u3rpovkqcrbndwwz3ltbk75q.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/nw/cnwmvztqrbjwoi473u5qitnxkngbgcuw5kcyf7re5yovaflz7lu2.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ea/ceaq2lx6uciw27w63cxgcnqqm5xteez6dezf5mx5sqok2gv4cg6l.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ps/cpsliltnujy72slrbeq44fp3oye3ldviqbljjv3inoa66dlmk5lg.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/7z/c7zihhtgrytywzcdhlvc2uyabsvsfqf3mzdih3d64vy3fjr2auvg.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vf/cvfa6qtw4adef6nklcpbiwjwtshopzljqwyglpakkzkfskqglq26.py
inductor_output_code: /tmp/torchinductor_ubuntu/kd/ckdvnjmrawk6dn2qlqohaax5dasvuaaj5ke3ci3wzktgwbgakk4n.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/yy/cyyy3jozpp7o3m6jxcbmv5ytzhs2p2pszf4ryo5wjrtjur5wzwrn.py
inductor_output_code: /tmp/torchinductor_ubuntu/ij/cijpas2axgjszrfuockfnu2iaemjdaa5pdtq6beq5k543smjdy4p.py
inductor_output_code: /tmp/torchinductor_ubuntu/7e/c7e55w6vtzg4cwoy4kftrt32fitoy6xc2u3z2e5bm3gmf4hv3wjz.py
inductor_output_code: /tmp/torchinductor_ubuntu/vn/cvnp3hye32d6gtum6ssg53ko23znadoaop747hdwkw7tlcar4dik.py
inductor_output_code: /tmp/torchinductor_ubuntu/qi/cqijmax67f7bnmnslxmq64yo422uqudtakvm7wifucvc4zt32h57.py
inductor_output_code: /tmp/torchinductor_ubuntu/rk/crk7su4b7xpejvheo5gz6rpdorzzgpth65exdwfvo7ezfgyzgqfh.py
inductor_output_code: /tmp/torchinductor_ubuntu/ha/chaulm7ltsokkarrumul5qjrnx4ahkimqhauxh26exd2hcuk3l7x.py
inductor_output_code: /tmp/torchinductor_ubuntu/xp/cxpgiz2wiajvso43kie77hcmxvtsiaqz2te7otoesquvdyoapxm6.py
inductor_output_code: /tmp/torchinductor_ubuntu/ry/crykauzc3oifekn667dgcyrf5bibnkbghoch5mqvljqasw2k7aqg.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/kl/ckllj5sjejqdb6ipkfp4m745swsno7n6gygf22clrcp74t3u3wti.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/z5/cz5f7iwr6al2eokhvc2i57wbq3sgdcans5vfvv6wx3fp5ammhigu.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/n4/cn4fwpvyaac5phl4qcqmrfwwi646mxowmyuqb57mj5mnnzskkapw.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/zd/czdr7mghhrcxjpxd4e7awowuyl4xv64mqklrxdzlbgmtg2ikmnlo.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/ml/cml5y4cguscckibnxjkdkym25pt2fgjmvitan7zr4ybgrlraqps6.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/pe/cpeghbtcj37h3j2ztaq7llhet653sbihhvmnsvv7eqh6vopspdii.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/qg/cqgedru6kihsfgglrxbjmedufnrcaydomq3kwszain4vavckrgxu.py
inductor_output_code: /tmp/torchinductor_ubuntu/7w/c7whqyvq3cp5l2a5sluqd6lpgl7k3pdvxchu2m2llth2cjhi3pmz.py
inductor_output_code: /tmp/torchinductor_ubuntu/r5/cr5klalefi6b6skemtsuq7frgj2ouai7ilonjkvwg5o574xtchjg.py
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
inductor_output_code: /tmp/torchinductor_ubuntu/mc/cmcm6fww7tjiwmcvahcg4lzc7lyqpox2n56ccnewo33dhcin2knk.py
inductor_output_code: /tmp/torchinductor_ubuntu/p4/cp4fa4yeij2caf5yvvh2et4fngrovgk5x7w6srdh2i2o2bjjz6cb.py
inductor_output_code: /tmp/torchinductor_ubuntu/7c/c7ckg2hjgek3w2j6waxt5d5ffzdyeznjkhbqtrcmn42no6x5td3d.py
Kernel warmup complete.
Starting training.
Running validation...
step:0/1750 val_loss:10.944356 train_time:2ms step_avg:2.16ms
[train step 0] avg_loss=10.942436 main=10.942436 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:1/1750 train_time:284ms step_avg:283.62ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 1] avg_loss=10.028184 main=10.028184 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:2/1750 train_time:905ms step_avg:452.27ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 2] avg_loss=7.884569 main=7.884569 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:3/1750 train_time:1514ms step_avg:504.75ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 3] avg_loss=7.498556 main=7.498556 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:4/1750 train_time:1943ms step_avg:485.76ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 4] avg_loss=7.541026 main=7.541026 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:5/1750 train_time:2322ms step_avg:464.38ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 5] avg_loss=7.655585 main=7.655585 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:6/1750 train_time:2717ms step_avg:452.80ms
inductor_output_code: /tmp/torchinductor_ubuntu/2n/c2n2w6qzsfdnctazt2c5de2phzr3e337vaij5kvunku4qdnmahby.py
[train step 6] avg_loss=7.257362 main=7.257362 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:7/1750 train_time:3099ms step_avg:442.67ms
[train step 7] avg_loss=6.893272 main=6.893272 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:8/1750 train_time:3325ms step_avg:415.65ms
[train step 8] avg_loss=6.786455 main=6.786455 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:9/1750 train_time:3551ms step_avg:394.54ms
[train step 9] avg_loss=7.174589 main=7.174589 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:10/1750 train_time:3778ms step_avg:377.85ms
[train step 10] avg_loss=7.050612 main=7.050612 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:11/1750 train_time:4005ms step_avg:364.08ms
[train step 11] avg_loss=6.826104 main=6.826104 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:12/1750 train_time:4231ms step_avg:352.58ms
[train step 12] avg_loss=6.570293 main=6.570293 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:13/1750 train_time:4463ms step_avg:343.33ms
[train step 13] avg_loss=6.614467 main=6.614467 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:14/1750 train_time:4691ms step_avg:335.10ms
[train step 14] avg_loss=6.348972 main=6.348972 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:15/1750 train_time:4919ms step_avg:327.91ms
[train step 15] avg_loss=6.506894 main=6.506894 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:16/1750 train_time:5147ms step_avg:321.68ms
[train step 16] avg_loss=6.184193 main=6.184193 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:17/1750 train_time:5372ms step_avg:316.02ms
[train step 17] avg_loss=6.239785 main=6.239785 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:18/1750 train_time:5599ms step_avg:311.04ms
[train step 18] avg_loss=6.387607 main=6.387607 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:19/1750 train_time:5827ms step_avg:306.66ms
[train step 19] avg_loss=6.045852 main=6.045852 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:20/1750 train_time:6055ms step_avg:302.73ms
[train step 20] avg_loss=6.557127 main=6.557127 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:21/1750 train_time:6281ms step_avg:299.10ms
[train step 21] avg_loss=6.449406 main=6.449406 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:22/1750 train_time:6509ms step_avg:295.86ms
[train step 22] avg_loss=6.285048 main=6.285048 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:23/1750 train_time:6737ms step_avg:292.92ms
[train step 23] avg_loss=6.401842 main=6.401842 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:24/1750 train_time:6965ms step_avg:290.19ms
[train step 24] avg_loss=6.128367 main=6.128367 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:25/1750 train_time:7196ms step_avg:287.82ms
[train step 25] avg_loss=6.014063 main=6.014063 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:26/1750 train_time:7423ms step_avg:285.48ms
[train step 26] avg_loss=6.113800 main=6.113800 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:27/1750 train_time:7648ms step_avg:283.27ms
[train step 27] avg_loss=5.984983 main=5.984983 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:28/1750 train_time:7876ms step_avg:281.29ms
[train step 28] avg_loss=5.648431 main=5.648431 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:29/1750 train_time:8102ms step_avg:279.39ms
[train step 29] avg_loss=6.104687 main=6.104687 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:30/1750 train_time:8329ms step_avg:277.64ms
[train step 30] avg_loss=5.927853 main=5.927853 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:31/1750 train_time:8554ms step_avg:275.95ms
[train step 31] avg_loss=6.045195 main=6.045195 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:32/1750 train_time:8781ms step_avg:274.40ms
[train step 32] avg_loss=6.193586 main=6.193586 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:33/1750 train_time:9008ms step_avg:272.98ms
[train step 33] avg_loss=5.958174 main=5.958174 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:34/1750 train_time:9235ms step_avg:271.61ms
[train step 34] avg_loss=6.293718 main=6.293718 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:35/1750 train_time:9460ms step_avg:270.28ms
[train step 35] avg_loss=6.171681 main=6.171681 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:36/1750 train_time:9688ms step_avg:269.11ms
[train step 36] avg_loss=5.640942 main=5.640942 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:37/1750 train_time:9914ms step_avg:267.94ms
[train step 37] avg_loss=5.894998 main=5.894998 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:38/1750 train_time:10140ms step_avg:266.86ms
[train step 38] avg_loss=5.673847 main=5.673847 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:39/1750 train_time:10366ms step_avg:265.79ms
[train step 39] avg_loss=5.942368 main=5.942368 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:40/1750 train_time:10591ms step_avg:264.77ms
[train step 40] avg_loss=4.541364 main=4.541364 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:41/1750 train_time:10827ms step_avg:264.07ms
[train step 41] avg_loss=5.926638 main=5.926638 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:42/1750 train_time:11053ms step_avg:263.16ms
[train step 42] avg_loss=5.491987 main=5.491987 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:43/1750 train_time:11280ms step_avg:262.32ms
[train step 43] avg_loss=5.711826 main=5.711826 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:44/1750 train_time:11508ms step_avg:261.55ms
[train step 44] avg_loss=5.805898 main=5.805898 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:45/1750 train_time:11734ms step_avg:260.76ms
[train step 45] avg_loss=5.881853 main=5.881853 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:46/1750 train_time:11961ms step_avg:260.02ms
[train step 46] avg_loss=5.477530 main=5.477530 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:47/1750 train_time:12186ms step_avg:259.28ms
[train step 47] avg_loss=5.508508 main=5.508508 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:48/1750 train_time:12412ms step_avg:258.58ms
[train step 48] avg_loss=5.896517 main=5.896517 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:49/1750 train_time:12640ms step_avg:257.95ms
[train step 49] avg_loss=5.624502 main=5.624502 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:50/1750 train_time:12865ms step_avg:257.30ms
Running validation...
step:50/1750 val_loss:5.816355 train_time:12882ms step_avg:257.64ms
[train step 50] avg_loss=5.461800 main=5.461800 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:51/1750 train_time:13102ms step_avg:256.90ms
[train step 51] avg_loss=5.561147 main=5.561147 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:52/1750 train_time:13332ms step_avg:256.39ms
[train step 52] avg_loss=5.355340 main=5.355340 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:53/1750 train_time:13562ms step_avg:255.89ms
[train step 53] avg_loss=5.628811 main=5.628811 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:54/1750 train_time:13789ms step_avg:255.35ms
[train step 54] avg_loss=5.503297 main=5.503297 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:55/1750 train_time:14016ms step_avg:254.83ms
[train step 55] avg_loss=5.504312 main=5.504312 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:56/1750 train_time:14242ms step_avg:254.32ms
[train step 56] avg_loss=5.628599 main=5.628599 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:57/1750 train_time:14469ms step_avg:253.84ms
[train step 57] avg_loss=5.503693 main=5.503693 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:58/1750 train_time:14697ms step_avg:253.40ms
[train step 58] avg_loss=6.493532 main=6.493532 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:59/1750 train_time:14928ms step_avg:253.01ms
[train step 59] avg_loss=5.489983 main=5.489983 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:60/1750 train_time:15156ms step_avg:252.61ms
[train step 60] avg_loss=5.655205 main=5.655205 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:61/1750 train_time:15382ms step_avg:252.16ms
[train step 61] avg_loss=5.260143 main=5.260143 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:62/1750 train_time:15608ms step_avg:251.75ms
[train step 62] avg_loss=5.553867 main=5.553867 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:63/1750 train_time:15834ms step_avg:251.34ms
[train step 63] avg_loss=5.651846 main=5.651846 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:64/1750 train_time:16061ms step_avg:250.95ms
[train step 64] avg_loss=5.340246 main=5.340246 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:65/1750 train_time:16288ms step_avg:250.59ms
[train step 65] avg_loss=5.463250 main=5.463250 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:66/1750 train_time:16518ms step_avg:250.27ms
[train step 66] avg_loss=5.753294 main=5.753294 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:67/1750 train_time:16745ms step_avg:249.93ms
[train step 67] avg_loss=5.530449 main=5.530449 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:68/1750 train_time:16972ms step_avg:249.58ms
[train step 68] avg_loss=5.527917 main=5.527917 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:69/1750 train_time:17197ms step_avg:249.23ms
[train step 69] avg_loss=5.670498 main=5.670498 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:70/1750 train_time:17423ms step_avg:248.90ms
[train step 70] avg_loss=5.566574 main=5.566574 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:71/1750 train_time:17649ms step_avg:248.57ms
[train step 71] avg_loss=5.310161 main=5.310161 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:72/1750 train_time:17877ms step_avg:248.29ms
[train step 72] avg_loss=5.384438 main=5.384438 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:73/1750 train_time:18104ms step_avg:248.00ms
[train step 73] avg_loss=5.003659 main=5.003659 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:74/1750 train_time:18334ms step_avg:247.76ms
[train step 74] avg_loss=5.356695 main=5.356695 aux=0.000000 imp_cv2=6.9996 load_cv2=6.9996 usage_frac=0.1250 topk_prob_mean=1.0000 ema_alpha_reverse=nan max_logit=nan
step:75/1750 train_time:18562ms step_avg:247.50ms
[train step 75] avg_loss=5.810136 main=5.358946 aux=0.451190 imp_cv2=3.0068 load_cv2=3.0262 usage_frac=0.2500 topk_prob_mean=0.6627 ema_alpha_reverse=nan max_logit=1.1660
step:76/1750 train_time:19430ms step_avg:255.65ms
[train step 76] avg_loss=6.543746 main=5.499350 aux=1.044396 imp_cv2=5.6101 load_cv2=6.9591 usage_frac=0.2232 topk_prob_mean=0.9000 ema_alpha_reverse=nan max_logit=1.1660
step:77/1750 train_time:19921ms step_avg:258.72ms
[train step 77] avg_loss=6.627856 main=5.590929 aux=1.036927 imp_cv2=5.6039 load_cv2=6.8947 usage_frac=0.2500 topk_prob_mean=0.8993 ema_alpha_reverse=nan max_logit=1.1660
step:78/1750 train_time:20392ms step_avg:261.44ms
[train step 78] avg_loss=6.626961 main=5.587190 aux=1.039770 imp_cv2=5.6029 load_cv2=6.9232 usage_frac=0.2321 topk_prob_mean=0.8984 ema_alpha_reverse=nan max_logit=1.1660
step:79/1750 train_time:20865ms step_avg:264.12ms
[train step 79] avg_loss=6.602329 main=5.559918 aux=1.042411 imp_cv2=5.6014 load_cv2=6.9499 usage_frac=0.2411 topk_prob_mean=0.8976 ema_alpha_reverse=nan max_logit=1.1660
step:80/1750 train_time:21322ms step_avg:266.53ms
[train step 80] avg_loss=6.731399 main=5.689810 aux=1.041589 imp_cv2=5.5911 load_cv2=6.9516 usage_frac=0.2500 topk_prob_mean=0.8971 ema_alpha_reverse=nan max_logit=1.1660
step:81/1750 train_time:21766ms step_avg:268.72ms
[train step 81] avg_loss=6.340866 main=5.298966 aux=1.041900 imp_cv2=5.5912 load_cv2=6.9530 usage_frac=0.2455 topk_prob_mean=0.8970 ema_alpha_reverse=nan max_logit=1.1660
step:82/1750 train_time:22254ms step_avg:271.39ms
[train step 82] avg_loss=6.218900 main=5.183652 aux=1.035248 imp_cv2=5.5610 load_cv2=6.9147 usage_frac=0.2411 topk_prob_mean=0.8965 ema_alpha_reverse=nan max_logit=1.1660
step:83/1750 train_time:22803ms step_avg:274.74ms
[train step 83] avg_loss=6.356452 main=5.342531 aux=1.013921 imp_cv2=5.4758 load_cv2=6.7837 usage_frac=0.2411 topk_prob_mean=0.8964 ema_alpha_reverse=nan max_logit=1.1660
step:84/1750 train_time:23401ms step_avg:278.58ms
[train step 84] avg_loss=6.589796 main=5.575948 aux=1.013848 imp_cv2=5.4721 load_cv2=6.7892 usage_frac=0.2455 topk_prob_mean=0.8960 ema_alpha_reverse=nan max_logit=1.1660
step:85/1750 train_time:24044ms step_avg:282.87ms
[train step 85] avg_loss=6.695727 main=5.714807 aux=0.980920 imp_cv2=5.3360 load_cv2=6.5859 usage_frac=0.2500 topk_prob_mean=0.8956 ema_alpha_reverse=nan max_logit=1.1660
step:86/1750 train_time:24727ms step_avg:287.53ms
[train step 86] avg_loss=6.159520 main=5.194476 aux=0.965045 imp_cv2=5.2687 load_cv2=6.4968 usage_frac=0.2500 topk_prob_mean=0.8955 ema_alpha_reverse=nan max_logit=1.1660
step:87/1750 train_time:25459ms step_avg:292.63ms
[train step 87] avg_loss=6.218208 main=5.300213 aux=0.917995 imp_cv2=5.0717 load_cv2=6.1991 usage_frac=0.2500 topk_prob_mean=0.8953 ema_alpha_reverse=nan max_logit=1.1660
step:88/1750 train_time:26176ms step_avg:297.46ms
[train step 88] avg_loss=5.862358 main=4.928843 aux=0.933515 imp_cv2=5.1300 load_cv2=6.3008 usage_frac=0.2500 topk_prob_mean=0.8938 ema_alpha_reverse=nan max_logit=1.1660
step:89/1750 train_time:26917ms step_avg:302.44ms
[train step 89] avg_loss=6.287546 main=5.497867 aux=0.789679 imp_cv2=4.5059 load_cv2=5.3495 usage_frac=0.2500 topk_prob_mean=0.8913 ema_alpha_reverse=nan max_logit=1.1660
step:90/1750 train_time:27673ms step_avg:307.48ms
[train step 90] avg_loss=5.990851 main=5.319590 aux=0.671261 imp_cv2=3.9836 load_cv2=4.5759 usage_frac=0.2500 topk_prob_mean=0.8889 ema_alpha_reverse=nan max_logit=1.1660
step:91/1750 train_time:28419ms step_avg:312.30ms
[train step 91] avg_loss=5.971701 main=5.385845 aux=0.585856 imp_cv2=3.6151 load_cv2=3.9950 usage_frac=0.2500 topk_prob_mean=0.8892 ema_alpha_reverse=nan max_logit=1.1661
step:92/1750 train_time:29122ms step_avg:316.54ms
[train step 92] avg_loss=6.126678 main=5.576803 aux=0.549875 imp_cv2=3.4655 load_cv2=3.7534 usage_frac=0.2500 topk_prob_mean=0.8891 ema_alpha_reverse=nan max_logit=1.1661
step:93/1750 train_time:29800ms step_avg:320.43ms
[train step 93] avg_loss=6.614007 main=6.037848 aux=0.576160 imp_cv2=3.5898 load_cv2=3.9049 usage_frac=0.2500 topk_prob_mean=0.8903 ema_alpha_reverse=nan max_logit=1.1661
step:94/1750 train_time:30694ms step_avg:326.53ms
[train step 94] avg_loss=5.771669 main=5.243606 aux=0.528063 imp_cv2=3.3230 load_cv2=3.6358 usage_frac=0.2500 topk_prob_mean=0.8870 ema_alpha_reverse=nan max_logit=1.1661
step:95/1750 train_time:31355ms step_avg:330.05ms
[train step 95] avg_loss=5.829450 main=5.329157 aux=0.500292 imp_cv2=3.1870 load_cv2=3.4315 usage_frac=0.2500 topk_prob_mean=0.8854 ema_alpha_reverse=nan max_logit=1.1661
step:96/1750 train_time:31983ms step_avg:333.15ms
[train step 96] avg_loss=5.769213 main=5.277939 aux=0.491274 imp_cv2=3.1410 load_cv2=3.3606 usage_frac=0.2500 topk_prob_mean=0.8833 ema_alpha_reverse=nan max_logit=1.1662
step:97/1750 train_time:32630ms step_avg:336.39ms
[train step 97] avg_loss=5.700875 main=5.201949 aux=0.498926 imp_cv2=3.1712 load_cv2=3.4265 usage_frac=0.2455 topk_prob_mean=0.8859 ema_alpha_reverse=nan max_logit=1.1662
step:98/1750 train_time:33448ms step_avg:341.31ms
[train step 98] avg_loss=5.947054 main=5.468434 aux=0.478620 imp_cv2=3.0754 load_cv2=3.2670 usage_frac=0.2500 topk_prob_mean=0.8839 ema_alpha_reverse=nan max_logit=1.1663
step:99/1750 train_time:34082ms step_avg:344.26ms
[train step 99] avg_loss=6.038774 main=5.558283 aux=0.480492 imp_cv2=3.0779 load_cv2=3.2864 usage_frac=0.2500 topk_prob_mean=0.8826 ema_alpha_reverse=nan max_logit=1.1663
step:100/1750 train_time:34694ms step_avg:346.94ms
Running validation...
step:100/1750 val_loss:5.375410 train_time:34705ms step_avg:347.05ms
[train step 100] avg_loss=5.503354 main=5.015664 aux=0.487690 imp_cv2=3.1066 load_cv2=3.3369 usage_frac=0.2455 topk_prob_mean=0.8834 ema_alpha_reverse=nan max_logit=1.1664
step:101/1750 train_time:35326ms step_avg:349.76ms
[train step 101] avg_loss=5.916641 main=5.447949 aux=0.468692 imp_cv2=3.0269 load_cv2=3.1857 usage_frac=0.2500 topk_prob_mean=0.8822 ema_alpha_reverse=nan max_logit=1.1664
step:102/1750 train_time:35940ms step_avg:352.35ms
[train step 102] avg_loss=5.582545 main=5.111749 aux=0.470796 imp_cv2=3.0304 load_cv2=3.2078 usage_frac=0.2455 topk_prob_mean=0.8820 ema_alpha_reverse=nan max_logit=1.1665
step:103/1750 train_time:36553ms step_avg:354.89ms
[train step 103] avg_loss=5.631058 main=5.163968 aux=0.467090 imp_cv2=3.0151 load_cv2=3.1775 usage_frac=0.2455 topk_prob_mean=0.8808 ema_alpha_reverse=nan max_logit=1.1666
step:104/1750 train_time:37136ms step_avg:357.08ms
[train step 104] avg_loss=5.702920 main=5.237382 aux=0.465539 imp_cv2=3.0071 load_cv2=3.1643 usage_frac=0.2455 topk_prob_mean=0.8800 ema_alpha_reverse=nan max_logit=1.1666
step:105/1750 train_time:37715ms step_avg:359.19ms
[train step 105] avg_loss=5.768793 main=5.304275 aux=0.464518 imp_cv2=3.0054 load_cv2=3.1536 usage_frac=0.2500 topk_prob_mean=0.8792 ema_alpha_reverse=nan max_logit=1.1667
step:106/1750 train_time:38291ms step_avg:361.24ms
[train step 106] avg_loss=5.912147 main=5.438683 aux=0.473464 imp_cv2=3.0360 load_cv2=3.2333 usage_frac=0.2455 topk_prob_mean=0.8790 ema_alpha_reverse=nan max_logit=1.1668
step:107/1750 train_time:38928ms step_avg:363.81ms
[train step 107] avg_loss=5.664146 main=5.199255 aux=0.464890 imp_cv2=3.0038 load_cv2=3.1597 usage_frac=0.2455 topk_prob_mean=0.8779 ema_alpha_reverse=nan max_logit=1.1670
step:108/1750 train_time:39520ms step_avg:365.92ms
[train step 108] avg_loss=5.774617 main=5.306566 aux=0.468050 imp_cv2=3.0119 load_cv2=3.1893 usage_frac=0.2455 topk_prob_mean=0.8775 ema_alpha_reverse=nan max_logit=1.1671
step:109/1750 train_time:40074ms step_avg:367.65ms
[train step 109] avg_loss=5.498901 main=5.034098 aux=0.464803 imp_cv2=3.0037 load_cv2=3.1587 usage_frac=0.2455 topk_prob_mean=0.8787 ema_alpha_reverse=nan max_logit=1.1672
step:110/1750 train_time:40660ms step_avg:369.64ms
[train step 110] avg_loss=5.584389 main=5.118534 aux=0.465855 imp_cv2=3.0160 load_cv2=3.1570 usage_frac=0.2455 topk_prob_mean=0.8758 ema_alpha_reverse=nan max_logit=1.1674
step:111/1750 train_time:41197ms step_avg:371.15ms
[train step 111] avg_loss=5.599591 main=5.134066 aux=0.465524 imp_cv2=3.0031 load_cv2=3.1672 usage_frac=0.2455 topk_prob_mean=0.8776 ema_alpha_reverse=nan max_logit=1.1675
step:112/1750 train_time:41764ms step_avg:372.90ms
[train step 112] avg_loss=6.067849 main=5.600274 aux=0.467575 imp_cv2=3.0075 load_cv2=3.1867 usage_frac=0.2455 topk_prob_mean=0.8749 ema_alpha_reverse=nan max_logit=1.1677
step:113/1750 train_time:42328ms step_avg:374.58ms
[train step 113] avg_loss=5.772807 main=5.308115 aux=0.464693 imp_cv2=3.0079 load_cv2=3.1523 usage_frac=0.2455 topk_prob_mean=0.8765 ema_alpha_reverse=nan max_logit=1.1679
step:114/1750 train_time:42863ms step_avg:375.99ms
[train step 114] avg_loss=6.223578 main=5.750895 aux=0.472683 imp_cv2=3.0225 load_cv2=3.2386 usage_frac=0.2455 topk_prob_mean=0.8720 ema_alpha_reverse=nan max_logit=1.1681
step:115/1750 train_time:43418ms step_avg:377.55ms
[train step 115] avg_loss=5.467772 main=5.000201 aux=0.467572 imp_cv2=3.0094 load_cv2=3.1876 usage_frac=0.2455 topk_prob_mean=0.8785 ema_alpha_reverse=nan max_logit=1.1683
step:116/1750 train_time:43938ms step_avg:378.77ms
[train step 116] avg_loss=5.853009 main=5.384367 aux=0.468642 imp_cv2=3.0056 load_cv2=3.2035 usage_frac=0.2455 topk_prob_mean=0.8689 ema_alpha_reverse=nan max_logit=1.1686
step:117/1750 train_time:44500ms step_avg:380.34ms
[train step 117] avg_loss=5.618953 main=5.153000 aux=0.465954 imp_cv2=3.0018 load_cv2=3.1760 usage_frac=0.2455 topk_prob_mean=0.8722 ema_alpha_reverse=nan max_logit=1.1688
step:118/1750 train_time:45060ms step_avg:381.86ms
[train step 118] avg_loss=5.563210 main=5.097637 aux=0.465573 imp_cv2=3.0195 load_cv2=3.1513 usage_frac=0.2455 topk_prob_mean=0.8686 ema_alpha_reverse=nan max_logit=1.1691
step:119/1750 train_time:45583ms step_avg:383.05ms
[train step 119] avg_loss=5.381807 main=4.915763 aux=0.466044 imp_cv2=3.0267 load_cv2=3.1518 usage_frac=0.2455 topk_prob_mean=0.8735 ema_alpha_reverse=nan max_logit=1.1694
step:120/1750 train_time:46123ms step_avg:384.36ms
[train step 120] avg_loss=5.573260 main=5.105639 aux=0.467621 imp_cv2=3.0041 load_cv2=3.1939 usage_frac=0.2455 topk_prob_mean=0.8653 ema_alpha_reverse=nan max_logit=1.1697
step:121/1750 train_time:46652ms step_avg:385.55ms
[train step 121] avg_loss=5.502931 main=5.031113 aux=0.471818 imp_cv2=3.0077 load_cv2=3.2433 usage_frac=0.2455 topk_prob_mean=0.8633 ema_alpha_reverse=nan max_logit=1.1701
step:122/1750 train_time:47165ms step_avg:386.60ms
[train step 122] avg_loss=5.273467 main=4.801108 aux=0.472359 imp_cv2=3.0108 load_cv2=3.2447 usage_frac=0.2455 topk_prob_mean=0.8622 ema_alpha_reverse=nan max_logit=1.1705
step:123/1750 train_time:47723ms step_avg:387.99ms
[train step 123] avg_loss=5.550121 main=5.077237 aux=0.472885 imp_cv2=3.0074 load_cv2=3.2594 usage_frac=0.2455 topk_prob_mean=0.8595 ema_alpha_reverse=nan max_logit=1.1709
step:124/1750 train_time:48236ms step_avg:389.00ms
[train step 124] avg_loss=5.411479 main=4.945593 aux=0.465886 imp_cv2=3.0075 load_cv2=3.1680 usage_frac=0.2455 topk_prob_mean=0.8646 ema_alpha_reverse=nan max_logit=1.1713
step:125/1750 train_time:48715ms step_avg:389.72ms
[train step 125] avg_loss=5.529171 main=5.056916 aux=0.472256 imp_cv2=3.0071 load_cv2=3.2475 usage_frac=0.2455 topk_prob_mean=0.8586 ema_alpha_reverse=nan max_logit=1.1717
step:126/1750 train_time:49254ms step_avg:390.90ms
[train step 126] avg_loss=5.659740 main=5.182629 aux=0.477111 imp_cv2=3.0117 load_cv2=3.3045 usage_frac=0.2455 topk_prob_mean=0.8518 ema_alpha_reverse=nan max_logit=1.1722
step:127/1750 train_time:49767ms step_avg:391.87ms
[train step 127] avg_loss=5.356879 main=4.888356 aux=0.468523 imp_cv2=3.0012 load_cv2=3.2090 usage_frac=0.2455 topk_prob_mean=0.8590 ema_alpha_reverse=nan max_logit=1.1727
step:128/1750 train_time:50322ms step_avg:393.14ms
[train step 128] avg_loss=5.266787 main=4.796350 aux=0.470437 imp_cv2=3.0020 load_cv2=3.2340 usage_frac=0.2455 topk_prob_mean=0.8516 ema_alpha_reverse=nan max_logit=1.1732
step:129/1750 train_time:50837ms step_avg:394.09ms
[train step 129] avg_loss=5.345721 main=4.876751 aux=0.468970 imp_cv2=3.0192 load_cv2=3.1959 usage_frac=0.2455 topk_prob_mean=0.8518 ema_alpha_reverse=nan max_logit=1.1738
step:130/1750 train_time:51369ms step_avg:395.15ms
[train step 130] avg_loss=5.463115 main=4.985175 aux=0.477939 imp_cv2=3.0132 load_cv2=3.3111 usage_frac=0.2455 topk_prob_mean=0.8512 ema_alpha_reverse=nan max_logit=1.1744
step:131/1750 train_time:51890ms step_avg:396.11ms
[train step 131] avg_loss=5.316508 main=4.843338 aux=0.473170 imp_cv2=3.0065 load_cv2=3.2670 usage_frac=0.2455 topk_prob_mean=0.8559 ema_alpha_reverse=nan max_logit=1.1750
step:132/1750 train_time:52398ms step_avg:396.95ms
[train step 132] avg_loss=5.482254 main=5.002341 aux=0.479913 imp_cv2=3.0113 load_cv2=3.3413 usage_frac=0.2455 topk_prob_mean=0.8471 ema_alpha_reverse=nan max_logit=1.1757
step:133/1750 train_time:52928ms step_avg:397.95ms
[train step 133] avg_loss=5.607342 main=5.132867 aux=0.474474 imp_cv2=3.0043 load_cv2=3.2811 usage_frac=0.2455 topk_prob_mean=0.8423 ema_alpha_reverse=nan max_logit=1.1764
step:134/1750 train_time:53493ms step_avg:399.20ms
[train step 134] avg_loss=5.649312 main=5.160674 aux=0.488638 imp_cv2=3.0242 load_cv2=3.4392 usage_frac=0.2455 topk_prob_mean=0.8386 ema_alpha_reverse=nan max_logit=1.1771
step:135/1750 train_time:54037ms step_avg:400.28ms
[train step 135] avg_loss=5.535806 main=5.057610 aux=0.478197 imp_cv2=3.0075 load_cv2=3.3203 usage_frac=0.2455 topk_prob_mean=0.8401 ema_alpha_reverse=nan max_logit=1.1779
step:136/1750 train_time:54584ms step_avg:401.36ms
[train step 136] avg_loss=5.294226 main=4.815508 aux=0.478718 imp_cv2=3.0081 load_cv2=3.3346 usage_frac=0.2455 topk_prob_mean=0.8314 ema_alpha_reverse=nan max_logit=1.1787
step:137/1750 train_time:55099ms step_avg:402.18ms
[train step 137] avg_loss=5.322246 main=4.839372 aux=0.482875 imp_cv2=3.0034 load_cv2=3.3889 usage_frac=0.2455 topk_prob_mean=0.8259 ema_alpha_reverse=nan max_logit=1.1796
step:138/1750 train_time:55649ms step_avg:403.25ms
[train step 138] avg_loss=5.438934 main=4.945292 aux=0.493643 imp_cv2=3.0131 load_cv2=3.5113 usage_frac=0.2455 topk_prob_mean=0.8271 ema_alpha_reverse=nan max_logit=1.1805
step:139/1750 train_time:56212ms step_avg:404.40ms
[train step 139] avg_loss=5.380800 main=4.900362 aux=0.480438 imp_cv2=3.0039 load_cv2=3.3570 usage_frac=0.2455 topk_prob_mean=0.8290 ema_alpha_reverse=nan max_logit=1.1814
step:140/1750 train_time:56758ms step_avg:405.42ms
[train step 140] avg_loss=5.294485 main=4.817806 aux=0.476680 imp_cv2=3.0180 load_cv2=3.2955 usage_frac=0.2455 topk_prob_mean=0.8298 ema_alpha_reverse=nan max_logit=1.1824
step:141/1750 train_time:57292ms step_avg:406.33ms
[train step 141] avg_loss=5.347183 main=5.031567 aux=0.315616 imp_cv2=1.7515 load_cv2=2.3278 usage_frac=0.3705 topk_prob_mean=0.6511 ema_alpha_reverse=nan max_logit=1.1834
step:142/1750 train_time:58212ms step_avg:409.94ms
[train step 142] avg_loss=5.139890 main=4.680050 aux=0.459840 imp_cv2=2.2250 load_cv2=3.4391 usage_frac=0.2812 topk_prob_mean=0.7290 ema_alpha_reverse=nan max_logit=1.1845
step:143/1750 train_time:58826ms step_avg:411.37ms
[train step 143] avg_loss=5.396241 main=4.945852 aux=0.450389 imp_cv2=2.0538 load_cv2=3.5226 usage_frac=0.2812 topk_prob_mean=0.6768 ema_alpha_reverse=nan max_logit=1.1857
step:144/1750 train_time:59444ms step_avg:412.80ms
[train step 144] avg_loss=5.178811 main=4.719024 aux=0.459787 imp_cv2=1.9296 load_cv2=3.7932 usage_frac=0.2857 topk_prob_mean=0.6191 ema_alpha_reverse=nan max_logit=1.1869
step:145/1750 train_time:60109ms step_avg:414.55ms
[train step 145] avg_loss=5.467105 main=5.005795 aux=0.461310 imp_cv2=1.8092 load_cv2=3.9191 usage_frac=0.2991 topk_prob_mean=0.5479 ema_alpha_reverse=nan max_logit=1.1881
step:146/1750 train_time:60798ms step_avg:416.42ms
[train step 146] avg_loss=5.436001 main=4.954162 aux=0.481839 imp_cv2=1.7739 load_cv2=4.1852 usage_frac=0.3036 topk_prob_mean=0.5228 ema_alpha_reverse=nan max_logit=1.1894
step:147/1750 train_time:61475ms step_avg:418.20ms
[train step 147] avg_loss=5.299225 main=4.778229 aux=0.520996 imp_cv2=1.7438 load_cv2=4.6648 usage_frac=0.3170 topk_prob_mean=0.4827 ema_alpha_reverse=nan max_logit=1.1908
step:148/1750 train_time:62212ms step_avg:420.35ms
[train step 148] avg_loss=5.404529 main=4.872965 aux=0.531564 imp_cv2=1.7215 load_cv2=4.8364 usage_frac=0.3214 topk_prob_mean=0.4629 ema_alpha_reverse=nan max_logit=1.1922
step:149/1750 train_time:62929ms step_avg:422.34ms
[train step 149] avg_loss=5.347753 main=4.800475 aux=0.547278 imp_cv2=1.7174 load_cv2=5.0093 usage_frac=0.3170 topk_prob_mean=0.4519 ema_alpha_reverse=nan max_logit=1.1937
step:150/1750 train_time:63630ms step_avg:424.20ms
Running validation...
step:150/1750 val_loss:4.937801 train_time:63642ms step_avg:424.28ms
[train step 150] avg_loss=5.510801 main=4.975256 aux=0.535544 imp_cv2=1.7110 load_cv2=4.8900 usage_frac=0.3080 topk_prob_mean=0.4544 ema_alpha_reverse=nan max_logit=1.1952
step:151/1750 train_time:64362ms step_avg:426.24ms
[train step 151] avg_loss=5.472934 main=4.926710 aux=0.546224 imp_cv2=1.7145 load_cv2=5.0114 usage_frac=0.3259 topk_prob_mean=0.4532 ema_alpha_reverse=nan max_logit=1.1968
step:152/1750 train_time:65074ms step_avg:428.12ms
[train step 152] avg_loss=5.664008 main=5.097182 aux=0.566826 imp_cv2=1.7206 load_cv2=5.2606 usage_frac=0.3259 topk_prob_mean=0.4562 ema_alpha_reverse=nan max_logit=1.1985
step:153/1750 train_time:65777ms step_avg:429.92ms
[train step 153] avg_loss=5.766715 main=5.204290 aux=0.562424 imp_cv2=1.7019 load_cv2=5.2067 usage_frac=0.3259 topk_prob_mean=0.4285 ema_alpha_reverse=nan max_logit=1.2003
step:154/1750 train_time:66516ms step_avg:431.92ms
[train step 154] avg_loss=5.036678 main=4.471714 aux=0.564964 imp_cv2=1.7066 load_cv2=5.2316 usage_frac=0.3125 topk_prob_mean=0.4409 ema_alpha_reverse=nan max_logit=1.2021
step:155/1750 train_time:67212ms step_avg:433.62ms
[train step 155] avg_loss=5.252251 main=4.678351 aux=0.573901 imp_cv2=1.7073 load_cv2=5.3398 usage_frac=0.3170 topk_prob_mean=0.4389 ema_alpha_reverse=nan max_logit=1.2040
step:156/1750 train_time:67899ms step_avg:435.25ms
[train step 156] avg_loss=5.273757 main=4.699850 aux=0.573908 imp_cv2=1.7025 load_cv2=5.3395 usage_frac=0.3125 topk_prob_mean=0.4348 ema_alpha_reverse=nan max_logit=1.2059
step:157/1750 train_time:68594ms step_avg:436.90ms
[train step 157] avg_loss=5.069898 main=4.504690 aux=0.565208 imp_cv2=1.7036 load_cv2=5.2390 usage_frac=0.3125 topk_prob_mean=0.4409 ema_alpha_reverse=nan max_logit=1.2080
step:158/1750 train_time:69274ms step_avg:438.44ms
[train step 158] avg_loss=5.356955 main=4.779033 aux=0.577922 imp_cv2=1.6993 load_cv2=5.3971 usage_frac=0.3259 topk_prob_mean=0.4299 ema_alpha_reverse=nan max_logit=1.2101
step:159/1750 train_time:69972ms step_avg:440.07ms
[train step 159] avg_loss=5.228356 main=4.654998 aux=0.573358 imp_cv2=1.6882 load_cv2=5.3676 usage_frac=0.3214 topk_prob_mean=0.4236 ema_alpha_reverse=nan max_logit=1.2123
step:160/1750 train_time:70652ms step_avg:441.57ms
[train step 160] avg_loss=5.076928 main=4.504608 aux=0.572320 imp_cv2=1.6993 load_cv2=5.3277 usage_frac=0.3125 topk_prob_mean=0.4338 ema_alpha_reverse=nan max_logit=1.2146
step:161/1750 train_time:71325ms step_avg:443.01ms
[train step 161] avg_loss=5.282805 main=4.709204 aux=0.573601 imp_cv2=1.7045 load_cv2=5.3229 usage_frac=0.3125 topk_prob_mean=0.4371 ema_alpha_reverse=nan max_logit=1.2170
step:162/1750 train_time:71991ms step_avg:444.39ms
[train step 162] avg_loss=5.247216 main=4.676729 aux=0.570487 imp_cv2=1.6938 load_cv2=5.3084 usage_frac=0.3125 topk_prob_mean=0.4331 ema_alpha_reverse=nan max_logit=1.2194
step:163/1750 train_time:72688ms step_avg:445.94ms
[train step 163] avg_loss=5.993648 main=5.413103 aux=0.580545 imp_cv2=1.6894 load_cv2=5.4440 usage_frac=0.3259 topk_prob_mean=0.4188 ema_alpha_reverse=nan max_logit=1.2220
step:164/1750 train_time:73319ms step_avg:447.07ms
[train step 164] avg_loss=5.149958 main=4.566127 aux=0.583831 imp_cv2=1.6918 load_cv2=5.4765 usage_frac=0.3125 topk_prob_mean=0.4306 ema_alpha_reverse=nan max_logit=1.2247
step:165/1750 train_time:73981ms step_avg:448.37ms
[train step 165] avg_loss=5.183829 main=4.600523 aux=0.583307 imp_cv2=1.6861 load_cv2=5.4749 usage_frac=0.3214 topk_prob_mean=0.4239 ema_alpha_reverse=nan max_logit=1.2274
step:166/1750 train_time:74630ms step_avg:449.58ms
[train step 166] avg_loss=5.011490 main=4.429367 aux=0.582123 imp_cv2=1.6935 load_cv2=5.4459 usage_frac=0.3214 topk_prob_mean=0.4302 ema_alpha_reverse=nan max_logit=1.2303
step:167/1750 train_time:75270ms step_avg:450.72ms
[train step 167] avg_loss=5.266591 main=4.680584 aux=0.586007 imp_cv2=1.7126 load_cv2=5.4638 usage_frac=0.3259 topk_prob_mean=0.4393 ema_alpha_reverse=nan max_logit=1.2332
step:168/1750 train_time:75887ms step_avg:451.71ms
[train step 168] avg_loss=5.181816 main=4.595055 aux=0.586761 imp_cv2=1.6928 load_cv2=5.5037 usage_frac=0.3214 topk_prob_mean=0.4253 ema_alpha_reverse=nan max_logit=1.2363
step:169/1750 train_time:76524ms step_avg:452.80ms
[train step 169] avg_loss=5.231194 main=4.647296 aux=0.583897 imp_cv2=1.7015 load_cv2=5.4488 usage_frac=0.3170 topk_prob_mean=0.4285 ema_alpha_reverse=nan max_logit=1.2394
step:170/1750 train_time:77146ms step_avg:453.80ms
[train step 170] avg_loss=5.187464 main=4.601082 aux=0.586382 imp_cv2=1.7065 load_cv2=5.4800 usage_frac=0.3170 topk_prob_mean=0.4335 ema_alpha_reverse=nan max_logit=1.2427
step:171/1750 train_time:77735ms step_avg:454.59ms
[train step 171] avg_loss=5.472480 main=4.894071 aux=0.578409 imp_cv2=1.6927 load_cv2=5.4159 usage_frac=0.3125 topk_prob_mean=0.4177 ema_alpha_reverse=nan max_logit=1.2461
step:172/1750 train_time:78361ms step_avg:455.59ms
[train step 172] avg_loss=5.232238 main=4.642880 aux=0.589358 imp_cv2=1.7015 load_cv2=5.5143 usage_frac=0.3170 topk_prob_mean=0.4312 ema_alpha_reverse=nan max_logit=1.2496
step:173/1750 train_time:78981ms step_avg:456.54ms
[train step 173] avg_loss=5.360549 main=4.778691 aux=0.581858 imp_cv2=1.6876 load_cv2=5.4456 usage_frac=0.3125 topk_prob_mean=0.4261 ema_alpha_reverse=nan max_logit=1.2532
step:174/1750 train_time:79578ms step_avg:457.35ms
[train step 174] avg_loss=5.499687 main=4.911514 aux=0.588173 imp_cv2=1.7082 load_cv2=5.4928 usage_frac=0.3125 topk_prob_mean=0.4332 ema_alpha_reverse=nan max_logit=1.2570
step:175/1750 train_time:80170ms step_avg:458.11ms
[train step 175] avg_loss=5.090740 main=4.497531 aux=0.593209 imp_cv2=1.7154 load_cv2=5.5385 usage_frac=0.3170 topk_prob_mean=0.4345 ema_alpha_reverse=nan max_logit=1.2609
step:176/1750 train_time:80782ms step_avg:458.99ms
[train step 176] avg_loss=5.369055 main=4.786894 aux=0.582161 imp_cv2=1.6955 load_cv2=5.4362 usage_frac=0.3214 topk_prob_mean=0.4306 ema_alpha_reverse=nan max_logit=1.2649
step:177/1750 train_time:81366ms step_avg:459.69ms
[train step 177] avg_loss=5.066071 main=4.484748 aux=0.581323 imp_cv2=1.6832 load_cv2=5.4526 usage_frac=0.3214 topk_prob_mean=0.4178 ema_alpha_reverse=nan max_logit=1.2690
step:178/1750 train_time:81947ms step_avg:460.37ms
[train step 178] avg_loss=5.099881 main=4.519034 aux=0.580847 imp_cv2=1.6904 load_cv2=5.4335 usage_frac=0.3214 topk_prob_mean=0.4276 ema_alpha_reverse=nan max_logit=1.2733
step:179/1750 train_time:82540ms step_avg:461.12ms
[train step 179] avg_loss=5.100548 main=4.516474 aux=0.584074 imp_cv2=1.7001 load_cv2=5.4603 usage_frac=0.3214 topk_prob_mean=0.4370 ema_alpha_reverse=nan max_logit=1.2777
step:180/1750 train_time:83124ms step_avg:461.80ms
[train step 180] avg_loss=5.371275 main=4.778870 aux=0.592405 imp_cv2=1.7071 load_cv2=5.5555 usage_frac=0.3214 topk_prob_mean=0.4390 ema_alpha_reverse=nan max_logit=1.2823
step:181/1750 train_time:83707ms step_avg:462.47ms
[train step 181] avg_loss=5.280754 main=4.690657 aux=0.590097 imp_cv2=1.6990 load_cv2=5.5417 usage_frac=0.3170 topk_prob_mean=0.4364 ema_alpha_reverse=nan max_logit=1.2870
step:182/1750 train_time:84286ms step_avg:463.11ms
[train step 182] avg_loss=5.354298 main=4.773495 aux=0.580803 imp_cv2=1.6932 load_cv2=5.4444 usage_frac=0.3304 topk_prob_mean=0.4233 ema_alpha_reverse=nan max_logit=1.2919
step:183/1750 train_time:84903ms step_avg:463.95ms
[train step 183] avg_loss=5.496236 main=4.903048 aux=0.593188 imp_cv2=1.6981 load_cv2=5.5809 usage_frac=0.3170 topk_prob_mean=0.4288 ema_alpha_reverse=nan max_logit=1.2969
step:184/1750 train_time:85494ms step_avg:464.64ms
[train step 184] avg_loss=5.322380 main=4.728849 aux=0.593531 imp_cv2=1.6976 load_cv2=5.5772 usage_frac=0.3080 topk_prob_mean=0.4262 ema_alpha_reverse=nan max_logit=1.3021
step:185/1750 train_time:86060ms step_avg:465.19ms
[train step 185] avg_loss=5.238075 main=4.648821 aux=0.589254 imp_cv2=1.7055 load_cv2=5.5107 usage_frac=0.3259 topk_prob_mean=0.4340 ema_alpha_reverse=nan max_logit=1.3075
step:186/1750 train_time:86626ms step_avg:465.73ms
[train step 186] avg_loss=5.228329 main=4.625877 aux=0.602452 imp_cv2=1.7161 load_cv2=5.6544 usage_frac=0.3170 topk_prob_mean=0.4318 ema_alpha_reverse=nan max_logit=1.3130
step:187/1750 train_time:87178ms step_avg:466.19ms
[train step 187] avg_loss=5.479111 main=4.874369 aux=0.604742 imp_cv2=1.6925 load_cv2=5.7147 usage_frac=0.3214 topk_prob_mean=0.4203 ema_alpha_reverse=nan max_logit=1.3187
step:188/1750 train_time:87737ms step_avg:466.68ms
[train step 188] avg_loss=5.174401 main=4.580603 aux=0.593798 imp_cv2=1.7032 load_cv2=5.5675 usage_frac=0.3214 topk_prob_mean=0.4309 ema_alpha_reverse=nan max_logit=1.3246
step:189/1750 train_time:88288ms step_avg:467.13ms
[train step 189] avg_loss=5.567447 main=4.965712 aux=0.601735 imp_cv2=1.6931 load_cv2=5.6748 usage_frac=0.3214 topk_prob_mean=0.4188 ema_alpha_reverse=nan max_logit=1.3307
step:190/1750 train_time:88847ms step_avg:467.62ms
[train step 190] avg_loss=4.956487 main=4.369674 aux=0.586813 imp_cv2=1.6934 load_cv2=5.4931 usage_frac=0.3214 topk_prob_mean=0.4188 ema_alpha_reverse=nan max_logit=1.3370
step:191/1750 train_time:89402ms step_avg:468.07ms
[train step 191] avg_loss=5.104700 main=4.506824 aux=0.597875 imp_cv2=1.7146 load_cv2=5.6110 usage_frac=0.3214 topk_prob_mean=0.4304 ema_alpha_reverse=nan max_logit=1.3434
step:192/1750 train_time:89976ms step_avg:468.62ms
[train step 192] avg_loss=5.204657 main=4.607323 aux=0.597334 imp_cv2=1.7073 load_cv2=5.6038 usage_frac=0.3214 topk_prob_mean=0.4250 ema_alpha_reverse=nan max_logit=1.3501
step:193/1750 train_time:90557ms step_avg:469.21ms
[train step 193] avg_loss=5.211447 main=4.611655 aux=0.599792 imp_cv2=1.6975 load_cv2=5.6421 usage_frac=0.3214 topk_prob_mean=0.4235 ema_alpha_reverse=nan max_logit=1.3570
step:194/1750 train_time:91114ms step_avg:469.66ms
[train step 194] avg_loss=5.352565 main=4.767416 aux=0.585149 imp_cv2=1.6986 load_cv2=5.4767 usage_frac=0.2991 topk_prob_mean=0.4143 ema_alpha_reverse=nan max_logit=1.3640
step:195/1750 train_time:91692ms step_avg:470.22ms
[train step 195] avg_loss=5.463451 main=4.867078 aux=0.596373 imp_cv2=1.6921 load_cv2=5.6070 usage_frac=0.3214 topk_prob_mean=0.4235 ema_alpha_reverse=nan max_logit=1.3713
step:196/1750 train_time:92242ms step_avg:470.62ms
[train step 196] avg_loss=4.908785 main=4.311305 aux=0.597481 imp_cv2=1.6988 load_cv2=5.6118 usage_frac=0.3080 topk_prob_mean=0.4264 ema_alpha_reverse=nan max_logit=1.3789
step:197/1750 train_time:92808ms step_avg:471.10ms
[train step 197] avg_loss=4.999045 main=4.401666 aux=0.597379 imp_cv2=1.7139 load_cv2=5.6010 usage_frac=0.3170 topk_prob_mean=0.4341 ema_alpha_reverse=nan max_logit=1.3866
step:198/1750 train_time:93360ms step_avg:471.51ms
[train step 198] avg_loss=5.229277 main=4.636232 aux=0.593045 imp_cv2=1.7001 load_cv2=5.5670 usage_frac=0.3170 topk_prob_mean=0.4266 ema_alpha_reverse=nan max_logit=1.3946
step:199/1750 train_time:93916ms step_avg:471.94ms
[train step 199] avg_loss=5.035119 main=4.437676 aux=0.597443 imp_cv2=1.6829 load_cv2=5.6373 usage_frac=0.3170 topk_prob_mean=0.4138 ema_alpha_reverse=nan max_logit=1.4029
step:200/1750 train_time:94468ms step_avg:472.34ms
Running validation...
step:200/1750 val_loss:4.586460 train_time:94480ms step_avg:472.40ms
[train step 200] avg_loss=5.454113 main=4.850692 aux=0.603420 imp_cv2=1.6873 load_cv2=5.6998 usage_frac=0.3080 topk_prob_mean=0.4199 ema_alpha_reverse=nan max_logit=1.4114
step:201/1750 train_time:95023ms step_avg:472.75ms
[train step 201] avg_loss=5.262684 main=4.657506 aux=0.605178 imp_cv2=1.6987 load_cv2=5.7120 usage_frac=0.3170 topk_prob_mean=0.4228 ema_alpha_reverse=nan max_logit=1.4201
step:202/1750 train_time:95565ms step_avg:473.09ms
[train step 202] avg_loss=5.265948 main=4.686760 aux=0.579188 imp_cv2=1.6963 load_cv2=5.4082 usage_frac=0.3170 topk_prob_mean=0.4232 ema_alpha_reverse=nan max_logit=1.4291
step:203/1750 train_time:96118ms step_avg:473.49ms
[train step 203] avg_loss=5.072092 main=4.473231 aux=0.598861 imp_cv2=1.7006 load_cv2=5.6310 usage_frac=0.3170 topk_prob_mean=0.4222 ema_alpha_reverse=nan max_logit=1.4384
step:204/1750 train_time:96686ms step_avg:473.95ms
[train step 204] avg_loss=4.956160 main=4.349432 aux=0.606728 imp_cv2=1.7159 load_cv2=5.7107 usage_frac=0.3170 topk_prob_mean=0.4341 ema_alpha_reverse=nan max_logit=1.4480
step:205/1750 train_time:97231ms step_avg:474.30ms
[train step 205] avg_loss=5.119996 main=4.513306 aux=0.606689 imp_cv2=1.7044 load_cv2=5.7230 usage_frac=0.3125 topk_prob_mean=0.4264 ema_alpha_reverse=nan max_logit=1.4579
step:206/1750 train_time:97777ms step_avg:474.64ms
[train step 206] avg_loss=5.003389 main=4.399809 aux=0.603579 imp_cv2=1.7351 load_cv2=5.6613 usage_frac=0.3170 topk_prob_mean=0.4384 ema_alpha_reverse=nan max_logit=1.4681
step:207/1750 train_time:98321ms step_avg:474.98ms
[train step 207] avg_loss=5.075089 main=4.471626 aux=0.603462 imp_cv2=1.7064 load_cv2=5.6917 usage_frac=0.3170 topk_prob_mean=0.4237 ema_alpha_reverse=nan max_logit=1.4786
step:208/1750 train_time:98833ms step_avg:475.16ms
[train step 208] avg_loss=5.085693 main=4.481893 aux=0.603800 imp_cv2=1.6987 load_cv2=5.7009 usage_frac=0.3125 topk_prob_mean=0.4209 ema_alpha_reverse=nan max_logit=1.4894
step:209/1750 train_time:99365ms step_avg:475.43ms
[train step 209] avg_loss=5.158886 main=4.550727 aux=0.608159 imp_cv2=1.6812 load_cv2=5.7747 usage_frac=0.3170 topk_prob_mean=0.4083 ema_alpha_reverse=nan max_logit=1.5005
step:210/1750 train_time:99890ms step_avg:475.67ms
[train step 210] avg_loss=5.111062 main=4.499392 aux=0.611670 imp_cv2=1.7042 load_cv2=5.7851 usage_frac=0.3125 topk_prob_mean=0.4266 ema_alpha_reverse=nan max_logit=1.5120
step:211/1750 train_time:100412ms step_avg:475.89ms
[train step 211] avg_loss=4.958310 main=4.353726 aux=0.604584 imp_cv2=1.6925 load_cv2=5.7108 usage_frac=0.3214 topk_prob_mean=0.4216 ema_alpha_reverse=nan max_logit=1.5238
step:212/1750 train_time:100938ms step_avg:476.12ms
[train step 212] avg_loss=5.122364 main=4.508964 aux=0.613400 imp_cv2=1.7123 load_cv2=5.7959 usage_frac=0.3170 topk_prob_mean=0.4324 ema_alpha_reverse=nan max_logit=1.5359
step:213/1750 train_time:101465ms step_avg:476.36ms
[train step 213] avg_loss=5.379881 main=4.763461 aux=0.616420 imp_cv2=1.6988 load_cv2=5.8410 usage_frac=0.3080 topk_prob_mean=0.4114 ema_alpha_reverse=nan max_logit=1.5485
step:214/1750 train_time:101973ms step_avg:476.51ms
[train step 214] avg_loss=5.010001 main=4.394844 aux=0.615157 imp_cv2=1.7218 load_cv2=5.8044 usage_frac=0.3125 topk_prob_mean=0.4326 ema_alpha_reverse=nan max_logit=1.5614
step:215/1750 train_time:102513ms step_avg:476.80ms
[train step 215] avg_loss=5.229432 main=4.613710 aux=0.615722 imp_cv2=1.7042 load_cv2=5.8311 usage_frac=0.3170 topk_prob_mean=0.4249 ema_alpha_reverse=nan max_logit=1.5747
step:216/1750 train_time:103054ms step_avg:477.10ms
[train step 216] avg_loss=5.034553 main=4.424797 aux=0.609756 imp_cv2=1.7180 load_cv2=5.7446 usage_frac=0.3170 topk_prob_mean=0.4330 ema_alpha_reverse=nan max_logit=1.5885
step:217/1750 train_time:103574ms step_avg:477.30ms
[train step 217] avg_loss=5.081129 main=4.468639 aux=0.612490 imp_cv2=1.7054 load_cv2=5.7865 usage_frac=0.3259 topk_prob_mean=0.4240 ema_alpha_reverse=nan max_logit=1.6026
step:218/1750 train_time:104088ms step_avg:477.47ms
[train step 218] avg_loss=5.259584 main=4.648782 aux=0.610802 imp_cv2=1.6932 load_cv2=5.7832 usage_frac=0.3259 topk_prob_mean=0.4184 ema_alpha_reverse=nan max_logit=1.6172
step:219/1750 train_time:104593ms step_avg:477.59ms
[train step 219] avg_loss=5.152052 main=4.545230 aux=0.606821 imp_cv2=1.6884 load_cv2=5.7368 usage_frac=0.3214 topk_prob_mean=0.4158 ema_alpha_reverse=nan max_logit=1.6322
step:220/1750 train_time:105098ms step_avg:477.72ms
[train step 220] avg_loss=4.907498 main=4.288910 aux=0.618589 imp_cv2=1.6927 load_cv2=5.8662 usage_frac=0.3170 topk_prob_mean=0.4163 ema_alpha_reverse=nan max_logit=1.6477
step:221/1750 train_time:105602ms step_avg:477.84ms
[train step 221] avg_loss=5.098871 main=4.488752 aux=0.610120 imp_cv2=1.7217 load_cv2=5.7375 usage_frac=0.3170 topk_prob_mean=0.4373 ema_alpha_reverse=nan max_logit=1.6636
step:222/1750 train_time:106135ms step_avg:478.09ms
[train step 222] avg_loss=5.013263 main=4.397043 aux=0.616221 imp_cv2=1.7017 load_cv2=5.8322 usage_frac=0.3170 topk_prob_mean=0.4253 ema_alpha_reverse=nan max_logit=1.6801
step:223/1750 train_time:106643ms step_avg:478.22ms
[train step 223] avg_loss=5.357179 main=4.752474 aux=0.604705 imp_cv2=1.7038 load_cv2=5.6865 usage_frac=0.3214 topk_prob_mean=0.4258 ema_alpha_reverse=nan max_logit=1.6971
step:224/1750 train_time:107181ms step_avg:478.48ms
[train step 224] avg_loss=5.198213 main=4.582285 aux=0.615927 imp_cv2=1.6969 load_cv2=5.8247 usage_frac=0.3170 topk_prob_mean=0.4188 ema_alpha_reverse=nan max_logit=1.7145
step:225/1750 train_time:107728ms step_avg:478.79ms
[train step 225] avg_loss=5.224808 main=4.612630 aux=0.612178 imp_cv2=1.7081 load_cv2=5.7705 usage_frac=0.3214 topk_prob_mean=0.4311 ema_alpha_reverse=nan max_logit=1.7325
step:226/1750 train_time:108250ms step_avg:478.98ms
[train step 226] avg_loss=5.754854 main=5.148785 aux=0.606069 imp_cv2=1.7143 load_cv2=5.6966 usage_frac=0.3304 topk_prob_mean=0.4283 ema_alpha_reverse=nan max_logit=1.7511
step:227/1750 train_time:108765ms step_avg:479.14ms
[train step 227] avg_loss=5.093557 main=4.486730 aux=0.606827 imp_cv2=1.7017 load_cv2=5.7094 usage_frac=0.3170 topk_prob_mean=0.4251 ema_alpha_reverse=nan max_logit=1.7703
step:228/1750 train_time:109302ms step_avg:479.40ms
[train step 228] avg_loss=5.054418 main=4.438381 aux=0.616037 imp_cv2=1.7088 load_cv2=5.8100 usage_frac=0.3170 topk_prob_mean=0.4250 ema_alpha_reverse=nan max_logit=1.7900
step:229/1750 train_time:109838ms step_avg:479.64ms
[train step 229] avg_loss=4.995455 main=4.389583 aux=0.605872 imp_cv2=1.6973 load_cv2=5.7069 usage_frac=0.3170 topk_prob_mean=0.4270 ema_alpha_reverse=nan max_logit=1.8104
step:230/1750 train_time:110345ms step_avg:479.76ms
[train step 230] avg_loss=5.087837 main=4.484280 aux=0.603557 imp_cv2=1.7067 load_cv2=5.6726 usage_frac=0.3214 topk_prob_mean=0.4274 ema_alpha_reverse=nan max_logit=1.8314
step:231/1750 train_time:110858ms step_avg:479.91ms
[train step 231] avg_loss=4.965299 main=4.361491 aux=0.603808 imp_cv2=1.6973 load_cv2=5.6853 usage_frac=0.3214 topk_prob_mean=0.4232 ema_alpha_reverse=nan max_logit=1.8531
step:232/1750 train_time:111359ms step_avg:480.00ms
[train step 232] avg_loss=4.937043 main=4.324325 aux=0.612718 imp_cv2=1.7089 load_cv2=5.7803 usage_frac=0.3170 topk_prob_mean=0.4269 ema_alpha_reverse=nan max_logit=1.8755
step:233/1750 train_time:111861ms step_avg:480.09ms
[train step 233] avg_loss=4.999491 main=4.370691 aux=0.628800 imp_cv2=1.7091 load_cv2=5.9594 usage_frac=0.3170 topk_prob_mean=0.4116 ema_alpha_reverse=nan max_logit=1.8985
step:234/1750 train_time:112380ms step_avg:480.26ms
[train step 234] avg_loss=5.164053 main=4.549735 aux=0.614318 imp_cv2=2.5338 load_cv2=4.8374 usage_frac=0.4330 topk_prob_mean=0.6908 ema_alpha_reverse=nan max_logit=1.9223
step:235/1750 train_time:113032ms step_avg:480.99ms
[train step 235] avg_loss=5.567631 main=4.993879 aux=0.573752 imp_cv2=1.0924 load_cv2=5.8033 usage_frac=0.3661 topk_prob_mean=0.3647 ema_alpha_reverse=nan max_logit=1.9469
step:236/1750 train_time:113546ms step_avg:481.13ms
[train step 236] avg_loss=4.826825 main=4.260397 aux=0.566428 imp_cv2=1.0977 load_cv2=5.7098 usage_frac=0.3438 topk_prob_mean=0.3740 ema_alpha_reverse=nan max_logit=1.9722
step:237/1750 train_time:114056ms step_avg:481.25ms
[train step 237] avg_loss=4.880559 main=4.319277 aux=0.561282 imp_cv2=1.0815 load_cv2=5.6698 usage_frac=0.3527 topk_prob_mean=0.3675 ema_alpha_reverse=nan max_logit=1.9984
step:238/1750 train_time:114578ms step_avg:481.42ms
[train step 238] avg_loss=4.856906 main=4.295421 aux=0.561485 imp_cv2=1.0750 load_cv2=5.6836 usage_frac=0.3393 topk_prob_mean=0.3550 ema_alpha_reverse=nan max_logit=2.0254
step:239/1750 train_time:115101ms step_avg:481.59ms
[train step 239] avg_loss=5.013973 main=4.452129 aux=0.561844 imp_cv2=1.0837 load_cv2=5.6860 usage_frac=0.3482 topk_prob_mean=0.3629 ema_alpha_reverse=nan max_logit=2.0533
step:240/1750 train_time:115629ms step_avg:481.79ms
[train step 240] avg_loss=5.151589 main=4.594803 aux=0.556786 imp_cv2=1.0715 load_cv2=5.6352 usage_frac=0.3527 topk_prob_mean=0.3548 ema_alpha_reverse=nan max_logit=2.0821
step:241/1750 train_time:116180ms step_avg:482.08ms
[train step 241] avg_loss=4.839018 main=4.278368 aux=0.560650 imp_cv2=1.1300 load_cv2=5.6297 usage_frac=0.3527 topk_prob_mean=0.3751 ema_alpha_reverse=nan max_logit=2.1119
step:242/1750 train_time:116709ms step_avg:482.27ms
[train step 242] avg_loss=4.897657 main=4.334491 aux=0.563166 imp_cv2=1.0542 load_cv2=5.7310 usage_frac=0.3482 topk_prob_mean=0.3396 ema_alpha_reverse=nan max_logit=2.1426
step:243/1750 train_time:117228ms step_avg:482.42ms
[train step 243] avg_loss=4.977101 main=4.408063 aux=0.569038 imp_cv2=1.1002 load_cv2=5.7569 usage_frac=0.3393 topk_prob_mean=0.3641 ema_alpha_reverse=nan max_logit=2.1743
step:244/1750 train_time:117744ms step_avg:482.56ms
[train step 244] avg_loss=5.050807 main=4.476854 aux=0.573953 imp_cv2=1.0783 load_cv2=5.8326 usage_frac=0.3482 topk_prob_mean=0.3518 ema_alpha_reverse=nan max_logit=2.2071
step:245/1750 train_time:118257ms step_avg:482.68ms
[train step 245] avg_loss=4.737799 main=4.173073 aux=0.564726 imp_cv2=1.0991 load_cv2=5.6939 usage_frac=0.3527 topk_prob_mean=0.3608 ema_alpha_reverse=nan max_logit=2.2410
step:246/1750 train_time:118763ms step_avg:482.78ms
[train step 246] avg_loss=5.035646 main=4.464901 aux=0.570745 imp_cv2=1.0771 load_cv2=5.7944 usage_frac=0.3482 topk_prob_mean=0.3543 ema_alpha_reverse=nan max_logit=2.2760
step:247/1750 train_time:119284ms step_avg:482.93ms
[train step 247] avg_loss=4.644046 main=4.075411 aux=0.568635 imp_cv2=1.0929 load_cv2=5.7513 usage_frac=0.3527 topk_prob_mean=0.3573 ema_alpha_reverse=nan max_logit=2.3122
step:248/1750 train_time:119792ms step_avg:483.03ms
[train step 248] avg_loss=4.940376 main=4.374861 aux=0.565515 imp_cv2=1.0914 load_cv2=5.7171 usage_frac=0.3527 topk_prob_mean=0.3596 ema_alpha_reverse=nan max_logit=2.3497
step:249/1750 train_time:120321ms step_avg:483.22ms
[train step 249] avg_loss=4.689001 main=4.120646 aux=0.568355 imp_cv2=1.0959 load_cv2=5.7448 usage_frac=0.3482 topk_prob_mean=0.3598 ema_alpha_reverse=nan max_logit=2.3884
step:250/1750 train_time:120845ms step_avg:483.38ms
Running validation...
step:250/1750 val_loss:4.348526 train_time:120857ms step_avg:483.43ms
[train step 250] avg_loss=4.802825 main=4.237914 aux=0.564911 imp_cv2=1.0617 load_cv2=5.7357 usage_frac=0.3571 topk_prob_mean=0.3494 ema_alpha_reverse=nan max_logit=2.4284
step:251/1750 train_time:121368ms step_avg:483.54ms
[train step 251] avg_loss=4.931563 main=4.364092 aux=0.567471 imp_cv2=1.0805 load_cv2=5.7528 usage_frac=0.3438 topk_prob_mean=0.3577 ema_alpha_reverse=nan max_logit=2.4699
step:252/1750 train_time:121871ms step_avg:483.62ms
[train step 252] avg_loss=5.332063 main=4.765269 aux=0.566795 imp_cv2=1.0533 load_cv2=5.7747 usage_frac=0.3527 topk_prob_mean=0.3384 ema_alpha_reverse=nan max_logit=2.5127
step:253/1750 train_time:122393ms step_avg:483.77ms
[train step 253] avg_loss=4.723266 main=4.159490 aux=0.563776 imp_cv2=1.0819 load_cv2=5.7054 usage_frac=0.3482 topk_prob_mean=0.3586 ema_alpha_reverse=nan max_logit=2.5571
step:254/1750 train_time:122911ms step_avg:483.90ms
[train step 254] avg_loss=4.870432 main=4.300032 aux=0.570400 imp_cv2=1.0643 load_cv2=5.8050 usage_frac=0.3527 topk_prob_mean=0.3478 ema_alpha_reverse=nan max_logit=2.6030
step:255/1750 train_time:123430ms step_avg:484.04ms
[train step 255] avg_loss=4.980169 main=4.415229 aux=0.564939 imp_cv2=1.0697 load_cv2=5.7360 usage_frac=0.3482 topk_prob_mean=0.3531 ema_alpha_reverse=nan max_logit=2.6505
step:256/1750 train_time:123951ms step_avg:484.18ms
[train step 256] avg_loss=4.679216 main=4.106875 aux=0.572341 imp_cv2=1.0636 load_cv2=5.8341 usage_frac=0.3527 topk_prob_mean=0.3434 ema_alpha_reverse=nan max_logit=2.6997
step:257/1750 train_time:124448ms step_avg:484.23ms
[train step 257] avg_loss=4.976643 main=4.402600 aux=0.574043 imp_cv2=1.0802 load_cv2=5.8372 usage_frac=0.3482 topk_prob_mean=0.3515 ema_alpha_reverse=nan max_logit=2.7507
step:258/1750 train_time:124948ms step_avg:484.29ms
[train step 258] avg_loss=5.039218 main=4.470940 aux=0.568278 imp_cv2=1.0644 load_cv2=5.7869 usage_frac=0.3482 topk_prob_mean=0.3455 ema_alpha_reverse=nan max_logit=2.8035
step:259/1750 train_time:125436ms step_avg:484.31ms
[train step 259] avg_loss=4.764573 main=4.190611 aux=0.573962 imp_cv2=1.0713 load_cv2=5.8468 usage_frac=0.3482 topk_prob_mean=0.3458 ema_alpha_reverse=nan max_logit=2.8583
step:260/1750 train_time:125932ms step_avg:484.36ms
[train step 260] avg_loss=4.975387 main=4.399942 aux=0.575445 imp_cv2=1.0611 load_cv2=5.8702 usage_frac=0.3527 topk_prob_mean=0.3402 ema_alpha_reverse=nan max_logit=2.9150
step:261/1750 train_time:126438ms step_avg:484.44ms
[train step 261] avg_loss=4.758780 main=4.185032 aux=0.573748 imp_cv2=1.0749 load_cv2=5.8352 usage_frac=0.3527 topk_prob_mean=0.3474 ema_alpha_reverse=nan max_logit=2.9738
step:262/1750 train_time:126934ms step_avg:484.48ms
[train step 262] avg_loss=4.891198 main=4.312909 aux=0.578289 imp_cv2=1.0531 load_cv2=5.9113 usage_frac=0.3482 topk_prob_mean=0.3257 ema_alpha_reverse=nan max_logit=3.0348
step:263/1750 train_time:127439ms step_avg:484.56ms
[train step 263] avg_loss=4.995862 main=4.424588 aux=0.571274 imp_cv2=1.0503 load_cv2=5.8349 usage_frac=0.3527 topk_prob_mean=0.3320 ema_alpha_reverse=nan max_logit=3.0980
step:264/1750 train_time:127943ms step_avg:484.63ms
[train step 264] avg_loss=4.703120 main=4.135154 aux=0.567966 imp_cv2=1.0596 load_cv2=5.7834 usage_frac=0.3482 topk_prob_mean=0.3428 ema_alpha_reverse=nan max_logit=3.1636
step:265/1750 train_time:128437ms step_avg:484.67ms
[train step 265] avg_loss=4.786970 main=4.226204 aux=0.560766 imp_cv2=1.0608 load_cv2=5.6947 usage_frac=0.3482 topk_prob_mean=0.3431 ema_alpha_reverse=nan max_logit=3.2317
step:266/1750 train_time:128938ms step_avg:484.73ms
[train step 266] avg_loss=4.737800 main=4.167985 aux=0.569816 imp_cv2=1.0791 load_cv2=5.7901 usage_frac=0.3527 topk_prob_mean=0.3499 ema_alpha_reverse=nan max_logit=3.3024
step:267/1750 train_time:129432ms step_avg:484.76ms
[train step 267] avg_loss=4.910468 main=4.335581 aux=0.574887 imp_cv2=1.0735 load_cv2=5.8452 usage_frac=0.3482 topk_prob_mean=0.3458 ema_alpha_reverse=nan max_logit=3.3758
step:268/1750 train_time:129938ms step_avg:484.84ms
[train step 268] avg_loss=4.594192 main=4.020320 aux=0.573872 imp_cv2=1.0964 load_cv2=5.8124 usage_frac=0.3482 topk_prob_mean=0.3578 ema_alpha_reverse=nan max_logit=3.4520
step:269/1750 train_time:130436ms step_avg:484.89ms
[train step 269] avg_loss=4.646612 main=4.071712 aux=0.574900 imp_cv2=1.0769 load_cv2=5.8432 usage_frac=0.3482 topk_prob_mean=0.3479 ema_alpha_reverse=nan max_logit=3.5311
step:270/1750 train_time:130910ms step_avg:484.85ms
[train step 270] avg_loss=4.485049 main=3.903179 aux=0.581869 imp_cv2=1.0602 load_cv2=5.9406 usage_frac=0.3080 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=2.8391
step:271/1750 train_time:131394ms step_avg:484.85ms
[train step 271] avg_loss=4.835660 main=4.247633 aux=0.588028 imp_cv2=1.0569 load_cv2=6.0209 usage_frac=0.3438 topk_prob_mean=0.3269 ema_alpha_reverse=nan max_logit=3.6988
step:272/1750 train_time:131875ms step_avg:484.83ms
[train step 272] avg_loss=4.674153 main=4.097250 aux=0.576904 imp_cv2=1.0891 load_cv2=5.8540 usage_frac=0.3482 topk_prob_mean=0.3549 ema_alpha_reverse=nan max_logit=3.7877
step:273/1750 train_time:132388ms step_avg:484.94ms
[train step 273] avg_loss=4.843794 main=4.275961 aux=0.567832 imp_cv2=1.0769 load_cv2=5.7612 usage_frac=0.3571 topk_prob_mean=0.3546 ema_alpha_reverse=nan max_logit=3.8801
step:274/1750 train_time:132896ms step_avg:485.02ms
[train step 274] avg_loss=4.697633 main=4.136379 aux=0.561254 imp_cv2=1.0623 load_cv2=5.7039 usage_frac=0.3482 topk_prob_mean=0.3363 ema_alpha_reverse=nan max_logit=3.9762
step:275/1750 train_time:133411ms step_avg:485.13ms
[train step 275] avg_loss=4.822886 main=4.254191 aux=0.568695 imp_cv2=1.0601 load_cv2=5.7862 usage_frac=0.3482 topk_prob_mean=0.3450 ema_alpha_reverse=nan max_logit=4.0763
step:276/1750 train_time:133901ms step_avg:485.15ms
[train step 276] avg_loss=4.920099 main=4.343559 aux=0.576541 imp_cv2=1.0474 load_cv2=5.8968 usage_frac=0.3438 topk_prob_mean=0.3221 ema_alpha_reverse=nan max_logit=4.1804
step:277/1750 train_time:134406ms step_avg:485.22ms
[train step 277] avg_loss=4.613446 main=4.048788 aux=0.564658 imp_cv2=1.0729 load_cv2=5.7295 usage_frac=0.3705 topk_prob_mean=0.3525 ema_alpha_reverse=nan max_logit=4.2888
step:278/1750 train_time:134926ms step_avg:485.35ms
[train step 278] avg_loss=4.679322 main=4.108195 aux=0.571126 imp_cv2=1.0523 load_cv2=5.8247 usage_frac=0.3482 topk_prob_mean=0.3344 ema_alpha_reverse=nan max_logit=4.4017
step:279/1750 train_time:135406ms step_avg:485.32ms
[train step 279] avg_loss=4.759875 main=4.190254 aux=0.569621 imp_cv2=1.0686 load_cv2=5.7916 usage_frac=0.3482 topk_prob_mean=0.3516 ema_alpha_reverse=nan max_logit=4.5193
step:280/1750 train_time:135875ms step_avg:485.27ms
[train step 280] avg_loss=4.725976 main=4.145952 aux=0.580024 imp_cv2=1.0561 load_cv2=5.9286 usage_frac=0.3527 topk_prob_mean=0.3381 ema_alpha_reverse=nan max_logit=4.6419
step:281/1750 train_time:136359ms step_avg:485.26ms
[train step 281] avg_loss=4.793146 main=4.214318 aux=0.578829 imp_cv2=1.0634 load_cv2=5.9007 usage_frac=0.3527 topk_prob_mean=0.3436 ema_alpha_reverse=nan max_logit=4.7696
step:282/1750 train_time:136835ms step_avg:485.23ms
[train step 282] avg_loss=4.632309 main=4.052281 aux=0.580028 imp_cv2=1.0735 load_cv2=5.9037 usage_frac=0.3482 topk_prob_mean=0.3511 ema_alpha_reverse=nan max_logit=4.9029
step:283/1750 train_time:137318ms step_avg:485.22ms
[train step 283] avg_loss=4.634412 main=4.058179 aux=0.576233 imp_cv2=1.0544 load_cv2=5.8792 usage_frac=0.3482 topk_prob_mean=0.3369 ema_alpha_reverse=nan max_logit=5.0419
step:284/1750 train_time:137810ms step_avg:485.24ms
[train step 284] avg_loss=4.757829 main=4.181421 aux=0.576408 imp_cv2=1.0800 load_cv2=5.8552 usage_frac=0.3482 topk_prob_mean=0.3558 ema_alpha_reverse=nan max_logit=5.1869
step:285/1750 train_time:138293ms step_avg:485.24ms
[train step 285] avg_loss=4.787199 main=4.213244 aux=0.573954 imp_cv2=1.0668 load_cv2=5.8401 usage_frac=0.3527 topk_prob_mean=0.3496 ema_alpha_reverse=nan max_logit=5.3383
step:286/1750 train_time:138781ms step_avg:485.25ms
[train step 286] avg_loss=4.779520 main=4.208767 aux=0.570753 imp_cv2=1.0563 load_cv2=5.8137 usage_frac=0.3482 topk_prob_mean=0.3427 ema_alpha_reverse=nan max_logit=5.4964
step:287/1750 train_time:139265ms step_avg:485.24ms
[train step 287] avg_loss=4.631006 main=4.053534 aux=0.577473 imp_cv2=1.0781 load_cv2=5.8643 usage_frac=0.3527 topk_prob_mean=0.3518 ema_alpha_reverse=nan max_logit=5.6616
step:288/1750 train_time:139746ms step_avg:485.23ms
[train step 288] avg_loss=4.757914 main=4.181316 aux=0.576598 imp_cv2=1.0668 load_cv2=5.8729 usage_frac=0.3482 topk_prob_mean=0.3477 ema_alpha_reverse=nan max_logit=5.8341
step:289/1750 train_time:140230ms step_avg:485.23ms
[train step 289] avg_loss=4.608704 main=4.037589 aux=0.571116 imp_cv2=1.0812 load_cv2=5.7933 usage_frac=0.3482 topk_prob_mean=0.3556 ema_alpha_reverse=nan max_logit=6.0145
step:290/1750 train_time:140713ms step_avg:485.22ms
[train step 290] avg_loss=4.591627 main=4.020392 aux=0.571235 imp_cv2=1.0556 load_cv2=5.8199 usage_frac=0.3482 topk_prob_mean=0.3402 ema_alpha_reverse=nan max_logit=6.2031
step:291/1750 train_time:141217ms step_avg:485.28ms
[train step 291] avg_loss=4.738433 main=4.168592 aux=0.569841 imp_cv2=1.0722 load_cv2=5.7861 usage_frac=0.3527 topk_prob_mean=0.3514 ema_alpha_reverse=nan max_logit=6.4005
step:292/1750 train_time:141712ms step_avg:485.32ms
[train step 292] avg_loss=4.551923 main=3.981830 aux=0.570093 imp_cv2=1.0788 load_cv2=5.7791 usage_frac=0.3527 topk_prob_mean=0.3531 ema_alpha_reverse=nan max_logit=6.6070
step:293/1750 train_time:142203ms step_avg:485.33ms
[train step 293] avg_loss=4.533888 main=3.952012 aux=0.581875 imp_cv2=1.0610 load_cv2=5.9200 usage_frac=0.3125 topk_prob_mean=0.3142 ema_alpha_reverse=nan max_logit=5.3610
step:294/1750 train_time:142878ms step_avg:485.98ms
[train step 294] avg_loss=4.993428 main=4.419951 aux=0.573477 imp_cv2=1.0598 load_cv2=5.8417 usage_frac=0.3527 topk_prob_mean=0.3363 ema_alpha_reverse=nan max_logit=7.0495
step:295/1750 train_time:143366ms step_avg:485.99ms
[train step 295] avg_loss=4.820026 main=4.247595 aux=0.572431 imp_cv2=1.0615 load_cv2=5.8276 usage_frac=0.3482 topk_prob_mean=0.3426 ema_alpha_reverse=nan max_logit=7.2867
step:296/1750 train_time:143864ms step_avg:486.03ms
[train step 296] avg_loss=4.639076 main=4.071369 aux=0.567707 imp_cv2=1.0748 load_cv2=5.7541 usage_frac=0.3527 topk_prob_mean=0.3552 ema_alpha_reverse=nan max_logit=7.5353
step:297/1750 train_time:144364ms step_avg:486.07ms
[train step 297] avg_loss=4.722195 main=4.150700 aux=0.571496 imp_cv2=1.0708 load_cv2=5.8057 usage_frac=0.3482 topk_prob_mean=0.3495 ema_alpha_reverse=nan max_logit=7.7959
step:298/1750 train_time:144862ms step_avg:486.11ms
[train step 298] avg_loss=4.828170 main=4.259989 aux=0.568181 imp_cv2=1.0824 load_cv2=5.7469 usage_frac=0.3482 topk_prob_mean=0.3582 ema_alpha_reverse=nan max_logit=8.0693
step:299/1750 train_time:145358ms step_avg:486.15ms
[train step 299] avg_loss=4.560019 main=3.992120 aux=0.567899 imp_cv2=1.0609 load_cv2=5.7776 usage_frac=0.3482 topk_prob_mean=0.3474 ema_alpha_reverse=nan max_logit=8.3562
step:300/1750 train_time:145837ms step_avg:486.12ms
Running validation...
step:300/1750 val_loss:4.180922 train_time:145849ms step_avg:486.16ms
[train step 300] avg_loss=4.948392 main=4.380543 aux=0.567849 imp_cv2=1.0555 load_cv2=5.7786 usage_frac=0.3527 topk_prob_mean=0.3368 ema_alpha_reverse=nan max_logit=8.6573
step:301/1750 train_time:146325ms step_avg:486.13ms
[train step 301] avg_loss=4.880936 main=4.310772 aux=0.570164 imp_cv2=1.0683 load_cv2=5.7965 usage_frac=0.3527 topk_prob_mean=0.3496 ema_alpha_reverse=nan max_logit=8.9736
step:302/1750 train_time:146807ms step_avg:486.11ms
[train step 302] avg_loss=4.722832 main=4.151797 aux=0.571035 imp_cv2=1.0646 load_cv2=5.8126 usage_frac=0.3571 topk_prob_mean=0.3508 ema_alpha_reverse=nan max_logit=9.3058
step:303/1750 train_time:147319ms step_avg:486.20ms
[train step 303] avg_loss=4.712970 main=4.139844 aux=0.573126 imp_cv2=1.0669 load_cv2=5.8335 usage_frac=0.3527 topk_prob_mean=0.3477 ema_alpha_reverse=nan max_logit=9.6551
step:304/1750 train_time:147806ms step_avg:486.21ms
[train step 304] avg_loss=4.492249 main=3.918074 aux=0.574174 imp_cv2=1.0956 load_cv2=5.8194 usage_frac=0.3571 topk_prob_mean=0.3643 ema_alpha_reverse=nan max_logit=10.0223
step:305/1750 train_time:148303ms step_avg:486.24ms
[train step 305] avg_loss=4.659428 main=4.083369 aux=0.576060 imp_cv2=1.0705 load_cv2=5.8614 usage_frac=0.3482 topk_prob_mean=0.3497 ema_alpha_reverse=nan max_logit=10.4087
step:306/1750 train_time:148787ms step_avg:486.23ms
[train step 306] avg_loss=5.010439 main=4.449133 aux=0.561306 imp_cv2=1.0696 load_cv2=5.6846 usage_frac=0.3571 topk_prob_mean=0.3569 ema_alpha_reverse=nan max_logit=10.8153
step:307/1750 train_time:149282ms step_avg:486.26ms
[train step 307] avg_loss=5.204682 main=4.626368 aux=0.578314 imp_cv2=1.0646 load_cv2=5.8905 usage_frac=0.3482 topk_prob_mean=0.3473 ema_alpha_reverse=nan max_logit=11.2434
step:308/1750 train_time:149771ms step_avg:486.27ms
[train step 308] avg_loss=4.231217 main=3.645497 aux=0.585720 imp_cv2=1.0560 load_cv2=5.9907 usage_frac=0.3438 topk_prob_mean=0.3291 ema_alpha_reverse=nan max_logit=11.6943
step:309/1750 train_time:150239ms step_avg:486.21ms
[train step 309] avg_loss=4.671515 main=4.088050 aux=0.583465 imp_cv2=1.0500 load_cv2=5.9774 usage_frac=0.3438 topk_prob_mean=0.3260 ema_alpha_reverse=nan max_logit=12.1696
step:310/1750 train_time:150703ms step_avg:486.14ms
[train step 310] avg_loss=4.560904 main=3.990840 aux=0.570064 imp_cv2=1.0879 load_cv2=5.7681 usage_frac=0.3482 topk_prob_mean=0.3638 ema_alpha_reverse=nan max_logit=12.6707
step:311/1750 train_time:151197ms step_avg:486.16ms
[train step 311] avg_loss=4.681336 main=4.112419 aux=0.568918 imp_cv2=1.0660 load_cv2=5.7779 usage_frac=0.3527 topk_prob_mean=0.3501 ema_alpha_reverse=nan max_logit=13.1992
step:312/1750 train_time:151686ms step_avg:486.17ms
[train step 312] avg_loss=4.671974 main=4.103697 aux=0.568277 imp_cv2=1.0648 load_cv2=5.7766 usage_frac=0.3438 topk_prob_mean=0.3523 ema_alpha_reverse=nan max_logit=13.7570
step:313/1750 train_time:152198ms step_avg:486.26ms
[train step 313] avg_loss=4.609627 main=4.044304 aux=0.565323 imp_cv2=1.0581 load_cv2=5.7459 usage_frac=0.3438 topk_prob_mean=0.3487 ema_alpha_reverse=nan max_logit=13.7570
step:314/1750 train_time:152849ms step_avg:486.78ms
[train step 314] avg_loss=4.492935 main=3.923663 aux=0.569272 imp_cv2=1.0580 load_cv2=5.7912 usage_frac=0.3393 topk_prob_mean=0.3485 ema_alpha_reverse=nan max_logit=13.7570
step:315/1750 train_time:153331ms step_avg:486.77ms
[train step 315] avg_loss=4.962876 main=4.390386 aux=0.572491 imp_cv2=1.0507 load_cv2=5.8309 usage_frac=0.3393 topk_prob_mean=0.3436 ema_alpha_reverse=nan max_logit=13.7570
step:316/1750 train_time:153834ms step_avg:486.82ms
[train step 316] avg_loss=4.599620 main=4.039139 aux=0.560480 imp_cv2=1.0632 load_cv2=5.6770 usage_frac=0.3438 topk_prob_mean=0.3553 ema_alpha_reverse=nan max_logit=13.7404
step:317/1750 train_time:154333ms step_avg:486.86ms
[train step 317] avg_loss=4.507556 main=3.949646 aux=0.557910 imp_cv2=1.0968 load_cv2=5.6067 usage_frac=0.3616 topk_prob_mean=0.3778 ema_alpha_reverse=nan max_logit=13.7570
step:318/1750 train_time:154829ms step_avg:486.88ms
[train step 318] avg_loss=4.902177 main=4.327388 aux=0.574788 imp_cv2=1.1125 load_cv2=5.7961 usage_frac=0.3438 topk_prob_mean=0.3779 ema_alpha_reverse=nan max_logit=13.7570
step:319/1750 train_time:155332ms step_avg:486.93ms
[train step 319] avg_loss=4.577554 main=4.007652 aux=0.569902 imp_cv2=1.1080 load_cv2=5.7365 usage_frac=0.3438 topk_prob_mean=0.3771 ema_alpha_reverse=nan max_logit=13.7570
step:320/1750 train_time:155826ms step_avg:486.96ms
[train step 320] avg_loss=4.509428 main=3.938779 aux=0.570649 imp_cv2=1.0720 load_cv2=5.7862 usage_frac=0.3482 topk_prob_mean=0.3585 ema_alpha_reverse=nan max_logit=13.7570
step:321/1750 train_time:156331ms step_avg:487.01ms
[train step 321] avg_loss=4.763406 main=4.196525 aux=0.566881 imp_cv2=1.0819 load_cv2=5.7325 usage_frac=0.3438 topk_prob_mean=0.3630 ema_alpha_reverse=nan max_logit=13.7570
step:322/1750 train_time:156810ms step_avg:486.99ms
[train step 322] avg_loss=4.536086 main=3.971143 aux=0.564943 imp_cv2=1.0704 load_cv2=5.7198 usage_frac=0.3393 topk_prob_mean=0.3599 ema_alpha_reverse=nan max_logit=13.7570
step:323/1750 train_time:157297ms step_avg:486.99ms
[train step 323] avg_loss=4.879542 main=4.303491 aux=0.576052 imp_cv2=1.0733 load_cv2=5.8633 usage_frac=0.3036 topk_prob_mean=0.3246 ema_alpha_reverse=nan max_logit=10.8345
step:324/1750 train_time:157780ms step_avg:486.97ms
[train step 324] avg_loss=4.718020 main=4.148499 aux=0.569522 imp_cv2=1.0615 load_cv2=5.7865 usage_frac=0.3438 topk_prob_mean=0.3486 ema_alpha_reverse=nan max_logit=13.6651
step:325/1750 train_time:158251ms step_avg:486.93ms
[train step 325] avg_loss=4.436993 main=3.878542 aux=0.558452 imp_cv2=1.0831 load_cv2=5.6269 usage_frac=0.3438 topk_prob_mean=0.3654 ema_alpha_reverse=nan max_logit=13.5608
step:326/1750 train_time:158966ms step_avg:487.63ms
[train step 326] avg_loss=4.617751 main=4.063721 aux=0.554030 imp_cv2=1.0949 load_cv2=5.5633 usage_frac=0.3393 topk_prob_mean=0.3710 ema_alpha_reverse=nan max_logit=13.7570
step:327/1750 train_time:159463ms step_avg:487.65ms
[train step 327] avg_loss=4.598964 main=4.042167 aux=0.556797 imp_cv2=1.0791 load_cv2=5.6111 usage_frac=0.3438 topk_prob_mean=0.3627 ema_alpha_reverse=nan max_logit=13.4549
step:328/1750 train_time:159945ms step_avg:487.64ms
[train step 328] avg_loss=4.753942 main=4.197299 aux=0.556643 imp_cv2=1.0782 load_cv2=5.6077 usage_frac=0.3348 topk_prob_mean=0.3568 ema_alpha_reverse=nan max_logit=13.7570
step:329/1750 train_time:160434ms step_avg:487.64ms
[train step 329] avg_loss=4.606608 main=4.035371 aux=0.571237 imp_cv2=1.0876 load_cv2=5.7668 usage_frac=0.3438 topk_prob_mean=0.3426 ema_alpha_reverse=nan max_logit=13.7570
step:330/1750 train_time:161114ms step_avg:488.23ms
[train step 330] avg_loss=4.485249 main=3.926609 aux=0.558640 imp_cv2=1.1073 load_cv2=5.5970 usage_frac=0.3393 topk_prob_mean=0.3759 ema_alpha_reverse=nan max_logit=13.7570
step:331/1750 train_time:161598ms step_avg:488.21ms
[train step 331] avg_loss=4.504618 main=3.945789 aux=0.558829 imp_cv2=1.1225 load_cv2=5.5842 usage_frac=0.3438 topk_prob_mean=0.3816 ema_alpha_reverse=nan max_logit=13.7570
step:332/1750 train_time:162065ms step_avg:488.15ms
[train step 332] avg_loss=4.616081 main=4.061884 aux=0.554196 imp_cv2=1.0857 load_cv2=5.5639 usage_frac=0.3482 topk_prob_mean=0.3684 ema_alpha_reverse=nan max_logit=13.7570
step:333/1750 train_time:162568ms step_avg:488.19ms
[train step 333] avg_loss=4.656656 main=4.094499 aux=0.562157 imp_cv2=1.0794 load_cv2=5.6638 usage_frac=0.3438 topk_prob_mean=0.3616 ema_alpha_reverse=nan max_logit=13.7570
step:334/1750 train_time:163049ms step_avg:488.17ms
[train step 334] avg_loss=4.587150 main=4.024160 aux=0.562990 imp_cv2=1.0895 load_cv2=5.6660 usage_frac=0.3393 topk_prob_mean=0.3659 ema_alpha_reverse=nan max_logit=13.7570
step:335/1750 train_time:163567ms step_avg:488.26ms
[train step 335] avg_loss=4.381262 main=3.825106 aux=0.556156 imp_cv2=1.1722 load_cv2=5.4991 usage_frac=0.3482 topk_prob_mean=0.4015 ema_alpha_reverse=nan max_logit=13.1916
step:336/1750 train_time:164081ms step_avg:488.34ms
[train step 336] avg_loss=3.958880 main=3.400431 aux=0.558449 imp_cv2=1.2592 load_cv2=5.4170 usage_frac=0.3438 topk_prob_mean=0.3747 ema_alpha_reverse=nan max_logit=9.6345
step:337/1750 train_time:164565ms step_avg:488.32ms
[train step 337] avg_loss=4.475720 main=3.904096 aux=0.571624 imp_cv2=1.0594 load_cv2=5.8143 usage_frac=0.3393 topk_prob_mean=0.3303 ema_alpha_reverse=nan max_logit=13.7570
step:338/1750 train_time:165242ms step_avg:488.88ms
[train step 338] avg_loss=5.049633 main=4.265406 aux=0.784226 imp_cv2=4.3693 load_cv2=4.8822 usage_frac=0.4554 topk_prob_mean=0.9068 ema_alpha_reverse=nan max_logit=13.7570
step:339/1750 train_time:165830ms step_avg:489.17ms
[train step 339] avg_loss=4.771208 main=4.344114 aux=0.427094 imp_cv2=1.5545 load_cv2=3.5341 usage_frac=0.4598 topk_prob_mean=0.5493 ema_alpha_reverse=nan max_logit=13.7570
step:340/1750 train_time:166467ms step_avg:489.61ms
[train step 340] avg_loss=5.183238 main=4.641832 aux=0.541405 imp_cv2=0.9573 load_cv2=5.5031 usage_frac=0.4196 topk_prob_mean=0.3482 ema_alpha_reverse=nan max_logit=13.7570
step:341/1750 train_time:167208ms step_avg:490.35ms
[train step 341] avg_loss=4.626720 main=4.106632 aux=0.520088 imp_cv2=0.8689 load_cv2=5.3123 usage_frac=0.3973 topk_prob_mean=0.3742 ema_alpha_reverse=nan max_logit=13.2605
step:342/1750 train_time:167731ms step_avg:490.44ms
[train step 342] avg_loss=4.423350 main=3.905434 aux=0.517916 imp_cv2=0.7741 load_cv2=5.3986 usage_frac=0.3839 topk_prob_mean=0.3405 ema_alpha_reverse=nan max_logit=13.7570
step:343/1750 train_time:168271ms step_avg:490.59ms
[train step 343] avg_loss=4.913490 main=4.405610 aux=0.507880 imp_cv2=0.7039 load_cv2=5.3239 usage_frac=0.3795 topk_prob_mean=0.3416 ema_alpha_reverse=nan max_logit=13.4124
step:344/1750 train_time:168811ms step_avg:490.73ms
[train step 344] avg_loss=4.712406 main=4.193628 aux=0.518778 imp_cv2=0.6702 load_cv2=5.4857 usage_frac=0.3616 topk_prob_mean=0.3095 ema_alpha_reverse=nan max_logit=12.8153
step:345/1750 train_time:169350ms step_avg:490.87ms
[train step 345] avg_loss=4.246311 main=3.735564 aux=0.510748 imp_cv2=0.6943 load_cv2=5.3736 usage_frac=0.3705 topk_prob_mean=0.3314 ema_alpha_reverse=nan max_logit=13.7570
step:346/1750 train_time:169877ms step_avg:490.97ms
[train step 346] avg_loss=4.613046 main=4.098986 aux=0.514060 imp_cv2=0.6934 load_cv2=5.4224 usage_frac=0.3839 topk_prob_mean=0.3291 ema_alpha_reverse=nan max_logit=13.7570
step:347/1750 train_time:170407ms step_avg:491.09ms
[train step 347] avg_loss=4.379558 main=3.859241 aux=0.520317 imp_cv2=0.8156 load_cv2=5.3666 usage_frac=0.3839 topk_prob_mean=0.3598 ema_alpha_reverse=nan max_logit=13.7570
step:348/1750 train_time:170927ms step_avg:491.17ms
[train step 348] avg_loss=4.382861 main=3.866168 aux=0.516693 imp_cv2=0.6932 load_cv2=5.4577 usage_frac=0.3795 topk_prob_mean=0.3289 ema_alpha_reverse=nan max_logit=13.7570
step:349/1750 train_time:171440ms step_avg:491.23ms
[train step 349] avg_loss=4.749538 main=4.229502 aux=0.520035 imp_cv2=0.6568 load_cv2=5.5331 usage_frac=0.3705 topk_prob_mean=0.3111 ema_alpha_reverse=nan max_logit=13.7570
step:350/1750 train_time:171952ms step_avg:491.29ms
Running validation...
step:350/1750 val_loss:4.062872 train_time:171964ms step_avg:491.32ms
[train step 350] avg_loss=4.574888 main=4.047490 aux=0.527398 imp_cv2=0.6609 load_cv2=5.6226 usage_frac=0.3661 topk_prob_mean=0.3093 ema_alpha_reverse=nan max_logit=13.7570
step:351/1750 train_time:172462ms step_avg:491.35ms
[train step 351] avg_loss=4.573733 main=4.061852 aux=0.511881 imp_cv2=0.6660 load_cv2=5.4254 usage_frac=0.3705 topk_prob_mean=0.3195 ema_alpha_reverse=nan max_logit=13.7570
step:352/1750 train_time:172971ms step_avg:491.40ms
[train step 352] avg_loss=4.438902 main=3.922245 aux=0.516656 imp_cv2=0.6894 load_cv2=5.4556 usage_frac=0.3705 topk_prob_mean=0.3285 ema_alpha_reverse=nan max_logit=13.7570
step:353/1750 train_time:173476ms step_avg:491.43ms
[train step 353] avg_loss=4.338102 main=3.823011 aux=0.515091 imp_cv2=0.7073 load_cv2=5.4210 usage_frac=0.3750 topk_prob_mean=0.3372 ema_alpha_reverse=nan max_logit=13.7570
step:354/1750 train_time:173981ms step_avg:491.47ms
[train step 354] avg_loss=4.630105 main=4.112867 aux=0.517238 imp_cv2=0.6991 load_cv2=5.4561 usage_frac=0.3750 topk_prob_mean=0.3365 ema_alpha_reverse=nan max_logit=13.7570
step:355/1750 train_time:174493ms step_avg:491.53ms
[train step 355] avg_loss=4.770312 main=4.255047 aux=0.515265 imp_cv2=0.6685 load_cv2=5.4631 usage_frac=0.3750 topk_prob_mean=0.3224 ema_alpha_reverse=nan max_logit=13.7570
step:356/1750 train_time:174979ms step_avg:491.51ms
[train step 356] avg_loss=4.325537 main=3.811366 aux=0.514171 imp_cv2=0.6731 load_cv2=5.4413 usage_frac=0.3661 topk_prob_mean=0.3220 ema_alpha_reverse=nan max_logit=13.7570
step:357/1750 train_time:175480ms step_avg:491.54ms
[train step 357] avg_loss=4.663672 main=4.154823 aux=0.508849 imp_cv2=0.6853 load_cv2=5.3763 usage_frac=0.3571 topk_prob_mean=0.3208 ema_alpha_reverse=nan max_logit=13.7570
step:358/1750 train_time:175974ms step_avg:491.55ms
[train step 358] avg_loss=4.981501 main=4.475906 aux=0.505595 imp_cv2=0.6811 load_cv2=5.3349 usage_frac=0.3661 topk_prob_mean=0.3174 ema_alpha_reverse=nan max_logit=13.7570
step:359/1750 train_time:176457ms step_avg:491.52ms
[train step 359] avg_loss=4.797644 main=4.269796 aux=0.527847 imp_cv2=0.6628 load_cv2=5.6083 usage_frac=0.3438 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=12.7744
step:360/1750 train_time:176973ms step_avg:491.59ms
[train step 360] avg_loss=4.416905 main=3.907900 aux=0.509005 imp_cv2=0.7548 load_cv2=5.2893 usage_frac=0.3750 topk_prob_mean=0.3469 ema_alpha_reverse=nan max_logit=13.7570
step:361/1750 train_time:177477ms step_avg:491.63ms
[train step 361] avg_loss=4.858687 main=4.342230 aux=0.516457 imp_cv2=0.6631 load_cv2=5.4904 usage_frac=0.3661 topk_prob_mean=0.3068 ema_alpha_reverse=nan max_logit=13.7570
step:362/1750 train_time:178006ms step_avg:491.73ms
[train step 362] avg_loss=4.851694 main=4.341688 aux=0.510007 imp_cv2=0.6747 load_cv2=5.3956 usage_frac=0.3750 topk_prob_mean=0.3174 ema_alpha_reverse=nan max_logit=13.7570
step:363/1750 train_time:178520ms step_avg:491.79ms
[train step 363] avg_loss=4.559598 main=4.042694 aux=0.516904 imp_cv2=0.6691 load_cv2=5.4896 usage_frac=0.3705 topk_prob_mean=0.3127 ema_alpha_reverse=nan max_logit=13.7570
step:364/1750 train_time:179030ms step_avg:491.84ms
[train step 364] avg_loss=5.000498 main=4.484684 aux=0.515813 imp_cv2=0.6752 load_cv2=5.4588 usage_frac=0.3661 topk_prob_mean=0.3149 ema_alpha_reverse=nan max_logit=13.2376
step:365/1750 train_time:179565ms step_avg:491.96ms
[train step 365] avg_loss=4.647959 main=4.136146 aux=0.511813 imp_cv2=0.6869 load_cv2=5.4119 usage_frac=0.3750 topk_prob_mean=0.3185 ema_alpha_reverse=nan max_logit=13.7570
step:366/1750 train_time:180072ms step_avg:492.00ms
[train step 366] avg_loss=4.405568 main=3.875475 aux=0.530092 imp_cv2=0.7399 load_cv2=5.5900 usage_frac=0.3616 topk_prob_mean=0.3117 ema_alpha_reverse=nan max_logit=13.7570
step:367/1750 train_time:180584ms step_avg:492.06ms
[train step 367] avg_loss=4.801212 main=4.282522 aux=0.518690 imp_cv2=0.6752 load_cv2=5.4885 usage_frac=0.3750 topk_prob_mean=0.3167 ema_alpha_reverse=nan max_logit=13.7570
step:368/1750 train_time:181104ms step_avg:492.13ms
[train step 368] avg_loss=4.734327 main=4.212337 aux=0.521989 imp_cv2=0.6798 load_cv2=5.5300 usage_frac=0.3750 topk_prob_mean=0.3190 ema_alpha_reverse=nan max_logit=13.3946
step:369/1750 train_time:181598ms step_avg:492.14ms
[train step 369] avg_loss=4.177461 main=3.657682 aux=0.519780 imp_cv2=0.7212 load_cv2=5.4591 usage_frac=0.3795 topk_prob_mean=0.3321 ema_alpha_reverse=nan max_logit=13.7570
step:370/1750 train_time:182107ms step_avg:492.18ms
[train step 370] avg_loss=4.431272 main=3.909278 aux=0.521994 imp_cv2=0.7113 load_cv2=5.5004 usage_frac=0.3839 topk_prob_mean=0.3312 ema_alpha_reverse=nan max_logit=13.3336
step:371/1750 train_time:182592ms step_avg:492.16ms
[train step 371] avg_loss=4.293824 main=3.766713 aux=0.527111 imp_cv2=0.6771 load_cv2=5.6010 usage_frac=0.3705 topk_prob_mean=0.3123 ema_alpha_reverse=nan max_logit=12.7744
step:372/1750 train_time:183085ms step_avg:492.17ms
[train step 372] avg_loss=4.481161 main=3.957978 aux=0.523183 imp_cv2=0.6928 load_cv2=5.5362 usage_frac=0.3795 topk_prob_mean=0.3242 ema_alpha_reverse=nan max_logit=13.6668
step:373/1750 train_time:183586ms step_avg:492.19ms
[train step 373] avg_loss=4.935743 main=4.401792 aux=0.533951 imp_cv2=0.6675 load_cv2=5.6781 usage_frac=0.3884 topk_prob_mean=0.3052 ema_alpha_reverse=nan max_logit=12.7744
step:374/1750 train_time:184078ms step_avg:492.19ms
[train step 374] avg_loss=4.328823 main=3.795567 aux=0.533256 imp_cv2=0.6711 load_cv2=5.6693 usage_frac=0.3661 topk_prob_mean=0.3160 ema_alpha_reverse=nan max_logit=12.7744
step:375/1750 train_time:184571ms step_avg:492.19ms
[train step 375] avg_loss=4.424000 main=3.901923 aux=0.522077 imp_cv2=0.6737 load_cv2=5.5333 usage_frac=0.3795 topk_prob_mean=0.3206 ema_alpha_reverse=nan max_logit=12.7744
step:376/1750 train_time:185062ms step_avg:492.19ms
[train step 376] avg_loss=4.419316 main=3.904175 aux=0.515141 imp_cv2=0.7394 load_cv2=5.3818 usage_frac=0.3750 topk_prob_mean=0.3520 ema_alpha_reverse=nan max_logit=13.0041
step:377/1750 train_time:185565ms step_avg:492.21ms
[train step 377] avg_loss=4.981763 main=4.431318 aux=0.550445 imp_cv2=0.6694 load_cv2=5.8536 usage_frac=0.3304 topk_prob_mean=0.2774 ema_alpha_reverse=nan max_logit=10.0752
step:378/1750 train_time:186060ms step_avg:492.22ms
[train step 378] avg_loss=4.502498 main=3.980024 aux=0.522474 imp_cv2=0.6780 load_cv2=5.5337 usage_frac=0.3795 topk_prob_mean=0.3254 ema_alpha_reverse=nan max_logit=12.7744
step:379/1750 train_time:186570ms step_avg:492.27ms
[train step 379] avg_loss=4.497006 main=3.970671 aux=0.526336 imp_cv2=0.6838 load_cv2=5.5739 usage_frac=0.3884 topk_prob_mean=0.3283 ema_alpha_reverse=nan max_logit=13.7570
step:380/1750 train_time:187050ms step_avg:492.24ms
[train step 380] avg_loss=4.519430 main=3.995223 aux=0.524207 imp_cv2=0.6851 load_cv2=5.5340 usage_frac=0.3839 topk_prob_mean=0.3339 ema_alpha_reverse=nan max_logit=12.7744
step:381/1750 train_time:187561ms step_avg:492.29ms
[train step 381] avg_loss=4.326968 main=3.792618 aux=0.534350 imp_cv2=0.6889 load_cv2=5.6571 usage_frac=0.3705 topk_prob_mean=0.3252 ema_alpha_reverse=nan max_logit=12.7744
step:382/1750 train_time:188061ms step_avg:492.31ms
[train step 382] avg_loss=4.427417 main=3.901614 aux=0.525802 imp_cv2=0.6907 load_cv2=5.5482 usage_frac=0.3616 topk_prob_mean=0.3287 ema_alpha_reverse=nan max_logit=12.7744
step:383/1750 train_time:188549ms step_avg:492.30ms
[train step 383] avg_loss=4.478456 main=3.955182 aux=0.523274 imp_cv2=0.6876 load_cv2=5.5131 usage_frac=0.3884 topk_prob_mean=0.3268 ema_alpha_reverse=nan max_logit=13.7570
step:384/1750 train_time:189029ms step_avg:492.26ms
[train step 384] avg_loss=4.440842 main=3.907619 aux=0.533223 imp_cv2=0.6611 load_cv2=5.6708 usage_frac=0.3661 topk_prob_mean=0.3079 ema_alpha_reverse=nan max_logit=12.7744
step:385/1750 train_time:189531ms step_avg:492.29ms
[train step 385] avg_loss=4.377297 main=3.844074 aux=0.533223 imp_cv2=0.7234 load_cv2=5.6110 usage_frac=0.3839 topk_prob_mean=0.3297 ema_alpha_reverse=nan max_logit=13.7570
step:386/1750 train_time:190027ms step_avg:492.30ms
[train step 386] avg_loss=4.779696 main=4.251321 aux=0.528375 imp_cv2=0.6503 load_cv2=5.6274 usage_frac=0.3750 topk_prob_mean=0.3027 ema_alpha_reverse=nan max_logit=13.7570
step:387/1750 train_time:190510ms step_avg:492.27ms
[train step 387] avg_loss=4.321398 main=3.791298 aux=0.530100 imp_cv2=0.6569 load_cv2=5.6396 usage_frac=0.3705 topk_prob_mean=0.3060 ema_alpha_reverse=nan max_logit=13.7570
step:388/1750 train_time:191009ms step_avg:492.29ms
[train step 388] avg_loss=4.123822 main=3.595803 aux=0.528019 imp_cv2=0.6559 load_cv2=5.6023 usage_frac=0.3661 topk_prob_mean=0.2998 ema_alpha_reverse=nan max_logit=13.5276
step:389/1750 train_time:191491ms step_avg:492.26ms
[train step 389] avg_loss=4.368243 main=3.834368 aux=0.533874 imp_cv2=0.7022 load_cv2=5.6353 usage_frac=0.3750 topk_prob_mean=0.3248 ema_alpha_reverse=nan max_logit=13.7570
step:390/1750 train_time:191974ms step_avg:492.24ms
[train step 390] avg_loss=4.448060 main=3.911814 aux=0.536246 imp_cv2=0.6738 load_cv2=5.6916 usage_frac=0.3705 topk_prob_mean=0.3106 ema_alpha_reverse=nan max_logit=13.7570
step:391/1750 train_time:192444ms step_avg:492.18ms
[train step 391] avg_loss=4.301750 main=3.759710 aux=0.542040 imp_cv2=0.6516 load_cv2=5.7954 usage_frac=0.3527 topk_prob_mean=0.2918 ema_alpha_reverse=nan max_logit=13.7436
step:392/1750 train_time:192920ms step_avg:492.14ms
[train step 392] avg_loss=4.296553 main=3.763579 aux=0.532974 imp_cv2=0.6495 load_cv2=5.6880 usage_frac=0.3571 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=13.5520
step:393/1750 train_time:193405ms step_avg:492.13ms
[train step 393] avg_loss=4.631396 main=4.110047 aux=0.521349 imp_cv2=0.6743 load_cv2=5.5153 usage_frac=0.3616 topk_prob_mean=0.3169 ema_alpha_reverse=nan max_logit=13.7570
step:394/1750 train_time:193887ms step_avg:492.10ms
[train step 394] avg_loss=4.364874 main=3.836735 aux=0.528139 imp_cv2=0.7399 load_cv2=5.5216 usage_frac=0.3616 topk_prob_mean=0.3381 ema_alpha_reverse=nan max_logit=13.6225
step:395/1750 train_time:194385ms step_avg:492.11ms
[train step 395] avg_loss=4.329551 main=3.797633 aux=0.531917 imp_cv2=0.6888 load_cv2=5.6217 usage_frac=0.3616 topk_prob_mean=0.3186 ema_alpha_reverse=nan max_logit=13.7570
step:396/1750 train_time:194870ms step_avg:492.10ms
[train step 396] avg_loss=4.479498 main=3.952104 aux=0.527394 imp_cv2=0.7187 load_cv2=5.5357 usage_frac=0.3661 topk_prob_mean=0.3318 ema_alpha_reverse=nan max_logit=13.1909
step:397/1750 train_time:195360ms step_avg:492.09ms
[train step 397] avg_loss=4.477244 main=3.948972 aux=0.528272 imp_cv2=0.6557 load_cv2=5.6184 usage_frac=0.3571 topk_prob_mean=0.3033 ema_alpha_reverse=nan max_logit=13.7570
step:398/1750 train_time:195839ms step_avg:492.06ms
[train step 398] avg_loss=4.013775 main=3.488619 aux=0.525156 imp_cv2=0.6801 load_cv2=5.5461 usage_frac=0.3571 topk_prob_mean=0.3206 ema_alpha_reverse=nan max_logit=12.9042
step:399/1750 train_time:196336ms step_avg:492.07ms
[train step 399] avg_loss=4.480981 main=3.953252 aux=0.527729 imp_cv2=0.6533 load_cv2=5.6132 usage_frac=0.3571 topk_prob_mean=0.3011 ema_alpha_reverse=nan max_logit=13.7570
step:400/1750 train_time:196821ms step_avg:492.05ms
Running validation...
step:400/1750 val_loss:3.977363 train_time:196833ms step_avg:492.08ms
[train step 400] avg_loss=4.413880 main=3.880481 aux=0.533399 imp_cv2=0.6690 load_cv2=5.6410 usage_frac=0.3438 topk_prob_mean=0.2951 ema_alpha_reverse=nan max_logit=13.7570
step:401/1750 train_time:197310ms step_avg:492.05ms
[train step 401] avg_loss=4.407381 main=3.887614 aux=0.519766 imp_cv2=0.6606 load_cv2=5.4932 usage_frac=0.3616 topk_prob_mean=0.3019 ema_alpha_reverse=nan max_logit=13.7570
step:402/1750 train_time:197807ms step_avg:492.06ms
[train step 402] avg_loss=4.738107 main=4.205591 aux=0.532515 imp_cv2=0.6808 load_cv2=5.6195 usage_frac=0.3080 topk_prob_mean=0.2915 ema_alpha_reverse=nan max_logit=10.0861
step:403/1750 train_time:198278ms step_avg:492.00ms
[train step 403] avg_loss=4.449126 main=3.923241 aux=0.525885 imp_cv2=0.6506 load_cv2=5.5825 usage_frac=0.3571 topk_prob_mean=0.3044 ema_alpha_reverse=nan max_logit=13.4940
step:404/1750 train_time:198751ms step_avg:491.96ms
[train step 404] avg_loss=4.167401 main=3.633516 aux=0.533885 imp_cv2=0.7390 load_cv2=5.5889 usage_frac=0.3527 topk_prob_mean=0.3365 ema_alpha_reverse=nan max_logit=13.7570
step:405/1750 train_time:199240ms step_avg:491.95ms
[train step 405] avg_loss=4.331986 main=3.790451 aux=0.541535 imp_cv2=0.6915 load_cv2=5.7284 usage_frac=0.3616 topk_prob_mean=0.3145 ema_alpha_reverse=nan max_logit=13.6618
step:406/1750 train_time:199726ms step_avg:491.94ms
[train step 406] avg_loss=4.672637 main=4.135430 aux=0.537207 imp_cv2=0.6842 load_cv2=5.6779 usage_frac=0.3393 topk_prob_mean=0.2905 ema_alpha_reverse=nan max_logit=11.8155
step:407/1750 train_time:200191ms step_avg:491.87ms
[train step 407] avg_loss=4.105063 main=3.568985 aux=0.536078 imp_cv2=0.6582 load_cv2=5.6926 usage_frac=0.3482 topk_prob_mean=0.2819 ema_alpha_reverse=nan max_logit=12.7744
step:408/1750 train_time:200680ms step_avg:491.86ms
[train step 408] avg_loss=4.534722 main=3.998902 aux=0.535820 imp_cv2=0.6968 load_cv2=5.6499 usage_frac=0.3527 topk_prob_mean=0.3178 ema_alpha_reverse=nan max_logit=13.3863
step:409/1750 train_time:201159ms step_avg:491.83ms
[train step 409] avg_loss=4.340813 main=3.802163 aux=0.538650 imp_cv2=0.6436 load_cv2=5.7445 usage_frac=0.3482 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=13.0160
step:410/1750 train_time:201652ms step_avg:491.83ms
[train step 410] avg_loss=4.534336 main=4.001102 aux=0.533233 imp_cv2=0.6878 load_cv2=5.6314 usage_frac=0.3571 topk_prob_mean=0.3161 ema_alpha_reverse=nan max_logit=13.6575
step:411/1750 train_time:202139ms step_avg:491.82ms
[train step 411] avg_loss=6.060809 main=5.518046 aux=0.542763 imp_cv2=0.6494 load_cv2=5.7848 usage_frac=0.3527 topk_prob_mean=0.2836 ema_alpha_reverse=nan max_logit=12.7744
step:412/1750 train_time:202615ms step_avg:491.78ms
[train step 412] avg_loss=4.440967 main=3.905308 aux=0.535659 imp_cv2=0.7108 load_cv2=5.6322 usage_frac=0.3571 topk_prob_mean=0.3262 ema_alpha_reverse=nan max_logit=13.6833
step:413/1750 train_time:203088ms step_avg:491.74ms
[train step 413] avg_loss=4.459585 main=3.923567 aux=0.536018 imp_cv2=0.7262 load_cv2=5.6114 usage_frac=0.3571 topk_prob_mean=0.3319 ema_alpha_reverse=nan max_logit=12.7744
step:414/1750 train_time:203576ms step_avg:491.73ms
[train step 414] avg_loss=4.155101 main=3.609847 aux=0.545254 imp_cv2=0.6396 load_cv2=5.8187 usage_frac=0.3259 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=9.9737
step:415/1750 train_time:204069ms step_avg:491.73ms
[train step 415] avg_loss=4.777483 main=4.245342 aux=0.532141 imp_cv2=0.6913 load_cv2=5.6142 usage_frac=0.3750 topk_prob_mean=0.3280 ema_alpha_reverse=nan max_logit=13.7570
step:416/1750 train_time:204580ms step_avg:491.78ms
[train step 416] avg_loss=4.274824 main=3.737874 aux=0.536950 imp_cv2=0.6755 load_cv2=5.6924 usage_frac=0.3527 topk_prob_mean=0.3176 ema_alpha_reverse=nan max_logit=13.1884
step:417/1750 train_time:205058ms step_avg:491.75ms
[train step 417] avg_loss=4.790392 main=4.240859 aux=0.549534 imp_cv2=0.6632 load_cv2=5.8478 usage_frac=0.3170 topk_prob_mean=0.2758 ema_alpha_reverse=nan max_logit=10.4876
step:418/1750 train_time:205530ms step_avg:491.70ms
[train step 418] avg_loss=4.278886 main=3.747434 aux=0.531452 imp_cv2=0.7487 load_cv2=5.5491 usage_frac=0.3616 topk_prob_mean=0.3462 ema_alpha_reverse=nan max_logit=13.0685
step:419/1750 train_time:206014ms step_avg:491.68ms
[train step 419] avg_loss=4.370545 main=3.824699 aux=0.545846 imp_cv2=0.6757 load_cv2=5.7942 usage_frac=0.3571 topk_prob_mean=0.2920 ema_alpha_reverse=nan max_logit=12.4979
step:420/1750 train_time:206481ms step_avg:491.62ms
[train step 420] avg_loss=4.565030 main=4.022408 aux=0.542622 imp_cv2=0.7572 load_cv2=5.6793 usage_frac=0.3482 topk_prob_mean=0.3429 ema_alpha_reverse=nan max_logit=12.7046
step:421/1750 train_time:206947ms step_avg:491.56ms
[train step 421] avg_loss=4.563827 main=4.002053 aux=0.561774 imp_cv2=0.6273 load_cv2=6.0492 usage_frac=0.3125 topk_prob_mean=0.2604 ema_alpha_reverse=nan max_logit=10.5697
step:422/1750 train_time:207420ms step_avg:491.52ms
[train step 422] avg_loss=4.353271 main=3.821194 aux=0.532077 imp_cv2=0.7024 load_cv2=5.6059 usage_frac=0.3616 topk_prob_mean=0.3291 ema_alpha_reverse=nan max_logit=11.9634
step:423/1750 train_time:207883ms step_avg:491.45ms
[train step 423] avg_loss=4.697354 main=4.159719 aux=0.537635 imp_cv2=0.6720 load_cv2=5.7034 usage_frac=0.3527 topk_prob_mean=0.3143 ema_alpha_reverse=nan max_logit=12.2141
step:424/1750 train_time:208365ms step_avg:491.43ms
[train step 424] avg_loss=4.434888 main=3.901581 aux=0.533307 imp_cv2=0.6965 load_cv2=5.6295 usage_frac=0.3482 topk_prob_mean=0.3247 ema_alpha_reverse=nan max_logit=11.7917
step:425/1750 train_time:208836ms step_avg:491.38ms
[train step 425] avg_loss=4.552186 main=4.019859 aux=0.532327 imp_cv2=0.6835 load_cv2=5.6323 usage_frac=0.3571 topk_prob_mean=0.3227 ema_alpha_reverse=nan max_logit=11.7917
step:426/1750 train_time:209312ms step_avg:491.34ms
[train step 426] avg_loss=4.509613 main=3.978813 aux=0.530799 imp_cv2=0.6836 load_cv2=5.6087 usage_frac=0.3527 topk_prob_mean=0.3196 ema_alpha_reverse=nan max_logit=12.5713
step:427/1750 train_time:209786ms step_avg:491.30ms
[train step 427] avg_loss=4.583045 main=4.050942 aux=0.532103 imp_cv2=0.6782 load_cv2=5.6289 usage_frac=0.4107 topk_prob_mean=0.3203 ema_alpha_reverse=nan max_logit=12.8286
step:428/1750 train_time:210260ms step_avg:491.26ms
[train step 428] avg_loss=4.107118 main=3.579770 aux=0.527348 imp_cv2=0.7813 load_cv2=5.4671 usage_frac=0.3482 topk_prob_mean=0.3572 ema_alpha_reverse=nan max_logit=11.7917
step:429/1750 train_time:210729ms step_avg:491.21ms
[train step 429] avg_loss=4.437403 main=3.905762 aux=0.531642 imp_cv2=0.7356 load_cv2=5.5647 usage_frac=0.3527 topk_prob_mean=0.3418 ema_alpha_reverse=nan max_logit=12.7744
step:430/1750 train_time:211216ms step_avg:491.20ms
[train step 430] avg_loss=4.524917 main=3.994022 aux=0.530895 imp_cv2=0.6624 load_cv2=5.6414 usage_frac=0.3527 topk_prob_mean=0.3095 ema_alpha_reverse=nan max_logit=12.3641
step:431/1750 train_time:211697ms step_avg:491.18ms
[train step 431] avg_loss=4.422675 main=3.892892 aux=0.529783 imp_cv2=0.7149 load_cv2=5.5696 usage_frac=0.3527 topk_prob_mean=0.3355 ema_alpha_reverse=nan max_logit=12.1045
step:432/1750 train_time:212189ms step_avg:491.18ms
[train step 432] avg_loss=4.267919 main=3.741994 aux=0.525925 imp_cv2=0.6650 load_cv2=5.5724 usage_frac=0.3482 topk_prob_mean=0.3189 ema_alpha_reverse=nan max_logit=11.7917
step:433/1750 train_time:212665ms step_avg:491.14ms
[train step 433] avg_loss=4.509061 main=3.983430 aux=0.525632 imp_cv2=0.6555 load_cv2=5.5732 usage_frac=0.3661 topk_prob_mean=0.3142 ema_alpha_reverse=nan max_logit=11.7917
step:434/1750 train_time:213157ms step_avg:491.15ms
[train step 434] avg_loss=4.876010 main=4.336271 aux=0.539739 imp_cv2=0.6381 load_cv2=5.7645 usage_frac=0.3571 topk_prob_mean=0.2921 ema_alpha_reverse=nan max_logit=12.5087
step:435/1750 train_time:213645ms step_avg:491.14ms
[train step 435] avg_loss=4.550058 main=4.013079 aux=0.536979 imp_cv2=0.6499 load_cv2=5.7262 usage_frac=0.3571 topk_prob_mean=0.3073 ema_alpha_reverse=nan max_logit=11.7917
step:436/1750 train_time:214116ms step_avg:491.09ms
[train step 436] avg_loss=4.113570 main=3.575214 aux=0.538355 imp_cv2=0.7396 load_cv2=5.6416 usage_frac=0.3616 topk_prob_mean=0.3433 ema_alpha_reverse=nan max_logit=12.4531
step:437/1750 train_time:214586ms step_avg:491.04ms
[train step 437] avg_loss=4.479326 main=3.941923 aux=0.537403 imp_cv2=0.7162 load_cv2=5.6530 usage_frac=0.3616 topk_prob_mean=0.3364 ema_alpha_reverse=nan max_logit=11.8342
step:438/1750 train_time:215063ms step_avg:491.01ms
[train step 438] avg_loss=4.129212 main=3.597378 aux=0.531834 imp_cv2=0.7244 load_cv2=5.5680 usage_frac=0.3705 topk_prob_mean=0.3444 ema_alpha_reverse=nan max_logit=11.9895
step:439/1750 train_time:215539ms step_avg:490.98ms
[train step 439] avg_loss=4.428251 main=3.892626 aux=0.535625 imp_cv2=0.7155 load_cv2=5.6291 usage_frac=0.3705 topk_prob_mean=0.3389 ema_alpha_reverse=nan max_logit=11.8086
step:440/1750 train_time:216012ms step_avg:490.94ms
[train step 440] avg_loss=4.450727 main=3.917990 aux=0.532737 imp_cv2=0.7149 load_cv2=5.6024 usage_frac=0.3705 topk_prob_mean=0.3366 ema_alpha_reverse=nan max_logit=11.8950
step:441/1750 train_time:216503ms step_avg:490.94ms
[train step 441] avg_loss=5.302536 main=4.463839 aux=0.838697 imp_cv2=4.5135 load_cv2=5.3194 usage_frac=0.4554 topk_prob_mean=0.8765 ema_alpha_reverse=nan max_logit=13.1675
step:442/1750 train_time:217057ms step_avg:491.08ms
[train step 442] avg_loss=4.357341 main=3.900085 aux=0.457256 imp_cv2=1.0896 load_cv2=4.2891 usage_frac=0.4821 topk_prob_mean=0.4584 ema_alpha_reverse=nan max_logit=12.7506
step:443/1750 train_time:217634ms step_avg:491.27ms
[train step 443] avg_loss=4.719538 main=4.210240 aux=0.509298 imp_cv2=0.5119 load_cv2=5.4532 usage_frac=0.4420 topk_prob_mean=0.3150 ema_alpha_reverse=nan max_logit=12.5574
step:444/1750 train_time:218149ms step_avg:491.33ms
[train step 444] avg_loss=4.314037 main=3.808034 aux=0.506003 imp_cv2=0.4144 load_cv2=5.5149 usage_frac=0.4286 topk_prob_mean=0.2978 ema_alpha_reverse=nan max_logit=12.9709
step:445/1750 train_time:218653ms step_avg:491.35ms
[train step 445] avg_loss=4.257338 main=3.748336 aux=0.509002 imp_cv2=0.4675 load_cv2=5.5077 usage_frac=0.4107 topk_prob_mean=0.3239 ema_alpha_reverse=nan max_logit=12.7744
step:446/1750 train_time:219163ms step_avg:491.40ms
[train step 446] avg_loss=4.648106 main=4.131469 aux=0.516637 imp_cv2=0.4645 load_cv2=5.5732 usage_frac=0.3393 topk_prob_mean=0.2833 ema_alpha_reverse=nan max_logit=9.8264
step:447/1750 train_time:219649ms step_avg:491.38ms
[train step 447] avg_loss=4.416936 main=3.905816 aux=0.511120 imp_cv2=0.4381 load_cv2=5.5602 usage_frac=0.3973 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=12.0240
step:448/1750 train_time:220138ms step_avg:491.38ms
[train step 448] avg_loss=4.272868 main=3.764036 aux=0.508832 imp_cv2=0.4633 load_cv2=5.5098 usage_frac=0.4018 topk_prob_mean=0.3259 ema_alpha_reverse=nan max_logit=12.7744
step:449/1750 train_time:220658ms step_avg:491.44ms
[train step 449] avg_loss=4.224688 main=3.714712 aux=0.509976 imp_cv2=0.4212 load_cv2=5.5759 usage_frac=0.3929 topk_prob_mean=0.3063 ema_alpha_reverse=nan max_logit=11.7917
step:450/1750 train_time:221144ms step_avg:491.43ms
Running validation...
step:450/1750 val_loss:3.880289 train_time:221156ms step_avg:491.46ms
[train step 450] avg_loss=4.489718 main=3.980686 aux=0.509032 imp_cv2=0.4155 load_cv2=5.5659 usage_frac=0.3884 topk_prob_mean=0.3014 ema_alpha_reverse=nan max_logit=12.7744
step:451/1750 train_time:221628ms step_avg:491.41ms
[train step 451] avg_loss=4.388184 main=3.869298 aux=0.518886 imp_cv2=0.3973 load_cv2=5.7090 usage_frac=0.3839 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=12.4790
step:452/1750 train_time:222299ms step_avg:491.81ms
[train step 452] avg_loss=4.514622 main=4.019642 aux=0.494980 imp_cv2=0.4316 load_cv2=5.3832 usage_frac=0.3973 topk_prob_mean=0.3159 ema_alpha_reverse=nan max_logit=11.7917
step:453/1750 train_time:222780ms step_avg:491.79ms
[train step 453] avg_loss=4.449664 main=3.950131 aux=0.499533 imp_cv2=0.4083 load_cv2=5.4645 usage_frac=0.3839 topk_prob_mean=0.3034 ema_alpha_reverse=nan max_logit=11.7917
step:454/1750 train_time:223258ms step_avg:491.76ms
[train step 454] avg_loss=4.145005 main=3.645590 aux=0.499416 imp_cv2=0.4982 load_cv2=5.3677 usage_frac=0.4062 topk_prob_mean=0.3347 ema_alpha_reverse=nan max_logit=12.6385
step:455/1750 train_time:223762ms step_avg:491.78ms
[train step 455] avg_loss=4.333137 main=3.823276 aux=0.509861 imp_cv2=0.4545 load_cv2=5.5508 usage_frac=0.3929 topk_prob_mean=0.3121 ema_alpha_reverse=nan max_logit=11.7917
step:456/1750 train_time:224250ms step_avg:491.78ms
[train step 456] avg_loss=4.300892 main=3.793577 aux=0.507315 imp_cv2=0.4685 load_cv2=5.5020 usage_frac=0.3884 topk_prob_mean=0.3181 ema_alpha_reverse=nan max_logit=12.9317
step:457/1750 train_time:224727ms step_avg:491.74ms
[train step 457] avg_loss=4.485593 main=3.982020 aux=0.503574 imp_cv2=0.4536 load_cv2=5.4733 usage_frac=0.4018 topk_prob_mean=0.3188 ema_alpha_reverse=nan max_logit=12.7744
step:458/1750 train_time:225224ms step_avg:491.75ms
[train step 458] avg_loss=4.409030 main=3.899028 aux=0.510002 imp_cv2=0.4087 load_cv2=5.6064 usage_frac=0.3929 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=11.7917
step:459/1750 train_time:225715ms step_avg:491.75ms
[train step 459] avg_loss=4.110706 main=3.600897 aux=0.509809 imp_cv2=0.4645 load_cv2=5.5434 usage_frac=0.3929 topk_prob_mean=0.3142 ema_alpha_reverse=nan max_logit=12.9778
step:460/1750 train_time:226207ms step_avg:491.76ms
[train step 460] avg_loss=4.040013 main=3.528222 aux=0.511792 imp_cv2=0.5133 load_cv2=5.5118 usage_frac=0.3884 topk_prob_mean=0.3281 ema_alpha_reverse=nan max_logit=11.9230
step:461/1750 train_time:226702ms step_avg:491.76ms
[train step 461] avg_loss=4.417715 main=3.904229 aux=0.513486 imp_cv2=0.4341 load_cv2=5.6190 usage_frac=0.4062 topk_prob_mean=0.3049 ema_alpha_reverse=nan max_logit=12.6005
step:462/1750 train_time:227184ms step_avg:491.74ms
[train step 462] avg_loss=4.625512 main=4.120151 aux=0.505361 imp_cv2=0.4167 load_cv2=5.5399 usage_frac=0.3929 topk_prob_mean=0.2984 ema_alpha_reverse=nan max_logit=11.7928
step:463/1750 train_time:227669ms step_avg:491.73ms
[train step 463] avg_loss=4.490507 main=3.981640 aux=0.508867 imp_cv2=0.4612 load_cv2=5.5393 usage_frac=0.3929 topk_prob_mean=0.3150 ema_alpha_reverse=nan max_logit=12.7744
step:464/1750 train_time:228166ms step_avg:491.74ms
[train step 464] avg_loss=4.435673 main=3.925783 aux=0.509890 imp_cv2=0.4257 load_cv2=5.5938 usage_frac=0.3929 topk_prob_mean=0.3004 ema_alpha_reverse=nan max_logit=12.7744
step:465/1750 train_time:228639ms step_avg:491.70ms
[train step 465] avg_loss=4.166342 main=3.657440 aux=0.508901 imp_cv2=0.5168 load_cv2=5.4854 usage_frac=0.4062 topk_prob_mean=0.3330 ema_alpha_reverse=nan max_logit=12.4254
step:466/1750 train_time:229131ms step_avg:491.70ms
[train step 466] avg_loss=4.347883 main=3.842613 aux=0.505270 imp_cv2=0.5146 load_cv2=5.4417 usage_frac=0.3973 topk_prob_mean=0.3350 ema_alpha_reverse=nan max_logit=12.7744
step:467/1750 train_time:229653ms step_avg:491.76ms
[train step 467] avg_loss=4.416423 main=3.909590 aux=0.506832 imp_cv2=0.5192 load_cv2=5.4451 usage_frac=0.3929 topk_prob_mean=0.3364 ema_alpha_reverse=nan max_logit=12.7744
step:468/1750 train_time:230142ms step_avg:491.76ms
[train step 468] avg_loss=4.711939 main=4.205427 aux=0.506512 imp_cv2=0.4269 load_cv2=5.5462 usage_frac=0.3884 topk_prob_mean=0.2990 ema_alpha_reverse=nan max_logit=12.2836
step:469/1750 train_time:230632ms step_avg:491.75ms
[train step 469] avg_loss=4.287412 main=3.774031 aux=0.513380 imp_cv2=0.4882 load_cv2=5.5629 usage_frac=0.3884 topk_prob_mean=0.3224 ema_alpha_reverse=nan max_logit=12.7744
step:470/1750 train_time:231111ms step_avg:491.73ms
[train step 470] avg_loss=4.490703 main=3.986143 aux=0.504560 imp_cv2=0.4078 load_cv2=5.5385 usage_frac=0.3839 topk_prob_mean=0.2915 ema_alpha_reverse=nan max_logit=12.7744
step:471/1750 train_time:231589ms step_avg:491.70ms
[train step 471] avg_loss=4.287450 main=3.783181 aux=0.504269 imp_cv2=0.4402 load_cv2=5.4983 usage_frac=0.3884 topk_prob_mean=0.3127 ema_alpha_reverse=nan max_logit=12.7744
step:472/1750 train_time:232080ms step_avg:491.69ms
[train step 472] avg_loss=4.242442 main=3.735617 aux=0.506825 imp_cv2=0.4777 load_cv2=5.4854 usage_frac=0.3929 topk_prob_mean=0.3220 ema_alpha_reverse=nan max_logit=12.4381
step:473/1750 train_time:232571ms step_avg:491.69ms
[train step 473] avg_loss=4.340014 main=3.836718 aux=0.503296 imp_cv2=0.4469 load_cv2=5.4732 usage_frac=0.3973 topk_prob_mean=0.3135 ema_alpha_reverse=nan max_logit=12.7744
step:474/1750 train_time:233053ms step_avg:491.67ms
[train step 474] avg_loss=4.231208 main=3.729180 aux=0.502028 imp_cv2=0.4265 load_cv2=5.4824 usage_frac=0.3929 topk_prob_mean=0.3075 ema_alpha_reverse=nan max_logit=12.7744
step:475/1750 train_time:233557ms step_avg:491.70ms
[train step 475] avg_loss=4.372182 main=3.867268 aux=0.504915 imp_cv2=0.4312 load_cv2=5.5110 usage_frac=0.3973 topk_prob_mean=0.3091 ema_alpha_reverse=nan max_logit=12.7744
step:476/1750 train_time:234048ms step_avg:491.70ms
[train step 476] avg_loss=4.146427 main=3.644920 aux=0.501506 imp_cv2=0.4234 load_cv2=5.4816 usage_frac=0.3884 topk_prob_mean=0.3068 ema_alpha_reverse=nan max_logit=12.7744
step:477/1750 train_time:234549ms step_avg:491.72ms
[train step 477] avg_loss=4.594780 main=4.096895 aux=0.497885 imp_cv2=0.3988 load_cv2=5.4581 usage_frac=0.3884 topk_prob_mean=0.2803 ema_alpha_reverse=nan max_logit=12.7744
step:478/1750 train_time:235041ms step_avg:491.72ms
[train step 478] avg_loss=4.266725 main=3.764849 aux=0.501877 imp_cv2=0.4332 load_cv2=5.4790 usage_frac=0.3929 topk_prob_mean=0.3103 ema_alpha_reverse=nan max_logit=12.7744
step:479/1750 train_time:235548ms step_avg:491.75ms
[train step 479] avg_loss=4.204527 main=3.702888 aux=0.501639 imp_cv2=0.4296 load_cv2=5.4697 usage_frac=0.3884 topk_prob_mean=0.3127 ema_alpha_reverse=nan max_logit=12.7744
step:480/1750 train_time:236059ms step_avg:491.79ms
[train step 480] avg_loss=4.603780 main=4.096653 aux=0.507127 imp_cv2=0.3944 load_cv2=5.5718 usage_frac=0.3795 topk_prob_mean=0.2845 ema_alpha_reverse=nan max_logit=12.7744
step:481/1750 train_time:236545ms step_avg:491.78ms
[train step 481] avg_loss=4.372815 main=3.862707 aux=0.510108 imp_cv2=0.4660 load_cv2=5.5295 usage_frac=0.3929 topk_prob_mean=0.3210 ema_alpha_reverse=nan max_logit=12.7744
step:482/1750 train_time:237026ms step_avg:491.75ms
[train step 482] avg_loss=4.221949 main=3.706182 aux=0.515767 imp_cv2=0.5068 load_cv2=5.5573 usage_frac=0.3929 topk_prob_mean=0.3310 ema_alpha_reverse=nan max_logit=12.7744
step:483/1750 train_time:237523ms step_avg:491.77ms
[train step 483] avg_loss=4.310317 main=3.799093 aux=0.511223 imp_cv2=0.4328 load_cv2=5.5877 usage_frac=0.3839 topk_prob_mean=0.3063 ema_alpha_reverse=nan max_logit=12.7744
step:484/1750 train_time:238017ms step_avg:491.77ms
[train step 484] avg_loss=4.100994 main=3.593260 aux=0.507734 imp_cv2=0.4281 load_cv2=5.5497 usage_frac=0.3929 topk_prob_mean=0.3024 ema_alpha_reverse=nan max_logit=12.7744
step:485/1750 train_time:238520ms step_avg:491.79ms
[train step 485] avg_loss=5.330057 main=4.829292 aux=0.500765 imp_cv2=0.3933 load_cv2=5.4901 usage_frac=0.3839 topk_prob_mean=0.2822 ema_alpha_reverse=nan max_logit=12.7744
step:486/1750 train_time:238995ms step_avg:491.76ms
[train step 486] avg_loss=4.183241 main=3.677077 aux=0.506164 imp_cv2=0.5225 load_cv2=5.4282 usage_frac=0.3884 topk_prob_mean=0.3399 ema_alpha_reverse=nan max_logit=12.7744
step:487/1750 train_time:239492ms step_avg:491.77ms
[train step 487] avg_loss=4.050164 main=3.554822 aux=0.495342 imp_cv2=0.4742 load_cv2=5.3516 usage_frac=0.3884 topk_prob_mean=0.3292 ema_alpha_reverse=nan max_logit=12.7744
step:488/1750 train_time:240006ms step_avg:491.81ms
[train step 488] avg_loss=4.170259 main=3.676457 aux=0.493802 imp_cv2=0.4136 load_cv2=5.3975 usage_frac=0.3884 topk_prob_mean=0.3045 ema_alpha_reverse=nan max_logit=12.7744
step:489/1750 train_time:240485ms step_avg:491.79ms
[train step 489] avg_loss=4.143463 main=3.653438 aux=0.490025 imp_cv2=0.4513 load_cv2=5.3045 usage_frac=0.3973 topk_prob_mean=0.3243 ema_alpha_reverse=nan max_logit=12.7744
step:490/1750 train_time:240985ms step_avg:491.81ms
[train step 490] avg_loss=4.534485 main=4.042235 aux=0.492251 imp_cv2=0.4120 load_cv2=5.3761 usage_frac=0.3839 topk_prob_mean=0.3023 ema_alpha_reverse=nan max_logit=12.7744
step:491/1750 train_time:241679ms step_avg:492.22ms
[train step 491] avg_loss=4.303976 main=3.805084 aux=0.498892 imp_cv2=0.4555 load_cv2=5.4114 usage_frac=0.3839 topk_prob_mean=0.3202 ema_alpha_reverse=nan max_logit=12.7744
step:492/1750 train_time:242169ms step_avg:492.21ms
[train step 492] avg_loss=4.135768 main=3.640229 aux=0.495538 imp_cv2=0.4961 load_cv2=5.3303 usage_frac=0.3929 topk_prob_mean=0.3349 ema_alpha_reverse=nan max_logit=12.7744
step:493/1750 train_time:242675ms step_avg:492.24ms
[train step 493] avg_loss=4.297769 main=3.808786 aux=0.488982 imp_cv2=0.4750 load_cv2=5.2646 usage_frac=0.3929 topk_prob_mean=0.3332 ema_alpha_reverse=nan max_logit=12.7744
step:494/1750 train_time:243184ms step_avg:492.27ms
[train step 494] avg_loss=4.327661 main=3.834164 aux=0.493498 imp_cv2=0.4161 load_cv2=5.3839 usage_frac=0.3929 topk_prob_mean=0.3065 ema_alpha_reverse=nan max_logit=12.7744
step:495/1750 train_time:243671ms step_avg:492.26ms
[train step 495] avg_loss=4.289436 main=3.793482 aux=0.495954 imp_cv2=0.4289 load_cv2=5.3939 usage_frac=0.3973 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=12.7744
step:496/1750 train_time:244160ms step_avg:492.26ms
[train step 496] avg_loss=4.423590 main=3.928183 aux=0.495407 imp_cv2=0.4158 load_cv2=5.3958 usage_frac=0.3929 topk_prob_mean=0.2971 ema_alpha_reverse=nan max_logit=12.7744
step:497/1750 train_time:244827ms step_avg:492.61ms
[train step 497] avg_loss=4.129650 main=3.630123 aux=0.499527 imp_cv2=0.4650 load_cv2=5.4131 usage_frac=0.3973 topk_prob_mean=0.3233 ema_alpha_reverse=nan max_logit=12.7744
step:498/1750 train_time:245339ms step_avg:492.65ms
[train step 498] avg_loss=4.376306 main=3.860513 aux=0.515793 imp_cv2=0.4120 load_cv2=5.6588 usage_frac=0.3839 topk_prob_mean=0.2830 ema_alpha_reverse=nan max_logit=11.7917
step:499/1750 train_time:245842ms step_avg:492.67ms
[train step 499] avg_loss=5.735096 main=5.211277 aux=0.523819 imp_cv2=0.4418 load_cv2=5.7235 usage_frac=0.3482 topk_prob_mean=0.2610 ema_alpha_reverse=nan max_logit=10.8091
step:500/1750 train_time:246325ms step_avg:492.65ms
Running validation...
step:500/1750 val_loss:3.799637 train_time:246337ms step_avg:492.67ms
[train step 500] avg_loss=4.200023 main=3.700025 aux=0.499998 imp_cv2=0.4217 load_cv2=5.4738 usage_frac=0.3929 topk_prob_mean=0.3035 ema_alpha_reverse=nan max_logit=12.7744
step:501/1750 train_time:246809ms step_avg:492.63ms
[train step 501] avg_loss=4.204084 main=3.710582 aux=0.493502 imp_cv2=0.4169 load_cv2=5.3939 usage_frac=0.3973 topk_prob_mean=0.3073 ema_alpha_reverse=nan max_logit=12.7744
step:502/1750 train_time:247300ms step_avg:492.63ms
[train step 502] avg_loss=4.223088 main=3.729128 aux=0.493960 imp_cv2=0.4734 load_cv2=5.3327 usage_frac=0.3929 topk_prob_mean=0.3310 ema_alpha_reverse=nan max_logit=12.7744
step:503/1750 train_time:247793ms step_avg:492.63ms
[train step 503] avg_loss=4.140924 main=3.647715 aux=0.493209 imp_cv2=0.4484 load_cv2=5.3559 usage_frac=0.3929 topk_prob_mean=0.3217 ema_alpha_reverse=nan max_logit=12.7744
step:504/1750 train_time:248291ms step_avg:492.64ms
[train step 504] avg_loss=4.185432 main=3.688464 aux=0.496968 imp_cv2=0.4059 load_cv2=5.4464 usage_frac=0.3929 topk_prob_mean=0.2970 ema_alpha_reverse=nan max_logit=12.7744
step:505/1750 train_time:248780ms step_avg:492.63ms
[train step 505] avg_loss=4.112155 main=3.616168 aux=0.495987 imp_cv2=0.4266 load_cv2=5.4208 usage_frac=0.3884 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=12.7744
step:506/1750 train_time:249285ms step_avg:492.66ms
[train step 506] avg_loss=4.005416 main=3.504531 aux=0.500885 imp_cv2=0.4969 load_cv2=5.3971 usage_frac=0.3929 topk_prob_mean=0.3330 ema_alpha_reverse=nan max_logit=12.7744
step:507/1750 train_time:249791ms step_avg:492.68ms
[train step 507] avg_loss=4.200398 main=3.698035 aux=0.502363 imp_cv2=0.4248 load_cv2=5.5055 usage_frac=0.3839 topk_prob_mean=0.3000 ema_alpha_reverse=nan max_logit=12.7744
step:508/1750 train_time:250286ms step_avg:492.69ms
[train step 508] avg_loss=4.426425 main=3.926734 aux=0.499691 imp_cv2=0.4336 load_cv2=5.4479 usage_frac=0.3929 topk_prob_mean=0.3119 ema_alpha_reverse=nan max_logit=12.7744
step:509/1750 train_time:250770ms step_avg:492.67ms
[train step 509] avg_loss=4.160828 main=3.655759 aux=0.505069 imp_cv2=0.5235 load_cv2=5.4177 usage_frac=0.3884 topk_prob_mean=0.3402 ema_alpha_reverse=nan max_logit=12.7744
step:510/1750 train_time:251262ms step_avg:492.67ms
[train step 510] avg_loss=4.045792 main=3.536902 aux=0.508890 imp_cv2=0.4821 load_cv2=5.5102 usage_frac=0.3929 topk_prob_mean=0.3252 ema_alpha_reverse=nan max_logit=12.7744
step:511/1750 train_time:251750ms step_avg:492.66ms
[train step 511] avg_loss=4.037701 main=3.535524 aux=0.502177 imp_cv2=0.4620 load_cv2=5.4499 usage_frac=0.3884 topk_prob_mean=0.3209 ema_alpha_reverse=nan max_logit=12.7744
step:512/1750 train_time:252237ms step_avg:492.65ms
[train step 512] avg_loss=4.211497 main=3.704360 aux=0.507137 imp_cv2=0.4260 load_cv2=5.5571 usage_frac=0.3929 topk_prob_mean=0.3008 ema_alpha_reverse=nan max_logit=12.7744
step:513/1750 train_time:252716ms step_avg:492.62ms
[train step 513] avg_loss=4.179840 main=3.675667 aux=0.504174 imp_cv2=0.5825 load_cv2=5.3460 usage_frac=0.3929 topk_prob_mean=0.3545 ema_alpha_reverse=nan max_logit=12.7744
step:514/1750 train_time:253206ms step_avg:492.62ms
[train step 514] avg_loss=4.205087 main=3.700308 aux=0.504779 imp_cv2=0.4526 load_cv2=5.4970 usage_frac=0.3973 topk_prob_mean=0.3144 ema_alpha_reverse=nan max_logit=12.7744
step:515/1750 train_time:253693ms step_avg:492.61ms
[train step 515] avg_loss=4.146497 main=3.640784 aux=0.505713 imp_cv2=0.5044 load_cv2=5.4532 usage_frac=0.4018 topk_prob_mean=0.3314 ema_alpha_reverse=nan max_logit=13.0207
step:516/1750 train_time:254184ms step_avg:492.61ms
[train step 516] avg_loss=4.325539 main=3.817278 aux=0.508261 imp_cv2=0.5062 load_cv2=5.4839 usage_frac=0.3973 topk_prob_mean=0.3275 ema_alpha_reverse=nan max_logit=13.3946
step:517/1750 train_time:254662ms step_avg:492.58ms
[train step 517] avg_loss=5.400498 main=4.895288 aux=0.505210 imp_cv2=0.4129 load_cv2=5.5333 usage_frac=0.3973 topk_prob_mean=0.2980 ema_alpha_reverse=nan max_logit=12.7744
step:518/1750 train_time:255296ms step_avg:492.85ms
[train step 518] avg_loss=4.870582 main=4.355724 aux=0.514857 imp_cv2=0.4051 load_cv2=5.6618 usage_frac=0.3884 topk_prob_mean=0.2826 ema_alpha_reverse=nan max_logit=12.7744
step:519/1750 train_time:255777ms step_avg:492.83ms
[train step 519] avg_loss=4.153319 main=3.641270 aux=0.512049 imp_cv2=0.4985 load_cv2=5.5334 usage_frac=0.3973 topk_prob_mean=0.3272 ema_alpha_reverse=nan max_logit=12.7744
step:520/1750 train_time:256257ms step_avg:492.80ms
[train step 520] avg_loss=4.189031 main=3.686671 aux=0.502360 imp_cv2=0.4476 load_cv2=5.4708 usage_frac=0.3839 topk_prob_mean=0.3142 ema_alpha_reverse=nan max_logit=12.7744
step:521/1750 train_time:256729ms step_avg:492.76ms
[train step 521] avg_loss=4.003094 main=3.498245 aux=0.504850 imp_cv2=0.5342 load_cv2=5.4094 usage_frac=0.3884 topk_prob_mean=0.3393 ema_alpha_reverse=nan max_logit=12.7744
step:522/1750 train_time:257201ms step_avg:492.72ms
[train step 522] avg_loss=4.890067 main=4.379043 aux=0.511024 imp_cv2=0.3924 load_cv2=5.6271 usage_frac=0.3750 topk_prob_mean=0.2585 ema_alpha_reverse=nan max_logit=11.7917
step:523/1750 train_time:257686ms step_avg:492.71ms
[train step 523] avg_loss=4.229528 main=3.727811 aux=0.501717 imp_cv2=0.5011 load_cv2=5.4017 usage_frac=0.3973 topk_prob_mean=0.3320 ema_alpha_reverse=nan max_logit=12.7744
step:524/1750 train_time:258172ms step_avg:492.70ms
[train step 524] avg_loss=4.550591 main=4.053078 aux=0.497513 imp_cv2=0.4218 load_cv2=5.4329 usage_frac=0.3839 topk_prob_mean=0.3069 ema_alpha_reverse=nan max_logit=12.7744
step:525/1750 train_time:258639ms step_avg:492.65ms
[train step 525] avg_loss=4.470811 main=3.956643 aux=0.514169 imp_cv2=0.3932 load_cv2=5.6700 usage_frac=0.3929 topk_prob_mean=0.2614 ema_alpha_reverse=nan max_logit=12.7744
step:526/1750 train_time:259113ms step_avg:492.61ms
[train step 526] avg_loss=4.276126 main=3.769390 aux=0.506736 imp_cv2=0.4058 load_cv2=5.5686 usage_frac=0.3884 topk_prob_mean=0.2929 ema_alpha_reverse=nan max_logit=12.7744
step:527/1750 train_time:259598ms step_avg:492.60ms
[train step 527] avg_loss=3.926403 main=3.427016 aux=0.499387 imp_cv2=0.5073 load_cv2=5.3775 usage_frac=0.4018 topk_prob_mean=0.3380 ema_alpha_reverse=nan max_logit=12.7744
step:528/1750 train_time:260089ms step_avg:492.59ms
[train step 528] avg_loss=4.487995 main=3.988553 aux=0.499442 imp_cv2=0.4088 load_cv2=5.4847 usage_frac=0.4152 topk_prob_mean=0.2988 ema_alpha_reverse=nan max_logit=12.7744
step:529/1750 train_time:260575ms step_avg:492.58ms
[train step 529] avg_loss=4.131246 main=3.627302 aux=0.503943 imp_cv2=0.4450 load_cv2=5.4963 usage_frac=0.3929 topk_prob_mean=0.3149 ema_alpha_reverse=nan max_logit=12.7744
step:530/1750 train_time:261050ms step_avg:492.55ms
[train step 530] avg_loss=4.245738 main=3.737386 aux=0.508352 imp_cv2=0.4826 load_cv2=5.5107 usage_frac=0.3973 topk_prob_mean=0.3244 ema_alpha_reverse=nan max_logit=12.7744
step:531/1750 train_time:261517ms step_avg:492.50ms
[train step 531] avg_loss=4.289208 main=3.782980 aux=0.506228 imp_cv2=0.4283 load_cv2=5.5425 usage_frac=0.3839 topk_prob_mean=0.3035 ema_alpha_reverse=nan max_logit=12.7744
step:532/1750 train_time:262000ms step_avg:492.48ms
[train step 532] avg_loss=4.553427 main=4.010651 aux=0.542777 imp_cv2=0.3932 load_cv2=6.0041 usage_frac=0.3259 topk_prob_mean=0.2365 ema_alpha_reverse=nan max_logit=9.8264
step:533/1750 train_time:262478ms step_avg:492.45ms
[train step 533] avg_loss=4.537123 main=4.010770 aux=0.526353 imp_cv2=0.3973 load_cv2=5.8093 usage_frac=0.3393 topk_prob_mean=0.2476 ema_alpha_reverse=nan max_logit=10.7435
step:534/1750 train_time:262941ms step_avg:492.40ms
[train step 534] avg_loss=4.253156 main=3.736963 aux=0.516193 imp_cv2=0.4909 load_cv2=5.5926 usage_frac=0.3973 topk_prob_mean=0.3239 ema_alpha_reverse=nan max_logit=12.7744
step:535/1750 train_time:263410ms step_avg:492.36ms
[train step 535] avg_loss=4.321921 main=3.811714 aux=0.510207 imp_cv2=0.4794 load_cv2=5.5319 usage_frac=0.3929 topk_prob_mean=0.3213 ema_alpha_reverse=nan max_logit=12.7744
step:536/1750 train_time:263880ms step_avg:492.31ms
[train step 536] avg_loss=4.154585 main=3.650711 aux=0.503874 imp_cv2=0.4348 load_cv2=5.5099 usage_frac=0.4018 topk_prob_mean=0.3085 ema_alpha_reverse=nan max_logit=12.7744
step:537/1750 train_time:264356ms step_avg:492.28ms
[train step 537] avg_loss=3.881063 main=3.368797 aux=0.512266 imp_cv2=0.5758 load_cv2=5.4571 usage_frac=0.3973 topk_prob_mean=0.3433 ema_alpha_reverse=nan max_logit=12.7744
step:538/1750 train_time:264827ms step_avg:492.24ms
[train step 538] avg_loss=4.076929 main=3.570259 aux=0.506670 imp_cv2=0.4289 load_cv2=5.5436 usage_frac=0.4018 topk_prob_mean=0.3016 ema_alpha_reverse=nan max_logit=12.7744
step:539/1750 train_time:265307ms step_avg:492.22ms
[train step 539] avg_loss=4.400071 main=3.891789 aux=0.508283 imp_cv2=0.4114 load_cv2=5.5792 usage_frac=0.4018 topk_prob_mean=0.2909 ema_alpha_reverse=nan max_logit=12.7744
step:540/1750 train_time:265782ms step_avg:492.19ms
[train step 540] avg_loss=4.391963 main=3.886955 aux=0.505008 imp_cv2=0.4327 load_cv2=5.5236 usage_frac=0.4152 topk_prob_mean=0.3027 ema_alpha_reverse=nan max_logit=12.7744
step:541/1750 train_time:266277ms step_avg:492.19ms
[train step 541] avg_loss=4.057095 main=3.555396 aux=0.501699 imp_cv2=0.4390 load_cv2=5.4770 usage_frac=0.4062 topk_prob_mean=0.3061 ema_alpha_reverse=nan max_logit=12.7744
step:542/1750 train_time:266747ms step_avg:492.15ms
[train step 542] avg_loss=4.381107 main=3.857871 aux=0.523236 imp_cv2=0.3752 load_cv2=5.7945 usage_frac=0.4152 topk_prob_mean=0.2500 ema_alpha_reverse=nan max_logit=12.7744
step:543/1750 train_time:267237ms step_avg:492.15ms
[train step 543] avg_loss=4.366744 main=3.868493 aux=0.498252 imp_cv2=0.4557 load_cv2=5.4156 usage_frac=0.4152 topk_prob_mean=0.3135 ema_alpha_reverse=nan max_logit=12.7744
step:544/1750 train_time:267720ms step_avg:492.13ms
[train step 544] avg_loss=4.345143 main=3.840141 aux=0.505002 imp_cv2=0.4340 load_cv2=5.5261 usage_frac=0.4107 topk_prob_mean=0.3028 ema_alpha_reverse=nan max_logit=12.7744
step:545/1750 train_time:268219ms step_avg:492.15ms
[train step 545] avg_loss=4.151972 main=3.645113 aux=0.506859 imp_cv2=0.4452 load_cv2=5.5379 usage_frac=0.4107 topk_prob_mean=0.3068 ema_alpha_reverse=nan max_logit=12.7744
step:546/1750 train_time:268701ms step_avg:492.13ms
[train step 546] avg_loss=4.323080 main=3.823935 aux=0.499145 imp_cv2=0.4258 load_cv2=5.4612 usage_frac=0.4062 topk_prob_mean=0.3009 ema_alpha_reverse=nan max_logit=12.7744
step:547/1750 train_time:269188ms step_avg:492.12ms
[train step 547] avg_loss=4.749563 main=4.221764 aux=0.527799 imp_cv2=0.3891 load_cv2=5.8302 usage_frac=0.3973 topk_prob_mean=0.2588 ema_alpha_reverse=nan max_logit=11.9163
step:548/1750 train_time:269679ms step_avg:492.11ms
[train step 548] avg_loss=4.734192 main=4.221052 aux=0.513140 imp_cv2=0.4051 load_cv2=5.6388 usage_frac=0.4152 topk_prob_mean=0.2791 ema_alpha_reverse=nan max_logit=12.7744
step:549/1750 train_time:270159ms step_avg:492.09ms
[train step 549] avg_loss=4.167111 main=3.667924 aux=0.499187 imp_cv2=0.4035 load_cv2=5.5000 usage_frac=0.4152 topk_prob_mean=0.2886 ema_alpha_reverse=nan max_logit=12.7744
step:550/1750 train_time:270648ms step_avg:492.09ms
Running validation...
step:550/1750 val_loss:3.715492 train_time:270659ms step_avg:492.11ms
[train step 550] avg_loss=4.640263 main=4.134532 aux=0.505731 imp_cv2=0.3945 load_cv2=5.5781 usage_frac=0.4107 topk_prob_mean=0.2846 ema_alpha_reverse=nan max_logit=12.7744
step:551/1750 train_time:271128ms step_avg:492.07ms
[train step 551] avg_loss=6.578276 main=6.054507 aux=0.523770 imp_cv2=0.3992 load_cv2=5.7678 usage_frac=0.3616 topk_prob_mean=0.2457 ema_alpha_reverse=nan max_logit=8.8438
step:552/1750 train_time:271612ms step_avg:492.05ms
[train step 552] avg_loss=3.799206 main=3.306278 aux=0.492928 imp_cv2=0.4924 load_cv2=5.3220 usage_frac=0.4062 topk_prob_mean=0.3308 ema_alpha_reverse=nan max_logit=12.7744
step:553/1750 train_time:272091ms step_avg:492.03ms
[train step 553] avg_loss=4.308100 main=3.807206 aux=0.500894 imp_cv2=0.3988 load_cv2=5.5168 usage_frac=0.4062 topk_prob_mean=0.2903 ema_alpha_reverse=nan max_logit=12.7744
step:554/1750 train_time:272584ms step_avg:492.03ms
[train step 554] avg_loss=4.301318 main=3.809757 aux=0.491561 imp_cv2=0.4312 load_cv2=5.3647 usage_frac=0.4062 topk_prob_mean=0.3088 ema_alpha_reverse=nan max_logit=12.7744
step:555/1750 train_time:273077ms step_avg:492.03ms
[train step 555] avg_loss=4.147735 main=3.656463 aux=0.491273 imp_cv2=0.4481 load_cv2=5.3508 usage_frac=0.4152 topk_prob_mean=0.3141 ema_alpha_reverse=nan max_logit=12.7744
step:556/1750 train_time:273583ms step_avg:492.06ms
[train step 556] avg_loss=4.385220 main=3.899431 aux=0.485789 imp_cv2=0.4210 load_cv2=5.3131 usage_frac=0.4152 topk_prob_mean=0.2971 ema_alpha_reverse=nan max_logit=12.7744
step:557/1750 train_time:274084ms step_avg:492.07ms
[train step 557] avg_loss=3.837327 main=3.345464 aux=0.491863 imp_cv2=0.5056 load_cv2=5.3039 usage_frac=0.4018 topk_prob_mean=0.3317 ema_alpha_reverse=nan max_logit=12.7744
step:558/1750 train_time:274576ms step_avg:492.07ms
[train step 558] avg_loss=4.895293 main=4.391970 aux=0.503323 imp_cv2=0.4051 load_cv2=5.5406 usage_frac=0.4196 topk_prob_mean=0.2824 ema_alpha_reverse=nan max_logit=12.7744
step:559/1750 train_time:275072ms step_avg:492.08ms
[train step 559] avg_loss=3.890134 main=3.397850 aux=0.492284 imp_cv2=0.4949 load_cv2=5.3078 usage_frac=0.4241 topk_prob_mean=0.3290 ema_alpha_reverse=nan max_logit=12.7744
step:560/1750 train_time:275561ms step_avg:492.07ms
[train step 560] avg_loss=4.051877 main=3.557544 aux=0.494333 imp_cv2=0.4307 load_cv2=5.4081 usage_frac=0.4241 topk_prob_mean=0.3052 ema_alpha_reverse=nan max_logit=12.7744
step:561/1750 train_time:276063ms step_avg:492.09ms
[train step 561] avg_loss=4.072497 main=3.578397 aux=0.494100 imp_cv2=0.4146 load_cv2=5.4246 usage_frac=0.4241 topk_prob_mean=0.2980 ema_alpha_reverse=nan max_logit=12.7744
step:562/1750 train_time:276542ms step_avg:492.07ms
[train step 562] avg_loss=3.993041 main=3.502821 aux=0.490220 imp_cv2=0.4576 load_cv2=5.3274 usage_frac=0.4196 topk_prob_mean=0.3162 ema_alpha_reverse=nan max_logit=12.7744
step:563/1750 train_time:277039ms step_avg:492.08ms
[train step 563] avg_loss=4.209393 main=3.722229 aux=0.487164 imp_cv2=0.4789 load_cv2=5.2674 usage_frac=0.4196 topk_prob_mean=0.3258 ema_alpha_reverse=nan max_logit=12.7744
step:564/1750 train_time:277540ms step_avg:492.09ms
[train step 564] avg_loss=4.312001 main=3.823695 aux=0.488306 imp_cv2=0.4867 load_cv2=5.2718 usage_frac=0.4107 topk_prob_mean=0.3257 ema_alpha_reverse=nan max_logit=12.7744
step:565/1750 train_time:278042ms step_avg:492.11ms
[train step 565] avg_loss=4.069845 main=3.585437 aux=0.484408 imp_cv2=0.5278 load_cv2=5.1885 usage_frac=0.4107 topk_prob_mean=0.3389 ema_alpha_reverse=nan max_logit=12.7744
step:566/1750 train_time:278539ms step_avg:492.12ms
[train step 566] avg_loss=4.027979 main=3.542169 aux=0.485810 imp_cv2=0.5010 load_cv2=5.2259 usage_frac=0.4330 topk_prob_mean=0.3357 ema_alpha_reverse=nan max_logit=12.7744
step:567/1750 train_time:279040ms step_avg:492.13ms
[train step 567] avg_loss=4.711708 main=4.201491 aux=0.510217 imp_cv2=0.3981 load_cv2=5.6207 usage_frac=0.4107 topk_prob_mean=0.2779 ema_alpha_reverse=nan max_logit=12.7744
step:568/1750 train_time:279523ms step_avg:492.12ms
[train step 568] avg_loss=4.017078 main=3.531414 aux=0.485665 imp_cv2=0.5485 load_cv2=5.1816 usage_frac=0.4152 topk_prob_mean=0.3454 ema_alpha_reverse=nan max_logit=12.7744
step:569/1750 train_time:280016ms step_avg:492.12ms
[train step 569] avg_loss=4.154208 main=3.665192 aux=0.489016 imp_cv2=0.5093 load_cv2=5.2629 usage_frac=0.4107 topk_prob_mean=0.3349 ema_alpha_reverse=nan max_logit=12.7744
step:570/1750 train_time:280519ms step_avg:492.14ms
[train step 570] avg_loss=3.906349 main=3.414257 aux=0.492092 imp_cv2=0.4157 load_cv2=5.3971 usage_frac=0.4107 topk_prob_mean=0.3020 ema_alpha_reverse=nan max_logit=12.7744
step:571/1750 train_time:281019ms step_avg:492.15ms
[train step 571] avg_loss=4.187456 main=3.684850 aux=0.502607 imp_cv2=0.3979 load_cv2=5.5436 usage_frac=0.4018 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=12.7744
step:572/1750 train_time:281496ms step_avg:492.13ms
[train step 572] avg_loss=3.878847 main=3.394776 aux=0.484071 imp_cv2=0.5051 load_cv2=5.2172 usage_frac=0.4062 topk_prob_mean=0.3363 ema_alpha_reverse=nan max_logit=12.7744
step:573/1750 train_time:281981ms step_avg:492.11ms
[train step 573] avg_loss=4.200646 main=3.710523 aux=0.490123 imp_cv2=0.4206 load_cv2=5.3784 usage_frac=0.4062 topk_prob_mean=0.3081 ema_alpha_reverse=nan max_logit=12.7744
step:574/1750 train_time:282477ms step_avg:492.12ms
[train step 574] avg_loss=4.130515 main=3.650686 aux=0.479830 imp_cv2=0.4318 load_cv2=5.2364 usage_frac=0.3973 topk_prob_mean=0.3220 ema_alpha_reverse=nan max_logit=12.7744
step:575/1750 train_time:282978ms step_avg:492.14ms
[train step 575] avg_loss=4.198052 main=3.723029 aux=0.475024 imp_cv2=0.4772 load_cv2=5.1241 usage_frac=0.3973 topk_prob_mean=0.3400 ema_alpha_reverse=nan max_logit=12.7744
step:576/1750 train_time:283483ms step_avg:492.16ms
[train step 576] avg_loss=4.359425 main=3.868755 aux=0.490671 imp_cv2=0.3953 load_cv2=5.3875 usage_frac=0.4241 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=12.7744
step:577/1750 train_time:283963ms step_avg:492.14ms
[train step 577] avg_loss=4.044351 main=3.565149 aux=0.479202 imp_cv2=0.4233 load_cv2=5.2395 usage_frac=0.4062 topk_prob_mean=0.3248 ema_alpha_reverse=nan max_logit=12.7744
step:578/1750 train_time:284466ms step_avg:492.16ms
[train step 578] avg_loss=4.382131 main=3.901778 aux=0.480352 imp_cv2=0.4631 load_cv2=5.1989 usage_frac=0.4107 topk_prob_mean=0.3412 ema_alpha_reverse=nan max_logit=12.7744
step:579/1750 train_time:284959ms step_avg:492.16ms
[train step 579] avg_loss=4.574043 main=4.080151 aux=0.493892 imp_cv2=0.4002 load_cv2=5.4175 usage_frac=0.4107 topk_prob_mean=0.3025 ema_alpha_reverse=nan max_logit=12.7744
step:580/1750 train_time:285450ms step_avg:492.15ms
[train step 580] avg_loss=3.921275 main=3.441218 aux=0.480056 imp_cv2=0.4795 load_cv2=5.1874 usage_frac=0.4152 topk_prob_mean=0.3442 ema_alpha_reverse=nan max_logit=12.7744
step:581/1750 train_time:285933ms step_avg:492.14ms
[train step 581] avg_loss=4.344684 main=3.868567 aux=0.476117 imp_cv2=0.4629 load_cv2=5.1582 usage_frac=0.4152 topk_prob_mean=0.3382 ema_alpha_reverse=nan max_logit=12.7744
step:582/1750 train_time:286439ms step_avg:492.16ms
[train step 582] avg_loss=4.421548 main=3.940894 aux=0.480654 imp_cv2=0.4150 load_cv2=5.2517 usage_frac=0.4152 topk_prob_mean=0.3206 ema_alpha_reverse=nan max_logit=12.7744
step:583/1750 train_time:286932ms step_avg:492.17ms
[train step 583] avg_loss=4.190300 main=3.714997 aux=0.475303 imp_cv2=0.4055 load_cv2=5.2043 usage_frac=0.4018 topk_prob_mean=0.3138 ema_alpha_reverse=nan max_logit=12.7744
step:584/1750 train_time:287420ms step_avg:492.16ms
[train step 584] avg_loss=4.268913 main=3.799028 aux=0.469885 imp_cv2=0.4587 load_cv2=5.0801 usage_frac=0.4152 topk_prob_mean=0.3419 ema_alpha_reverse=nan max_logit=12.7744
step:585/1750 train_time:287914ms step_avg:492.16ms
[train step 585] avg_loss=4.094681 main=3.624544 aux=0.470137 imp_cv2=0.4833 load_cv2=5.0585 usage_frac=0.4152 topk_prob_mean=0.3478 ema_alpha_reverse=nan max_logit=12.7744
step:586/1750 train_time:288424ms step_avg:492.19ms
[train step 586] avg_loss=3.989344 main=3.507318 aux=0.482025 imp_cv2=0.4177 load_cv2=5.2613 usage_frac=0.4018 topk_prob_mean=0.3113 ema_alpha_reverse=nan max_logit=12.7744
step:587/1750 train_time:288938ms step_avg:492.23ms
[train step 587] avg_loss=3.935151 main=3.461690 aux=0.473461 imp_cv2=0.5074 load_cv2=5.0698 usage_frac=0.4018 topk_prob_mean=0.3541 ema_alpha_reverse=nan max_logit=12.7744
step:588/1750 train_time:289436ms step_avg:492.24ms
[train step 588] avg_loss=4.154811 main=3.674047 aux=0.480763 imp_cv2=0.4708 load_cv2=5.1942 usage_frac=0.4107 topk_prob_mean=0.3368 ema_alpha_reverse=nan max_logit=12.7744
step:589/1750 train_time:289938ms step_avg:492.25ms
[train step 589] avg_loss=4.010400 main=3.536991 aux=0.473409 imp_cv2=0.4627 load_cv2=5.1147 usage_frac=0.4018 topk_prob_mean=0.3378 ema_alpha_reverse=nan max_logit=12.7744
step:590/1750 train_time:290429ms step_avg:492.25ms
[train step 590] avg_loss=4.041073 main=3.574700 aux=0.466373 imp_cv2=0.4765 load_cv2=5.0089 usage_frac=0.4152 topk_prob_mean=0.3459 ema_alpha_reverse=nan max_logit=12.7744
step:591/1750 train_time:290926ms step_avg:492.26ms
[train step 591] avg_loss=4.288656 main=3.631060 aux=0.657596 imp_cv2=3.4222 load_cv2=4.1683 usage_frac=0.4866 topk_prob_mean=0.8642 ema_alpha_reverse=nan max_logit=13.5482
step:592/1750 train_time:291483ms step_avg:492.37ms
[train step 592] avg_loss=4.729767 main=4.287235 aux=0.442532 imp_cv2=1.2588 load_cv2=3.9029 usage_frac=0.5089 topk_prob_mean=0.4986 ema_alpha_reverse=nan max_logit=13.1728
step:593/1750 train_time:292072ms step_avg:492.53ms
[train step 593] avg_loss=4.122251 main=3.662009 aux=0.460242 imp_cv2=0.6067 load_cv2=4.7706 usage_frac=0.4911 topk_prob_mean=0.3979 ema_alpha_reverse=nan max_logit=12.7744
step:594/1750 train_time:292593ms step_avg:492.58ms
[train step 594] avg_loss=4.105390 main=3.652590 aux=0.452801 imp_cv2=0.3893 load_cv2=4.8782 usage_frac=0.4420 topk_prob_mean=0.3551 ema_alpha_reverse=nan max_logit=12.7744
step:595/1750 train_time:293171ms step_avg:492.72ms
[train step 595] avg_loss=4.083964 main=3.634340 aux=0.449624 imp_cv2=0.4138 load_cv2=4.8235 usage_frac=0.4509 topk_prob_mean=0.3599 ema_alpha_reverse=nan max_logit=12.7744
step:596/1750 train_time:293676ms step_avg:492.75ms
[train step 596] avg_loss=3.864510 main=3.404338 aux=0.460172 imp_cv2=0.4970 load_cv2=4.8745 usage_frac=0.4286 topk_prob_mean=0.3692 ema_alpha_reverse=nan max_logit=12.7744
step:597/1750 train_time:294199ms step_avg:492.80ms
[train step 597] avg_loss=4.061028 main=3.604457 aux=0.456571 imp_cv2=0.3997 load_cv2=4.9212 usage_frac=0.4286 topk_prob_mean=0.3484 ema_alpha_reverse=nan max_logit=12.7744
step:598/1750 train_time:294730ms step_avg:492.86ms
[train step 598] avg_loss=4.349799 main=3.892643 aux=0.457156 imp_cv2=0.3757 load_cv2=4.9492 usage_frac=0.4330 topk_prob_mean=0.3442 ema_alpha_reverse=nan max_logit=12.7744
step:599/1750 train_time:295241ms step_avg:492.89ms
[train step 599] avg_loss=3.940810 main=3.480227 aux=0.460583 imp_cv2=0.3765 load_cv2=4.9964 usage_frac=0.4286 topk_prob_mean=0.3400 ema_alpha_reverse=nan max_logit=12.7744
step:600/1750 train_time:295738ms step_avg:492.90ms
Running validation...
step:600/1750 val_loss:3.692503 train_time:295750ms step_avg:492.92ms
[train step 600] avg_loss=4.056422 main=3.581404 aux=0.475018 imp_cv2=0.2870 load_cv2=5.2616 usage_frac=0.4196 topk_prob_mean=0.2963 ema_alpha_reverse=nan max_logit=12.7744
step:601/1750 train_time:296266ms step_avg:492.96ms
[train step 601] avg_loss=3.962565 main=3.505650 aux=0.456915 imp_cv2=0.4199 load_cv2=4.9074 usage_frac=0.4375 topk_prob_mean=0.3516 ema_alpha_reverse=nan max_logit=12.7744
step:602/1750 train_time:296814ms step_avg:493.05ms
[train step 602] avg_loss=4.282768 main=3.821986 aux=0.460782 imp_cv2=0.3324 load_cv2=5.0456 usage_frac=0.4330 topk_prob_mean=0.3258 ema_alpha_reverse=nan max_logit=12.7744
step:603/1750 train_time:297329ms step_avg:493.08ms
[train step 603] avg_loss=3.983155 main=3.514247 aux=0.468908 imp_cv2=0.3272 load_cv2=5.1496 usage_frac=0.4375 topk_prob_mean=0.3162 ema_alpha_reverse=nan max_logit=12.7744
step:604/1750 train_time:297849ms step_avg:493.13ms
[train step 604] avg_loss=4.352025 main=3.866727 aux=0.485298 imp_cv2=0.2803 load_cv2=5.3938 usage_frac=0.4330 topk_prob_mean=0.2803 ema_alpha_reverse=nan max_logit=12.7744
step:605/1750 train_time:298349ms step_avg:493.14ms
[train step 605] avg_loss=4.036709 main=3.572423 aux=0.464286 imp_cv2=0.3385 load_cv2=5.0857 usage_frac=0.4330 topk_prob_mean=0.3210 ema_alpha_reverse=nan max_logit=12.7744
step:606/1750 train_time:298861ms step_avg:493.17ms
[train step 606] avg_loss=4.158853 main=3.694391 aux=0.464463 imp_cv2=0.3204 load_cv2=5.1006 usage_frac=0.4286 topk_prob_mean=0.3137 ema_alpha_reverse=nan max_logit=12.7744
step:607/1750 train_time:299549ms step_avg:493.49ms
[train step 607] avg_loss=4.192928 main=3.720457 aux=0.472471 imp_cv2=0.2939 load_cv2=5.2225 usage_frac=0.4420 topk_prob_mean=0.2951 ema_alpha_reverse=nan max_logit=12.7744
step:608/1750 train_time:300061ms step_avg:493.52ms
[train step 608] avg_loss=3.818039 main=3.355366 aux=0.462673 imp_cv2=0.4152 load_cv2=4.9790 usage_frac=0.4375 topk_prob_mean=0.3424 ema_alpha_reverse=nan max_logit=12.7744
step:609/1750 train_time:300572ms step_avg:493.55ms
[train step 609] avg_loss=4.131457 main=3.671963 aux=0.459494 imp_cv2=0.3235 load_cv2=5.0338 usage_frac=0.4286 topk_prob_mean=0.3197 ema_alpha_reverse=nan max_logit=12.7744
step:610/1750 train_time:301097ms step_avg:493.60ms
[train step 610] avg_loss=4.251041 main=3.788789 aux=0.462252 imp_cv2=0.3060 load_cv2=5.0899 usage_frac=0.4330 topk_prob_mean=0.3091 ema_alpha_reverse=nan max_logit=12.7744
step:611/1750 train_time:301609ms step_avg:493.63ms
[train step 611] avg_loss=3.923103 main=3.472656 aux=0.450447 imp_cv2=0.3550 load_cv2=4.9016 usage_frac=0.4286 topk_prob_mean=0.3359 ema_alpha_reverse=nan max_logit=12.7744
step:612/1750 train_time:302110ms step_avg:493.64ms
[train step 612] avg_loss=4.150244 main=3.695703 aux=0.454540 imp_cv2=0.3425 load_cv2=4.9535 usage_frac=0.4375 topk_prob_mean=0.3297 ema_alpha_reverse=nan max_logit=12.7744
step:613/1750 train_time:302611ms step_avg:493.66ms
[train step 613] avg_loss=3.957105 main=3.498348 aux=0.458757 imp_cv2=0.3331 load_cv2=5.0116 usage_frac=0.4286 topk_prob_mean=0.3268 ema_alpha_reverse=nan max_logit=12.7744
step:614/1750 train_time:303146ms step_avg:493.72ms
[train step 614] avg_loss=4.075184 main=3.612692 aux=0.462493 imp_cv2=0.2861 load_cv2=5.1084 usage_frac=0.4330 topk_prob_mean=0.3032 ema_alpha_reverse=nan max_logit=12.7744
step:615/1750 train_time:303650ms step_avg:493.74ms
[train step 615] avg_loss=4.430319 main=3.954641 aux=0.475678 imp_cv2=0.2780 load_cv2=5.2854 usage_frac=0.4330 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=12.7744
step:616/1750 train_time:304156ms step_avg:493.76ms
[train step 616] avg_loss=4.143304 main=3.654281 aux=0.489024 imp_cv2=0.2870 load_cv2=5.4282 usage_frac=0.4464 topk_prob_mean=0.2684 ema_alpha_reverse=nan max_logit=12.7744
step:617/1750 train_time:304660ms step_avg:493.78ms
[train step 617] avg_loss=3.744531 main=3.272025 aux=0.472505 imp_cv2=0.4513 load_cv2=5.0592 usage_frac=0.4286 topk_prob_mean=0.3510 ema_alpha_reverse=nan max_logit=12.7744
step:618/1750 train_time:305180ms step_avg:493.82ms
[train step 618] avg_loss=4.285804 main=3.824049 aux=0.461755 imp_cv2=0.3376 load_cv2=5.0533 usage_frac=0.4375 topk_prob_mean=0.3257 ema_alpha_reverse=nan max_logit=12.7744
step:619/1750 train_time:305706ms step_avg:493.87ms
[train step 619] avg_loss=4.204227 main=3.745433 aux=0.458794 imp_cv2=0.3086 load_cv2=5.0458 usage_frac=0.4420 topk_prob_mean=0.3172 ema_alpha_reverse=nan max_logit=12.7744
step:620/1750 train_time:306211ms step_avg:493.89ms
[train step 620] avg_loss=3.913968 main=3.446528 aux=0.467441 imp_cv2=0.2697 load_cv2=5.1925 usage_frac=0.4375 topk_prob_mean=0.2937 ema_alpha_reverse=nan max_logit=12.7744
step:621/1750 train_time:306710ms step_avg:493.90ms
[train step 621] avg_loss=3.908752 main=3.451500 aux=0.457252 imp_cv2=0.3368 load_cv2=5.0048 usage_frac=0.4375 topk_prob_mean=0.3290 ema_alpha_reverse=nan max_logit=12.7744
step:622/1750 train_time:307221ms step_avg:493.92ms
[train step 622] avg_loss=3.956192 main=3.486187 aux=0.470006 imp_cv2=0.3184 load_cv2=5.1810 usage_frac=0.4375 topk_prob_mean=0.3147 ema_alpha_reverse=nan max_logit=12.7744
step:623/1750 train_time:307714ms step_avg:493.92ms
[train step 623] avg_loss=4.489854 main=4.007177 aux=0.482677 imp_cv2=0.2832 load_cv2=5.3564 usage_frac=0.4375 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=12.7073
step:624/1750 train_time:308222ms step_avg:493.95ms
[train step 624] avg_loss=4.315130 main=3.842584 aux=0.472546 imp_cv2=0.2963 load_cv2=5.2227 usage_frac=0.4375 topk_prob_mean=0.3036 ema_alpha_reverse=nan max_logit=12.7744
step:625/1750 train_time:308720ms step_avg:493.95ms
[train step 625] avg_loss=4.072723 main=3.602442 aux=0.470281 imp_cv2=0.3099 load_cv2=5.1852 usage_frac=0.4241 topk_prob_mean=0.3095 ema_alpha_reverse=nan max_logit=12.7744
step:626/1750 train_time:309235ms step_avg:493.98ms
[train step 626] avg_loss=4.084802 main=3.611215 aux=0.473587 imp_cv2=0.3279 load_cv2=5.2100 usage_frac=0.4286 topk_prob_mean=0.3145 ema_alpha_reverse=nan max_logit=12.7744
step:627/1750 train_time:309725ms step_avg:493.98ms
[train step 627] avg_loss=3.609949 main=3.127925 aux=0.482025 imp_cv2=0.4911 load_cv2=5.1335 usage_frac=0.4286 topk_prob_mean=0.3535 ema_alpha_reverse=nan max_logit=12.7744
step:628/1750 train_time:310228ms step_avg:493.99ms
[train step 628] avg_loss=4.107499 main=3.637338 aux=0.470161 imp_cv2=0.2912 load_cv2=5.2030 usage_frac=0.4196 topk_prob_mean=0.3034 ema_alpha_reverse=nan max_logit=12.7744
step:629/1750 train_time:310729ms step_avg:494.00ms
[train step 629] avg_loss=3.822456 main=3.355252 aux=0.467204 imp_cv2=0.3081 load_cv2=5.1547 usage_frac=0.4196 topk_prob_mean=0.3135 ema_alpha_reverse=nan max_logit=12.7744
step:630/1750 train_time:311222ms step_avg:494.00ms
[train step 630] avg_loss=3.708321 main=3.246838 aux=0.461483 imp_cv2=0.3929 load_cv2=4.9945 usage_frac=0.4241 topk_prob_mean=0.3419 ema_alpha_reverse=nan max_logit=12.7744
step:631/1750 train_time:311712ms step_avg:494.00ms
[train step 631] avg_loss=4.372140 main=3.904100 aux=0.468040 imp_cv2=0.2778 load_cv2=5.1917 usage_frac=0.4241 topk_prob_mean=0.2996 ema_alpha_reverse=nan max_logit=12.7744
step:632/1750 train_time:312218ms step_avg:494.02ms
[train step 632] avg_loss=3.851104 main=3.388487 aux=0.462617 imp_cv2=0.2673 load_cv2=5.1346 usage_frac=0.4196 topk_prob_mean=0.2999 ema_alpha_reverse=nan max_logit=12.7744
step:633/1750 train_time:312717ms step_avg:494.02ms
[train step 633] avg_loss=4.068997 main=3.609452 aux=0.459545 imp_cv2=0.3014 load_cv2=5.0675 usage_frac=0.4241 topk_prob_mean=0.3174 ema_alpha_reverse=nan max_logit=12.7744
step:634/1750 train_time:313209ms step_avg:494.02ms
[train step 634] avg_loss=3.830083 main=3.367137 aux=0.462946 imp_cv2=0.3199 load_cv2=5.0886 usage_frac=0.4241 topk_prob_mean=0.3240 ema_alpha_reverse=nan max_logit=12.7744
step:635/1750 train_time:313738ms step_avg:494.08ms
[train step 635] avg_loss=4.175019 main=3.684756 aux=0.490263 imp_cv2=0.2986 load_cv2=5.4443 usage_frac=0.4241 topk_prob_mean=0.2756 ema_alpha_reverse=nan max_logit=12.7744
step:636/1750 train_time:314216ms step_avg:494.05ms
[train step 636] avg_loss=4.087813 main=3.621327 aux=0.466485 imp_cv2=0.3028 load_cv2=5.1479 usage_frac=0.4152 topk_prob_mean=0.3120 ema_alpha_reverse=nan max_logit=12.7744
step:637/1750 train_time:314732ms step_avg:494.08ms
[train step 637] avg_loss=4.191968 main=3.725782 aux=0.466186 imp_cv2=0.3444 load_cv2=5.1023 usage_frac=0.4196 topk_prob_mean=0.3260 ema_alpha_reverse=nan max_logit=12.7744
step:638/1750 train_time:315236ms step_avg:494.10ms
[train step 638] avg_loss=3.849800 main=3.384741 aux=0.465059 imp_cv2=0.4169 load_cv2=5.0162 usage_frac=0.4286 topk_prob_mean=0.3435 ema_alpha_reverse=nan max_logit=12.7744
step:639/1750 train_time:315735ms step_avg:494.11ms
[train step 639] avg_loss=4.029245 main=3.565850 aux=0.463394 imp_cv2=0.2834 load_cv2=5.1338 usage_frac=0.4152 topk_prob_mean=0.3046 ema_alpha_reverse=nan max_logit=12.7744
step:640/1750 train_time:316225ms step_avg:494.10ms
[train step 640] avg_loss=3.806072 main=3.342382 aux=0.463690 imp_cv2=0.3397 load_cv2=5.0709 usage_frac=0.4241 topk_prob_mean=0.3246 ema_alpha_reverse=nan max_logit=12.7744
step:641/1750 train_time:316738ms step_avg:494.13ms
[train step 641] avg_loss=3.938673 main=3.470618 aux=0.468056 imp_cv2=0.3154 load_cv2=5.1578 usage_frac=0.4241 topk_prob_mean=0.3157 ema_alpha_reverse=nan max_logit=12.7744
step:642/1750 train_time:317246ms step_avg:494.15ms
[train step 642] avg_loss=4.281127 main=3.815108 aux=0.466019 imp_cv2=0.2842 load_cv2=5.1544 usage_frac=0.4241 topk_prob_mean=0.3029 ema_alpha_reverse=nan max_logit=12.7744
step:643/1750 train_time:317737ms step_avg:494.15ms
[train step 643] avg_loss=3.761856 main=3.291868 aux=0.469987 imp_cv2=0.4014 load_cv2=5.0836 usage_frac=0.4196 topk_prob_mean=0.3439 ema_alpha_reverse=nan max_logit=12.7744
step:644/1750 train_time:318232ms step_avg:494.15ms
[train step 644] avg_loss=4.136612 main=3.669565 aux=0.467047 imp_cv2=0.2730 load_cv2=5.1787 usage_frac=0.4241 topk_prob_mean=0.3031 ema_alpha_reverse=nan max_logit=12.7744
step:645/1750 train_time:318732ms step_avg:494.16ms
[train step 645] avg_loss=4.186990 main=3.712846 aux=0.474144 imp_cv2=0.2667 load_cv2=5.2806 usage_frac=0.4196 topk_prob_mean=0.2999 ema_alpha_reverse=nan max_logit=12.7744
step:646/1750 train_time:319220ms step_avg:494.15ms
[train step 646] avg_loss=4.062816 main=3.586961 aux=0.475855 imp_cv2=0.3224 load_cv2=5.2359 usage_frac=0.4241 topk_prob_mean=0.3162 ema_alpha_reverse=nan max_logit=12.7744
step:647/1750 train_time:319901ms step_avg:494.44ms
[train step 647] avg_loss=4.210431 main=3.734776 aux=0.475654 imp_cv2=0.2566 load_cv2=5.3046 usage_frac=0.4152 topk_prob_mean=0.2930 ema_alpha_reverse=nan max_logit=12.7744
step:648/1750 train_time:320408ms step_avg:494.46ms
[train step 648] avg_loss=3.669794 main=3.199613 aux=0.470181 imp_cv2=0.3436 load_cv2=5.1485 usage_frac=0.4196 topk_prob_mean=0.3286 ema_alpha_reverse=nan max_logit=12.7744
step:649/1750 train_time:320908ms step_avg:494.47ms
[train step 649] avg_loss=4.843156 main=4.348300 aux=0.494856 imp_cv2=0.2490 load_cv2=5.5453 usage_frac=0.4196 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=12.7744
step:650/1750 train_time:321578ms step_avg:494.74ms
Running validation...
step:650/1750 val_loss:3.603584 train_time:321590ms step_avg:494.75ms
[train step 650] avg_loss=4.081351 main=3.571819 aux=0.509533 imp_cv2=0.2623 load_cv2=5.7002 usage_frac=0.3839 topk_prob_mean=0.2486 ema_alpha_reverse=nan max_logit=10.3509
step:651/1750 train_time:322063ms step_avg:494.72ms
[train step 651] avg_loss=4.153146 main=3.676802 aux=0.476344 imp_cv2=0.2521 load_cv2=5.3148 usage_frac=0.4196 topk_prob_mean=0.2902 ema_alpha_reverse=nan max_logit=12.7744
step:652/1750 train_time:322722ms step_avg:494.97ms
[train step 652] avg_loss=3.755833 main=3.283656 aux=0.472177 imp_cv2=0.3798 load_cv2=5.1337 usage_frac=0.4152 topk_prob_mean=0.3398 ema_alpha_reverse=nan max_logit=12.7744
step:653/1750 train_time:323227ms step_avg:494.99ms
[train step 653] avg_loss=3.890244 main=3.416529 aux=0.473715 imp_cv2=0.2920 load_cv2=5.2495 usage_frac=0.4196 topk_prob_mean=0.3112 ema_alpha_reverse=nan max_logit=12.7744
step:654/1750 train_time:323725ms step_avg:494.99ms
[train step 654] avg_loss=5.015147 main=4.543584 aux=0.471563 imp_cv2=0.2404 load_cv2=5.2689 usage_frac=0.4241 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=12.7437
step:655/1750 train_time:324228ms step_avg:495.00ms
[train step 655] avg_loss=3.874581 main=3.410974 aux=0.463607 imp_cv2=0.3763 load_cv2=5.0257 usage_frac=0.4196 topk_prob_mean=0.3432 ema_alpha_reverse=nan max_logit=12.7744
step:656/1750 train_time:324740ms step_avg:495.03ms
[train step 656] avg_loss=3.886964 main=3.419816 aux=0.467148 imp_cv2=0.3882 load_cv2=5.0513 usage_frac=0.4152 topk_prob_mean=0.3419 ema_alpha_reverse=nan max_logit=12.7744
step:657/1750 train_time:325241ms step_avg:495.04ms
[train step 657] avg_loss=4.561959 main=4.083161 aux=0.478798 imp_cv2=0.2480 load_cv2=5.3436 usage_frac=0.4241 topk_prob_mean=0.2888 ema_alpha_reverse=nan max_logit=12.7744
step:658/1750 train_time:325734ms step_avg:495.04ms
[train step 658] avg_loss=3.803493 main=3.343668 aux=0.459825 imp_cv2=0.3667 load_cv2=4.9860 usage_frac=0.4152 topk_prob_mean=0.3438 ema_alpha_reverse=nan max_logit=12.7744
step:659/1750 train_time:326253ms step_avg:495.07ms
[train step 659] avg_loss=3.760979 main=3.302406 aux=0.458573 imp_cv2=0.3325 load_cv2=5.0053 usage_frac=0.4241 topk_prob_mean=0.3325 ema_alpha_reverse=nan max_logit=13.1512
step:660/1750 train_time:326744ms step_avg:495.07ms
[train step 660] avg_loss=3.946892 main=3.489888 aux=0.457003 imp_cv2=0.2884 load_cv2=5.0449 usage_frac=0.4107 topk_prob_mean=0.3210 ema_alpha_reverse=nan max_logit=12.7744
step:661/1750 train_time:327235ms step_avg:495.06ms
[train step 661] avg_loss=3.850194 main=3.387985 aux=0.462209 imp_cv2=0.3284 load_cv2=5.0607 usage_frac=0.4107 topk_prob_mean=0.3316 ema_alpha_reverse=nan max_logit=12.7744
step:662/1750 train_time:327744ms step_avg:495.08ms
[train step 662] avg_loss=4.162930 main=3.697197 aux=0.465733 imp_cv2=0.2560 load_cv2=5.1844 usage_frac=0.4107 topk_prob_mean=0.3050 ema_alpha_reverse=nan max_logit=12.7744
step:663/1750 train_time:328233ms step_avg:495.07ms
[train step 663] avg_loss=4.053862 main=3.585896 aux=0.467966 imp_cv2=0.2296 load_cv2=5.2403 usage_frac=0.4196 topk_prob_mean=0.2911 ema_alpha_reverse=nan max_logit=12.5842
step:664/1750 train_time:328714ms step_avg:495.05ms
[train step 664] avg_loss=4.083801 main=3.613698 aux=0.470103 imp_cv2=0.2341 load_cv2=5.2607 usage_frac=0.4152 topk_prob_mean=0.2932 ema_alpha_reverse=nan max_logit=11.7917
step:665/1750 train_time:329204ms step_avg:495.04ms
[train step 665] avg_loss=3.917944 main=3.452502 aux=0.465442 imp_cv2=0.2663 load_cv2=5.1685 usage_frac=0.4330 topk_prob_mean=0.3107 ema_alpha_reverse=nan max_logit=12.7744
step:666/1750 train_time:329695ms step_avg:495.04ms
[train step 666] avg_loss=4.137487 main=3.668948 aux=0.468538 imp_cv2=0.2862 load_cv2=5.1862 usage_frac=0.4286 topk_prob_mean=0.3125 ema_alpha_reverse=nan max_logit=12.7744
step:667/1750 train_time:330189ms step_avg:495.04ms
[train step 667] avg_loss=3.956398 main=3.491649 aux=0.464749 imp_cv2=0.2355 load_cv2=5.1917 usage_frac=0.4241 topk_prob_mean=0.2976 ema_alpha_reverse=nan max_logit=12.4878
step:668/1750 train_time:330684ms step_avg:495.04ms
[train step 668] avg_loss=4.479252 main=4.007770 aux=0.471482 imp_cv2=0.2366 load_cv2=5.2724 usage_frac=0.4152 topk_prob_mean=0.2884 ema_alpha_reverse=nan max_logit=11.7917
step:669/1750 train_time:331175ms step_avg:495.03ms
[train step 669] avg_loss=3.865941 main=3.403397 aux=0.462544 imp_cv2=0.3487 load_cv2=5.0489 usage_frac=0.4286 topk_prob_mean=0.3351 ema_alpha_reverse=nan max_logit=12.7744
step:670/1750 train_time:331675ms step_avg:495.04ms
[train step 670] avg_loss=4.414757 main=3.926187 aux=0.488569 imp_cv2=0.2126 load_cv2=5.4934 usage_frac=0.4241 topk_prob_mean=0.2657 ema_alpha_reverse=nan max_logit=11.7917
step:671/1750 train_time:332185ms step_avg:495.06ms
[train step 671] avg_loss=3.787972 main=3.320769 aux=0.467203 imp_cv2=0.2977 load_cv2=5.1700 usage_frac=0.4241 topk_prob_mean=0.3182 ema_alpha_reverse=nan max_logit=12.2820
step:672/1750 train_time:332676ms step_avg:495.05ms
[train step 672] avg_loss=3.707136 main=3.244535 aux=0.462600 imp_cv2=0.3002 load_cv2=5.1025 usage_frac=0.4330 topk_prob_mean=0.3210 ema_alpha_reverse=nan max_logit=11.8882
step:673/1750 train_time:333158ms step_avg:495.03ms
[train step 673] avg_loss=3.866304 main=3.399982 aux=0.466322 imp_cv2=0.2781 load_cv2=5.1706 usage_frac=0.4330 topk_prob_mean=0.3125 ema_alpha_reverse=nan max_logit=12.7744
step:674/1750 train_time:333642ms step_avg:495.02ms
[train step 674] avg_loss=4.226427 main=3.755326 aux=0.471101 imp_cv2=0.2371 load_cv2=5.2744 usage_frac=0.4196 topk_prob_mean=0.2957 ema_alpha_reverse=nan max_logit=11.7917
step:675/1750 train_time:334137ms step_avg:495.02ms
[train step 675] avg_loss=3.928062 main=3.455651 aux=0.472411 imp_cv2=0.2756 load_cv2=5.2509 usage_frac=0.4286 topk_prob_mean=0.3082 ema_alpha_reverse=nan max_logit=12.7744
step:676/1750 train_time:334620ms step_avg:495.00ms
[train step 676] avg_loss=4.918413 main=4.434721 aux=0.483692 imp_cv2=0.2009 load_cv2=5.4607 usage_frac=0.4152 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=11.7917
step:677/1750 train_time:335110ms step_avg:494.99ms
[train step 677] avg_loss=4.116250 main=3.646452 aux=0.469798 imp_cv2=0.2197 load_cv2=5.2755 usage_frac=0.4241 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=11.7917
step:678/1750 train_time:335591ms step_avg:494.97ms
[train step 678] avg_loss=4.012758 main=3.533474 aux=0.479284 imp_cv2=0.2051 load_cv2=5.4023 usage_frac=0.4286 topk_prob_mean=0.2770 ema_alpha_reverse=nan max_logit=12.7744
step:679/1750 train_time:336088ms step_avg:494.98ms
[train step 679] avg_loss=3.948185 main=3.476290 aux=0.471895 imp_cv2=0.2226 load_cv2=5.2987 usage_frac=0.4152 topk_prob_mean=0.2899 ema_alpha_reverse=nan max_logit=11.7917
step:680/1750 train_time:336599ms step_avg:495.00ms
[train step 680] avg_loss=3.893631 main=3.420295 aux=0.473336 imp_cv2=0.3741 load_cv2=5.1642 usage_frac=0.4241 topk_prob_mean=0.3394 ema_alpha_reverse=nan max_logit=12.7744
step:681/1750 train_time:337110ms step_avg:495.02ms
[train step 681] avg_loss=4.531810 main=4.056828 aux=0.474983 imp_cv2=0.2339 load_cv2=5.3365 usage_frac=0.4107 topk_prob_mean=0.2874 ema_alpha_reverse=nan max_logit=12.6178
step:682/1750 train_time:337587ms step_avg:495.00ms
[train step 682] avg_loss=4.365330 main=3.891791 aux=0.473539 imp_cv2=0.2279 load_cv2=5.3149 usage_frac=0.4196 topk_prob_mean=0.2848 ema_alpha_reverse=nan max_logit=12.3849
step:683/1750 train_time:338073ms step_avg:494.98ms
[train step 683] avg_loss=4.546155 main=4.067255 aux=0.478899 imp_cv2=0.2136 load_cv2=5.3999 usage_frac=0.4152 topk_prob_mean=0.2705 ema_alpha_reverse=nan max_logit=11.7917
step:684/1750 train_time:338566ms step_avg:494.98ms
[train step 684] avg_loss=3.656453 main=3.188306 aux=0.468148 imp_cv2=0.3439 load_cv2=5.1275 usage_frac=0.4062 topk_prob_mean=0.3336 ema_alpha_reverse=nan max_logit=11.7917
step:685/1750 train_time:339074ms step_avg:495.00ms
[train step 685] avg_loss=4.257168 main=3.780055 aux=0.477112 imp_cv2=0.2039 load_cv2=5.3828 usage_frac=0.4107 topk_prob_mean=0.2773 ema_alpha_reverse=nan max_logit=11.7917
step:686/1750 train_time:339559ms step_avg:494.98ms
[train step 686] avg_loss=3.944635 main=3.475899 aux=0.468737 imp_cv2=0.2634 load_cv2=5.2252 usage_frac=0.4152 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=12.7744
step:687/1750 train_time:340057ms step_avg:494.99ms
[train step 687] avg_loss=4.078663 main=3.608617 aux=0.470046 imp_cv2=0.2364 load_cv2=5.2675 usage_frac=0.4286 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=12.7744
step:688/1750 train_time:340539ms step_avg:494.97ms
[train step 688] avg_loss=4.413301 main=3.921916 aux=0.491385 imp_cv2=0.2031 load_cv2=5.5488 usage_frac=0.4107 topk_prob_mean=0.2521 ema_alpha_reverse=nan max_logit=11.7917
step:689/1750 train_time:341025ms step_avg:494.96ms
[train step 689] avg_loss=3.802105 main=3.338898 aux=0.463206 imp_cv2=0.2711 load_cv2=5.1396 usage_frac=0.4107 topk_prob_mean=0.3143 ema_alpha_reverse=nan max_logit=12.7744
step:690/1750 train_time:341513ms step_avg:494.95ms
[train step 690] avg_loss=3.748465 main=3.280677 aux=0.467788 imp_cv2=0.2266 load_cv2=5.2361 usage_frac=0.4062 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=11.7917
step:691/1750 train_time:341998ms step_avg:494.93ms
[train step 691] avg_loss=3.893860 main=3.438346 aux=0.455514 imp_cv2=0.2993 load_cv2=5.0131 usage_frac=0.4152 topk_prob_mean=0.3196 ema_alpha_reverse=nan max_logit=12.7744
step:692/1750 train_time:342496ms step_avg:494.94ms
[train step 692] avg_loss=3.495610 main=3.028872 aux=0.466738 imp_cv2=0.3829 load_cv2=5.0512 usage_frac=0.4152 topk_prob_mean=0.3378 ema_alpha_reverse=nan max_logit=12.7744
step:693/1750 train_time:342983ms step_avg:494.93ms
[train step 693] avg_loss=4.051119 main=3.582582 aux=0.468537 imp_cv2=0.2250 load_cv2=5.2482 usage_frac=0.4196 topk_prob_mean=0.2824 ema_alpha_reverse=nan max_logit=11.8673
step:694/1750 train_time:343480ms step_avg:494.93ms
[train step 694] avg_loss=3.908221 main=3.445599 aux=0.462623 imp_cv2=0.3519 load_cv2=5.0338 usage_frac=0.4152 topk_prob_mean=0.3319 ema_alpha_reverse=nan max_logit=12.7744
step:695/1750 train_time:343978ms step_avg:494.93ms
[train step 695] avg_loss=4.152660 main=3.477248 aux=0.675412 imp_cv2=3.4732 load_cv2=4.3054 usage_frac=0.4911 topk_prob_mean=0.8455 ema_alpha_reverse=nan max_logit=13.3472
step:696/1750 train_time:344549ms step_avg:495.04ms
[train step 696] avg_loss=3.736614 main=3.319061 aux=0.417553 imp_cv2=1.0754 load_cv2=3.6653 usage_frac=0.5223 topk_prob_mean=0.5076 ema_alpha_reverse=nan max_logit=13.0249
step:697/1750 train_time:345142ms step_avg:495.18ms
[train step 697] avg_loss=3.872303 main=3.427244 aux=0.445058 imp_cv2=0.3791 load_cv2=4.7481 usage_frac=0.5045 topk_prob_mean=0.3502 ema_alpha_reverse=nan max_logit=12.5515
step:698/1750 train_time:345670ms step_avg:495.23ms
[train step 698] avg_loss=4.143346 main=3.700969 aux=0.442377 imp_cv2=0.3106 load_cv2=4.7925 usage_frac=0.4777 topk_prob_mean=0.3345 ema_alpha_reverse=nan max_logit=12.7744
step:699/1750 train_time:346193ms step_avg:495.27ms
[train step 699] avg_loss=4.063752 main=3.600068 aux=0.463684 imp_cv2=0.2988 load_cv2=5.0536 usage_frac=0.4643 topk_prob_mean=0.3059 ema_alpha_reverse=nan max_logit=12.7744
step:700/1750 train_time:346694ms step_avg:495.28ms
Running validation...
step:700/1750 val_loss:3.574295 train_time:346706ms step_avg:495.29ms
[train step 700] avg_loss=3.791499 main=3.353854 aux=0.437645 imp_cv2=0.2581 load_cv2=4.7991 usage_frac=0.4509 topk_prob_mean=0.3257 ema_alpha_reverse=nan max_logit=11.7917
step:701/1750 train_time:347200ms step_avg:495.29ms
[train step 701] avg_loss=3.836066 main=3.407948 aux=0.428118 imp_cv2=0.2434 load_cv2=4.7106 usage_frac=0.4643 topk_prob_mean=0.3341 ema_alpha_reverse=nan max_logit=12.7744
step:702/1750 train_time:347711ms step_avg:495.32ms
[train step 702] avg_loss=3.794907 main=3.366585 aux=0.428322 imp_cv2=0.2802 load_cv2=4.6808 usage_frac=0.4509 topk_prob_mean=0.3468 ema_alpha_reverse=nan max_logit=12.7744
step:703/1750 train_time:348226ms step_avg:495.34ms
[train step 703] avg_loss=3.941510 main=3.513073 aux=0.428437 imp_cv2=0.1706 load_cv2=4.7946 usage_frac=0.4464 topk_prob_mean=0.3190 ema_alpha_reverse=nan max_logit=11.8276
step:704/1750 train_time:348743ms step_avg:495.37ms
[train step 704] avg_loss=3.917287 main=3.485250 aux=0.432037 imp_cv2=0.1650 load_cv2=4.8417 usage_frac=0.4464 topk_prob_mean=0.3167 ema_alpha_reverse=nan max_logit=11.7917
step:705/1750 train_time:349268ms step_avg:495.42ms
[train step 705] avg_loss=3.691953 main=3.260234 aux=0.431719 imp_cv2=0.1998 load_cv2=4.8007 usage_frac=0.4420 topk_prob_mean=0.3298 ema_alpha_reverse=nan max_logit=11.7952
step:706/1750 train_time:349788ms step_avg:495.45ms
[train step 706] avg_loss=3.760260 main=3.327270 aux=0.432991 imp_cv2=0.2139 load_cv2=4.8044 usage_frac=0.4509 topk_prob_mean=0.3321 ema_alpha_reverse=nan max_logit=12.0499
step:707/1750 train_time:350292ms step_avg:495.46ms
[train step 707] avg_loss=3.821902 main=3.382817 aux=0.439085 imp_cv2=0.1419 load_cv2=4.9537 usage_frac=0.4420 topk_prob_mean=0.3049 ema_alpha_reverse=nan max_logit=12.7744
step:708/1750 train_time:350796ms step_avg:495.47ms
[train step 708] avg_loss=4.096383 main=3.654776 aux=0.441607 imp_cv2=0.1119 load_cv2=5.0147 usage_frac=0.4464 topk_prob_mean=0.2933 ema_alpha_reverse=nan max_logit=13.2936
step:709/1750 train_time:351301ms step_avg:495.49ms
[train step 709] avg_loss=3.866921 main=3.432409 aux=0.434512 imp_cv2=0.1639 load_cv2=4.8733 usage_frac=0.4509 topk_prob_mean=0.3162 ema_alpha_reverse=nan max_logit=13.7570
step:710/1750 train_time:351801ms step_avg:495.49ms
[train step 710] avg_loss=4.008313 main=3.567590 aux=0.440723 imp_cv2=0.1171 load_cv2=5.0001 usage_frac=0.4509 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=13.0616
step:711/1750 train_time:352300ms step_avg:495.50ms
[train step 711] avg_loss=3.838515 main=3.393159 aux=0.445357 imp_cv2=0.1265 load_cv2=5.0440 usage_frac=0.4554 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=13.7570
step:712/1750 train_time:352790ms step_avg:495.49ms
[train step 712] avg_loss=4.527135 main=4.033526 aux=0.493609 imp_cv2=0.0814 load_cv2=5.6582 usage_frac=0.4330 topk_prob_mean=0.2241 ema_alpha_reverse=nan max_logit=12.5734
step:713/1750 train_time:353290ms step_avg:495.50ms
[train step 713] avg_loss=3.668818 main=3.221617 aux=0.447201 imp_cv2=0.1834 load_cv2=5.0036 usage_frac=0.4509 topk_prob_mean=0.3169 ema_alpha_reverse=nan max_logit=13.7570
step:714/1750 train_time:353780ms step_avg:495.49ms
[train step 714] avg_loss=3.611540 main=3.161274 aux=0.450266 imp_cv2=0.2418 load_cv2=4.9740 usage_frac=0.4464 topk_prob_mean=0.3337 ema_alpha_reverse=nan max_logit=12.6410
step:715/1750 train_time:354289ms step_avg:495.51ms
[train step 715] avg_loss=4.029119 main=3.582913 aux=0.446205 imp_cv2=0.1533 load_cv2=5.0237 usage_frac=0.4464 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=13.7570
step:716/1750 train_time:354798ms step_avg:495.53ms
[train step 716] avg_loss=3.618757 main=3.164874 aux=0.453882 imp_cv2=0.0849 load_cv2=5.1936 usage_frac=0.4464 topk_prob_mean=0.2769 ema_alpha_reverse=nan max_logit=13.7570
step:717/1750 train_time:355294ms step_avg:495.53ms
[train step 717] avg_loss=4.693703 main=4.228980 aux=0.464724 imp_cv2=0.0622 load_cv2=5.3446 usage_frac=0.4420 topk_prob_mean=0.2537 ema_alpha_reverse=nan max_logit=13.7570
step:718/1750 train_time:355813ms step_avg:495.56ms
[train step 718] avg_loss=3.925973 main=3.472625 aux=0.453348 imp_cv2=0.1008 load_cv2=5.1685 usage_frac=0.4464 topk_prob_mean=0.2841 ema_alpha_reverse=nan max_logit=12.7744
step:719/1750 train_time:356305ms step_avg:495.56ms
[train step 719] avg_loss=3.977528 main=3.523765 aux=0.453764 imp_cv2=0.1202 load_cv2=5.1563 usage_frac=0.4464 topk_prob_mean=0.2884 ema_alpha_reverse=nan max_logit=12.9575
step:720/1750 train_time:356790ms step_avg:495.54ms
[train step 720] avg_loss=3.828916 main=3.376951 aux=0.451965 imp_cv2=0.0966 load_cv2=5.1589 usage_frac=0.4464 topk_prob_mean=0.2811 ema_alpha_reverse=nan max_logit=13.4562
step:721/1750 train_time:357268ms step_avg:495.52ms
[train step 721] avg_loss=3.772262 main=3.317548 aux=0.454714 imp_cv2=0.0922 load_cv2=5.1963 usage_frac=0.4464 topk_prob_mean=0.2788 ema_alpha_reverse=nan max_logit=13.1091
step:722/1750 train_time:357771ms step_avg:495.53ms
[train step 722] avg_loss=3.806977 main=3.357452 aux=0.449525 imp_cv2=0.1512 load_cv2=5.0755 usage_frac=0.4464 topk_prob_mean=0.3051 ema_alpha_reverse=nan max_logit=13.7570
step:723/1750 train_time:358265ms step_avg:495.52ms
[train step 723] avg_loss=4.291916 main=3.808026 aux=0.483890 imp_cv2=0.0573 load_cv2=5.5828 usage_frac=0.4286 topk_prob_mean=0.2295 ema_alpha_reverse=nan max_logit=13.7570
step:724/1750 train_time:358737ms step_avg:495.49ms
[train step 724] avg_loss=3.754197 main=3.298779 aux=0.455418 imp_cv2=0.1817 load_cv2=5.1063 usage_frac=0.4509 topk_prob_mean=0.3102 ema_alpha_reverse=nan max_logit=13.7570
step:725/1750 train_time:359223ms step_avg:495.48ms
[train step 725] avg_loss=4.196068 main=3.732068 aux=0.464000 imp_cv2=0.0893 load_cv2=5.3074 usage_frac=0.4509 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=13.7570
step:726/1750 train_time:359730ms step_avg:495.50ms
[train step 726] avg_loss=4.121961 main=3.666361 aux=0.455600 imp_cv2=0.1063 load_cv2=5.1949 usage_frac=0.4509 topk_prob_mean=0.2838 ema_alpha_reverse=nan max_logit=13.7570
step:727/1750 train_time:360211ms step_avg:495.48ms
[train step 727] avg_loss=3.879619 main=3.420860 aux=0.458759 imp_cv2=0.1777 load_cv2=5.1535 usage_frac=0.4509 topk_prob_mean=0.3070 ema_alpha_reverse=nan max_logit=13.7570
step:728/1750 train_time:360701ms step_avg:495.47ms
[train step 728] avg_loss=4.479735 main=3.984537 aux=0.495198 imp_cv2=0.0770 load_cv2=5.6823 usage_frac=0.4018 topk_prob_mean=0.2154 ema_alpha_reverse=nan max_logit=9.8264
step:729/1750 train_time:361221ms step_avg:495.50ms
[train step 729] avg_loss=4.175045 main=3.714132 aux=0.460912 imp_cv2=0.1004 load_cv2=5.2561 usage_frac=0.4554 topk_prob_mean=0.2735 ema_alpha_reverse=nan max_logit=13.2867
step:730/1750 train_time:361703ms step_avg:495.48ms
[train step 730] avg_loss=3.826266 main=3.373138 aux=0.453128 imp_cv2=0.1309 load_cv2=5.1334 usage_frac=0.4375 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=11.7917
step:731/1750 train_time:362189ms step_avg:495.47ms
[train step 731] avg_loss=3.879302 main=3.427840 aux=0.451461 imp_cv2=0.1717 load_cv2=5.0666 usage_frac=0.4464 topk_prob_mean=0.3050 ema_alpha_reverse=nan max_logit=12.7744
step:732/1750 train_time:362681ms step_avg:495.47ms
[train step 732] avg_loss=4.253962 main=3.797145 aux=0.456817 imp_cv2=0.1032 load_cv2=5.2115 usage_frac=0.4420 topk_prob_mean=0.2765 ema_alpha_reverse=nan max_logit=12.3638
step:733/1750 train_time:363159ms step_avg:495.44ms
[train step 733] avg_loss=4.008237 main=3.549044 aux=0.459194 imp_cv2=0.1137 load_cv2=5.2223 usage_frac=0.4330 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=11.7917
step:734/1750 train_time:363644ms step_avg:495.43ms
[train step 734] avg_loss=3.737184 main=3.284427 aux=0.452757 imp_cv2=0.2699 load_cv2=4.9802 usage_frac=0.4375 topk_prob_mean=0.3345 ema_alpha_reverse=nan max_logit=12.7744
step:735/1750 train_time:364134ms step_avg:495.42ms
[train step 735] avg_loss=4.235426 main=3.776181 aux=0.459245 imp_cv2=0.1045 load_cv2=5.2354 usage_frac=0.4375 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=11.7917
step:736/1750 train_time:364628ms step_avg:495.42ms
[train step 736] avg_loss=4.278778 main=3.821842 aux=0.456936 imp_cv2=0.0913 load_cv2=5.2218 usage_frac=0.4330 topk_prob_mean=0.2669 ema_alpha_reverse=nan max_logit=11.7917
step:737/1750 train_time:365102ms step_avg:495.39ms
[train step 737] avg_loss=3.757711 main=3.309840 aux=0.447871 imp_cv2=0.1826 load_cv2=5.0218 usage_frac=0.4420 topk_prob_mean=0.3095 ema_alpha_reverse=nan max_logit=11.7917
step:738/1750 train_time:365590ms step_avg:495.38ms
[train step 738] avg_loss=4.087672 main=3.637645 aux=0.450027 imp_cv2=0.1431 load_cv2=5.0819 usage_frac=0.4509 topk_prob_mean=0.2902 ema_alpha_reverse=nan max_logit=11.7917
step:739/1750 train_time:366093ms step_avg:495.39ms
[train step 739] avg_loss=4.216494 main=3.757455 aux=0.459040 imp_cv2=0.0901 load_cv2=5.2549 usage_frac=0.4420 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=11.9215
step:740/1750 train_time:366588ms step_avg:495.39ms
[train step 740] avg_loss=4.244963 main=3.790721 aux=0.454242 imp_cv2=0.0863 load_cv2=5.1978 usage_frac=0.4375 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=11.7917
step:741/1750 train_time:367104ms step_avg:495.42ms
[train step 741] avg_loss=4.164622 main=3.709762 aux=0.454860 imp_cv2=0.1077 load_cv2=5.1824 usage_frac=0.4375 topk_prob_mean=0.2748 ema_alpha_reverse=nan max_logit=11.7917
step:742/1750 train_time:367595ms step_avg:495.41ms
[train step 742] avg_loss=4.117481 main=3.662812 aux=0.454669 imp_cv2=0.0773 load_cv2=5.2103 usage_frac=0.4420 topk_prob_mean=0.2627 ema_alpha_reverse=nan max_logit=11.7917
step:743/1750 train_time:368282ms step_avg:495.67ms
[train step 743] avg_loss=3.872564 main=3.422424 aux=0.450141 imp_cv2=0.1583 load_cv2=5.0674 usage_frac=0.4330 topk_prob_mean=0.2994 ema_alpha_reverse=nan max_logit=11.7917
step:744/1750 train_time:368769ms step_avg:495.66ms
[train step 744] avg_loss=3.978582 main=3.523195 aux=0.455386 imp_cv2=0.1440 load_cv2=5.1491 usage_frac=0.4330 topk_prob_mean=0.2918 ema_alpha_reverse=nan max_logit=11.7917
step:745/1750 train_time:369263ms step_avg:495.65ms
[train step 745] avg_loss=4.299027 main=3.849337 aux=0.449689 imp_cv2=0.1378 load_cv2=5.0871 usage_frac=0.4375 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=11.7917
step:746/1750 train_time:369752ms step_avg:495.65ms
[train step 746] avg_loss=3.874902 main=3.414897 aux=0.460005 imp_cv2=0.1570 load_cv2=5.1896 usage_frac=0.4420 topk_prob_mean=0.2962 ema_alpha_reverse=nan max_logit=11.7917
step:747/1750 train_time:370252ms step_avg:495.65ms
[train step 747] avg_loss=3.786537 main=3.327169 aux=0.459368 imp_cv2=0.1280 load_cv2=5.2164 usage_frac=0.4375 topk_prob_mean=0.2870 ema_alpha_reverse=nan max_logit=11.7917
step:748/1750 train_time:370738ms step_avg:495.64ms
[train step 748] avg_loss=4.080739 main=3.620985 aux=0.459754 imp_cv2=0.1175 load_cv2=5.2317 usage_frac=0.4464 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=11.7917
step:749/1750 train_time:371217ms step_avg:495.62ms
[train step 749] avg_loss=4.422838 main=3.923099 aux=0.499739 imp_cv2=0.0577 load_cv2=5.7825 usage_frac=0.4286 topk_prob_mean=0.2113 ema_alpha_reverse=nan max_logit=11.7917
step:750/1750 train_time:371704ms step_avg:495.61ms
Running validation...
step:750/1750 val_loss:3.479282 train_time:371716ms step_avg:495.62ms
[train step 750] avg_loss=4.420917 main=3.942203 aux=0.478714 imp_cv2=0.0529 load_cv2=5.5284 usage_frac=0.4420 topk_prob_mean=0.2347 ema_alpha_reverse=nan max_logit=11.7917
step:751/1750 train_time:372190ms step_avg:495.59ms
[train step 751] avg_loss=4.301436 main=3.831500 aux=0.469936 imp_cv2=0.0556 load_cv2=5.4126 usage_frac=0.4375 topk_prob_mean=0.2406 ema_alpha_reverse=nan max_logit=11.7917
step:752/1750 train_time:372686ms step_avg:495.59ms
[train step 752] avg_loss=3.939434 main=3.468524 aux=0.470910 imp_cv2=0.0614 load_cv2=5.4221 usage_frac=0.4375 topk_prob_mean=0.2446 ema_alpha_reverse=nan max_logit=11.7917
step:753/1750 train_time:373170ms step_avg:495.58ms
[train step 753] avg_loss=3.938923 main=3.480025 aux=0.458898 imp_cv2=0.1141 load_cv2=5.2143 usage_frac=0.4286 topk_prob_mean=0.2821 ema_alpha_reverse=nan max_logit=11.7917
step:754/1750 train_time:373657ms step_avg:495.57ms
[train step 754] avg_loss=4.148418 main=3.691978 aux=0.456440 imp_cv2=0.1234 load_cv2=5.1768 usage_frac=0.4286 topk_prob_mean=0.2856 ema_alpha_reverse=nan max_logit=11.7917
step:755/1750 train_time:374135ms step_avg:495.54ms
[train step 755] avg_loss=4.741050 main=4.228738 aux=0.512312 imp_cv2=0.0703 load_cv2=5.9025 usage_frac=0.3973 topk_prob_mean=0.2010 ema_alpha_reverse=nan max_logit=10.8091
step:756/1750 train_time:374629ms step_avg:495.54ms
[train step 756] avg_loss=4.357209 main=3.899131 aux=0.458079 imp_cv2=0.0813 load_cv2=5.2391 usage_frac=0.4286 topk_prob_mean=0.2593 ema_alpha_reverse=nan max_logit=11.7917
step:757/1750 train_time:375121ms step_avg:495.54ms
[train step 757] avg_loss=4.174374 main=3.712816 aux=0.461558 imp_cv2=0.0668 load_cv2=5.2919 usage_frac=0.4286 topk_prob_mean=0.2560 ema_alpha_reverse=nan max_logit=11.7917
step:758/1750 train_time:375608ms step_avg:495.53ms
[train step 758] avg_loss=3.342509 main=2.894833 aux=0.447676 imp_cv2=0.2130 load_cv2=4.9678 usage_frac=0.4420 topk_prob_mean=0.3194 ema_alpha_reverse=nan max_logit=11.7917
step:759/1750 train_time:376091ms step_avg:495.51ms
[train step 759] avg_loss=3.626822 main=3.176747 aux=0.450075 imp_cv2=0.1683 load_cv2=5.0451 usage_frac=0.4286 topk_prob_mean=0.3037 ema_alpha_reverse=nan max_logit=11.7917
step:760/1750 train_time:376559ms step_avg:495.47ms
[train step 760] avg_loss=4.193592 main=3.738525 aux=0.455067 imp_cv2=0.0815 load_cv2=5.1930 usage_frac=0.4330 topk_prob_mean=0.2669 ema_alpha_reverse=nan max_logit=11.7917
step:761/1750 train_time:377039ms step_avg:495.45ms
[train step 761] avg_loss=3.958558 main=3.505559 aux=0.452998 imp_cv2=0.1247 load_cv2=5.1208 usage_frac=0.4330 topk_prob_mean=0.2866 ema_alpha_reverse=nan max_logit=11.7917
step:762/1750 train_time:377531ms step_avg:495.45ms
[train step 762] avg_loss=3.833540 main=3.377399 aux=0.456141 imp_cv2=0.1190 load_cv2=5.1637 usage_frac=0.4286 topk_prob_mean=0.2838 ema_alpha_reverse=nan max_logit=11.7917
step:763/1750 train_time:378003ms step_avg:495.42ms
[train step 763] avg_loss=3.749519 main=3.293756 aux=0.455764 imp_cv2=0.1751 load_cv2=5.0976 usage_frac=0.4330 topk_prob_mean=0.3022 ema_alpha_reverse=nan max_logit=11.7917
step:764/1750 train_time:378492ms step_avg:495.41ms
[train step 764] avg_loss=4.271172 main=3.809249 aux=0.461923 imp_cv2=0.0793 load_cv2=5.2798 usage_frac=0.4420 topk_prob_mean=0.2582 ema_alpha_reverse=nan max_logit=11.7917
step:765/1750 train_time:378970ms step_avg:495.39ms
[train step 765] avg_loss=3.694075 main=3.239439 aux=0.454636 imp_cv2=0.1785 load_cv2=5.0833 usage_frac=0.4464 topk_prob_mean=0.3061 ema_alpha_reverse=nan max_logit=12.7744
step:766/1750 train_time:379456ms step_avg:495.37ms
[train step 766] avg_loss=4.012984 main=3.556553 aux=0.456430 imp_cv2=0.0840 load_cv2=5.2145 usage_frac=0.4375 topk_prob_mean=0.2681 ema_alpha_reverse=nan max_logit=11.7917
step:767/1750 train_time:380119ms step_avg:495.59ms
[train step 767] avg_loss=3.682300 main=3.219471 aux=0.462829 imp_cv2=0.0779 load_cv2=5.2939 usage_frac=0.4375 topk_prob_mean=0.2584 ema_alpha_reverse=nan max_logit=11.7917
step:768/1750 train_time:380598ms step_avg:495.57ms
[train step 768] avg_loss=3.630676 main=3.174799 aux=0.455877 imp_cv2=0.1562 load_cv2=5.1279 usage_frac=0.4420 topk_prob_mean=0.2987 ema_alpha_reverse=nan max_logit=11.7917
step:769/1750 train_time:381078ms step_avg:495.55ms
[train step 769] avg_loss=3.596831 main=3.143512 aux=0.453319 imp_cv2=0.1933 load_cv2=5.0556 usage_frac=0.4464 topk_prob_mean=0.3092 ema_alpha_reverse=nan max_logit=12.4456
step:770/1750 train_time:381567ms step_avg:495.54ms
[train step 770] avg_loss=4.077424 main=3.611869 aux=0.465556 imp_cv2=0.0650 load_cv2=5.3419 usage_frac=0.4330 topk_prob_mean=0.2504 ema_alpha_reverse=nan max_logit=12.7744
step:771/1750 train_time:382242ms step_avg:495.77ms
[train step 771] avg_loss=3.681843 main=3.232180 aux=0.449663 imp_cv2=0.1427 load_cv2=5.0715 usage_frac=0.4420 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=11.7917
step:772/1750 train_time:382737ms step_avg:495.77ms
[train step 772] avg_loss=3.690559 main=3.246747 aux=0.443812 imp_cv2=0.1802 load_cv2=4.9628 usage_frac=0.4464 topk_prob_mean=0.3149 ema_alpha_reverse=nan max_logit=11.7917
step:773/1750 train_time:383215ms step_avg:495.75ms
[train step 773] avg_loss=3.848598 main=3.395169 aux=0.453429 imp_cv2=0.1546 load_cv2=5.1096 usage_frac=0.4464 topk_prob_mean=0.3002 ema_alpha_reverse=nan max_logit=12.7744
step:774/1750 train_time:383702ms step_avg:495.74ms
[train step 774] avg_loss=3.516544 main=3.050705 aux=0.465839 imp_cv2=0.0667 load_cv2=5.3480 usage_frac=0.4375 topk_prob_mean=0.2496 ema_alpha_reverse=nan max_logit=11.7917
step:775/1750 train_time:384192ms step_avg:495.73ms
[train step 775] avg_loss=3.963595 main=3.502937 aux=0.460658 imp_cv2=0.1024 load_cv2=5.2492 usage_frac=0.4330 topk_prob_mean=0.2769 ema_alpha_reverse=nan max_logit=11.7917
step:776/1750 train_time:384656ms step_avg:495.69ms
[train step 776] avg_loss=3.865410 main=3.416243 aux=0.449168 imp_cv2=0.1661 load_cv2=5.0469 usage_frac=0.4375 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=11.7917
step:777/1750 train_time:385137ms step_avg:495.67ms
[train step 777] avg_loss=3.656847 main=3.205207 aux=0.451640 imp_cv2=0.1022 load_cv2=5.1419 usage_frac=0.4420 topk_prob_mean=0.2807 ema_alpha_reverse=nan max_logit=11.8604
step:778/1750 train_time:385801ms step_avg:495.89ms
[train step 778] avg_loss=3.677802 main=3.229734 aux=0.448068 imp_cv2=0.1413 load_cv2=5.0542 usage_frac=0.4420 topk_prob_mean=0.2980 ema_alpha_reverse=nan max_logit=11.7917
step:779/1750 train_time:386280ms step_avg:495.87ms
[train step 779] avg_loss=4.432444 main=3.959351 aux=0.473093 imp_cv2=0.0567 load_cv2=5.4483 usage_frac=0.4375 topk_prob_mean=0.2414 ema_alpha_reverse=nan max_logit=11.7917
step:780/1750 train_time:386767ms step_avg:495.86ms
[train step 780] avg_loss=3.614960 main=3.161615 aux=0.453345 imp_cv2=0.1139 load_cv2=5.1455 usage_frac=0.4286 topk_prob_mean=0.2847 ema_alpha_reverse=nan max_logit=11.7917
step:781/1750 train_time:387270ms step_avg:495.86ms
[train step 781] avg_loss=3.813740 main=3.360616 aux=0.453124 imp_cv2=0.1476 load_cv2=5.1110 usage_frac=0.4375 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=11.7917
step:782/1750 train_time:387763ms step_avg:495.86ms
[train step 782] avg_loss=3.736501 main=3.284872 aux=0.451629 imp_cv2=0.1425 load_cv2=5.0900 usage_frac=0.4330 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=11.7917
step:783/1750 train_time:388250ms step_avg:495.85ms
[train step 783] avg_loss=3.751536 main=3.293016 aux=0.458520 imp_cv2=0.1535 load_cv2=5.1646 usage_frac=0.4286 topk_prob_mean=0.2924 ema_alpha_reverse=nan max_logit=11.7917
step:784/1750 train_time:388731ms step_avg:495.83ms
[train step 784] avg_loss=4.016031 main=3.557640 aux=0.458391 imp_cv2=0.1003 load_cv2=5.2238 usage_frac=0.4375 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=11.7917
step:785/1750 train_time:389423ms step_avg:496.08ms
[train step 785] avg_loss=4.074551 main=3.614150 aux=0.460401 imp_cv2=0.0803 load_cv2=5.2687 usage_frac=0.4286 topk_prob_mean=0.2625 ema_alpha_reverse=nan max_logit=11.7917
step:786/1750 train_time:389913ms step_avg:496.07ms
[train step 786] avg_loss=3.494277 main=3.034793 aux=0.459484 imp_cv2=0.2572 load_cv2=5.0592 usage_frac=0.4286 topk_prob_mean=0.3238 ema_alpha_reverse=nan max_logit=11.7917
step:787/1750 train_time:390404ms step_avg:496.07ms
[train step 787] avg_loss=3.971321 main=3.510096 aux=0.461225 imp_cv2=0.0804 load_cv2=5.2803 usage_frac=0.4420 topk_prob_mean=0.2628 ema_alpha_reverse=nan max_logit=11.7917
step:788/1750 train_time:390888ms step_avg:496.05ms
[train step 788] avg_loss=4.164429 main=3.690888 aux=0.473540 imp_cv2=0.0743 load_cv2=5.4264 usage_frac=0.4420 topk_prob_mean=0.2370 ema_alpha_reverse=nan max_logit=11.7917
step:789/1750 train_time:391365ms step_avg:496.03ms
[train step 789] avg_loss=4.734762 main=4.243579 aux=0.491183 imp_cv2=0.0798 load_cv2=5.6343 usage_frac=0.4330 topk_prob_mean=0.2219 ema_alpha_reverse=nan max_logit=11.7917
step:790/1750 train_time:391842ms step_avg:496.00ms
[train step 790] avg_loss=3.686758 main=3.231292 aux=0.455466 imp_cv2=0.1948 load_cv2=5.0786 usage_frac=0.4375 topk_prob_mean=0.3066 ema_alpha_reverse=nan max_logit=11.0098
step:791/1750 train_time:392326ms step_avg:495.99ms
[train step 791] avg_loss=3.983400 main=3.520442 aux=0.462958 imp_cv2=0.0807 load_cv2=5.2986 usage_frac=0.4286 topk_prob_mean=0.2566 ema_alpha_reverse=nan max_logit=11.7917
step:792/1750 train_time:392805ms step_avg:495.97ms
[train step 792] avg_loss=3.791027 main=3.335014 aux=0.456013 imp_cv2=0.1276 load_cv2=5.1600 usage_frac=0.4330 topk_prob_mean=0.2830 ema_alpha_reverse=nan max_logit=12.4208
step:793/1750 train_time:393271ms step_avg:495.93ms
[train step 793] avg_loss=3.690305 main=3.233189 aux=0.457116 imp_cv2=0.1424 load_cv2=5.1506 usage_frac=0.4286 topk_prob_mean=0.2879 ema_alpha_reverse=nan max_logit=11.7917
step:794/1750 train_time:393752ms step_avg:495.91ms
[train step 794] avg_loss=4.716607 main=4.215002 aux=0.501605 imp_cv2=0.0531 load_cv2=5.8004 usage_frac=0.4286 topk_prob_mean=0.2037 ema_alpha_reverse=nan max_logit=11.7917
step:795/1750 train_time:394214ms step_avg:495.87ms
[train step 795] avg_loss=4.105947 main=3.646920 aux=0.459027 imp_cv2=0.1124 load_cv2=5.2141 usage_frac=0.4375 topk_prob_mean=0.2742 ema_alpha_reverse=nan max_logit=11.7917
step:796/1750 train_time:394690ms step_avg:495.84ms
[train step 796] avg_loss=5.598175 main=5.100099 aux=0.498076 imp_cv2=0.0505 load_cv2=5.7523 usage_frac=0.4286 topk_prob_mean=0.2090 ema_alpha_reverse=nan max_logit=11.7917
step:797/1750 train_time:395166ms step_avg:495.82ms
[train step 797] avg_loss=3.895663 main=3.418218 aux=0.477445 imp_cv2=0.0510 load_cv2=5.4999 usage_frac=0.4286 topk_prob_mean=0.2326 ema_alpha_reverse=nan max_logit=11.7917
step:798/1750 train_time:395864ms step_avg:496.07ms
[train step 798] avg_loss=3.582858 main=3.129105 aux=0.453753 imp_cv2=0.1664 load_cv2=5.0934 usage_frac=0.4330 topk_prob_mean=0.2998 ema_alpha_reverse=nan max_logit=12.2889
step:799/1750 train_time:396342ms step_avg:496.05ms
[train step 799] avg_loss=3.976917 main=3.511960 aux=0.464957 imp_cv2=0.0826 load_cv2=5.3229 usage_frac=0.4241 topk_prob_mean=0.2588 ema_alpha_reverse=nan max_logit=11.7917
step:800/1750 train_time:396829ms step_avg:496.04ms
Running validation...
step:800/1750 val_loss:3.431280 train_time:396840ms step_avg:496.05ms
[train step 800] avg_loss=3.636348 main=3.180474 aux=0.455874 imp_cv2=0.1463 load_cv2=5.1410 usage_frac=0.4286 topk_prob_mean=0.2906 ema_alpha_reverse=nan max_logit=12.1604
step:801/1750 train_time:397310ms step_avg:496.02ms
[train step 801] avg_loss=3.543138 main=3.088266 aux=0.454872 imp_cv2=0.1844 load_cv2=5.0911 usage_frac=0.4330 topk_prob_mean=0.3039 ema_alpha_reverse=nan max_logit=11.7917
step:802/1750 train_time:397798ms step_avg:496.01ms
[train step 802] avg_loss=3.633739 main=3.176088 aux=0.457652 imp_cv2=0.1498 load_cv2=5.1568 usage_frac=0.4330 topk_prob_mean=0.2915 ema_alpha_reverse=nan max_logit=11.7917
step:803/1750 train_time:398284ms step_avg:495.99ms
[train step 803] avg_loss=3.827944 main=3.360660 aux=0.467284 imp_cv2=0.1369 load_cv2=5.2854 usage_frac=0.4196 topk_prob_mean=0.2827 ema_alpha_reverse=nan max_logit=11.7917
step:804/1750 train_time:398752ms step_avg:495.96ms
[train step 804] avg_loss=4.453323 main=3.932720 aux=0.520603 imp_cv2=0.0560 load_cv2=6.0088 usage_frac=0.3795 topk_prob_mean=0.1909 ema_alpha_reverse=nan max_logit=9.8264
step:805/1750 train_time:399230ms step_avg:495.94ms
[train step 805] avg_loss=3.965260 main=3.503962 aux=0.461299 imp_cv2=0.1515 load_cv2=5.1972 usage_frac=0.4330 topk_prob_mean=0.2920 ema_alpha_reverse=nan max_logit=12.0086
step:806/1750 train_time:399712ms step_avg:495.92ms
[train step 806] avg_loss=4.126074 main=3.629946 aux=0.496128 imp_cv2=0.0460 load_cv2=5.7358 usage_frac=0.4286 topk_prob_mean=0.2154 ema_alpha_reverse=nan max_logit=12.1042
step:807/1750 train_time:400194ms step_avg:495.90ms
[train step 807] avg_loss=3.633110 main=3.165831 aux=0.467280 imp_cv2=0.1014 load_cv2=5.3213 usage_frac=0.4286 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=11.7917
step:808/1750 train_time:400670ms step_avg:495.88ms
[train step 808] avg_loss=4.257652 main=3.749753 aux=0.507900 imp_cv2=0.1024 load_cv2=5.8132 usage_frac=0.3973 topk_prob_mean=0.2108 ema_alpha_reverse=nan max_logit=10.0104
step:809/1750 train_time:401143ms step_avg:495.85ms
[train step 809] avg_loss=3.525041 main=3.056267 aux=0.468774 imp_cv2=0.1877 load_cv2=5.2500 usage_frac=0.4241 topk_prob_mean=0.3016 ema_alpha_reverse=nan max_logit=11.7917
step:810/1750 train_time:401629ms step_avg:495.84ms
[train step 810] avg_loss=4.001090 main=3.532289 aux=0.468801 imp_cv2=0.1067 load_cv2=5.3375 usage_frac=0.4286 topk_prob_mean=0.2727 ema_alpha_reverse=nan max_logit=12.7744
step:811/1750 train_time:402087ms step_avg:495.79ms
[train step 811] avg_loss=3.858607 main=3.395144 aux=0.463464 imp_cv2=0.1612 load_cv2=5.2185 usage_frac=0.4286 topk_prob_mean=0.2959 ema_alpha_reverse=nan max_logit=12.7744
step:812/1750 train_time:402559ms step_avg:495.76ms
[train step 812] avg_loss=3.780566 main=3.318342 aux=0.462225 imp_cv2=0.1479 load_cv2=5.2120 usage_frac=0.4375 topk_prob_mean=0.2924 ema_alpha_reverse=nan max_logit=12.7744
step:813/1750 train_time:403030ms step_avg:495.73ms
[train step 813] avg_loss=3.675695 main=3.211021 aux=0.464674 imp_cv2=0.0960 load_cv2=5.2991 usage_frac=0.4241 topk_prob_mean=0.2704 ema_alpha_reverse=nan max_logit=11.7917
step:814/1750 train_time:403511ms step_avg:495.71ms
[train step 814] avg_loss=3.954939 main=3.490922 aux=0.464017 imp_cv2=0.1294 load_cv2=5.2548 usage_frac=0.4286 topk_prob_mean=0.2835 ema_alpha_reverse=nan max_logit=12.4339
step:815/1750 train_time:403980ms step_avg:495.68ms
[train step 815] avg_loss=3.990667 main=3.525807 aux=0.464860 imp_cv2=0.1208 load_cv2=5.2842 usage_frac=0.4286 topk_prob_mean=0.2801 ema_alpha_reverse=nan max_logit=11.7917
step:816/1750 train_time:404453ms step_avg:495.65ms
[train step 816] avg_loss=3.735647 main=3.272255 aux=0.463392 imp_cv2=0.2088 load_cv2=5.1652 usage_frac=0.4420 topk_prob_mean=0.3081 ema_alpha_reverse=nan max_logit=11.7917
step:817/1750 train_time:404939ms step_avg:495.64ms
[train step 817] avg_loss=4.052194 main=3.581430 aux=0.470764 imp_cv2=0.0809 load_cv2=5.3963 usage_frac=0.4241 topk_prob_mean=0.2587 ema_alpha_reverse=nan max_logit=11.7917
step:818/1750 train_time:405402ms step_avg:495.60ms
[train step 818] avg_loss=4.517383 main=4.045352 aux=0.472031 imp_cv2=0.0885 load_cv2=5.4020 usage_frac=0.4330 topk_prob_mean=0.2630 ema_alpha_reverse=nan max_logit=11.7917
step:819/1750 train_time:405886ms step_avg:495.59ms
[train step 819] avg_loss=3.967222 main=3.482800 aux=0.484422 imp_cv2=0.0660 load_cv2=5.5703 usage_frac=0.4330 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=11.7917
step:820/1750 train_time:406352ms step_avg:495.55ms
[train step 820] avg_loss=4.078565 main=3.602534 aux=0.476031 imp_cv2=0.0895 load_cv2=5.4497 usage_frac=0.4330 topk_prob_mean=0.2597 ema_alpha_reverse=nan max_logit=11.7917
step:821/1750 train_time:406824ms step_avg:495.52ms
[train step 821] avg_loss=3.805636 main=3.333856 aux=0.471780 imp_cv2=0.2399 load_cv2=5.2274 usage_frac=0.4420 topk_prob_mean=0.3154 ema_alpha_reverse=nan max_logit=12.7744
step:822/1750 train_time:407323ms step_avg:495.53ms
[train step 822] avg_loss=4.228150 main=3.750044 aux=0.478106 imp_cv2=0.0880 load_cv2=5.4762 usage_frac=0.4375 topk_prob_mean=0.2562 ema_alpha_reverse=nan max_logit=11.7917
step:823/1750 train_time:407782ms step_avg:495.48ms
[train step 823] avg_loss=3.826804 main=3.355712 aux=0.471092 imp_cv2=0.1937 load_cv2=5.2693 usage_frac=0.4286 topk_prob_mean=0.3022 ema_alpha_reverse=nan max_logit=12.7744
step:824/1750 train_time:408255ms step_avg:495.45ms
[train step 824] avg_loss=3.329917 main=2.867286 aux=0.462631 imp_cv2=0.1666 load_cv2=5.1996 usage_frac=0.4330 topk_prob_mean=0.2989 ema_alpha_reverse=nan max_logit=11.7917
step:825/1750 train_time:408731ms step_avg:495.43ms
[train step 825] avg_loss=4.746025 main=4.269265 aux=0.476760 imp_cv2=0.1112 load_cv2=5.4342 usage_frac=0.4286 topk_prob_mean=0.2634 ema_alpha_reverse=nan max_logit=11.7917
step:826/1750 train_time:409209ms step_avg:495.41ms
[train step 826] avg_loss=3.485957 main=3.010910 aux=0.475047 imp_cv2=0.3174 load_cv2=5.1872 usage_frac=0.4330 topk_prob_mean=0.3355 ema_alpha_reverse=nan max_logit=11.8769
step:827/1750 train_time:409695ms step_avg:495.40ms
[train step 827] avg_loss=3.623355 main=3.149683 aux=0.473672 imp_cv2=0.2383 load_cv2=5.2528 usage_frac=0.4286 topk_prob_mean=0.3126 ema_alpha_reverse=nan max_logit=11.7917
step:828/1750 train_time:410184ms step_avg:495.39ms
[train step 828] avg_loss=4.069037 main=3.601058 aux=0.467980 imp_cv2=0.1189 load_cv2=5.3128 usage_frac=0.4196 topk_prob_mean=0.2757 ema_alpha_reverse=nan max_logit=11.7917
step:829/1750 train_time:410669ms step_avg:495.38ms
[train step 829] avg_loss=4.073083 main=3.599732 aux=0.473351 imp_cv2=0.1044 load_cv2=5.3970 usage_frac=0.4241 topk_prob_mean=0.2656 ema_alpha_reverse=nan max_logit=11.7917
step:830/1750 train_time:411138ms step_avg:495.35ms
[train step 830] avg_loss=3.967237 main=3.497684 aux=0.469554 imp_cv2=0.1067 load_cv2=5.3478 usage_frac=0.4375 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=11.7917
step:831/1750 train_time:411610ms step_avg:495.32ms
[train step 831] avg_loss=3.640155 main=3.169345 aux=0.470809 imp_cv2=0.1804 load_cv2=5.2862 usage_frac=0.4330 topk_prob_mean=0.2965 ema_alpha_reverse=nan max_logit=11.7917
step:832/1750 train_time:412097ms step_avg:495.31ms
[train step 832] avg_loss=4.222192 main=3.756828 aux=0.465364 imp_cv2=0.1511 load_cv2=5.2546 usage_frac=0.4375 topk_prob_mean=0.2887 ema_alpha_reverse=nan max_logit=11.7917
step:833/1750 train_time:412571ms step_avg:495.28ms
[train step 833] avg_loss=4.100649 main=3.633353 aux=0.467295 imp_cv2=0.1231 load_cv2=5.3065 usage_frac=0.4375 topk_prob_mean=0.2779 ema_alpha_reverse=nan max_logit=11.7917
step:834/1750 train_time:413049ms step_avg:495.26ms
[train step 834] avg_loss=3.637965 main=3.168770 aux=0.469195 imp_cv2=0.2652 load_cv2=5.1713 usage_frac=0.4330 topk_prob_mean=0.3243 ema_alpha_reverse=nan max_logit=11.7917
step:835/1750 train_time:413537ms step_avg:495.25ms
[train step 835] avg_loss=3.758972 main=3.292755 aux=0.466217 imp_cv2=0.1849 load_cv2=5.2231 usage_frac=0.4286 topk_prob_mean=0.3019 ema_alpha_reverse=nan max_logit=11.7917
step:836/1750 train_time:414015ms step_avg:495.23ms
[train step 836] avg_loss=3.929812 main=3.467381 aux=0.462431 imp_cv2=0.1174 load_cv2=5.2500 usage_frac=0.4420 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=13.1744
step:837/1750 train_time:414491ms step_avg:495.21ms
[train step 837] avg_loss=3.900336 main=3.439899 aux=0.460436 imp_cv2=0.1485 load_cv2=5.1913 usage_frac=0.4330 topk_prob_mean=0.2933 ema_alpha_reverse=nan max_logit=11.7917
step:838/1750 train_time:414965ms step_avg:495.18ms
[train step 838] avg_loss=3.878922 main=3.417140 aux=0.461782 imp_cv2=0.1569 load_cv2=5.1996 usage_frac=0.4330 topk_prob_mean=0.2926 ema_alpha_reverse=nan max_logit=11.8657
step:839/1750 train_time:415458ms step_avg:495.18ms
[train step 839] avg_loss=3.882090 main=3.424886 aux=0.457205 imp_cv2=0.1388 load_cv2=5.1670 usage_frac=0.4286 topk_prob_mean=0.2897 ema_alpha_reverse=nan max_logit=12.1069
step:840/1750 train_time:415945ms step_avg:495.17ms
[train step 840] avg_loss=3.590832 main=3.136223 aux=0.454609 imp_cv2=0.2064 load_cv2=5.0603 usage_frac=0.4241 topk_prob_mean=0.3153 ema_alpha_reverse=nan max_logit=11.7917
step:841/1750 train_time:416428ms step_avg:495.16ms
[train step 841] avg_loss=4.087984 main=3.628217 aux=0.459768 imp_cv2=0.1400 load_cv2=5.1989 usage_frac=0.4286 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=11.7917
step:842/1750 train_time:416906ms step_avg:495.14ms
[train step 842] avg_loss=4.327494 main=3.859182 aux=0.468312 imp_cv2=0.0889 load_cv2=5.3704 usage_frac=0.4196 topk_prob_mean=0.2581 ema_alpha_reverse=nan max_logit=11.7917
step:843/1750 train_time:417395ms step_avg:495.13ms
[train step 843] avg_loss=3.703414 main=3.241282 aux=0.462131 imp_cv2=0.1325 load_cv2=5.2327 usage_frac=0.4286 topk_prob_mean=0.2864 ema_alpha_reverse=nan max_logit=11.7917
step:844/1750 train_time:417872ms step_avg:495.11ms
[train step 844] avg_loss=3.770559 main=3.313032 aux=0.457527 imp_cv2=0.2235 load_cv2=5.0774 usage_frac=0.4286 topk_prob_mean=0.3166 ema_alpha_reverse=nan max_logit=11.7917
step:845/1750 train_time:418367ms step_avg:495.11ms
[train step 845] avg_loss=4.091033 main=3.630043 aux=0.460990 imp_cv2=0.1028 load_cv2=5.2534 usage_frac=0.4196 topk_prob_mean=0.2718 ema_alpha_reverse=nan max_logit=11.7917
step:846/1750 train_time:418831ms step_avg:495.07ms
[train step 846] avg_loss=3.486626 main=3.028278 aux=0.458348 imp_cv2=0.2042 load_cv2=5.1096 usage_frac=0.4241 topk_prob_mean=0.3128 ema_alpha_reverse=nan max_logit=11.7917
step:847/1750 train_time:419302ms step_avg:495.04ms
[train step 847] avg_loss=4.021309 main=3.548924 aux=0.472385 imp_cv2=0.0881 load_cv2=5.4100 usage_frac=0.4196 topk_prob_mean=0.2610 ema_alpha_reverse=nan max_logit=11.7917
step:848/1750 train_time:419773ms step_avg:495.02ms
[train step 848] avg_loss=3.682699 main=3.219384 aux=0.463315 imp_cv2=0.1199 load_cv2=5.2624 usage_frac=0.4196 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=11.7917
step:849/1750 train_time:420234ms step_avg:494.97ms
[train step 849] avg_loss=3.900578 main=3.440269 aux=0.460309 imp_cv2=0.1211 load_cv2=5.2223 usage_frac=0.4196 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=11.7917
step:850/1750 train_time:420711ms step_avg:494.95ms
Running validation...
step:850/1750 val_loss:3.388148 train_time:420722ms step_avg:494.97ms
[train step 850] avg_loss=3.848371 main=3.388919 aux=0.459452 imp_cv2=0.1696 load_cv2=5.1594 usage_frac=0.4286 topk_prob_mean=0.2984 ema_alpha_reverse=nan max_logit=11.7917
step:851/1750 train_time:421204ms step_avg:494.95ms
[train step 851] avg_loss=3.771881 main=3.309317 aux=0.462564 imp_cv2=0.1675 load_cv2=5.1981 usage_frac=0.4286 topk_prob_mean=0.2992 ema_alpha_reverse=nan max_logit=11.7917
step:852/1750 train_time:421676ms step_avg:494.93ms
[train step 852] avg_loss=3.843789 main=3.376740 aux=0.467049 imp_cv2=0.0883 load_cv2=5.3430 usage_frac=0.4196 topk_prob_mean=0.2659 ema_alpha_reverse=nan max_logit=11.7917
step:853/1750 train_time:422148ms step_avg:494.90ms
[train step 853] avg_loss=4.355016 main=3.875742 aux=0.479274 imp_cv2=0.0607 load_cv2=5.5199 usage_frac=0.4241 topk_prob_mean=0.2408 ema_alpha_reverse=nan max_logit=11.7917
step:854/1750 train_time:422603ms step_avg:494.85ms
[train step 854] avg_loss=4.094103 main=3.632008 aux=0.462094 imp_cv2=0.1250 load_cv2=5.2392 usage_frac=0.4196 topk_prob_mean=0.2826 ema_alpha_reverse=nan max_logit=11.7917
step:855/1750 train_time:423074ms step_avg:494.82ms
[train step 855] avg_loss=4.615738 main=4.125838 aux=0.489900 imp_cv2=0.0567 load_cv2=5.6634 usage_frac=0.4152 topk_prob_mean=0.2311 ema_alpha_reverse=nan max_logit=11.7917
step:856/1750 train_time:423545ms step_avg:494.80ms
[train step 856] avg_loss=4.091405 main=3.592686 aux=0.498719 imp_cv2=0.2174 load_cv2=5.5838 usage_frac=0.4107 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=11.7917
step:857/1750 train_time:424022ms step_avg:494.78ms
[train step 857] avg_loss=3.514400 main=3.050225 aux=0.464175 imp_cv2=0.1583 load_cv2=5.2296 usage_frac=0.4241 topk_prob_mean=0.2949 ema_alpha_reverse=nan max_logit=11.7917
step:858/1750 train_time:424486ms step_avg:494.74ms
[train step 858] avg_loss=3.836068 main=3.359407 aux=0.476661 imp_cv2=0.0873 load_cv2=5.4655 usage_frac=0.4241 topk_prob_mean=0.2595 ema_alpha_reverse=nan max_logit=11.7917
step:859/1750 train_time:424953ms step_avg:494.71ms
[train step 859] avg_loss=4.126207 main=3.654905 aux=0.471302 imp_cv2=0.1238 load_cv2=5.3569 usage_frac=0.4286 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=11.7917
step:860/1750 train_time:425434ms step_avg:494.69ms
[train step 860] avg_loss=4.060865 main=3.589805 aux=0.471060 imp_cv2=0.1133 load_cv2=5.3765 usage_frac=0.4196 topk_prob_mean=0.2709 ema_alpha_reverse=nan max_logit=11.7917
step:861/1750 train_time:425918ms step_avg:494.68ms
[train step 861] avg_loss=3.858750 main=3.390740 aux=0.468010 imp_cv2=0.1636 load_cv2=5.2736 usage_frac=0.4241 topk_prob_mean=0.2926 ema_alpha_reverse=nan max_logit=11.7917
step:862/1750 train_time:426390ms step_avg:494.65ms
[train step 862] avg_loss=3.794042 main=3.325775 aux=0.468267 imp_cv2=0.1747 load_cv2=5.2625 usage_frac=0.4241 topk_prob_mean=0.2976 ema_alpha_reverse=nan max_logit=11.7917
step:863/1750 train_time:426870ms step_avg:494.64ms
[train step 863] avg_loss=3.678504 main=3.209753 aux=0.468751 imp_cv2=0.1866 load_cv2=5.2531 usage_frac=0.4286 topk_prob_mean=0.2999 ema_alpha_reverse=nan max_logit=11.9628
step:864/1750 train_time:427353ms step_avg:494.62ms
[train step 864] avg_loss=3.835733 main=3.372563 aux=0.463171 imp_cv2=0.1231 load_cv2=5.2568 usage_frac=0.4241 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=11.7917
step:865/1750 train_time:427816ms step_avg:494.58ms
[train step 865] avg_loss=3.877783 main=3.408283 aux=0.469500 imp_cv2=0.1555 load_cv2=5.2964 usage_frac=0.4152 topk_prob_mean=0.2873 ema_alpha_reverse=nan max_logit=11.7917
step:866/1750 train_time:428291ms step_avg:494.56ms
[train step 866] avg_loss=4.008527 main=3.544663 aux=0.463864 imp_cv2=0.1218 load_cv2=5.2629 usage_frac=0.4330 topk_prob_mean=0.2784 ema_alpha_reverse=nan max_logit=12.2748
step:867/1750 train_time:428773ms step_avg:494.55ms
[train step 867] avg_loss=3.559348 main=3.093440 aux=0.465908 imp_cv2=0.2160 load_cv2=5.1888 usage_frac=0.4330 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=11.7917
step:868/1750 train_time:429267ms step_avg:494.55ms
[train step 868] avg_loss=3.879932 main=3.413100 aux=0.466832 imp_cv2=0.1156 load_cv2=5.3091 usage_frac=0.4286 topk_prob_mean=0.2760 ema_alpha_reverse=nan max_logit=11.7917
step:869/1750 train_time:429756ms step_avg:494.54ms
[train step 869] avg_loss=3.724347 main=3.262395 aux=0.461952 imp_cv2=0.1569 load_cv2=5.2017 usage_frac=0.4375 topk_prob_mean=0.2922 ema_alpha_reverse=nan max_logit=12.2929
step:870/1750 train_time:430230ms step_avg:494.52ms
[train step 870] avg_loss=3.673351 main=3.212029 aux=0.461323 imp_cv2=0.2344 load_cv2=5.1113 usage_frac=0.4420 topk_prob_mean=0.3154 ema_alpha_reverse=nan max_logit=11.8877
step:871/1750 train_time:430711ms step_avg:494.50ms
[train step 871] avg_loss=3.475414 main=3.008144 aux=0.467270 imp_cv2=0.2802 load_cv2=5.1391 usage_frac=0.4286 topk_prob_mean=0.3266 ema_alpha_reverse=nan max_logit=11.7917
step:872/1750 train_time:431208ms step_avg:494.50ms
[train step 872] avg_loss=3.724632 main=3.259796 aux=0.464836 imp_cv2=0.1469 load_cv2=5.2564 usage_frac=0.4196 topk_prob_mean=0.2872 ema_alpha_reverse=nan max_logit=11.7917
step:873/1750 train_time:431689ms step_avg:494.49ms
[train step 873] avg_loss=4.128436 main=3.661561 aux=0.466875 imp_cv2=0.1345 load_cv2=5.2912 usage_frac=0.4330 topk_prob_mean=0.2795 ema_alpha_reverse=nan max_logit=11.7917
step:874/1750 train_time:432168ms step_avg:494.47ms
[train step 874] avg_loss=3.966128 main=3.498554 aux=0.467573 imp_cv2=0.1056 load_cv2=5.3337 usage_frac=0.4241 topk_prob_mean=0.2685 ema_alpha_reverse=nan max_logit=11.7917
step:875/1750 train_time:432826ms step_avg:494.66ms
[train step 875] avg_loss=3.939517 main=3.472165 aux=0.467352 imp_cv2=0.1416 load_cv2=5.2898 usage_frac=0.4286 topk_prob_mean=0.2829 ema_alpha_reverse=nan max_logit=11.7917
step:876/1750 train_time:433313ms step_avg:494.65ms
[train step 876] avg_loss=3.469112 main=3.006202 aux=0.462911 imp_cv2=0.2608 load_cv2=5.1034 usage_frac=0.4330 topk_prob_mean=0.3217 ema_alpha_reverse=nan max_logit=11.7917
step:877/1750 train_time:433794ms step_avg:494.63ms
[train step 877] avg_loss=3.690526 main=3.227153 aux=0.463373 imp_cv2=0.1611 load_cv2=5.2204 usage_frac=0.4286 topk_prob_mean=0.2922 ema_alpha_reverse=nan max_logit=11.7917
step:878/1750 train_time:434285ms step_avg:494.63ms
[train step 878] avg_loss=3.788108 main=3.325375 aux=0.462733 imp_cv2=0.1736 load_cv2=5.1970 usage_frac=0.4420 topk_prob_mean=0.2961 ema_alpha_reverse=nan max_logit=11.7917
step:879/1750 train_time:434767ms step_avg:494.62ms
[train step 879] avg_loss=3.867117 main=3.380206 aux=0.486911 imp_cv2=0.0603 load_cv2=5.6174 usage_frac=0.4107 topk_prob_mean=0.2352 ema_alpha_reverse=nan max_logit=11.7917
step:880/1750 train_time:435257ms step_avg:494.61ms
[train step 880] avg_loss=3.922195 main=3.459695 aux=0.462500 imp_cv2=0.1617 load_cv2=5.2063 usage_frac=0.4152 topk_prob_mean=0.2920 ema_alpha_reverse=nan max_logit=11.7917
step:881/1750 train_time:435732ms step_avg:494.59ms
[train step 881] avg_loss=4.078697 main=3.604722 aux=0.473975 imp_cv2=0.0944 load_cv2=5.4191 usage_frac=0.4196 topk_prob_mean=0.2608 ema_alpha_reverse=nan max_logit=11.7917
step:882/1750 train_time:436203ms step_avg:494.56ms
[train step 882] avg_loss=4.112184 main=3.625880 aux=0.486303 imp_cv2=0.0483 load_cv2=5.6169 usage_frac=0.4152 topk_prob_mean=0.2222 ema_alpha_reverse=nan max_logit=11.7917
step:883/1750 train_time:436669ms step_avg:494.53ms
[train step 883] avg_loss=3.918023 main=3.447213 aux=0.470810 imp_cv2=0.1106 load_cv2=5.3617 usage_frac=0.4152 topk_prob_mean=0.2692 ema_alpha_reverse=nan max_logit=11.7917
step:884/1750 train_time:437148ms step_avg:494.51ms
[train step 884] avg_loss=3.706326 main=3.238440 aux=0.467886 imp_cv2=0.1373 load_cv2=5.3006 usage_frac=0.4196 topk_prob_mean=0.2820 ema_alpha_reverse=nan max_logit=11.7917
step:885/1750 train_time:437614ms step_avg:494.48ms
[train step 885] avg_loss=3.608348 main=3.140726 aux=0.467621 imp_cv2=0.0966 load_cv2=5.3401 usage_frac=0.4241 topk_prob_mean=0.2658 ema_alpha_reverse=nan max_logit=11.7917
step:886/1750 train_time:438079ms step_avg:494.45ms
[train step 886] avg_loss=3.733244 main=3.257591 aux=0.475653 imp_cv2=0.1035 load_cv2=5.4313 usage_frac=0.4152 topk_prob_mean=0.2662 ema_alpha_reverse=nan max_logit=11.7917
step:887/1750 train_time:438552ms step_avg:494.42ms
[train step 887] avg_loss=3.939707 main=3.456042 aux=0.483665 imp_cv2=0.0636 load_cv2=5.5759 usage_frac=0.4062 topk_prob_mean=0.2383 ema_alpha_reverse=nan max_logit=11.7917
step:888/1750 train_time:439020ms step_avg:494.39ms
[train step 888] avg_loss=4.048015 main=3.568334 aux=0.479681 imp_cv2=0.1218 load_cv2=5.4647 usage_frac=0.4062 topk_prob_mean=0.2711 ema_alpha_reverse=nan max_logit=11.7917
step:889/1750 train_time:439473ms step_avg:494.35ms
[train step 889] avg_loss=3.945239 main=3.467440 aux=0.477799 imp_cv2=0.1280 load_cv2=5.4413 usage_frac=0.4196 topk_prob_mean=0.2734 ema_alpha_reverse=nan max_logit=11.7917
step:890/1750 train_time:439951ms step_avg:494.33ms
[train step 890] avg_loss=3.703985 main=3.231019 aux=0.472966 imp_cv2=0.1489 load_cv2=5.3579 usage_frac=0.4286 topk_prob_mean=0.2826 ema_alpha_reverse=nan max_logit=11.7917
step:891/1750 train_time:440427ms step_avg:494.31ms
[train step 891] avg_loss=3.431371 main=2.959380 aux=0.471991 imp_cv2=0.1675 load_cv2=5.3203 usage_frac=0.4286 topk_prob_mean=0.2896 ema_alpha_reverse=nan max_logit=11.7917
step:892/1750 train_time:440909ms step_avg:494.29ms
[train step 892] avg_loss=4.119471 main=3.633481 aux=0.485990 imp_cv2=0.0630 load_cv2=5.6145 usage_frac=0.4330 topk_prob_mean=0.2389 ema_alpha_reverse=nan max_logit=11.7917
step:893/1750 train_time:441382ms step_avg:494.27ms
[train step 893] avg_loss=3.516942 main=3.042979 aux=0.473963 imp_cv2=0.0752 load_cv2=5.4510 usage_frac=0.4286 topk_prob_mean=0.2508 ema_alpha_reverse=nan max_logit=11.7917
step:894/1750 train_time:441845ms step_avg:494.23ms
[train step 894] avg_loss=4.591291 main=4.095150 aux=0.496140 imp_cv2=0.0492 load_cv2=5.7483 usage_frac=0.4286 topk_prob_mean=0.2138 ema_alpha_reverse=nan max_logit=11.7917
step:895/1750 train_time:442307ms step_avg:494.20ms
[train step 895] avg_loss=3.666007 main=3.194119 aux=0.471887 imp_cv2=0.0993 load_cv2=5.3949 usage_frac=0.4241 topk_prob_mean=0.2650 ema_alpha_reverse=nan max_logit=11.7917
step:896/1750 train_time:442778ms step_avg:494.17ms
[train step 896] avg_loss=3.817607 main=3.343138 aux=0.474469 imp_cv2=0.1027 load_cv2=5.4230 usage_frac=0.4196 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=11.7917
step:897/1750 train_time:443244ms step_avg:494.14ms
[train step 897] avg_loss=3.845680 main=3.376587 aux=0.469093 imp_cv2=0.1053 load_cv2=5.3530 usage_frac=0.4196 topk_prob_mean=0.2697 ema_alpha_reverse=nan max_logit=11.7917
step:898/1750 train_time:443713ms step_avg:494.11ms
[train step 898] avg_loss=3.924210 main=3.456290 aux=0.467919 imp_cv2=0.1302 load_cv2=5.3111 usage_frac=0.4330 topk_prob_mean=0.2774 ema_alpha_reverse=nan max_logit=11.7917
step:899/1750 train_time:444173ms step_avg:494.07ms
[train step 899] avg_loss=4.130976 main=3.649246 aux=0.481729 imp_cv2=0.0690 load_cv2=5.5507 usage_frac=0.4196 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=11.7917
step:900/1750 train_time:444643ms step_avg:494.05ms
Running validation...
step:900/1750 val_loss:3.332385 train_time:444655ms step_avg:494.06ms
[train step 900] avg_loss=4.045286 main=3.572753 aux=0.472533 imp_cv2=0.0841 load_cv2=5.4172 usage_frac=0.4286 topk_prob_mean=0.2573 ema_alpha_reverse=nan max_logit=11.7917
step:901/1750 train_time:445114ms step_avg:494.02ms
[train step 901] avg_loss=3.704724 main=3.241075 aux=0.463649 imp_cv2=0.1843 load_cv2=5.2061 usage_frac=0.4286 topk_prob_mean=0.2964 ema_alpha_reverse=nan max_logit=11.7917
step:902/1750 train_time:445580ms step_avg:493.99ms
[train step 902] avg_loss=4.172892 main=3.670567 aux=0.502325 imp_cv2=0.0519 load_cv2=5.8260 usage_frac=0.4152 topk_prob_mean=0.2095 ema_alpha_reverse=nan max_logit=11.7917
step:903/1750 train_time:446072ms step_avg:493.99ms
[train step 903] avg_loss=3.659753 main=3.196870 aux=0.462883 imp_cv2=0.1324 load_cv2=5.2540 usage_frac=0.4375 topk_prob_mean=0.2822 ema_alpha_reverse=nan max_logit=11.7917
step:904/1750 train_time:446726ms step_avg:494.17ms
[train step 904] avg_loss=4.099722 main=3.627429 aux=0.472293 imp_cv2=0.0717 load_cv2=5.4404 usage_frac=0.4241 topk_prob_mean=0.2479 ema_alpha_reverse=nan max_logit=11.7917
step:905/1750 train_time:447202ms step_avg:494.15ms
[train step 905] avg_loss=3.496760 main=3.030914 aux=0.465846 imp_cv2=0.2118 load_cv2=5.2061 usage_frac=0.4286 topk_prob_mean=0.3054 ema_alpha_reverse=nan max_logit=11.7917
step:906/1750 train_time:447674ms step_avg:494.12ms
[train step 906] avg_loss=4.024540 main=3.523177 aux=0.501363 imp_cv2=0.0632 load_cv2=5.7934 usage_frac=0.4152 topk_prob_mean=0.2072 ema_alpha_reverse=nan max_logit=11.7917
step:907/1750 train_time:448150ms step_avg:494.10ms
[train step 907] avg_loss=3.946431 main=3.480200 aux=0.466231 imp_cv2=0.0871 load_cv2=5.3391 usage_frac=0.4330 topk_prob_mean=0.2562 ema_alpha_reverse=nan max_logit=11.7917
step:908/1750 train_time:448619ms step_avg:494.07ms
[train step 908] avg_loss=4.199117 main=3.739567 aux=0.459550 imp_cv2=0.0829 load_cv2=5.2687 usage_frac=0.4286 topk_prob_mean=0.2596 ema_alpha_reverse=nan max_logit=11.7917
step:909/1750 train_time:449098ms step_avg:494.06ms
[train step 909] avg_loss=3.596745 main=3.143507 aux=0.453238 imp_cv2=0.1936 load_cv2=5.0730 usage_frac=0.4286 topk_prob_mean=0.3048 ema_alpha_reverse=nan max_logit=11.7917
step:910/1750 train_time:449566ms step_avg:494.03ms
[train step 910] avg_loss=3.975179 main=3.509730 aux=0.465449 imp_cv2=0.0900 load_cv2=5.3341 usage_frac=0.4330 topk_prob_mean=0.2604 ema_alpha_reverse=nan max_logit=11.7917
step:911/1750 train_time:450041ms step_avg:494.01ms
[train step 911] avg_loss=3.686391 main=3.231882 aux=0.454509 imp_cv2=0.1597 load_cv2=5.1254 usage_frac=0.4241 topk_prob_mean=0.2918 ema_alpha_reverse=nan max_logit=11.7917
step:912/1750 train_time:450517ms step_avg:493.99ms
[train step 912] avg_loss=3.809524 main=3.357998 aux=0.451526 imp_cv2=0.1430 load_cv2=5.1044 usage_frac=0.4241 topk_prob_mean=0.2894 ema_alpha_reverse=nan max_logit=11.7917
step:913/1750 train_time:450997ms step_avg:493.97ms
[train step 913] avg_loss=4.267076 main=3.778743 aux=0.488333 imp_cv2=0.0451 load_cv2=5.6484 usage_frac=0.4196 topk_prob_mean=0.2127 ema_alpha_reverse=nan max_logit=11.7917
step:914/1750 train_time:451678ms step_avg:494.18ms
[train step 914] avg_loss=4.037277 main=3.557989 aux=0.479288 imp_cv2=0.0563 load_cv2=5.5450 usage_frac=0.4196 topk_prob_mean=0.2289 ema_alpha_reverse=nan max_logit=11.7917
step:915/1750 train_time:452145ms step_avg:494.15ms
[train step 915] avg_loss=3.664605 main=3.209152 aux=0.455453 imp_cv2=0.1350 load_cv2=5.1655 usage_frac=0.4286 topk_prob_mean=0.2828 ema_alpha_reverse=nan max_logit=11.7917
step:916/1750 train_time:452614ms step_avg:494.12ms
[train step 916] avg_loss=4.194596 main=3.733443 aux=0.461152 imp_cv2=0.0786 load_cv2=5.2926 usage_frac=0.4241 topk_prob_mean=0.2559 ema_alpha_reverse=nan max_logit=11.7917
step:917/1750 train_time:453101ms step_avg:494.11ms
[train step 917] avg_loss=3.392656 main=2.940509 aux=0.452147 imp_cv2=0.2152 load_cv2=5.0289 usage_frac=0.4286 topk_prob_mean=0.3104 ema_alpha_reverse=nan max_logit=11.7917
step:918/1750 train_time:453588ms step_avg:494.10ms
[train step 918] avg_loss=3.556819 main=3.100723 aux=0.456096 imp_cv2=0.1787 load_cv2=5.1147 usage_frac=0.4330 topk_prob_mean=0.2987 ema_alpha_reverse=nan max_logit=11.7917
step:919/1750 train_time:454060ms step_avg:494.08ms
[train step 919] avg_loss=3.522300 main=3.063543 aux=0.458757 imp_cv2=0.2812 load_cv2=5.0365 usage_frac=0.4196 topk_prob_mean=0.3267 ema_alpha_reverse=nan max_logit=11.7917
step:920/1750 train_time:454548ms step_avg:494.07ms
[train step 920] avg_loss=3.928825 main=3.462409 aux=0.466416 imp_cv2=0.0798 load_cv2=5.3468 usage_frac=0.4196 topk_prob_mean=0.2532 ema_alpha_reverse=nan max_logit=11.7917
step:921/1750 train_time:455014ms step_avg:494.04ms
[train step 921] avg_loss=3.731074 main=3.271598 aux=0.459476 imp_cv2=0.1106 load_cv2=5.2329 usage_frac=0.4196 topk_prob_mean=0.2725 ema_alpha_reverse=nan max_logit=11.7917
step:922/1750 train_time:455485ms step_avg:494.02ms
[train step 922] avg_loss=3.900495 main=3.438912 aux=0.461583 imp_cv2=0.0818 load_cv2=5.2866 usage_frac=0.4286 topk_prob_mean=0.2564 ema_alpha_reverse=nan max_logit=11.7917
step:923/1750 train_time:455957ms step_avg:493.99ms
[train step 923] avg_loss=4.071140 main=3.622246 aux=0.448894 imp_cv2=0.1501 load_cv2=5.0562 usage_frac=0.4330 topk_prob_mean=0.2901 ema_alpha_reverse=nan max_logit=11.7917
step:924/1750 train_time:456426ms step_avg:493.97ms
[train step 924] avg_loss=4.270450 main=3.775050 aux=0.495400 imp_cv2=0.0547 load_cv2=5.7286 usage_frac=0.4196 topk_prob_mean=0.2104 ema_alpha_reverse=nan max_logit=11.7917
step:925/1750 train_time:456917ms step_avg:493.96ms
[train step 925] avg_loss=3.421681 main=2.973330 aux=0.448351 imp_cv2=0.2434 load_cv2=4.9485 usage_frac=0.4196 topk_prob_mean=0.3197 ema_alpha_reverse=nan max_logit=11.7917
step:926/1750 train_time:457392ms step_avg:493.94ms
[train step 926] avg_loss=3.482175 main=3.025525 aux=0.456650 imp_cv2=0.1562 load_cv2=5.1461 usage_frac=0.4196 topk_prob_mean=0.2889 ema_alpha_reverse=nan max_logit=11.7917
step:927/1750 train_time:457873ms step_avg:493.93ms
[train step 927] avg_loss=3.652861 main=3.191413 aux=0.461448 imp_cv2=0.0981 load_cv2=5.2648 usage_frac=0.4330 topk_prob_mean=0.2665 ema_alpha_reverse=nan max_logit=11.7917
step:928/1750 train_time:458364ms step_avg:493.93ms
[train step 928] avg_loss=4.127520 main=3.659583 aux=0.467937 imp_cv2=0.0797 load_cv2=5.3732 usage_frac=0.4196 topk_prob_mean=0.2527 ema_alpha_reverse=nan max_logit=11.7917
step:929/1750 train_time:458836ms step_avg:493.90ms
[train step 929] avg_loss=3.214667 main=2.762744 aux=0.451923 imp_cv2=0.2882 load_cv2=4.9455 usage_frac=0.4286 topk_prob_mean=0.3315 ema_alpha_reverse=nan max_logit=11.7917
step:930/1750 train_time:459315ms step_avg:493.89ms
[train step 930] avg_loss=3.746019 main=3.296066 aux=0.449954 imp_cv2=0.2184 load_cv2=4.9979 usage_frac=0.4286 topk_prob_mean=0.3134 ema_alpha_reverse=nan max_logit=11.7917
step:931/1750 train_time:459814ms step_avg:493.89ms
[train step 931] avg_loss=3.731800 main=3.252482 aux=0.479317 imp_cv2=0.0783 load_cv2=5.5066 usage_frac=0.4196 topk_prob_mean=0.2354 ema_alpha_reverse=nan max_logit=11.7917
step:932/1750 train_time:460277ms step_avg:493.86ms
[train step 932] avg_loss=3.518270 main=3.070702 aux=0.447567 imp_cv2=0.1686 load_cv2=5.0270 usage_frac=0.4241 topk_prob_mean=0.2993 ema_alpha_reverse=nan max_logit=11.7917
step:933/1750 train_time:460759ms step_avg:493.85ms
[train step 933] avg_loss=3.907657 main=3.442682 aux=0.464975 imp_cv2=0.0943 load_cv2=5.3179 usage_frac=0.4286 topk_prob_mean=0.2626 ema_alpha_reverse=nan max_logit=11.7917
step:934/1750 train_time:461229ms step_avg:493.82ms
[train step 934] avg_loss=4.009897 main=3.542154 aux=0.467743 imp_cv2=0.0748 load_cv2=5.3752 usage_frac=0.4286 topk_prob_mean=0.2501 ema_alpha_reverse=nan max_logit=11.7917
step:935/1750 train_time:461696ms step_avg:493.79ms
[train step 935] avg_loss=3.610716 main=3.155312 aux=0.455404 imp_cv2=0.1104 load_cv2=5.1801 usage_frac=0.4330 topk_prob_mean=0.2753 ema_alpha_reverse=nan max_logit=11.7917
step:936/1750 train_time:462166ms step_avg:493.77ms
[train step 936] avg_loss=3.688053 main=3.233277 aux=0.454776 imp_cv2=0.1451 load_cv2=5.1373 usage_frac=0.4286 topk_prob_mean=0.2878 ema_alpha_reverse=nan max_logit=11.7917
step:937/1750 train_time:462665ms step_avg:493.77ms
[train step 937] avg_loss=4.393084 main=3.893337 aux=0.499747 imp_cv2=0.0643 load_cv2=5.7779 usage_frac=0.4152 topk_prob_mean=0.2056 ema_alpha_reverse=nan max_logit=11.7917
step:938/1750 train_time:463131ms step_avg:493.74ms
[train step 938] avg_loss=3.919889 main=3.463990 aux=0.455899 imp_cv2=0.1497 load_cv2=5.1470 usage_frac=0.4241 topk_prob_mean=0.2859 ema_alpha_reverse=nan max_logit=11.7917
step:939/1750 train_time:463603ms step_avg:493.72ms
[train step 939] avg_loss=3.369923 main=2.917443 aux=0.452480 imp_cv2=0.1872 load_cv2=5.0580 usage_frac=0.4286 topk_prob_mean=0.3024 ema_alpha_reverse=nan max_logit=11.7917
step:940/1750 train_time:464092ms step_avg:493.71ms
[train step 940] avg_loss=3.483403 main=3.032845 aux=0.450558 imp_cv2=0.2401 load_cv2=4.9833 usage_frac=0.4241 topk_prob_mean=0.3182 ema_alpha_reverse=nan max_logit=11.7917
step:941/1750 train_time:464596ms step_avg:493.73ms
[train step 941] avg_loss=3.414160 main=2.962185 aux=0.451975 imp_cv2=0.2018 load_cv2=5.0364 usage_frac=0.4330 topk_prob_mean=0.3079 ema_alpha_reverse=nan max_logit=11.7917
step:942/1750 train_time:465074ms step_avg:493.71ms
[train step 942] avg_loss=4.092786 main=3.628012 aux=0.464774 imp_cv2=0.0724 load_cv2=5.3359 usage_frac=0.4241 topk_prob_mean=0.2528 ema_alpha_reverse=nan max_logit=11.7917
step:943/1750 train_time:465547ms step_avg:493.69ms
[train step 943] avg_loss=3.977433 main=3.523074 aux=0.454359 imp_cv2=0.1238 load_cv2=5.1520 usage_frac=0.4196 topk_prob_mean=0.2818 ema_alpha_reverse=nan max_logit=11.7917
step:944/1750 train_time:466005ms step_avg:493.65ms
[train step 944] avg_loss=3.648693 main=3.197644 aux=0.451049 imp_cv2=0.1394 load_cv2=5.0949 usage_frac=0.4286 topk_prob_mean=0.2896 ema_alpha_reverse=nan max_logit=11.7917
step:945/1750 train_time:466476ms step_avg:493.63ms
[train step 945] avg_loss=3.937143 main=3.469382 aux=0.467760 imp_cv2=0.0717 load_cv2=5.3791 usage_frac=0.4286 topk_prob_mean=0.2491 ema_alpha_reverse=nan max_logit=11.7917
step:946/1750 train_time:466963ms step_avg:493.62ms
[train step 946] avg_loss=3.412914 main=2.964352 aux=0.448563 imp_cv2=0.2519 load_cv2=4.9459 usage_frac=0.4375 topk_prob_mean=0.3239 ema_alpha_reverse=nan max_logit=11.7917
step:947/1750 train_time:467444ms step_avg:493.60ms
[train step 947] avg_loss=3.981171 main=3.522282 aux=0.458889 imp_cv2=0.0819 load_cv2=5.2509 usage_frac=0.4196 topk_prob_mean=0.2595 ema_alpha_reverse=nan max_logit=11.7917
step:948/1750 train_time:467931ms step_avg:493.60ms
[train step 948] avg_loss=3.824023 main=3.375399 aux=0.448624 imp_cv2=0.1373 load_cv2=5.0723 usage_frac=0.4241 topk_prob_mean=0.2894 ema_alpha_reverse=nan max_logit=11.7917
step:949/1750 train_time:468413ms step_avg:493.59ms
[train step 949] avg_loss=3.903279 main=3.446031 aux=0.457248 imp_cv2=0.1114 load_cv2=5.2035 usage_frac=0.4375 topk_prob_mean=0.2751 ema_alpha_reverse=nan max_logit=11.7917
step:950/1750 train_time:468882ms step_avg:493.56ms
Running validation...
step:950/1750 val_loss:3.301540 train_time:468894ms step_avg:493.57ms
[train step 950] avg_loss=3.867817 main=3.397744 aux=0.470073 imp_cv2=0.0849 load_cv2=5.3794 usage_frac=0.4286 topk_prob_mean=0.2426 ema_alpha_reverse=nan max_logit=11.7917
step:951/1750 train_time:469357ms step_avg:493.54ms
[train step 951] avg_loss=3.596203 main=3.147735 aux=0.448469 imp_cv2=0.1750 load_cv2=5.0241 usage_frac=0.4330 topk_prob_mean=0.3000 ema_alpha_reverse=nan max_logit=11.7917
step:952/1750 train_time:469841ms step_avg:493.53ms
[train step 952] avg_loss=3.716450 main=3.266740 aux=0.449710 imp_cv2=0.1370 load_cv2=5.0777 usage_frac=0.4330 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=11.7917
step:953/1750 train_time:470322ms step_avg:493.52ms
[train step 953] avg_loss=3.734829 main=3.284588 aux=0.450240 imp_cv2=0.1228 load_cv2=5.1029 usage_frac=0.4241 topk_prob_mean=0.2812 ema_alpha_reverse=nan max_logit=11.7917
step:954/1750 train_time:470792ms step_avg:493.49ms
[train step 954] avg_loss=4.418754 main=3.934163 aux=0.484591 imp_cv2=0.0718 load_cv2=5.5736 usage_frac=0.4286 topk_prob_mean=0.2273 ema_alpha_reverse=nan max_logit=11.7917
step:955/1750 train_time:471282ms step_avg:493.49ms
[train step 955] avg_loss=3.491735 main=3.048726 aux=0.443008 imp_cv2=0.1548 load_cv2=4.9835 usage_frac=0.4330 topk_prob_mean=0.2968 ema_alpha_reverse=nan max_logit=11.7917
step:956/1750 train_time:471757ms step_avg:493.47ms
[train step 956] avg_loss=3.852758 main=3.407979 aux=0.444779 imp_cv2=0.1247 load_cv2=5.0326 usage_frac=0.4196 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=11.7917
step:957/1750 train_time:472233ms step_avg:493.45ms
[train step 957] avg_loss=3.621114 main=3.174514 aux=0.446600 imp_cv2=0.1701 load_cv2=5.0072 usage_frac=0.4196 topk_prob_mean=0.3021 ema_alpha_reverse=nan max_logit=11.7917
step:958/1750 train_time:472729ms step_avg:493.45ms
[train step 958] avg_loss=3.746252 main=3.294476 aux=0.451775 imp_cv2=0.1142 load_cv2=5.1320 usage_frac=0.4241 topk_prob_mean=0.2797 ema_alpha_reverse=nan max_logit=11.7917
step:959/1750 train_time:473216ms step_avg:493.45ms
[train step 959] avg_loss=3.412529 main=2.966852 aux=0.445677 imp_cv2=0.2195 load_cv2=4.9397 usage_frac=0.4196 topk_prob_mean=0.3171 ema_alpha_reverse=nan max_logit=11.7917
step:960/1750 train_time:473693ms step_avg:493.43ms
[train step 960] avg_loss=3.331650 main=2.881793 aux=0.449857 imp_cv2=0.2055 load_cv2=5.0019 usage_frac=0.4241 topk_prob_mean=0.3112 ema_alpha_reverse=nan max_logit=11.7917
step:961/1750 train_time:474186ms step_avg:493.43ms
[train step 961] avg_loss=3.668776 main=3.209316 aux=0.459459 imp_cv2=0.1251 load_cv2=5.2136 usage_frac=0.4286 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=11.7917
step:962/1750 train_time:474657ms step_avg:493.41ms
[train step 962] avg_loss=3.501643 main=3.046984 aux=0.454659 imp_cv2=0.1826 load_cv2=5.0890 usage_frac=0.4330 topk_prob_mean=0.3014 ema_alpha_reverse=nan max_logit=11.7917
step:963/1750 train_time:475148ms step_avg:493.40ms
[train step 963] avg_loss=3.395817 main=2.945335 aux=0.450482 imp_cv2=0.2124 load_cv2=5.0083 usage_frac=0.4241 topk_prob_mean=0.3130 ema_alpha_reverse=nan max_logit=11.7917
step:964/1750 train_time:475621ms step_avg:493.38ms
[train step 964] avg_loss=3.986559 main=3.529536 aux=0.457023 imp_cv2=0.1095 load_cv2=5.1976 usage_frac=0.4286 topk_prob_mean=0.2752 ema_alpha_reverse=nan max_logit=11.7917
step:965/1750 train_time:476103ms step_avg:493.37ms
[train step 965] avg_loss=4.209955 main=3.736751 aux=0.473204 imp_cv2=0.0786 load_cv2=5.4368 usage_frac=0.4286 topk_prob_mean=0.2545 ema_alpha_reverse=nan max_logit=11.7917
step:966/1750 train_time:476599ms step_avg:493.37ms
[train step 966] avg_loss=3.877789 main=3.417581 aux=0.460208 imp_cv2=0.1049 load_cv2=5.2424 usage_frac=0.4241 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:967/1750 train_time:477084ms step_avg:493.36ms
[train step 967] avg_loss=3.596200 main=3.138207 aux=0.457993 imp_cv2=0.1634 load_cv2=5.1496 usage_frac=0.4286 topk_prob_mean=0.2956 ema_alpha_reverse=nan max_logit=11.7917
step:968/1750 train_time:477557ms step_avg:493.34ms
[train step 968] avg_loss=3.527699 main=3.069695 aux=0.458004 imp_cv2=0.1638 load_cv2=5.1505 usage_frac=0.4196 topk_prob_mean=0.2974 ema_alpha_reverse=nan max_logit=11.7917
step:969/1750 train_time:478024ms step_avg:493.32ms
[train step 969] avg_loss=4.506295 main=4.038214 aux=0.468081 imp_cv2=0.0896 load_cv2=5.3563 usage_frac=0.4330 topk_prob_mean=0.2618 ema_alpha_reverse=nan max_logit=11.7917
step:970/1750 train_time:478502ms step_avg:493.30ms
[train step 970] avg_loss=4.311642 main=3.853594 aux=0.458048 imp_cv2=0.0941 load_cv2=5.2352 usage_frac=0.4241 topk_prob_mean=0.2666 ema_alpha_reverse=nan max_logit=11.7917
step:971/1750 train_time:478982ms step_avg:493.29ms
[train step 971] avg_loss=3.921448 main=3.453130 aux=0.468318 imp_cv2=0.0731 load_cv2=5.3865 usage_frac=0.4375 topk_prob_mean=0.2539 ema_alpha_reverse=nan max_logit=11.8119
step:972/1750 train_time:479452ms step_avg:493.26ms
[train step 972] avg_loss=3.488546 main=3.040751 aux=0.447795 imp_cv2=0.1464 load_cv2=5.0504 usage_frac=0.4241 topk_prob_mean=0.2959 ema_alpha_reverse=nan max_logit=11.7917
step:973/1750 train_time:479925ms step_avg:493.24ms
[train step 973] avg_loss=3.197039 main=2.744237 aux=0.452802 imp_cv2=0.2177 load_cv2=5.0356 usage_frac=0.4286 topk_prob_mean=0.3160 ema_alpha_reverse=nan max_logit=11.7917
step:974/1750 train_time:480401ms step_avg:493.23ms
[train step 974] avg_loss=3.608299 main=3.152255 aux=0.456045 imp_cv2=0.1422 load_cv2=5.1586 usage_frac=0.4286 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=11.7917
step:975/1750 train_time:480869ms step_avg:493.20ms
[train step 975] avg_loss=4.002454 main=3.508281 aux=0.494173 imp_cv2=0.0467 load_cv2=5.7315 usage_frac=0.4152 topk_prob_mean=0.2146 ema_alpha_reverse=nan max_logit=11.7917
step:976/1750 train_time:481337ms step_avg:493.17ms
[train step 976] avg_loss=3.608485 main=3.156586 aux=0.451899 imp_cv2=0.1524 load_cv2=5.0953 usage_frac=0.4286 topk_prob_mean=0.2956 ema_alpha_reverse=nan max_logit=11.7917
step:977/1750 train_time:481816ms step_avg:493.16ms
[train step 977] avg_loss=4.477893 main=3.974234 aux=0.503659 imp_cv2=0.0444 load_cv2=5.8465 usage_frac=0.4196 topk_prob_mean=0.2000 ema_alpha_reverse=nan max_logit=11.7917
step:978/1750 train_time:482301ms step_avg:493.15ms
[train step 978] avg_loss=3.469722 main=3.014748 aux=0.454974 imp_cv2=0.1445 load_cv2=5.1438 usage_frac=0.4286 topk_prob_mean=0.2896 ema_alpha_reverse=nan max_logit=11.7917
step:979/1750 train_time:482769ms step_avg:493.12ms
[train step 979] avg_loss=3.949206 main=3.487434 aux=0.461771 imp_cv2=0.0783 load_cv2=5.3020 usage_frac=0.4286 topk_prob_mean=0.2597 ema_alpha_reverse=nan max_logit=11.7917
step:980/1750 train_time:483235ms step_avg:493.10ms
[train step 980] avg_loss=3.697403 main=3.232587 aux=0.464817 imp_cv2=0.0797 load_cv2=5.3430 usage_frac=0.4286 topk_prob_mean=0.2579 ema_alpha_reverse=nan max_logit=11.7917
step:981/1750 train_time:483697ms step_avg:493.07ms
[train step 981] avg_loss=3.340734 main=2.874218 aux=0.466516 imp_cv2=0.0698 load_cv2=5.3735 usage_frac=0.4286 topk_prob_mean=0.2485 ema_alpha_reverse=nan max_logit=11.7917
step:982/1750 train_time:484169ms step_avg:493.04ms
[train step 982] avg_loss=3.795786 main=3.325953 aux=0.469833 imp_cv2=0.0675 load_cv2=5.4154 usage_frac=0.4286 topk_prob_mean=0.2480 ema_alpha_reverse=nan max_logit=11.7917
step:983/1750 train_time:484634ms step_avg:493.02ms
[train step 983] avg_loss=3.690494 main=3.218447 aux=0.472047 imp_cv2=0.0714 load_cv2=5.4364 usage_frac=0.4241 topk_prob_mean=0.2509 ema_alpha_reverse=nan max_logit=11.7917
step:984/1750 train_time:485099ms step_avg:492.99ms
[train step 984] avg_loss=3.294848 main=2.829919 aux=0.464929 imp_cv2=0.2667 load_cv2=5.1407 usage_frac=0.4286 topk_prob_mean=0.3212 ema_alpha_reverse=nan max_logit=11.7917
step:985/1750 train_time:485591ms step_avg:492.99ms
[train step 985] avg_loss=4.017105 main=3.540127 aux=0.476979 imp_cv2=0.0604 load_cv2=5.5167 usage_frac=0.4196 topk_prob_mean=0.2425 ema_alpha_reverse=nan max_logit=11.7917
step:986/1750 train_time:486065ms step_avg:492.97ms
[train step 986] avg_loss=3.739798 main=3.275206 aux=0.464593 imp_cv2=0.0993 load_cv2=5.3165 usage_frac=0.4286 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=11.7917
step:987/1750 train_time:486540ms step_avg:492.95ms
[train step 987] avg_loss=3.448978 main=2.982292 aux=0.466685 imp_cv2=0.1726 load_cv2=5.2650 usage_frac=0.4241 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=11.7917
step:988/1750 train_time:487010ms step_avg:492.93ms
[train step 988] avg_loss=3.656330 main=3.186979 aux=0.469352 imp_cv2=0.1604 load_cv2=5.3078 usage_frac=0.4286 topk_prob_mean=0.2873 ema_alpha_reverse=nan max_logit=11.7917
step:989/1750 train_time:487492ms step_avg:492.91ms
[train step 989] avg_loss=3.504471 main=3.039616 aux=0.464854 imp_cv2=0.1907 load_cv2=5.2267 usage_frac=0.4196 topk_prob_mean=0.2995 ema_alpha_reverse=nan max_logit=11.7917
step:990/1750 train_time:487956ms step_avg:492.88ms
[train step 990] avg_loss=3.653388 main=3.184910 aux=0.468479 imp_cv2=0.1120 load_cv2=5.3508 usage_frac=0.4241 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=11.7917
step:991/1750 train_time:488422ms step_avg:492.86ms
[train step 991] avg_loss=3.477676 main=3.013653 aux=0.464023 imp_cv2=0.2152 load_cv2=5.1896 usage_frac=0.4241 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=11.7917
step:992/1750 train_time:488907ms step_avg:492.85ms
[train step 992] avg_loss=4.051407 main=3.586404 aux=0.465003 imp_cv2=0.0934 load_cv2=5.3225 usage_frac=0.4286 topk_prob_mean=0.2579 ema_alpha_reverse=nan max_logit=11.7917
step:993/1750 train_time:489381ms step_avg:492.83ms
[train step 993] avg_loss=4.186820 main=3.676067 aux=0.510752 imp_cv2=0.0814 load_cv2=5.8879 usage_frac=0.4196 topk_prob_mean=0.2056 ema_alpha_reverse=nan max_logit=11.7917
step:994/1750 train_time:489857ms step_avg:492.81ms
[train step 994] avg_loss=3.878839 main=3.407448 aux=0.471391 imp_cv2=0.0928 load_cv2=5.4086 usage_frac=0.4196 topk_prob_mean=0.2608 ema_alpha_reverse=nan max_logit=11.7917
step:995/1750 train_time:490319ms step_avg:492.78ms
[train step 995] avg_loss=3.275270 main=2.812447 aux=0.462824 imp_cv2=0.2470 load_cv2=5.1427 usage_frac=0.4286 topk_prob_mean=0.3166 ema_alpha_reverse=nan max_logit=11.7917
step:996/1750 train_time:490787ms step_avg:492.76ms
[train step 996] avg_loss=3.480496 main=3.019133 aux=0.461363 imp_cv2=0.1687 load_cv2=5.2079 usage_frac=0.4241 topk_prob_mean=0.2940 ema_alpha_reverse=nan max_logit=11.7917
step:997/1750 train_time:491270ms step_avg:492.75ms
[train step 997] avg_loss=3.689303 main=3.229414 aux=0.459889 imp_cv2=0.1417 load_cv2=5.2203 usage_frac=0.4286 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=11.7917
step:998/1750 train_time:491745ms step_avg:492.73ms
[train step 998] avg_loss=3.348231 main=2.893070 aux=0.455161 imp_cv2=0.2241 load_cv2=5.0702 usage_frac=0.4286 topk_prob_mean=0.3140 ema_alpha_reverse=nan max_logit=11.7917
step:999/1750 train_time:492208ms step_avg:492.70ms
[train step 999] avg_loss=3.782400 main=3.317265 aux=0.465135 imp_cv2=0.1237 load_cv2=5.3004 usage_frac=0.4241 topk_prob_mean=0.2740 ema_alpha_reverse=nan max_logit=11.7917
step:1000/1750 train_time:492672ms step_avg:492.67ms
Running validation...
step:1000/1750 val_loss:3.268753 train_time:492684ms step_avg:492.68ms
[train step 1000] avg_loss=3.805154 main=3.338018 aux=0.467135 imp_cv2=0.0823 load_cv2=5.3689 usage_frac=0.4152 topk_prob_mean=0.2543 ema_alpha_reverse=nan max_logit=11.7917
step:1001/1750 train_time:493152ms step_avg:492.66ms
[train step 1001] avg_loss=3.389614 main=2.928738 aux=0.460876 imp_cv2=0.1585 load_cv2=5.2097 usage_frac=0.4241 topk_prob_mean=0.2883 ema_alpha_reverse=nan max_logit=11.7917
step:1002/1750 train_time:493610ms step_avg:492.63ms
[train step 1002] avg_loss=3.578061 main=3.107137 aux=0.470924 imp_cv2=0.0898 load_cv2=5.4051 usage_frac=0.4241 topk_prob_mean=0.2559 ema_alpha_reverse=nan max_logit=11.7917
step:1003/1750 train_time:494073ms step_avg:492.60ms
[train step 1003] avg_loss=3.546737 main=3.083164 aux=0.463573 imp_cv2=0.1234 load_cv2=5.2789 usage_frac=0.4241 topk_prob_mean=0.2727 ema_alpha_reverse=nan max_logit=11.7917
step:1004/1750 train_time:494551ms step_avg:492.58ms
[train step 1004] avg_loss=3.750961 main=3.290030 aux=0.460932 imp_cv2=0.1135 load_cv2=5.2582 usage_frac=0.4241 topk_prob_mean=0.2705 ema_alpha_reverse=nan max_logit=11.7917
step:1005/1750 train_time:495014ms step_avg:492.55ms
[train step 1005] avg_loss=3.342388 main=2.886805 aux=0.455582 imp_cv2=0.2277 load_cv2=5.0710 usage_frac=0.4241 topk_prob_mean=0.3091 ema_alpha_reverse=nan max_logit=11.7917
step:1006/1750 train_time:495483ms step_avg:492.53ms
[train step 1006] avg_loss=3.744722 main=3.287303 aux=0.457419 imp_cv2=0.1440 load_cv2=5.1869 usage_frac=0.4196 topk_prob_mean=0.2819 ema_alpha_reverse=nan max_logit=11.7917
step:1007/1750 train_time:495970ms step_avg:492.52ms
[train step 1007] avg_loss=3.997082 main=3.466635 aux=0.530446 imp_cv2=0.0557 load_cv2=6.1646 usage_frac=0.4062 topk_prob_mean=0.1802 ema_alpha_reverse=nan max_logit=10.8091
step:1008/1750 train_time:496443ms step_avg:492.50ms
[train step 1008] avg_loss=3.602856 main=3.146934 aux=0.455922 imp_cv2=0.1378 load_cv2=5.1758 usage_frac=0.4196 topk_prob_mean=0.2794 ema_alpha_reverse=nan max_logit=11.7917
step:1009/1750 train_time:496909ms step_avg:492.48ms
[train step 1009] avg_loss=3.923503 main=3.467203 aux=0.456299 imp_cv2=0.1424 load_cv2=5.1725 usage_frac=0.4241 topk_prob_mean=0.2800 ema_alpha_reverse=nan max_logit=11.7917
step:1010/1750 train_time:497375ms step_avg:492.45ms
[train step 1010] avg_loss=4.017077 main=3.545619 aux=0.471458 imp_cv2=0.0862 load_cv2=5.4148 usage_frac=0.4196 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:1011/1750 train_time:497850ms step_avg:492.43ms
[train step 1011] avg_loss=3.363593 main=2.905406 aux=0.458188 imp_cv2=0.2594 load_cv2=5.0663 usage_frac=0.4196 topk_prob_mean=0.3164 ema_alpha_reverse=nan max_logit=11.7917
step:1012/1750 train_time:498335ms step_avg:492.43ms
[train step 1012] avg_loss=3.913266 main=3.436590 aux=0.476675 imp_cv2=0.0775 load_cv2=5.4873 usage_frac=0.4196 topk_prob_mean=0.2463 ema_alpha_reverse=nan max_logit=11.7917
step:1013/1750 train_time:498802ms step_avg:492.40ms
[train step 1013] avg_loss=3.722916 main=3.261986 aux=0.460930 imp_cv2=0.1844 load_cv2=5.1812 usage_frac=0.4286 topk_prob_mean=0.2935 ema_alpha_reverse=nan max_logit=11.7917
step:1014/1750 train_time:499266ms step_avg:492.37ms
[train step 1014] avg_loss=4.028199 main=3.572960 aux=0.455239 imp_cv2=0.1538 load_cv2=5.1524 usage_frac=0.4196 topk_prob_mean=0.2848 ema_alpha_reverse=nan max_logit=11.7917
step:1015/1750 train_time:499731ms step_avg:492.35ms
[train step 1015] avg_loss=3.636829 main=3.146842 aux=0.489987 imp_cv2=0.0568 load_cv2=5.6578 usage_frac=0.4152 topk_prob_mean=0.2161 ema_alpha_reverse=nan max_logit=11.7917
step:1016/1750 train_time:500198ms step_avg:492.32ms
[train step 1016] avg_loss=3.883311 main=3.393836 aux=0.489475 imp_cv2=0.0570 load_cv2=5.6687 usage_frac=0.4241 topk_prob_mean=0.2268 ema_alpha_reverse=nan max_logit=11.7917
step:1017/1750 train_time:500660ms step_avg:492.29ms
[train step 1017] avg_loss=3.598525 main=3.131917 aux=0.466609 imp_cv2=0.1101 load_cv2=5.3250 usage_frac=0.4286 topk_prob_mean=0.2661 ema_alpha_reverse=nan max_logit=11.7917
step:1018/1750 train_time:501211ms step_avg:492.35ms
[train step 1018] avg_loss=3.322887 main=2.861484 aux=0.461403 imp_cv2=0.2144 load_cv2=5.1472 usage_frac=0.4196 topk_prob_mean=0.3021 ema_alpha_reverse=nan max_logit=11.7917
step:1019/1750 train_time:501861ms step_avg:492.50ms
[train step 1019] avg_loss=3.559842 main=3.101379 aux=0.458463 imp_cv2=0.1569 load_cv2=5.1758 usage_frac=0.4286 topk_prob_mean=0.2860 ema_alpha_reverse=nan max_logit=11.7917
step:1020/1750 train_time:502343ms step_avg:492.49ms
[train step 1020] avg_loss=3.616441 main=3.150525 aux=0.465917 imp_cv2=0.1287 load_cv2=5.2955 usage_frac=0.4241 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=11.7917
step:1021/1750 train_time:502818ms step_avg:492.48ms
[train step 1021] avg_loss=3.401680 main=2.941078 aux=0.460602 imp_cv2=0.1070 load_cv2=5.2579 usage_frac=0.4196 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=11.7917
step:1022/1750 train_time:503277ms step_avg:492.44ms
[train step 1022] avg_loss=4.067990 main=3.567253 aux=0.500737 imp_cv2=0.0552 load_cv2=5.8042 usage_frac=0.4107 topk_prob_mean=0.2056 ema_alpha_reverse=nan max_logit=11.7917
step:1023/1750 train_time:503745ms step_avg:492.42ms
[train step 1023] avg_loss=4.218535 main=3.730574 aux=0.487960 imp_cv2=0.0677 load_cv2=5.6391 usage_frac=0.4196 topk_prob_mean=0.2308 ema_alpha_reverse=nan max_logit=11.7917
step:1024/1750 train_time:504226ms step_avg:492.41ms
[train step 1024] avg_loss=3.486113 main=3.032099 aux=0.454015 imp_cv2=0.2063 load_cv2=5.0727 usage_frac=0.4196 topk_prob_mean=0.3022 ema_alpha_reverse=nan max_logit=11.7917
step:1025/1750 train_time:504696ms step_avg:492.39ms
[train step 1025] avg_loss=3.546743 main=3.089328 aux=0.457415 imp_cv2=0.1630 load_cv2=5.1583 usage_frac=0.4196 topk_prob_mean=0.2870 ema_alpha_reverse=nan max_logit=11.7917
step:1026/1750 train_time:505159ms step_avg:492.36ms
[train step 1026] avg_loss=3.525407 main=3.071791 aux=0.453616 imp_cv2=0.1810 load_cv2=5.0984 usage_frac=0.4286 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=11.7917
step:1027/1750 train_time:505626ms step_avg:492.33ms
[train step 1027] avg_loss=3.722118 main=3.251619 aux=0.470500 imp_cv2=0.1173 load_cv2=5.3767 usage_frac=0.4241 topk_prob_mean=0.2619 ema_alpha_reverse=nan max_logit=11.7917
step:1028/1750 train_time:506108ms step_avg:492.32ms
[train step 1028] avg_loss=3.539974 main=3.085280 aux=0.454694 imp_cv2=0.2174 load_cv2=5.0769 usage_frac=0.4196 topk_prob_mean=0.3053 ema_alpha_reverse=nan max_logit=11.7917
step:1029/1750 train_time:506583ms step_avg:492.31ms
[train step 1029] avg_loss=4.232635 main=3.704332 aux=0.528303 imp_cv2=0.0447 load_cv2=6.1525 usage_frac=0.3929 topk_prob_mean=0.1738 ema_alpha_reverse=nan max_logit=10.8091
step:1030/1750 train_time:507041ms step_avg:492.27ms
[train step 1030] avg_loss=3.832155 main=3.369102 aux=0.463053 imp_cv2=0.1288 load_cv2=5.2734 usage_frac=0.4241 topk_prob_mean=0.2721 ema_alpha_reverse=nan max_logit=11.7917
step:1031/1750 train_time:507508ms step_avg:492.25ms
[train step 1031] avg_loss=3.530817 main=3.071895 aux=0.458921 imp_cv2=0.1439 load_cv2=5.2008 usage_frac=0.4196 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=11.7917
step:1032/1750 train_time:507990ms step_avg:492.24ms
[train step 1032] avg_loss=3.338649 main=2.883212 aux=0.455437 imp_cv2=0.1965 load_cv2=5.1019 usage_frac=0.4196 topk_prob_mean=0.3003 ema_alpha_reverse=nan max_logit=11.7917
step:1033/1750 train_time:508472ms step_avg:492.23ms
[train step 1033] avg_loss=3.651268 main=3.186559 aux=0.464709 imp_cv2=0.1264 load_cv2=5.2898 usage_frac=0.4196 topk_prob_mean=0.2710 ema_alpha_reverse=nan max_logit=11.7917
step:1034/1750 train_time:508940ms step_avg:492.21ms
[train step 1034] avg_loss=3.627390 main=3.164912 aux=0.462478 imp_cv2=0.1948 load_cv2=5.1868 usage_frac=0.4196 topk_prob_mean=0.2948 ema_alpha_reverse=nan max_logit=11.7917
step:1035/1750 train_time:509413ms step_avg:492.19ms
[train step 1035] avg_loss=3.344314 main=2.886321 aux=0.457993 imp_cv2=0.1940 load_cv2=5.1340 usage_frac=0.4286 topk_prob_mean=0.2967 ema_alpha_reverse=nan max_logit=11.7917
step:1036/1750 train_time:509890ms step_avg:492.17ms
[train step 1036] avg_loss=3.458507 main=3.002639 aux=0.455868 imp_cv2=0.2293 load_cv2=5.0625 usage_frac=0.4196 topk_prob_mean=0.3087 ema_alpha_reverse=nan max_logit=11.7917
step:1037/1750 train_time:510363ms step_avg:492.15ms
[train step 1037] avg_loss=4.570462 main=4.100096 aux=0.470366 imp_cv2=0.0996 load_cv2=5.3882 usage_frac=0.4241 topk_prob_mean=0.2554 ema_alpha_reverse=nan max_logit=11.7917
step:1038/1750 train_time:510829ms step_avg:492.13ms
[train step 1038] avg_loss=4.243165 main=3.755667 aux=0.487498 imp_cv2=0.0721 load_cv2=5.6307 usage_frac=0.4196 topk_prob_mean=0.2332 ema_alpha_reverse=nan max_logit=11.7917
step:1039/1750 train_time:511288ms step_avg:492.10ms
[train step 1039] avg_loss=3.471723 main=3.007904 aux=0.463819 imp_cv2=0.1895 load_cv2=5.2086 usage_frac=0.4196 topk_prob_mean=0.2941 ema_alpha_reverse=nan max_logit=11.7917
step:1040/1750 train_time:511755ms step_avg:492.07ms
[train step 1040] avg_loss=3.729149 main=3.266619 aux=0.462530 imp_cv2=0.1538 load_cv2=5.2293 usage_frac=0.4196 topk_prob_mean=0.2855 ema_alpha_reverse=nan max_logit=11.7917
step:1041/1750 train_time:512222ms step_avg:492.05ms
[train step 1041] avg_loss=4.385609 main=3.898877 aux=0.486732 imp_cv2=0.0557 load_cv2=5.6324 usage_frac=0.4241 topk_prob_mean=0.2240 ema_alpha_reverse=nan max_logit=11.7917
step:1042/1750 train_time:512884ms step_avg:492.21ms
[train step 1042] avg_loss=3.574564 main=3.106405 aux=0.468159 imp_cv2=0.0822 load_cv2=5.3769 usage_frac=0.4241 topk_prob_mean=0.2499 ema_alpha_reverse=nan max_logit=11.7917
step:1043/1750 train_time:513358ms step_avg:492.19ms
[train step 1043] avg_loss=3.516271 main=3.059361 aux=0.456910 imp_cv2=0.2062 load_cv2=5.1018 usage_frac=0.4241 topk_prob_mean=0.3047 ema_alpha_reverse=nan max_logit=11.7917
step:1044/1750 train_time:513835ms step_avg:492.18ms
[train step 1044] avg_loss=3.557888 main=3.101397 aux=0.456491 imp_cv2=0.2121 load_cv2=5.0909 usage_frac=0.4286 topk_prob_mean=0.3050 ema_alpha_reverse=nan max_logit=11.7917
step:1045/1750 train_time:514303ms step_avg:492.16ms
[train step 1045] avg_loss=4.654398 main=4.133676 aux=0.520722 imp_cv2=0.0644 load_cv2=6.0430 usage_frac=0.4018 topk_prob_mean=0.1878 ema_alpha_reverse=nan max_logit=10.8091
step:1046/1750 train_time:514754ms step_avg:492.12ms
[train step 1046] avg_loss=3.830834 main=3.367868 aux=0.462967 imp_cv2=0.1446 load_cv2=5.2441 usage_frac=0.4286 topk_prob_mean=0.2785 ema_alpha_reverse=nan max_logit=11.7917
step:1047/1750 train_time:515210ms step_avg:492.08ms
[train step 1047] avg_loss=3.998199 main=3.524737 aux=0.473462 imp_cv2=0.0811 load_cv2=5.4423 usage_frac=0.4196 topk_prob_mean=0.2480 ema_alpha_reverse=nan max_logit=11.7917
step:1048/1750 train_time:515676ms step_avg:492.06ms
[train step 1048] avg_loss=3.376829 main=2.920966 aux=0.455863 imp_cv2=0.2359 load_cv2=5.0672 usage_frac=0.4241 topk_prob_mean=0.3137 ema_alpha_reverse=nan max_logit=11.7917
step:1049/1750 train_time:516141ms step_avg:492.03ms
[train step 1049] avg_loss=3.646241 main=3.175191 aux=0.471050 imp_cv2=0.0894 load_cv2=5.4049 usage_frac=0.4152 topk_prob_mean=0.2541 ema_alpha_reverse=nan max_logit=11.7917
step:1050/1750 train_time:516605ms step_avg:492.00ms
Running validation...
step:1050/1750 val_loss:3.238004 train_time:516617ms step_avg:492.02ms
[train step 1050] avg_loss=3.473015 main=3.010031 aux=0.462985 imp_cv2=0.1393 load_cv2=5.2521 usage_frac=0.4196 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=11.7917
step:1051/1750 train_time:517069ms step_avg:491.98ms
[train step 1051] avg_loss=4.509576 main=4.012223 aux=0.497353 imp_cv2=0.0557 load_cv2=5.7666 usage_frac=0.4196 topk_prob_mean=0.2133 ema_alpha_reverse=nan max_logit=11.7917
step:1052/1750 train_time:517540ms step_avg:491.96ms
[train step 1052] avg_loss=3.733456 main=3.270291 aux=0.463166 imp_cv2=0.1294 load_cv2=5.2658 usage_frac=0.4241 topk_prob_mean=0.2742 ema_alpha_reverse=nan max_logit=11.7917
step:1053/1750 train_time:518014ms step_avg:491.94ms
[train step 1053] avg_loss=4.007098 main=3.525977 aux=0.481121 imp_cv2=0.0641 load_cv2=5.5592 usage_frac=0.4196 topk_prob_mean=0.2354 ema_alpha_reverse=nan max_logit=11.7917
step:1054/1750 train_time:518479ms step_avg:491.92ms
[train step 1054] avg_loss=3.510110 main=3.048075 aux=0.462035 imp_cv2=0.1801 load_cv2=5.1915 usage_frac=0.4241 topk_prob_mean=0.2934 ema_alpha_reverse=nan max_logit=11.7917
step:1055/1750 train_time:518942ms step_avg:491.89ms
[train step 1055] avg_loss=4.277227 main=3.777043 aux=0.500184 imp_cv2=0.0638 load_cv2=5.7784 usage_frac=0.4196 topk_prob_mean=0.2126 ema_alpha_reverse=nan max_logit=11.7917
step:1056/1750 train_time:519620ms step_avg:492.06ms
[train step 1056] avg_loss=3.544899 main=3.082193 aux=0.462706 imp_cv2=0.2021 load_cv2=5.1778 usage_frac=0.4196 topk_prob_mean=0.3000 ema_alpha_reverse=nan max_logit=11.7917
step:1057/1750 train_time:520087ms step_avg:492.04ms
[train step 1057] avg_loss=3.438144 main=2.974786 aux=0.463358 imp_cv2=0.2336 load_cv2=5.1515 usage_frac=0.4196 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=11.7917
step:1058/1750 train_time:520561ms step_avg:492.02ms
[train step 1058] avg_loss=4.024669 main=3.548410 aux=0.476260 imp_cv2=0.0938 load_cv2=5.4714 usage_frac=0.4152 topk_prob_mean=0.2555 ema_alpha_reverse=nan max_logit=11.7917
step:1059/1750 train_time:521022ms step_avg:491.99ms
[train step 1059] avg_loss=4.465670 main=3.974374 aux=0.491296 imp_cv2=0.0532 load_cv2=5.6817 usage_frac=0.4152 topk_prob_mean=0.2162 ema_alpha_reverse=nan max_logit=11.7917
step:1060/1750 train_time:521481ms step_avg:491.96ms
[train step 1060] avg_loss=3.591601 main=3.129117 aux=0.462484 imp_cv2=0.1253 load_cv2=5.2551 usage_frac=0.4196 topk_prob_mean=0.2743 ema_alpha_reverse=nan max_logit=11.7917
step:1061/1750 train_time:521933ms step_avg:491.93ms
[train step 1061] avg_loss=3.701464 main=3.233479 aux=0.467985 imp_cv2=0.1241 load_cv2=5.3246 usage_frac=0.4152 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:1062/1750 train_time:522398ms step_avg:491.90ms
[train step 1062] avg_loss=3.871524 main=3.398783 aux=0.472740 imp_cv2=0.0994 load_cv2=5.4052 usage_frac=0.4241 topk_prob_mean=0.2609 ema_alpha_reverse=nan max_logit=11.7917
step:1063/1750 train_time:522855ms step_avg:491.87ms
[train step 1063] avg_loss=3.386025 main=2.921785 aux=0.464240 imp_cv2=0.2654 load_cv2=5.1267 usage_frac=0.4196 topk_prob_mean=0.3194 ema_alpha_reverse=nan max_logit=11.7917
step:1064/1750 train_time:523326ms step_avg:491.85ms
[train step 1064] avg_loss=3.779392 main=3.297024 aux=0.482368 imp_cv2=0.0690 load_cv2=5.5551 usage_frac=0.4196 topk_prob_mean=0.2371 ema_alpha_reverse=nan max_logit=11.7917
step:1065/1750 train_time:523793ms step_avg:491.82ms
[train step 1065] avg_loss=3.536202 main=3.072030 aux=0.464172 imp_cv2=0.1575 load_cv2=5.2366 usage_frac=0.4241 topk_prob_mean=0.2865 ema_alpha_reverse=nan max_logit=11.7917
step:1066/1750 train_time:524259ms step_avg:491.80ms
[train step 1066] avg_loss=4.237030 main=3.761994 aux=0.475036 imp_cv2=0.0932 load_cv2=5.4458 usage_frac=0.4241 topk_prob_mean=0.2568 ema_alpha_reverse=nan max_logit=11.7917
step:1067/1750 train_time:524726ms step_avg:491.78ms
[train step 1067] avg_loss=3.551077 main=3.072143 aux=0.478935 imp_cv2=0.1232 load_cv2=5.4531 usage_frac=0.4152 topk_prob_mean=0.2658 ema_alpha_reverse=nan max_logit=11.7917
step:1068/1750 train_time:525184ms step_avg:491.75ms
[train step 1068] avg_loss=4.022224 main=3.553467 aux=0.468757 imp_cv2=0.1371 load_cv2=5.3221 usage_frac=0.4196 topk_prob_mean=0.2770 ema_alpha_reverse=nan max_logit=11.7917
step:1069/1750 train_time:525650ms step_avg:491.72ms
[train step 1069] avg_loss=3.604028 main=3.132931 aux=0.471097 imp_cv2=0.1154 load_cv2=5.3743 usage_frac=0.4152 topk_prob_mean=0.2674 ema_alpha_reverse=nan max_logit=11.7917
step:1070/1750 train_time:526105ms step_avg:491.69ms
[train step 1070] avg_loss=3.833390 main=3.354499 aux=0.478892 imp_cv2=0.0735 load_cv2=5.5111 usage_frac=0.4241 topk_prob_mean=0.2430 ema_alpha_reverse=nan max_logit=11.7917
step:1071/1750 train_time:526573ms step_avg:491.67ms
[train step 1071] avg_loss=3.471480 main=3.007008 aux=0.464471 imp_cv2=0.2156 load_cv2=5.1760 usage_frac=0.4196 topk_prob_mean=0.3045 ema_alpha_reverse=nan max_logit=11.7917
step:1072/1750 train_time:527041ms step_avg:491.64ms
[train step 1072] avg_loss=4.176226 main=3.708726 aux=0.467500 imp_cv2=0.1137 load_cv2=5.3303 usage_frac=0.4241 topk_prob_mean=0.2682 ema_alpha_reverse=nan max_logit=11.7917
step:1073/1750 train_time:527506ms step_avg:491.62ms
[train step 1073] avg_loss=5.755672 main=5.266284 aux=0.489388 imp_cv2=0.0778 load_cv2=5.6508 usage_frac=0.4107 topk_prob_mean=0.2211 ema_alpha_reverse=nan max_logit=11.7917
step:1074/1750 train_time:527960ms step_avg:491.58ms
[train step 1074] avg_loss=3.642932 main=3.171592 aux=0.471340 imp_cv2=0.1038 load_cv2=5.3860 usage_frac=0.4241 topk_prob_mean=0.2591 ema_alpha_reverse=nan max_logit=11.7917
step:1075/1750 train_time:528425ms step_avg:491.56ms
[train step 1075] avg_loss=3.458399 main=2.998100 aux=0.460299 imp_cv2=0.1823 load_cv2=5.1619 usage_frac=0.4152 topk_prob_mean=0.2951 ema_alpha_reverse=nan max_logit=11.7917
step:1076/1750 train_time:528890ms step_avg:491.53ms
[train step 1076] avg_loss=3.828745 main=3.360357 aux=0.468388 imp_cv2=0.1044 load_cv2=5.3536 usage_frac=0.4196 topk_prob_mean=0.2639 ema_alpha_reverse=nan max_logit=11.7917
step:1077/1750 train_time:529343ms step_avg:491.50ms
[train step 1077] avg_loss=3.982755 main=3.519097 aux=0.463658 imp_cv2=0.1421 load_cv2=5.2527 usage_frac=0.4241 topk_prob_mean=0.2800 ema_alpha_reverse=nan max_logit=11.7917
step:1078/1750 train_time:529801ms step_avg:491.47ms
[train step 1078] avg_loss=3.530057 main=3.062715 aux=0.467342 imp_cv2=0.1195 load_cv2=5.3273 usage_frac=0.4152 topk_prob_mean=0.2698 ema_alpha_reverse=nan max_logit=11.7917
step:1079/1750 train_time:530257ms step_avg:491.43ms
[train step 1079] avg_loss=3.533797 main=3.072771 aux=0.461026 imp_cv2=0.1479 load_cv2=5.2210 usage_frac=0.4152 topk_prob_mean=0.2846 ema_alpha_reverse=nan max_logit=11.7917
step:1080/1750 train_time:530716ms step_avg:491.40ms
[train step 1080] avg_loss=3.375173 main=2.908908 aux=0.466265 imp_cv2=0.1519 load_cv2=5.2826 usage_frac=0.4152 topk_prob_mean=0.2828 ema_alpha_reverse=nan max_logit=11.7917
step:1081/1750 train_time:531167ms step_avg:491.37ms
[train step 1081] avg_loss=3.500741 main=3.041878 aux=0.458862 imp_cv2=0.1345 load_cv2=5.2098 usage_frac=0.4196 topk_prob_mean=0.2813 ema_alpha_reverse=nan max_logit=11.7917
step:1082/1750 train_time:531629ms step_avg:491.34ms
[train step 1082] avg_loss=3.761092 main=3.303295 aux=0.457797 imp_cv2=0.1777 load_cv2=5.1525 usage_frac=0.4152 topk_prob_mean=0.2946 ema_alpha_reverse=nan max_logit=11.7917
step:1083/1750 train_time:532090ms step_avg:491.31ms
[train step 1083] avg_loss=3.792634 main=3.331340 aux=0.461294 imp_cv2=0.1290 load_cv2=5.2498 usage_frac=0.4107 topk_prob_mean=0.2759 ema_alpha_reverse=nan max_logit=11.7917
step:1084/1750 train_time:532555ms step_avg:491.29ms
[train step 1084] avg_loss=3.495949 main=3.035533 aux=0.460416 imp_cv2=0.1576 load_cv2=5.2078 usage_frac=0.4196 topk_prob_mean=0.2851 ema_alpha_reverse=nan max_logit=11.7917
step:1085/1750 train_time:533018ms step_avg:491.26ms
[train step 1085] avg_loss=3.570754 main=3.109060 aux=0.461694 imp_cv2=0.1690 load_cv2=5.2152 usage_frac=0.4152 topk_prob_mean=0.2885 ema_alpha_reverse=nan max_logit=11.7917
step:1086/1750 train_time:533485ms step_avg:491.24ms
[train step 1086] avg_loss=3.484295 main=3.024372 aux=0.459923 imp_cv2=0.1370 load_cv2=5.2334 usage_frac=0.4196 topk_prob_mean=0.2797 ema_alpha_reverse=nan max_logit=11.7917
step:1087/1750 train_time:533957ms step_avg:491.22ms
[train step 1087] avg_loss=3.720071 main=3.253834 aux=0.466237 imp_cv2=0.1305 load_cv2=5.3093 usage_frac=0.4152 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=11.7917
step:1088/1750 train_time:534427ms step_avg:491.20ms
[train step 1088] avg_loss=3.428387 main=2.965755 aux=0.462632 imp_cv2=0.1363 load_cv2=5.2586 usage_frac=0.4196 topk_prob_mean=0.2767 ema_alpha_reverse=nan max_logit=11.7917
step:1089/1750 train_time:534880ms step_avg:491.17ms
[train step 1089] avg_loss=3.596548 main=3.131907 aux=0.464641 imp_cv2=0.1463 load_cv2=5.2693 usage_frac=0.4196 topk_prob_mean=0.2790 ema_alpha_reverse=nan max_logit=11.7917
step:1090/1750 train_time:535572ms step_avg:491.35ms
[train step 1090] avg_loss=3.579028 main=3.121358 aux=0.457670 imp_cv2=0.2073 load_cv2=5.1235 usage_frac=0.4241 topk_prob_mean=0.3021 ema_alpha_reverse=nan max_logit=11.7917
step:1091/1750 train_time:536049ms step_avg:491.34ms
[train step 1091] avg_loss=3.479887 main=3.015103 aux=0.464783 imp_cv2=0.1307 load_cv2=5.2890 usage_frac=0.4196 topk_prob_mean=0.2752 ema_alpha_reverse=nan max_logit=11.7917
step:1092/1750 train_time:536540ms step_avg:491.34ms
[train step 1092] avg_loss=4.658121 main=4.154328 aux=0.503793 imp_cv2=0.1715 load_cv2=5.7272 usage_frac=0.4196 topk_prob_mean=0.2332 ema_alpha_reverse=nan max_logit=11.7917
step:1093/1750 train_time:537015ms step_avg:491.32ms
[train step 1093] avg_loss=3.511882 main=3.059695 aux=0.452187 imp_cv2=0.1488 load_cv2=5.1171 usage_frac=0.4196 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=11.7917
step:1094/1750 train_time:537500ms step_avg:491.32ms
[train step 1094] avg_loss=3.580306 main=3.116072 aux=0.464234 imp_cv2=0.1881 load_cv2=5.2271 usage_frac=0.4196 topk_prob_mean=0.2946 ema_alpha_reverse=nan max_logit=11.7917
step:1095/1750 train_time:537976ms step_avg:491.30ms
[train step 1095] avg_loss=3.487660 main=3.027365 aux=0.460296 imp_cv2=0.1657 load_cv2=5.2015 usage_frac=0.4196 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=11.7917
step:1096/1750 train_time:538614ms step_avg:491.44ms
[train step 1096] avg_loss=3.808418 main=3.353304 aux=0.455113 imp_cv2=0.1750 load_cv2=5.1261 usage_frac=0.4241 topk_prob_mean=0.2951 ema_alpha_reverse=nan max_logit=11.7917
step:1097/1750 train_time:539084ms step_avg:491.42ms
[train step 1097] avg_loss=3.419904 main=2.960398 aux=0.459506 imp_cv2=0.2044 load_cv2=5.1501 usage_frac=0.4196 topk_prob_mean=0.3008 ema_alpha_reverse=nan max_logit=11.7917
step:1098/1750 train_time:539551ms step_avg:491.39ms
[train step 1098] avg_loss=3.625853 main=3.165449 aux=0.460404 imp_cv2=0.1133 load_cv2=5.2664 usage_frac=0.4241 topk_prob_mean=0.2688 ema_alpha_reverse=nan max_logit=11.7917
step:1099/1750 train_time:540014ms step_avg:491.37ms
[train step 1099] avg_loss=3.421943 main=2.968545 aux=0.453398 imp_cv2=0.2044 load_cv2=5.0775 usage_frac=0.4286 topk_prob_mean=0.3016 ema_alpha_reverse=nan max_logit=11.7917
step:1100/1750 train_time:540498ms step_avg:491.36ms
Running validation...
step:1100/1750 val_loss:3.182067 train_time:540510ms step_avg:491.37ms
[train step 1100] avg_loss=3.522081 main=3.072740 aux=0.449341 imp_cv2=0.1655 load_cv2=5.0758 usage_frac=0.4196 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=11.7917
step:1101/1750 train_time:540974ms step_avg:491.35ms
[train step 1101] avg_loss=3.768009 main=3.311298 aux=0.456711 imp_cv2=0.1562 load_cv2=5.1751 usage_frac=0.4241 topk_prob_mean=0.2842 ema_alpha_reverse=nan max_logit=11.7917
step:1102/1750 train_time:541443ms step_avg:491.33ms
[train step 1102] avg_loss=3.650230 main=3.192786 aux=0.457444 imp_cv2=0.0995 load_cv2=5.2438 usage_frac=0.4241 topk_prob_mean=0.2635 ema_alpha_reverse=nan max_logit=11.7917
step:1103/1750 train_time:541928ms step_avg:491.32ms
[train step 1103] avg_loss=3.816990 main=3.352860 aux=0.464130 imp_cv2=0.1233 load_cv2=5.3012 usage_frac=0.4241 topk_prob_mean=0.2674 ema_alpha_reverse=nan max_logit=11.7917
step:1104/1750 train_time:542403ms step_avg:491.31ms
[train step 1104] avg_loss=3.746466 main=3.286259 aux=0.460207 imp_cv2=0.1086 load_cv2=5.2736 usage_frac=0.4286 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=11.7917
step:1105/1750 train_time:542874ms step_avg:491.29ms
[train step 1105] avg_loss=3.589568 main=3.137238 aux=0.452329 imp_cv2=0.1597 load_cv2=5.1231 usage_frac=0.4241 topk_prob_mean=0.2881 ema_alpha_reverse=nan max_logit=11.7917
step:1106/1750 train_time:543349ms step_avg:491.27ms
[train step 1106] avg_loss=3.147073 main=2.698670 aux=0.448404 imp_cv2=0.2670 load_cv2=4.9602 usage_frac=0.4241 topk_prob_mean=0.3227 ema_alpha_reverse=nan max_logit=11.7917
step:1107/1750 train_time:543829ms step_avg:491.26ms
[train step 1107] avg_loss=3.416941 main=2.964838 aux=0.452103 imp_cv2=0.2071 load_cv2=5.0726 usage_frac=0.4241 topk_prob_mean=0.3030 ema_alpha_reverse=nan max_logit=11.7917
step:1108/1750 train_time:544296ms step_avg:491.24ms
[train step 1108] avg_loss=3.462172 main=3.005973 aux=0.456199 imp_cv2=0.1364 load_cv2=5.1967 usage_frac=0.4286 topk_prob_mean=0.2776 ema_alpha_reverse=nan max_logit=11.7917
step:1109/1750 train_time:544765ms step_avg:491.22ms
[train step 1109] avg_loss=3.990247 main=3.523919 aux=0.466328 imp_cv2=0.0859 load_cv2=5.3782 usage_frac=0.4241 topk_prob_mean=0.2531 ema_alpha_reverse=nan max_logit=11.7917
step:1110/1750 train_time:545223ms step_avg:491.19ms
[train step 1110] avg_loss=3.788635 main=3.323932 aux=0.464703 imp_cv2=0.1069 load_cv2=5.3289 usage_frac=0.4241 topk_prob_mean=0.2638 ema_alpha_reverse=nan max_logit=11.7917
step:1111/1750 train_time:545694ms step_avg:491.17ms
[train step 1111] avg_loss=3.361495 main=2.904279 aux=0.457217 imp_cv2=0.1686 load_cv2=5.1731 usage_frac=0.4241 topk_prob_mean=0.2888 ema_alpha_reverse=nan max_logit=11.7917
step:1112/1750 train_time:546159ms step_avg:491.15ms
[train step 1112] avg_loss=3.758221 main=3.272785 aux=0.485435 imp_cv2=0.0761 load_cv2=5.6180 usage_frac=0.4286 topk_prob_mean=0.2325 ema_alpha_reverse=nan max_logit=11.7917
step:1113/1750 train_time:546633ms step_avg:491.13ms
[train step 1113] avg_loss=3.766697 main=3.303640 aux=0.463057 imp_cv2=0.1344 load_cv2=5.2756 usage_frac=0.4241 topk_prob_mean=0.2735 ema_alpha_reverse=nan max_logit=11.7917
step:1114/1750 train_time:547095ms step_avg:491.11ms
[train step 1114] avg_loss=3.892521 main=3.418116 aux=0.474405 imp_cv2=0.1018 load_cv2=5.4581 usage_frac=0.4196 topk_prob_mean=0.2431 ema_alpha_reverse=nan max_logit=11.7917
step:1115/1750 train_time:547553ms step_avg:491.08ms
[train step 1115] avg_loss=3.798877 main=3.327393 aux=0.471484 imp_cv2=0.0740 load_cv2=5.4467 usage_frac=0.4241 topk_prob_mean=0.2445 ema_alpha_reverse=nan max_logit=11.7917
step:1116/1750 train_time:548014ms step_avg:491.05ms
[train step 1116] avg_loss=3.724352 main=3.255388 aux=0.468964 imp_cv2=0.0840 load_cv2=5.4055 usage_frac=0.4241 topk_prob_mean=0.2506 ema_alpha_reverse=nan max_logit=11.7917
step:1117/1750 train_time:548471ms step_avg:491.02ms
[train step 1117] avg_loss=3.639451 main=3.176053 aux=0.463398 imp_cv2=0.1193 load_cv2=5.3032 usage_frac=0.4152 topk_prob_mean=0.2693 ema_alpha_reverse=nan max_logit=11.7917
step:1118/1750 train_time:548927ms step_avg:490.99ms
[train step 1118] avg_loss=3.599316 main=3.130717 aux=0.468599 imp_cv2=0.0697 load_cv2=5.4252 usage_frac=0.4152 topk_prob_mean=0.2446 ema_alpha_reverse=nan max_logit=11.7917
step:1119/1750 train_time:549382ms step_avg:490.96ms
[train step 1119] avg_loss=3.322356 main=2.864530 aux=0.457826 imp_cv2=0.1721 load_cv2=5.1776 usage_frac=0.4196 topk_prob_mean=0.2924 ema_alpha_reverse=nan max_logit=11.7917
step:1120/1750 train_time:549847ms step_avg:490.93ms
[train step 1120] avg_loss=4.344657 main=3.858634 aux=0.486022 imp_cv2=0.0586 load_cv2=5.6367 usage_frac=0.4241 topk_prob_mean=0.2267 ema_alpha_reverse=nan max_logit=11.7917
step:1121/1750 train_time:550307ms step_avg:490.91ms
[train step 1121] avg_loss=3.715456 main=3.253503 aux=0.461953 imp_cv2=0.1326 load_cv2=5.2713 usage_frac=0.4241 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=11.7917
step:1122/1750 train_time:550768ms step_avg:490.88ms
[train step 1122] avg_loss=3.680272 main=3.216247 aux=0.464026 imp_cv2=0.0964 load_cv2=5.3268 usage_frac=0.4241 topk_prob_mean=0.2587 ema_alpha_reverse=nan max_logit=11.7917
step:1123/1750 train_time:551234ms step_avg:490.86ms
[train step 1123] avg_loss=3.351792 main=2.883433 aux=0.468359 imp_cv2=0.1567 load_cv2=5.3212 usage_frac=0.4152 topk_prob_mean=0.2812 ema_alpha_reverse=nan max_logit=11.7917
step:1124/1750 train_time:551693ms step_avg:490.83ms
[train step 1124] avg_loss=3.358441 main=2.897441 aux=0.461000 imp_cv2=0.1518 load_cv2=5.2352 usage_frac=0.4196 topk_prob_mean=0.2840 ema_alpha_reverse=nan max_logit=11.7917
step:1125/1750 train_time:552172ms step_avg:490.82ms
[train step 1125] avg_loss=3.518836 main=3.054470 aux=0.464366 imp_cv2=0.1656 load_cv2=5.2626 usage_frac=0.4196 topk_prob_mean=0.2852 ema_alpha_reverse=nan max_logit=11.7917
step:1126/1750 train_time:552631ms step_avg:490.79ms
[train step 1126] avg_loss=3.682820 main=3.218653 aux=0.464167 imp_cv2=0.1102 load_cv2=5.3209 usage_frac=0.4152 topk_prob_mean=0.2652 ema_alpha_reverse=nan max_logit=11.7917
step:1127/1750 train_time:553092ms step_avg:490.76ms
[train step 1127] avg_loss=3.789370 main=3.318577 aux=0.470793 imp_cv2=0.1026 load_cv2=5.4099 usage_frac=0.4241 topk_prob_mean=0.2594 ema_alpha_reverse=nan max_logit=11.7917
step:1128/1750 train_time:553557ms step_avg:490.74ms
[train step 1128] avg_loss=3.292033 main=2.828338 aux=0.463695 imp_cv2=0.1485 load_cv2=5.2702 usage_frac=0.4241 topk_prob_mean=0.2808 ema_alpha_reverse=nan max_logit=11.7917
step:1129/1750 train_time:554028ms step_avg:490.72ms
[train step 1129] avg_loss=3.628898 main=3.165408 aux=0.463490 imp_cv2=0.1934 load_cv2=5.2208 usage_frac=0.4241 topk_prob_mean=0.2939 ema_alpha_reverse=nan max_logit=11.7917
step:1130/1750 train_time:554514ms step_avg:490.72ms
[train step 1130] avg_loss=3.568035 main=3.099041 aux=0.468994 imp_cv2=0.1407 load_cv2=5.3395 usage_frac=0.4241 topk_prob_mean=0.2749 ema_alpha_reverse=nan max_logit=11.7917
step:1131/1750 train_time:554975ms step_avg:490.69ms
[train step 1131] avg_loss=3.575671 main=3.113301 aux=0.462370 imp_cv2=0.1701 load_cv2=5.2326 usage_frac=0.4286 topk_prob_mean=0.2885 ema_alpha_reverse=nan max_logit=11.7917
step:1132/1750 train_time:555435ms step_avg:490.67ms
[train step 1132] avg_loss=3.519675 main=3.055751 aux=0.463924 imp_cv2=0.1702 load_cv2=5.2510 usage_frac=0.4196 topk_prob_mean=0.2876 ema_alpha_reverse=nan max_logit=11.7917
step:1133/1750 train_time:555904ms step_avg:490.65ms
[train step 1133] avg_loss=3.963446 main=3.501132 aux=0.462314 imp_cv2=0.2109 load_cv2=5.1893 usage_frac=0.4196 topk_prob_mean=0.3010 ema_alpha_reverse=nan max_logit=11.7917
step:1134/1750 train_time:556380ms step_avg:490.64ms
[train step 1134] avg_loss=3.852569 main=3.375081 aux=0.477489 imp_cv2=0.0826 load_cv2=5.5093 usage_frac=0.4196 topk_prob_mean=0.2477 ema_alpha_reverse=nan max_logit=11.7917
step:1135/1750 train_time:556833ms step_avg:490.60ms
[train step 1135] avg_loss=3.733530 main=3.259968 aux=0.473562 imp_cv2=0.0982 load_cv2=5.4381 usage_frac=0.4152 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:1136/1750 train_time:557290ms step_avg:490.57ms
[train step 1136] avg_loss=3.874426 main=3.398336 aux=0.476090 imp_cv2=0.0883 load_cv2=5.4852 usage_frac=0.4196 topk_prob_mean=0.2511 ema_alpha_reverse=nan max_logit=11.7917
step:1137/1750 train_time:557752ms step_avg:490.55ms
[train step 1137] avg_loss=3.317299 main=2.853563 aux=0.463737 imp_cv2=0.1433 load_cv2=5.2756 usage_frac=0.4196 topk_prob_mean=0.2790 ema_alpha_reverse=nan max_logit=11.7917
step:1138/1750 train_time:558212ms step_avg:490.52ms
[train step 1138] avg_loss=4.034234 main=3.543670 aux=0.490564 imp_cv2=0.0549 load_cv2=5.7008 usage_frac=0.4152 topk_prob_mean=0.2213 ema_alpha_reverse=nan max_logit=11.7917
step:1139/1750 train_time:558684ms step_avg:490.50ms
[train step 1139] avg_loss=3.924363 main=3.446243 aux=0.478120 imp_cv2=0.0561 load_cv2=5.5464 usage_frac=0.4152 topk_prob_mean=0.2328 ema_alpha_reverse=nan max_logit=11.7917
step:1140/1750 train_time:559146ms step_avg:490.48ms
[train step 1140] avg_loss=3.577778 main=3.108224 aux=0.469554 imp_cv2=0.1112 load_cv2=5.3824 usage_frac=0.4152 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=11.7917
step:1141/1750 train_time:559617ms step_avg:490.46ms
[train step 1141] avg_loss=3.597453 main=3.126684 aux=0.470769 imp_cv2=0.0830 load_cv2=5.4290 usage_frac=0.4152 topk_prob_mean=0.2519 ema_alpha_reverse=nan max_logit=11.7917
step:1142/1750 train_time:560078ms step_avg:490.44ms
[train step 1142] avg_loss=3.363818 main=2.904250 aux=0.459568 imp_cv2=0.1828 load_cv2=5.1849 usage_frac=0.4196 topk_prob_mean=0.2950 ema_alpha_reverse=nan max_logit=11.7917
step:1143/1750 train_time:560554ms step_avg:490.42ms
[train step 1143] avg_loss=3.718487 main=3.241159 aux=0.477328 imp_cv2=0.0781 load_cv2=5.5149 usage_frac=0.4107 topk_prob_mean=0.2469 ema_alpha_reverse=nan max_logit=11.7917
step:1144/1750 train_time:561019ms step_avg:490.40ms
[train step 1144] avg_loss=4.179637 main=3.701341 aux=0.478296 imp_cv2=0.0753 load_cv2=5.5348 usage_frac=0.4241 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=11.7917
step:1145/1750 train_time:561474ms step_avg:490.37ms
[train step 1145] avg_loss=3.542201 main=3.068073 aux=0.474129 imp_cv2=0.0783 load_cv2=5.4813 usage_frac=0.4196 topk_prob_mean=0.2472 ema_alpha_reverse=nan max_logit=11.7917
step:1146/1750 train_time:561937ms step_avg:490.35ms
[train step 1146] avg_loss=3.692356 main=3.229292 aux=0.463064 imp_cv2=0.1770 load_cv2=5.2375 usage_frac=0.4196 topk_prob_mean=0.2914 ema_alpha_reverse=nan max_logit=11.7917
step:1147/1750 train_time:562393ms step_avg:490.32ms
[train step 1147] avg_loss=3.728605 main=3.265858 aux=0.462747 imp_cv2=0.1606 load_cv2=5.2521 usage_frac=0.4196 topk_prob_mean=0.2862 ema_alpha_reverse=nan max_logit=11.7917
step:1148/1750 train_time:562856ms step_avg:490.29ms
[train step 1148] avg_loss=3.724417 main=3.243563 aux=0.480855 imp_cv2=0.0764 load_cv2=5.5652 usage_frac=0.4241 topk_prob_mean=0.2429 ema_alpha_reverse=nan max_logit=11.7917
step:1149/1750 train_time:563313ms step_avg:490.26ms
[train step 1149] avg_loss=3.371433 main=2.909674 aux=0.461759 imp_cv2=0.1404 load_cv2=5.2618 usage_frac=0.4241 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=11.7917
step:1150/1750 train_time:563779ms step_avg:490.24ms
Running validation...
step:1150/1750 val_loss:3.157763 train_time:563791ms step_avg:490.25ms
[train step 1150] avg_loss=3.494903 main=2.992152 aux=0.502751 imp_cv2=0.1015 load_cv2=5.7898 usage_frac=0.4107 topk_prob_mean=0.2156 ema_alpha_reverse=nan max_logit=11.7917
step:1151/1750 train_time:564440ms step_avg:490.39ms
[train step 1151] avg_loss=3.183508 main=2.721395 aux=0.462114 imp_cv2=0.2421 load_cv2=5.1589 usage_frac=0.4286 topk_prob_mean=0.3113 ema_alpha_reverse=nan max_logit=11.7917
step:1152/1750 train_time:564909ms step_avg:490.37ms
[train step 1152] avg_loss=3.624688 main=3.163860 aux=0.460827 imp_cv2=0.1674 load_cv2=5.2249 usage_frac=0.4286 topk_prob_mean=0.2893 ema_alpha_reverse=nan max_logit=11.7917
step:1153/1750 train_time:565376ms step_avg:490.35ms
[train step 1153] avg_loss=3.563636 main=3.098537 aux=0.465099 imp_cv2=0.1801 load_cv2=5.2624 usage_frac=0.4241 topk_prob_mean=0.2906 ema_alpha_reverse=nan max_logit=11.7917
step:1154/1750 train_time:565847ms step_avg:490.34ms
[train step 1154] avg_loss=3.651492 main=3.180913 aux=0.470580 imp_cv2=0.1244 load_cv2=5.3877 usage_frac=0.4241 topk_prob_mean=0.2701 ema_alpha_reverse=nan max_logit=11.7917
step:1155/1750 train_time:566306ms step_avg:490.31ms
[train step 1155] avg_loss=3.416967 main=2.958219 aux=0.458748 imp_cv2=0.1678 load_cv2=5.2030 usage_frac=0.4286 topk_prob_mean=0.2909 ema_alpha_reverse=nan max_logit=11.7917
step:1156/1750 train_time:566770ms step_avg:490.29ms
[train step 1156] avg_loss=3.746284 main=3.279809 aux=0.466475 imp_cv2=0.0945 load_cv2=5.3648 usage_frac=0.4241 topk_prob_mean=0.2614 ema_alpha_reverse=nan max_logit=11.7917
step:1157/1750 train_time:567237ms step_avg:490.27ms
[train step 1157] avg_loss=3.298442 main=2.838942 aux=0.459500 imp_cv2=0.1827 load_cv2=5.1874 usage_frac=0.4241 topk_prob_mean=0.2973 ema_alpha_reverse=nan max_logit=11.7917
step:1158/1750 train_time:567707ms step_avg:490.25ms
[train step 1158] avg_loss=3.908981 main=3.428815 aux=0.480167 imp_cv2=0.0686 load_cv2=5.5556 usage_frac=0.4241 topk_prob_mean=0.2401 ema_alpha_reverse=nan max_logit=11.7917
step:1159/1750 train_time:568169ms step_avg:490.22ms
[train step 1159] avg_loss=3.946866 main=3.471889 aux=0.474977 imp_cv2=0.0659 load_cv2=5.4995 usage_frac=0.4241 topk_prob_mean=0.2423 ema_alpha_reverse=nan max_logit=11.7917
step:1160/1750 train_time:568636ms step_avg:490.20ms
[train step 1160] avg_loss=3.441180 main=2.980820 aux=0.460360 imp_cv2=0.1571 load_cv2=5.2205 usage_frac=0.4241 topk_prob_mean=0.2884 ema_alpha_reverse=nan max_logit=11.7917
step:1161/1750 train_time:569106ms step_avg:490.19ms
[train step 1161] avg_loss=3.226737 main=2.763554 aux=0.463184 imp_cv2=0.2180 load_cv2=5.1907 usage_frac=0.4241 topk_prob_mean=0.3053 ema_alpha_reverse=nan max_logit=11.7917
step:1162/1750 train_time:569573ms step_avg:490.17ms
[train step 1162] avg_loss=3.532484 main=3.076977 aux=0.455508 imp_cv2=0.1709 load_cv2=5.1503 usage_frac=0.4241 topk_prob_mean=0.2929 ema_alpha_reverse=nan max_logit=11.7917
step:1163/1750 train_time:570046ms step_avg:490.15ms
[train step 1163] avg_loss=3.461611 main=3.003592 aux=0.458018 imp_cv2=0.1484 load_cv2=5.2079 usage_frac=0.4286 topk_prob_mean=0.2864 ema_alpha_reverse=nan max_logit=11.7917
step:1164/1750 train_time:570507ms step_avg:490.13ms
[train step 1164] avg_loss=3.567508 main=3.098102 aux=0.469406 imp_cv2=0.0820 load_cv2=5.4140 usage_frac=0.4286 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:1165/1750 train_time:570969ms step_avg:490.10ms
[train step 1165] avg_loss=3.410419 main=2.955888 aux=0.454531 imp_cv2=0.1826 load_cv2=5.1273 usage_frac=0.4286 topk_prob_mean=0.2998 ema_alpha_reverse=nan max_logit=11.7917
step:1166/1750 train_time:571439ms step_avg:490.09ms
[train step 1166] avg_loss=3.362368 main=2.904425 aux=0.457943 imp_cv2=0.1114 load_cv2=5.2477 usage_frac=0.4286 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:1167/1750 train_time:571906ms step_avg:490.06ms
[train step 1167] avg_loss=3.761955 main=3.299481 aux=0.462475 imp_cv2=0.1275 load_cv2=5.2862 usage_frac=0.4241 topk_prob_mean=0.2754 ema_alpha_reverse=nan max_logit=11.7917
step:1168/1750 train_time:572369ms step_avg:490.04ms
[train step 1168] avg_loss=3.528436 main=3.069142 aux=0.459295 imp_cv2=0.1434 load_cv2=5.2254 usage_frac=0.4241 topk_prob_mean=0.2831 ema_alpha_reverse=nan max_logit=11.7917
step:1169/1750 train_time:572832ms step_avg:490.02ms
[train step 1169] avg_loss=3.479072 main=3.013212 aux=0.465860 imp_cv2=0.1353 load_cv2=5.3179 usage_frac=0.4286 topk_prob_mean=0.2765 ema_alpha_reverse=nan max_logit=11.7917
step:1170/1750 train_time:573295ms step_avg:490.00ms
[train step 1170] avg_loss=4.567605 main=4.078493 aux=0.489112 imp_cv2=0.0547 load_cv2=5.6875 usage_frac=0.4241 topk_prob_mean=0.2246 ema_alpha_reverse=nan max_logit=11.7917
step:1171/1750 train_time:573770ms step_avg:489.98ms
[train step 1171] avg_loss=3.279258 main=2.824908 aux=0.454349 imp_cv2=0.2710 load_cv2=5.0325 usage_frac=0.4241 topk_prob_mean=0.3250 ema_alpha_reverse=nan max_logit=11.7917
step:1172/1750 train_time:574241ms step_avg:489.97ms
[train step 1172] avg_loss=3.316356 main=2.857998 aux=0.458358 imp_cv2=0.2253 load_cv2=5.1273 usage_frac=0.4286 topk_prob_mean=0.3101 ema_alpha_reverse=nan max_logit=11.7917
step:1173/1750 train_time:574701ms step_avg:489.94ms
[train step 1173] avg_loss=3.630168 main=3.167639 aux=0.462529 imp_cv2=0.1102 load_cv2=5.3064 usage_frac=0.4330 topk_prob_mean=0.2705 ema_alpha_reverse=nan max_logit=11.7917
step:1174/1750 train_time:575160ms step_avg:489.91ms
[train step 1174] avg_loss=3.327807 main=2.877226 aux=0.450582 imp_cv2=0.2216 load_cv2=5.0395 usage_frac=0.4241 topk_prob_mean=0.3157 ema_alpha_reverse=nan max_logit=11.7917
step:1175/1750 train_time:575623ms step_avg:489.89ms
[train step 1175] avg_loss=3.548703 main=3.092623 aux=0.456080 imp_cv2=0.1469 load_cv2=5.1865 usage_frac=0.4286 topk_prob_mean=0.2874 ema_alpha_reverse=nan max_logit=11.7917
step:1176/1750 train_time:576085ms step_avg:489.87ms
[train step 1176] avg_loss=3.596936 main=3.135529 aux=0.461407 imp_cv2=0.1314 load_cv2=5.2639 usage_frac=0.4241 topk_prob_mean=0.2784 ema_alpha_reverse=nan max_logit=11.7917
step:1177/1750 train_time:576560ms step_avg:489.86ms
[train step 1177] avg_loss=3.500557 main=3.046237 aux=0.454320 imp_cv2=0.1935 load_cv2=5.1172 usage_frac=0.4286 topk_prob_mean=0.3018 ema_alpha_reverse=nan max_logit=11.7917
step:1178/1750 train_time:577035ms step_avg:489.84ms
[train step 1178] avg_loss=3.820756 main=3.316705 aux=0.504051 imp_cv2=0.0635 load_cv2=5.8585 usage_frac=0.4241 topk_prob_mean=0.2115 ema_alpha_reverse=nan max_logit=11.7917
step:1179/1750 train_time:577500ms step_avg:489.82ms
[train step 1179] avg_loss=3.596249 main=3.137968 aux=0.458281 imp_cv2=0.1679 load_cv2=5.1857 usage_frac=0.4286 topk_prob_mean=0.2910 ema_alpha_reverse=nan max_logit=11.7917
step:1180/1750 train_time:577957ms step_avg:489.79ms
[train step 1180] avg_loss=4.041178 main=3.581220 aux=0.459959 imp_cv2=0.1176 load_cv2=5.2518 usage_frac=0.4241 topk_prob_mean=0.2698 ema_alpha_reverse=nan max_logit=11.7917
step:1181/1750 train_time:578421ms step_avg:489.77ms
[train step 1181] avg_loss=3.516204 main=3.066011 aux=0.450192 imp_cv2=0.1908 load_cv2=5.0639 usage_frac=0.4241 topk_prob_mean=0.3027 ema_alpha_reverse=nan max_logit=11.7917
step:1182/1750 train_time:578877ms step_avg:489.74ms
[train step 1182] avg_loss=3.655636 main=3.194330 aux=0.461306 imp_cv2=0.1303 load_cv2=5.2655 usage_frac=0.4286 topk_prob_mean=0.2753 ema_alpha_reverse=nan max_logit=11.7917
step:1183/1750 train_time:579350ms step_avg:489.73ms
[train step 1183] avg_loss=3.613584 main=3.153378 aux=0.460207 imp_cv2=0.1358 load_cv2=5.2477 usage_frac=0.4286 topk_prob_mean=0.2771 ema_alpha_reverse=nan max_logit=11.7917
step:1184/1750 train_time:579814ms step_avg:489.71ms
[train step 1184] avg_loss=3.558122 main=3.103221 aux=0.454901 imp_cv2=0.2001 load_cv2=5.1113 usage_frac=0.4196 topk_prob_mean=0.3018 ema_alpha_reverse=nan max_logit=11.7917
step:1185/1750 train_time:580269ms step_avg:489.68ms
[train step 1185] avg_loss=4.294201 main=3.793000 aux=0.501201 imp_cv2=0.0807 load_cv2=5.7894 usage_frac=0.4241 topk_prob_mean=0.2139 ema_alpha_reverse=nan max_logit=11.7917
step:1186/1750 train_time:580732ms step_avg:489.66ms
[train step 1186] avg_loss=4.325189 main=3.844927 aux=0.480262 imp_cv2=0.0938 load_cv2=5.5274 usage_frac=0.4196 topk_prob_mean=0.2468 ema_alpha_reverse=nan max_logit=11.7917
step:1187/1750 train_time:581218ms step_avg:489.65ms
[train step 1187] avg_loss=3.897138 main=3.433269 aux=0.463869 imp_cv2=0.1082 load_cv2=5.3172 usage_frac=0.4286 topk_prob_mean=0.2627 ema_alpha_reverse=nan max_logit=11.7917
step:1188/1750 train_time:581683ms step_avg:489.63ms
[train step 1188] avg_loss=3.524613 main=3.069904 aux=0.454709 imp_cv2=0.2279 load_cv2=5.0743 usage_frac=0.4286 topk_prob_mean=0.3077 ema_alpha_reverse=nan max_logit=11.7917
step:1189/1750 train_time:582146ms step_avg:489.61ms
[train step 1189] avg_loss=3.224854 main=2.767501 aux=0.457353 imp_cv2=0.2076 load_cv2=5.1247 usage_frac=0.4375 topk_prob_mean=0.3012 ema_alpha_reverse=nan max_logit=11.7917
step:1190/1750 train_time:582613ms step_avg:489.59ms
[train step 1190] avg_loss=3.169729 main=2.721151 aux=0.448578 imp_cv2=0.3184 load_cv2=4.9020 usage_frac=0.4286 topk_prob_mean=0.3345 ema_alpha_reverse=nan max_logit=11.7917
step:1191/1750 train_time:583288ms step_avg:489.75ms
[train step 1191] avg_loss=3.926408 main=3.460187 aux=0.466221 imp_cv2=0.0987 load_cv2=5.3511 usage_frac=0.4241 topk_prob_mean=0.2552 ema_alpha_reverse=nan max_logit=11.7917
step:1192/1750 train_time:583753ms step_avg:489.73ms
[train step 1192] avg_loss=4.435500 main=3.988208 aux=0.447292 imp_cv2=0.1569 load_cv2=5.0570 usage_frac=0.4330 topk_prob_mean=0.2867 ema_alpha_reverse=nan max_logit=11.7917
step:1193/1750 train_time:584223ms step_avg:489.71ms
[train step 1193] avg_loss=4.691392 main=4.207010 aux=0.484382 imp_cv2=0.0705 load_cv2=5.6035 usage_frac=0.4241 topk_prob_mean=0.2290 ema_alpha_reverse=nan max_logit=11.7917
step:1194/1750 train_time:584685ms step_avg:489.69ms
[train step 1194] avg_loss=3.737686 main=3.283969 aux=0.453717 imp_cv2=0.1682 load_cv2=5.1251 usage_frac=0.4241 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=11.7917
step:1195/1750 train_time:585147ms step_avg:489.66ms
[train step 1195] avg_loss=4.151478 main=3.672256 aux=0.479222 imp_cv2=0.0775 load_cv2=5.5370 usage_frac=0.4196 topk_prob_mean=0.2320 ema_alpha_reverse=nan max_logit=11.7917
step:1196/1750 train_time:585611ms step_avg:489.64ms
[train step 1196] avg_loss=3.361200 main=2.908920 aux=0.452279 imp_cv2=0.1885 load_cv2=5.0915 usage_frac=0.4196 topk_prob_mean=0.2919 ema_alpha_reverse=nan max_logit=11.7917
step:1197/1750 train_time:586082ms step_avg:489.63ms
[train step 1197] avg_loss=3.326818 main=2.878149 aux=0.448669 imp_cv2=0.3070 load_cv2=4.9162 usage_frac=0.4286 topk_prob_mean=0.3295 ema_alpha_reverse=nan max_logit=11.7917
step:1198/1750 train_time:586554ms step_avg:489.61ms
[train step 1198] avg_loss=3.030548 main=2.577688 aux=0.452860 imp_cv2=0.4300 load_cv2=4.8307 usage_frac=0.4286 topk_prob_mean=0.3567 ema_alpha_reverse=nan max_logit=11.7917
step:1199/1750 train_time:587046ms step_avg:489.61ms
[train step 1199] avg_loss=3.580852 main=3.127751 aux=0.453101 imp_cv2=0.1867 load_cv2=5.0970 usage_frac=0.4286 topk_prob_mean=0.2925 ema_alpha_reverse=nan max_logit=11.7917
step:1200/1750 train_time:587507ms step_avg:489.59ms
Running validation...
step:1200/1750 val_loss:3.116431 train_time:587519ms step_avg:489.60ms
[train step 1200] avg_loss=3.236610 main=2.791578 aux=0.445032 imp_cv2=0.3336 load_cv2=4.8427 usage_frac=0.4286 topk_prob_mean=0.3384 ema_alpha_reverse=nan max_logit=11.7917
step:1201/1750 train_time:587988ms step_avg:489.58ms
[train step 1201] avg_loss=3.500922 main=3.049956 aux=0.450966 imp_cv2=0.2240 load_cv2=5.0345 usage_frac=0.4330 topk_prob_mean=0.3077 ema_alpha_reverse=nan max_logit=11.7917
step:1202/1750 train_time:588459ms step_avg:489.57ms
[train step 1202] avg_loss=3.103734 main=2.658060 aux=0.445674 imp_cv2=0.3589 load_cv2=4.8241 usage_frac=0.4330 topk_prob_mean=0.3455 ema_alpha_reverse=nan max_logit=11.7917
step:1203/1750 train_time:588932ms step_avg:489.55ms
[train step 1203] avg_loss=3.265174 main=2.820996 aux=0.444178 imp_cv2=0.2047 load_cv2=4.9700 usage_frac=0.4286 topk_prob_mean=0.3055 ema_alpha_reverse=nan max_logit=11.7917
step:1204/1750 train_time:589403ms step_avg:489.54ms
[train step 1204] avg_loss=3.146037 main=2.697745 aux=0.448292 imp_cv2=0.3486 load_cv2=4.8694 usage_frac=0.4286 topk_prob_mean=0.3429 ema_alpha_reverse=nan max_logit=11.7917
step:1205/1750 train_time:589882ms step_avg:489.53ms
[train step 1205] avg_loss=3.950381 main=3.491423 aux=0.458958 imp_cv2=0.1423 load_cv2=5.2223 usage_frac=0.4241 topk_prob_mean=0.2773 ema_alpha_reverse=nan max_logit=11.7917
step:1206/1750 train_time:590364ms step_avg:489.52ms
[train step 1206] avg_loss=3.602635 main=3.146454 aux=0.456181 imp_cv2=0.1431 load_cv2=5.1853 usage_frac=0.4375 topk_prob_mean=0.2788 ema_alpha_reverse=nan max_logit=11.7917
step:1207/1750 train_time:590838ms step_avg:489.51ms
[train step 1207] avg_loss=3.481529 main=3.026719 aux=0.454810 imp_cv2=0.1711 load_cv2=5.1457 usage_frac=0.4286 topk_prob_mean=0.2907 ema_alpha_reverse=nan max_logit=11.7917
step:1208/1750 train_time:591316ms step_avg:489.50ms
[train step 1208] avg_loss=3.716585 main=3.261348 aux=0.455236 imp_cv2=0.2292 load_cv2=5.0765 usage_frac=0.4286 topk_prob_mean=0.3059 ema_alpha_reverse=nan max_logit=11.7917
step:1209/1750 train_time:591805ms step_avg:489.50ms
[train step 1209] avg_loss=3.568158 main=3.115746 aux=0.452411 imp_cv2=0.2074 load_cv2=5.0663 usage_frac=0.4286 topk_prob_mean=0.3020 ema_alpha_reverse=nan max_logit=11.7917
step:1210/1750 train_time:592280ms step_avg:489.49ms
[train step 1210] avg_loss=3.103887 main=2.645559 aux=0.458328 imp_cv2=0.3998 load_cv2=4.9380 usage_frac=0.4286 topk_prob_mean=0.3496 ema_alpha_reverse=nan max_logit=11.7917
step:1211/1750 train_time:592758ms step_avg:489.48ms
[train step 1211] avg_loss=4.075728 main=3.596943 aux=0.478786 imp_cv2=0.0725 load_cv2=5.5235 usage_frac=0.4286 topk_prob_mean=0.2333 ema_alpha_reverse=nan max_logit=11.7917
step:1212/1750 train_time:593232ms step_avg:489.47ms
[train step 1212] avg_loss=3.720644 main=3.264506 aux=0.456138 imp_cv2=0.1952 load_cv2=5.1238 usage_frac=0.4286 topk_prob_mean=0.2957 ema_alpha_reverse=nan max_logit=11.7917
step:1213/1750 train_time:593694ms step_avg:489.44ms
[train step 1213] avg_loss=3.300357 main=2.843200 aux=0.457157 imp_cv2=0.3040 load_cv2=5.0211 usage_frac=0.4241 topk_prob_mean=0.3240 ema_alpha_reverse=nan max_logit=11.7917
step:1214/1750 train_time:594172ms step_avg:489.43ms
[train step 1214] avg_loss=3.434855 main=2.980102 aux=0.454753 imp_cv2=0.2142 load_cv2=5.0890 usage_frac=0.4286 topk_prob_mean=0.3046 ema_alpha_reverse=nan max_logit=11.7917
step:1215/1750 train_time:594640ms step_avg:489.42ms
[train step 1215] avg_loss=3.509173 main=3.050909 aux=0.458264 imp_cv2=0.2009 load_cv2=5.1453 usage_frac=0.4196 topk_prob_mean=0.2989 ema_alpha_reverse=nan max_logit=11.7917
step:1216/1750 train_time:595108ms step_avg:489.40ms
[train step 1216] avg_loss=3.380839 main=2.921107 aux=0.459732 imp_cv2=0.2377 load_cv2=5.1215 usage_frac=0.4241 topk_prob_mean=0.3086 ema_alpha_reverse=nan max_logit=11.7917
step:1217/1750 train_time:595573ms step_avg:489.38ms
[train step 1217] avg_loss=3.279165 main=2.812864 aux=0.466302 imp_cv2=0.3240 load_cv2=5.1045 usage_frac=0.4286 topk_prob_mean=0.3269 ema_alpha_reverse=nan max_logit=11.7917
step:1218/1750 train_time:596044ms step_avg:489.36ms
[train step 1218] avg_loss=3.843043 main=3.375402 aux=0.467641 imp_cv2=0.1633 load_cv2=5.2967 usage_frac=0.4241 topk_prob_mean=0.2804 ema_alpha_reverse=nan max_logit=11.7917
step:1219/1750 train_time:596520ms step_avg:489.35ms
[train step 1219] avg_loss=3.576331 main=3.114564 aux=0.461768 imp_cv2=0.1481 load_cv2=5.2389 usage_frac=0.4241 topk_prob_mean=0.2821 ema_alpha_reverse=nan max_logit=11.7917
step:1220/1750 train_time:596975ms step_avg:489.32ms
[train step 1220] avg_loss=3.536669 main=3.078785 aux=0.457884 imp_cv2=0.1159 load_cv2=5.2336 usage_frac=0.4196 topk_prob_mean=0.2705 ema_alpha_reverse=nan max_logit=11.7917
step:1221/1750 train_time:597448ms step_avg:489.31ms
[train step 1221] avg_loss=3.556402 main=3.093586 aux=0.462815 imp_cv2=0.1648 load_cv2=5.2371 usage_frac=0.4196 topk_prob_mean=0.2856 ema_alpha_reverse=nan max_logit=11.7917
step:1222/1750 train_time:597930ms step_avg:489.30ms
[train step 1222] avg_loss=3.106445 main=2.648271 aux=0.458175 imp_cv2=0.3229 load_cv2=5.0085 usage_frac=0.4196 topk_prob_mean=0.3339 ema_alpha_reverse=nan max_logit=11.7917
step:1223/1750 train_time:598392ms step_avg:489.28ms
[train step 1223] avg_loss=3.689992 main=3.219886 aux=0.470106 imp_cv2=0.0833 load_cv2=5.4150 usage_frac=0.4196 topk_prob_mean=0.2518 ema_alpha_reverse=nan max_logit=11.7917
step:1224/1750 train_time:598843ms step_avg:489.25ms
[train step 1224] avg_loss=3.837511 main=3.363834 aux=0.473677 imp_cv2=0.0721 load_cv2=5.4679 usage_frac=0.4286 topk_prob_mean=0.2446 ema_alpha_reverse=nan max_logit=11.7917
step:1225/1750 train_time:599294ms step_avg:489.22ms
[train step 1225] avg_loss=3.168883 main=2.712947 aux=0.455936 imp_cv2=0.2476 load_cv2=5.0705 usage_frac=0.4330 topk_prob_mean=0.3163 ema_alpha_reverse=nan max_logit=11.7917
step:1226/1750 train_time:599748ms step_avg:489.19ms
[train step 1226] avg_loss=3.219566 main=2.764162 aux=0.455404 imp_cv2=0.2719 load_cv2=5.0357 usage_frac=0.4241 topk_prob_mean=0.3238 ema_alpha_reverse=nan max_logit=11.7917
step:1227/1750 train_time:600221ms step_avg:489.18ms
[train step 1227] avg_loss=4.684542 main=4.174299 aux=0.510243 imp_cv2=0.0377 load_cv2=5.9268 usage_frac=0.4241 topk_prob_mean=0.1925 ema_alpha_reverse=nan max_logit=11.7917
step:1228/1750 train_time:600894ms step_avg:489.33ms
[train step 1228] avg_loss=3.670182 main=3.210035 aux=0.460147 imp_cv2=0.1433 load_cv2=5.2384 usage_frac=0.4330 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=11.7917
step:1229/1750 train_time:601365ms step_avg:489.31ms
[train step 1229] avg_loss=3.614658 main=3.130500 aux=0.484158 imp_cv2=0.0494 load_cv2=5.6176 usage_frac=0.4152 topk_prob_mean=0.2228 ema_alpha_reverse=nan max_logit=11.7917
step:1230/1750 train_time:601840ms step_avg:489.30ms
[train step 1230] avg_loss=3.788478 main=3.308029 aux=0.480449 imp_cv2=0.0701 load_cv2=5.5613 usage_frac=0.4152 topk_prob_mean=0.2363 ema_alpha_reverse=nan max_logit=11.7917
step:1231/1750 train_time:602295ms step_avg:489.27ms
[train step 1231] avg_loss=3.799950 main=3.335052 aux=0.464898 imp_cv2=0.0886 load_cv2=5.3500 usage_frac=0.4286 topk_prob_mean=0.2563 ema_alpha_reverse=nan max_logit=11.7917
step:1232/1750 train_time:602766ms step_avg:489.26ms
[train step 1232] avg_loss=3.670672 main=3.198800 aux=0.471872 imp_cv2=0.0929 load_cv2=5.4346 usage_frac=0.4196 topk_prob_mean=0.2529 ema_alpha_reverse=nan max_logit=11.7917
step:1233/1750 train_time:603253ms step_avg:489.26ms
[train step 1233] avg_loss=3.615043 main=3.154820 aux=0.460223 imp_cv2=0.1059 load_cv2=5.2874 usage_frac=0.4241 topk_prob_mean=0.2649 ema_alpha_reverse=nan max_logit=11.7917
step:1234/1750 train_time:603715ms step_avg:489.23ms
[train step 1234] avg_loss=3.349971 main=2.898991 aux=0.450980 imp_cv2=0.1958 load_cv2=5.0744 usage_frac=0.4330 topk_prob_mean=0.2986 ema_alpha_reverse=nan max_logit=11.7917
step:1235/1750 train_time:604368ms step_avg:489.37ms
[train step 1235] avg_loss=3.252778 main=2.800726 aux=0.452052 imp_cv2=0.2199 load_cv2=5.0641 usage_frac=0.4286 topk_prob_mean=0.3057 ema_alpha_reverse=nan max_logit=11.7917
step:1236/1750 train_time:604840ms step_avg:489.35ms
[train step 1236] avg_loss=3.656207 main=3.193481 aux=0.462727 imp_cv2=0.1072 load_cv2=5.3149 usage_frac=0.4196 topk_prob_mean=0.2636 ema_alpha_reverse=nan max_logit=11.7917
step:1237/1750 train_time:605321ms step_avg:489.35ms
[train step 1237] avg_loss=3.345946 main=2.895855 aux=0.450091 imp_cv2=0.1873 load_cv2=5.0715 usage_frac=0.4196 topk_prob_mean=0.2968 ema_alpha_reverse=nan max_logit=11.7917
step:1238/1750 train_time:605788ms step_avg:489.33ms
[train step 1238] avg_loss=3.874837 main=3.411180 aux=0.463657 imp_cv2=0.0857 load_cv2=5.3479 usage_frac=0.4241 topk_prob_mean=0.2532 ema_alpha_reverse=nan max_logit=11.7917
step:1239/1750 train_time:606251ms step_avg:489.31ms
[train step 1239] avg_loss=3.478431 main=3.011253 aux=0.467178 imp_cv2=0.1018 load_cv2=5.3746 usage_frac=0.4196 topk_prob_mean=0.2591 ema_alpha_reverse=nan max_logit=11.7917
step:1240/1750 train_time:606728ms step_avg:489.30ms
[train step 1240] avg_loss=3.775174 main=3.306744 aux=0.468431 imp_cv2=0.0767 load_cv2=5.4130 usage_frac=0.4241 topk_prob_mean=0.2455 ema_alpha_reverse=nan max_logit=11.7917
step:1241/1750 train_time:607188ms step_avg:489.27ms
[train step 1241] avg_loss=4.533993 main=4.032466 aux=0.501527 imp_cv2=0.0707 load_cv2=5.8214 usage_frac=0.4196 topk_prob_mean=0.1997 ema_alpha_reverse=nan max_logit=11.7917
step:1242/1750 train_time:607662ms step_avg:489.26ms
[train step 1242] avg_loss=3.293583 main=2.845976 aux=0.447607 imp_cv2=0.1757 load_cv2=5.0512 usage_frac=0.4286 topk_prob_mean=0.2919 ema_alpha_reverse=nan max_logit=11.7917
step:1243/1750 train_time:608323ms step_avg:489.40ms
[train step 1243] avg_loss=3.977203 main=3.514187 aux=0.463016 imp_cv2=0.0799 load_cv2=5.3393 usage_frac=0.4196 topk_prob_mean=0.2470 ema_alpha_reverse=nan max_logit=11.7917
step:1244/1750 train_time:608795ms step_avg:489.39ms
[train step 1244] avg_loss=3.251468 main=2.801362 aux=0.450107 imp_cv2=0.2298 load_cv2=5.0232 usage_frac=0.4286 topk_prob_mean=0.3071 ema_alpha_reverse=nan max_logit=11.7917
step:1245/1750 train_time:609270ms step_avg:489.37ms
[train step 1245] avg_loss=3.725651 main=3.262088 aux=0.463563 imp_cv2=0.0873 load_cv2=5.3386 usage_frac=0.4241 topk_prob_mean=0.2507 ema_alpha_reverse=nan max_logit=11.7917
step:1246/1750 train_time:609728ms step_avg:489.35ms
[train step 1246] avg_loss=3.779199 main=3.331871 aux=0.447328 imp_cv2=0.1921 load_cv2=5.0276 usage_frac=0.4375 topk_prob_mean=0.2959 ema_alpha_reverse=nan max_logit=11.7917
step:1247/1750 train_time:610206ms step_avg:489.34ms
[train step 1247] avg_loss=3.559817 main=3.098946 aux=0.460871 imp_cv2=0.1153 load_cv2=5.2758 usage_frac=0.4286 topk_prob_mean=0.2646 ema_alpha_reverse=nan max_logit=11.7917
step:1248/1750 train_time:610665ms step_avg:489.32ms
[train step 1248] avg_loss=4.613699 main=4.089888 aux=0.523811 imp_cv2=0.0511 load_cv2=6.0901 usage_frac=0.4018 topk_prob_mean=0.1832 ema_alpha_reverse=nan max_logit=9.8264
step:1249/1750 train_time:611131ms step_avg:489.30ms
[train step 1249] avg_loss=3.930908 main=3.453937 aux=0.476971 imp_cv2=0.0568 load_cv2=5.5317 usage_frac=0.4330 topk_prob_mean=0.2270 ema_alpha_reverse=nan max_logit=11.7917
step:1250/1750 train_time:611609ms step_avg:489.29ms
Running validation...
step:1250/1750 val_loss:3.106403 train_time:611621ms step_avg:489.30ms
[train step 1250] avg_loss=3.314676 main=2.865398 aux=0.449277 imp_cv2=0.1864 load_cv2=5.0573 usage_frac=0.4330 topk_prob_mean=0.2954 ema_alpha_reverse=nan max_logit=11.7917
step:1251/1750 train_time:612080ms step_avg:489.27ms
[train step 1251] avg_loss=3.793279 main=3.332246 aux=0.461033 imp_cv2=0.1083 load_cv2=5.2839 usage_frac=0.4330 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=11.7917
step:1252/1750 train_time:612537ms step_avg:489.25ms
[train step 1252] avg_loss=3.672813 main=3.222030 aux=0.450783 imp_cv2=0.1414 load_cv2=5.1216 usage_frac=0.4330 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=11.7917
step:1253/1750 train_time:613013ms step_avg:489.24ms
[train step 1253] avg_loss=3.766657 main=3.299499 aux=0.467158 imp_cv2=0.0806 load_cv2=5.3870 usage_frac=0.4330 topk_prob_mean=0.2478 ema_alpha_reverse=nan max_logit=11.7917
step:1254/1750 train_time:613489ms step_avg:489.23ms
[train step 1254] avg_loss=4.148778 main=3.669694 aux=0.479084 imp_cv2=0.0608 load_cv2=5.5536 usage_frac=0.4330 topk_prob_mean=0.2307 ema_alpha_reverse=nan max_logit=11.7917
step:1255/1750 train_time:613959ms step_avg:489.21ms
[train step 1255] avg_loss=3.403077 main=2.955903 aux=0.447174 imp_cv2=0.2514 load_cv2=4.9646 usage_frac=0.4375 topk_prob_mean=0.3137 ema_alpha_reverse=nan max_logit=11.7917
step:1256/1750 train_time:614436ms step_avg:489.20ms
[train step 1256] avg_loss=4.488779 main=3.975152 aux=0.513627 imp_cv2=0.0724 load_cv2=5.9491 usage_frac=0.4196 topk_prob_mean=0.1934 ema_alpha_reverse=nan max_logit=10.8091
step:1257/1750 train_time:614904ms step_avg:489.18ms
[train step 1257] avg_loss=3.364382 main=2.918186 aux=0.446196 imp_cv2=0.2116 load_cv2=4.9918 usage_frac=0.4420 topk_prob_mean=0.3034 ema_alpha_reverse=nan max_logit=11.7917
step:1258/1750 train_time:615366ms step_avg:489.16ms
[train step 1258] avg_loss=3.565586 main=3.120202 aux=0.445383 imp_cv2=0.1508 load_cv2=5.0444 usage_frac=0.4330 topk_prob_mean=0.2861 ema_alpha_reverse=nan max_logit=11.7917
step:1259/1750 train_time:615837ms step_avg:489.15ms
[train step 1259] avg_loss=3.432787 main=2.984735 aux=0.448052 imp_cv2=0.1961 load_cv2=5.0320 usage_frac=0.4286 topk_prob_mean=0.2969 ema_alpha_reverse=nan max_logit=11.7917
step:1260/1750 train_time:616315ms step_avg:489.14ms
[train step 1260] avg_loss=3.310455 main=2.856009 aux=0.454445 imp_cv2=0.1184 load_cv2=5.1909 usage_frac=0.4286 topk_prob_mean=0.2683 ema_alpha_reverse=nan max_logit=11.7917
step:1261/1750 train_time:616786ms step_avg:489.12ms
[train step 1261] avg_loss=3.975983 main=3.515341 aux=0.460642 imp_cv2=0.1152 load_cv2=5.2708 usage_frac=0.4330 topk_prob_mean=0.2662 ema_alpha_reverse=nan max_logit=11.7917
step:1262/1750 train_time:617253ms step_avg:489.11ms
[train step 1262] avg_loss=3.187695 main=2.735734 aux=0.451960 imp_cv2=0.2748 load_cv2=4.9933 usage_frac=0.4420 topk_prob_mean=0.3205 ema_alpha_reverse=nan max_logit=11.7917
step:1263/1750 train_time:617724ms step_avg:489.09ms
[train step 1263] avg_loss=3.413406 main=2.950780 aux=0.462626 imp_cv2=0.1148 load_cv2=5.2897 usage_frac=0.4375 topk_prob_mean=0.2678 ema_alpha_reverse=nan max_logit=11.7917
step:1264/1750 train_time:618188ms step_avg:489.07ms
[train step 1264] avg_loss=4.196220 main=3.663158 aux=0.533062 imp_cv2=0.0659 load_cv2=6.1972 usage_frac=0.4152 topk_prob_mean=0.1822 ema_alpha_reverse=nan max_logit=10.8091
step:1265/1750 train_time:618675ms step_avg:489.07ms
[train step 1265] avg_loss=3.389983 main=2.931660 aux=0.458323 imp_cv2=0.1939 load_cv2=5.1553 usage_frac=0.4241 topk_prob_mean=0.2969 ema_alpha_reverse=nan max_logit=11.7917
step:1266/1750 train_time:619145ms step_avg:489.06ms
[train step 1266] avg_loss=3.460078 main=3.004663 aux=0.455414 imp_cv2=0.1805 load_cv2=5.1311 usage_frac=0.4420 topk_prob_mean=0.2953 ema_alpha_reverse=nan max_logit=11.7917
step:1267/1750 train_time:619612ms step_avg:489.04ms
[train step 1267] avg_loss=3.518824 main=3.055375 aux=0.463449 imp_cv2=0.0962 load_cv2=5.3292 usage_frac=0.4375 topk_prob_mean=0.2601 ema_alpha_reverse=nan max_logit=11.7917
step:1268/1750 train_time:620083ms step_avg:489.02ms
[train step 1268] avg_loss=3.580871 main=3.118459 aux=0.462412 imp_cv2=0.1337 load_cv2=5.2764 usage_frac=0.4330 topk_prob_mean=0.2737 ema_alpha_reverse=nan max_logit=11.7917
step:1269/1750 train_time:620560ms step_avg:489.02ms
[train step 1269] avg_loss=3.519189 main=3.062401 aux=0.456788 imp_cv2=0.1279 load_cv2=5.2086 usage_frac=0.4286 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=11.7917
step:1270/1750 train_time:621037ms step_avg:489.01ms
[train step 1270] avg_loss=3.585407 main=3.131602 aux=0.453805 imp_cv2=0.1427 load_cv2=5.1564 usage_frac=0.4286 topk_prob_mean=0.2809 ema_alpha_reverse=nan max_logit=11.7917
step:1271/1750 train_time:621502ms step_avg:488.99ms
[train step 1271] avg_loss=3.363626 main=2.912836 aux=0.450791 imp_cv2=0.2215 load_cv2=5.0376 usage_frac=0.4464 topk_prob_mean=0.3092 ema_alpha_reverse=nan max_logit=11.7917
step:1272/1750 train_time:621984ms step_avg:488.98ms
[train step 1272] avg_loss=3.759994 main=3.287087 aux=0.472907 imp_cv2=0.0959 load_cv2=5.4397 usage_frac=0.4286 topk_prob_mean=0.2528 ema_alpha_reverse=nan max_logit=11.7917
step:1273/1750 train_time:622455ms step_avg:488.97ms
[train step 1273] avg_loss=3.209421 main=2.763638 aux=0.445784 imp_cv2=0.2403 load_cv2=4.9525 usage_frac=0.4330 topk_prob_mean=0.3173 ema_alpha_reverse=nan max_logit=11.7917
step:1274/1750 train_time:622934ms step_avg:488.96ms
[train step 1274] avg_loss=3.173020 main=2.722425 aux=0.450594 imp_cv2=0.2535 load_cv2=4.9994 usage_frac=0.4420 topk_prob_mean=0.3194 ema_alpha_reverse=nan max_logit=12.2820
step:1275/1750 train_time:623405ms step_avg:488.94ms
[train step 1275] avg_loss=3.155170 main=2.707891 aux=0.447279 imp_cv2=0.2248 load_cv2=4.9873 usage_frac=0.4375 topk_prob_mean=0.3118 ema_alpha_reverse=nan max_logit=11.7917
step:1276/1750 train_time:623895ms step_avg:488.95ms
[train step 1276] avg_loss=3.154844 main=2.704051 aux=0.450793 imp_cv2=0.2275 load_cv2=5.0300 usage_frac=0.4375 topk_prob_mean=0.3105 ema_alpha_reverse=nan max_logit=11.7917
step:1277/1750 train_time:624377ms step_avg:488.94ms
[train step 1277] avg_loss=3.816794 main=3.345200 aux=0.471594 imp_cv2=0.0776 load_cv2=5.4410 usage_frac=0.4286 topk_prob_mean=0.2452 ema_alpha_reverse=nan max_logit=11.7917
step:1278/1750 train_time:624840ms step_avg:488.92ms
[train step 1278] avg_loss=3.260906 main=2.810673 aux=0.450233 imp_cv2=0.2100 load_cv2=5.0391 usage_frac=0.4330 topk_prob_mean=0.3041 ema_alpha_reverse=nan max_logit=11.7917
step:1279/1750 train_time:625309ms step_avg:488.90ms
[train step 1279] avg_loss=3.725802 main=3.233683 aux=0.492120 imp_cv2=0.0643 load_cv2=5.7171 usage_frac=0.4286 topk_prob_mean=0.2257 ema_alpha_reverse=nan max_logit=11.7917
step:1280/1750 train_time:625772ms step_avg:488.88ms
[train step 1280] avg_loss=3.702157 main=3.236379 aux=0.465778 imp_cv2=0.0902 load_cv2=5.3629 usage_frac=0.4375 topk_prob_mean=0.2488 ema_alpha_reverse=nan max_logit=11.7917
step:1281/1750 train_time:626242ms step_avg:488.87ms
[train step 1281] avg_loss=3.965117 main=3.493257 aux=0.471860 imp_cv2=0.0688 load_cv2=5.4554 usage_frac=0.4330 topk_prob_mean=0.2392 ema_alpha_reverse=nan max_logit=11.7917
step:1282/1750 train_time:626688ms step_avg:488.84ms
[train step 1282] avg_loss=4.076787 main=3.587804 aux=0.488983 imp_cv2=0.0576 load_cv2=5.6740 usage_frac=0.4375 topk_prob_mean=0.2185 ema_alpha_reverse=nan max_logit=11.7917
step:1283/1750 train_time:627160ms step_avg:488.82ms
[train step 1283] avg_loss=3.406024 main=2.953420 aux=0.452604 imp_cv2=0.1491 load_cv2=5.1360 usage_frac=0.4464 topk_prob_mean=0.2800 ema_alpha_reverse=nan max_logit=11.7917
step:1284/1750 train_time:627636ms step_avg:488.81ms
[train step 1284] avg_loss=3.281355 main=2.831161 aux=0.450193 imp_cv2=0.1875 load_cv2=5.0660 usage_frac=0.4330 topk_prob_mean=0.2957 ema_alpha_reverse=nan max_logit=11.7917
step:1285/1750 train_time:628117ms step_avg:488.81ms
[train step 1285] avg_loss=3.542318 main=3.095257 aux=0.447061 imp_cv2=0.2212 load_cv2=4.9930 usage_frac=0.4330 topk_prob_mean=0.3046 ema_alpha_reverse=nan max_logit=11.7917
step:1286/1750 train_time:628599ms step_avg:488.80ms
[train step 1286] avg_loss=3.614671 main=3.164096 aux=0.450576 imp_cv2=0.1713 load_cv2=5.0883 usage_frac=0.4420 topk_prob_mean=0.2879 ema_alpha_reverse=nan max_logit=11.7917
step:1287/1750 train_time:629073ms step_avg:488.79ms
[train step 1287] avg_loss=5.718594 main=5.211823 aux=0.506771 imp_cv2=0.0573 load_cv2=5.8873 usage_frac=0.4286 topk_prob_mean=0.2008 ema_alpha_reverse=nan max_logit=11.7917
step:1288/1750 train_time:629540ms step_avg:488.77ms
[train step 1288] avg_loss=5.174204 main=4.696255 aux=0.477949 imp_cv2=0.0762 load_cv2=5.5267 usage_frac=0.4375 topk_prob_mean=0.2329 ema_alpha_reverse=nan max_logit=11.7917
step:1289/1750 train_time:630016ms step_avg:488.76ms
[train step 1289] avg_loss=3.573955 main=3.102323 aux=0.471632 imp_cv2=0.0808 load_cv2=5.4429 usage_frac=0.4286 topk_prob_mean=0.2433 ema_alpha_reverse=nan max_logit=11.7917
step:1290/1750 train_time:630486ms step_avg:488.75ms
[train step 1290] avg_loss=3.497097 main=3.037504 aux=0.459593 imp_cv2=0.1214 load_cv2=5.2511 usage_frac=0.4375 topk_prob_mean=0.2673 ema_alpha_reverse=nan max_logit=11.7917
step:1291/1750 train_time:630964ms step_avg:488.74ms
[train step 1291] avg_loss=3.146853 main=2.698294 aux=0.448559 imp_cv2=0.2653 load_cv2=4.9627 usage_frac=0.4420 topk_prob_mean=0.3183 ema_alpha_reverse=nan max_logit=11.7917
step:1292/1750 train_time:631439ms step_avg:488.73ms
[train step 1292] avg_loss=3.519578 main=3.071075 aux=0.448504 imp_cv2=0.2246 load_cv2=5.0082 usage_frac=0.4375 topk_prob_mean=0.3090 ema_alpha_reverse=nan max_logit=11.7917
step:1293/1750 train_time:631911ms step_avg:488.72ms
[train step 1293] avg_loss=3.433074 main=2.982756 aux=0.450318 imp_cv2=0.2273 load_cv2=5.0252 usage_frac=0.4375 topk_prob_mean=0.3082 ema_alpha_reverse=nan max_logit=11.7917
step:1294/1750 train_time:632392ms step_avg:488.71ms
[train step 1294] avg_loss=3.190005 main=2.741200 aux=0.448805 imp_cv2=0.2808 load_cv2=4.9520 usage_frac=0.4330 topk_prob_mean=0.3262 ema_alpha_reverse=nan max_logit=11.7917
step:1295/1750 train_time:632875ms step_avg:488.71ms
[train step 1295] avg_loss=3.804769 main=3.336447 aux=0.468322 imp_cv2=0.0925 load_cv2=5.3908 usage_frac=0.4375 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:1296/1750 train_time:633344ms step_avg:488.69ms
[train step 1296] avg_loss=3.241095 main=2.792617 aux=0.448479 imp_cv2=0.1726 load_cv2=5.0634 usage_frac=0.4420 topk_prob_mean=0.2974 ema_alpha_reverse=nan max_logit=11.7917
step:1297/1750 train_time:633813ms step_avg:488.68ms
[train step 1297] avg_loss=3.599963 main=3.145965 aux=0.453998 imp_cv2=0.1762 load_cv2=5.1285 usage_frac=0.4375 topk_prob_mean=0.2959 ema_alpha_reverse=nan max_logit=11.7917
step:1298/1750 train_time:634473ms step_avg:488.81ms
[train step 1298] avg_loss=4.030818 main=3.568909 aux=0.461909 imp_cv2=0.0862 load_cv2=5.3200 usage_frac=0.4375 topk_prob_mean=0.2568 ema_alpha_reverse=nan max_logit=11.7917
step:1299/1750 train_time:634942ms step_avg:488.79ms
[train step 1299] avg_loss=3.631104 main=3.161455 aux=0.469649 imp_cv2=0.0877 load_cv2=5.4125 usage_frac=0.4464 topk_prob_mean=0.2521 ema_alpha_reverse=nan max_logit=11.7917
step:1300/1750 train_time:635424ms step_avg:488.79ms
Running validation...
step:1300/1750 val_loss:3.063729 train_time:635436ms step_avg:488.80ms
[train step 1300] avg_loss=3.626890 main=3.170733 aux=0.456157 imp_cv2=0.1444 load_cv2=5.1852 usage_frac=0.4375 topk_prob_mean=0.2832 ema_alpha_reverse=nan max_logit=11.7917
step:1301/1750 train_time:635903ms step_avg:488.78ms
[train step 1301] avg_loss=4.538562 main=4.063087 aux=0.475475 imp_cv2=0.0620 load_cv2=5.5098 usage_frac=0.4330 topk_prob_mean=0.2347 ema_alpha_reverse=nan max_logit=11.7917
step:1302/1750 train_time:636374ms step_avg:488.77ms
[train step 1302] avg_loss=3.739808 main=3.270803 aux=0.469005 imp_cv2=0.0799 load_cv2=5.4072 usage_frac=0.4420 topk_prob_mean=0.2496 ema_alpha_reverse=nan max_logit=11.7917
step:1303/1750 train_time:636839ms step_avg:488.75ms
[train step 1303] avg_loss=2.939961 main=2.486757 aux=0.453205 imp_cv2=0.3101 load_cv2=4.9695 usage_frac=0.4420 topk_prob_mean=0.3343 ema_alpha_reverse=nan max_logit=11.7917
step:1304/1750 train_time:637312ms step_avg:488.74ms
[train step 1304] avg_loss=4.096855 main=3.620305 aux=0.476549 imp_cv2=0.0649 load_cv2=5.5192 usage_frac=0.4330 topk_prob_mean=0.2401 ema_alpha_reverse=nan max_logit=11.7917
step:1305/1750 train_time:637783ms step_avg:488.72ms
[train step 1305] avg_loss=4.035268 main=3.571120 aux=0.464148 imp_cv2=0.0909 load_cv2=5.3420 usage_frac=0.4330 topk_prob_mean=0.2592 ema_alpha_reverse=nan max_logit=11.7917
step:1306/1750 train_time:638242ms step_avg:488.70ms
[train step 1306] avg_loss=3.251210 main=2.797630 aux=0.453580 imp_cv2=0.2726 load_cv2=5.0175 usage_frac=0.4286 topk_prob_mean=0.3230 ema_alpha_reverse=nan max_logit=11.7917
step:1307/1750 train_time:638707ms step_avg:488.68ms
[train step 1307] avg_loss=3.791635 main=3.317762 aux=0.473873 imp_cv2=0.0732 load_cv2=5.4761 usage_frac=0.4375 topk_prob_mean=0.2450 ema_alpha_reverse=nan max_logit=11.7917
step:1308/1750 train_time:639191ms step_avg:488.68ms
[train step 1308] avg_loss=3.786856 main=3.321001 aux=0.465854 imp_cv2=0.1076 load_cv2=5.3469 usage_frac=0.4420 topk_prob_mean=0.2654 ema_alpha_reverse=nan max_logit=11.7917
step:1309/1750 train_time:639655ms step_avg:488.66ms
[train step 1309] avg_loss=3.103641 main=2.654074 aux=0.449567 imp_cv2=0.2189 load_cv2=5.0272 usage_frac=0.4509 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=11.7917
step:1310/1750 train_time:640133ms step_avg:488.65ms
[train step 1310] avg_loss=3.681628 main=3.220725 aux=0.460904 imp_cv2=0.1054 load_cv2=5.2830 usage_frac=0.4509 topk_prob_mean=0.2662 ema_alpha_reverse=nan max_logit=11.7917
step:1311/1750 train_time:640611ms step_avg:488.64ms
[train step 1311] avg_loss=3.799241 main=3.316039 aux=0.483202 imp_cv2=0.0579 load_cv2=5.6087 usage_frac=0.4375 topk_prob_mean=0.2300 ema_alpha_reverse=nan max_logit=11.7917
step:1312/1750 train_time:641079ms step_avg:488.63ms
[train step 1312] avg_loss=3.265531 main=2.811738 aux=0.453793 imp_cv2=0.1353 load_cv2=5.1688 usage_frac=0.4375 topk_prob_mean=0.2836 ema_alpha_reverse=nan max_logit=11.7917
step:1313/1750 train_time:641548ms step_avg:488.61ms
[train step 1313] avg_loss=3.318721 main=2.863354 aux=0.455367 imp_cv2=0.1325 load_cv2=5.1882 usage_frac=0.4375 topk_prob_mean=0.2804 ema_alpha_reverse=nan max_logit=11.7917
step:1314/1750 train_time:642024ms step_avg:488.60ms
[train step 1314] avg_loss=3.283833 main=2.828351 aux=0.455482 imp_cv2=0.1871 load_cv2=5.1324 usage_frac=0.4330 topk_prob_mean=0.2999 ema_alpha_reverse=nan max_logit=11.7917
step:1315/1750 train_time:642501ms step_avg:488.59ms
[train step 1315] avg_loss=3.497200 main=3.022005 aux=0.475195 imp_cv2=0.0702 load_cv2=5.4906 usage_frac=0.4330 topk_prob_mean=0.2434 ema_alpha_reverse=nan max_logit=11.7917
step:1316/1750 train_time:642966ms step_avg:488.58ms
[train step 1316] avg_loss=3.337079 main=2.876228 aux=0.460851 imp_cv2=0.1342 load_cv2=5.2590 usage_frac=0.4375 topk_prob_mean=0.2776 ema_alpha_reverse=nan max_logit=11.7917
step:1317/1750 train_time:643437ms step_avg:488.56ms
[train step 1317] avg_loss=3.106909 main=2.651047 aux=0.455862 imp_cv2=0.1984 load_cv2=5.1273 usage_frac=0.4420 topk_prob_mean=0.3020 ema_alpha_reverse=nan max_logit=11.7917
step:1318/1750 train_time:643897ms step_avg:488.54ms
[train step 1318] avg_loss=3.618336 main=3.146859 aux=0.471477 imp_cv2=0.1039 load_cv2=5.4215 usage_frac=0.4375 topk_prob_mean=0.2602 ema_alpha_reverse=nan max_logit=11.7917
step:1319/1750 train_time:644366ms step_avg:488.53ms
[train step 1319] avg_loss=3.376931 main=2.905699 aux=0.471232 imp_cv2=0.1115 load_cv2=5.4147 usage_frac=0.4330 topk_prob_mean=0.2623 ema_alpha_reverse=nan max_logit=11.7917
step:1320/1750 train_time:644824ms step_avg:488.50ms
[train step 1320] avg_loss=3.917277 main=3.436088 aux=0.481189 imp_cv2=0.0542 load_cv2=5.5901 usage_frac=0.4375 topk_prob_mean=0.2291 ema_alpha_reverse=nan max_logit=11.7917
step:1321/1750 train_time:645291ms step_avg:488.49ms
[train step 1321] avg_loss=3.861570 main=3.384791 aux=0.476779 imp_cv2=0.0637 load_cv2=5.5261 usage_frac=0.4420 topk_prob_mean=0.2360 ema_alpha_reverse=nan max_logit=11.7917
step:1322/1750 train_time:645762ms step_avg:488.47ms
[train step 1322] avg_loss=3.746923 main=3.289638 aux=0.457285 imp_cv2=0.1807 load_cv2=5.1688 usage_frac=0.4464 topk_prob_mean=0.2910 ema_alpha_reverse=nan max_logit=11.7917
step:1323/1750 train_time:646235ms step_avg:488.46ms
[train step 1323] avg_loss=4.292677 main=3.802379 aux=0.490298 imp_cv2=0.0516 load_cv2=5.7002 usage_frac=0.4330 topk_prob_mean=0.2174 ema_alpha_reverse=nan max_logit=11.7917
step:1324/1750 train_time:646697ms step_avg:488.44ms
[train step 1324] avg_loss=3.331868 main=2.885082 aux=0.446787 imp_cv2=0.2250 load_cv2=4.9967 usage_frac=0.4420 topk_prob_mean=0.3135 ema_alpha_reverse=nan max_logit=11.7917
step:1325/1750 train_time:647170ms step_avg:488.43ms
[train step 1325] avg_loss=3.373686 main=2.915787 aux=0.457899 imp_cv2=0.1629 load_cv2=5.1924 usage_frac=0.4330 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=11.7917
step:1326/1750 train_time:647637ms step_avg:488.41ms
[train step 1326] avg_loss=3.149029 main=2.679637 aux=0.469393 imp_cv2=0.0960 load_cv2=5.4040 usage_frac=0.4330 topk_prob_mean=0.2558 ema_alpha_reverse=nan max_logit=11.7917
step:1327/1750 train_time:648119ms step_avg:488.41ms
[train step 1327] avg_loss=3.571696 main=3.102381 aux=0.469315 imp_cv2=0.0698 load_cv2=5.4289 usage_frac=0.4330 topk_prob_mean=0.2418 ema_alpha_reverse=nan max_logit=11.7917
step:1328/1750 train_time:648584ms step_avg:488.39ms
[train step 1328] avg_loss=3.672484 main=3.213271 aux=0.459213 imp_cv2=0.0814 load_cv2=5.2960 usage_frac=0.4286 topk_prob_mean=0.2557 ema_alpha_reverse=nan max_logit=11.7917
step:1329/1750 train_time:649040ms step_avg:488.37ms
[train step 1329] avg_loss=3.311396 main=2.862615 aux=0.448782 imp_cv2=0.2283 load_cv2=5.0121 usage_frac=0.4330 topk_prob_mean=0.3109 ema_alpha_reverse=nan max_logit=11.7917
step:1330/1750 train_time:649506ms step_avg:488.35ms
[train step 1330] avg_loss=3.488192 main=3.033803 aux=0.454389 imp_cv2=0.1088 load_cv2=5.2061 usage_frac=0.4375 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=11.7917
step:1331/1750 train_time:649981ms step_avg:488.34ms
[train step 1331] avg_loss=4.018914 main=3.537189 aux=0.481725 imp_cv2=0.0608 load_cv2=5.5878 usage_frac=0.4330 topk_prob_mean=0.2311 ema_alpha_reverse=nan max_logit=11.7917
step:1332/1750 train_time:650445ms step_avg:488.32ms
[train step 1332] avg_loss=3.308909 main=2.851056 aux=0.457853 imp_cv2=0.1687 load_cv2=5.1761 usage_frac=0.4286 topk_prob_mean=0.2884 ema_alpha_reverse=nan max_logit=11.7917
step:1333/1750 train_time:651116ms step_avg:488.46ms
[train step 1333] avg_loss=3.613405 main=3.150315 aux=0.463090 imp_cv2=0.1173 load_cv2=5.2974 usage_frac=0.4330 topk_prob_mean=0.2686 ema_alpha_reverse=nan max_logit=11.7917
step:1334/1750 train_time:651576ms step_avg:488.44ms
[train step 1334] avg_loss=3.261582 main=2.803190 aux=0.458392 imp_cv2=0.1844 load_cv2=5.1667 usage_frac=0.4286 topk_prob_mean=0.2929 ema_alpha_reverse=nan max_logit=11.7917
step:1335/1750 train_time:652052ms step_avg:488.43ms
[train step 1335] avg_loss=4.164060 main=3.687983 aux=0.476078 imp_cv2=0.0894 load_cv2=5.4777 usage_frac=0.4330 topk_prob_mean=0.2440 ema_alpha_reverse=nan max_logit=11.7917
step:1336/1750 train_time:652513ms step_avg:488.41ms
[train step 1336] avg_loss=3.258386 main=2.791244 aux=0.467142 imp_cv2=0.0827 load_cv2=5.3742 usage_frac=0.4330 topk_prob_mean=0.2524 ema_alpha_reverse=nan max_logit=11.7917
step:1337/1750 train_time:652965ms step_avg:488.38ms
[train step 1337] avg_loss=3.296908 main=2.838526 aux=0.458382 imp_cv2=0.2349 load_cv2=5.1169 usage_frac=0.4375 topk_prob_mean=0.3076 ema_alpha_reverse=nan max_logit=11.7917
step:1338/1750 train_time:653453ms step_avg:488.38ms
[train step 1338] avg_loss=3.396279 main=2.928581 aux=0.467698 imp_cv2=0.1193 load_cv2=5.3507 usage_frac=0.4375 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=11.7917
step:1339/1750 train_time:653922ms step_avg:488.37ms
[train step 1339] avg_loss=3.194755 main=2.734500 aux=0.460255 imp_cv2=0.2414 load_cv2=5.1283 usage_frac=0.4375 topk_prob_mean=0.3094 ema_alpha_reverse=nan max_logit=11.7917
step:1340/1750 train_time:654387ms step_avg:488.35ms
[train step 1340] avg_loss=3.786371 main=3.302056 aux=0.484315 imp_cv2=0.0654 load_cv2=5.6044 usage_frac=0.4286 topk_prob_mean=0.2309 ema_alpha_reverse=nan max_logit=11.7917
step:1341/1750 train_time:654854ms step_avg:488.33ms
[train step 1341] avg_loss=3.677686 main=3.214397 aux=0.463289 imp_cv2=0.1116 load_cv2=5.3050 usage_frac=0.4375 topk_prob_mean=0.2670 ema_alpha_reverse=nan max_logit=11.7917
step:1342/1750 train_time:655328ms step_avg:488.32ms
[train step 1342] avg_loss=3.114341 main=2.661783 aux=0.452558 imp_cv2=0.2808 load_cv2=4.9916 usage_frac=0.4330 topk_prob_mean=0.3242 ema_alpha_reverse=nan max_logit=11.7917
step:1343/1750 train_time:655794ms step_avg:488.31ms
[train step 1343] avg_loss=3.127759 main=2.669985 aux=0.457775 imp_cv2=0.2541 load_cv2=5.0864 usage_frac=0.4375 topk_prob_mean=0.3136 ema_alpha_reverse=nan max_logit=11.7917
step:1344/1750 train_time:656263ms step_avg:488.29ms
[train step 1344] avg_loss=3.204430 main=2.746284 aux=0.458146 imp_cv2=0.2096 load_cv2=5.1420 usage_frac=0.4375 topk_prob_mean=0.3004 ema_alpha_reverse=nan max_logit=11.7917
step:1345/1750 train_time:656723ms step_avg:488.27ms
[train step 1345] avg_loss=3.647334 main=3.172915 aux=0.474419 imp_cv2=0.0808 load_cv2=5.4728 usage_frac=0.4330 topk_prob_mean=0.2459 ema_alpha_reverse=nan max_logit=11.7917
step:1346/1750 train_time:657181ms step_avg:488.25ms
[train step 1346] avg_loss=3.861734 main=3.400023 aux=0.461712 imp_cv2=0.1105 load_cv2=5.2814 usage_frac=0.4375 topk_prob_mean=0.2632 ema_alpha_reverse=nan max_logit=11.7917
step:1347/1750 train_time:657844ms step_avg:488.38ms
[train step 1347] avg_loss=2.993727 main=2.544374 aux=0.449353 imp_cv2=0.2501 load_cv2=4.9881 usage_frac=0.4420 topk_prob_mean=0.3157 ema_alpha_reverse=nan max_logit=11.7917
step:1348/1750 train_time:658318ms step_avg:488.37ms
[train step 1348] avg_loss=3.803309 main=3.339988 aux=0.463322 imp_cv2=0.1087 load_cv2=5.3077 usage_frac=0.4375 topk_prob_mean=0.2643 ema_alpha_reverse=nan max_logit=11.7917
step:1349/1750 train_time:658784ms step_avg:488.35ms
[train step 1349] avg_loss=3.644831 main=3.155014 aux=0.489817 imp_cv2=0.0684 load_cv2=5.6652 usage_frac=0.4286 topk_prob_mean=0.2204 ema_alpha_reverse=nan max_logit=11.7917
step:1350/1750 train_time:659446ms step_avg:488.48ms
Running validation...
step:1350/1750 val_loss:3.030149 train_time:659458ms step_avg:488.49ms
[train step 1350] avg_loss=3.282360 main=2.838657 aux=0.443703 imp_cv2=0.2356 load_cv2=4.9312 usage_frac=0.4375 topk_prob_mean=0.3163 ema_alpha_reverse=nan max_logit=11.7917
step:1351/1750 train_time:659932ms step_avg:488.48ms
[train step 1351] avg_loss=3.901397 main=3.440657 aux=0.460740 imp_cv2=0.0864 load_cv2=5.2978 usage_frac=0.4375 topk_prob_mean=0.2575 ema_alpha_reverse=nan max_logit=11.7917
step:1352/1750 train_time:660394ms step_avg:488.46ms
[train step 1352] avg_loss=3.427927 main=2.974521 aux=0.453406 imp_cv2=0.1230 load_cv2=5.1615 usage_frac=0.4420 topk_prob_mean=0.2768 ema_alpha_reverse=nan max_logit=11.7917
step:1353/1750 train_time:660858ms step_avg:488.44ms
[train step 1353] avg_loss=3.664512 main=3.205474 aux=0.459038 imp_cv2=0.1136 load_cv2=5.2434 usage_frac=0.4241 topk_prob_mean=0.2691 ema_alpha_reverse=nan max_logit=11.7917
step:1354/1750 train_time:661323ms step_avg:488.42ms
[train step 1354] avg_loss=2.894033 main=2.451959 aux=0.442074 imp_cv2=0.2866 load_cv2=4.8542 usage_frac=0.4286 topk_prob_mean=0.3335 ema_alpha_reverse=nan max_logit=11.7917
step:1355/1750 train_time:661791ms step_avg:488.41ms
[train step 1355] avg_loss=3.035942 main=2.591021 aux=0.444921 imp_cv2=0.2340 load_cv2=4.9421 usage_frac=0.4330 topk_prob_mean=0.3175 ema_alpha_reverse=nan max_logit=11.7917
step:1356/1750 train_time:662251ms step_avg:488.39ms
[train step 1356] avg_loss=3.361331 main=2.901669 aux=0.459662 imp_cv2=0.0784 load_cv2=5.2960 usage_frac=0.4330 topk_prob_mean=0.2545 ema_alpha_reverse=nan max_logit=11.7917
step:1357/1750 train_time:662715ms step_avg:488.37ms
[train step 1357] avg_loss=4.171872 main=3.654717 aux=0.517156 imp_cv2=0.0436 load_cv2=6.0220 usage_frac=0.4330 topk_prob_mean=0.1881 ema_alpha_reverse=nan max_logit=11.7917
step:1358/1750 train_time:663188ms step_avg:488.36ms
[train step 1358] avg_loss=3.417608 main=2.975514 aux=0.442093 imp_cv2=0.2047 load_cv2=4.9434 usage_frac=0.4375 topk_prob_mean=0.3111 ema_alpha_reverse=nan max_logit=11.7917
step:1359/1750 train_time:663657ms step_avg:488.34ms
[train step 1359] avg_loss=4.016787 main=3.556459 aux=0.460328 imp_cv2=0.0904 load_cv2=5.2871 usage_frac=0.4420 topk_prob_mean=0.2607 ema_alpha_reverse=nan max_logit=11.7917
step:1360/1750 train_time:664130ms step_avg:488.33ms
[train step 1360] avg_loss=3.503153 main=3.057868 aux=0.445285 imp_cv2=0.1797 load_cv2=5.0105 usage_frac=0.4330 topk_prob_mean=0.3018 ema_alpha_reverse=nan max_logit=11.7917
step:1361/1750 train_time:664597ms step_avg:488.31ms
[train step 1361] avg_loss=3.483641 main=3.033663 aux=0.449978 imp_cv2=0.1666 load_cv2=5.0800 usage_frac=0.4286 topk_prob_mean=0.2950 ema_alpha_reverse=nan max_logit=11.7917
step:1362/1750 train_time:665057ms step_avg:488.29ms
[train step 1362] avg_loss=3.395304 main=2.950238 aux=0.445066 imp_cv2=0.1573 load_cv2=5.0383 usage_frac=0.4330 topk_prob_mean=0.2947 ema_alpha_reverse=nan max_logit=11.7917
step:1363/1750 train_time:665529ms step_avg:488.28ms
[train step 1363] avg_loss=3.129866 main=2.683853 aux=0.446013 imp_cv2=0.2050 load_cv2=5.0010 usage_frac=0.4375 topk_prob_mean=0.3103 ema_alpha_reverse=nan max_logit=11.7917
step:1364/1750 train_time:665995ms step_avg:488.27ms
[train step 1364] avg_loss=3.015275 main=2.569536 aux=0.445738 imp_cv2=0.1964 load_cv2=4.9954 usage_frac=0.4286 topk_prob_mean=0.3071 ema_alpha_reverse=nan max_logit=11.7917
step:1365/1750 train_time:666459ms step_avg:488.25ms
[train step 1365] avg_loss=3.755874 main=3.288290 aux=0.467584 imp_cv2=0.0807 load_cv2=5.3910 usage_frac=0.4241 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=11.7917
step:1366/1750 train_time:666931ms step_avg:488.24ms
[train step 1366] avg_loss=3.199189 main=2.755387 aux=0.443802 imp_cv2=0.2561 load_cv2=4.9066 usage_frac=0.4330 topk_prob_mean=0.3248 ema_alpha_reverse=nan max_logit=11.7917
step:1367/1750 train_time:667409ms step_avg:488.23ms
[train step 1367] avg_loss=3.728251 main=3.230484 aux=0.497767 imp_cv2=0.0565 load_cv2=5.7799 usage_frac=0.4375 topk_prob_mean=0.2073 ema_alpha_reverse=nan max_logit=11.7917
step:1368/1750 train_time:667897ms step_avg:488.23ms
[train step 1368] avg_loss=3.528867 main=3.078193 aux=0.450674 imp_cv2=0.1504 load_cv2=5.1075 usage_frac=0.4286 topk_prob_mean=0.2880 ema_alpha_reverse=nan max_logit=11.7917
step:1369/1750 train_time:668378ms step_avg:488.22ms
[train step 1369] avg_loss=3.247483 main=2.802122 aux=0.445361 imp_cv2=0.1895 load_cv2=5.0031 usage_frac=0.4375 topk_prob_mean=0.3031 ema_alpha_reverse=nan max_logit=11.7917
step:1370/1750 train_time:668856ms step_avg:488.22ms
[train step 1370] avg_loss=3.522324 main=3.064409 aux=0.457915 imp_cv2=0.1163 load_cv2=5.2373 usage_frac=0.4330 topk_prob_mean=0.2702 ema_alpha_reverse=nan max_logit=11.7917
step:1371/1750 train_time:669326ms step_avg:488.20ms
[train step 1371] avg_loss=3.056273 main=2.612077 aux=0.444196 imp_cv2=0.2337 load_cv2=4.9392 usage_frac=0.4330 topk_prob_mean=0.3166 ema_alpha_reverse=nan max_logit=11.7917
step:1372/1750 train_time:669805ms step_avg:488.20ms
[train step 1372] avg_loss=3.448393 main=2.997575 aux=0.450818 imp_cv2=0.1543 load_cv2=5.1088 usage_frac=0.4330 topk_prob_mean=0.2888 ema_alpha_reverse=nan max_logit=11.7917
step:1373/1750 train_time:670464ms step_avg:488.32ms
[train step 1373] avg_loss=3.259466 main=2.815064 aux=0.444402 imp_cv2=0.1954 load_cv2=4.9895 usage_frac=0.4464 topk_prob_mean=0.3058 ema_alpha_reverse=nan max_logit=11.7917
step:1374/1750 train_time:671156ms step_avg:488.47ms
[train step 1374] avg_loss=3.508837 main=3.057695 aux=0.451142 imp_cv2=0.1517 load_cv2=5.1248 usage_frac=0.4286 topk_prob_mean=0.2890 ema_alpha_reverse=nan max_logit=11.7917
step:1375/1750 train_time:671615ms step_avg:488.45ms
[train step 1375] avg_loss=3.918806 main=3.448977 aux=0.469829 imp_cv2=0.0648 load_cv2=5.4409 usage_frac=0.4241 topk_prob_mean=0.2436 ema_alpha_reverse=nan max_logit=11.7917
step:1376/1750 train_time:672074ms step_avg:488.43ms
[train step 1376] avg_loss=4.307460 main=3.828090 aux=0.479370 imp_cv2=0.0468 load_cv2=5.5770 usage_frac=0.4241 topk_prob_mean=0.2237 ema_alpha_reverse=nan max_logit=11.7917
step:1377/1750 train_time:672549ms step_avg:488.42ms
[train step 1377] avg_loss=3.228490 main=2.771825 aux=0.456665 imp_cv2=0.1518 load_cv2=5.1832 usage_frac=0.4286 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=11.7917
step:1378/1750 train_time:673025ms step_avg:488.41ms
[train step 1378] avg_loss=4.369263 main=3.862411 aux=0.506852 imp_cv2=0.0384 load_cv2=5.9151 usage_frac=0.4241 topk_prob_mean=0.2008 ema_alpha_reverse=nan max_logit=11.7917
step:1379/1750 train_time:673507ms step_avg:488.40ms
[train step 1379] avg_loss=3.604673 main=3.145172 aux=0.459501 imp_cv2=0.1432 load_cv2=5.2328 usage_frac=0.4241 topk_prob_mean=0.2812 ema_alpha_reverse=nan max_logit=11.7917
step:1380/1750 train_time:673980ms step_avg:488.39ms
[train step 1380] avg_loss=3.548276 main=3.093719 aux=0.454557 imp_cv2=0.1500 load_cv2=5.1608 usage_frac=0.4286 topk_prob_mean=0.2853 ema_alpha_reverse=nan max_logit=11.7917
step:1381/1750 train_time:674446ms step_avg:488.37ms
[train step 1381] avg_loss=3.138797 main=2.684809 aux=0.453988 imp_cv2=0.2071 load_cv2=5.0986 usage_frac=0.4330 topk_prob_mean=0.3054 ema_alpha_reverse=nan max_logit=11.7917
step:1382/1750 train_time:674914ms step_avg:488.36ms
[train step 1382] avg_loss=3.414101 main=2.957227 aux=0.456875 imp_cv2=0.1534 load_cv2=5.1901 usage_frac=0.4375 topk_prob_mean=0.2863 ema_alpha_reverse=nan max_logit=11.7917
step:1383/1750 train_time:675392ms step_avg:488.35ms
[train step 1383] avg_loss=3.314232 main=2.856666 aux=0.457566 imp_cv2=0.1355 load_cv2=5.2191 usage_frac=0.4286 topk_prob_mean=0.2820 ema_alpha_reverse=nan max_logit=11.7917
step:1384/1750 train_time:675853ms step_avg:488.33ms
[train step 1384] avg_loss=3.899611 main=3.420787 aux=0.478825 imp_cv2=0.0648 load_cv2=5.5514 usage_frac=0.4286 topk_prob_mean=0.2398 ema_alpha_reverse=nan max_logit=11.7917
step:1385/1750 train_time:676312ms step_avg:488.31ms
[train step 1385] avg_loss=4.495088 main=3.956018 aux=0.539070 imp_cv2=0.0579 load_cv2=6.2779 usage_frac=0.4062 topk_prob_mean=0.1747 ema_alpha_reverse=nan max_logit=10.8091
step:1386/1750 train_time:676782ms step_avg:488.30ms
[train step 1386] avg_loss=3.071447 main=2.615163 aux=0.456283 imp_cv2=0.2313 load_cv2=5.1006 usage_frac=0.4330 topk_prob_mean=0.3117 ema_alpha_reverse=nan max_logit=11.7917
step:1387/1750 train_time:677254ms step_avg:488.29ms
[train step 1387] avg_loss=3.137656 main=2.677956 aux=0.459701 imp_cv2=0.1477 load_cv2=5.2320 usage_frac=0.4375 topk_prob_mean=0.2844 ema_alpha_reverse=nan max_logit=11.7917
step:1388/1750 train_time:677720ms step_avg:488.27ms
[train step 1388] avg_loss=3.768164 main=3.289590 aux=0.478574 imp_cv2=0.0708 load_cv2=5.5360 usage_frac=0.4286 topk_prob_mean=0.2421 ema_alpha_reverse=nan max_logit=11.7917
step:1389/1750 train_time:678383ms step_avg:488.40ms
[train step 1389] avg_loss=3.472950 main=3.004447 aux=0.468503 imp_cv2=0.0755 load_cv2=5.4164 usage_frac=0.4330 topk_prob_mean=0.2495 ema_alpha_reverse=nan max_logit=11.7917
step:1390/1750 train_time:678840ms step_avg:488.37ms
[train step 1390] avg_loss=3.606845 main=3.126968 aux=0.479876 imp_cv2=0.0794 load_cv2=5.5424 usage_frac=0.4286 topk_prob_mean=0.2442 ema_alpha_reverse=nan max_logit=11.7917
step:1391/1750 train_time:679309ms step_avg:488.36ms
[train step 1391] avg_loss=3.247286 main=2.783113 aux=0.464173 imp_cv2=0.1359 load_cv2=5.2973 usage_frac=0.4241 topk_prob_mean=0.2760 ema_alpha_reverse=nan max_logit=11.7917
step:1392/1750 train_time:679773ms step_avg:488.34ms
[train step 1392] avg_loss=3.721235 main=3.244901 aux=0.476334 imp_cv2=0.0752 load_cv2=5.5117 usage_frac=0.4241 topk_prob_mean=0.2465 ema_alpha_reverse=nan max_logit=11.7917
step:1393/1750 train_time:680237ms step_avg:488.33ms
[train step 1393] avg_loss=3.250651 main=2.784352 aux=0.466299 imp_cv2=0.1254 load_cv2=5.3333 usage_frac=0.4330 topk_prob_mean=0.2722 ema_alpha_reverse=nan max_logit=11.7917
step:1394/1750 train_time:680706ms step_avg:488.31ms
[train step 1394] avg_loss=3.630530 main=3.159415 aux=0.471115 imp_cv2=0.0836 load_cv2=5.4379 usage_frac=0.4286 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:1395/1750 train_time:681159ms step_avg:488.29ms
[train step 1395] avg_loss=4.106573 main=3.580056 aux=0.526517 imp_cv2=0.0488 load_cv2=6.1339 usage_frac=0.4152 topk_prob_mean=0.1804 ema_alpha_reverse=nan max_logit=10.8091
step:1396/1750 train_time:681620ms step_avg:488.27ms
[train step 1396] avg_loss=3.824411 main=3.351474 aux=0.472937 imp_cv2=0.0691 load_cv2=5.4756 usage_frac=0.4241 topk_prob_mean=0.2444 ema_alpha_reverse=nan max_logit=11.7917
step:1397/1750 train_time:682077ms step_avg:488.24ms
[train step 1397] avg_loss=3.956370 main=3.488750 aux=0.467620 imp_cv2=0.0766 load_cv2=5.4088 usage_frac=0.4330 topk_prob_mean=0.2521 ema_alpha_reverse=nan max_logit=11.7917
step:1398/1750 train_time:682548ms step_avg:488.23ms
[train step 1398] avg_loss=3.860162 main=3.394689 aux=0.465473 imp_cv2=0.1065 load_cv2=5.3458 usage_frac=0.4286 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=11.7917
step:1399/1750 train_time:683015ms step_avg:488.22ms
[train step 1399] avg_loss=3.764008 main=3.294069 aux=0.469940 imp_cv2=0.0987 load_cv2=5.4046 usage_frac=0.4241 topk_prob_mean=0.2595 ema_alpha_reverse=nan max_logit=11.7917
step:1400/1750 train_time:683490ms step_avg:488.21ms
Running validation...
step:1400/1750 val_loss:3.015557 train_time:683502ms step_avg:488.22ms
[train step 1400] avg_loss=3.395174 main=2.932519 aux=0.462655 imp_cv2=0.1367 load_cv2=5.2800 usage_frac=0.4241 topk_prob_mean=0.2780 ema_alpha_reverse=nan max_logit=11.7917
step:1401/1750 train_time:683953ms step_avg:488.19ms
[train step 1401] avg_loss=3.435002 main=2.977556 aux=0.457446 imp_cv2=0.1289 load_cv2=5.2268 usage_frac=0.4286 topk_prob_mean=0.2783 ema_alpha_reverse=nan max_logit=11.7917
step:1402/1750 train_time:684420ms step_avg:488.17ms
[train step 1402] avg_loss=4.100653 main=3.599584 aux=0.501069 imp_cv2=0.0375 load_cv2=5.8323 usage_frac=0.4196 topk_prob_mean=0.2031 ema_alpha_reverse=nan max_logit=11.7917
step:1403/1750 train_time:684872ms step_avg:488.15ms
[train step 1403] avg_loss=3.454171 main=2.993399 aux=0.460772 imp_cv2=0.0955 load_cv2=5.2970 usage_frac=0.4330 topk_prob_mean=0.2637 ema_alpha_reverse=nan max_logit=11.7917
step:1404/1750 train_time:685337ms step_avg:488.13ms
[train step 1404] avg_loss=3.077908 main=2.626373 aux=0.451535 imp_cv2=0.2261 load_cv2=5.0478 usage_frac=0.4286 topk_prob_mean=0.3122 ema_alpha_reverse=nan max_logit=11.7917
step:1405/1750 train_time:685813ms step_avg:488.12ms
[train step 1405] avg_loss=3.128174 main=2.680237 aux=0.447937 imp_cv2=0.2269 load_cv2=5.0015 usage_frac=0.4330 topk_prob_mean=0.3138 ema_alpha_reverse=nan max_logit=11.7917
step:1406/1750 train_time:686271ms step_avg:488.10ms
[train step 1406] avg_loss=4.193505 main=3.706766 aux=0.486739 imp_cv2=0.0498 load_cv2=5.6627 usage_frac=0.4241 topk_prob_mean=0.2222 ema_alpha_reverse=nan max_logit=11.7917
step:1407/1750 train_time:686748ms step_avg:488.09ms
[train step 1407] avg_loss=3.946940 main=3.473253 aux=0.473687 imp_cv2=0.0548 load_cv2=5.4944 usage_frac=0.4375 topk_prob_mean=0.2312 ema_alpha_reverse=nan max_logit=11.7917
step:1408/1750 train_time:687206ms step_avg:488.07ms
[train step 1408] avg_loss=3.530907 main=3.078078 aux=0.452829 imp_cv2=0.1266 load_cv2=5.1708 usage_frac=0.4375 topk_prob_mean=0.2773 ema_alpha_reverse=nan max_logit=11.7917
step:1409/1750 train_time:687662ms step_avg:488.05ms
[train step 1409] avg_loss=3.787855 main=3.327537 aux=0.460319 imp_cv2=0.0957 load_cv2=5.2934 usage_frac=0.4420 topk_prob_mean=0.2614 ema_alpha_reverse=nan max_logit=11.7917
step:1410/1750 train_time:688126ms step_avg:488.03ms
[train step 1410] avg_loss=4.483864 main=3.974423 aux=0.509441 imp_cv2=0.0437 load_cv2=5.9438 usage_frac=0.4241 topk_prob_mean=0.1965 ema_alpha_reverse=nan max_logit=11.7917
step:1411/1750 train_time:688789ms step_avg:488.16ms
[train step 1411] avg_loss=3.354110 main=2.899204 aux=0.454905 imp_cv2=0.1516 load_cv2=5.1666 usage_frac=0.4330 topk_prob_mean=0.2855 ema_alpha_reverse=nan max_logit=11.7917
step:1412/1750 train_time:689247ms step_avg:488.14ms
[train step 1412] avg_loss=3.115794 main=2.664434 aux=0.451359 imp_cv2=0.2309 load_cv2=5.0398 usage_frac=0.4330 topk_prob_mean=0.3115 ema_alpha_reverse=nan max_logit=11.7917
step:1413/1750 train_time:689703ms step_avg:488.11ms
[train step 1413] avg_loss=3.670354 main=3.182987 aux=0.487367 imp_cv2=0.0532 load_cv2=5.6680 usage_frac=0.4286 topk_prob_mean=0.2242 ema_alpha_reverse=nan max_logit=11.7917
step:1414/1750 train_time:690167ms step_avg:488.10ms
[train step 1414] avg_loss=3.479227 main=3.030764 aux=0.448463 imp_cv2=0.1405 load_cv2=5.1059 usage_frac=0.4286 topk_prob_mean=0.2850 ema_alpha_reverse=nan max_logit=11.7917
step:1415/1750 train_time:690642ms step_avg:488.09ms
[train step 1415] avg_loss=3.186783 main=2.744830 aux=0.441953 imp_cv2=0.1883 load_cv2=4.9789 usage_frac=0.4330 topk_prob_mean=0.3059 ema_alpha_reverse=nan max_logit=11.7917
step:1416/1750 train_time:691105ms step_avg:488.07ms
[train step 1416] avg_loss=3.519049 main=3.054823 aux=0.464227 imp_cv2=0.0719 load_cv2=5.3634 usage_frac=0.4330 topk_prob_mean=0.2434 ema_alpha_reverse=nan max_logit=11.7917
step:1417/1750 train_time:691572ms step_avg:488.05ms
[train step 1417] avg_loss=3.889503 main=3.418919 aux=0.470584 imp_cv2=0.0576 load_cv2=5.4523 usage_frac=0.4375 topk_prob_mean=0.2348 ema_alpha_reverse=nan max_logit=11.7917
step:1418/1750 train_time:692049ms step_avg:488.05ms
[train step 1418] avg_loss=3.307360 main=2.858021 aux=0.449339 imp_cv2=0.2261 load_cv2=5.0142 usage_frac=0.4330 topk_prob_mean=0.3119 ema_alpha_reverse=nan max_logit=11.7917
step:1419/1750 train_time:692533ms step_avg:488.04ms
[train step 1419] avg_loss=3.737371 main=3.278020 aux=0.459351 imp_cv2=0.1013 load_cv2=5.2666 usage_frac=0.4375 topk_prob_mean=0.2633 ema_alpha_reverse=nan max_logit=11.7917
step:1420/1750 train_time:692996ms step_avg:488.03ms
[train step 1420] avg_loss=3.155480 main=2.709412 aux=0.446069 imp_cv2=0.1932 load_cv2=5.0135 usage_frac=0.4330 topk_prob_mean=0.3040 ema_alpha_reverse=nan max_logit=11.7917
step:1421/1750 train_time:693470ms step_avg:488.02ms
[train step 1421] avg_loss=3.490224 main=3.004118 aux=0.486106 imp_cv2=0.0617 load_cv2=5.6302 usage_frac=0.4375 topk_prob_mean=0.2178 ema_alpha_reverse=nan max_logit=11.7917
step:1422/1750 train_time:693935ms step_avg:488.00ms
[train step 1422] avg_loss=3.476343 main=3.011176 aux=0.465167 imp_cv2=0.0920 load_cv2=5.3518 usage_frac=0.4286 topk_prob_mean=0.2587 ema_alpha_reverse=nan max_logit=11.7917
step:1423/1750 train_time:694394ms step_avg:487.98ms
[train step 1423] avg_loss=3.747891 main=3.280660 aux=0.467232 imp_cv2=0.0977 load_cv2=5.3691 usage_frac=0.4286 topk_prob_mean=0.2609 ema_alpha_reverse=nan max_logit=11.7917
step:1424/1750 train_time:694865ms step_avg:487.97ms
[train step 1424] avg_loss=3.611197 main=3.148503 aux=0.462694 imp_cv2=0.0703 load_cv2=5.3467 usage_frac=0.4375 topk_prob_mean=0.2496 ema_alpha_reverse=nan max_logit=11.7917
step:1425/1750 train_time:695335ms step_avg:487.95ms
[train step 1425] avg_loss=4.312556 main=3.784250 aux=0.528305 imp_cv2=0.0513 load_cv2=6.1495 usage_frac=0.4107 topk_prob_mean=0.1815 ema_alpha_reverse=nan max_logit=10.8091
step:1426/1750 train_time:695806ms step_avg:487.94ms
[train step 1426] avg_loss=3.354547 main=2.906543 aux=0.448004 imp_cv2=0.1883 load_cv2=5.0431 usage_frac=0.4286 topk_prob_mean=0.3040 ema_alpha_reverse=nan max_logit=11.7917
step:1427/1750 train_time:696283ms step_avg:487.93ms
[train step 1427] avg_loss=3.401654 main=2.936103 aux=0.465551 imp_cv2=0.0744 load_cv2=5.3782 usage_frac=0.4241 topk_prob_mean=0.2436 ema_alpha_reverse=nan max_logit=11.7917
step:1428/1750 train_time:696738ms step_avg:487.91ms
[train step 1428] avg_loss=3.088984 main=2.627231 aux=0.461753 imp_cv2=0.2017 load_cv2=5.1917 usage_frac=0.4241 topk_prob_mean=0.2991 ema_alpha_reverse=nan max_logit=11.7917
step:1429/1750 train_time:697205ms step_avg:487.90ms
[train step 1429] avg_loss=3.460589 main=3.003997 aux=0.456592 imp_cv2=0.1288 load_cv2=5.2126 usage_frac=0.4241 topk_prob_mean=0.2790 ema_alpha_reverse=nan max_logit=11.7917
step:1430/1750 train_time:697679ms step_avg:487.89ms
[train step 1430] avg_loss=3.821936 main=3.339026 aux=0.482910 imp_cv2=0.0559 load_cv2=5.6058 usage_frac=0.4330 topk_prob_mean=0.2254 ema_alpha_reverse=nan max_logit=11.7917
step:1431/1750 train_time:698132ms step_avg:487.86ms
[train step 1431] avg_loss=3.283952 main=2.816061 aux=0.467891 imp_cv2=0.1153 load_cv2=5.3600 usage_frac=0.4241 topk_prob_mean=0.2673 ema_alpha_reverse=nan max_logit=11.7917
step:1432/1750 train_time:698601ms step_avg:487.85ms
[train step 1432] avg_loss=3.336888 main=2.877281 aux=0.459607 imp_cv2=0.1528 load_cv2=5.2223 usage_frac=0.4375 topk_prob_mean=0.2858 ema_alpha_reverse=nan max_logit=11.7917
step:1433/1750 train_time:699064ms step_avg:487.83ms
[train step 1433] avg_loss=3.072897 main=2.618638 aux=0.454259 imp_cv2=0.1845 load_cv2=5.1220 usage_frac=0.4286 topk_prob_mean=0.2983 ema_alpha_reverse=nan max_logit=11.7917
step:1434/1750 train_time:699548ms step_avg:487.83ms
[train step 1434] avg_loss=3.575700 main=3.117594 aux=0.458106 imp_cv2=0.1764 load_cv2=5.1811 usage_frac=0.4286 topk_prob_mean=0.2942 ema_alpha_reverse=nan max_logit=11.7917
step:1435/1750 train_time:700005ms step_avg:487.81ms
[train step 1435] avg_loss=3.374074 main=2.913860 aux=0.460214 imp_cv2=0.1321 load_cv2=5.2509 usage_frac=0.4330 topk_prob_mean=0.2783 ema_alpha_reverse=nan max_logit=11.7917
step:1436/1750 train_time:700476ms step_avg:487.80ms
[train step 1436] avg_loss=3.540413 main=3.077978 aux=0.462435 imp_cv2=0.1376 load_cv2=5.2710 usage_frac=0.4286 topk_prob_mean=0.2786 ema_alpha_reverse=nan max_logit=11.7917
step:1437/1750 train_time:700945ms step_avg:487.78ms
[train step 1437] avg_loss=3.542674 main=3.076336 aux=0.466339 imp_cv2=0.1159 load_cv2=5.3471 usage_frac=0.4286 topk_prob_mean=0.2676 ema_alpha_reverse=nan max_logit=11.7917
step:1438/1750 train_time:701412ms step_avg:487.77ms
[train step 1438] avg_loss=3.409585 main=2.957880 aux=0.451705 imp_cv2=0.2055 load_cv2=5.0678 usage_frac=0.4420 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=11.9263
step:1439/1750 train_time:701876ms step_avg:487.75ms
[train step 1439] avg_loss=3.257772 main=2.803317 aux=0.454456 imp_cv2=0.1622 load_cv2=5.1458 usage_frac=0.4375 topk_prob_mean=0.2926 ema_alpha_reverse=nan max_logit=11.7917
step:1440/1750 train_time:702335ms step_avg:487.73ms
[train step 1440] avg_loss=3.106823 main=2.662968 aux=0.443855 imp_cv2=0.2124 load_cv2=4.9676 usage_frac=0.4330 topk_prob_mean=0.3130 ema_alpha_reverse=nan max_logit=11.7917
step:1441/1750 train_time:702822ms step_avg:487.73ms
[train step 1441] avg_loss=3.478183 main=3.028342 aux=0.449842 imp_cv2=0.1179 load_cv2=5.1368 usage_frac=0.4464 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=12.1548
step:1442/1750 train_time:703291ms step_avg:487.72ms
[train step 1442] avg_loss=3.186406 main=2.738482 aux=0.447924 imp_cv2=0.2367 load_cv2=4.9859 usage_frac=0.4330 topk_prob_mean=0.3177 ema_alpha_reverse=nan max_logit=11.7917
step:1443/1750 train_time:703761ms step_avg:487.71ms
[train step 1443] avg_loss=3.182013 main=2.735836 aux=0.446177 imp_cv2=0.1687 load_cv2=5.0406 usage_frac=0.4286 topk_prob_mean=0.2983 ema_alpha_reverse=nan max_logit=11.7917
step:1444/1750 train_time:704246ms step_avg:487.71ms
[train step 1444] avg_loss=3.210837 main=2.763523 aux=0.447313 imp_cv2=0.1750 load_cv2=5.0474 usage_frac=0.4375 topk_prob_mean=0.2985 ema_alpha_reverse=nan max_logit=11.9389
step:1445/1750 train_time:704716ms step_avg:487.69ms
[train step 1445] avg_loss=3.311696 main=2.864939 aux=0.446757 imp_cv2=0.1734 load_cv2=5.0462 usage_frac=0.4375 topk_prob_mean=0.2989 ema_alpha_reverse=nan max_logit=11.9241
step:1446/1750 train_time:705191ms step_avg:487.68ms
[train step 1446] avg_loss=3.697311 main=3.240243 aux=0.457068 imp_cv2=0.0985 load_cv2=5.2507 usage_frac=0.4286 topk_prob_mean=0.2669 ema_alpha_reverse=nan max_logit=11.7917
step:1447/1750 train_time:705659ms step_avg:487.67ms
[train step 1447] avg_loss=3.441941 main=2.988659 aux=0.453282 imp_cv2=0.1404 load_cv2=5.1615 usage_frac=0.4330 topk_prob_mean=0.2850 ema_alpha_reverse=nan max_logit=11.8967
step:1448/1750 train_time:706130ms step_avg:487.66ms
[train step 1448] avg_loss=3.268612 main=2.817024 aux=0.451589 imp_cv2=0.2296 load_cv2=5.0461 usage_frac=0.4375 topk_prob_mean=0.3126 ema_alpha_reverse=nan max_logit=11.9262
step:1449/1750 train_time:706613ms step_avg:487.66ms
[train step 1449] avg_loss=3.274976 main=2.820285 aux=0.454691 imp_cv2=0.1274 load_cv2=5.1928 usage_frac=0.4330 topk_prob_mean=0.2797 ema_alpha_reverse=nan max_logit=11.7917
step:1450/1750 train_time:707081ms step_avg:487.64ms
Running validation...
step:1450/1750 val_loss:2.978703 train_time:707092ms step_avg:487.65ms
[train step 1450] avg_loss=3.702232 main=3.242742 aux=0.459491 imp_cv2=0.1197 load_cv2=5.2614 usage_frac=0.4286 topk_prob_mean=0.2743 ema_alpha_reverse=nan max_logit=11.7917
step:1451/1750 train_time:707558ms step_avg:487.63ms
[train step 1451] avg_loss=3.644241 main=3.177076 aux=0.467165 imp_cv2=0.0770 load_cv2=5.3927 usage_frac=0.4286 topk_prob_mean=0.2512 ema_alpha_reverse=nan max_logit=11.7917
step:1452/1750 train_time:708027ms step_avg:487.62ms
[train step 1452] avg_loss=3.458576 main=2.999263 aux=0.459314 imp_cv2=0.1089 load_cv2=5.2677 usage_frac=0.4286 topk_prob_mean=0.2690 ema_alpha_reverse=nan max_logit=11.7917
step:1453/1750 train_time:708478ms step_avg:487.60ms
[train step 1453] avg_loss=3.224142 main=2.774566 aux=0.449576 imp_cv2=0.2015 load_cv2=5.0514 usage_frac=0.4286 topk_prob_mean=0.3057 ema_alpha_reverse=nan max_logit=11.7917
step:1454/1750 train_time:708950ms step_avg:487.59ms
[train step 1454] avg_loss=3.450764 main=2.993957 aux=0.456807 imp_cv2=0.1404 load_cv2=5.2007 usage_frac=0.4420 topk_prob_mean=0.2826 ema_alpha_reverse=nan max_logit=12.5849
step:1455/1750 train_time:709420ms step_avg:487.57ms
[train step 1455] avg_loss=3.251123 main=2.799248 aux=0.451875 imp_cv2=0.1921 load_cv2=5.0850 usage_frac=0.4330 topk_prob_mean=0.3018 ema_alpha_reverse=nan max_logit=11.7917
step:1456/1750 train_time:709882ms step_avg:487.56ms
[train step 1456] avg_loss=3.258224 main=2.807439 aux=0.450785 imp_cv2=0.1523 load_cv2=5.1198 usage_frac=0.4286 topk_prob_mean=0.2882 ema_alpha_reverse=nan max_logit=11.7917
step:1457/1750 train_time:710346ms step_avg:487.54ms
[train step 1457] avg_loss=4.112889 main=3.607361 aux=0.505528 imp_cv2=0.0755 load_cv2=5.8335 usage_frac=0.4196 topk_prob_mean=0.1958 ema_alpha_reverse=nan max_logit=10.8091
step:1458/1750 train_time:710823ms step_avg:487.53ms
[train step 1458] avg_loss=4.048771 main=3.579368 aux=0.469403 imp_cv2=0.0685 load_cv2=5.4372 usage_frac=0.4286 topk_prob_mean=0.2422 ema_alpha_reverse=nan max_logit=11.7917
step:1459/1750 train_time:711288ms step_avg:487.52ms
[train step 1459] avg_loss=3.237047 main=2.783801 aux=0.453246 imp_cv2=0.1700 load_cv2=5.1287 usage_frac=0.4286 topk_prob_mean=0.2920 ema_alpha_reverse=nan max_logit=11.7917
step:1460/1750 train_time:711756ms step_avg:487.50ms
[train step 1460] avg_loss=3.314634 main=2.866194 aux=0.448440 imp_cv2=0.1691 load_cv2=5.0738 usage_frac=0.4330 topk_prob_mean=0.2962 ema_alpha_reverse=nan max_logit=11.7917
step:1461/1750 train_time:712217ms step_avg:487.49ms
[train step 1461] avg_loss=3.017223 main=2.570212 aux=0.447011 imp_cv2=0.2286 load_cv2=4.9916 usage_frac=0.4420 topk_prob_mean=0.3136 ema_alpha_reverse=nan max_logit=11.7917
step:1462/1750 train_time:712691ms step_avg:487.48ms
[train step 1462] avg_loss=3.419599 main=2.968542 aux=0.451057 imp_cv2=0.1175 load_cv2=5.1600 usage_frac=0.4286 topk_prob_mean=0.2771 ema_alpha_reverse=nan max_logit=11.7917
step:1463/1750 train_time:713159ms step_avg:487.46ms
[train step 1463] avg_loss=3.691732 main=3.223074 aux=0.468659 imp_cv2=0.0799 load_cv2=5.4118 usage_frac=0.4286 topk_prob_mean=0.2506 ema_alpha_reverse=nan max_logit=11.7917
step:1464/1750 train_time:713627ms step_avg:487.45ms
[train step 1464] avg_loss=3.638167 main=3.171959 aux=0.466208 imp_cv2=0.0901 load_cv2=5.3794 usage_frac=0.4286 topk_prob_mean=0.2577 ema_alpha_reverse=nan max_logit=11.7917
step:1465/1750 train_time:714091ms step_avg:487.43ms
[train step 1465] avg_loss=3.857556 main=3.385219 aux=0.472337 imp_cv2=0.0916 load_cv2=5.4418 usage_frac=0.4241 topk_prob_mean=0.2510 ema_alpha_reverse=nan max_logit=11.7917
step:1466/1750 train_time:714554ms step_avg:487.42ms
[train step 1466] avg_loss=3.534605 main=3.080490 aux=0.454114 imp_cv2=0.1341 load_cv2=5.1788 usage_frac=0.4330 topk_prob_mean=0.2806 ema_alpha_reverse=nan max_logit=12.1310
step:1467/1750 train_time:715016ms step_avg:487.40ms
[train step 1467] avg_loss=3.249761 main=2.797470 aux=0.452291 imp_cv2=0.1504 load_cv2=5.1375 usage_frac=0.4420 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=11.7917
step:1468/1750 train_time:715478ms step_avg:487.38ms
[train step 1468] avg_loss=3.159258 main=2.705904 aux=0.453354 imp_cv2=0.1521 load_cv2=5.1495 usage_frac=0.4330 topk_prob_mean=0.2881 ema_alpha_reverse=nan max_logit=11.7917
step:1469/1750 train_time:715940ms step_avg:487.37ms
[train step 1469] avg_loss=3.324526 main=2.884289 aux=0.440237 imp_cv2=0.1851 load_cv2=4.9492 usage_frac=0.4330 topk_prob_mean=0.3048 ema_alpha_reverse=nan max_logit=11.7917
step:1470/1750 train_time:716406ms step_avg:487.35ms
[train step 1470] avg_loss=2.832225 main=2.387605 aux=0.444620 imp_cv2=0.2282 load_cv2=4.9584 usage_frac=0.4330 topk_prob_mean=0.3154 ema_alpha_reverse=nan max_logit=11.7917
step:1471/1750 train_time:716877ms step_avg:487.34ms
[train step 1471] avg_loss=4.296298 main=3.833420 aux=0.462878 imp_cv2=0.1337 load_cv2=5.2877 usage_frac=0.4375 topk_prob_mean=0.2613 ema_alpha_reverse=nan max_logit=11.7917
step:1472/1750 train_time:717350ms step_avg:487.33ms
[train step 1472] avg_loss=3.636455 main=3.182925 aux=0.453531 imp_cv2=0.1344 load_cv2=5.1694 usage_frac=0.4286 topk_prob_mean=0.2787 ema_alpha_reverse=nan max_logit=11.7917
step:1473/1750 train_time:718024ms step_avg:487.46ms
[train step 1473] avg_loss=4.116959 main=3.652282 aux=0.464677 imp_cv2=0.0693 load_cv2=5.3701 usage_frac=0.4286 topk_prob_mean=0.2436 ema_alpha_reverse=nan max_logit=11.7917
step:1474/1750 train_time:718510ms step_avg:487.46ms
[train step 1474] avg_loss=3.468560 main=3.017120 aux=0.451440 imp_cv2=0.1561 load_cv2=5.1191 usage_frac=0.4241 topk_prob_mean=0.2899 ema_alpha_reverse=nan max_logit=11.7917
step:1475/1750 train_time:718968ms step_avg:487.44ms
[train step 1475] avg_loss=4.153814 main=3.628455 aux=0.525359 imp_cv2=0.0577 load_cv2=6.1077 usage_frac=0.4196 topk_prob_mean=0.1804 ema_alpha_reverse=nan max_logit=10.8091
step:1476/1750 train_time:719441ms step_avg:487.43ms
[train step 1476] avg_loss=3.837982 main=3.385630 aux=0.452352 imp_cv2=0.1148 load_cv2=5.1719 usage_frac=0.4286 topk_prob_mean=0.2747 ema_alpha_reverse=nan max_logit=11.7917
step:1477/1750 train_time:719913ms step_avg:487.42ms
[train step 1477] avg_loss=3.291682 main=2.844846 aux=0.446836 imp_cv2=0.1346 load_cv2=5.0829 usage_frac=0.4286 topk_prob_mean=0.2856 ema_alpha_reverse=nan max_logit=11.7917
step:1478/1750 train_time:720394ms step_avg:487.41ms
[train step 1478] avg_loss=3.770365 main=3.319417 aux=0.450948 imp_cv2=0.1146 load_cv2=5.1539 usage_frac=0.4330 topk_prob_mean=0.2768 ema_alpha_reverse=nan max_logit=11.7917
step:1479/1750 train_time:720861ms step_avg:487.40ms
[train step 1479] avg_loss=3.155449 main=2.708871 aux=0.446577 imp_cv2=0.2077 load_cv2=5.0031 usage_frac=0.4286 topk_prob_mean=0.3099 ema_alpha_reverse=nan max_logit=11.7917
step:1480/1750 train_time:721334ms step_avg:487.39ms
[train step 1480] avg_loss=3.171714 main=2.728904 aux=0.442811 imp_cv2=0.2022 load_cv2=4.9625 usage_frac=0.4375 topk_prob_mean=0.3096 ema_alpha_reverse=nan max_logit=11.7917
step:1481/1750 train_time:721800ms step_avg:487.37ms
[train step 1481] avg_loss=3.530571 main=3.073314 aux=0.457257 imp_cv2=0.0970 load_cv2=5.2521 usage_frac=0.4375 topk_prob_mean=0.2652 ema_alpha_reverse=nan max_logit=11.7917
step:1482/1750 train_time:722277ms step_avg:487.37ms
[train step 1482] avg_loss=3.029874 main=2.585110 aux=0.444763 imp_cv2=0.2773 load_cv2=4.9049 usage_frac=0.4286 topk_prob_mean=0.3285 ema_alpha_reverse=nan max_logit=11.7917
step:1483/1750 train_time:722746ms step_avg:487.35ms
[train step 1483] avg_loss=3.447208 main=2.992158 aux=0.455050 imp_cv2=0.1083 load_cv2=5.2149 usage_frac=0.4286 topk_prob_mean=0.2700 ema_alpha_reverse=nan max_logit=11.7917
step:1484/1750 train_time:723214ms step_avg:487.34ms
[train step 1484] avg_loss=3.350746 main=2.906980 aux=0.443766 imp_cv2=0.1744 load_cv2=5.0034 usage_frac=0.4330 topk_prob_mean=0.2991 ema_alpha_reverse=nan max_logit=11.7917
step:1485/1750 train_time:723678ms step_avg:487.33ms
[train step 1485] avg_loss=2.981463 main=2.536892 aux=0.444571 imp_cv2=0.2380 load_cv2=4.9483 usage_frac=0.4286 topk_prob_mean=0.3199 ema_alpha_reverse=nan max_logit=11.7917
step:1486/1750 train_time:724143ms step_avg:487.31ms
[train step 1486] avg_loss=3.178822 main=2.738965 aux=0.439857 imp_cv2=0.1993 load_cv2=4.9281 usage_frac=0.4241 topk_prob_mean=0.3094 ema_alpha_reverse=nan max_logit=11.7917
step:1487/1750 train_time:724797ms step_avg:487.42ms
[train step 1487] avg_loss=3.295613 main=2.846028 aux=0.449585 imp_cv2=0.1574 load_cv2=5.0987 usage_frac=0.4286 topk_prob_mean=0.2915 ema_alpha_reverse=nan max_logit=11.7917
step:1488/1750 train_time:725263ms step_avg:487.41ms
[train step 1488] avg_loss=3.243895 main=2.793126 aux=0.450769 imp_cv2=0.1651 load_cv2=5.0988 usage_frac=0.4375 topk_prob_mean=0.2923 ema_alpha_reverse=nan max_logit=11.7917
step:1489/1750 train_time:725954ms step_avg:487.54ms
[train step 1489] avg_loss=3.554427 main=3.096979 aux=0.457447 imp_cv2=0.1233 load_cv2=5.2246 usage_frac=0.4375 topk_prob_mean=0.2749 ema_alpha_reverse=nan max_logit=11.7917
step:1490/1750 train_time:726424ms step_avg:487.53ms
[train step 1490] avg_loss=3.408353 main=2.952590 aux=0.455763 imp_cv2=0.1438 load_cv2=5.1862 usage_frac=0.4330 topk_prob_mean=0.2777 ema_alpha_reverse=nan max_logit=11.7917
step:1491/1750 train_time:726888ms step_avg:487.52ms
[train step 1491] avg_loss=3.526476 main=3.073027 aux=0.453450 imp_cv2=0.1359 load_cv2=5.1630 usage_frac=0.4241 topk_prob_mean=0.2801 ema_alpha_reverse=nan max_logit=11.7917
step:1492/1750 train_time:727361ms step_avg:487.51ms
[train step 1492] avg_loss=3.817018 main=3.343112 aux=0.473906 imp_cv2=0.0727 load_cv2=5.4819 usage_frac=0.4286 topk_prob_mean=0.2444 ema_alpha_reverse=nan max_logit=11.7917
step:1493/1750 train_time:727845ms step_avg:487.50ms
[train step 1493] avg_loss=3.091592 main=2.645076 aux=0.446516 imp_cv2=0.2453 load_cv2=4.9653 usage_frac=0.4286 topk_prob_mean=0.3177 ema_alpha_reverse=nan max_logit=11.7917
step:1494/1750 train_time:728505ms step_avg:487.62ms
[train step 1494] avg_loss=3.454299 main=3.006027 aux=0.448272 imp_cv2=0.1420 load_cv2=5.0938 usage_frac=0.4286 topk_prob_mean=0.2848 ema_alpha_reverse=nan max_logit=11.7917
step:1495/1750 train_time:728987ms step_avg:487.62ms
[train step 1495] avg_loss=3.431136 main=2.981614 aux=0.449522 imp_cv2=0.1454 load_cv2=5.1086 usage_frac=0.4330 topk_prob_mean=0.2870 ema_alpha_reverse=nan max_logit=11.7917
step:1496/1750 train_time:729457ms step_avg:487.60ms
[train step 1496] avg_loss=3.128876 main=2.680041 aux=0.448835 imp_cv2=0.1428 load_cv2=5.1006 usage_frac=0.4375 topk_prob_mean=0.2857 ema_alpha_reverse=nan max_logit=11.7917
step:1497/1750 train_time:729922ms step_avg:487.59ms
[train step 1497] avg_loss=3.310702 main=2.865455 aux=0.445247 imp_cv2=0.1796 load_cv2=5.0211 usage_frac=0.4241 topk_prob_mean=0.2984 ema_alpha_reverse=nan max_logit=11.7917
step:1498/1750 train_time:730395ms step_avg:487.58ms
[train step 1498] avg_loss=3.851612 main=3.398784 aux=0.452828 imp_cv2=0.1126 load_cv2=5.1822 usage_frac=0.4286 topk_prob_mean=0.2712 ema_alpha_reverse=nan max_logit=11.7917
step:1499/1750 train_time:730870ms step_avg:487.57ms
[train step 1499] avg_loss=3.398052 main=2.949164 aux=0.448888 imp_cv2=0.1026 load_cv2=5.1483 usage_frac=0.4330 topk_prob_mean=0.2693 ema_alpha_reverse=nan max_logit=11.7917
step:1500/1750 train_time:731344ms step_avg:487.56ms
Running validation...
step:1500/1750 val_loss:2.961537 train_time:731355ms step_avg:487.57ms
[train step 1500] avg_loss=3.332799 main=2.876758 aux=0.456041 imp_cv2=0.0921 load_cv2=5.2478 usage_frac=0.4330 topk_prob_mean=0.2636 ema_alpha_reverse=nan max_logit=11.7917
step:1501/1750 train_time:731819ms step_avg:487.55ms
[train step 1501] avg_loss=3.208979 main=2.761842 aux=0.447137 imp_cv2=0.1998 load_cv2=5.0235 usage_frac=0.4330 topk_prob_mean=0.3050 ema_alpha_reverse=nan max_logit=11.7917
step:1502/1750 train_time:732276ms step_avg:487.53ms
[train step 1502] avg_loss=3.937862 main=3.425570 aux=0.512292 imp_cv2=0.0619 load_cv2=5.9445 usage_frac=0.4196 topk_prob_mean=0.1932 ema_alpha_reverse=nan max_logit=10.8091
step:1503/1750 train_time:732741ms step_avg:487.52ms
[train step 1503] avg_loss=4.654732 main=4.151409 aux=0.503323 imp_cv2=0.0627 load_cv2=5.8463 usage_frac=0.4107 topk_prob_mean=0.1961 ema_alpha_reverse=nan max_logit=9.8264
step:1504/1750 train_time:733201ms step_avg:487.50ms
[train step 1504] avg_loss=3.064776 main=2.613576 aux=0.451200 imp_cv2=0.1968 load_cv2=5.0717 usage_frac=0.4241 topk_prob_mean=0.3013 ema_alpha_reverse=nan max_logit=11.7917
step:1505/1750 train_time:733676ms step_avg:487.49ms
[train step 1505] avg_loss=3.812422 main=3.320747 aux=0.491675 imp_cv2=0.0503 load_cv2=5.7204 usage_frac=0.4286 topk_prob_mean=0.2172 ema_alpha_reverse=nan max_logit=11.7917
step:1506/1750 train_time:734133ms step_avg:487.47ms
[train step 1506] avg_loss=3.115578 main=2.670135 aux=0.445443 imp_cv2=0.1736 load_cv2=5.0326 usage_frac=0.4241 topk_prob_mean=0.2983 ema_alpha_reverse=nan max_logit=11.7917
step:1507/1750 train_time:734606ms step_avg:487.46ms
[train step 1507] avg_loss=3.316885 main=2.863340 aux=0.453544 imp_cv2=0.1133 load_cv2=5.1932 usage_frac=0.4241 topk_prob_mean=0.2718 ema_alpha_reverse=nan max_logit=11.7917
step:1508/1750 train_time:735075ms step_avg:487.45ms
[train step 1508] avg_loss=3.544488 main=3.093118 aux=0.451370 imp_cv2=0.1112 load_cv2=5.1728 usage_frac=0.4286 topk_prob_mean=0.2716 ema_alpha_reverse=nan max_logit=11.7917
step:1509/1750 train_time:735541ms step_avg:487.44ms
[train step 1509] avg_loss=3.207345 main=2.759940 aux=0.447405 imp_cv2=0.1645 load_cv2=5.0648 usage_frac=0.4286 topk_prob_mean=0.2928 ema_alpha_reverse=nan max_logit=11.7917
step:1510/1750 train_time:736003ms step_avg:487.42ms
[train step 1510] avg_loss=3.192476 main=2.744729 aux=0.447747 imp_cv2=0.2066 load_cv2=5.0217 usage_frac=0.4286 topk_prob_mean=0.3067 ema_alpha_reverse=nan max_logit=11.7917
step:1511/1750 train_time:736472ms step_avg:487.41ms
[train step 1511] avg_loss=3.541936 main=3.079471 aux=0.462465 imp_cv2=0.0714 load_cv2=5.3489 usage_frac=0.4241 topk_prob_mean=0.2491 ema_alpha_reverse=nan max_logit=11.7917
step:1512/1750 train_time:736938ms step_avg:487.39ms
[train step 1512] avg_loss=2.960733 main=2.507537 aux=0.453196 imp_cv2=0.1923 load_cv2=5.1051 usage_frac=0.4330 topk_prob_mean=0.2984 ema_alpha_reverse=nan max_logit=11.7917
step:1513/1750 train_time:737402ms step_avg:487.38ms
[train step 1513] avg_loss=3.959304 main=3.461583 aux=0.497721 imp_cv2=0.0448 load_cv2=5.7995 usage_frac=0.4286 topk_prob_mean=0.2029 ema_alpha_reverse=nan max_logit=11.7917
step:1514/1750 train_time:737869ms step_avg:487.36ms
[train step 1514] avg_loss=3.333965 main=2.885306 aux=0.448659 imp_cv2=0.1447 load_cv2=5.1012 usage_frac=0.4241 topk_prob_mean=0.2875 ema_alpha_reverse=nan max_logit=11.7917
step:1515/1750 train_time:738333ms step_avg:487.35ms
[train step 1515] avg_loss=3.276510 main=2.823300 aux=0.453210 imp_cv2=0.1360 load_cv2=5.1627 usage_frac=0.4286 topk_prob_mean=0.2817 ema_alpha_reverse=nan max_logit=11.7917
step:1516/1750 train_time:738797ms step_avg:487.33ms
[train step 1516] avg_loss=3.730737 main=3.263389 aux=0.467348 imp_cv2=0.0765 load_cv2=5.3983 usage_frac=0.4375 topk_prob_mean=0.2492 ema_alpha_reverse=nan max_logit=11.7917
step:1517/1750 train_time:739258ms step_avg:487.32ms
[train step 1517] avg_loss=3.490425 main=3.031490 aux=0.458936 imp_cv2=0.1138 load_cv2=5.2583 usage_frac=0.4330 topk_prob_mean=0.2706 ema_alpha_reverse=nan max_logit=11.7917
step:1518/1750 train_time:739904ms step_avg:487.42ms
[train step 1518] avg_loss=3.351075 main=2.887282 aux=0.463793 imp_cv2=0.1137 load_cv2=5.3168 usage_frac=0.4286 topk_prob_mean=0.2668 ema_alpha_reverse=nan max_logit=11.7917
step:1519/1750 train_time:740366ms step_avg:487.40ms
[train step 1519] avg_loss=3.273921 main=2.817226 aux=0.456695 imp_cv2=0.1890 load_cv2=5.1520 usage_frac=0.4286 topk_prob_mean=0.2971 ema_alpha_reverse=nan max_logit=11.7917
step:1520/1750 train_time:740829ms step_avg:487.39ms
[train step 1520] avg_loss=3.950718 main=3.479073 aux=0.471645 imp_cv2=0.0891 load_cv2=5.4485 usage_frac=0.4241 topk_prob_mean=0.2494 ema_alpha_reverse=nan max_logit=11.7917
step:1521/1750 train_time:741289ms step_avg:487.37ms
[train step 1521] avg_loss=3.350682 main=2.896338 aux=0.454344 imp_cv2=0.1900 load_cv2=5.1201 usage_frac=0.4286 topk_prob_mean=0.2971 ema_alpha_reverse=nan max_logit=11.7917
step:1522/1750 train_time:741754ms step_avg:487.35ms
[train step 1522] avg_loss=4.032729 main=3.536940 aux=0.495788 imp_cv2=0.0429 load_cv2=5.7735 usage_frac=0.4241 topk_prob_mean=0.2107 ema_alpha_reverse=nan max_logit=11.7917
step:1523/1750 train_time:742409ms step_avg:487.47ms
[train step 1523] avg_loss=3.462492 main=3.007617 aux=0.454876 imp_cv2=0.1123 load_cv2=5.2044 usage_frac=0.4330 topk_prob_mean=0.2713 ema_alpha_reverse=nan max_logit=11.7917
step:1524/1750 train_time:742874ms step_avg:487.45ms
[train step 1524] avg_loss=3.478674 main=3.020047 aux=0.458626 imp_cv2=0.1232 load_cv2=5.2403 usage_frac=0.4286 topk_prob_mean=0.2741 ema_alpha_reverse=nan max_logit=11.7917
step:1525/1750 train_time:743338ms step_avg:487.43ms
[train step 1525] avg_loss=3.010548 main=2.561894 aux=0.448654 imp_cv2=0.2313 load_cv2=5.0009 usage_frac=0.4286 topk_prob_mean=0.3145 ema_alpha_reverse=nan max_logit=11.7917
step:1526/1750 train_time:743800ms step_avg:487.42ms
[train step 1526] avg_loss=2.838218 main=2.386714 aux=0.451504 imp_cv2=0.3077 load_cv2=4.9523 usage_frac=0.4375 topk_prob_mean=0.3336 ema_alpha_reverse=nan max_logit=11.7917
step:1527/1750 train_time:744504ms step_avg:487.56ms
[train step 1527] avg_loss=3.400939 main=2.941480 aux=0.459459 imp_cv2=0.1266 load_cv2=5.2483 usage_frac=0.4286 topk_prob_mean=0.2761 ema_alpha_reverse=nan max_logit=11.7917
step:1528/1750 train_time:744962ms step_avg:487.54ms
[train step 1528] avg_loss=3.281897 main=2.829185 aux=0.452711 imp_cv2=0.1373 load_cv2=5.1524 usage_frac=0.4241 topk_prob_mean=0.2834 ema_alpha_reverse=nan max_logit=11.7917
step:1529/1750 train_time:745428ms step_avg:487.53ms
[train step 1529] avg_loss=3.322829 main=2.869257 aux=0.453572 imp_cv2=0.1433 load_cv2=5.1563 usage_frac=0.4330 topk_prob_mean=0.2845 ema_alpha_reverse=nan max_logit=11.7917
step:1530/1750 train_time:745885ms step_avg:487.51ms
[train step 1530] avg_loss=3.158058 main=2.712238 aux=0.445821 imp_cv2=0.1877 load_cv2=5.0152 usage_frac=0.4286 topk_prob_mean=0.3024 ema_alpha_reverse=nan max_logit=11.7917
step:1531/1750 train_time:746355ms step_avg:487.49ms
[train step 1531] avg_loss=3.529801 main=3.074613 aux=0.455188 imp_cv2=0.1291 load_cv2=5.1916 usage_frac=0.4286 topk_prob_mean=0.2792 ema_alpha_reverse=nan max_logit=11.7917
step:1532/1750 train_time:746830ms step_avg:487.49ms
[train step 1532] avg_loss=3.523408 main=3.067463 aux=0.455945 imp_cv2=0.1595 load_cv2=5.1680 usage_frac=0.4286 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=11.7917
step:1533/1750 train_time:747296ms step_avg:487.47ms
[train step 1533] avg_loss=3.073219 main=2.624926 aux=0.448294 imp_cv2=0.2194 load_cv2=5.0082 usage_frac=0.4464 topk_prob_mean=0.3113 ema_alpha_reverse=nan max_logit=12.2181
step:1534/1750 train_time:747768ms step_avg:487.46ms
[train step 1534] avg_loss=3.490441 main=3.035522 aux=0.454919 imp_cv2=0.0872 load_cv2=5.2338 usage_frac=0.4286 topk_prob_mean=0.2577 ema_alpha_reverse=nan max_logit=11.7917
step:1535/1750 train_time:748246ms step_avg:487.46ms
[train step 1535] avg_loss=3.096977 main=2.652941 aux=0.444036 imp_cv2=0.2165 load_cv2=4.9621 usage_frac=0.4286 topk_prob_mean=0.3133 ema_alpha_reverse=nan max_logit=11.7917
step:1536/1750 train_time:748712ms step_avg:487.44ms
[train step 1536] avg_loss=3.239561 main=2.794100 aux=0.445462 imp_cv2=0.1403 load_cv2=5.0573 usage_frac=0.4330 topk_prob_mean=0.2851 ema_alpha_reverse=nan max_logit=11.7917
step:1537/1750 train_time:749185ms step_avg:487.43ms
[train step 1537] avg_loss=2.918531 main=2.478158 aux=0.440373 imp_cv2=0.2751 load_cv2=4.8555 usage_frac=0.4286 topk_prob_mean=0.3280 ema_alpha_reverse=nan max_logit=11.7917
step:1538/1750 train_time:749657ms step_avg:487.42ms
[train step 1538] avg_loss=3.265330 main=2.820526 aux=0.444804 imp_cv2=0.1643 load_cv2=5.0296 usage_frac=0.4330 topk_prob_mean=0.2952 ema_alpha_reverse=nan max_logit=11.7917
step:1539/1750 train_time:750119ms step_avg:487.41ms
[train step 1539] avg_loss=4.013591 main=3.537493 aux=0.476097 imp_cv2=0.0662 load_cv2=5.5100 usage_frac=0.4286 topk_prob_mean=0.2345 ema_alpha_reverse=nan max_logit=11.7917
step:1540/1750 train_time:750581ms step_avg:487.39ms
[train step 1540] avg_loss=3.455400 main=2.995589 aux=0.459810 imp_cv2=0.0677 load_cv2=5.3063 usage_frac=0.4286 topk_prob_mean=0.2456 ema_alpha_reverse=nan max_logit=11.7917
step:1541/1750 train_time:751052ms step_avg:487.38ms
[train step 1541] avg_loss=3.018995 main=2.573815 aux=0.445180 imp_cv2=0.1720 load_cv2=5.0232 usage_frac=0.4375 topk_prob_mean=0.2957 ema_alpha_reverse=nan max_logit=11.7917
step:1542/1750 train_time:751521ms step_avg:487.37ms
[train step 1542] avg_loss=3.264218 main=2.809943 aux=0.454275 imp_cv2=0.1164 load_cv2=5.1967 usage_frac=0.4286 topk_prob_mean=0.2719 ema_alpha_reverse=nan max_logit=11.7917
step:1543/1750 train_time:751984ms step_avg:487.35ms
[train step 1543] avg_loss=3.537265 main=3.075653 aux=0.461612 imp_cv2=0.0839 load_cv2=5.3171 usage_frac=0.4330 topk_prob_mean=0.2536 ema_alpha_reverse=nan max_logit=11.7917
step:1544/1750 train_time:752449ms step_avg:487.34ms
[train step 1544] avg_loss=3.186921 main=2.735907 aux=0.451013 imp_cv2=0.1361 load_cv2=5.1353 usage_frac=0.4286 topk_prob_mean=0.2808 ema_alpha_reverse=nan max_logit=11.7917
step:1545/1750 train_time:752936ms step_avg:487.34ms
[train step 1545] avg_loss=2.973248 main=2.526803 aux=0.446445 imp_cv2=0.2368 load_cv2=4.9728 usage_frac=0.4330 topk_prob_mean=0.3137 ema_alpha_reverse=nan max_logit=11.7917
step:1546/1750 train_time:753405ms step_avg:487.33ms
[train step 1546] avg_loss=3.111682 main=2.655507 aux=0.456175 imp_cv2=0.0843 load_cv2=5.2504 usage_frac=0.4330 topk_prob_mean=0.2581 ema_alpha_reverse=nan max_logit=11.7917
step:1547/1750 train_time:753863ms step_avg:487.31ms
[train step 1547] avg_loss=3.212899 main=2.753412 aux=0.459488 imp_cv2=0.1082 load_cv2=5.2668 usage_frac=0.4375 topk_prob_mean=0.2653 ema_alpha_reverse=nan max_logit=11.7917
step:1548/1750 train_time:754324ms step_avg:487.29ms
[train step 1548] avg_loss=2.992481 main=2.547916 aux=0.444565 imp_cv2=0.2416 load_cv2=4.9429 usage_frac=0.4375 topk_prob_mean=0.3170 ema_alpha_reverse=nan max_logit=11.7917
step:1549/1750 train_time:754796ms step_avg:487.28ms
[train step 1549] avg_loss=3.019206 main=2.573170 aux=0.446036 imp_cv2=0.1907 load_cv2=5.0134 usage_frac=0.4286 topk_prob_mean=0.3030 ema_alpha_reverse=nan max_logit=11.7917
step:1550/1750 train_time:755263ms step_avg:487.27ms
Running validation...
step:1550/1750 val_loss:2.941441 train_time:755275ms step_avg:487.27ms
[train step 1550] avg_loss=2.780499 main=2.330225 aux=0.450274 imp_cv2=0.2996 load_cv2=4.9467 usage_frac=0.4330 topk_prob_mean=0.3310 ema_alpha_reverse=nan max_logit=11.7917
step:1551/1750 train_time:755729ms step_avg:487.25ms
[train step 1551] avg_loss=3.125447 main=2.679559 aux=0.445889 imp_cv2=0.1970 load_cv2=5.0052 usage_frac=0.4375 topk_prob_mean=0.3043 ema_alpha_reverse=nan max_logit=11.7917
step:1552/1750 train_time:756210ms step_avg:487.25ms
[train step 1552] avg_loss=3.409408 main=2.956378 aux=0.453030 imp_cv2=0.1177 load_cv2=5.1788 usage_frac=0.4330 topk_prob_mean=0.2762 ema_alpha_reverse=nan max_logit=11.7917
step:1553/1750 train_time:756676ms step_avg:487.23ms
[train step 1553] avg_loss=3.165496 main=2.711709 aux=0.453787 imp_cv2=0.1395 load_cv2=5.1617 usage_frac=0.4241 topk_prob_mean=0.2827 ema_alpha_reverse=nan max_logit=11.7917
step:1554/1750 train_time:757151ms step_avg:487.23ms
[train step 1554] avg_loss=3.051088 main=2.606519 aux=0.444569 imp_cv2=0.1998 load_cv2=4.9863 usage_frac=0.4375 topk_prob_mean=0.3079 ema_alpha_reverse=nan max_logit=11.7917
step:1555/1750 train_time:757622ms step_avg:487.22ms
[train step 1555] avg_loss=3.292067 main=2.833303 aux=0.458764 imp_cv2=0.0982 load_cv2=5.2665 usage_frac=0.4286 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=11.7917
step:1556/1750 train_time:758087ms step_avg:487.20ms
[train step 1556] avg_loss=3.269661 main=2.813702 aux=0.455958 imp_cv2=0.1248 load_cv2=5.2026 usage_frac=0.4375 topk_prob_mean=0.2765 ema_alpha_reverse=nan max_logit=11.7917
step:1557/1750 train_time:758552ms step_avg:487.19ms
[train step 1557] avg_loss=3.664307 main=3.209201 aux=0.455106 imp_cv2=0.1334 load_cv2=5.1951 usage_frac=0.4375 topk_prob_mean=0.2778 ema_alpha_reverse=nan max_logit=11.7917
step:1558/1750 train_time:759037ms step_avg:487.19ms
[train step 1558] avg_loss=3.489708 main=3.029786 aux=0.459922 imp_cv2=0.1004 load_cv2=5.2816 usage_frac=0.4241 topk_prob_mean=0.2646 ema_alpha_reverse=nan max_logit=11.7917
step:1559/1750 train_time:759497ms step_avg:487.17ms
[train step 1559] avg_loss=3.612780 main=3.157658 aux=0.455121 imp_cv2=0.1180 load_cv2=5.1989 usage_frac=0.4330 topk_prob_mean=0.2728 ema_alpha_reverse=nan max_logit=11.7917
step:1560/1750 train_time:760162ms step_avg:487.28ms
[train step 1560] avg_loss=3.559033 main=3.100261 aux=0.458772 imp_cv2=0.1217 load_cv2=5.2400 usage_frac=0.4375 topk_prob_mean=0.2718 ema_alpha_reverse=nan max_logit=11.7917
step:1561/1750 train_time:760628ms step_avg:487.27ms
[train step 1561] avg_loss=2.940007 main=2.495809 aux=0.444198 imp_cv2=0.1903 load_cv2=4.9979 usage_frac=0.4286 topk_prob_mean=0.3038 ema_alpha_reverse=nan max_logit=11.7917
step:1562/1750 train_time:761092ms step_avg:487.25ms
[train step 1562] avg_loss=3.183674 main=2.730767 aux=0.452907 imp_cv2=0.1204 load_cv2=5.1738 usage_frac=0.4375 topk_prob_mean=0.2752 ema_alpha_reverse=nan max_logit=11.7917
step:1563/1750 train_time:761565ms step_avg:487.25ms
[train step 1563] avg_loss=3.555563 main=3.082361 aux=0.473203 imp_cv2=0.0708 load_cv2=5.4788 usage_frac=0.4330 topk_prob_mean=0.2443 ema_alpha_reverse=nan max_logit=11.7917
step:1564/1750 train_time:762028ms step_avg:487.23ms
[train step 1564] avg_loss=3.082555 main=2.634356 aux=0.448199 imp_cv2=0.1489 load_cv2=5.0824 usage_frac=0.4420 topk_prob_mean=0.2853 ema_alpha_reverse=nan max_logit=11.7917
step:1565/1750 train_time:762488ms step_avg:487.21ms
[train step 1565] avg_loss=3.157366 main=2.707562 aux=0.449804 imp_cv2=0.1345 load_cv2=5.1216 usage_frac=0.4286 topk_prob_mean=0.2814 ema_alpha_reverse=nan max_logit=11.7917
step:1566/1750 train_time:762957ms step_avg:487.20ms
[train step 1566] avg_loss=3.454120 main=2.998915 aux=0.455206 imp_cv2=0.1006 load_cv2=5.2329 usage_frac=0.4241 topk_prob_mean=0.2663 ema_alpha_reverse=nan max_logit=11.7917
step:1567/1750 train_time:763422ms step_avg:487.19ms
[train step 1567] avg_loss=3.223222 main=2.773250 aux=0.449972 imp_cv2=0.1202 load_cv2=5.1423 usage_frac=0.4330 topk_prob_mean=0.2774 ema_alpha_reverse=nan max_logit=11.7917
step:1568/1750 train_time:763888ms step_avg:487.17ms
[train step 1568] avg_loss=3.324278 main=2.869681 aux=0.454597 imp_cv2=0.1673 load_cv2=5.1463 usage_frac=0.4286 topk_prob_mean=0.2889 ema_alpha_reverse=nan max_logit=11.7917
step:1569/1750 train_time:764350ms step_avg:487.16ms
[train step 1569] avg_loss=3.302224 main=2.846465 aux=0.455760 imp_cv2=0.1570 load_cv2=5.1653 usage_frac=0.4330 topk_prob_mean=0.2862 ema_alpha_reverse=nan max_logit=11.7917
step:1570/1750 train_time:764815ms step_avg:487.14ms
[train step 1570] avg_loss=3.950514 main=3.485333 aux=0.465181 imp_cv2=0.0785 load_cv2=5.3658 usage_frac=0.4375 topk_prob_mean=0.2504 ema_alpha_reverse=nan max_logit=11.7917
step:1571/1750 train_time:765282ms step_avg:487.13ms
[train step 1571] avg_loss=3.302653 main=2.851111 aux=0.451542 imp_cv2=0.1654 load_cv2=5.1044 usage_frac=0.4286 topk_prob_mean=0.2913 ema_alpha_reverse=nan max_logit=11.7917
step:1572/1750 train_time:765749ms step_avg:487.12ms
[train step 1572] avg_loss=3.110214 main=2.655279 aux=0.454935 imp_cv2=0.1800 load_cv2=5.1326 usage_frac=0.4286 topk_prob_mean=0.2952 ema_alpha_reverse=nan max_logit=11.7917
step:1573/1750 train_time:766213ms step_avg:487.10ms
[train step 1573] avg_loss=3.229515 main=2.770398 aux=0.459117 imp_cv2=0.1432 load_cv2=5.2245 usage_frac=0.4241 topk_prob_mean=0.2810 ema_alpha_reverse=nan max_logit=11.7917
step:1574/1750 train_time:766679ms step_avg:487.09ms
[train step 1574] avg_loss=3.734257 main=3.231318 aux=0.502940 imp_cv2=0.0465 load_cv2=5.8543 usage_frac=0.4241 topk_prob_mean=0.1959 ema_alpha_reverse=nan max_logit=11.7917
step:1575/1750 train_time:767149ms step_avg:487.08ms
[train step 1575] avg_loss=3.377575 main=2.926580 aux=0.450995 imp_cv2=0.1780 load_cv2=5.0835 usage_frac=0.4286 topk_prob_mean=0.2957 ema_alpha_reverse=nan max_logit=11.7917
step:1576/1750 train_time:767611ms step_avg:487.06ms
[train step 1576] avg_loss=3.879023 main=3.399006 aux=0.480016 imp_cv2=0.0655 load_cv2=5.5578 usage_frac=0.4241 topk_prob_mean=0.2358 ema_alpha_reverse=nan max_logit=11.7917
step:1577/1750 train_time:768079ms step_avg:487.05ms
[train step 1577] avg_loss=3.276083 main=2.823272 aux=0.452811 imp_cv2=0.1565 load_cv2=5.1256 usage_frac=0.4330 topk_prob_mean=0.2893 ema_alpha_reverse=nan max_logit=11.7917
step:1578/1750 train_time:768541ms step_avg:487.03ms
[train step 1578] avg_loss=3.475256 main=3.021991 aux=0.453266 imp_cv2=0.1678 load_cv2=5.1235 usage_frac=0.4330 topk_prob_mean=0.2921 ema_alpha_reverse=nan max_logit=11.7917
step:1579/1750 train_time:769013ms step_avg:487.03ms
[train step 1579] avg_loss=3.339584 main=2.872646 aux=0.466938 imp_cv2=0.0798 load_cv2=5.3804 usage_frac=0.4330 topk_prob_mean=0.2520 ema_alpha_reverse=nan max_logit=11.7917
step:1580/1750 train_time:769472ms step_avg:487.01ms
[train step 1580] avg_loss=3.153076 main=2.701905 aux=0.451170 imp_cv2=0.1485 load_cv2=5.1158 usage_frac=0.4375 topk_prob_mean=0.2870 ema_alpha_reverse=nan max_logit=11.7917
step:1581/1750 train_time:769935ms step_avg:486.99ms
[train step 1581] avg_loss=3.901737 main=3.436144 aux=0.465594 imp_cv2=0.0742 load_cv2=5.3696 usage_frac=0.4330 topk_prob_mean=0.2482 ema_alpha_reverse=nan max_logit=11.7917
step:1582/1750 train_time:770409ms step_avg:486.98ms
[train step 1582] avg_loss=4.151302 main=3.656897 aux=0.494405 imp_cv2=0.0557 load_cv2=5.7484 usage_frac=0.4330 topk_prob_mean=0.2094 ema_alpha_reverse=nan max_logit=11.7917
step:1583/1750 train_time:770876ms step_avg:486.97ms
[train step 1583] avg_loss=3.849921 main=3.378626 aux=0.471295 imp_cv2=0.0639 load_cv2=5.4558 usage_frac=0.4241 topk_prob_mean=0.2381 ema_alpha_reverse=nan max_logit=11.7917
step:1584/1750 train_time:771338ms step_avg:486.96ms
[train step 1584] avg_loss=3.492234 main=3.031126 aux=0.461108 imp_cv2=0.0753 load_cv2=5.3274 usage_frac=0.4375 topk_prob_mean=0.2510 ema_alpha_reverse=nan max_logit=11.7917
step:1585/1750 train_time:771823ms step_avg:486.95ms
[train step 1585] avg_loss=3.180465 main=2.730121 aux=0.450345 imp_cv2=0.1720 load_cv2=5.0840 usage_frac=0.4330 topk_prob_mean=0.2962 ema_alpha_reverse=nan max_logit=11.7917
step:1586/1750 train_time:772289ms step_avg:486.94ms
[train step 1586] avg_loss=3.608341 main=3.156468 aux=0.451872 imp_cv2=0.0944 load_cv2=5.1924 usage_frac=0.4286 topk_prob_mean=0.2663 ema_alpha_reverse=nan max_logit=11.7917
step:1587/1750 train_time:772751ms step_avg:486.93ms
[train step 1587] avg_loss=3.044041 main=2.595205 aux=0.448835 imp_cv2=0.1891 load_cv2=5.0493 usage_frac=0.4375 topk_prob_mean=0.3023 ema_alpha_reverse=nan max_logit=11.7917
step:1588/1750 train_time:773223ms step_avg:486.92ms
[train step 1588] avg_loss=3.052275 main=2.599617 aux=0.452658 imp_cv2=0.1753 load_cv2=5.1125 usage_frac=0.4330 topk_prob_mean=0.2960 ema_alpha_reverse=nan max_logit=11.7917
step:1589/1750 train_time:773688ms step_avg:486.90ms
[train step 1589] avg_loss=3.271306 main=2.821522 aux=0.449785 imp_cv2=0.1562 load_cv2=5.0998 usage_frac=0.4420 topk_prob_mean=0.2902 ema_alpha_reverse=nan max_logit=11.7917
step:1590/1750 train_time:774147ms step_avg:486.88ms
[train step 1590] avg_loss=3.439299 main=2.990685 aux=0.448614 imp_cv2=0.1368 load_cv2=5.1045 usage_frac=0.4241 topk_prob_mean=0.2863 ema_alpha_reverse=nan max_logit=11.7917
step:1591/1750 train_time:774606ms step_avg:486.87ms
[train step 1591] avg_loss=3.081602 main=2.626570 aux=0.455032 imp_cv2=0.1285 load_cv2=5.1924 usage_frac=0.4241 topk_prob_mean=0.2795 ema_alpha_reverse=nan max_logit=11.7917
step:1592/1750 train_time:775076ms step_avg:486.86ms
[train step 1592] avg_loss=3.371228 main=2.909509 aux=0.461718 imp_cv2=0.0921 load_cv2=5.3108 usage_frac=0.4286 topk_prob_mean=0.2615 ema_alpha_reverse=nan max_logit=11.7917
step:1593/1750 train_time:775547ms step_avg:486.85ms
[train step 1593] avg_loss=3.409725 main=2.956538 aux=0.453187 imp_cv2=0.1192 load_cv2=5.1806 usage_frac=0.4286 topk_prob_mean=0.2772 ema_alpha_reverse=nan max_logit=11.7917
step:1594/1750 train_time:776016ms step_avg:486.84ms
[train step 1594] avg_loss=3.333505 main=2.846847 aux=0.486658 imp_cv2=0.0644 load_cv2=5.6366 usage_frac=0.4196 topk_prob_mean=0.2231 ema_alpha_reverse=nan max_logit=11.7917
step:1595/1750 train_time:776484ms step_avg:486.82ms
[train step 1595] avg_loss=3.761895 main=3.284874 aux=0.477021 imp_cv2=0.0620 load_cv2=5.5344 usage_frac=0.4196 topk_prob_mean=0.2299 ema_alpha_reverse=nan max_logit=11.7917
step:1596/1750 train_time:776953ms step_avg:486.81ms
[train step 1596] avg_loss=3.357532 main=2.893381 aux=0.464151 imp_cv2=0.0836 load_cv2=5.3444 usage_frac=0.4286 topk_prob_mean=0.2554 ema_alpha_reverse=nan max_logit=11.7917
step:1597/1750 train_time:777409ms step_avg:486.79ms
[train step 1597] avg_loss=3.120880 main=2.672817 aux=0.448064 imp_cv2=0.1955 load_cv2=5.0306 usage_frac=0.4330 topk_prob_mean=0.3056 ema_alpha_reverse=nan max_logit=11.7917
step:1598/1750 train_time:777882ms step_avg:486.78ms
[train step 1598] avg_loss=3.017378 main=2.566979 aux=0.450399 imp_cv2=0.1905 load_cv2=5.0645 usage_frac=0.4330 topk_prob_mean=0.3037 ema_alpha_reverse=nan max_logit=11.7917
step:1599/1750 train_time:778350ms step_avg:486.77ms
[train step 1599] avg_loss=2.921060 main=2.475951 aux=0.445109 imp_cv2=0.1992 load_cv2=4.9952 usage_frac=0.4330 topk_prob_mean=0.3078 ema_alpha_reverse=nan max_logit=11.7917
step:1600/1750 train_time:778825ms step_avg:486.77ms
Running validation...
step:1600/1750 val_loss:2.917301 train_time:778836ms step_avg:486.77ms
[train step 1600] avg_loss=3.765050 main=3.295812 aux=0.469237 imp_cv2=0.0679 load_cv2=5.4324 usage_frac=0.4286 topk_prob_mean=0.2470 ema_alpha_reverse=nan max_logit=11.7917
step:1601/1750 train_time:779304ms step_avg:486.76ms
[train step 1601] avg_loss=3.468478 main=3.011035 aux=0.457443 imp_cv2=0.1056 load_cv2=5.2444 usage_frac=0.4286 topk_prob_mean=0.2703 ema_alpha_reverse=nan max_logit=11.7917
step:1602/1750 train_time:779773ms step_avg:486.75ms
[train step 1602] avg_loss=3.526396 main=3.044525 aux=0.481871 imp_cv2=0.0572 load_cv2=5.5858 usage_frac=0.4286 topk_prob_mean=0.2338 ema_alpha_reverse=nan max_logit=11.7917
step:1603/1750 train_time:780237ms step_avg:486.74ms
[train step 1603] avg_loss=3.000085 main=2.547890 aux=0.452195 imp_cv2=0.2257 load_cv2=5.0488 usage_frac=0.4330 topk_prob_mean=0.3122 ema_alpha_reverse=nan max_logit=11.7917
step:1604/1750 train_time:780705ms step_avg:486.72ms
[train step 1604] avg_loss=3.601615 main=3.142107 aux=0.459509 imp_cv2=0.0962 load_cv2=5.2800 usage_frac=0.4286 topk_prob_mean=0.2639 ema_alpha_reverse=nan max_logit=11.7917
step:1605/1750 train_time:781170ms step_avg:486.71ms
[train step 1605] avg_loss=3.399951 main=2.940462 aux=0.459489 imp_cv2=0.1030 load_cv2=5.2704 usage_frac=0.4330 topk_prob_mean=0.2678 ema_alpha_reverse=nan max_logit=11.7917
step:1606/1750 train_time:781639ms step_avg:486.70ms
[train step 1606] avg_loss=3.340575 main=2.883706 aux=0.456869 imp_cv2=0.1184 load_cv2=5.2227 usage_frac=0.4286 topk_prob_mean=0.2766 ema_alpha_reverse=nan max_logit=11.7917
step:1607/1750 train_time:782122ms step_avg:486.70ms
[train step 1607] avg_loss=3.255787 main=2.803920 aux=0.451866 imp_cv2=0.1468 load_cv2=5.1343 usage_frac=0.4330 topk_prob_mean=0.2869 ema_alpha_reverse=nan max_logit=11.7917
step:1608/1750 train_time:782590ms step_avg:486.69ms
[train step 1608] avg_loss=3.301890 main=2.840518 aux=0.461372 imp_cv2=0.1001 load_cv2=5.3045 usage_frac=0.4286 topk_prob_mean=0.2640 ema_alpha_reverse=nan max_logit=11.7917
step:1609/1750 train_time:783060ms step_avg:486.67ms
[train step 1609] avg_loss=3.077600 main=2.626230 aux=0.451370 imp_cv2=0.1661 load_cv2=5.1062 usage_frac=0.4286 topk_prob_mean=0.2936 ema_alpha_reverse=nan max_logit=11.7917
step:1610/1750 train_time:783522ms step_avg:486.66ms
[train step 1610] avg_loss=3.888225 main=3.396024 aux=0.492201 imp_cv2=0.0375 load_cv2=5.7408 usage_frac=0.4196 topk_prob_mean=0.2110 ema_alpha_reverse=nan max_logit=11.7917
step:1611/1750 train_time:783989ms step_avg:486.65ms
[train step 1611] avg_loss=3.036284 main=2.590386 aux=0.445898 imp_cv2=0.2107 load_cv2=4.9920 usage_frac=0.4330 topk_prob_mean=0.3107 ema_alpha_reverse=nan max_logit=11.7917
step:1612/1750 train_time:784457ms step_avg:486.64ms
[train step 1612] avg_loss=3.441594 main=2.980677 aux=0.460917 imp_cv2=0.0752 load_cv2=5.3150 usage_frac=0.4286 topk_prob_mean=0.2541 ema_alpha_reverse=nan max_logit=11.7917
step:1613/1750 train_time:784921ms step_avg:486.62ms
[train step 1613] avg_loss=3.465705 main=3.015584 aux=0.450121 imp_cv2=0.1195 load_cv2=5.1389 usage_frac=0.4330 topk_prob_mean=0.2775 ema_alpha_reverse=nan max_logit=11.7917
step:1614/1750 train_time:785391ms step_avg:486.61ms
[train step 1614] avg_loss=3.504739 main=3.057917 aux=0.446822 imp_cv2=0.1343 load_cv2=5.0846 usage_frac=0.4286 topk_prob_mean=0.2847 ema_alpha_reverse=nan max_logit=11.7917
step:1615/1750 train_time:785854ms step_avg:486.60ms
[train step 1615] avg_loss=3.459776 main=3.002945 aux=0.456830 imp_cv2=0.1280 load_cv2=5.2131 usage_frac=0.4286 topk_prob_mean=0.2762 ema_alpha_reverse=nan max_logit=11.7917
step:1616/1750 train_time:786322ms step_avg:486.59ms
[train step 1616] avg_loss=3.208905 main=2.766261 aux=0.442644 imp_cv2=0.1782 load_cv2=4.9900 usage_frac=0.4330 topk_prob_mean=0.3009 ema_alpha_reverse=nan max_logit=11.7917
step:1617/1750 train_time:786794ms step_avg:486.58ms
[train step 1617] avg_loss=3.194343 main=2.755448 aux=0.438895 imp_cv2=0.1743 load_cv2=4.9458 usage_frac=0.4330 topk_prob_mean=0.3023 ema_alpha_reverse=nan max_logit=11.7917
step:1618/1750 train_time:787264ms step_avg:486.57ms
[train step 1618] avg_loss=3.476896 main=3.018124 aux=0.458772 imp_cv2=0.1061 load_cv2=5.2582 usage_frac=0.4375 topk_prob_mean=0.2678 ema_alpha_reverse=nan max_logit=11.7917
step:1619/1750 train_time:787729ms step_avg:486.55ms
[train step 1619] avg_loss=2.948581 main=2.503773 aux=0.444807 imp_cv2=0.2241 load_cv2=4.9635 usage_frac=0.4286 topk_prob_mean=0.3136 ema_alpha_reverse=nan max_logit=11.7917
step:1620/1750 train_time:788194ms step_avg:486.54ms
[train step 1620] avg_loss=3.585358 main=3.118713 aux=0.466645 imp_cv2=0.0679 load_cv2=5.3996 usage_frac=0.4286 topk_prob_mean=0.2478 ema_alpha_reverse=nan max_logit=11.7917
step:1621/1750 train_time:788660ms step_avg:486.53ms
[train step 1621] avg_loss=3.253060 main=2.807704 aux=0.445356 imp_cv2=0.1537 load_cv2=5.0488 usage_frac=0.4286 topk_prob_mean=0.2911 ema_alpha_reverse=nan max_logit=11.7917
step:1622/1750 train_time:789338ms step_avg:486.64ms
[train step 1622] avg_loss=3.554718 main=3.089174 aux=0.465544 imp_cv2=0.0820 load_cv2=5.3655 usage_frac=0.4286 topk_prob_mean=0.2522 ema_alpha_reverse=nan max_logit=11.7917
step:1623/1750 train_time:789796ms step_avg:486.63ms
[train step 1623] avg_loss=3.227662 main=2.784192 aux=0.443470 imp_cv2=0.1333 load_cv2=5.0473 usage_frac=0.4241 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=11.7917
step:1624/1750 train_time:790274ms step_avg:486.62ms
[train step 1624] avg_loss=3.356504 main=2.888028 aux=0.468476 imp_cv2=0.0609 load_cv2=5.4324 usage_frac=0.4241 topk_prob_mean=0.2382 ema_alpha_reverse=nan max_logit=11.7917
step:1625/1750 train_time:790735ms step_avg:486.61ms
[train step 1625] avg_loss=6.200277 main=5.679070 aux=0.521207 imp_cv2=0.0941 load_cv2=6.0190 usage_frac=0.4152 topk_prob_mean=0.1893 ema_alpha_reverse=nan max_logit=10.8091
step:1626/1750 train_time:791205ms step_avg:486.60ms
[train step 1626] avg_loss=3.241077 main=2.785728 aux=0.455348 imp_cv2=0.0864 load_cv2=5.2407 usage_frac=0.4286 topk_prob_mean=0.2603 ema_alpha_reverse=nan max_logit=11.7917
step:1627/1750 train_time:791668ms step_avg:486.58ms
[train step 1627] avg_loss=3.277724 main=2.832031 aux=0.445693 imp_cv2=0.1202 load_cv2=5.0877 usage_frac=0.4330 topk_prob_mean=0.2780 ema_alpha_reverse=nan max_logit=11.7917
step:1628/1750 train_time:792150ms step_avg:486.58ms
[train step 1628] avg_loss=3.291964 main=2.854285 aux=0.437679 imp_cv2=0.1915 load_cv2=4.9158 usage_frac=0.4330 topk_prob_mean=0.3054 ema_alpha_reverse=nan max_logit=11.7917
step:1629/1750 train_time:792800ms step_avg:486.68ms
[train step 1629] avg_loss=3.798577 main=3.266465 aux=0.532112 imp_cv2=0.0409 load_cv2=6.2066 usage_frac=0.4152 topk_prob_mean=0.1760 ema_alpha_reverse=nan max_logit=10.8091
step:1630/1750 train_time:793275ms step_avg:486.67ms
[train step 1630] avg_loss=3.095999 main=2.649343 aux=0.446657 imp_cv2=0.1614 load_cv2=5.0572 usage_frac=0.4330 topk_prob_mean=0.2926 ema_alpha_reverse=nan max_logit=11.7917
step:1631/1750 train_time:793743ms step_avg:486.66ms
[train step 1631] avg_loss=4.019639 main=3.518005 aux=0.501634 imp_cv2=0.0427 load_cv2=5.8427 usage_frac=0.4241 topk_prob_mean=0.1996 ema_alpha_reverse=nan max_logit=11.7917
step:1632/1750 train_time:794201ms step_avg:486.64ms
[train step 1632] avg_loss=3.185846 main=2.738309 aux=0.447537 imp_cv2=0.1347 load_cv2=5.0943 usage_frac=0.4286 topk_prob_mean=0.2835 ema_alpha_reverse=nan max_logit=11.7917
step:1633/1750 train_time:794661ms step_avg:486.63ms
[train step 1633] avg_loss=3.001394 main=2.554562 aux=0.446831 imp_cv2=0.2624 load_cv2=4.9443 usage_frac=0.4241 topk_prob_mean=0.3205 ema_alpha_reverse=nan max_logit=11.7917
step:1634/1750 train_time:795125ms step_avg:486.61ms
[train step 1634] avg_loss=3.360081 main=2.906711 aux=0.453370 imp_cv2=0.1210 load_cv2=5.1789 usage_frac=0.4286 topk_prob_mean=0.2750 ema_alpha_reverse=nan max_logit=11.7917
step:1635/1750 train_time:795608ms step_avg:486.61ms
[train step 1635] avg_loss=3.165486 main=2.717906 aux=0.447580 imp_cv2=0.1472 load_cv2=5.0804 usage_frac=0.4241 topk_prob_mean=0.2884 ema_alpha_reverse=nan max_logit=11.7917
step:1636/1750 train_time:796077ms step_avg:486.60ms
[train step 1636] avg_loss=3.377834 main=2.921670 aux=0.456163 imp_cv2=0.0957 load_cv2=5.2395 usage_frac=0.4286 topk_prob_mean=0.2660 ema_alpha_reverse=nan max_logit=11.7917
step:1637/1750 train_time:796538ms step_avg:486.58ms
[train step 1637] avg_loss=4.962483 main=4.434474 aux=0.528010 imp_cv2=0.0460 load_cv2=6.1556 usage_frac=0.4152 topk_prob_mean=0.1775 ema_alpha_reverse=nan max_logit=10.8091
step:1638/1750 train_time:797005ms step_avg:486.57ms
[train step 1638] avg_loss=3.260798 main=2.791549 aux=0.469249 imp_cv2=0.0618 load_cv2=5.4375 usage_frac=0.4286 topk_prob_mean=0.2412 ema_alpha_reverse=nan max_logit=11.7917
step:1639/1750 train_time:797471ms step_avg:486.56ms
[train step 1639] avg_loss=3.236965 main=2.781421 aux=0.455544 imp_cv2=0.1279 load_cv2=5.1961 usage_frac=0.4330 topk_prob_mean=0.2797 ema_alpha_reverse=nan max_logit=11.7917
step:1640/1750 train_time:797957ms step_avg:486.56ms
[train step 1640] avg_loss=3.233730 main=2.777530 aux=0.456200 imp_cv2=0.1185 load_cv2=5.2144 usage_frac=0.4241 topk_prob_mean=0.2741 ema_alpha_reverse=nan max_logit=11.7917
step:1641/1750 train_time:798418ms step_avg:486.54ms
[train step 1641] avg_loss=3.797694 main=3.338078 aux=0.459616 imp_cv2=0.1016 load_cv2=5.2746 usage_frac=0.4330 topk_prob_mean=0.2656 ema_alpha_reverse=nan max_logit=11.7917
step:1642/1750 train_time:798887ms step_avg:486.53ms
[train step 1642] avg_loss=3.457894 main=2.993606 aux=0.464288 imp_cv2=0.0869 load_cv2=5.3493 usage_frac=0.4286 topk_prob_mean=0.2589 ema_alpha_reverse=nan max_logit=11.7917
step:1643/1750 train_time:799362ms step_avg:486.53ms
[train step 1643] avg_loss=3.308954 main=2.853441 aux=0.455513 imp_cv2=0.1738 load_cv2=5.1435 usage_frac=0.4286 topk_prob_mean=0.2937 ema_alpha_reverse=nan max_logit=11.7917
step:1644/1750 train_time:799832ms step_avg:486.52ms
[train step 1644] avg_loss=2.936955 main=2.489489 aux=0.447466 imp_cv2=0.2200 load_cv2=5.0004 usage_frac=0.4241 topk_prob_mean=0.3136 ema_alpha_reverse=nan max_logit=11.7917
step:1645/1750 train_time:800295ms step_avg:486.50ms
[train step 1645] avg_loss=3.834102 main=3.339852 aux=0.494250 imp_cv2=0.0419 load_cv2=5.7647 usage_frac=0.4241 topk_prob_mean=0.2117 ema_alpha_reverse=nan max_logit=11.7917
step:1646/1750 train_time:800752ms step_avg:486.48ms
[train step 1646] avg_loss=2.919887 main=2.473015 aux=0.446872 imp_cv2=0.2013 load_cv2=5.0194 usage_frac=0.4241 topk_prob_mean=0.3079 ema_alpha_reverse=nan max_logit=11.7917
step:1647/1750 train_time:801221ms step_avg:486.47ms
[train step 1647] avg_loss=3.067979 main=2.617482 aux=0.450498 imp_cv2=0.1875 load_cv2=5.0752 usage_frac=0.4241 topk_prob_mean=0.3015 ema_alpha_reverse=nan max_logit=11.7917
step:1648/1750 train_time:801688ms step_avg:486.46ms
[train step 1648] avg_loss=3.197005 main=2.744430 aux=0.452575 imp_cv2=0.1645 load_cv2=5.1250 usage_frac=0.4241 topk_prob_mean=0.2911 ema_alpha_reverse=nan max_logit=11.7917
step:1649/1750 train_time:802153ms step_avg:486.45ms
[train step 1649] avg_loss=3.239867 main=2.785816 aux=0.454051 imp_cv2=0.1226 load_cv2=5.1875 usage_frac=0.4241 topk_prob_mean=0.2789 ema_alpha_reverse=nan max_logit=11.7917
step:1650/1750 train_time:802620ms step_avg:486.44ms
Running validation...
step:1650/1750 val_loss:2.895824 train_time:802631ms step_avg:486.44ms
[train step 1650] avg_loss=2.800736 main=2.352548 aux=0.448189 imp_cv2=0.1778 load_cv2=5.0551 usage_frac=0.4286 topk_prob_mean=0.3003 ema_alpha_reverse=nan max_logit=11.7917
step:1651/1750 train_time:803094ms step_avg:486.43ms
[train step 1651] avg_loss=3.595998 main=3.127671 aux=0.468328 imp_cv2=0.0964 load_cv2=5.3903 usage_frac=0.4286 topk_prob_mean=0.2598 ema_alpha_reverse=nan max_logit=11.7917
step:1652/1750 train_time:803553ms step_avg:486.41ms
[train step 1652] avg_loss=3.437496 main=2.975815 aux=0.461681 imp_cv2=0.1255 load_cv2=5.2730 usage_frac=0.4241 topk_prob_mean=0.2738 ema_alpha_reverse=nan max_logit=11.7917
step:1653/1750 train_time:804016ms step_avg:486.40ms
[train step 1653] avg_loss=3.341649 main=2.890559 aux=0.451090 imp_cv2=0.1473 load_cv2=5.1269 usage_frac=0.4286 topk_prob_mean=0.2883 ema_alpha_reverse=nan max_logit=11.7917
step:1654/1750 train_time:804477ms step_avg:486.38ms
[train step 1654] avg_loss=3.184392 main=2.728966 aux=0.455426 imp_cv2=0.1215 load_cv2=5.2058 usage_frac=0.4286 topk_prob_mean=0.2769 ema_alpha_reverse=nan max_logit=11.7917
step:1655/1750 train_time:804936ms step_avg:486.37ms
[train step 1655] avg_loss=4.406426 main=3.940432 aux=0.465995 imp_cv2=0.0697 load_cv2=5.3891 usage_frac=0.4330 topk_prob_mean=0.2485 ema_alpha_reverse=nan max_logit=11.7917
step:1656/1750 train_time:805395ms step_avg:486.35ms
[train step 1656] avg_loss=3.292847 main=2.838015 aux=0.454831 imp_cv2=0.1056 load_cv2=5.2205 usage_frac=0.4330 topk_prob_mean=0.2716 ema_alpha_reverse=nan max_logit=11.7917
step:1657/1750 train_time:805857ms step_avg:486.34ms
[train step 1657] avg_loss=3.385258 main=2.913632 aux=0.471626 imp_cv2=0.0570 load_cv2=5.4721 usage_frac=0.4286 topk_prob_mean=0.2393 ema_alpha_reverse=nan max_logit=11.7917
step:1658/1750 train_time:806319ms step_avg:486.32ms
[train step 1658] avg_loss=3.423647 main=2.959121 aux=0.464526 imp_cv2=0.1004 load_cv2=5.3413 usage_frac=0.4286 topk_prob_mean=0.2629 ema_alpha_reverse=nan max_logit=11.7917
step:1659/1750 train_time:806780ms step_avg:486.30ms
[train step 1659] avg_loss=3.071176 main=2.618765 aux=0.452411 imp_cv2=0.2180 load_cv2=5.0657 usage_frac=0.4286 topk_prob_mean=0.3120 ema_alpha_reverse=nan max_logit=11.7917
step:1660/1750 train_time:807247ms step_avg:486.29ms
[train step 1660] avg_loss=3.361054 main=2.902251 aux=0.458803 imp_cv2=0.1178 load_cv2=5.2499 usage_frac=0.4196 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=11.7917
step:1661/1750 train_time:807714ms step_avg:486.28ms
[train step 1661] avg_loss=2.932180 main=2.481011 aux=0.451170 imp_cv2=0.2361 load_cv2=5.0320 usage_frac=0.4286 topk_prob_mean=0.3173 ema_alpha_reverse=nan max_logit=11.7917
step:1662/1750 train_time:808181ms step_avg:486.27ms
[train step 1662] avg_loss=3.230931 main=2.769843 aux=0.461088 imp_cv2=0.1160 load_cv2=5.2821 usage_frac=0.4196 topk_prob_mean=0.2724 ema_alpha_reverse=nan max_logit=11.7917
step:1663/1750 train_time:808644ms step_avg:486.26ms
[train step 1663] avg_loss=3.697431 main=3.220845 aux=0.476587 imp_cv2=0.0616 load_cv2=5.5309 usage_frac=0.4286 topk_prob_mean=0.2390 ema_alpha_reverse=nan max_logit=11.7917
step:1664/1750 train_time:809113ms step_avg:486.25ms
[train step 1664] avg_loss=3.458233 main=2.994953 aux=0.463280 imp_cv2=0.0777 load_cv2=5.3541 usage_frac=0.4286 topk_prob_mean=0.2538 ema_alpha_reverse=nan max_logit=11.7917
step:1665/1750 train_time:809578ms step_avg:486.23ms
[train step 1665] avg_loss=3.503356 main=3.042023 aux=0.461334 imp_cv2=0.0777 load_cv2=5.3243 usage_frac=0.4241 topk_prob_mean=0.2551 ema_alpha_reverse=nan max_logit=11.7917
step:1666/1750 train_time:810041ms step_avg:486.22ms
[train step 1666] avg_loss=4.443502 main=3.919436 aux=0.524066 imp_cv2=0.0367 load_cv2=6.1155 usage_frac=0.4152 topk_prob_mean=0.1780 ema_alpha_reverse=nan max_logit=10.8091
step:1667/1750 train_time:810499ms step_avg:486.20ms
[train step 1667] avg_loss=3.290185 main=2.836688 aux=0.453497 imp_cv2=0.1116 load_cv2=5.1991 usage_frac=0.4286 topk_prob_mean=0.2756 ema_alpha_reverse=nan max_logit=11.7917
step:1668/1750 train_time:810958ms step_avg:486.19ms
[train step 1668] avg_loss=4.112701 main=3.594859 aux=0.517842 imp_cv2=0.0559 load_cv2=6.0302 usage_frac=0.4107 topk_prob_mean=0.1859 ema_alpha_reverse=nan max_logit=10.8091
step:1669/1750 train_time:811430ms step_avg:486.18ms
[train step 1669] avg_loss=3.534652 main=3.077527 aux=0.457125 imp_cv2=0.1178 load_cv2=5.2346 usage_frac=0.4286 topk_prob_mean=0.2739 ema_alpha_reverse=nan max_logit=11.7917
step:1670/1750 train_time:811898ms step_avg:486.17ms
[train step 1670] avg_loss=3.431244 main=2.978748 aux=0.452496 imp_cv2=0.1214 load_cv2=5.1790 usage_frac=0.4241 topk_prob_mean=0.2780 ema_alpha_reverse=nan max_logit=11.7917
step:1671/1750 train_time:812372ms step_avg:486.16ms
[train step 1671] avg_loss=3.339155 main=2.896371 aux=0.442784 imp_cv2=0.1572 load_cv2=5.0194 usage_frac=0.4286 topk_prob_mean=0.2968 ema_alpha_reverse=nan max_logit=11.7917
step:1672/1750 train_time:812842ms step_avg:486.15ms
[train step 1672] avg_loss=3.390008 main=2.927247 aux=0.462761 imp_cv2=0.1092 load_cv2=5.3134 usage_frac=0.4286 topk_prob_mean=0.2691 ema_alpha_reverse=nan max_logit=11.7917
step:1673/1750 train_time:813299ms step_avg:486.13ms
[train step 1673] avg_loss=3.136540 main=2.683310 aux=0.453230 imp_cv2=0.1885 load_cv2=5.1117 usage_frac=0.4286 topk_prob_mean=0.3008 ema_alpha_reverse=nan max_logit=11.7917
step:1674/1750 train_time:813778ms step_avg:486.13ms
[train step 1674] avg_loss=2.991838 main=2.548591 aux=0.443247 imp_cv2=0.1835 load_cv2=4.9990 usage_frac=0.4286 topk_prob_mean=0.3051 ema_alpha_reverse=nan max_logit=11.7917
step:1675/1750 train_time:814242ms step_avg:486.11ms
[train step 1675] avg_loss=3.157365 main=2.705058 aux=0.452308 imp_cv2=0.1218 load_cv2=5.1727 usage_frac=0.4286 topk_prob_mean=0.2799 ema_alpha_reverse=nan max_logit=11.7917
step:1676/1750 train_time:814901ms step_avg:486.22ms
[train step 1676] avg_loss=3.582959 main=3.128761 aux=0.454198 imp_cv2=0.0854 load_cv2=5.2324 usage_frac=0.4286 topk_prob_mean=0.2639 ema_alpha_reverse=nan max_logit=11.7917
step:1677/1750 train_time:815371ms step_avg:486.21ms
[train step 1677] avg_loss=4.020478 main=3.554797 aux=0.465681 imp_cv2=0.0655 load_cv2=5.3982 usage_frac=0.4286 topk_prob_mean=0.2468 ema_alpha_reverse=nan max_logit=11.7917
step:1678/1750 train_time:815844ms step_avg:486.20ms
[train step 1678] avg_loss=4.186013 main=3.682468 aux=0.503545 imp_cv2=0.0465 load_cv2=5.8757 usage_frac=0.4152 topk_prob_mean=0.2011 ema_alpha_reverse=nan max_logit=11.7917
step:1679/1750 train_time:816311ms step_avg:486.19ms
[train step 1679] avg_loss=3.135557 main=2.681435 aux=0.454122 imp_cv2=0.1572 load_cv2=5.1507 usage_frac=0.4286 topk_prob_mean=0.2903 ema_alpha_reverse=nan max_logit=11.7917
step:1680/1750 train_time:816771ms step_avg:486.17ms
[train step 1680] avg_loss=3.846755 main=3.383235 aux=0.463520 imp_cv2=0.0738 load_cv2=5.3598 usage_frac=0.4196 topk_prob_mean=0.2532 ema_alpha_reverse=nan max_logit=11.7917
step:1681/1750 train_time:817238ms step_avg:486.16ms
[train step 1681] avg_loss=3.204282 main=2.752420 aux=0.451862 imp_cv2=0.1311 load_cv2=5.1573 usage_frac=0.4286 topk_prob_mean=0.2821 ema_alpha_reverse=nan max_logit=11.7917
step:1682/1750 train_time:817698ms step_avg:486.15ms
[train step 1682] avg_loss=3.217324 main=2.760619 aux=0.456705 imp_cv2=0.1346 load_cv2=5.2134 usage_frac=0.4286 topk_prob_mean=0.2809 ema_alpha_reverse=nan max_logit=11.7917
step:1683/1750 train_time:818164ms step_avg:486.13ms
[train step 1683] avg_loss=3.000592 main=2.555072 aux=0.445520 imp_cv2=0.2139 load_cv2=4.9890 usage_frac=0.4286 topk_prob_mean=0.3120 ema_alpha_reverse=nan max_logit=11.7917
step:1684/1750 train_time:818630ms step_avg:486.12ms
[train step 1684] avg_loss=3.713843 main=3.245276 aux=0.468567 imp_cv2=0.0540 load_cv2=5.4433 usage_frac=0.4286 topk_prob_mean=0.2364 ema_alpha_reverse=nan max_logit=11.7917
step:1685/1750 train_time:819091ms step_avg:486.11ms
[train step 1685] avg_loss=3.160815 main=2.716939 aux=0.443876 imp_cv2=0.1403 load_cv2=5.0513 usage_frac=0.4330 topk_prob_mean=0.2892 ema_alpha_reverse=nan max_logit=11.7917
step:1686/1750 train_time:819554ms step_avg:486.09ms
[train step 1686] avg_loss=3.326233 main=2.876832 aux=0.449401 imp_cv2=0.1376 load_cv2=5.1187 usage_frac=0.4286 topk_prob_mean=0.2836 ema_alpha_reverse=nan max_logit=11.7917
step:1687/1750 train_time:820020ms step_avg:486.08ms
[train step 1687] avg_loss=3.206194 main=2.762562 aux=0.443633 imp_cv2=0.1794 load_cv2=5.0076 usage_frac=0.4375 topk_prob_mean=0.3022 ema_alpha_reverse=nan max_logit=11.7917
step:1688/1750 train_time:820483ms step_avg:486.07ms
[train step 1688] avg_loss=2.642476 main=2.197276 aux=0.445199 imp_cv2=0.3254 load_cv2=4.8629 usage_frac=0.4286 topk_prob_mean=0.3418 ema_alpha_reverse=nan max_logit=11.7917
step:1689/1750 train_time:820953ms step_avg:486.06ms
[train step 1689] avg_loss=4.265731 main=3.759575 aux=0.506156 imp_cv2=0.0429 load_cv2=5.9044 usage_frac=0.4241 topk_prob_mean=0.1995 ema_alpha_reverse=nan max_logit=11.7917
step:1690/1750 train_time:821418ms step_avg:486.05ms
[train step 1690] avg_loss=3.134891 main=2.689617 aux=0.445274 imp_cv2=0.1875 load_cv2=5.0181 usage_frac=0.4330 topk_prob_mean=0.3019 ema_alpha_reverse=nan max_logit=11.7917
step:1691/1750 train_time:822119ms step_avg:486.17ms
[train step 1691] avg_loss=3.364577 main=2.908371 aux=0.456206 imp_cv2=0.0979 load_cv2=5.2468 usage_frac=0.4286 topk_prob_mean=0.2647 ema_alpha_reverse=nan max_logit=11.7917
step:1692/1750 train_time:822586ms step_avg:486.16ms
[train step 1692] avg_loss=3.398128 main=2.950604 aux=0.447524 imp_cv2=0.1148 load_cv2=5.1259 usage_frac=0.4330 topk_prob_mean=0.2763 ema_alpha_reverse=nan max_logit=11.7917
step:1693/1750 train_time:823053ms step_avg:486.15ms
[train step 1693] avg_loss=3.335139 main=2.885076 aux=0.450063 imp_cv2=0.1421 load_cv2=5.1221 usage_frac=0.4286 topk_prob_mean=0.2822 ema_alpha_reverse=nan max_logit=11.7917
step:1694/1750 train_time:823514ms step_avg:486.14ms
[train step 1694] avg_loss=3.738719 main=3.275945 aux=0.462774 imp_cv2=0.0695 load_cv2=5.3561 usage_frac=0.4330 topk_prob_mean=0.2463 ema_alpha_reverse=nan max_logit=11.7917
step:1695/1750 train_time:823974ms step_avg:486.12ms
[train step 1695] avg_loss=4.150824 main=3.660751 aux=0.490073 imp_cv2=0.0403 load_cv2=5.7080 usage_frac=0.4286 topk_prob_mean=0.2104 ema_alpha_reverse=nan max_logit=11.7917
step:1696/1750 train_time:824431ms step_avg:486.10ms
[train step 1696] avg_loss=3.809511 main=3.305677 aux=0.503834 imp_cv2=0.0465 load_cv2=5.8713 usage_frac=0.4196 topk_prob_mean=0.2004 ema_alpha_reverse=nan max_logit=11.7917
step:1697/1750 train_time:824898ms step_avg:486.09ms
[train step 1697] avg_loss=3.002590 main=2.560564 aux=0.442026 imp_cv2=0.1970 load_cv2=4.9652 usage_frac=0.4330 topk_prob_mean=0.3052 ema_alpha_reverse=nan max_logit=11.7917
step:1698/1750 train_time:825375ms step_avg:486.09ms
[train step 1698] avg_loss=3.091320 main=2.646519 aux=0.444802 imp_cv2=0.2013 load_cv2=4.9949 usage_frac=0.4330 topk_prob_mean=0.3043 ema_alpha_reverse=nan max_logit=11.7917
step:1699/1750 train_time:825853ms step_avg:486.08ms
[train step 1699] avg_loss=3.032049 main=2.586904 aux=0.445145 imp_cv2=0.2378 load_cv2=4.9594 usage_frac=0.4330 topk_prob_mean=0.3145 ema_alpha_reverse=nan max_logit=11.7917
step:1700/1750 train_time:826320ms step_avg:486.07ms
Running validation...
step:1700/1750 val_loss:2.885472 train_time:826332ms step_avg:486.08ms
[train step 1700] avg_loss=3.591957 main=3.119599 aux=0.472359 imp_cv2=0.0713 load_cv2=5.4699 usage_frac=0.4286 topk_prob_mean=0.2415 ema_alpha_reverse=nan max_logit=11.7917
step:1701/1750 train_time:826789ms step_avg:486.06ms
[train step 1701] avg_loss=3.588171 main=3.133059 aux=0.455112 imp_cv2=0.1168 load_cv2=5.2078 usage_frac=0.4241 topk_prob_mean=0.2724 ema_alpha_reverse=nan max_logit=11.7917
step:1702/1750 train_time:827248ms step_avg:486.04ms
[train step 1702] avg_loss=3.139848 main=2.686903 aux=0.452945 imp_cv2=0.1746 load_cv2=5.1169 usage_frac=0.4241 topk_prob_mean=0.2936 ema_alpha_reverse=nan max_logit=11.7917
step:1703/1750 train_time:827706ms step_avg:486.03ms
[train step 1703] avg_loss=2.924884 main=2.481138 aux=0.443746 imp_cv2=0.2462 load_cv2=4.9315 usage_frac=0.4286 topk_prob_mean=0.3187 ema_alpha_reverse=nan max_logit=11.7917
step:1704/1750 train_time:828184ms step_avg:486.02ms
[train step 1704] avg_loss=3.009870 main=2.564844 aux=0.445026 imp_cv2=0.2085 load_cv2=4.9941 usage_frac=0.4241 topk_prob_mean=0.3081 ema_alpha_reverse=nan max_logit=11.7917
step:1705/1750 train_time:828650ms step_avg:486.01ms
[train step 1705] avg_loss=4.886040 main=4.361046 aux=0.524994 imp_cv2=0.0436 load_cv2=6.1190 usage_frac=0.4196 topk_prob_mean=0.1801 ema_alpha_reverse=nan max_logit=11.0414
step:1706/1750 train_time:829110ms step_avg:486.00ms
[train step 1706] avg_loss=3.223329 main=2.774513 aux=0.448816 imp_cv2=0.1852 load_cv2=5.0633 usage_frac=0.4286 topk_prob_mean=0.2995 ema_alpha_reverse=nan max_logit=11.7917
step:1707/1750 train_time:829574ms step_avg:485.98ms
[train step 1707] avg_loss=3.379926 main=2.926042 aux=0.453884 imp_cv2=0.1163 load_cv2=5.1980 usage_frac=0.4375 topk_prob_mean=0.2757 ema_alpha_reverse=nan max_logit=11.7917
step:1708/1750 train_time:830044ms step_avg:485.97ms
[train step 1708] avg_loss=3.336971 main=2.877732 aux=0.459238 imp_cv2=0.1295 load_cv2=5.2454 usage_frac=0.4241 topk_prob_mean=0.2756 ema_alpha_reverse=nan max_logit=11.7917
step:1709/1750 train_time:830514ms step_avg:485.96ms
[train step 1709] avg_loss=3.279292 main=2.822308 aux=0.456983 imp_cv2=0.1510 load_cv2=5.1932 usage_frac=0.4330 topk_prob_mean=0.2837 ema_alpha_reverse=nan max_logit=11.7917
step:1710/1750 train_time:830971ms step_avg:485.95ms
[train step 1710] avg_loss=3.409182 main=2.959457 aux=0.449725 imp_cv2=0.1459 load_cv2=5.1133 usage_frac=0.4286 topk_prob_mean=0.2861 ema_alpha_reverse=nan max_logit=11.7917
step:1711/1750 train_time:831436ms step_avg:485.94ms
[train step 1711] avg_loss=3.485199 main=3.018037 aux=0.467162 imp_cv2=0.0640 load_cv2=5.4053 usage_frac=0.4241 topk_prob_mean=0.2433 ema_alpha_reverse=nan max_logit=11.7917
step:1712/1750 train_time:831907ms step_avg:485.93ms
[train step 1712] avg_loss=3.013002 main=2.567823 aux=0.445179 imp_cv2=0.2168 load_cv2=4.9823 usage_frac=0.4286 topk_prob_mean=0.3108 ema_alpha_reverse=nan max_logit=11.7917
step:1713/1750 train_time:832373ms step_avg:485.92ms
[train step 1713] avg_loss=4.080477 main=3.599774 aux=0.480703 imp_cv2=0.0495 load_cv2=5.5892 usage_frac=0.4286 topk_prob_mean=0.2236 ema_alpha_reverse=nan max_logit=11.7917
step:1714/1750 train_time:832834ms step_avg:485.90ms
[train step 1714] avg_loss=3.292652 main=2.845540 aux=0.447112 imp_cv2=0.1138 load_cv2=5.1203 usage_frac=0.4286 topk_prob_mean=0.2772 ema_alpha_reverse=nan max_logit=11.7917
step:1715/1750 train_time:833299ms step_avg:485.89ms
[train step 1715] avg_loss=3.714156 main=3.242503 aux=0.471652 imp_cv2=0.0669 load_cv2=5.4710 usage_frac=0.4286 topk_prob_mean=0.2421 ema_alpha_reverse=nan max_logit=11.7917
step:1716/1750 train_time:833762ms step_avg:485.88ms
[train step 1716] avg_loss=3.412248 main=2.961287 aux=0.450961 imp_cv2=0.1643 load_cv2=5.1122 usage_frac=0.4330 topk_prob_mean=0.2902 ema_alpha_reverse=nan max_logit=11.7917
step:1717/1750 train_time:834226ms step_avg:485.86ms
[train step 1717] avg_loss=3.177430 main=2.729899 aux=0.447531 imp_cv2=0.1726 load_cv2=5.0625 usage_frac=0.4286 topk_prob_mean=0.2956 ema_alpha_reverse=nan max_logit=11.7917
step:1718/1750 train_time:834690ms step_avg:485.85ms
[train step 1718] avg_loss=3.076783 main=2.632406 aux=0.444377 imp_cv2=0.2469 load_cv2=4.9462 usage_frac=0.4241 topk_prob_mean=0.3199 ema_alpha_reverse=nan max_logit=11.7917
step:1719/1750 train_time:835156ms step_avg:485.84ms
[train step 1719] avg_loss=3.174032 main=2.718324 aux=0.455708 imp_cv2=0.1055 load_cv2=5.2308 usage_frac=0.4286 topk_prob_mean=0.2679 ema_alpha_reverse=nan max_logit=11.7917
step:1720/1750 train_time:835621ms step_avg:485.83ms
[train step 1720] avg_loss=3.033644 main=2.586514 aux=0.447131 imp_cv2=0.2270 load_cv2=4.9989 usage_frac=0.4286 topk_prob_mean=0.3122 ema_alpha_reverse=nan max_logit=11.7917
step:1721/1750 train_time:836087ms step_avg:485.81ms
[train step 1721] avg_loss=3.975255 main=3.512447 aux=0.462808 imp_cv2=0.0935 load_cv2=5.3291 usage_frac=0.4330 topk_prob_mean=0.2592 ema_alpha_reverse=nan max_logit=11.7917
step:1722/1750 train_time:836552ms step_avg:485.80ms
[train step 1722] avg_loss=3.071281 main=2.627037 aux=0.444244 imp_cv2=0.1362 load_cv2=5.0588 usage_frac=0.4286 topk_prob_mean=0.2878 ema_alpha_reverse=nan max_logit=11.7917
step:1723/1750 train_time:837018ms step_avg:485.79ms
[train step 1723] avg_loss=3.855287 main=3.347719 aux=0.507568 imp_cv2=0.0616 load_cv2=5.8888 usage_frac=0.4286 topk_prob_mean=0.1999 ema_alpha_reverse=nan max_logit=11.7917
step:1724/1750 train_time:837490ms step_avg:485.78ms
[train step 1724] avg_loss=3.372878 main=2.909841 aux=0.463038 imp_cv2=0.0807 load_cv2=5.3487 usage_frac=0.4241 topk_prob_mean=0.2552 ema_alpha_reverse=nan max_logit=11.7917
step:1725/1750 train_time:837950ms step_avg:485.77ms
[train step 1725] avg_loss=3.257463 main=2.807063 aux=0.450400 imp_cv2=0.2118 load_cv2=5.0478 usage_frac=0.4241 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=11.7917
step:1726/1750 train_time:838414ms step_avg:485.76ms
[train step 1726] avg_loss=3.186774 main=2.734195 aux=0.452580 imp_cv2=0.1959 load_cv2=5.0935 usage_frac=0.4241 topk_prob_mean=0.3014 ema_alpha_reverse=nan max_logit=11.7917
step:1727/1750 train_time:838884ms step_avg:485.75ms
[train step 1727] avg_loss=3.628035 main=3.173392 aux=0.454643 imp_cv2=0.1138 load_cv2=5.2061 usage_frac=0.4330 topk_prob_mean=0.2709 ema_alpha_reverse=nan max_logit=11.7917
step:1728/1750 train_time:839348ms step_avg:485.73ms
[train step 1728] avg_loss=3.148795 main=2.707878 aux=0.440916 imp_cv2=0.1619 load_cv2=4.9888 usage_frac=0.4241 topk_prob_mean=0.2974 ema_alpha_reverse=nan max_logit=11.7917
step:1729/1750 train_time:839814ms step_avg:485.72ms
[train step 1729] avg_loss=3.187750 main=2.738351 aux=0.449399 imp_cv2=0.1476 load_cv2=5.1105 usage_frac=0.4286 topk_prob_mean=0.2868 ema_alpha_reverse=nan max_logit=11.7917
step:1730/1750 train_time:840282ms step_avg:485.71ms
[train step 1730] avg_loss=3.230651 main=2.768865 aux=0.461787 imp_cv2=0.0871 load_cv2=5.3202 usage_frac=0.4241 topk_prob_mean=0.2574 ema_alpha_reverse=nan max_logit=11.7917
step:1731/1750 train_time:840749ms step_avg:485.70ms
[train step 1731] avg_loss=2.739784 main=2.297996 aux=0.441788 imp_cv2=0.2155 load_cv2=4.9467 usage_frac=0.4330 topk_prob_mean=0.3124 ema_alpha_reverse=nan max_logit=11.7917
step:1732/1750 train_time:841212ms step_avg:485.69ms
[train step 1732] avg_loss=4.044760 main=3.586759 aux=0.458001 imp_cv2=0.0861 load_cv2=5.2773 usage_frac=0.4330 topk_prob_mean=0.2578 ema_alpha_reverse=nan max_logit=11.7917
step:1733/1750 train_time:841680ms step_avg:485.68ms
[train step 1733] avg_loss=4.279356 main=3.789626 aux=0.489730 imp_cv2=0.0402 load_cv2=5.7143 usage_frac=0.4241 topk_prob_mean=0.2144 ema_alpha_reverse=nan max_logit=11.7917
step:1734/1750 train_time:842147ms step_avg:485.67ms
[train step 1734] avg_loss=4.066076 main=3.601095 aux=0.464981 imp_cv2=0.0663 load_cv2=5.3847 usage_frac=0.4286 topk_prob_mean=0.2454 ema_alpha_reverse=nan max_logit=11.7917
step:1735/1750 train_time:842614ms step_avg:485.66ms
[train step 1735] avg_loss=3.066420 main=2.619810 aux=0.446610 imp_cv2=0.2067 load_cv2=5.0092 usage_frac=0.4286 topk_prob_mean=0.3062 ema_alpha_reverse=nan max_logit=11.7917
step:1736/1750 train_time:843073ms step_avg:485.64ms
[train step 1736] avg_loss=3.264366 main=2.809213 aux=0.455153 imp_cv2=0.0967 load_cv2=5.2321 usage_frac=0.4286 topk_prob_mean=0.2635 ema_alpha_reverse=nan max_logit=11.7917
step:1737/1750 train_time:843550ms step_avg:485.64ms
[train step 1737] avg_loss=3.334059 main=2.872080 aux=0.461979 imp_cv2=0.0770 load_cv2=5.3345 usage_frac=0.4286 topk_prob_mean=0.2517 ema_alpha_reverse=nan max_logit=11.7917
step:1738/1750 train_time:844015ms step_avg:485.62ms
[train step 1738] avg_loss=3.202312 main=2.749598 aux=0.452715 imp_cv2=0.1177 load_cv2=5.1782 usage_frac=0.4330 topk_prob_mean=0.2736 ema_alpha_reverse=nan max_logit=11.7917
step:1739/1750 train_time:844487ms step_avg:485.62ms
[train step 1739] avg_loss=3.935074 main=3.437555 aux=0.497519 imp_cv2=0.0447 load_cv2=5.7971 usage_frac=0.4286 topk_prob_mean=0.2119 ema_alpha_reverse=nan max_logit=11.7917
step:1740/1750 train_time:844949ms step_avg:485.60ms
[train step 1740] avg_loss=3.264717 main=2.814398 aux=0.450319 imp_cv2=0.1023 load_cv2=5.1728 usage_frac=0.4241 topk_prob_mean=0.2689 ema_alpha_reverse=nan max_logit=11.7917
step:1741/1750 train_time:845421ms step_avg:485.60ms
[train step 1741] avg_loss=4.259998 main=3.768536 aux=0.491462 imp_cv2=0.0514 load_cv2=5.7187 usage_frac=0.4241 topk_prob_mean=0.2145 ema_alpha_reverse=nan max_logit=11.7917
step:1742/1750 train_time:845893ms step_avg:485.59ms
[train step 1742] avg_loss=2.874890 main=2.436652 aux=0.438239 imp_cv2=0.2474 load_cv2=4.8647 usage_frac=0.4330 topk_prob_mean=0.3217 ema_alpha_reverse=nan max_logit=11.7917
step:1743/1750 train_time:846358ms step_avg:485.58ms
[train step 1743] avg_loss=3.120709 main=2.675387 aux=0.445321 imp_cv2=0.2081 load_cv2=4.9923 usage_frac=0.4330 topk_prob_mean=0.3068 ema_alpha_reverse=nan max_logit=11.7917
step:1744/1750 train_time:846823ms step_avg:485.56ms
[train step 1744] avg_loss=3.983374 main=3.523306 aux=0.460068 imp_cv2=0.0711 load_cv2=5.3171 usage_frac=0.4286 topk_prob_mean=0.2502 ema_alpha_reverse=nan max_logit=11.7917
step:1745/1750 train_time:847284ms step_avg:485.55ms
[train step 1745] avg_loss=3.439810 main=2.980490 aux=0.459320 imp_cv2=0.0742 load_cv2=5.3061 usage_frac=0.4286 topk_prob_mean=0.2514 ema_alpha_reverse=nan max_logit=11.7917
step:1746/1750 train_time:847752ms step_avg:485.54ms
[train step 1746] avg_loss=3.421669 main=2.962894 aux=0.458775 imp_cv2=0.0900 load_cv2=5.2835 usage_frac=0.4375 topk_prob_mean=0.2602 ema_alpha_reverse=nan max_logit=11.7917
step:1747/1750 train_time:848211ms step_avg:485.52ms
[train step 1747] avg_loss=3.533593 main=3.064547 aux=0.469047 imp_cv2=0.0730 load_cv2=5.4237 usage_frac=0.4375 topk_prob_mean=0.2460 ema_alpha_reverse=nan max_logit=11.8203
step:1748/1750 train_time:848680ms step_avg:485.51ms
[train step 1748] avg_loss=3.297263 main=2.851402 aux=0.445862 imp_cv2=0.1378 load_cv2=5.0730 usage_frac=0.4286 topk_prob_mean=0.2849 ema_alpha_reverse=nan max_logit=11.7917
step:1749/1750 train_time:849143ms step_avg:485.50ms
[train step 1749] avg_loss=3.651673 main=3.178214 aux=0.473459 imp_cv2=0.0556 load_cv2=5.4882 usage_frac=0.4330 topk_prob_mean=0.2330 ema_alpha_reverse=nan max_logit=11.7917
step:1750/1750 train_time:849607ms step_avg:485.49ms
Running validation...
step:1750/1750 val_loss:2.901154 train_time:849618ms step_avg:485.50ms
peak memory allocated: 29973 MiB reserved: 33172 MiB
