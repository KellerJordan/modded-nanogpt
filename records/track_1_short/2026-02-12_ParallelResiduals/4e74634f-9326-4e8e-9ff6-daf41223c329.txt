import os
import sys

# Read the current file and the kernels file code ASAP, for logging
with open(sys.argv[0], 'r') as f:
    code = f.read()
with open(os.path.join(os.path.dirname(sys.argv[0]), 'triton_kernels.py'), 'r') as f:
    code += f"\n\n{'-'*40}\n# triton_kernels.py\n{'-'*40}\n\n"
    code += f.read()

import copy
import glob
import math
import threading
import time
import uuid
from dataclasses import dataclass
from itertools import accumulate, pairwise
from pathlib import Path
import gc

os.environ["PYTORCH_ALLOC_CONF"] = "expandable_segments:True"
import torch
import triton

torch.empty(
    1, device=f"cuda:{os.environ['LOCAL_RANK']}", requires_grad=True
).backward()  # prevents a bug on some systems
import torch._dynamo as dynamo
import torch.distributed as dist
import torch.nn.functional as F

# torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min
from kernels import get_kernel
from torch import Tensor, nn

from triton_kernels import XXT, ba_plus_cAA, FusedLinearReLUSquareFunction, FusedSoftcappedCrossEntropy

dynamo.config.recompile_limit = 64

# -----------------------------------------------------------------------------
# Distributed training setup
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert 8 % world_size == 0, "world_size must be a divisor of 8"
grad_accum_steps = 8 // world_size
grad_scale = 1 / grad_accum_steps # consistent grad magnitudes between different num_devices
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng
# Transposed layout by @ChrisJMcCormick allows for faster gradient accumulation.

@torch.library.custom_op("nanogpt::mm_t", mutates_args=())
def mm_t_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    """Computes y = x @ w with F8 weights stored as (in_features, out_features)."""
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        assert x.shape[1] == w.shape[0]  # x: (batch, in), w: (in, out)

        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)

        # _scaled_mm requires column-major B. w_f8 is row-major (in, out).
        # .T.contiguous().T creates a column-major view without changing logical shape.
        w_f8_col_major = w_f8.T.contiguous().T

        out = torch._scaled_mm(
            x_f8,
            w_f8_col_major,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_t_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[0]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_t_backward", mutates_args=())
def mm_t_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()

        x_scale = grad.new_tensor(x_s, dtype=torch.float32)
        w_scale = grad.new_tensor(w_s, dtype=torch.float32)
        grad_scale = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)

        # grad_x = grad @ w.T
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=grad_scale,
            scale_b=w_scale,
            use_fast_accum=False,
        )

        # grad_w = x.T @ grad
        # Result is (in, out), naturally matching weight storage. No final .T needed.
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_scale,
            scale_b=grad_scale,
            use_fast_accum=False,
        )

        return grad_x, grad_w

    grad_x, grad_w = impl(g, x_f8, w_f8)

    return grad_x, grad_w

@mm_t_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward_t(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_t_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context_t(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_t_op.register_autograd(backward_t, setup_context=setup_context_t)

# -----------------------------------------------------------------------------
# Polar Express

# Computed for num_iters=5, safety_factor=2e-2, cushion=2
polar_express_coeffs = [
    (8.156554524902461, -22.48329292557795, 15.878769915207462),
    (4.042929935166739, -2.808917465908714, 0.5000178451051316),
    (3.8916678022926607, -2.772484153217685, 0.5060648178503393),
    (3.285753657755655, -2.3681294933425376, 0.46449024233003106),
    (2.3465413258596377, -1.7097828382687081, 0.42323551169305323)
]

@torch.compile(dynamic=False, fullgraph=True) # Must use dynamic=False or else it's much slower
def polar_express(G: torch.Tensor, split_baddbmm: bool = False):
    """
    Polar Express Sign Method: https://arxiv.org/pdf/2505.16932
    by Noah Amsel, David Persson, Christopher Musco, Robert M. Gower.
    """
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) * (1 + 2e-2) + 1e-6)

    # Allocate buffers
    X = X.contiguous()
    A = torch.empty((*X.shape[:-1], X.size(-2)), device=X.device, dtype=X.dtype)
    B = torch.empty_like(A)
    C = torch.empty_like(X)

    # Select batched vs unbatched
    if split_baddbmm:
        BX_matmul = torch.bmm if X.ndim > 2 else torch.mm
    else:
        aX_plus_BX = torch.baddbmm if X.ndim > 2 else torch.addmm

    # Perform the iterations
    for a, b, c in polar_express_coeffs:
        XXT(X, out=A)  # A = X @ X.mT
        ba_plus_cAA(A, alpha=c, beta=b, out=B)  # B = b * A + c * A @ A

        # Referencing X twice causes pytorch to make a defensive copy,
        # resulting in a cudaMemcpyAsync in baddbmm.
        # For large matrices (i.e., the mlp weights), it's faster to split
        # the operation into two kernels to avoid this.
        if split_baddbmm:
            BX_matmul(B, X, out=C)  # C = B @ X
            C.add_(X, alpha=a)      # C = C + a*X  (in-place, X only read)
        else:
            aX_plus_BX(X, B, X, beta=a, out=C)  # C = a * X + B @ X

        X, C = C, X  # Swap references to avoid unnecessary copies

    if G.size(-2) > G.size(-1):
        X = X.mT
    return X


# -----------------------------------------------------------------------------
# Combined NorMuon + Adam Optimizer

@dataclass
class ParamConfig:
    """Per-parameter configuration for NorMuonAndAdam optimizer."""
    label: str
    optim: str  # "adam" or "normuon"
    comms: str  # "none", "replicated", or "sharded"
    adam_betas: tuple[float, float] | None
    lr_mul: float
    wd_mul: float
    lr: float
    initial_lr: float
    weight_decay: float
    # Adam-specific
    eps: float | None = None
    # NorMuon-specific
    reshape: tuple | None = None
    chunk_size: int | None = None
    momentum: float | None = None
    beta2: float | None = None
    per_matrix_lr_mul: list[float] | None = None


class NorMuonAndAdam:
    """
    Combined optimizer that handles both NorMuon (for projection matrices) and
    Adam (for embeddings/scalars/gate weights).

    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, Muon uses a Newton-Schulz iteration (replaced
    here with Polar Express), which has the advantage that it can be stably run in bfloat16 on the GPU.

    Muon is applied only to the projection matrices in the attention and MLP layers, and is not recommended
    for embeddings, scalars, or individual weight vectors (e.g., bias terms or gate weights).

    Differences from standard Muon:
    - Newton-Shulz is replaced with Polar Express for the orthogonalization step
    - NorMuon adds a low-rank variance estimator similar to Adafactor. https://arxiv.org/pdf/2510.05491
    - Cautious weight decay, a gated version of decoupled weight decay
    - Mantissa tracking for precision

    Adam (for embeddings/scalars/gates):
    - Standard Adam with bias correction
    - Cautious weight decay

    Configuration:
    Unlike torch.optim.Optimizer, this class uses per-parameter configs from a `param_table` dict
    and does not include parameter "groups". All parameters require a .label attribute, and a
    corresponding entry in the param_table to specify their hyperparameters (lr_mul, wd_mul, adam_betas, etc.).

    Communication and ordering:
    Gradient communication is explicitly scheduled rather than hook-driven.
    Reductions are launched in `scatter_order`, while update math and final
    gathers are executed in `work_order`. These orders are independent and
    must each contain every parameter label exactly once.

    Two communication modes are supported per parameter:
    - 'replicated': Gradients are all-reduced and each rank computes the full update.
    - 'sharded': Gradients are reduce-scattered, each rank updates its shard,
      and results are all-gathered.

    Adam parameters may be freely sharded. NorMuon operates on full matrices; sharding is
    supported by grouping matrices into parameter banks. NorMuon parameters must have a
    `.reshape` attribute that reshapes the bank so that the leading dimension is divisible
    by world_size.

    # Contributors include @YouJiacheng, @KonstantinWilleke, @alexrgilbert, @adricarda,
    # @tuttyfrutyee, @vdlad, @ryanyang0, @vagrawal, @varunneal, @chrisjmccormick
    """
    def __init__(self, named_params, param_table: dict, scatter_order: list, work_order: list,
                 adam_defaults: dict, normuon_defaults: dict):
        self.world_size = dist.get_world_size() if dist.is_initialized() else 1

        # Store defaults for each optimizer type
        self.adam_defaults = adam_defaults
        self.normuon_defaults = normuon_defaults
        self.param_table = param_table
        self.scatter_order = scatter_order
        self.work_order = work_order

        # Collect params by label and build config
        self.param_cfgs: dict[nn.Parameter, ParamConfig] = {}
        self.param_states: dict[nn.Parameter, dict] = {}
        self._param_by_label: dict[str, nn.Parameter] = {}
        for name, param in named_params:
            label = getattr(param, "label", None)
            assert label is not None and label in param_table  # all params must have valid label
            assert label not in self._param_by_label  # exactly one param per label
            self._param_by_label[label] = param
            self._build_param_cfg(param, label)

        # Assert scatter_order and work_order match present labels exactly
        present = set(self._param_by_label.keys())
        assert set(scatter_order) == present and set(work_order) == present

        # Handle world_size=1: overwrite comms to "none"
        if self.world_size == 1:
            for p_cfg in self.param_cfgs.values():
                p_cfg.comms = "none"

        # Initialize state for all params
        self._init_state()

        # 0-D CPU tensors to avoid recompilation
        self._step_size_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")
        self._eff_wd_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")
        self._eff_lr_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")

        # Track async operations
        self._reduce_futures: dict[nn.Parameter, tuple] = {}

        # Embed/lm_head tying state
        self.split_embed = False
        self._lm_head_param = self._param_by_label.get("lm_head")
        self._embed_param = self._param_by_label.get("embed")

    def _build_param_cfg(self, param: nn.Parameter, label: str):
        """Build config for a single parameter from param_table."""
        table_entry = self.param_table[label]
        optim = table_entry["optim"]
        comms = table_entry["comms"]
        adam_betas = table_entry.get("adam_betas")
        lr_mul = table_entry.get("lr_mul", 1.0)
        wd_mul = table_entry.get("wd_mul", 1.0)

        if optim == "adam":
            chunk_size = param.shape[0] // self.world_size if comms == "sharded" else None
            p_cfg = ParamConfig(
                label=label,
                optim=optim,
                comms=comms,
                adam_betas=tuple(adam_betas) if adam_betas else None,
                lr_mul=lr_mul,
                wd_mul=wd_mul,
                lr=self.adam_defaults["lr"],
                initial_lr=self.adam_defaults["lr"],
                weight_decay=self.adam_defaults["weight_decay"],
                eps=self.adam_defaults["eps"],
                chunk_size=chunk_size,
            )
        elif optim == "normuon":
            reshape = getattr(param, "reshape", None)
            if reshape is None:
                raise ValueError(f"NorMuon param {label} must have .reshape attribute")
            if reshape[0] % self.world_size != 0:
                raise ValueError(f"reshape[0]={reshape[0]} must be divisible by world_size")

            chunk_size = reshape[0] // self.world_size
            chunk_shape = (chunk_size, *reshape[1:])
            # Shape-based LR multiplier for NorMuon
            shape_mult = max(1.0, chunk_shape[-2] / chunk_shape[-1]) ** 0.5 if len(chunk_shape) >= 2 else 1.0
            lr_mul = shape_mult * lr_mul

            # Per-matrix LR multipliers for MLP c_proj (2x LR on odd indices)
            per_matrix_lr_mul = None
            if label == "mlp":
                rank = dist.get_rank() if dist.is_initialized() else 0
                start_idx = rank * chunk_size
                per_matrix_lr_mul = []
                for i in range(chunk_size):
                    global_idx = start_idx + i
                    is_c_proj = (global_idx % 2 == 1)
                    per_matrix_lr_mul.append(2.0 if is_c_proj else 1.0)

            p_cfg = ParamConfig(
                label=label,
                optim=optim,
                comms=comms,
                adam_betas=tuple(adam_betas) if adam_betas else None,
                lr_mul=lr_mul,
                wd_mul=wd_mul,
                lr=self.normuon_defaults["lr"],
                initial_lr=self.normuon_defaults["lr"],
                weight_decay=self.normuon_defaults["weight_decay"],
                reshape=reshape,
                chunk_size=chunk_size,
                momentum=self.normuon_defaults["momentum"],
                beta2=self.normuon_defaults["beta2"],
                per_matrix_lr_mul=per_matrix_lr_mul,
            )
        else:
            raise ValueError(f"Unknown optim type: {optim}")

        self.param_cfgs[param] = p_cfg

    def _init_state(self):
        """Initialize optimizer state for all parameters."""
        for param, p_cfg in self.param_cfgs.items():
            if p_cfg.optim == "adam":
                # Sharded params use chunk state, replicated use full state
                if p_cfg.comms == "sharded":
                    chunk = param[:p_cfg.chunk_size]
                else:
                    chunk = param
                exp_avg = torch.zeros_like(chunk, dtype=torch.float32, device=param.device)
                self.param_states[param] = dict(step=0, exp_avg=exp_avg, exp_avg_sq=torch.zeros_like(exp_avg))

            elif p_cfg.optim == "normuon":
                chunk_shape = (p_cfg.chunk_size, *p_cfg.reshape[1:])

                # Momentum buffer (FP32 for precision)
                momentum_buffer = torch.zeros(
                    chunk_shape, dtype=torch.float32, device=param.device
                )

                # Second momentum buffer - reduced along one dimension
                if chunk_shape[-2] >= chunk_shape[-1]:
                    second_mom_shape = (*chunk_shape[:-1], 1)
                else:
                    second_mom_shape = (*chunk_shape[:-2], 1, chunk_shape[-1])
                second_momentum_buffer = torch.zeros(
                    second_mom_shape, dtype=torch.float32, device=param.device
                )

                # Mantissa buffer for precision tracking
                mantissa = torch.zeros(
                    chunk_shape, dtype=torch.uint16, device=param.device
                )

                self.param_states[param] = dict(
                    momentum_buffer=momentum_buffer,
                    second_momentum_buffer=second_momentum_buffer,
                    mantissa=mantissa,
                )

    # -----------------------------------
    # Reduce/Gather operations

    def _launch_reduce(self, param: nn.Parameter, grad: Tensor):
        """Launch async reduce for a parameter based on its comms policy."""
        p_cfg = self.param_cfgs[param]

        if p_cfg.comms == "none":
            if p_cfg.optim == "normuon":
                # NorMuon needs reshaped gradient even without communication
                grad = grad.view(p_cfg.reshape)
            self._reduce_futures[param] = (None, grad)
        elif p_cfg.comms == "replicated":
            future = dist.all_reduce(grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
            self._reduce_futures[param] = (future, grad)
        elif p_cfg.comms == "sharded":
            if p_cfg.optim == "normuon":
                # NorMuon: reshape before reduce_scatter
                grad_reshaped = grad.view(p_cfg.reshape)
                grad_chunk = torch.empty(
                    (p_cfg.chunk_size, *grad_reshaped.shape[1:]),
                    dtype=grad.dtype,
                    device=grad.device
                )
                future = dist.reduce_scatter_tensor(
                    grad_chunk, grad_reshaped.contiguous(), op=dist.ReduceOp.AVG, async_op=True
                ).get_future()
                self._reduce_futures[param] = (future, grad_chunk)
            else:
                # Adam: simple reduce_scatter
                grad_chunk = torch.empty_like(grad[:p_cfg.chunk_size])
                future = dist.reduce_scatter_tensor(
                    grad_chunk, grad, op=dist.ReduceOp.AVG, async_op=True
                ).get_future()
                self._reduce_futures[param] = (future, grad_chunk)

    def _launch_gather(self, param: nn.Parameter, p_slice: Tensor) -> "torch.futures.Future":
        """Launch async all_gather for a sharded parameter."""
        p_cfg = self.param_cfgs[param]
        if p_cfg.optim == "normuon":
            full_param = param.data.view(p_cfg.reshape)
            assert full_param.is_contiguous()
            return dist.all_gather_into_tensor(
                full_param, p_slice.contiguous(), async_op=True
            ).get_future()
        else:
            return dist.all_gather_into_tensor(
                param, p_slice.contiguous(), async_op=True
            ).get_future()

    # -----------------------------------
    # State management

    def reset(self):
        """Reset NorMuon momentum buffers and split_embed state (called on training reset)."""
        self.split_embed = False
        for param, p_cfg in self.param_cfgs.items():
            if p_cfg.optim == "normuon":
                p_state = self.param_states[param]
                p_state["momentum_buffer"].zero_()
                p_state["mantissa"].zero_()
                p_state["second_momentum_buffer"].zero_()

    def copy_lm_state_to_embed(self):
        """
        Copy the optimizer state from the lm_head to the embed at the untie point.
        This requires an all-gather + reshard because of different sharding:
        - lm_head (768, 50304) is sharded to (96, 50304) per rank (along model_dim)
        - embed (50304, 768) is sharded to (6288, 768) per rank (along vocab_size)

        We all-gather the lm_head momentum, transpose it, then each rank takes their
        embed shard to get the correct momentum state.
        """
        lm_head = self._lm_head_param
        embed = self._embed_param
        lm_state = self.param_states[lm_head]
        embed_state = self.param_states[embed]
        lm_cfg = self.param_cfgs[lm_head]
        embed_cfg = self.param_cfgs[embed]

        embed_state['step'] = lm_state['step'] # Preserve step count for bias correction

        # Copy optimizer state with all-gather + transpose + reshard
        if self.world_size > 1:
            rank = dist.get_rank()
            lm_chunk_size = lm_cfg.chunk_size  # 96
            embed_chunk_size = embed_cfg.chunk_size  # 6288

            # All-gather lm_head momentum to get full (768, 50304) tensor
            for key in ["exp_avg", "exp_avg_sq"]:
                lm_chunk = lm_state[key]  # (96, 50304)
                full_lm = torch.empty(lm_head.shape[0], lm_head.shape[1], dtype=lm_chunk.dtype, device=lm_chunk.device)
                dist.all_gather_into_tensor(full_lm, lm_chunk.contiguous())
                embed_state[key].copy_(full_lm.T[rank * embed_chunk_size:(rank + 1) * embed_chunk_size])
        else:
            # Single GPU: simple transpose
            for key in ["exp_avg", "exp_avg_sq"]:
                embed_state[key].copy_(lm_state[key].T)

        # Mark as split
        self.split_embed = True

    def state_dict(self):
        """Return the optimizer state as a dict."""
        return {
            "param_states": {id(p): s for p, s in self.param_states.items()},
            "param_cfgs": {id(p): s for p, s in self.param_cfgs.items()},
        }

    def load_state_dict(self, state_dict):
        """Load optimizer state from a dict."""
        # Build id->param mapping
        id_to_param = {id(p): p for p in self.param_cfgs.keys()}

        # Load state, preserving dtypes
        for param_id, saved_p_state in state_dict["param_states"].items():
            if param_id in id_to_param:
                param = id_to_param[param_id]
                p_state = self.param_states[param]
                for k, v in saved_p_state.items():
                    if isinstance(v, torch.Tensor) and k in p_state:
                        target_dtype = p_state[k].dtype
                        p_state[k] = v.to(dtype=target_dtype, device=p_state[k].device)
                    else:
                        p_state[k] = v

    # -----------------------------------
    # Unified optimizer step with explicit ordering

    @torch.no_grad()
    def step(self, do_adam: bool = True):
        """
        Combined optimizer step with explicit ordering.

        Args:
            do_adam: If True, update Adam params. NorMuon params always updated.

        Flow:
        1. Scatter phase: Launch reduces in scatter_order
        2. Work phase: Process updates in work_order
           - Wait for reduce, compute update, launch gather
        3. Finalize phase: Wait for gathers

        While the embeddings are tied:
        - Comms and update math are only done on lm_head.
        - We add embed.grad.T into lm_head.grad before comms.
        - After lm_head gather, we copy lm_head.data.T --> embed.data
        """
        rank = dist.get_rank() if dist.is_initialized() else 0
        lm_param, embed_param = self._lm_head_param, self._embed_param

        # ===== Phase 1: Launch reduces in scatter_order =====
        for label in self.scatter_order:
            param = self._param_by_label[label]
            p_cfg = self.param_cfgs[param]

            if p_cfg.optim == "adam" and not do_adam:
                continue
            if param.grad is None:
                continue

            # lm_head when tied: aggregate embed.grad.T (transposed shapes)
            if label == "lm_head" and do_adam and not self.split_embed:
                if embed_param is not None and embed_param.grad is not None:
                    param.grad.add_(embed_param.grad.T)

            # Skip embed when tied (copied from lm_head after gather)
            if label == "embed" and not self.split_embed:
                continue

            self._launch_reduce(param, param.grad)

        # ===== Phase 2: Process updates in work_order =====
        gather_futures = []
        lm_head_gather_future = None

        for label in self.work_order:
            param = self._param_by_label[label]
            if param not in self._reduce_futures:
                continue

            p_cfg = self.param_cfgs[param]
            if p_cfg.optim == "adam" and not do_adam:
                continue
            # Wait for reduce
            future, grad_chunk = self._reduce_futures[param]
            if future is not None:
                future.wait()
            # Apply update based on optim type
            if p_cfg.optim == "adam":
                p_slice = self._adam_update(param, grad_chunk, p_cfg, rank)
            else:
                p_slice = self._normuon_update(param, grad_chunk, p_cfg, rank)
            # Launch gather for sharded params
            if p_cfg.comms == "sharded" and self.world_size > 1:
                gather_fut = self._launch_gather(param, p_slice)
                if label == "lm_head":
                    lm_head_gather_future = gather_fut
                else:
                    gather_futures.append(gather_fut)

        # ===== Phase 3: Wait for gathers, sync embed if tied =====
        # Wait for lm_head gather first so we can copy to embed while other gathers complete
        if lm_head_gather_future is not None:
            lm_head_gather_future.wait()

        # When tied: copy lm_head.T to embed
        if do_adam and not self.split_embed and embed_param is not None and lm_param is not None:
            embed_param.data.copy_(lm_param.data.T)

        # Wait for remaining gathers
        for fut in gather_futures:
            fut.wait()

        self._reduce_futures.clear()

        # Clear grads for updated params
        for param, p_cfg in self.param_cfgs.items():
            if p_cfg.optim == "adam" and not do_adam:
                continue  # Don't clear Adam grads on even steps
            param.grad = None

    # -----------------------------------
    # Adam update

    def _adam_update(self, param: nn.Parameter, grad_chunk: Tensor, p_cfg: ParamConfig, rank: int) -> Tensor:
        """Apply Adam update to a parameter. Returns the updated p_slice."""
        beta1, beta2 = p_cfg.adam_betas
        lr = p_cfg.lr * p_cfg.lr_mul

        # Get parameter slice
        if p_cfg.comms == "sharded":
            p_slice = param[rank * p_cfg.chunk_size:(rank + 1) * p_cfg.chunk_size]
        else:
            p_slice = param

        p_state = self.param_states[param]
        p_state["step"] += 1
        t = p_state["step"]

        bias1, bias2 = 1 - beta1 ** t, 1 - beta2 ** t
        self._step_size_t.fill_(lr * (bias2 ** 0.5 / bias1))
        self._eff_wd_t.fill_(lr * lr * p_cfg.weight_decay * p_cfg.wd_mul)

        NorMuonAndAdam._adam_update_step(
            p_slice, grad_chunk, p_state["exp_avg"], p_state["exp_avg_sq"],
            beta1, beta2, p_cfg.eps, self._step_size_t, self._eff_wd_t
        )

        return p_slice

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _adam_update_step(p_slice, g_slice, exp_avg, exp_avg_sq, beta1, beta2, eps, step_size_t, eff_wd_t):
        """Compiled Adam update step."""
        exp_avg.mul_(beta1).add_(g_slice, alpha=1 - beta1)
        exp_avg_sq.mul_(beta2).addcmul_(g_slice, g_slice, value=1 - beta2)
        update = exp_avg.div(exp_avg_sq.sqrt().add_(eps)).mul_(step_size_t)
        # Cautious weight decay
        mask = (update * p_slice) > 0
        update.addcmul_(p_slice, mask, value=eff_wd_t)
        p_slice.add_(other=update, alpha=-1.0)

    # -----------------------------------
    # NorMuon update

    def _normuon_update(self, param: nn.Parameter, grad_chunk: Tensor, p_cfg: ParamConfig, rank: int) -> Tensor:
        """Apply NorMuon update to a parameter. Returns the updated p_slice."""
        chunk_shape = grad_chunk.shape

        p_state = self.param_states[param]
        grad_chunk = grad_chunk.float()  # FP32 for momentum

        # Momentum update
        momentum_buffer = p_state["momentum_buffer"]
        momentum_buffer.lerp_(grad_chunk, 1 - p_cfg.momentum)
        updated_grads = grad_chunk.lerp_(momentum_buffer, p_cfg.momentum)

        self._eff_lr_t.fill_(p_cfg.lr_mul * p_cfg.lr)
        self._eff_wd_t.fill_(p_cfg.wd_mul * p_cfg.weight_decay * p_cfg.lr)

        # Polar Express orthogonalization
        is_large_matrix = chunk_shape[-2] > 1024
        v_chunk = polar_express(updated_grads, split_baddbmm=is_large_matrix)

        # Variance reduction
        red_dim = -1 if chunk_shape[-2] >= chunk_shape[-1] else -2
        v_chunk = NorMuonAndAdam._apply_normuon_variance_reduction(
            v_chunk, p_state["second_momentum_buffer"], p_cfg.beta2, red_dim
        )

        # Update parameter, in place, with cautious weight decay
        param_view = param.data.view(p_cfg.reshape)
        p_slice = param_view[rank * p_cfg.chunk_size:(rank + 1) * p_cfg.chunk_size]

        # MLP has per-matrix LR multipliers (c_proj gets 2x LR)
        if p_cfg.per_matrix_lr_mul is not None:
            for mat_idx in range(p_cfg.chunk_size):
                self._eff_lr_t.fill_(p_cfg.lr_mul * p_cfg.per_matrix_lr_mul[mat_idx] * p_cfg.lr)
                self._eff_wd_t.fill_(p_cfg.wd_mul * p_cfg.weight_decay * p_cfg.lr)
                NorMuonAndAdam._cautious_wd_and_update_inplace(
                    p_slice[mat_idx].view(torch.uint16), p_state["mantissa"][mat_idx], v_chunk[mat_idx],
                    self._eff_wd_t, self._eff_lr_t
                )
        else:
            NorMuonAndAdam._cautious_wd_and_update_inplace(
                p_slice.view(torch.uint16), p_state["mantissa"], v_chunk,
                self._eff_wd_t, self._eff_lr_t
            )

        return p_slice

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _cautious_wd_and_update_inplace(p, mantissa, grad, wd_tensor, lr_tensor):
        """
        Cautious weight decay + parameter update. wd_tensor and lr_tensor are 0-D CPU tensors.
        Mantissa is tracked to enable higher precision updates on bfloat16 parameters.
        bfloat16 format: 1 sign bit + 8 exponent bits + 7 mantissa bits = 16 bits total
        float32 format: 1 sign bit + 8 exponent bits + 23 mantissa bits = 32 bits total
        """
        assert p.dtype == mantissa.dtype == torch.uint16
        grad = grad.float()
        wd_factor = wd_tensor.to(torch.float32)
        lr_factor = lr_tensor.to(torch.float32)
        p_precise_raw = (p.to(torch.uint32) << 16) | mantissa.to(torch.uint32)
        p_precise = p_precise_raw.view(torch.float32)
        mask = (grad * p_precise) >= 0
        p_precise.copy_(p_precise - (p_precise * mask * wd_factor * lr_factor) - (grad * lr_factor))
        p.copy_((p_precise_raw >> 16).to(torch.uint16))
        mantissa.copy_(p_precise_raw.to(torch.uint16))

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _apply_normuon_variance_reduction(v_chunk, second_momentum_buffer, beta2, red_dim):
        """NorMuon variance reduction. Algebraically fuses the normalization steps to minimize memory ops."""
        v_mean = v_chunk.float().square().mean(dim=red_dim, keepdim=True)
        red_dim_size = v_chunk.size(red_dim)
        v_norm_sq = v_mean.sum(dim=(-2, -1), keepdim=True).mul_(red_dim_size)
        v_norm = v_norm_sq.sqrt_()
        second_momentum_buffer.lerp_(v_mean.to(dtype=second_momentum_buffer.dtype), 1 - beta2)
        step_size = second_momentum_buffer.clamp_min(1e-10).rsqrt_()
        scaled_sq_sum = (v_mean * red_dim_size) * step_size.float().square()
        v_norm_new = scaled_sq_sum.sum(dim=(-2, -1), keepdim=True).sqrt_()
        final_scale = step_size * (v_norm / v_norm_new.clamp_min_(1e-10))
        return v_chunk.mul_(final_scale.type_as(v_chunk))

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))


class CastedLinearT(nn.Module):
    """
    Linear layer with transposed weight storage (in_features, out_features) which
    addresses the slow kernel that was used for gradient accumulation. @chrisjmccormick
    """
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

        self.weight = nn.Parameter(torch.empty(in_features, out_features, dtype=torch.bfloat16))
        self.reset_parameters()

    def reset_parameters(self) -> None:
        with torch.no_grad():
            nn.init.zeros_(self.weight) # @Grad62304977 and others

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out = torch.ops.nanogpt.mm_t(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return x @ self.weight.type_as(x)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

class Yarn(nn.Module):
    def __init__(self, head_dim, max_seq_len, paired=False):
        super().__init__()
        self.head_dim = head_dim
        self.max_seq_len = max_seq_len
        self.paired = paired
        self.reset()

    def rotary(self, x_BTHD):
        assert self.factor1.size(0) >= x_BTHD.size(-3)
        factor1, factor2 = (
            self.factor1[None, : x_BTHD.size(-3), None, :],
            self.factor2[None, : x_BTHD.size(-3), None, :],
        )
        x_flip = x_BTHD.view(*x_BTHD.shape[:-1], x_BTHD.shape[-1] // 2, 2).flip(-1).view(x_BTHD.shape)
        return factor1 * x_BTHD + factor2 * x_flip

    def reset(self):
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=self.head_dim//4, dtype=torch.float32, device=device)
        angular_freq = angular_freq.repeat_interleave(2)
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(self.head_dim//2)])
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=device)
        if not self.paired:
            theta = torch.outer(t, angular_freq)
            self.factor1 = nn.Buffer(
                theta.cos().to(torch.bfloat16), persistent=False
            )
            self.factor2 = nn.Buffer(
                theta.sin().to(torch.bfloat16), persistent=False
            )
        else:
            t_even = 2 * t
            t_odd = 2 * t + 1
            theta1 = torch.outer(t_even, angular_freq)
            theta2 = torch.outer(t_odd, angular_freq)
            self.factor1 = nn.Buffer(
                torch.cat((theta1.cos(), theta2.cos()), dim=-1).to(torch.bfloat16),
                persistent=False
            )
            self.factor2 = nn.Buffer(
                torch.cat((theta1.sin(), theta2.sin()), dim=-1).to(torch.bfloat16),
                persistent=False
            )
        self.factor2[..., 1::2] *= -1
        self.angular_freq = angular_freq
        # start with 0.1, inspired by 0.12 from @leloykun and learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        self.attn_scale = 0.1

    def apply(self, old_window: int, new_window: int, alpha: int=1, beta: int=32):
        rotations = old_window * self.angular_freq / (2 * torch.pi)
        scaling_factor = old_window / new_window
        interpolation_weight = torch.clamp((rotations - alpha) / (beta - alpha), 0, 1)
        self.angular_freq *= scaling_factor + interpolation_weight * (1 - scaling_factor)
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=self.angular_freq.device)
        if not self.paired:
            theta = torch.outer(t, self.angular_freq)
            self.factor1.copy_(theta.cos())
            self.factor2.copy_(theta.sin())
        else:
            t_even = 2 * t
            t_odd = 2 * t + 1
            theta1 = torch.outer(t_even, self.angular_freq)
            theta2 = torch.outer(t_odd, self.angular_freq)
            self.factor1.copy_(torch.cat((theta1.cos(), theta2.cos()), dim=-1))
            self.factor2.copy_(torch.cat((theta1.sin(), theta2.sin()), dim=-1))
        self.factor2[..., 1::2] *= -1
        self.attn_scale *= 0.2 * math.log(new_window / old_window) + 1

@dataclass
class AttnArgs:
    ve: torch.Tensor
    sa_lambdas: torch.Tensor
    seqlens: torch.Tensor
    bm_size: int
    yarn: Yarn
    key_offset: bool
    attn_gate_w: torch.Tensor
    ve_gate_w: torch.Tensor

flash_attn_interface = get_kernel('varunneal/flash-attention-3').flash_attn_interface

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, head_dim: int, num_heads: int, paired: bool = False):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        self.dim = dim
        self.hdim = num_heads * head_dim
        self.paired = paired
        assert self.hdim == self.dim, "num_heads * head_dim must equal model_dim"
        # Weights are stored in parameter banks and passed via forward()

    def forward(self, x: Tensor, attn_args: AttnArgs, qkvo_w: Tensor):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "varlen sequences requires B == 1"
        assert T % 16 == 0
        # unpack attention args
        yarn = attn_args.yarn
        ve, sa_lambdas, key_offset = attn_args.ve, attn_args.sa_lambdas, attn_args.key_offset
        seqlens, bm_size = attn_args.seqlens, attn_args.bm_size
        # sparse gated attention to enable context based no-op by @classiclarryd
        # only include gates on layers with value embeds used on forward pass
        attn_gate_w, ve_gate_w = attn_args.attn_gate_w, attn_args.ve_gate_w

        q, k, v = F.linear(x, sa_lambdas[0] * qkvo_w[:self.dim * 3].type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        max_len = args.train_max_seq_len if self.training else (args.val_batch_size // (grad_accum_steps * world_size))

        q, k = norm(q), norm(k) # QK norm @Grad62304977

        if not self.paired:
            q, k = yarn.rotary(q), yarn.rotary(k)

            if key_offset:
                # shift keys forward for the stationary head dims. Enables 1-layer induction.
                k[:, 1:, :, self.head_dim // 2:] = k[:, :-1, :, self.head_dim // 2:]

            if ve is not None:
                ve_gate_out = 2 * torch.sigmoid(F.linear(x[..., :12], ve_gate_w)).view(B, T, self.num_heads, 1)
                v = v + ve_gate_out * ve.view_as(v) # @ KoszarskyB & @Grad62304977

        else:
            # Paired heads: adjacent heads' queries attend to each other's keys.
            # Two copies of the input stream are interleaved to achieve this, which:
            # - doubles the length of each sequence
            # - halves the effective window size
            q = q.view(B, T, self.num_heads // 2, self.head_dim * 2)
            k = k.view(B, T, self.num_heads // 2, self.head_dim * 2)
            v = v.reshape(B, T * 2, self.num_heads // 2, self.head_dim)

            q, k = yarn.rotary(q), yarn.rotary(k)

            q = q.view(B, T * 2, self.num_heads // 2, self.head_dim)
            k = k.view(B, T * 2, self.num_heads // 2, self.head_dim)

            if ve is not None:
                ve_gate_out = 2 * torch.sigmoid(F.linear(x[..., :12], ve_gate_w)).view(B, T * 2, self.num_heads // 2, 1)
                v = v + ve_gate_out * ve.view_as(v)

            seqlens = 2 * seqlens
            max_len = 2 * max_len

        # use flash_attn over flex_attn @varunneal. flash_attn_varlen suggested by @YouJiacheng
        y = flash_attn_interface.flash_attn_varlen_func(q[0], k[0], v[0], cu_seqlens_q=seqlens, cu_seqlens_k=seqlens,
                                                        max_seqlen_q=max_len, max_seqlen_k=max_len,
                                                        causal=True, softmax_scale=yarn.attn_scale, window_size=(bm_size, 0))
        y = y.view(B, T, self.num_heads, self.head_dim)
        y = y * torch.sigmoid(F.linear(x[..., :12], attn_gate_w)).view(B, T, self.num_heads, 1)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = F.linear(y, sa_lambdas[1] * qkvo_w[self.dim * 3:].type_as(y))  # sa_lambdas[1] pre-multiplied to O @shenberg
        return y

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        # Weights are stored in parameter banks and passed via forward()

    def forward(self, x: Tensor, c_fc: Tensor, c_proj: Tensor):
        # relu(x)^2:
        # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        # Fused triton kernel for relu(x @ W1.T)^2 @ W2.T
        return FusedLinearReLUSquareFunction.apply(x, c_fc, c_proj)

class Block(nn.Module):
    def __init__(self, dim: int, head_dim: int, num_heads: int, has_attn: bool, has_mlp: bool, use_paired_head: bool):
        super().__init__()
        # skip attention of blocks.6 (the 7th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, head_dim, num_heads, paired=use_paired_head) if has_attn else None
        # skip MLP blocks for first MLP layer by @EmelyanenkoK
        self.mlp = MLP() if has_mlp else None

    def forward(self, x: Tensor, attn_args: AttnArgs, qkvo_w: Tensor = None, c_fc: Tensor = None, c_proj: Tensor = None):
        if self.attn is not None:
            x = x + self.attn(norm(x), attn_args, qkvo_w)
        if self.mlp is not None:
            x = x + self.mlp(norm(x), c_fc, c_proj)
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

@dataclass
class ForwardScheduleConfig:
    mtp_weights: torch.Tensor
    ws_short: int
    ws_long: int

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, head_dim: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.num_layers = num_layers
        self.vocab_size = next_multiple_of_n(vocab_size, n=128)

        self.smear_gate = nn.Linear(12, 1, bias=False)
        nn.init.zeros_(self.smear_gate.weight)
        self.smear_gate.weight.label = 'smear_gate'

        self.skip_gate = nn.Linear(12, 1, bias=False)
        nn.init.zeros_(self.skip_gate.weight)
        self.skip_gate.weight.label = 'skip_gate'

        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.Parameter(torch.zeros(5 * self.vocab_size, model_dim, dtype=torch.bfloat16))
        self.value_embeds.label = 'value_embed'

        # parameter banks for attention and value embedding gate weights
        self.attn_gate_bank = nn.Parameter(torch.zeros(10, num_heads, 12)) # 10 layers
        self.attn_gate_bank.label = 'attn_gate_bank'
        self.ve_gate_bank = nn.Parameter(torch.zeros(5, num_heads, 12)) # 5 unique gates
        self.ve_gate_bank.label = 've_gate_bank'

        # -----------------------------------
        # Parameter banks for sharded optimization, by @chrisjmccormick

        # Identify which layers have attention/MLP
        # Attention is skipped in layer 6 by @YouJiacheng
        self.attn_layer_indices = [i for i in range(num_layers) if i != 6]
        # All layers have MLP (At 11 layers--dropped first layer @EmelyanenkoK)
        self.mlp_layer_indices = list(range(num_layers))

        hdim = num_heads * head_dim
        mlp_hdim = 4 * model_dim

        # Create index mappings: layer_idx -> bank_idx
        self.layer_to_attn_idx = {layer_idx: bank_idx for bank_idx, layer_idx in enumerate(self.attn_layer_indices)}
        self.layer_to_mlp_idx = {layer_idx: bank_idx for bank_idx, layer_idx in enumerate(self.mlp_layer_indices)}

        # Attention bank: stores QKVO weights for all attention layers
        # merged QKVO weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        # Simplified layout by @chrisjmccormick
        # Shape: (num_attn_layers, 4*model_dim, hdim) = (10, 3072, 768)
        # Reshape for sharding: (40, 768, 768) for even distribution across 8 GPUs
        self.attn_bank = nn.Parameter(torch.empty(len(self.attn_layer_indices), 4 * model_dim, hdim))
        self.attn_bank.label = 'attn'
        self.attn_bank.reshape = (len(self.attn_layer_indices) * 4, hdim, hdim)  # (40, 768, 768)

        # MLP bank: stores c_fc and c_proj for all MLP layers
        # Shape: (num_mlp_layers + padding, 2, mlp_hdim, model_dim) = (12, 2, 3072, 768)
        # We add 1 padding layer (index 11) to get 12*2=24 matrices for even distribution across 8 GPUs
        # Reshape for sharding: (24, 3072, 768)
        num_mlp_with_padding = len(self.mlp_layer_indices) + 1  # 11 + 1 = 12
        self.mlp_bank = nn.Parameter(torch.empty(num_mlp_with_padding, 2, mlp_hdim, model_dim))
        self.mlp_bank.label = 'mlp'
        self.mlp_bank.reshape = (num_mlp_with_padding * 2, mlp_hdim, model_dim)  # (24, 3072, 768)

        # improved init scale by @YouJiacheng and @srashedll
        std = 0.5 * model_dim ** -0.5
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.attn_bank.uniform_(-bound, bound)
            self.mlp_bank[:, 0, :, :].uniform_(-bound, bound)  # c_fc
            self.mlp_bank[:, 1, :, :].zero_()  # c_proj - zero init suggested by @Grad62304977

        # Create blocks with has_attn/has_mlp flags
        self.paired_head_layers = [0, 2, 5, 9]
        self.blocks = nn.ModuleList([
            Block(model_dim, head_dim, num_heads,
                  has_attn=(i in self.layer_to_attn_idx),
                  has_mlp=(i in self.layer_to_mlp_idx),
                  use_paired_head=(i in self.paired_head_layers))
            for i in range(num_layers)
        ])
        self.yarn = Yarn(head_dim, max_seq_len)
        self.yarn_paired_head = Yarn(head_dim, max_seq_len, paired=True)
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        use_fp8 = not os.environ.get("DISABLE_FP8", False)
        # Transposed weight storage for faster gradient accumulation
        self.lm_head = CastedLinearT(model_dim, self.vocab_size, use_fp8=use_fp8, x_s=100/448, w_s=1.6/448, grad_s=grad_scale * 0.75/448)

        nn.init.normal_(self.lm_head.weight, mean=0, std=0.005)
        self.lm_head.weight.label = 'lm_head'

        self.embed = nn.Embedding(self.vocab_size, model_dim)
        self.embed.weight.label = 'embed'
        with torch.no_grad():
            self.embed.weight.copy_(self.lm_head.weight.T)

        self.bigram_embed = nn.Embedding(args.bigram_vocab_size, model_dim)
        self.bigram_embed.weight.label = 'bigram_embed'
        nn.init.zeros_(self.bigram_embed.weight)

        n_sublayers = 2 * num_layers

        # Parallel-connections: 2-lane residual stream (attn reads lane0, MLP reads lane1)
        self.parallel_start = 7
        w_post_init = torch.ones(n_sublayers, 2, 1)
        for layer in range(num_layers):
            if layer >= self.parallel_start:
                si_attn = 2 * layer
                w_post_init[si_attn, 1, 0] = 1.5  # attn w_post1
        self.w_post = nn.Parameter(w_post_init)
        self.w_post.label = 'w_post'

        self.x0_lambda = nn.Parameter(torch.zeros(n_sublayers))
        self.x0_lambda.label = 'x0_lambda'

        self.bigram_lambda = nn.Parameter(0.05 * torch.ones(n_sublayers))
        self.bigram_lambda.label = 'bigram_lambda'

        self.resid_lambda = nn.Parameter(1.1**0.5 * torch.ones(n_sublayers))
        self.resid_lambda.label = 'resid_lambda'

        pad = (-num_layers * 2 - 3) % dist.get_world_size()  # updated: 2*num_layers (SA lambdas only)
        self.scalars = nn.Parameter(
            torch.cat(
                [
                    *[torch.tensor([0.5, 1.0]) for _ in range(num_layers)],  # SA lambdas
                    torch.zeros(1), # smear_lambda
                    0.5*torch.ones(1), # backout_lambda
                    -1.5 * torch.ones(1),  # skip_lambda -> (-1.5)  0.18
                    torch.ones(pad),
                ]
            )
        )
        self.scalars.label = 'scalars'

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _compute_bigram_hash(x: Tensor) -> Tensor:
        """
        Computes bigram hash for each position using [prev_token, curr_token].
        Multiply by arbitary large ints to get even spread over int32 range.
        Position 0 is mapped to the reserved index (vocab_size - 1).
        BOS_tokens within the batch will hash based on last token of prior doc. Masking this ran slower and showed no improvement.
        """
        rand_int_1 = 36313
        rand_int_2 = 27191
        mod = args.bigram_vocab_size-1
        result = torch.empty_like(x)
        result[0] = mod
        result[1:] = torch.bitwise_xor(rand_int_1 * x[1:], rand_int_2 * x[:-1]) % mod
        return result

    def forward(self, input_seq: Tensor, target_seq: Tensor, seqlens: Tensor, schedule_cfg: ForwardScheduleConfig):
        assert input_seq.ndim == 1

        # unpack schedule_cfg
        mtp_weights, ws_short, ws_long = schedule_cfg.mtp_weights, schedule_cfg.ws_short, schedule_cfg.ws_long

        # set configs
        skip_connections = []
        skip_in = [3] # long attention window on layer 3
        skip_out = [6] # no attn op on layer 6
        x_backout = None
        backout_layer = 7

        # set lambdas
        sa_lambdas = self.scalars[: 2 * self.num_layers].view(-1, 2)
        smear_lambda = self.scalars[2 * self.num_layers]
        backout_lambda = self.scalars[2 * self.num_layers + 1]
        skip_lambda = self.scalars[2 * self.num_layers + 2]

        # Unbind scalars per-sublayer per-lane (avoids select_backwards kernel)
        w_post0 = self.w_post[:, 0, 0].bfloat16().unbind(0)
        w_post1 = self.w_post[:, 1, 0].bfloat16().unbind(0)
        x0_lambda = self.x0_lambda.bfloat16().unbind(0)
        bigram_lambda = self.bigram_lambda.bfloat16().unbind(0)
        resid_lambda = self.resid_lambda.bfloat16().unbind(0)

        # set block masks and key shift
        bm_sizes = [ws_short, ws_short, ws_short, ws_long, ws_short, ws_short, None, ws_short, ws_short, ws_short, ws_long]
        assert len(bm_sizes) == self.num_layers
        key_offset = [b==ws_long for b in bm_sizes] # apply partial key offset to long windows

        # Embedding lookup - embed is synced from lm_head during tied phase by optimizer
        x = self.embed(input_seq)
        
        bigram_seq = self._compute_bigram_hash(input_seq)
        x0_bigram = self.bigram_embed(bigram_seq)[None]

        # Value embeddings - always computed (not precomputed)
        ve = self.value_embeds.view(5, self.vocab_size, -1)[:, input_seq]
        # 01 ... 234 structure on token value embeddings by @photomz
        ve = [ve[0], ve[1]] + [None] * (self.num_layers - 5) + [ve[2], ve[3], ve[4]]
        assert len(ve) == self.num_layers

        # smear token embed forward 1 position @classiclarryd
        smear_gate_out = smear_lambda * torch.sigmoid(self.smear_gate(x[1:, :self.smear_gate.weight.size(-1)]))
        x = torch.cat([x[:1], x[1:] + smear_gate_out * x[:-1]])
        x = x0 = norm(x[None])

        # Initialize residual stream with pre-layer-0 bigram injection
        # lane1 introduced at parallel_start block (single-stream before that)
        lane0 = x0 + x0_bigram * bigram_lambda[0]
        lane1 = None
        # Zero out sublayer-0 bigram to avoid double injection in the loop
        zero = bigram_lambda[0] * 0
        bigram_lambda = (zero,) + bigram_lambda[1:]

        # Precompute skip contributions outside loop 
        skip_bias = tuple(x0 * x0_lambda[2*i] + x0_bigram * bigram_lambda[2*i] for i in range(self.num_layers))

        ag = [w.bfloat16() for w in self.attn_gate_bank.unbind(0)]
        veg = [w.bfloat16() for w in self.ve_gate_bank.unbind(0)]
        attn_gates = ag[:6] + [None] + ag[6:]
        ve_gates = [veg[0], veg[1]] + [None] * (self.num_layers - 5) + [veg[2], veg[3], veg[4]]
        assert len(attn_gates) == self.num_layers
        assert len(ve_gates) == self.num_layers

        # unbind weight banks to avoid select_backwards kernel
        attn_weights = self.attn_bank.unbind(0)  # tuple of [4*dim, hdim] tensors
        mlp_fcs = self.mlp_bank[:, 0, :, :].unbind(0)  # tuple of [mlp_hdim, dim] tensors
        mlp_projs = self.mlp_bank[:, 1, :, :].unbind(0)  # tuple of [mlp_hdim, dim] tensors

        for i in range(self.num_layers):
            yarn = self.yarn_paired_head if i in self.paired_head_layers else self.yarn
            attn_args = AttnArgs(
                ve=ve[i],
                sa_lambdas=sa_lambdas[i],
                seqlens=seqlens,
                bm_size=bm_sizes[i],
                yarn=yarn,
                key_offset=key_offset[i],
                attn_gate_w=attn_gates[i],
                ve_gate_w=ve_gates[i]
            )
            qkvo_w = attn_weights[self.layer_to_attn_idx[i]] if i in self.layer_to_attn_idx else None
            c_fc = mlp_fcs[self.layer_to_mlp_idx[i]] if i in self.layer_to_mlp_idx else None
            c_proj = mlp_projs[self.layer_to_mlp_idx[i]] if i in self.layer_to_mlp_idx else None

            block = self.blocks[i]
            si = 2 * i  # sublayer index for attn

            # Introduce lane1 at parallel_start by copying lane0
            if i == self.parallel_start:
                lane1 = lane0

            if i in skip_out:
                skip_gate_out = torch.sigmoid(skip_lambda) * 2 * torch.sigmoid(self.skip_gate(x0[..., :self.skip_gate.weight.size(-1)]))
                skip_val = skip_connections.pop()
                lane0 = lane0 + skip_gate_out * skip_val
                if lane1 is not None:
                    lane1 = lane1 + skip_gate_out * skip_val

            if i < self.parallel_start:
                # Single-stream: only lane0, MLP also reads lane0
                if block.attn is not None:
                    layer_out = block.attn(norm(lane0), attn_args, qkvo_w)
                    layer_out = layer_out + skip_bias[i]
                    lane0 = resid_lambda[si] * lane0 + layer_out * w_post0[si]
                if i in skip_in:
                    skip_connections.append(lane0)
                if block.mlp is not None:
                    layer_out = block.mlp(norm(lane0), c_fc, c_proj)
                    lane0 = resid_lambda[si+1] * lane0 + layer_out * w_post0[si+1]
            else:
                # Full 2-lane parallel connections
                if block.attn is not None:
                    layer_out = block.attn(norm(lane0), attn_args, qkvo_w)
                    layer_out = layer_out + skip_bias[i]
                    lane0 = resid_lambda[si] * lane0 + layer_out * w_post0[si]
                    lane1 = resid_lambda[si] * lane1 + layer_out * w_post1[si]
                if i in skip_in:
                    skip_connections.append(lane0)
                if block.mlp is not None:
                    layer_out = block.mlp(norm(lane1), c_fc, c_proj)
                    lane0 = resid_lambda[si+1] * lane0 + layer_out * w_post0[si+1]
                    lane1 = resid_lambda[si+1] * lane1 + layer_out * w_post1[si+1]
            if i == backout_layer:
                x_backout = lane0

        x = (lane0 + lane1) * 0.5

        # back out contributions from first 7 layers that are only required for downstream context and not direct prediction
        x -= backout_lambda * x_backout
        x = norm(x)
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15
        # @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1). @classiclarryd updated to 23*sigmoid((logits+5)/7.5)
        if self.training:
            losses = FusedSoftcappedCrossEntropy.apply(x.view(-1, x.size(-1)), target_seq, mtp_weights, self.lm_head.weight, self.lm_head.x_s, self.lm_head.w_s, self.lm_head.grad_s)
            loss = losses.sum()
        else:
            logits = self.lm_head(x)
            logits = 23 * torch.sigmoid((logits + 5) / 7.5)
            logits_for_loss = logits.float()
            loss = F.cross_entropy(logits_for_loss.view(-1, logits_for_loss.size(-1)), target_seq, reduction="mean")
        return loss
# -----------------------------------------------------------------------------
# Distributed data loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

BOS_ID = 50256

class Shard:
    def __init__(self, tokens: Tensor, world_size: int = 1):
        self.tokens = tokens
        self.size = tokens.numel()
        self.world_size = world_size
        self.i = 0

        # Partial index now, full index async
        self.bos_idx = (tokens[:6_000_000] == BOS_ID).nonzero(as_tuple=True)[0].to(torch.int64).cpu().numpy()
        self._full_idx = None
        self._loader_thread = None
        self._ready = threading.Event()
        self._loader_thread = threading.Thread(target=self._scan)
        self._loader_thread.start()

    def _scan(self):
        self._full_idx = (self.tokens == BOS_ID).nonzero(as_tuple=True)[0].to(torch.int64).cpu().numpy()
        self._ready.set()

    def _maybe_switch(self):
        # Switch to full index as soon as async scan completes
        if self.bos_idx is not self._full_idx and self._ready.is_set():
            self._loader_thread.join()
            self.bos_idx = self._full_idx

    def next_batch(self, num_tokens_local: int, max_seq_len: int):
        self._maybe_switch()
        n = len(self.bos_idx)
        starts = [[] for _ in range(self.world_size)]
        ends = [[] for _ in range(self.world_size)]

        idx = self.i
        for r in range(self.world_size):
            cur_len = 0
            while cur_len <= num_tokens_local:
                if idx >= n:
                    raise StopIteration(f"Insufficient BOS ahead; hit tail of shard.")
                cur = self.bos_idx[idx]
                starts[r].append(cur)
                end = min(self.bos_idx[idx + 1] if idx + 1 < n else self.size,
                          cur + max_seq_len,
                          cur + num_tokens_local - cur_len + 1)
                ends[r].append(end)
                cur_len += end - cur
                idx += 1

            assert cur_len == num_tokens_local + 1
        self.i = idx
        return starts, ends

    @staticmethod
    def load_async(file: Path, world_size: int = 1):
        """Returns getter function for async shard loading"""
        result = {}
        ready = threading.Event()
        def load():
            tokens = _load_data_shard(file)
            result['shard'] = Shard(tokens, world_size)
            ready.set()
        thread = threading.Thread(target=load)
        thread.start()
        def get():
            ready.wait()
            thread.join()
            return result['shard']
        return get

def distributed_data_generator(filename_pattern: str, num_tokens: int, max_seq_len: int, grad_accum_steps: int = 1, align_to_bos: bool = True):
    # align_to_bos: each sequence begins with Beginning of Sequence token, sequences truncated to max_seq_len
    rank = dist.get_rank() if dist.is_initialized() else 0
    world_size = dist.get_world_size() if dist.is_initialized() else 1
    assert num_tokens % (world_size * grad_accum_steps) == 0, "Batch size must be divisible by world size"
    num_tokens = num_tokens // grad_accum_steps

    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    if not files:
        raise FileNotFoundError(f"No files found for pattern: {filename_pattern}")

    file_iter = iter(files)  # Use itertools.cycle(files) for multi-epoch training
    tokens = _load_data_shard(next(file_iter))
    if align_to_bos:
        shard = Shard(tokens, world_size)
        next_shard_getter = Shard.load_async(next(file_iter), world_size)
    else:
        pos = 0  # for unaligned case

    while True:
        num_tokens_local = num_tokens // world_size
        max_num_docs = next_multiple_of_n(num_tokens_local // 300, n=128)  # median doc length is ~400

        if align_to_bos:
            try:
                seq_starts, seq_ends = shard.next_batch(num_tokens_local, max_seq_len)
                start_idxs, end_idxs = torch.tensor(seq_starts[rank]), torch.tensor(seq_ends[rank])
            except StopIteration:
                # This shard is exhausted, load the next one in the next loop iteration.
                shard = next_shard_getter()
                tokens = shard.tokens
                try:
                    next_shard_getter = Shard.load_async(next(file_iter), world_size)
                except StopIteration:
                    next_shard_getter = None  # no more shards to preload
                continue

            buf = torch.cat([tokens[i:j] for i, j in zip(start_idxs, end_idxs)])
            _inputs = buf[:-1]
            _targets = buf[1:]
            end_idxs[-1] -= 1  # last document was too long to account for _targets offset
            cum_lengths = (end_idxs - start_idxs).cumsum(0)

        else:
            if pos + num_tokens + 1 >= len(tokens):  # should not occur for val data
                tokens, pos = _load_data_shard(next(file_iter)), 0

            pos_local = pos + rank * num_tokens_local
            buf = tokens[pos_local: pos_local + num_tokens_local + 1]
            _inputs = buf[:-1].view(num_tokens_local, )
            _targets = buf[1:].view(num_tokens_local, )

            cum_lengths = torch.nonzero(_inputs == BOS_ID)[:, 0]
            pos += num_tokens


        _cum_lengths = torch.full((max_num_docs,), num_tokens_local)
        _cum_lengths[0] = 0
        _cum_lengths[1:len(cum_lengths) + 1] = cum_lengths

        # Cast to int32 on CPU before transfer to avoid dtype conversion during .to()
        _inputs = _inputs.to(dtype=torch.int32)
        _targets = _targets.to(dtype=torch.int64)
        _cum_lengths = _cum_lengths.to(dtype=torch.int32)

        new_params = yield (
            _inputs.to(device="cuda", non_blocking=True),
            _targets.to(device="cuda", non_blocking=True),
            _cum_lengths.to(device="cuda", non_blocking=True),
        )

        if new_params is not None:
            # makes it possible for generator to receive new (num_tokens, max_seq_len, grad_accum_steps) via .send()
            new_num_tokens, new_max_seq_len, new_grad_accum_steps = new_params
            assert new_num_tokens % (world_size * new_grad_accum_steps) == 0, "Num tokens must be divisible by world size"
            num_tokens = new_num_tokens // new_grad_accum_steps
            max_seq_len = new_max_seq_len

# -----------------------------------------------------------------------------
# Training Management

@dataclass
class Hyperparameters:
    # data
    data_path = os.environ.get("DATA_PATH", ".")
    train_files: str = os.path.join(data_path, "data/fineweb10B/fineweb_train_*.bin") # input .bin to train on
    val_files: str = os.path.join(data_path, "data/fineweb10B/fineweb_val_*.bin") # input .bin to eval validation loss on
    val_tokens: int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # batch sizes
    train_max_seq_len: int = 128 * 16
    val_batch_size: int = 4 * 64 * 1024 * 8
    # schedule
    num_scheduled_iterations: int = 1470  # number of steps to complete lr and ws schedule
    num_extension_iterations: int = 40  # number of steps to continue training at final lr and ws
    # evaluation and logging
    run_id: str = f"{uuid.uuid4()}"
    val_loss_every: int = 250  # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint: bool = False
    # bigram hash embedding
    bigram_vocab_size: int = 50304 * 5

args = Hyperparameters()

@dataclass
class TrainingStage:
    lr_mul: float
    batch_size: int
    window_sizes: tuple[int, int]  # (short, long) in block units
    mtp_weights_start: list[float]
    mtp_weights_end: list[float]
    duration: float = None

class TrainingSchedule:
    """
    Training schedule initialized via TRAINING_STAGES
        1. Multi Token Prediction schedule of [1, 0.5, 0.25->0] -> [1, 0.5->0] -> [1] @varunneal
        2. Sliding Attention window schedule of [1,3] -> [3,7] -> [5,11] -> [6,13]
        3. YaRN updates to RoPE on window changes
        4. Split embed and lm head at 2/3 of training
        5. Batch size schedule of 8 -> 16 -> 24
        6. Post training extension of long windows from 13 to 20
    """

    def __init__(self, stages: list[TrainingStage], scheduled_iterations: int, extension_iterations: int,
                 cooldown_frac: float = 0.5, split_embed_stage: int = 2, ws_post_yarn_ext: int = 20):
        self.stages = stages
        self.scheduled_iterations = scheduled_iterations
        self.cooldown_frac = cooldown_frac
        # increase final validation ws, used for YaRN extension and short window size @classiclarryd
        self.ws_post_yarn_ext = ws_post_yarn_ext

        self.total_steps = self.scheduled_iterations + extension_iterations

        # Build stage boundaries (last is extension stage)
        ends = [0] + [round(c * scheduled_iterations) for c in accumulate(s.duration for s in stages[:-1])] + [self.total_steps]
        assert self.scheduled_iterations == ends[-2]
        self.boundaries = list(pairwise(ends))

        # Split embed at specified stage (ensure odd step for Adam)
        self.split_step = self.boundaries[split_embed_stage][0] | 1

        # Precompute MTP weights for all steps
        self.mtp_weights = []
        for step in range(self.total_steps + 1):
            stage, t = self.lookup(step)
            w = [a + (b - a) * t for a, b in zip(stage.mtp_weights_start, stage.mtp_weights_end)]
            self.mtp_weights.append(torch.tensor(w, device=device))

    def lookup(self, step: int) -> tuple[TrainingStage, float]:
        # Returns stage and % of the way through that stage
        for i, (start, end) in enumerate(self.boundaries):
            if step < end:
                t = (step - start) / (end - start)
                return self.stages[i], t
        return self.stages[-1], 1.0

    def get_lr(self, step: int) -> float:
        # learning rate schedule: tied to batch size schedule, with cooldown at the end
        stage, _ = self.lookup(step)
        lr = stage.lr_mul
        cd_start = int(self.scheduled_iterations * (1 - self.cooldown_frac))
        if step >= cd_start:
            t = min(1.0, (step - cd_start) / (self.scheduled_iterations - cd_start))
            lr = lr * (1 - t) + 0.1 * t
        return lr

# window_sizes are in units of `block_size` tokens (defined in TrainingManager)
TRAINING_STAGES = [
    TrainingStage(duration=1/3, batch_size=8 * 2048 * 8, window_sizes=(1, 3), lr_mul=1.0,
                  mtp_weights_start=[1.0, 0.5, 0.25], mtp_weights_end=[1.0, 0.5, 0.0]),
    TrainingStage(duration=1/3, batch_size=16 * 2048 * 8, window_sizes=(3, 7), lr_mul=1.52,  # (16/8)**0.6
                  mtp_weights_start=[1.0, 0.5], mtp_weights_end=[1.0, 0.0]),
    TrainingStage(duration=1/3, batch_size=24 * 2048 * 8, window_sizes=(5, 11), lr_mul=1.73,  # (24/8)**0.5
                  mtp_weights_start=[1.0], mtp_weights_end=[1.0]),
    # extension stage
    TrainingStage(batch_size=24 * 2048 * 8, window_sizes=(6, 13), lr_mul=1.0,  # lr_mul is not used
                  mtp_weights_start=[1.0], mtp_weights_end=[1.0]),
]

training_schedule = TrainingSchedule(TRAINING_STAGES, args.num_scheduled_iterations, args.num_extension_iterations, cooldown_frac=0.60)

def get_muon_momentum(step: int, muon_warmup_steps=300, muon_cooldown_steps=50, momentum_min=0.85, momentum_max=0.95):
    # warmup phase: linearly increase momentum from min to max
    # cooldown phase: linearly decrease momentum from max to min
    momentum_cd_start = training_schedule.total_steps - muon_cooldown_steps
    if step < muon_warmup_steps:
        frac = step / muon_warmup_steps
        momentum = momentum_min + frac * (momentum_max - momentum_min)
    elif step > momentum_cd_start:
        frac = (step - momentum_cd_start) / muon_cooldown_steps
        momentum = momentum_max - frac * (momentum_max - momentum_min)
    else:
        momentum = momentum_max
    return momentum

class TrainingManager():
    """
    Manages the NorMuonAndAdam for all parameters with explicit ordering.
        1. Scalars are given higher momentum terms to smooth learning @ChrisJMcCormick
        2. Adam optimizers are only stepped on odd steps @classiclarryd
        3. Explicit scatter_order and work_order for communication scheduling (no backward hooks)
        4. Muon has a linear momentum warmup and cooldown schedule
        5. Learning rates follow a linear decay schedule
        6. Embed is tied to lm_head until split step (2/3 of training), then untied @classiclarryd
    """
    def __init__(self, model):
        self.model = model
        self.block_size = 128

        # - Ordering dictates when to launch reduce/reduce_scatter operations
        # - "sharded" parameters use reduce_scatter/all_gather and "replicated" ones use all_reduce
        # - lr_mul and wd_mul are per-parameter learning rate and weight decay multipliers
        self.param_table = {
            "attn":           {"optim": "normuon", "comms": "sharded",    "adam_betas": None},
            "mlp":            {"optim": "normuon", "comms": "sharded",    "adam_betas": None},
            "scalars":        {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99], "lr_mul": 5.0,  "wd_mul": 0.0},
            "value_embed":    {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.75, 0.95], "lr_mul": 75.,  "wd_mul": 5.0},
            "bigram_embed":   {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.75, 0.95], "lr_mul": 75.,  "wd_mul": 5.0},
            "smear_gate":     {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99], "lr_mul": 0.01, "wd_mul": 0.0},
            "skip_gate":      {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99], "lr_mul": 0.05, "wd_mul": 0.0},
            "attn_gate_bank": {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99]},
            "ve_gate_bank":   {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99]},
            "w_post":          {"optim": "adam",    "comms": "replicated",    "adam_betas": [0.9,  0.95], "lr_mul": 1.0,  "wd_mul": 0.0},
            "x0_lambda":       {"optim": "adam",    "comms": "replicated",    "adam_betas": [0.9,  0.95], "lr_mul": 1.0,  "wd_mul": 0.0},
            "bigram_lambda":   {"optim": "adam",    "comms": "replicated",    "adam_betas": [0.9,  0.95], "lr_mul": 1.0,  "wd_mul": 0.0},
            "resid_lambda":  {"optim": "adam",    "comms": "replicated",    "adam_betas": [0.9,  0.95], "lr_mul": 5.0,  "wd_mul": 0.0},
            "lm_head":           {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.5,  0.95], "wd_mul": 150.},
            "embed":          {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.5,  0.95], "wd_mul": 150.},
        }

        # - Process smaller/faster params first while large reduces complete
        # - lm_head must complete before embed sync (when tied)
        self.work_order = [
            "scalars", "smear_gate", "skip_gate", "attn_gate_bank", "ve_gate_bank", "w_post", "x0_lambda", "bigram_lambda", "resid_lambda",  # Small, fast
            "value_embed", "bigram_embed",  # Medium
            "lm_head", "embed",   # lm_head must complete before embed sync (when tied)
            "attn", "mlp",        # Large, polar express - process last to maximize overlap
        ]

        adam_defaults = dict(
            lr=0.008,
            eps=1e-10,
            weight_decay=0.005,
        )

        normuon_defaults = dict(
            lr=0.023,
            momentum=0.95,
            beta2=0.95,
            weight_decay=1.2,
        )

        self.optimizer = NorMuonAndAdam(
            model.named_parameters(),
            param_table=self.param_table,
            scatter_order=list(self.param_table.keys()),  # Dict order defines scatter priority
            work_order=self.work_order,
            adam_defaults=adam_defaults,
            normuon_defaults=normuon_defaults,
        )

        # Split embed from lm_head at 2/3 of training (on an odd step so Adam updates)
        self.split_step = training_schedule.split_step

        self.reset()

    def apply_final_ws_ext(self):
        self.ws_long = training_schedule.ws_post_yarn_ext

    def get_forward_args(self):
        return ForwardScheduleConfig(
            mtp_weights = self.mtp_weights,
            ws_short = self.ws_short * self.block_size,
            ws_long = self.ws_long * self.block_size
        )

    def _is_adam_step(self, step: int):
        """Adam params are only updated on odd steps."""
        return step % 2 == 1

    def get_transition_steps(self):
        return [start for start, _ in training_schedule.boundaries[1:]]

    def advance_schedule(self, step: int):
        stage, _ = training_schedule.lookup(step)
        self.ws_short, new_ws_long = stage.window_sizes
        if new_ws_long != self.ws_long:
            self.model.yarn.apply(self.ws_long * self.block_size, new_ws_long * self.block_size)
            self.model.yarn_paired_head.apply(self.ws_long * self.block_size, new_ws_long * self.block_size)

        new_batch_size = stage.batch_size
        if new_batch_size != self.batch_size:
            self.train_loader_send_args = (new_batch_size, args.train_max_seq_len, grad_accum_steps)
            self.batch_size = new_batch_size
        else:
            self.train_loader_send_args = None

        self.ws_long = new_ws_long
        self.mtp_weights = training_schedule.mtp_weights[step]

    def step_optimizers(self, step: int):
        step_lr = training_schedule.get_lr(step)
        muon_momentum = get_muon_momentum(step)
        do_adam = self._is_adam_step(step)

        # Update learning rates and momentum for all params
        for param, p_cfg in self.optimizer.param_cfgs.items():
            p_cfg.lr = p_cfg.initial_lr * step_lr
            if p_cfg.optim == "normuon":
                p_cfg.momentum = muon_momentum

        # Step optimizer with do_adam flag
        self.optimizer.step(do_adam=do_adam)

        # At split step: copy lm_head optimizer state to embed and mark as split
        if step == self.split_step:
            self.optimizer.copy_lm_state_to_embed()

    def reset(self, state=None):
        if state is not None:
            self.optimizer.load_state_dict(state)

        # Reset NorMuon momentum buffers and split_embed state
        self.optimizer.reset()

        stage, _ = training_schedule.lookup(0)
        self.ws_short, self.ws_long = stage.window_sizes
        self.batch_size = stage.batch_size
        self.model.yarn.reset()
        self.model.yarn_paired_head.reset()

    def get_state(self):
        return copy.deepcopy(self.optimizer.state_dict())

# -----------------------------------------------------------------------------
# int main

# begin logging
logfile = None
if master_process:
    run_id = args.run_id
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
print0(f"Running Triton version {triton.__version__}")

def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

model: nn.Module = GPT(
    vocab_size=50257,
    num_layers=11,
    num_heads=6,
    head_dim=128,
    model_dim=768,
    max_seq_len=args.val_batch_size // (grad_accum_steps * world_size)
).cuda()
for m in model.modules():
    if isinstance(m, (nn.Embedding, nn.Linear)):
        m.weight.data = m.weight.data.bfloat16()
model.attn_gate_bank.data = model.attn_gate_bank.data.bfloat16()
model.ve_gate_bank.data = model.ve_gate_bank.data.bfloat16()
model.attn_bank.data = model.attn_bank.data.bfloat16()
model.mlp_bank.data = model.mlp_bank.data.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

model: nn.Module = torch.compile(model, dynamic=False, fullgraph=True)
training_manager = TrainingManager(model)

########################################
#            Warmup kernels            #
########################################
print0("Compiling model and warming up kernels (~7 minutes on first execution)", console=True)
# Warmup the training kernels, then re-initialize the state so we aren't cheating
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizer=training_manager.get_state()) # save the initial state
train_loader = distributed_data_generator(args.train_files, TRAINING_STAGES[0].batch_size, args.train_max_seq_len, grad_accum_steps=grad_accum_steps)
val_loader = distributed_data_generator(args.val_files, args.val_batch_size, -1, grad_accum_steps=grad_accum_steps, align_to_bos=False)

transition_steps = training_manager.get_transition_steps()
# first few steps plus transitions
warmup_steps = sorted({0, 1, 2} | set(s + offset for s in transition_steps for offset in [-1, 0, 1] if s + offset >= 0))
print0(f"Sampling steps {warmup_steps} for warmup", console=True)
for step in warmup_steps:
    training_manager.advance_schedule(step)
    model.eval()
    with torch.no_grad():
        inputs, targets, cum_seqlens = next(val_loader)
        model(inputs, targets, cum_seqlens, training_manager.get_forward_args())
    model.train()
    for idx in range(grad_accum_steps):
        send_args = training_manager.train_loader_send_args
        inputs, targets, cum_seqlens = train_loader.send(send_args)
        (model(inputs, targets, cum_seqlens, training_manager.get_forward_args()) * grad_scale).backward()
    training_manager.step_optimizers(step)
print0("Resetting Model", console=True)
model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
training_manager.reset(initial_state["optimizer"])
del val_loader, train_loader, initial_state
model.train()

########################################
#        Training and validation       #
########################################
train_loader = distributed_data_generator(args.train_files, TRAINING_STAGES[0].batch_size, args.train_max_seq_len, grad_accum_steps=grad_accum_steps)

gc.collect()

training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = training_schedule.total_steps
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    training_manager.advance_schedule(step)
    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        if last_step:
            training_manager.apply_final_ws_ext()
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        assert args.val_tokens % args.val_batch_size == 0
        val_steps = grad_accum_steps * args.val_tokens // args.val_batch_size
        val_loader = distributed_data_generator(args.val_files, args.val_batch_size, -1, grad_accum_steps=grad_accum_steps, align_to_bos=False)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets, cum_seqlens = next(val_loader)
                val_loss += model(inputs, targets, cum_seqlens, training_manager.get_forward_args())
        val_loss /= val_steps
        del val_loader
        dist.reduce(val_loss, 0, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizer=training_manager.get_state())
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    for idx in range(grad_accum_steps):
        inputs, targets, cum_seqlens = train_loader.send(training_manager.train_loader_send_args)
        (model(inputs, targets, cum_seqlens, training_manager.get_forward_args()) * grad_scale).backward()
    training_manager.step_optimizers(step)

    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()


----------------------------------------
# triton_kernels.py
----------------------------------------

import torch
import triton
import triton.language as tl
from triton.tools.tensor_descriptor import TensorDescriptor

# -----------------------------------------------------------------------------
# Triton kernel for symmetric matrix multiplication by @byronxu99

@triton.jit
def _pid_to_block(
    pid,
    M,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
):
    # Split output matrix into blocks of size (BLOCK_SIZE_M, BLOCK_SIZE_N)
    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(M, BLOCK_SIZE_N)

    # Map PID to a single matrix in batch
    batch_idx = pid // (num_pid_m * num_pid_n)
    pid = pid % (num_pid_m * num_pid_n)

    # Map PID to 2D grid of blocks
    pid_m = pid // num_pid_n
    pid_n = pid % num_pid_n
    pid_m, pid_n = tl.swizzle2d(pid_m, pid_n, num_pid_m, num_pid_n, GROUP_SIZE_M)

    m_idx = pid_m * BLOCK_SIZE_M
    n_idx = pid_n * BLOCK_SIZE_N
    return batch_idx, m_idx, n_idx

@triton.jit
def XXT_kernel(
    A_ptr, C_ptr,
    M, K,
    a_stride_b, a_stride_r, a_stride_c,
    c_stride_b, c_stride_r, c_stride_c,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
    LOWER_UPPER: tl.constexpr,
):
    pid = tl.program_id(axis=0)
    batch_idx, m_idx, n_idx = _pid_to_block(
        pid, M, BLOCK_SIZE_M, BLOCK_SIZE_N, GROUP_SIZE_M
    )

    # Skip blocks that don't need to be computed
    skip_block_below_diag = (LOWER_UPPER == 0) and (n_idx + BLOCK_SIZE_N <= m_idx)
    skip_block_above_diag = (LOWER_UPPER != 0) and (m_idx + BLOCK_SIZE_M <= n_idx)
    if skip_block_below_diag or skip_block_above_diag:
        return

    # Index into one matrix of batch
    A_ptr += batch_idx * a_stride_b
    C_ptr += batch_idx * c_stride_b

    # Create pointer arrays for A and A.T
    offs_m = (m_idx + tl.arange(0, BLOCK_SIZE_M)) % M
    offs_n = (n_idx + tl.arange(0, BLOCK_SIZE_N)) % M
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    a_ptrs = A_ptr + (offs_m[:, None] * a_stride_r + offs_k[None, :] * a_stride_c)
    at_ptrs = A_ptr + (offs_k[:, None] * a_stride_c + offs_n[None, :] * a_stride_r)

    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)

    # Accumulate over blocks of K
    for k in tl.range(0, tl.cdiv(K, BLOCK_SIZE_K)):
        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)
        at = tl.load(at_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)
        accumulator = tl.dot(a, at, accumulator)
        a_ptrs += BLOCK_SIZE_K * a_stride_c
        at_ptrs += BLOCK_SIZE_K * a_stride_c

    out_dtype = C_ptr.dtype.element_ty
    output = accumulator.to(out_dtype)

    # Store block of C
    offs_cm = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_cn = n_idx + tl.arange(0, BLOCK_SIZE_N)
    c_ptrs = C_ptr + (offs_cm[:, None] * c_stride_r + offs_cn[None, :] * c_stride_c)
    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < M)
    tl.store(c_ptrs, output, mask=c_mask)

    # Store block of C mirrored across the diagonal
    c_ptrs_t = C_ptr + (offs_cn[:, None] * c_stride_r + offs_cm[None, :] * c_stride_c)
    c_mask_t = (offs_cn[:, None] < M) & (offs_cm[None, :] < M)
    tl.store(c_ptrs_t, output.T, mask=c_mask_t)

def XXT(A: torch.Tensor, out: torch.Tensor):
    """
    Launch Triton kernel to compute C = A @ A.T
    """
    assert A.ndim == 2 or A.ndim == 3
    M, K = A.shape[-2:]
    assert out.size(-2) == M, "Output matrix has incorrect shape"
    assert out.size(-1) == M, "Output matrix has incorrect shape"

    batch_size = A.size(0) if A.ndim == 3 else 1
    input_batch_stride = A.stride(0) if A.ndim == 3 else 0
    output_batch_stride = out.stride(0) if out.ndim == 3 else 0

    # Hardcoded configs based on H100 autotuning
    if K == 768:
        BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 128, 128, 64
        num_stages, num_warps = 4, 4
    else:
        BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 64, 128, 128
        num_stages, num_warps = 4, 4

    grid = (batch_size * triton.cdiv(M, BLOCK_SIZE_M) * triton.cdiv(M, BLOCK_SIZE_N),)
    XXT_kernel[grid](
        A_ptr=A,
        C_ptr=out,
        M=M,
        K=K,
        a_stride_b=input_batch_stride,
        a_stride_r=A.stride(-2),
        a_stride_c=A.stride(-1),
        c_stride_b=output_batch_stride,
        c_stride_r=out.stride(-2),
        c_stride_c=out.stride(-1),
        BLOCK_SIZE_M=BLOCK_SIZE_M,
        BLOCK_SIZE_N=BLOCK_SIZE_N,
        BLOCK_SIZE_K=BLOCK_SIZE_K,
        GROUP_SIZE_M=8,
        LOWER_UPPER=1,
        num_stages=num_stages,
        num_warps=num_warps,
    )
    return out

@triton.jit
def ba_plus_cAA_kernel(
    A_ptr, C_ptr,
    M,
    a_stride_b, a_stride_r, a_stride_c,
    c_stride_b, c_stride_r, c_stride_c,
    alpha, beta,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
    LOWER_UPPER: tl.constexpr,
):
    # This is mostly duplicated from XXT_kernel, but also loads and adds a block of A
    # Performance is slightly slower than XXT_kernel, so we use two separate kernels
    pid = tl.program_id(axis=0)
    batch_idx, m_idx, n_idx = _pid_to_block(
        pid, M, BLOCK_SIZE_M, BLOCK_SIZE_N, GROUP_SIZE_M
    )

    # Skip blocks that don't need to be computed
    skip_block_below_diag = (LOWER_UPPER == 0) and (n_idx + BLOCK_SIZE_N <= m_idx)
    skip_block_above_diag = (LOWER_UPPER != 0) and (m_idx + BLOCK_SIZE_M <= n_idx)
    if skip_block_below_diag or skip_block_above_diag:
        return

    # Index into one matrix of batch
    A_ptr += batch_idx * a_stride_b
    C_ptr += batch_idx * c_stride_b

    # Create pointer arrays for A and A.T
    offs_m = (m_idx + tl.arange(0, BLOCK_SIZE_M)) % M
    offs_n = (n_idx + tl.arange(0, BLOCK_SIZE_N)) % M
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    a_ptrs = A_ptr + (offs_m[:, None] * a_stride_r + offs_k[None, :] * a_stride_c)
    at_ptrs = A_ptr + (offs_k[:, None] * a_stride_c + offs_n[None, :] * a_stride_r)

    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)

    # Accumulate over blocks of K
    for k in tl.range(0, tl.cdiv(M, BLOCK_SIZE_K)):
        a = tl.load(a_ptrs, mask=offs_k[None, :] < M - k * BLOCK_SIZE_K, other=0.0)
        at = tl.load(at_ptrs, mask=offs_k[:, None] < M - k * BLOCK_SIZE_K, other=0.0)
        accumulator = tl.dot(a, at, accumulator)
        a_ptrs += BLOCK_SIZE_K * a_stride_c
        at_ptrs += BLOCK_SIZE_K * a_stride_c

    # Load block of A to add (corresponds to the current block of C)
    offs_am = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_an = n_idx + tl.arange(0, BLOCK_SIZE_N)
    a_add_ptrs = A_ptr + (offs_am[:, None] * a_stride_r + offs_an[None, :] * a_stride_c)
    a_add_mask = (offs_am[:, None] < M) & (offs_an[None, :] < M)
    a_add = tl.load(a_add_ptrs, mask=a_add_mask, other=0.0).to(tl.float32)

    # Apply alpha and beta
    accumulator *= alpha
    accumulator += a_add * beta

    out_dtype = C_ptr.dtype.element_ty
    output = accumulator.to(out_dtype)

    # Store block of C
    offs_cm = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_cn = n_idx + tl.arange(0, BLOCK_SIZE_N)
    c_ptrs = C_ptr + (offs_cm[:, None] * c_stride_r + offs_cn[None, :] * c_stride_c)
    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < M)
    tl.store(c_ptrs, output, mask=c_mask)

    # Store block of C mirrored across the diagonal
    c_ptrs_t = C_ptr + (offs_cn[:, None] * c_stride_r + offs_cm[None, :] * c_stride_c)
    c_mask_t = (offs_cn[:, None] < M) & (offs_cm[None, :] < M)
    tl.store(c_ptrs_t, output.T, mask=c_mask_t)

def ba_plus_cAA(A: torch.Tensor, alpha: float, beta: float, out: torch.Tensor):
    """
    Launch Triton kernel to compute C = alpha * A @ A.T + beta * A
    """
    assert A.ndim == 2 or A.ndim == 3
    M, K = A.shape[-2:]
    assert M == K, "Input matrix must be square"
    assert out.size(-2) == M
    assert out.size(-1) == M

    batch_size = A.size(0) if A.ndim == 3 else 1
    input_batch_stride = A.stride(0) if A.ndim == 3 else 0
    output_batch_stride = out.stride(0) if out.ndim == 3 else 0

    # Hardcoded config based on H100 autotuning (M=768)
    BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 128, 128, 64
    num_stages, num_warps = 4, 4

    grid = (batch_size * triton.cdiv(M, BLOCK_SIZE_M) * triton.cdiv(M, BLOCK_SIZE_N),)
    ba_plus_cAA_kernel[grid](
        A_ptr=A,
        C_ptr=out,
        M=M,
        a_stride_b=input_batch_stride,
        a_stride_r=A.stride(-2),
        a_stride_c=A.stride(-1),
        c_stride_b=output_batch_stride,
        c_stride_r=out.stride(-2),
        c_stride_c=out.stride(-1),
        alpha=alpha,
        beta=beta,
        BLOCK_SIZE_M=BLOCK_SIZE_M,
        BLOCK_SIZE_N=BLOCK_SIZE_N,
        BLOCK_SIZE_K=BLOCK_SIZE_K,
        GROUP_SIZE_M=8,
        LOWER_UPPER=1,
        num_stages=num_stages,
        num_warps=num_warps,
    )
    return out

# -----------------------------------------------------------------------------
# Triton kernel for MLP: relu(x @ W1.T)^2, by @andrewbriand, @jrauvola

@triton.jit
def linear_relu_square_kernel(a_desc, b_desc, c_desc, aux_desc,
                                 M, N, K,
                                 BLOCK_SIZE_M: tl.constexpr,
                                 BLOCK_SIZE_N: tl.constexpr,
                                 BLOCK_SIZE_K: tl.constexpr,
                                 GROUP_SIZE_M: tl.constexpr,
                                 NUM_SMS: tl.constexpr,
                                 FORWARD: tl.constexpr,
                                 ):
    dtype = tl.bfloat16
    start_pid = tl.program_id(axis=0)
    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
    k_tiles = tl.cdiv(K, BLOCK_SIZE_K)
    num_tiles = num_pid_m * num_pid_n

    tile_id_c = start_pid - NUM_SMS
    num_pid_in_group = GROUP_SIZE_M * num_pid_n

    for tile_id in tl.range(start_pid, num_tiles, NUM_SMS, flatten=True):
        pid_m = tile_id // num_pid_n
        pid_n = tile_id % num_pid_n
        offs_am = pid_m * BLOCK_SIZE_M
        offs_bn = pid_n * BLOCK_SIZE_N

        accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
        for ki in range(k_tiles):
            offs_k = ki * BLOCK_SIZE_K
            a = a_desc.load([offs_am, offs_k])
            b = b_desc.load([offs_bn, offs_k])
            accumulator = tl.dot(a, b.T, accumulator)

        tile_id_c += NUM_SMS
        pid_m = tile_id // num_pid_n
        pid_n = tile_id % num_pid_n
        offs_am_c = pid_m * BLOCK_SIZE_M
        offs_bn_c = pid_n * BLOCK_SIZE_N

        acc = tl.reshape(accumulator, (BLOCK_SIZE_M, 2, BLOCK_SIZE_N // 2))
        acc = tl.permute(acc, (0, 2, 1))
        acc0, acc1 = tl.split(acc)

        c0 = acc0.to(dtype)
        if not FORWARD:
            c0_pre = aux_desc.load([offs_am_c, offs_bn_c])
            c0 = 2 * c0 * tl.where(c0_pre > 0, c0_pre, 0)

        c_desc.store([offs_am_c, offs_bn_c], c0)

        if FORWARD:
            c0_post = tl.maximum(c0, 0)
            c0_post = c0_post * c0_post
            aux_desc.store([offs_am_c, offs_bn_c], c0_post)

        c1 = acc1.to(dtype)
        if not FORWARD:
            c1_pre = aux_desc.load([offs_am_c, offs_bn_c + BLOCK_SIZE_N // 2])
            c1 = 2 * c1 * tl.where(c1_pre > 0, c1_pre, 0)

        c_desc.store([offs_am_c, offs_bn_c + BLOCK_SIZE_N // 2], c1)

        if FORWARD:
            c1_post = tl.maximum(c1, 0)
            c1_post = c1_post * c1_post
            aux_desc.store([offs_am_c, offs_bn_c + BLOCK_SIZE_N // 2], c1_post)


def linear_relu_square(a, b, aux=None):
    M, K = a.shape
    N, K = b.shape
    dtype = a.dtype

    c = torch.empty((M, N), device=a.device, dtype=dtype)

    FORWARD = False
    if aux is None:
        FORWARD = True
        aux = torch.empty((M, N), device=a.device, dtype=dtype)

    NUM_SMS = torch.cuda.get_device_properties("cuda").multi_processor_count

    BLOCK_SIZE_M = 128
    BLOCK_SIZE_N = 256
    BLOCK_SIZE_K = 64
    num_stages = 4 if FORWARD else 3
    num_warps = 8

    a_desc = TensorDescriptor.from_tensor(a, [BLOCK_SIZE_M, BLOCK_SIZE_K])
    b_desc = TensorDescriptor.from_tensor(b, [BLOCK_SIZE_N, BLOCK_SIZE_K])
    c_desc = TensorDescriptor.from_tensor(c, [BLOCK_SIZE_M, BLOCK_SIZE_N // 2])
    aux_desc = TensorDescriptor.from_tensor(aux, [BLOCK_SIZE_M, BLOCK_SIZE_N // 2])

    def grid(META):
        return (min(
            NUM_SMS,
            triton.cdiv(M, BLOCK_SIZE_M) * triton.cdiv(N, BLOCK_SIZE_N),
        ), )

    linear_relu_square_kernel[grid](
        a_desc, b_desc, c_desc, aux_desc,
        M, N, K,
        BLOCK_SIZE_M=BLOCK_SIZE_M,
        BLOCK_SIZE_N=BLOCK_SIZE_N,
        BLOCK_SIZE_K=BLOCK_SIZE_K,
        GROUP_SIZE_M=1,
        NUM_SMS=NUM_SMS,
        FORWARD=FORWARD,
        num_stages=num_stages,
        num_warps=num_warps
    )

    if FORWARD:
        return c, aux
    else:
        return c

class FusedLinearReLUSquareFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, W1, W2):
        pre, post = linear_relu_square(x.view((-1, x.shape[-1])), W1)
        x3 = post @ W2
        ctx.save_for_backward(x, W1, W2, pre, post)
        return x3.view(x.shape)

    @staticmethod
    def backward(ctx, grad_output):
        x, W1, W2, pre, post = ctx.saved_tensors
        dW2 = post.T @ grad_output
        dpre = linear_relu_square(grad_output.view((-1, grad_output.shape[-1])), W2, aux=pre)
        dW1 = dpre.T @ x
        dx = dpre @ W1
        return dx.view(x.shape), dW1, dW2

# -----------------------------------------------------------------------------
# Fused Softcapped Cross Entropy


@triton.jit
def fused_softcapped_entropy_fwd_kernel(
    logits_ptr, losses_ptr, lse_ptr, targets_ptr, mtp_weights_ptr,
    stride_logits_n, stride_logits_v,
    n_rows, n_cols, n_predict,
    A, B, C,
    BLOCK_SIZE: tl.constexpr
):
    row_idx = tl.program_id(0).to(tl.int64)
    logits_row_ptr = logits_ptr + row_idx * stride_logits_n

    max_val = -float('inf')
    sum_exp = 0.0

    for off in range(0, n_cols, BLOCK_SIZE):
        cols = off + tl.arange(0, BLOCK_SIZE)
        mask = cols < n_cols
        val = tl.load(logits_row_ptr + cols, mask=mask, other=-float('inf')).to(tl.float32)
        z = A * tl.sigmoid((val + B) / C)
        z = tl.where(mask, z, -float('inf'))
        curr_max = tl.max(z, axis=0)
        new_max = tl.maximum(max_val, curr_max)
        sum_exp = sum_exp * tl.exp(max_val - new_max) + tl.sum(tl.exp(z - new_max), axis=0)
        max_val = new_max

    lse = max_val + tl.log(sum_exp)
    tl.store(lse_ptr + row_idx, lse)

    total_loss = 0.0
    for k in range(n_predict):
        target_idx = row_idx + k
        if target_idx < n_rows:
            weight = tl.load(mtp_weights_ptr + k)
            if weight > 0:
                target = tl.load(targets_ptr + target_idx).to(tl.int32)
                if target >= 0 and target < n_cols:
                    val_target = tl.load(logits_row_ptr + target).to(tl.float32)
                    z_target = A * tl.sigmoid((val_target + B) / C)
                    total_loss += weight * (lse - z_target)

    tl.store(losses_ptr + row_idx, total_loss)

@triton.jit
def fused_softcapped_entropy_bwd_kernel(
    grad_input_ptr, grad_output_ptr, lse_ptr, logits_ptr, targets_ptr, mtp_weights_ptr,
    stride_logits_n, stride_logits_v, stride_grad_n, stride_grad_v,
    n_rows, n_cols, n_predict,
    A, B, C,
    grad_s,
    BLOCK_SIZE: tl.constexpr
):
    row_idx = tl.program_id(0).to(tl.int64)

    logits_row_ptr = logits_ptr + row_idx * stride_logits_n
    grad_row_ptr = grad_input_ptr + row_idx * stride_grad_n

    lse = tl.load(lse_ptr + row_idx)
    grad_loss = tl.load(grad_output_ptr + row_idx)

    S_w = 0.0
    for k in range(n_predict):
        if row_idx + k < n_rows:
            S_w += tl.load(mtp_weights_ptr + k)

    for off in range(0, n_cols, BLOCK_SIZE):
        cols = off + tl.arange(0, BLOCK_SIZE)
        mask = cols < n_cols
        val = tl.load(logits_row_ptr + cols, mask=mask, other=0.0).to(tl.float32)
        u = (val + B) / C
        sigmoid_u = tl.sigmoid(u)
        z = A * sigmoid_u
        p = tl.exp(z - lse)

        term1 = S_w * p
        term2 = tl.zeros([BLOCK_SIZE], dtype=tl.float32)
        for k in range(n_predict):
            if row_idx + k < n_rows:
                target = tl.load(targets_ptr + row_idx + k).to(tl.int32)
                weight = tl.load(mtp_weights_ptr + k)
                term2 += tl.where(cols == target, weight, 0.0)

        grad_z = grad_loss * (term1 - term2)
        dz_dx = (1.0 / C) * z * (1.0 - sigmoid_u)
        grad_x = grad_z * dz_dx
        grad_x = grad_x / grad_s
        grad_x = grad_x.to(tl.float8e5)
        tl.store(grad_row_ptr + cols, grad_x, mask=mask)

class FusedSoftcappedCrossEntropy(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, targets, mtp_weights, lm_head_weight, x_s, w_s, grad_s, A=23.0, B=5.0, C=7.5):

        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = lm_head_weight.div(w_s).to(torch.float8_e4m3fn)

        w_f8_col_major = w_f8.T.contiguous().T

        logits = torch._scaled_mm(
            x_f8,
            w_f8_col_major,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )

        n_rows, n_cols = logits.shape
        if mtp_weights is None:
             mtp_weights = torch.tensor([1.0], device=logits.device, dtype=torch.float32)
        n_predict = mtp_weights.shape[0]

        losses = torch.empty(n_rows, dtype=torch.float32, device=logits.device)
        lse = torch.empty(n_rows, dtype=torch.float32, device=logits.device)

        logits = logits.contiguous()
        targets = targets.contiguous()
        mtp_weights = mtp_weights.contiguous()

        grid = (n_rows,)
        fused_softcapped_entropy_fwd_kernel[grid](
            logits, losses, lse, targets, mtp_weights,
            logits.stride(0), logits.stride(1),
            n_rows, n_cols, n_predict,
            A, B, C,
            BLOCK_SIZE=1024,
            num_warps=2
        )

        ctx.save_for_backward(logits, targets, mtp_weights, lse, x, lm_head_weight, x_f8, w_f8)
        ctx.params = (A, B, C, x_s, w_s, grad_s)
        return losses

    @staticmethod
    def backward(ctx, grad_output):
        logits, targets, mtp_weights, lse, x, lm_head_weight, x_f8, w_f8 = ctx.saved_tensors
        A, B, C, x_s, w_s, grad_s = ctx.params
        n_rows, n_cols = logits.shape
        n_predict = mtp_weights.shape[0]

        grad_input = torch.empty((n_rows, n_cols), dtype=torch.float8_e5m2, device=logits.device)
        grad_output = grad_output.contiguous()

        grid = (n_rows,)
        fused_softcapped_entropy_bwd_kernel[grid](
            grad_input, grad_output, lse, logits, targets, mtp_weights,
            logits.stride(0), logits.stride(1), grad_input.stride(0), grad_input.stride(1),
            n_rows, n_cols, n_predict,
            A, B, C,
            grad_s,
            BLOCK_SIZE=1024,
            num_warps=2
        )

        x_scale = grad_input.new_tensor(x_s, dtype=torch.float32)
        w_scale = grad_input.new_tensor(w_s, dtype=torch.float32)
        grad_scale = grad_input.new_tensor(grad_s, dtype=torch.float32)

        grad_x = torch._scaled_mm(
            grad_input,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=grad_scale,
            scale_b=w_scale,
            use_fast_accum=False,
        )

        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_input.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_scale,
            scale_b=grad_scale,
            use_fast_accum=False,
        )

        return grad_x, None, None, grad_w, None, None, None

====================================================================================================
Running Python 3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:25:55) [GCC 14.3.0]
Running PyTorch 2.10.0+cu128 compiled for CUDA 12.8
Running Triton version 3.6.0
Wed Feb 11 23:22:41 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:04:00.0 Off |                    0 |
| N/A   42C    P0            123W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:05:00.0 Off |                    0 |
| N/A   37C    P0            116W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:0B:00.0 Off |                    0 |
| N/A   40C    P0            117W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:0C:00.0 Off |                    0 |
| N/A   36C    P0            117W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:84:00.0 Off |                    0 |
| N/A   40C    P0            118W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:85:00.0 Off |                    0 |
| N/A   37C    P0            117W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:8B:00.0 Off |                    0 |
| N/A   39C    P0            119W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   36C    P0            118W /  700W |    1521MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

====================================================================================================
Compiling model and warming up kernels (~7 minutes on first execution)
Sampling steps [0, 1, 2, 489, 490, 491, 979, 980, 981, 1469, 1470, 1471] for warmup
Resetting Model
step:0/1510 val_loss:10.8287 train_time:0ms step_avg:0.03ms
step:1/1510 train_time:64ms step_avg:64.26ms
step:2/1510 train_time:83ms step_avg:41.54ms
step:3/1510 train_time:102ms step_avg:33.93ms
step:4/1510 train_time:138ms step_avg:34.60ms
step:5/1510 train_time:168ms step_avg:33.59ms
step:6/1510 train_time:205ms step_avg:34.25ms
step:7/1510 train_time:235ms step_avg:33.60ms
step:8/1510 train_time:272ms step_avg:34.06ms
step:9/1510 train_time:303ms step_avg:33.63ms
step:10/1510 train_time:339ms step_avg:33.94ms
step:11/1510 train_time:369ms step_avg:33.57ms
step:12/1510 train_time:406ms step_avg:33.87ms
step:13/1510 train_time:437ms step_avg:33.60ms
step:14/1510 train_time:474ms step_avg:33.83ms
step:15/1510 train_time:504ms step_avg:33.59ms
step:16/1510 train_time:541ms step_avg:33.79ms
step:17/1510 train_time:571ms step_avg:33.58ms
step:18/1510 train_time:608ms step_avg:33.77ms
step:19/1510 train_time:638ms step_avg:33.59ms
step:20/1510 train_time:675ms step_avg:33.75ms
step:21/1510 train_time:705ms step_avg:33.59ms
step:22/1510 train_time:742ms step_avg:33.73ms
step:23/1510 train_time:772ms step_avg:33.57ms
step:24/1510 train_time:809ms step_avg:33.72ms
step:25/1510 train_time:840ms step_avg:33.59ms
step:26/1510 train_time:876ms step_avg:33.70ms
step:27/1510 train_time:906ms step_avg:33.57ms
step:28/1510 train_time:944ms step_avg:33.70ms
step:29/1510 train_time:974ms step_avg:33.59ms
step:30/1510 train_time:1011ms step_avg:33.71ms
step:31/1510 train_time:1042ms step_avg:33.62ms
step:32/1510 train_time:1079ms step_avg:33.72ms
step:33/1510 train_time:1109ms step_avg:33.61ms
step:34/1510 train_time:1146ms step_avg:33.72ms
step:35/1510 train_time:1177ms step_avg:33.63ms
step:36/1510 train_time:1214ms step_avg:33.72ms
step:37/1510 train_time:1244ms step_avg:33.62ms
step:38/1510 train_time:1281ms step_avg:33.72ms
step:39/1510 train_time:1312ms step_avg:33.63ms
step:40/1510 train_time:1348ms step_avg:33.71ms
step:41/1510 train_time:1379ms step_avg:33.64ms
step:42/1510 train_time:1416ms step_avg:33.71ms
step:43/1510 train_time:1446ms step_avg:33.63ms
step:44/1510 train_time:1483ms step_avg:33.71ms
step:45/1510 train_time:1514ms step_avg:33.64ms
step:46/1510 train_time:1551ms step_avg:33.71ms
step:47/1510 train_time:1581ms step_avg:33.65ms
step:48/1510 train_time:1618ms step_avg:33.71ms
step:49/1510 train_time:1648ms step_avg:33.64ms
step:50/1510 train_time:1685ms step_avg:33.71ms
step:51/1510 train_time:1716ms step_avg:33.64ms
step:52/1510 train_time:1753ms step_avg:33.71ms
step:53/1510 train_time:1783ms step_avg:33.65ms
step:54/1510 train_time:1820ms step_avg:33.70ms
step:55/1510 train_time:1850ms step_avg:33.64ms
step:56/1510 train_time:1887ms step_avg:33.70ms
step:57/1510 train_time:1918ms step_avg:33.64ms
step:58/1510 train_time:1954ms step_avg:33.70ms
step:59/1510 train_time:1985ms step_avg:33.64ms
step:60/1510 train_time:2022ms step_avg:33.70ms
step:61/1510 train_time:2052ms step_avg:33.64ms
step:62/1510 train_time:2089ms step_avg:33.69ms
step:63/1510 train_time:2120ms step_avg:33.65ms
step:64/1510 train_time:2157ms step_avg:33.70ms
step:65/1510 train_time:2187ms step_avg:33.65ms
step:66/1510 train_time:2224ms step_avg:33.70ms
step:67/1510 train_time:2254ms step_avg:33.65ms
step:68/1510 train_time:2291ms step_avg:33.70ms
step:69/1510 train_time:2322ms step_avg:33.65ms
step:70/1510 train_time:2359ms step_avg:33.69ms
step:71/1510 train_time:2389ms step_avg:33.65ms
step:72/1510 train_time:2426ms step_avg:33.69ms
step:73/1510 train_time:2457ms step_avg:33.65ms
step:74/1510 train_time:2494ms step_avg:33.70ms
step:75/1510 train_time:2524ms step_avg:33.66ms
step:76/1510 train_time:2561ms step_avg:33.70ms
step:77/1510 train_time:2591ms step_avg:33.66ms
step:78/1510 train_time:2629ms step_avg:33.70ms
step:79/1510 train_time:2659ms step_avg:33.66ms
step:80/1510 train_time:2696ms step_avg:33.71ms
step:81/1510 train_time:2727ms step_avg:33.67ms
step:82/1510 train_time:2764ms step_avg:33.71ms
step:83/1510 train_time:2794ms step_avg:33.67ms
step:84/1510 train_time:2831ms step_avg:33.71ms
step:85/1510 train_time:2862ms step_avg:33.67ms
step:86/1510 train_time:2898ms step_avg:33.70ms
step:87/1510 train_time:2928ms step_avg:33.66ms
step:88/1510 train_time:2965ms step_avg:33.70ms
step:89/1510 train_time:2996ms step_avg:33.66ms
step:90/1510 train_time:3032ms step_avg:33.69ms
step:91/1510 train_time:3063ms step_avg:33.66ms
step:92/1510 train_time:3100ms step_avg:33.69ms
step:93/1510 train_time:3130ms step_avg:33.65ms
step:94/1510 train_time:3167ms step_avg:33.69ms
step:95/1510 train_time:3197ms step_avg:33.65ms
step:96/1510 train_time:3233ms step_avg:33.68ms
step:97/1510 train_time:3263ms step_avg:33.64ms
step:98/1510 train_time:3300ms step_avg:33.68ms
step:99/1510 train_time:3330ms step_avg:33.64ms
step:100/1510 train_time:3368ms step_avg:33.68ms
step:101/1510 train_time:3398ms step_avg:33.64ms
step:102/1510 train_time:3435ms step_avg:33.67ms
step:103/1510 train_time:3465ms step_avg:33.64ms
step:104/1510 train_time:3502ms step_avg:33.67ms
step:105/1510 train_time:3532ms step_avg:33.64ms
step:106/1510 train_time:3569ms step_avg:33.67ms
step:107/1510 train_time:3599ms step_avg:33.63ms
step:108/1510 train_time:3636ms step_avg:33.66ms
step:109/1510 train_time:3666ms step_avg:33.63ms
step:110/1510 train_time:3703ms step_avg:33.67ms
step:111/1510 train_time:3733ms step_avg:33.63ms
step:112/1510 train_time:3770ms step_avg:33.66ms
step:113/1510 train_time:3801ms step_avg:33.64ms
step:114/1510 train_time:3838ms step_avg:33.67ms
step:115/1510 train_time:3868ms step_avg:33.64ms
step:116/1510 train_time:3906ms step_avg:33.67ms
step:117/1510 train_time:3936ms step_avg:33.64ms
step:118/1510 train_time:3973ms step_avg:33.67ms
step:119/1510 train_time:4003ms step_avg:33.64ms
step:120/1510 train_time:4040ms step_avg:33.67ms
step:121/1510 train_time:4070ms step_avg:33.64ms
step:122/1510 train_time:4107ms step_avg:33.67ms
step:123/1510 train_time:4138ms step_avg:33.64ms
step:124/1510 train_time:4175ms step_avg:33.67ms
step:125/1510 train_time:4205ms step_avg:33.64ms
step:126/1510 train_time:4242ms step_avg:33.67ms
step:127/1510 train_time:4273ms step_avg:33.64ms
step:128/1510 train_time:4309ms step_avg:33.67ms
step:129/1510 train_time:4340ms step_avg:33.64ms
step:130/1510 train_time:4377ms step_avg:33.67ms
step:131/1510 train_time:4406ms step_avg:33.64ms
step:132/1510 train_time:4443ms step_avg:33.66ms
step:133/1510 train_time:4473ms step_avg:33.63ms
step:134/1510 train_time:4510ms step_avg:33.66ms
step:135/1510 train_time:4541ms step_avg:33.63ms
step:136/1510 train_time:4577ms step_avg:33.66ms
step:137/1510 train_time:4607ms step_avg:33.63ms
step:138/1510 train_time:4645ms step_avg:33.66ms
step:139/1510 train_time:4675ms step_avg:33.63ms
step:140/1510 train_time:4711ms step_avg:33.65ms
step:141/1510 train_time:4742ms step_avg:33.63ms
step:142/1510 train_time:4779ms step_avg:33.65ms
step:143/1510 train_time:4809ms step_avg:33.63ms
step:144/1510 train_time:4846ms step_avg:33.65ms
step:145/1510 train_time:4876ms step_avg:33.63ms
step:146/1510 train_time:4913ms step_avg:33.65ms
step:147/1510 train_time:4943ms step_avg:33.63ms
step:148/1510 train_time:4980ms step_avg:33.65ms
step:149/1510 train_time:5010ms step_avg:33.63ms
step:150/1510 train_time:5047ms step_avg:33.65ms
step:151/1510 train_time:5078ms step_avg:33.63ms
step:152/1510 train_time:5114ms step_avg:33.65ms
step:153/1510 train_time:5145ms step_avg:33.62ms
step:154/1510 train_time:5182ms step_avg:33.65ms
step:155/1510 train_time:5212ms step_avg:33.62ms
step:156/1510 train_time:5249ms step_avg:33.65ms
step:157/1510 train_time:5279ms step_avg:33.63ms
step:158/1510 train_time:5316ms step_avg:33.65ms
step:159/1510 train_time:5346ms step_avg:33.62ms
step:160/1510 train_time:5384ms step_avg:33.65ms
step:161/1510 train_time:5414ms step_avg:33.62ms
step:162/1510 train_time:5450ms step_avg:33.64ms
step:163/1510 train_time:5481ms step_avg:33.62ms
step:164/1510 train_time:5518ms step_avg:33.64ms
step:165/1510 train_time:5547ms step_avg:33.62ms
step:166/1510 train_time:5585ms step_avg:33.64ms
step:167/1510 train_time:5615ms step_avg:33.62ms
step:168/1510 train_time:5652ms step_avg:33.64ms
step:169/1510 train_time:5682ms step_avg:33.62ms
step:170/1510 train_time:5719ms step_avg:33.64ms
step:171/1510 train_time:5749ms step_avg:33.62ms
step:172/1510 train_time:5786ms step_avg:33.64ms
step:173/1510 train_time:5816ms step_avg:33.62ms
step:174/1510 train_time:5853ms step_avg:33.64ms
step:175/1510 train_time:5883ms step_avg:33.62ms
step:176/1510 train_time:5920ms step_avg:33.63ms
step:177/1510 train_time:5949ms step_avg:33.61ms
step:178/1510 train_time:5987ms step_avg:33.63ms
step:179/1510 train_time:6017ms step_avg:33.61ms
step:180/1510 train_time:6054ms step_avg:33.63ms
step:181/1510 train_time:6084ms step_avg:33.61ms
step:182/1510 train_time:6121ms step_avg:33.63ms
step:183/1510 train_time:6151ms step_avg:33.61ms
step:184/1510 train_time:6188ms step_avg:33.63ms
step:185/1510 train_time:6218ms step_avg:33.61ms
step:186/1510 train_time:6255ms step_avg:33.63ms
step:187/1510 train_time:6285ms step_avg:33.61ms
step:188/1510 train_time:6322ms step_avg:33.63ms
step:189/1510 train_time:6352ms step_avg:33.61ms
step:190/1510 train_time:6389ms step_avg:33.62ms
step:191/1510 train_time:6418ms step_avg:33.60ms
step:192/1510 train_time:6455ms step_avg:33.62ms
step:193/1510 train_time:6485ms step_avg:33.60ms
step:194/1510 train_time:6523ms step_avg:33.62ms
step:195/1510 train_time:6553ms step_avg:33.61ms
step:196/1510 train_time:6590ms step_avg:33.62ms
step:197/1510 train_time:6621ms step_avg:33.61ms
step:198/1510 train_time:6657ms step_avg:33.62ms
step:199/1510 train_time:6687ms step_avg:33.60ms
step:200/1510 train_time:6724ms step_avg:33.62ms
step:201/1510 train_time:6754ms step_avg:33.60ms
step:202/1510 train_time:6791ms step_avg:33.62ms
step:203/1510 train_time:6821ms step_avg:33.60ms
step:204/1510 train_time:6858ms step_avg:33.62ms
step:205/1510 train_time:6888ms step_avg:33.60ms
step:206/1510 train_time:6925ms step_avg:33.62ms
step:207/1510 train_time:6955ms step_avg:33.60ms
step:208/1510 train_time:6992ms step_avg:33.62ms
step:209/1510 train_time:7023ms step_avg:33.60ms
step:210/1510 train_time:7059ms step_avg:33.62ms
step:211/1510 train_time:7090ms step_avg:33.60ms
step:212/1510 train_time:7127ms step_avg:33.62ms
step:213/1510 train_time:7157ms step_avg:33.60ms
step:214/1510 train_time:7194ms step_avg:33.62ms
step:215/1510 train_time:7224ms step_avg:33.60ms
step:216/1510 train_time:7261ms step_avg:33.62ms
step:217/1510 train_time:7291ms step_avg:33.60ms
step:218/1510 train_time:7328ms step_avg:33.62ms
step:219/1510 train_time:7359ms step_avg:33.60ms
step:220/1510 train_time:7395ms step_avg:33.61ms
step:221/1510 train_time:7425ms step_avg:33.60ms
step:222/1510 train_time:7463ms step_avg:33.62ms
step:223/1510 train_time:7493ms step_avg:33.60ms
step:224/1510 train_time:7530ms step_avg:33.62ms
step:225/1510 train_time:7560ms step_avg:33.60ms
step:226/1510 train_time:7597ms step_avg:33.62ms
step:227/1510 train_time:7627ms step_avg:33.60ms
step:228/1510 train_time:7665ms step_avg:33.62ms
step:229/1510 train_time:7695ms step_avg:33.60ms
step:230/1510 train_time:7732ms step_avg:33.62ms
step:231/1510 train_time:7762ms step_avg:33.60ms
step:232/1510 train_time:7798ms step_avg:33.61ms
step:233/1510 train_time:7829ms step_avg:33.60ms
step:234/1510 train_time:7866ms step_avg:33.61ms
step:235/1510 train_time:7896ms step_avg:33.60ms
step:236/1510 train_time:7933ms step_avg:33.61ms
step:237/1510 train_time:7963ms step_avg:33.60ms
step:238/1510 train_time:8000ms step_avg:33.61ms
step:239/1510 train_time:8030ms step_avg:33.60ms
step:240/1510 train_time:8067ms step_avg:33.61ms
step:241/1510 train_time:8097ms step_avg:33.60ms
step:242/1510 train_time:8134ms step_avg:33.61ms
step:243/1510 train_time:8164ms step_avg:33.60ms
step:244/1510 train_time:8200ms step_avg:33.61ms
step:245/1510 train_time:8230ms step_avg:33.59ms
step:246/1510 train_time:8267ms step_avg:33.61ms
step:247/1510 train_time:8297ms step_avg:33.59ms
step:248/1510 train_time:8334ms step_avg:33.60ms
step:249/1510 train_time:8364ms step_avg:33.59ms
step:250/1510 train_time:8401ms step_avg:33.60ms
step:250/1510 val_loss:4.5538 train_time:8443ms step_avg:33.77ms
step:251/1510 train_time:8458ms step_avg:33.70ms
step:252/1510 train_time:8474ms step_avg:33.63ms
step:253/1510 train_time:8500ms step_avg:33.60ms
step:254/1510 train_time:8537ms step_avg:33.61ms
step:255/1510 train_time:8569ms step_avg:33.60ms
step:256/1510 train_time:8607ms step_avg:33.62ms
step:257/1510 train_time:8637ms step_avg:33.61ms
step:258/1510 train_time:8674ms step_avg:33.62ms
step:259/1510 train_time:8705ms step_avg:33.61ms
step:260/1510 train_time:8742ms step_avg:33.62ms
step:261/1510 train_time:8772ms step_avg:33.61ms
step:262/1510 train_time:8808ms step_avg:33.62ms
step:263/1510 train_time:8839ms step_avg:33.61ms
step:264/1510 train_time:8875ms step_avg:33.62ms
step:265/1510 train_time:8905ms step_avg:33.60ms
step:266/1510 train_time:8942ms step_avg:33.62ms
step:267/1510 train_time:8972ms step_avg:33.60ms
step:268/1510 train_time:9009ms step_avg:33.62ms
step:269/1510 train_time:9039ms step_avg:33.60ms
step:270/1510 train_time:9076ms step_avg:33.61ms
step:271/1510 train_time:9106ms step_avg:33.60ms
step:272/1510 train_time:9143ms step_avg:33.61ms
step:273/1510 train_time:9173ms step_avg:33.60ms
step:274/1510 train_time:9209ms step_avg:33.61ms
step:275/1510 train_time:9239ms step_avg:33.60ms
step:276/1510 train_time:9276ms step_avg:33.61ms
step:277/1510 train_time:9306ms step_avg:33.60ms
step:278/1510 train_time:9343ms step_avg:33.61ms
step:279/1510 train_time:9373ms step_avg:33.59ms
step:280/1510 train_time:9409ms step_avg:33.60ms
step:281/1510 train_time:9440ms step_avg:33.59ms
step:282/1510 train_time:9477ms step_avg:33.60ms
step:283/1510 train_time:9506ms step_avg:33.59ms
step:284/1510 train_time:9544ms step_avg:33.60ms
step:285/1510 train_time:9574ms step_avg:33.59ms
step:286/1510 train_time:9611ms step_avg:33.60ms
step:287/1510 train_time:9641ms step_avg:33.59ms
step:288/1510 train_time:9678ms step_avg:33.60ms
step:289/1510 train_time:9708ms step_avg:33.59ms
step:290/1510 train_time:9744ms step_avg:33.60ms
step:291/1510 train_time:9775ms step_avg:33.59ms
step:292/1510 train_time:9812ms step_avg:33.60ms
step:293/1510 train_time:9842ms step_avg:33.59ms
step:294/1510 train_time:9879ms step_avg:33.60ms
step:295/1510 train_time:9909ms step_avg:33.59ms
step:296/1510 train_time:9946ms step_avg:33.60ms
step:297/1510 train_time:9976ms step_avg:33.59ms
step:298/1510 train_time:10013ms step_avg:33.60ms
step:299/1510 train_time:10043ms step_avg:33.59ms
step:300/1510 train_time:10079ms step_avg:33.60ms
step:301/1510 train_time:10109ms step_avg:33.59ms
step:302/1510 train_time:10146ms step_avg:33.60ms
step:303/1510 train_time:10177ms step_avg:33.59ms
step:304/1510 train_time:10214ms step_avg:33.60ms
step:305/1510 train_time:10244ms step_avg:33.59ms
step:306/1510 train_time:10281ms step_avg:33.60ms
step:307/1510 train_time:10311ms step_avg:33.58ms
step:308/1510 train_time:10347ms step_avg:33.60ms
step:309/1510 train_time:10378ms step_avg:33.59ms
step:310/1510 train_time:10415ms step_avg:33.60ms
step:311/1510 train_time:10445ms step_avg:33.58ms
step:312/1510 train_time:10481ms step_avg:33.59ms
step:313/1510 train_time:10511ms step_avg:33.58ms
step:314/1510 train_time:10548ms step_avg:33.59ms
step:315/1510 train_time:10579ms step_avg:33.58ms
step:316/1510 train_time:10616ms step_avg:33.60ms
step:317/1510 train_time:10646ms step_avg:33.58ms
step:318/1510 train_time:10683ms step_avg:33.59ms
step:319/1510 train_time:10713ms step_avg:33.58ms
step:320/1510 train_time:10750ms step_avg:33.59ms
step:321/1510 train_time:10780ms step_avg:33.58ms
step:322/1510 train_time:10817ms step_avg:33.59ms
step:323/1510 train_time:10847ms step_avg:33.58ms
step:324/1510 train_time:10884ms step_avg:33.59ms
step:325/1510 train_time:10914ms step_avg:33.58ms
step:326/1510 train_time:10951ms step_avg:33.59ms
step:327/1510 train_time:10981ms step_avg:33.58ms
step:328/1510 train_time:11017ms step_avg:33.59ms
step:329/1510 train_time:11047ms step_avg:33.58ms
step:330/1510 train_time:11084ms step_avg:33.59ms
step:331/1510 train_time:11115ms step_avg:33.58ms
step:332/1510 train_time:11151ms step_avg:33.59ms
step:333/1510 train_time:11182ms step_avg:33.58ms
step:334/1510 train_time:11218ms step_avg:33.59ms
step:335/1510 train_time:11248ms step_avg:33.58ms
step:336/1510 train_time:11285ms step_avg:33.59ms
step:337/1510 train_time:11315ms step_avg:33.58ms
step:338/1510 train_time:11352ms step_avg:33.58ms
step:339/1510 train_time:11382ms step_avg:33.58ms
step:340/1510 train_time:11419ms step_avg:33.58ms
step:341/1510 train_time:11449ms step_avg:33.57ms
step:342/1510 train_time:11486ms step_avg:33.58ms
step:343/1510 train_time:11516ms step_avg:33.57ms
step:344/1510 train_time:11554ms step_avg:33.59ms
step:345/1510 train_time:11584ms step_avg:33.58ms
step:346/1510 train_time:11620ms step_avg:33.59ms
step:347/1510 train_time:11650ms step_avg:33.57ms
step:348/1510 train_time:11688ms step_avg:33.59ms
step:349/1510 train_time:11718ms step_avg:33.58ms
step:350/1510 train_time:11755ms step_avg:33.58ms
step:351/1510 train_time:11785ms step_avg:33.58ms
step:352/1510 train_time:11822ms step_avg:33.59ms
step:353/1510 train_time:11852ms step_avg:33.57ms
step:354/1510 train_time:11889ms step_avg:33.58ms
step:355/1510 train_time:11919ms step_avg:33.57ms
step:356/1510 train_time:11956ms step_avg:33.58ms
step:357/1510 train_time:11986ms step_avg:33.57ms
step:358/1510 train_time:12023ms step_avg:33.58ms
step:359/1510 train_time:12053ms step_avg:33.57ms
step:360/1510 train_time:12089ms step_avg:33.58ms
step:361/1510 train_time:12120ms step_avg:33.57ms
step:362/1510 train_time:12157ms step_avg:33.58ms
step:363/1510 train_time:12187ms step_avg:33.57ms
step:364/1510 train_time:12224ms step_avg:33.58ms
step:365/1510 train_time:12254ms step_avg:33.57ms
step:366/1510 train_time:12290ms step_avg:33.58ms
step:367/1510 train_time:12320ms step_avg:33.57ms
step:368/1510 train_time:12357ms step_avg:33.58ms
step:369/1510 train_time:12387ms step_avg:33.57ms
step:370/1510 train_time:12424ms step_avg:33.58ms
step:371/1510 train_time:12454ms step_avg:33.57ms
step:372/1510 train_time:12491ms step_avg:33.58ms
step:373/1510 train_time:12521ms step_avg:33.57ms
step:374/1510 train_time:12558ms step_avg:33.58ms
step:375/1510 train_time:12588ms step_avg:33.57ms
step:376/1510 train_time:12625ms step_avg:33.58ms
step:377/1510 train_time:12655ms step_avg:33.57ms
step:378/1510 train_time:12692ms step_avg:33.58ms
step:379/1510 train_time:12722ms step_avg:33.57ms
step:380/1510 train_time:12759ms step_avg:33.58ms
step:381/1510 train_time:12789ms step_avg:33.57ms
step:382/1510 train_time:12826ms step_avg:33.58ms
step:383/1510 train_time:12857ms step_avg:33.57ms
step:384/1510 train_time:12894ms step_avg:33.58ms
step:385/1510 train_time:12925ms step_avg:33.57ms
step:386/1510 train_time:12962ms step_avg:33.58ms
step:387/1510 train_time:12992ms step_avg:33.57ms
step:388/1510 train_time:13029ms step_avg:33.58ms
step:389/1510 train_time:13059ms step_avg:33.57ms
step:390/1510 train_time:13097ms step_avg:33.58ms
step:391/1510 train_time:13126ms step_avg:33.57ms
step:392/1510 train_time:13163ms step_avg:33.58ms
step:393/1510 train_time:13193ms step_avg:33.57ms
step:394/1510 train_time:13230ms step_avg:33.58ms
step:395/1510 train_time:13261ms step_avg:33.57ms
step:396/1510 train_time:13297ms step_avg:33.58ms
step:397/1510 train_time:13327ms step_avg:33.57ms
step:398/1510 train_time:13364ms step_avg:33.58ms
step:399/1510 train_time:13395ms step_avg:33.57ms
step:400/1510 train_time:13432ms step_avg:33.58ms
step:401/1510 train_time:13462ms step_avg:33.57ms
step:402/1510 train_time:13498ms step_avg:33.58ms
step:403/1510 train_time:13528ms step_avg:33.57ms
step:404/1510 train_time:13565ms step_avg:33.58ms
step:405/1510 train_time:13595ms step_avg:33.57ms
step:406/1510 train_time:13632ms step_avg:33.58ms
step:407/1510 train_time:13662ms step_avg:33.57ms
step:408/1510 train_time:13699ms step_avg:33.58ms
step:409/1510 train_time:13729ms step_avg:33.57ms
step:410/1510 train_time:13766ms step_avg:33.57ms
step:411/1510 train_time:13796ms step_avg:33.57ms
step:412/1510 train_time:13833ms step_avg:33.58ms
step:413/1510 train_time:13864ms step_avg:33.57ms
step:414/1510 train_time:13901ms step_avg:33.58ms
step:415/1510 train_time:13930ms step_avg:33.57ms
step:416/1510 train_time:13967ms step_avg:33.58ms
step:417/1510 train_time:13998ms step_avg:33.57ms
step:418/1510 train_time:14035ms step_avg:33.58ms
step:419/1510 train_time:14065ms step_avg:33.57ms
step:420/1510 train_time:14102ms step_avg:33.58ms
step:421/1510 train_time:14131ms step_avg:33.57ms
step:422/1510 train_time:14168ms step_avg:33.57ms
step:423/1510 train_time:14199ms step_avg:33.57ms
step:424/1510 train_time:14236ms step_avg:33.57ms
step:425/1510 train_time:14265ms step_avg:33.57ms
step:426/1510 train_time:14302ms step_avg:33.57ms
step:427/1510 train_time:14332ms step_avg:33.57ms
step:428/1510 train_time:14369ms step_avg:33.57ms
step:429/1510 train_time:14400ms step_avg:33.57ms
step:430/1510 train_time:14437ms step_avg:33.57ms
step:431/1510 train_time:14467ms step_avg:33.57ms
step:432/1510 train_time:14503ms step_avg:33.57ms
step:433/1510 train_time:14533ms step_avg:33.56ms
step:434/1510 train_time:14570ms step_avg:33.57ms
step:435/1510 train_time:14600ms step_avg:33.56ms
step:436/1510 train_time:14637ms step_avg:33.57ms
step:437/1510 train_time:14667ms step_avg:33.56ms
step:438/1510 train_time:14704ms step_avg:33.57ms
step:439/1510 train_time:14734ms step_avg:33.56ms
step:440/1510 train_time:14771ms step_avg:33.57ms
step:441/1510 train_time:14801ms step_avg:33.56ms
step:442/1510 train_time:14837ms step_avg:33.57ms
step:443/1510 train_time:14867ms step_avg:33.56ms
step:444/1510 train_time:14905ms step_avg:33.57ms
step:445/1510 train_time:14935ms step_avg:33.56ms
step:446/1510 train_time:14972ms step_avg:33.57ms
step:447/1510 train_time:15002ms step_avg:33.56ms
step:448/1510 train_time:15039ms step_avg:33.57ms
step:449/1510 train_time:15068ms step_avg:33.56ms
step:450/1510 train_time:15106ms step_avg:33.57ms
step:451/1510 train_time:15136ms step_avg:33.56ms
step:452/1510 train_time:15173ms step_avg:33.57ms
step:453/1510 train_time:15204ms step_avg:33.56ms
step:454/1510 train_time:15240ms step_avg:33.57ms
step:455/1510 train_time:15270ms step_avg:33.56ms
step:456/1510 train_time:15308ms step_avg:33.57ms
step:457/1510 train_time:15338ms step_avg:33.56ms
step:458/1510 train_time:15375ms step_avg:33.57ms
step:459/1510 train_time:15405ms step_avg:33.56ms
step:460/1510 train_time:15442ms step_avg:33.57ms
step:461/1510 train_time:15472ms step_avg:33.56ms
step:462/1510 train_time:15509ms step_avg:33.57ms
step:463/1510 train_time:15539ms step_avg:33.56ms
step:464/1510 train_time:15576ms step_avg:33.57ms
step:465/1510 train_time:15606ms step_avg:33.56ms
step:466/1510 train_time:15643ms step_avg:33.57ms
step:467/1510 train_time:15673ms step_avg:33.56ms
step:468/1510 train_time:15710ms step_avg:33.57ms
step:469/1510 train_time:15740ms step_avg:33.56ms
step:470/1510 train_time:15777ms step_avg:33.57ms
step:471/1510 train_time:15807ms step_avg:33.56ms
step:472/1510 train_time:15844ms step_avg:33.57ms
step:473/1510 train_time:15875ms step_avg:33.56ms
step:474/1510 train_time:15912ms step_avg:33.57ms
step:475/1510 train_time:15942ms step_avg:33.56ms
step:476/1510 train_time:15978ms step_avg:33.57ms
step:477/1510 train_time:16008ms step_avg:33.56ms
step:478/1510 train_time:16045ms step_avg:33.57ms
step:479/1510 train_time:16076ms step_avg:33.56ms
step:480/1510 train_time:16113ms step_avg:33.57ms
step:481/1510 train_time:16143ms step_avg:33.56ms
step:482/1510 train_time:16180ms step_avg:33.57ms
step:483/1510 train_time:16210ms step_avg:33.56ms
step:484/1510 train_time:16247ms step_avg:33.57ms
step:485/1510 train_time:16278ms step_avg:33.56ms
step:486/1510 train_time:16315ms step_avg:33.57ms
step:487/1510 train_time:16345ms step_avg:33.56ms
step:488/1510 train_time:16383ms step_avg:33.57ms
step:489/1510 train_time:16413ms step_avg:33.56ms
step:490/1510 train_time:16449ms step_avg:33.57ms
step:491/1510 train_time:16483ms step_avg:33.57ms
step:492/1510 train_time:16546ms step_avg:33.63ms
step:493/1510 train_time:16603ms step_avg:33.68ms
step:494/1510 train_time:16666ms step_avg:33.74ms
step:495/1510 train_time:16724ms step_avg:33.79ms
step:496/1510 train_time:16787ms step_avg:33.84ms
step:497/1510 train_time:16844ms step_avg:33.89ms
step:498/1510 train_time:16907ms step_avg:33.95ms
step:499/1510 train_time:16964ms step_avg:34.00ms
step:500/1510 train_time:17028ms step_avg:34.06ms
step:500/1510 val_loss:4.2819 train_time:17097ms step_avg:34.19ms
step:501/1510 train_time:17114ms step_avg:34.16ms
step:502/1510 train_time:17150ms step_avg:34.16ms
step:503/1510 train_time:17210ms step_avg:34.22ms
step:504/1510 train_time:17273ms step_avg:34.27ms
step:505/1510 train_time:17332ms step_avg:34.32ms
step:506/1510 train_time:17394ms step_avg:34.38ms
step:507/1510 train_time:17451ms step_avg:34.42ms
step:508/1510 train_time:17512ms step_avg:34.47ms
step:509/1510 train_time:17568ms step_avg:34.51ms
step:510/1510 train_time:17630ms step_avg:34.57ms
step:511/1510 train_time:17687ms step_avg:34.61ms
step:512/1510 train_time:17750ms step_avg:34.67ms
step:513/1510 train_time:17806ms step_avg:34.71ms
step:514/1510 train_time:17869ms step_avg:34.76ms
step:515/1510 train_time:17926ms step_avg:34.81ms
step:516/1510 train_time:17989ms step_avg:34.86ms
step:517/1510 train_time:18047ms step_avg:34.91ms
step:518/1510 train_time:18111ms step_avg:34.96ms
step:519/1510 train_time:18170ms step_avg:35.01ms
step:520/1510 train_time:18233ms step_avg:35.06ms
step:521/1510 train_time:18292ms step_avg:35.11ms
step:522/1510 train_time:18355ms step_avg:35.16ms
step:523/1510 train_time:18412ms step_avg:35.20ms
step:524/1510 train_time:18474ms step_avg:35.26ms
step:525/1510 train_time:18531ms step_avg:35.30ms
step:526/1510 train_time:18593ms step_avg:35.35ms
step:527/1510 train_time:18651ms step_avg:35.39ms
step:528/1510 train_time:18713ms step_avg:35.44ms
step:529/1510 train_time:18769ms step_avg:35.48ms
step:530/1510 train_time:18831ms step_avg:35.53ms
step:531/1510 train_time:18888ms step_avg:35.57ms
step:532/1510 train_time:18951ms step_avg:35.62ms
step:533/1510 train_time:19009ms step_avg:35.66ms
step:534/1510 train_time:19072ms step_avg:35.72ms
step:535/1510 train_time:19130ms step_avg:35.76ms
step:536/1510 train_time:19194ms step_avg:35.81ms
step:537/1510 train_time:19252ms step_avg:35.85ms
step:538/1510 train_time:19314ms step_avg:35.90ms
step:539/1510 train_time:19372ms step_avg:35.94ms
step:540/1510 train_time:19434ms step_avg:35.99ms
step:541/1510 train_time:19492ms step_avg:36.03ms
step:542/1510 train_time:19554ms step_avg:36.08ms
step:543/1510 train_time:19610ms step_avg:36.11ms
step:544/1510 train_time:19673ms step_avg:36.16ms
step:545/1510 train_time:19729ms step_avg:36.20ms
step:546/1510 train_time:19792ms step_avg:36.25ms
step:547/1510 train_time:19848ms step_avg:36.29ms
step:548/1510 train_time:19911ms step_avg:36.33ms
step:549/1510 train_time:19969ms step_avg:36.37ms
step:550/1510 train_time:20032ms step_avg:36.42ms
step:551/1510 train_time:20090ms step_avg:36.46ms
step:552/1510 train_time:20153ms step_avg:36.51ms
step:553/1510 train_time:20212ms step_avg:36.55ms
step:554/1510 train_time:20275ms step_avg:36.60ms
step:555/1510 train_time:20332ms step_avg:36.63ms
step:556/1510 train_time:20394ms step_avg:36.68ms
step:557/1510 train_time:20452ms step_avg:36.72ms
step:558/1510 train_time:20514ms step_avg:36.76ms
step:559/1510 train_time:20571ms step_avg:36.80ms
step:560/1510 train_time:20633ms step_avg:36.85ms
step:561/1510 train_time:20691ms step_avg:36.88ms
step:562/1510 train_time:20753ms step_avg:36.93ms
step:563/1510 train_time:20810ms step_avg:36.96ms
step:564/1510 train_time:20872ms step_avg:37.01ms
step:565/1510 train_time:20929ms step_avg:37.04ms
step:566/1510 train_time:20992ms step_avg:37.09ms
step:567/1510 train_time:21050ms step_avg:37.13ms
step:568/1510 train_time:21113ms step_avg:37.17ms
step:569/1510 train_time:21171ms step_avg:37.21ms
step:570/1510 train_time:21234ms step_avg:37.25ms
step:571/1510 train_time:21292ms step_avg:37.29ms
step:572/1510 train_time:21354ms step_avg:37.33ms
step:573/1510 train_time:21412ms step_avg:37.37ms
step:574/1510 train_time:21474ms step_avg:37.41ms
step:575/1510 train_time:21531ms step_avg:37.44ms
step:576/1510 train_time:21593ms step_avg:37.49ms
step:577/1510 train_time:21650ms step_avg:37.52ms
step:578/1510 train_time:21713ms step_avg:37.57ms
step:579/1510 train_time:21769ms step_avg:37.60ms
step:580/1510 train_time:21831ms step_avg:37.64ms
step:581/1510 train_time:21888ms step_avg:37.67ms
step:582/1510 train_time:21951ms step_avg:37.72ms
step:583/1510 train_time:22008ms step_avg:37.75ms
step:584/1510 train_time:22071ms step_avg:37.79ms
step:585/1510 train_time:22129ms step_avg:37.83ms
step:586/1510 train_time:22192ms step_avg:37.87ms
step:587/1510 train_time:22249ms step_avg:37.90ms
step:588/1510 train_time:22312ms step_avg:37.95ms
step:589/1510 train_time:22369ms step_avg:37.98ms
step:590/1510 train_time:22432ms step_avg:38.02ms
step:591/1510 train_time:22489ms step_avg:38.05ms
step:592/1510 train_time:22552ms step_avg:38.10ms
step:593/1510 train_time:22609ms step_avg:38.13ms
step:594/1510 train_time:22672ms step_avg:38.17ms
step:595/1510 train_time:22730ms step_avg:38.20ms
step:596/1510 train_time:22793ms step_avg:38.24ms
step:597/1510 train_time:22849ms step_avg:38.27ms
step:598/1510 train_time:22912ms step_avg:38.31ms
step:599/1510 train_time:22969ms step_avg:38.35ms
step:600/1510 train_time:23032ms step_avg:38.39ms
step:601/1510 train_time:23090ms step_avg:38.42ms
step:602/1510 train_time:23153ms step_avg:38.46ms
step:603/1510 train_time:23210ms step_avg:38.49ms
step:604/1510 train_time:23273ms step_avg:38.53ms
step:605/1510 train_time:23331ms step_avg:38.56ms
step:606/1510 train_time:23394ms step_avg:38.60ms
step:607/1510 train_time:23451ms step_avg:38.63ms
step:608/1510 train_time:23513ms step_avg:38.67ms
step:609/1510 train_time:23569ms step_avg:38.70ms
step:610/1510 train_time:23632ms step_avg:38.74ms
step:611/1510 train_time:23689ms step_avg:38.77ms
step:612/1510 train_time:23752ms step_avg:38.81ms
step:613/1510 train_time:23809ms step_avg:38.84ms
step:614/1510 train_time:23872ms step_avg:38.88ms
step:615/1510 train_time:23929ms step_avg:38.91ms
step:616/1510 train_time:23991ms step_avg:38.95ms
step:617/1510 train_time:24049ms step_avg:38.98ms
step:618/1510 train_time:24111ms step_avg:39.01ms
step:619/1510 train_time:24168ms step_avg:39.04ms
step:620/1510 train_time:24232ms step_avg:39.08ms
step:621/1510 train_time:24289ms step_avg:39.11ms
step:622/1510 train_time:24352ms step_avg:39.15ms
step:623/1510 train_time:24409ms step_avg:39.18ms
step:624/1510 train_time:24472ms step_avg:39.22ms
step:625/1510 train_time:24530ms step_avg:39.25ms
step:626/1510 train_time:24593ms step_avg:39.29ms
step:627/1510 train_time:24650ms step_avg:39.31ms
step:628/1510 train_time:24712ms step_avg:39.35ms
step:629/1510 train_time:24770ms step_avg:39.38ms
step:630/1510 train_time:24832ms step_avg:39.42ms
step:631/1510 train_time:24889ms step_avg:39.44ms
step:632/1510 train_time:24951ms step_avg:39.48ms
step:633/1510 train_time:25008ms step_avg:39.51ms
step:634/1510 train_time:25071ms step_avg:39.54ms
step:635/1510 train_time:25129ms step_avg:39.57ms
step:636/1510 train_time:25192ms step_avg:39.61ms
step:637/1510 train_time:25250ms step_avg:39.64ms
step:638/1510 train_time:25312ms step_avg:39.67ms
step:639/1510 train_time:25370ms step_avg:39.70ms
step:640/1510 train_time:25433ms step_avg:39.74ms
step:641/1510 train_time:25490ms step_avg:39.77ms
step:642/1510 train_time:25553ms step_avg:39.80ms
step:643/1510 train_time:25610ms step_avg:39.83ms
step:644/1510 train_time:25672ms step_avg:39.86ms
step:645/1510 train_time:25730ms step_avg:39.89ms
step:646/1510 train_time:25793ms step_avg:39.93ms
step:647/1510 train_time:25849ms step_avg:39.95ms
step:648/1510 train_time:25913ms step_avg:39.99ms
step:649/1510 train_time:25970ms step_avg:40.02ms
step:650/1510 train_time:26033ms step_avg:40.05ms
step:651/1510 train_time:26091ms step_avg:40.08ms
step:652/1510 train_time:26154ms step_avg:40.11ms
step:653/1510 train_time:26211ms step_avg:40.14ms
step:654/1510 train_time:26274ms step_avg:40.17ms
step:655/1510 train_time:26331ms step_avg:40.20ms
step:656/1510 train_time:26394ms step_avg:40.23ms
step:657/1510 train_time:26451ms step_avg:40.26ms
step:658/1510 train_time:26514ms step_avg:40.29ms
step:659/1510 train_time:26571ms step_avg:40.32ms
step:660/1510 train_time:26633ms step_avg:40.35ms
step:661/1510 train_time:26691ms step_avg:40.38ms
step:662/1510 train_time:26753ms step_avg:40.41ms
step:663/1510 train_time:26809ms step_avg:40.44ms
step:664/1510 train_time:26872ms step_avg:40.47ms
step:665/1510 train_time:26929ms step_avg:40.49ms
step:666/1510 train_time:26991ms step_avg:40.53ms
step:667/1510 train_time:27048ms step_avg:40.55ms
step:668/1510 train_time:27111ms step_avg:40.59ms
step:669/1510 train_time:27169ms step_avg:40.61ms
step:670/1510 train_time:27232ms step_avg:40.65ms
step:671/1510 train_time:27290ms step_avg:40.67ms
step:672/1510 train_time:27352ms step_avg:40.70ms
step:673/1510 train_time:27409ms step_avg:40.73ms
step:674/1510 train_time:27472ms step_avg:40.76ms
step:675/1510 train_time:27529ms step_avg:40.78ms
step:676/1510 train_time:27592ms step_avg:40.82ms
step:677/1510 train_time:27650ms step_avg:40.84ms
step:678/1510 train_time:27712ms step_avg:40.87ms
step:679/1510 train_time:27770ms step_avg:40.90ms
step:680/1510 train_time:27833ms step_avg:40.93ms
step:681/1510 train_time:27889ms step_avg:40.95ms
step:682/1510 train_time:27952ms step_avg:40.99ms
step:683/1510 train_time:28008ms step_avg:41.01ms
step:684/1510 train_time:28071ms step_avg:41.04ms
step:685/1510 train_time:28129ms step_avg:41.06ms
step:686/1510 train_time:28192ms step_avg:41.10ms
step:687/1510 train_time:28249ms step_avg:41.12ms
step:688/1510 train_time:28312ms step_avg:41.15ms
step:689/1510 train_time:28368ms step_avg:41.17ms
step:690/1510 train_time:28432ms step_avg:41.21ms
step:691/1510 train_time:28488ms step_avg:41.23ms
step:692/1510 train_time:28552ms step_avg:41.26ms
step:693/1510 train_time:28609ms step_avg:41.28ms
step:694/1510 train_time:28672ms step_avg:41.31ms
step:695/1510 train_time:28729ms step_avg:41.34ms
step:696/1510 train_time:28792ms step_avg:41.37ms
step:697/1510 train_time:28849ms step_avg:41.39ms
step:698/1510 train_time:28911ms step_avg:41.42ms
step:699/1510 train_time:28969ms step_avg:41.44ms
step:700/1510 train_time:29032ms step_avg:41.47ms
step:701/1510 train_time:29089ms step_avg:41.50ms
step:702/1510 train_time:29152ms step_avg:41.53ms
step:703/1510 train_time:29210ms step_avg:41.55ms
step:704/1510 train_time:29272ms step_avg:41.58ms
step:705/1510 train_time:29330ms step_avg:41.60ms
step:706/1510 train_time:29392ms step_avg:41.63ms
step:707/1510 train_time:29450ms step_avg:41.65ms
step:708/1510 train_time:29512ms step_avg:41.68ms
step:709/1510 train_time:29570ms step_avg:41.71ms
step:710/1510 train_time:29633ms step_avg:41.74ms
step:711/1510 train_time:29691ms step_avg:41.76ms
step:712/1510 train_time:29754ms step_avg:41.79ms
step:713/1510 train_time:29812ms step_avg:41.81ms
step:714/1510 train_time:29874ms step_avg:41.84ms
step:715/1510 train_time:29930ms step_avg:41.86ms
step:716/1510 train_time:29993ms step_avg:41.89ms
step:717/1510 train_time:30049ms step_avg:41.91ms
step:718/1510 train_time:30112ms step_avg:41.94ms
step:719/1510 train_time:30169ms step_avg:41.96ms
step:720/1510 train_time:30232ms step_avg:41.99ms
step:721/1510 train_time:30290ms step_avg:42.01ms
step:722/1510 train_time:30352ms step_avg:42.04ms
step:723/1510 train_time:30410ms step_avg:42.06ms
step:724/1510 train_time:30473ms step_avg:42.09ms
step:725/1510 train_time:30529ms step_avg:42.11ms
step:726/1510 train_time:30592ms step_avg:42.14ms
step:727/1510 train_time:30649ms step_avg:42.16ms
step:728/1510 train_time:30713ms step_avg:42.19ms
step:729/1510 train_time:30770ms step_avg:42.21ms
step:730/1510 train_time:30833ms step_avg:42.24ms
step:731/1510 train_time:30891ms step_avg:42.26ms
step:732/1510 train_time:30953ms step_avg:42.29ms
step:733/1510 train_time:31009ms step_avg:42.30ms
step:734/1510 train_time:31074ms step_avg:42.33ms
step:735/1510 train_time:31131ms step_avg:42.35ms
step:736/1510 train_time:31193ms step_avg:42.38ms
step:737/1510 train_time:31251ms step_avg:42.40ms
step:738/1510 train_time:31313ms step_avg:42.43ms
step:739/1510 train_time:31369ms step_avg:42.45ms
step:740/1510 train_time:31432ms step_avg:42.48ms
step:741/1510 train_time:31488ms step_avg:42.49ms
step:742/1510 train_time:31551ms step_avg:42.52ms
step:743/1510 train_time:31609ms step_avg:42.54ms
step:744/1510 train_time:31672ms step_avg:42.57ms
step:745/1510 train_time:31729ms step_avg:42.59ms
step:746/1510 train_time:31793ms step_avg:42.62ms
step:747/1510 train_time:31850ms step_avg:42.64ms
step:748/1510 train_time:31913ms step_avg:42.66ms
step:749/1510 train_time:31970ms step_avg:42.68ms
step:750/1510 train_time:32033ms step_avg:42.71ms
step:750/1510 val_loss:3.8219 train_time:32103ms step_avg:42.80ms
step:751/1510 train_time:32120ms step_avg:42.77ms
step:752/1510 train_time:32156ms step_avg:42.76ms
step:753/1510 train_time:32216ms step_avg:42.78ms
step:754/1510 train_time:32280ms step_avg:42.81ms
step:755/1510 train_time:32337ms step_avg:42.83ms
step:756/1510 train_time:32399ms step_avg:42.86ms
step:757/1510 train_time:32455ms step_avg:42.87ms
step:758/1510 train_time:32516ms step_avg:42.90ms
step:759/1510 train_time:32574ms step_avg:42.92ms
step:760/1510 train_time:32635ms step_avg:42.94ms
step:761/1510 train_time:32692ms step_avg:42.96ms
step:762/1510 train_time:32754ms step_avg:42.98ms
step:763/1510 train_time:32809ms step_avg:43.00ms
step:764/1510 train_time:32871ms step_avg:43.03ms
step:765/1510 train_time:32929ms step_avg:43.04ms
step:766/1510 train_time:32991ms step_avg:43.07ms
step:767/1510 train_time:33049ms step_avg:43.09ms
step:768/1510 train_time:33112ms step_avg:43.11ms
step:769/1510 train_time:33170ms step_avg:43.13ms
step:770/1510 train_time:33234ms step_avg:43.16ms
step:771/1510 train_time:33292ms step_avg:43.18ms
step:772/1510 train_time:33355ms step_avg:43.21ms
step:773/1510 train_time:33413ms step_avg:43.22ms
step:774/1510 train_time:33475ms step_avg:43.25ms
step:775/1510 train_time:33532ms step_avg:43.27ms
step:776/1510 train_time:33595ms step_avg:43.29ms
step:777/1510 train_time:33651ms step_avg:43.31ms
step:778/1510 train_time:33713ms step_avg:43.33ms
step:779/1510 train_time:33769ms step_avg:43.35ms
step:780/1510 train_time:33832ms step_avg:43.37ms
step:781/1510 train_time:33888ms step_avg:43.39ms
step:782/1510 train_time:33951ms step_avg:43.42ms
step:783/1510 train_time:34008ms step_avg:43.43ms
step:784/1510 train_time:34072ms step_avg:43.46ms
step:785/1510 train_time:34129ms step_avg:43.48ms
step:786/1510 train_time:34193ms step_avg:43.50ms
step:787/1510 train_time:34250ms step_avg:43.52ms
step:788/1510 train_time:34314ms step_avg:43.55ms
step:789/1510 train_time:34372ms step_avg:43.56ms
step:790/1510 train_time:34435ms step_avg:43.59ms
step:791/1510 train_time:34491ms step_avg:43.60ms
step:792/1510 train_time:34555ms step_avg:43.63ms
step:793/1510 train_time:34611ms step_avg:43.65ms
step:794/1510 train_time:34674ms step_avg:43.67ms
step:795/1510 train_time:34729ms step_avg:43.68ms
step:796/1510 train_time:34791ms step_avg:43.71ms
step:797/1510 train_time:34847ms step_avg:43.72ms
step:798/1510 train_time:34909ms step_avg:43.75ms
step:799/1510 train_time:34966ms step_avg:43.76ms
step:800/1510 train_time:35029ms step_avg:43.79ms
step:801/1510 train_time:35087ms step_avg:43.80ms
step:802/1510 train_time:35151ms step_avg:43.83ms
step:803/1510 train_time:35209ms step_avg:43.85ms
step:804/1510 train_time:35273ms step_avg:43.87ms
step:805/1510 train_time:35330ms step_avg:43.89ms
step:806/1510 train_time:35393ms step_avg:43.91ms
step:807/1510 train_time:35450ms step_avg:43.93ms
step:808/1510 train_time:35514ms step_avg:43.95ms
step:809/1510 train_time:35571ms step_avg:43.97ms
step:810/1510 train_time:35634ms step_avg:43.99ms
step:811/1510 train_time:35690ms step_avg:44.01ms
step:812/1510 train_time:35753ms step_avg:44.03ms
step:813/1510 train_time:35809ms step_avg:44.05ms
step:814/1510 train_time:35871ms step_avg:44.07ms
step:815/1510 train_time:35928ms step_avg:44.08ms
step:816/1510 train_time:35990ms step_avg:44.10ms
step:817/1510 train_time:36046ms step_avg:44.12ms
step:818/1510 train_time:36109ms step_avg:44.14ms
step:819/1510 train_time:36166ms step_avg:44.16ms
step:820/1510 train_time:36229ms step_avg:44.18ms
step:821/1510 train_time:36287ms step_avg:44.20ms
step:822/1510 train_time:36349ms step_avg:44.22ms
step:823/1510 train_time:36407ms step_avg:44.24ms
step:824/1510 train_time:36469ms step_avg:44.26ms
step:825/1510 train_time:36527ms step_avg:44.28ms
step:826/1510 train_time:36589ms step_avg:44.30ms
step:827/1510 train_time:36647ms step_avg:44.31ms
step:828/1510 train_time:36709ms step_avg:44.33ms
step:829/1510 train_time:36765ms step_avg:44.35ms
step:830/1510 train_time:36827ms step_avg:44.37ms
step:831/1510 train_time:36883ms step_avg:44.38ms
step:832/1510 train_time:36945ms step_avg:44.40ms
step:833/1510 train_time:37001ms step_avg:44.42ms
step:834/1510 train_time:37064ms step_avg:44.44ms
step:835/1510 train_time:37121ms step_avg:44.46ms
step:836/1510 train_time:37183ms step_avg:44.48ms
step:837/1510 train_time:37239ms step_avg:44.49ms
step:838/1510 train_time:37301ms step_avg:44.51ms
step:839/1510 train_time:37358ms step_avg:44.53ms
step:840/1510 train_time:37420ms step_avg:44.55ms
step:841/1510 train_time:37476ms step_avg:44.56ms
step:842/1510 train_time:37539ms step_avg:44.58ms
step:843/1510 train_time:37595ms step_avg:44.60ms
step:844/1510 train_time:37658ms step_avg:44.62ms
step:845/1510 train_time:37714ms step_avg:44.63ms
step:846/1510 train_time:37777ms step_avg:44.65ms
step:847/1510 train_time:37833ms step_avg:44.67ms
step:848/1510 train_time:37896ms step_avg:44.69ms
step:849/1510 train_time:37954ms step_avg:44.70ms
step:850/1510 train_time:38017ms step_avg:44.73ms
step:851/1510 train_time:38074ms step_avg:44.74ms
step:852/1510 train_time:38136ms step_avg:44.76ms
step:853/1510 train_time:38192ms step_avg:44.77ms
step:854/1510 train_time:38256ms step_avg:44.80ms
step:855/1510 train_time:38313ms step_avg:44.81ms
step:856/1510 train_time:38376ms step_avg:44.83ms
step:857/1510 train_time:38433ms step_avg:44.85ms
step:858/1510 train_time:38496ms step_avg:44.87ms
step:859/1510 train_time:38552ms step_avg:44.88ms
step:860/1510 train_time:38615ms step_avg:44.90ms
step:861/1510 train_time:38672ms step_avg:44.91ms
step:862/1510 train_time:38734ms step_avg:44.94ms
step:863/1510 train_time:38790ms step_avg:44.95ms
step:864/1510 train_time:38854ms step_avg:44.97ms
step:865/1510 train_time:38910ms step_avg:44.98ms
step:866/1510 train_time:38973ms step_avg:45.00ms
step:867/1510 train_time:39030ms step_avg:45.02ms
step:868/1510 train_time:39094ms step_avg:45.04ms
step:869/1510 train_time:39151ms step_avg:45.05ms
step:870/1510 train_time:39214ms step_avg:45.07ms
step:871/1510 train_time:39272ms step_avg:45.09ms
step:872/1510 train_time:39335ms step_avg:45.11ms
step:873/1510 train_time:39392ms step_avg:45.12ms
step:874/1510 train_time:39454ms step_avg:45.14ms
step:875/1510 train_time:39511ms step_avg:45.16ms
step:876/1510 train_time:39574ms step_avg:45.18ms
step:877/1510 train_time:39631ms step_avg:45.19ms
step:878/1510 train_time:39694ms step_avg:45.21ms
step:879/1510 train_time:39751ms step_avg:45.22ms
step:880/1510 train_time:39813ms step_avg:45.24ms
step:881/1510 train_time:39870ms step_avg:45.26ms
step:882/1510 train_time:39933ms step_avg:45.28ms
step:883/1510 train_time:39990ms step_avg:45.29ms
step:884/1510 train_time:40052ms step_avg:45.31ms
step:885/1510 train_time:40110ms step_avg:45.32ms
step:886/1510 train_time:40173ms step_avg:45.34ms
step:887/1510 train_time:40229ms step_avg:45.35ms
step:888/1510 train_time:40292ms step_avg:45.37ms
step:889/1510 train_time:40350ms step_avg:45.39ms
step:890/1510 train_time:40412ms step_avg:45.41ms
step:891/1510 train_time:40469ms step_avg:45.42ms
step:892/1510 train_time:40532ms step_avg:45.44ms
step:893/1510 train_time:40589ms step_avg:45.45ms
step:894/1510 train_time:40652ms step_avg:45.47ms
step:895/1510 train_time:40709ms step_avg:45.48ms
step:896/1510 train_time:40771ms step_avg:45.50ms
step:897/1510 train_time:40829ms step_avg:45.52ms
step:898/1510 train_time:40891ms step_avg:45.54ms
step:899/1510 train_time:40947ms step_avg:45.55ms
step:900/1510 train_time:41010ms step_avg:45.57ms
step:901/1510 train_time:41068ms step_avg:45.58ms
step:902/1510 train_time:41131ms step_avg:45.60ms
step:903/1510 train_time:41189ms step_avg:45.61ms
step:904/1510 train_time:41252ms step_avg:45.63ms
step:905/1510 train_time:41310ms step_avg:45.65ms
step:906/1510 train_time:41373ms step_avg:45.67ms
step:907/1510 train_time:41430ms step_avg:45.68ms
step:908/1510 train_time:41493ms step_avg:45.70ms
step:909/1510 train_time:41550ms step_avg:45.71ms
step:910/1510 train_time:41612ms step_avg:45.73ms
step:911/1510 train_time:41668ms step_avg:45.74ms
step:912/1510 train_time:41731ms step_avg:45.76ms
step:913/1510 train_time:41789ms step_avg:45.77ms
step:914/1510 train_time:41852ms step_avg:45.79ms
step:915/1510 train_time:41908ms step_avg:45.80ms
step:916/1510 train_time:41970ms step_avg:45.82ms
step:917/1510 train_time:42027ms step_avg:45.83ms
step:918/1510 train_time:42089ms step_avg:45.85ms
step:919/1510 train_time:42146ms step_avg:45.86ms
step:920/1510 train_time:42208ms step_avg:45.88ms
step:921/1510 train_time:42266ms step_avg:45.89ms
step:922/1510 train_time:42329ms step_avg:45.91ms
step:923/1510 train_time:42386ms step_avg:45.92ms
step:924/1510 train_time:42449ms step_avg:45.94ms
step:925/1510 train_time:42507ms step_avg:45.95ms
step:926/1510 train_time:42569ms step_avg:45.97ms
step:927/1510 train_time:42626ms step_avg:45.98ms
step:928/1510 train_time:42688ms step_avg:46.00ms
step:929/1510 train_time:42745ms step_avg:46.01ms
step:930/1510 train_time:42807ms step_avg:46.03ms
step:931/1510 train_time:42864ms step_avg:46.04ms
step:932/1510 train_time:42926ms step_avg:46.06ms
step:933/1510 train_time:42983ms step_avg:46.07ms
step:934/1510 train_time:43045ms step_avg:46.09ms
step:935/1510 train_time:43101ms step_avg:46.10ms
step:936/1510 train_time:43162ms step_avg:46.11ms
step:937/1510 train_time:43218ms step_avg:46.12ms
step:938/1510 train_time:43281ms step_avg:46.14ms
step:939/1510 train_time:43337ms step_avg:46.15ms
step:940/1510 train_time:43399ms step_avg:46.17ms
step:941/1510 train_time:43455ms step_avg:46.18ms
step:942/1510 train_time:43518ms step_avg:46.20ms
step:943/1510 train_time:43574ms step_avg:46.21ms
step:944/1510 train_time:43636ms step_avg:46.22ms
step:945/1510 train_time:43693ms step_avg:46.24ms
step:946/1510 train_time:43756ms step_avg:46.25ms
step:947/1510 train_time:43813ms step_avg:46.27ms
step:948/1510 train_time:43876ms step_avg:46.28ms
step:949/1510 train_time:43932ms step_avg:46.29ms
step:950/1510 train_time:43995ms step_avg:46.31ms
step:951/1510 train_time:44053ms step_avg:46.32ms
step:952/1510 train_time:44115ms step_avg:46.34ms
step:953/1510 train_time:44172ms step_avg:46.35ms
step:954/1510 train_time:44234ms step_avg:46.37ms
step:955/1510 train_time:44292ms step_avg:46.38ms
step:956/1510 train_time:44355ms step_avg:46.40ms
step:957/1510 train_time:44411ms step_avg:46.41ms
step:958/1510 train_time:44474ms step_avg:46.42ms
step:959/1510 train_time:44531ms step_avg:46.43ms
step:960/1510 train_time:44594ms step_avg:46.45ms
step:961/1510 train_time:44650ms step_avg:46.46ms
step:962/1510 train_time:44712ms step_avg:46.48ms
step:963/1510 train_time:44769ms step_avg:46.49ms
step:964/1510 train_time:44832ms step_avg:46.51ms
step:965/1510 train_time:44889ms step_avg:46.52ms
step:966/1510 train_time:44952ms step_avg:46.53ms
step:967/1510 train_time:45010ms step_avg:46.55ms
step:968/1510 train_time:45073ms step_avg:46.56ms
step:969/1510 train_time:45130ms step_avg:46.57ms
step:970/1510 train_time:45192ms step_avg:46.59ms
step:971/1510 train_time:45249ms step_avg:46.60ms
step:972/1510 train_time:45312ms step_avg:46.62ms
step:973/1510 train_time:45369ms step_avg:46.63ms
step:974/1510 train_time:45431ms step_avg:46.64ms
step:975/1510 train_time:45488ms step_avg:46.65ms
step:976/1510 train_time:45551ms step_avg:46.67ms
step:977/1510 train_time:45607ms step_avg:46.68ms
step:978/1510 train_time:45670ms step_avg:46.70ms
step:979/1510 train_time:45727ms step_avg:46.71ms
step:980/1510 train_time:45788ms step_avg:46.72ms
step:981/1510 train_time:45847ms step_avg:46.74ms
step:982/1510 train_time:45938ms step_avg:46.78ms
step:983/1510 train_time:46021ms step_avg:46.82ms
step:984/1510 train_time:46110ms step_avg:46.86ms
step:985/1510 train_time:46194ms step_avg:46.90ms
step:986/1510 train_time:46282ms step_avg:46.94ms
step:987/1510 train_time:46365ms step_avg:46.98ms
step:988/1510 train_time:46453ms step_avg:47.02ms
step:989/1510 train_time:46536ms step_avg:47.05ms
step:990/1510 train_time:46624ms step_avg:47.10ms
step:991/1510 train_time:46707ms step_avg:47.13ms
step:992/1510 train_time:46797ms step_avg:47.17ms
step:993/1510 train_time:46880ms step_avg:47.21ms
step:994/1510 train_time:46968ms step_avg:47.25ms
step:995/1510 train_time:47051ms step_avg:47.29ms
step:996/1510 train_time:47140ms step_avg:47.33ms
step:997/1510 train_time:47224ms step_avg:47.37ms
step:998/1510 train_time:47312ms step_avg:47.41ms
step:999/1510 train_time:47395ms step_avg:47.44ms
step:1000/1510 train_time:47484ms step_avg:47.48ms
step:1000/1510 val_loss:3.5244 train_time:47581ms step_avg:47.58ms
step:1001/1510 train_time:47597ms step_avg:47.55ms
step:1002/1510 train_time:47661ms step_avg:47.57ms
step:1003/1510 train_time:47750ms step_avg:47.61ms
step:1004/1510 train_time:47838ms step_avg:47.65ms
step:1005/1510 train_time:47921ms step_avg:47.68ms
step:1006/1510 train_time:48009ms step_avg:47.72ms
step:1007/1510 train_time:48091ms step_avg:47.76ms
step:1008/1510 train_time:48180ms step_avg:47.80ms
step:1009/1510 train_time:48263ms step_avg:47.83ms
step:1010/1510 train_time:48351ms step_avg:47.87ms
step:1011/1510 train_time:48432ms step_avg:47.91ms
step:1012/1510 train_time:48521ms step_avg:47.95ms
step:1013/1510 train_time:48608ms step_avg:47.98ms
step:1014/1510 train_time:48700ms step_avg:48.03ms
step:1015/1510 train_time:48785ms step_avg:48.06ms
step:1016/1510 train_time:48874ms step_avg:48.10ms
step:1017/1510 train_time:48957ms step_avg:48.14ms
step:1018/1510 train_time:49044ms step_avg:48.18ms
step:1019/1510 train_time:49126ms step_avg:48.21ms
step:1020/1510 train_time:49214ms step_avg:48.25ms
step:1021/1510 train_time:49296ms step_avg:48.28ms
step:1022/1510 train_time:49385ms step_avg:48.32ms
step:1023/1510 train_time:49468ms step_avg:48.36ms
step:1024/1510 train_time:49557ms step_avg:48.40ms
step:1025/1510 train_time:49641ms step_avg:48.43ms
step:1026/1510 train_time:49731ms step_avg:48.47ms
step:1027/1510 train_time:49816ms step_avg:48.51ms
step:1028/1510 train_time:49906ms step_avg:48.55ms
step:1029/1510 train_time:49989ms step_avg:48.58ms
step:1030/1510 train_time:50078ms step_avg:48.62ms
step:1031/1510 train_time:50161ms step_avg:48.65ms
step:1032/1510 train_time:50248ms step_avg:48.69ms
step:1033/1510 train_time:50330ms step_avg:48.72ms
step:1034/1510 train_time:50417ms step_avg:48.76ms
step:1035/1510 train_time:50500ms step_avg:48.79ms
step:1036/1510 train_time:50589ms step_avg:48.83ms
step:1037/1510 train_time:50673ms step_avg:48.86ms
step:1038/1510 train_time:50763ms step_avg:48.90ms
step:1039/1510 train_time:50847ms step_avg:48.94ms
step:1040/1510 train_time:50936ms step_avg:48.98ms
step:1041/1510 train_time:51019ms step_avg:49.01ms
step:1042/1510 train_time:51109ms step_avg:49.05ms
step:1043/1510 train_time:51191ms step_avg:49.08ms
step:1044/1510 train_time:51279ms step_avg:49.12ms
step:1045/1510 train_time:51363ms step_avg:49.15ms
step:1046/1510 train_time:51451ms step_avg:49.19ms
step:1047/1510 train_time:51534ms step_avg:49.22ms
step:1048/1510 train_time:51624ms step_avg:49.26ms
step:1049/1510 train_time:51708ms step_avg:49.29ms
step:1050/1510 train_time:51797ms step_avg:49.33ms
step:1051/1510 train_time:51882ms step_avg:49.36ms
step:1052/1510 train_time:51971ms step_avg:49.40ms
step:1053/1510 train_time:52056ms step_avg:49.44ms
step:1054/1510 train_time:52145ms step_avg:49.47ms
step:1055/1510 train_time:52226ms step_avg:49.50ms
step:1056/1510 train_time:52314ms step_avg:49.54ms
step:1057/1510 train_time:52397ms step_avg:49.57ms
step:1058/1510 train_time:52486ms step_avg:49.61ms
step:1059/1510 train_time:52569ms step_avg:49.64ms
step:1060/1510 train_time:52658ms step_avg:49.68ms
step:1061/1510 train_time:52740ms step_avg:49.71ms
step:1062/1510 train_time:52829ms step_avg:49.75ms
step:1063/1510 train_time:52912ms step_avg:49.78ms
step:1064/1510 train_time:53002ms step_avg:49.81ms
step:1065/1510 train_time:53085ms step_avg:49.85ms
step:1066/1510 train_time:53174ms step_avg:49.88ms
step:1067/1510 train_time:53257ms step_avg:49.91ms
step:1068/1510 train_time:53345ms step_avg:49.95ms
step:1069/1510 train_time:53428ms step_avg:49.98ms
step:1070/1510 train_time:53516ms step_avg:50.01ms
step:1071/1510 train_time:53599ms step_avg:50.05ms
step:1072/1510 train_time:53688ms step_avg:50.08ms
step:1073/1510 train_time:53771ms step_avg:50.11ms
step:1074/1510 train_time:53860ms step_avg:50.15ms
step:1075/1510 train_time:53945ms step_avg:50.18ms
step:1076/1510 train_time:54033ms step_avg:50.22ms
step:1077/1510 train_time:54116ms step_avg:50.25ms
step:1078/1510 train_time:54204ms step_avg:50.28ms
step:1079/1510 train_time:54286ms step_avg:50.31ms
step:1080/1510 train_time:54375ms step_avg:50.35ms
step:1081/1510 train_time:54458ms step_avg:50.38ms
step:1082/1510 train_time:54547ms step_avg:50.41ms
step:1083/1510 train_time:54630ms step_avg:50.44ms
step:1084/1510 train_time:54719ms step_avg:50.48ms
step:1085/1510 train_time:54801ms step_avg:50.51ms
step:1086/1510 train_time:54889ms step_avg:50.54ms
step:1087/1510 train_time:54972ms step_avg:50.57ms
step:1088/1510 train_time:55062ms step_avg:50.61ms
step:1089/1510 train_time:55146ms step_avg:50.64ms
step:1090/1510 train_time:55234ms step_avg:50.67ms
step:1091/1510 train_time:55316ms step_avg:50.70ms
step:1092/1510 train_time:55405ms step_avg:50.74ms
step:1093/1510 train_time:55487ms step_avg:50.77ms
step:1094/1510 train_time:55575ms step_avg:50.80ms
step:1095/1510 train_time:55659ms step_avg:50.83ms
step:1096/1510 train_time:55748ms step_avg:50.86ms
step:1097/1510 train_time:55831ms step_avg:50.89ms
step:1098/1510 train_time:55920ms step_avg:50.93ms
step:1099/1510 train_time:56004ms step_avg:50.96ms
step:1100/1510 train_time:56093ms step_avg:50.99ms
step:1101/1510 train_time:56175ms step_avg:51.02ms
step:1102/1510 train_time:56263ms step_avg:51.06ms
step:1103/1510 train_time:56345ms step_avg:51.08ms
step:1104/1510 train_time:56434ms step_avg:51.12ms
step:1105/1510 train_time:56517ms step_avg:51.15ms
step:1106/1510 train_time:56606ms step_avg:51.18ms
step:1107/1510 train_time:56689ms step_avg:51.21ms
step:1108/1510 train_time:56777ms step_avg:51.24ms
step:1109/1510 train_time:56860ms step_avg:51.27ms
step:1110/1510 train_time:56949ms step_avg:51.31ms
step:1111/1510 train_time:57031ms step_avg:51.33ms
step:1112/1510 train_time:57120ms step_avg:51.37ms
step:1113/1510 train_time:57204ms step_avg:51.40ms
step:1114/1510 train_time:57292ms step_avg:51.43ms
step:1115/1510 train_time:57375ms step_avg:51.46ms
step:1116/1510 train_time:57464ms step_avg:51.49ms
step:1117/1510 train_time:57547ms step_avg:51.52ms
step:1118/1510 train_time:57636ms step_avg:51.55ms
step:1119/1510 train_time:57719ms step_avg:51.58ms
step:1120/1510 train_time:57808ms step_avg:51.61ms
step:1121/1510 train_time:57890ms step_avg:51.64ms
step:1122/1510 train_time:57978ms step_avg:51.67ms
step:1123/1510 train_time:58062ms step_avg:51.70ms
step:1124/1510 train_time:58150ms step_avg:51.73ms
step:1125/1510 train_time:58232ms step_avg:51.76ms
step:1126/1510 train_time:58322ms step_avg:51.80ms
step:1127/1510 train_time:58405ms step_avg:51.82ms
step:1128/1510 train_time:58494ms step_avg:51.86ms
step:1129/1510 train_time:58578ms step_avg:51.88ms
step:1130/1510 train_time:58667ms step_avg:51.92ms
step:1131/1510 train_time:58749ms step_avg:51.94ms
step:1132/1510 train_time:58837ms step_avg:51.98ms
step:1133/1510 train_time:58920ms step_avg:52.00ms
step:1134/1510 train_time:59010ms step_avg:52.04ms
step:1135/1510 train_time:59092ms step_avg:52.06ms
step:1136/1510 train_time:59181ms step_avg:52.10ms
step:1137/1510 train_time:59264ms step_avg:52.12ms
step:1138/1510 train_time:59351ms step_avg:52.15ms
step:1139/1510 train_time:59435ms step_avg:52.18ms
step:1140/1510 train_time:59524ms step_avg:52.21ms
step:1141/1510 train_time:59609ms step_avg:52.24ms
step:1142/1510 train_time:59699ms step_avg:52.28ms
step:1143/1510 train_time:59782ms step_avg:52.30ms
step:1144/1510 train_time:59870ms step_avg:52.33ms
step:1145/1510 train_time:59953ms step_avg:52.36ms
step:1146/1510 train_time:60042ms step_avg:52.39ms
step:1147/1510 train_time:60124ms step_avg:52.42ms
step:1148/1510 train_time:60212ms step_avg:52.45ms
step:1149/1510 train_time:60295ms step_avg:52.48ms
step:1150/1510 train_time:60384ms step_avg:52.51ms
step:1151/1510 train_time:60467ms step_avg:52.53ms
step:1152/1510 train_time:60556ms step_avg:52.57ms
step:1153/1510 train_time:60640ms step_avg:52.59ms
step:1154/1510 train_time:60729ms step_avg:52.62ms
step:1155/1510 train_time:60811ms step_avg:52.65ms
step:1156/1510 train_time:60899ms step_avg:52.68ms
step:1157/1510 train_time:60983ms step_avg:52.71ms
step:1158/1510 train_time:61071ms step_avg:52.74ms
step:1159/1510 train_time:61153ms step_avg:52.76ms
step:1160/1510 train_time:61242ms step_avg:52.79ms
step:1161/1510 train_time:61324ms step_avg:52.82ms
step:1162/1510 train_time:61412ms step_avg:52.85ms
step:1163/1510 train_time:61495ms step_avg:52.88ms
step:1164/1510 train_time:61585ms step_avg:52.91ms
step:1165/1510 train_time:61668ms step_avg:52.93ms
step:1166/1510 train_time:61757ms step_avg:52.96ms
step:1167/1510 train_time:61840ms step_avg:52.99ms
step:1168/1510 train_time:61929ms step_avg:53.02ms
step:1169/1510 train_time:62011ms step_avg:53.05ms
step:1170/1510 train_time:62102ms step_avg:53.08ms
step:1171/1510 train_time:62185ms step_avg:53.10ms
step:1172/1510 train_time:62273ms step_avg:53.13ms
step:1173/1510 train_time:62356ms step_avg:53.16ms
step:1174/1510 train_time:62445ms step_avg:53.19ms
step:1175/1510 train_time:62528ms step_avg:53.21ms
step:1176/1510 train_time:62616ms step_avg:53.25ms
step:1177/1510 train_time:62698ms step_avg:53.27ms
step:1178/1510 train_time:62787ms step_avg:53.30ms
step:1179/1510 train_time:62870ms step_avg:53.33ms
step:1180/1510 train_time:62959ms step_avg:53.36ms
step:1181/1510 train_time:63043ms step_avg:53.38ms
step:1182/1510 train_time:63131ms step_avg:53.41ms
step:1183/1510 train_time:63214ms step_avg:53.44ms
step:1184/1510 train_time:63304ms step_avg:53.47ms
step:1185/1510 train_time:63387ms step_avg:53.49ms
step:1186/1510 train_time:63476ms step_avg:53.52ms
step:1187/1510 train_time:63560ms step_avg:53.55ms
step:1188/1510 train_time:63649ms step_avg:53.58ms
step:1189/1510 train_time:63732ms step_avg:53.60ms
step:1190/1510 train_time:63821ms step_avg:53.63ms
step:1191/1510 train_time:63906ms step_avg:53.66ms
step:1192/1510 train_time:63994ms step_avg:53.69ms
step:1193/1510 train_time:64077ms step_avg:53.71ms
step:1194/1510 train_time:64165ms step_avg:53.74ms
step:1195/1510 train_time:64248ms step_avg:53.76ms
step:1196/1510 train_time:64337ms step_avg:53.79ms
step:1197/1510 train_time:64420ms step_avg:53.82ms
step:1198/1510 train_time:64509ms step_avg:53.85ms
step:1199/1510 train_time:64592ms step_avg:53.87ms
step:1200/1510 train_time:64680ms step_avg:53.90ms
step:1201/1510 train_time:64764ms step_avg:53.92ms
step:1202/1510 train_time:64852ms step_avg:53.95ms
step:1203/1510 train_time:64935ms step_avg:53.98ms
step:1204/1510 train_time:65024ms step_avg:54.01ms
step:1205/1510 train_time:65106ms step_avg:54.03ms
step:1206/1510 train_time:65195ms step_avg:54.06ms
step:1207/1510 train_time:65278ms step_avg:54.08ms
step:1208/1510 train_time:65366ms step_avg:54.11ms
step:1209/1510 train_time:65449ms step_avg:54.13ms
step:1210/1510 train_time:65538ms step_avg:54.16ms
step:1211/1510 train_time:65621ms step_avg:54.19ms
step:1212/1510 train_time:65710ms step_avg:54.22ms
step:1213/1510 train_time:65793ms step_avg:54.24ms
step:1214/1510 train_time:65881ms step_avg:54.27ms
step:1215/1510 train_time:65966ms step_avg:54.29ms
step:1216/1510 train_time:66054ms step_avg:54.32ms
step:1217/1510 train_time:66137ms step_avg:54.34ms
step:1218/1510 train_time:66225ms step_avg:54.37ms
step:1219/1510 train_time:66308ms step_avg:54.40ms
step:1220/1510 train_time:66396ms step_avg:54.42ms
step:1221/1510 train_time:66479ms step_avg:54.45ms
step:1222/1510 train_time:66567ms step_avg:54.47ms
step:1223/1510 train_time:66650ms step_avg:54.50ms
step:1224/1510 train_time:66740ms step_avg:54.53ms
step:1225/1510 train_time:66824ms step_avg:54.55ms
step:1226/1510 train_time:66912ms step_avg:54.58ms
step:1227/1510 train_time:66995ms step_avg:54.60ms
step:1228/1510 train_time:67084ms step_avg:54.63ms
step:1229/1510 train_time:67167ms step_avg:54.65ms
step:1230/1510 train_time:67256ms step_avg:54.68ms
step:1231/1510 train_time:67339ms step_avg:54.70ms
step:1232/1510 train_time:67428ms step_avg:54.73ms
step:1233/1510 train_time:67511ms step_avg:54.75ms
step:1234/1510 train_time:67599ms step_avg:54.78ms
step:1235/1510 train_time:67682ms step_avg:54.80ms
step:1236/1510 train_time:67771ms step_avg:54.83ms
step:1237/1510 train_time:67854ms step_avg:54.85ms
step:1238/1510 train_time:67943ms step_avg:54.88ms
step:1239/1510 train_time:68027ms step_avg:54.90ms
step:1240/1510 train_time:68115ms step_avg:54.93ms
step:1241/1510 train_time:68198ms step_avg:54.95ms
step:1242/1510 train_time:68286ms step_avg:54.98ms
step:1243/1510 train_time:68368ms step_avg:55.00ms
step:1244/1510 train_time:68457ms step_avg:55.03ms
step:1245/1510 train_time:68540ms step_avg:55.05ms
step:1246/1510 train_time:68628ms step_avg:55.08ms
step:1247/1510 train_time:68711ms step_avg:55.10ms
step:1248/1510 train_time:68800ms step_avg:55.13ms
step:1249/1510 train_time:68883ms step_avg:55.15ms
step:1250/1510 train_time:68971ms step_avg:55.18ms
step:1250/1510 val_loss:3.3787 train_time:69068ms step_avg:55.25ms
step:1251/1510 train_time:69085ms step_avg:55.22ms
step:1252/1510 train_time:69149ms step_avg:55.23ms
step:1253/1510 train_time:69237ms step_avg:55.26ms
step:1254/1510 train_time:69326ms step_avg:55.28ms
step:1255/1510 train_time:69408ms step_avg:55.30ms
step:1256/1510 train_time:69496ms step_avg:55.33ms
step:1257/1510 train_time:69578ms step_avg:55.35ms
step:1258/1510 train_time:69666ms step_avg:55.38ms
step:1259/1510 train_time:69747ms step_avg:55.40ms
step:1260/1510 train_time:69835ms step_avg:55.42ms
step:1261/1510 train_time:69918ms step_avg:55.45ms
step:1262/1510 train_time:70008ms step_avg:55.47ms
step:1263/1510 train_time:70092ms step_avg:55.50ms
step:1264/1510 train_time:70185ms step_avg:55.53ms
step:1265/1510 train_time:70269ms step_avg:55.55ms
step:1266/1510 train_time:70359ms step_avg:55.58ms
step:1267/1510 train_time:70442ms step_avg:55.60ms
step:1268/1510 train_time:70530ms step_avg:55.62ms
step:1269/1510 train_time:70612ms step_avg:55.64ms
step:1270/1510 train_time:70699ms step_avg:55.67ms
step:1271/1510 train_time:70782ms step_avg:55.69ms
step:1272/1510 train_time:70869ms step_avg:55.71ms
step:1273/1510 train_time:70953ms step_avg:55.74ms
step:1274/1510 train_time:71042ms step_avg:55.76ms
step:1275/1510 train_time:71128ms step_avg:55.79ms
step:1276/1510 train_time:71218ms step_avg:55.81ms
step:1277/1510 train_time:71300ms step_avg:55.83ms
step:1278/1510 train_time:71389ms step_avg:55.86ms
step:1279/1510 train_time:71472ms step_avg:55.88ms
step:1280/1510 train_time:71560ms step_avg:55.91ms
step:1281/1510 train_time:71644ms step_avg:55.93ms
step:1282/1510 train_time:71732ms step_avg:55.95ms
step:1283/1510 train_time:71814ms step_avg:55.97ms
step:1284/1510 train_time:71902ms step_avg:56.00ms
step:1285/1510 train_time:71986ms step_avg:56.02ms
step:1286/1510 train_time:72074ms step_avg:56.05ms
step:1287/1510 train_time:72158ms step_avg:56.07ms
step:1288/1510 train_time:72247ms step_avg:56.09ms
step:1289/1510 train_time:72331ms step_avg:56.11ms
step:1290/1510 train_time:72420ms step_avg:56.14ms
step:1291/1510 train_time:72502ms step_avg:56.16ms
step:1292/1510 train_time:72590ms step_avg:56.18ms
step:1293/1510 train_time:72673ms step_avg:56.21ms
step:1294/1510 train_time:72762ms step_avg:56.23ms
step:1295/1510 train_time:72844ms step_avg:56.25ms
step:1296/1510 train_time:72932ms step_avg:56.27ms
step:1297/1510 train_time:73015ms step_avg:56.30ms
step:1298/1510 train_time:73105ms step_avg:56.32ms
step:1299/1510 train_time:73188ms step_avg:56.34ms
step:1300/1510 train_time:73278ms step_avg:56.37ms
step:1301/1510 train_time:73363ms step_avg:56.39ms
step:1302/1510 train_time:73452ms step_avg:56.41ms
step:1303/1510 train_time:73535ms step_avg:56.43ms
step:1304/1510 train_time:73623ms step_avg:56.46ms
step:1305/1510 train_time:73706ms step_avg:56.48ms
step:1306/1510 train_time:73794ms step_avg:56.50ms
step:1307/1510 train_time:73876ms step_avg:56.52ms
step:1308/1510 train_time:73964ms step_avg:56.55ms
step:1309/1510 train_time:74047ms step_avg:56.57ms
step:1310/1510 train_time:74137ms step_avg:56.59ms
step:1311/1510 train_time:74220ms step_avg:56.61ms
step:1312/1510 train_time:74308ms step_avg:56.64ms
step:1313/1510 train_time:74393ms step_avg:56.66ms
step:1314/1510 train_time:74482ms step_avg:56.68ms
step:1315/1510 train_time:74565ms step_avg:56.70ms
step:1316/1510 train_time:74653ms step_avg:56.73ms
step:1317/1510 train_time:74736ms step_avg:56.75ms
step:1318/1510 train_time:74825ms step_avg:56.77ms
step:1319/1510 train_time:74908ms step_avg:56.79ms
step:1320/1510 train_time:74996ms step_avg:56.82ms
step:1321/1510 train_time:75079ms step_avg:56.84ms
step:1322/1510 train_time:75168ms step_avg:56.86ms
step:1323/1510 train_time:75250ms step_avg:56.88ms
step:1324/1510 train_time:75340ms step_avg:56.90ms
step:1325/1510 train_time:75423ms step_avg:56.92ms
step:1326/1510 train_time:75513ms step_avg:56.95ms
step:1327/1510 train_time:75596ms step_avg:56.97ms
step:1328/1510 train_time:75684ms step_avg:56.99ms
step:1329/1510 train_time:75766ms step_avg:57.01ms
step:1330/1510 train_time:75854ms step_avg:57.03ms
step:1331/1510 train_time:75938ms step_avg:57.05ms
step:1332/1510 train_time:76028ms step_avg:57.08ms
step:1333/1510 train_time:76111ms step_avg:57.10ms
step:1334/1510 train_time:76200ms step_avg:57.12ms
step:1335/1510 train_time:76284ms step_avg:57.14ms
step:1336/1510 train_time:76372ms step_avg:57.16ms
step:1337/1510 train_time:76456ms step_avg:57.18ms
step:1338/1510 train_time:76545ms step_avg:57.21ms
step:1339/1510 train_time:76628ms step_avg:57.23ms
step:1340/1510 train_time:76717ms step_avg:57.25ms
step:1341/1510 train_time:76800ms step_avg:57.27ms
step:1342/1510 train_time:76887ms step_avg:57.29ms
step:1343/1510 train_time:76969ms step_avg:57.31ms
step:1344/1510 train_time:77058ms step_avg:57.34ms
step:1345/1510 train_time:77143ms step_avg:57.36ms
step:1346/1510 train_time:77231ms step_avg:57.38ms
step:1347/1510 train_time:77314ms step_avg:57.40ms
step:1348/1510 train_time:77403ms step_avg:57.42ms
step:1349/1510 train_time:77486ms step_avg:57.44ms
step:1350/1510 train_time:77575ms step_avg:57.46ms
step:1351/1510 train_time:77658ms step_avg:57.48ms
step:1352/1510 train_time:77746ms step_avg:57.50ms
step:1353/1510 train_time:77828ms step_avg:57.52ms
step:1354/1510 train_time:77917ms step_avg:57.55ms
step:1355/1510 train_time:78000ms step_avg:57.56ms
step:1356/1510 train_time:78088ms step_avg:57.59ms
step:1357/1510 train_time:78171ms step_avg:57.61ms
step:1358/1510 train_time:78261ms step_avg:57.63ms
step:1359/1510 train_time:78345ms step_avg:57.65ms
step:1360/1510 train_time:78434ms step_avg:57.67ms
step:1361/1510 train_time:78517ms step_avg:57.69ms
step:1362/1510 train_time:78607ms step_avg:57.71ms
step:1363/1510 train_time:78689ms step_avg:57.73ms
step:1364/1510 train_time:78778ms step_avg:57.75ms
step:1365/1510 train_time:78860ms step_avg:57.77ms
step:1366/1510 train_time:78948ms step_avg:57.80ms
step:1367/1510 train_time:79032ms step_avg:57.81ms
step:1368/1510 train_time:79121ms step_avg:57.84ms
step:1369/1510 train_time:79205ms step_avg:57.86ms
step:1370/1510 train_time:79294ms step_avg:57.88ms
step:1371/1510 train_time:79378ms step_avg:57.90ms
step:1372/1510 train_time:79467ms step_avg:57.92ms
step:1373/1510 train_time:79551ms step_avg:57.94ms
step:1374/1510 train_time:79640ms step_avg:57.96ms
step:1375/1510 train_time:79723ms step_avg:57.98ms
step:1376/1510 train_time:79812ms step_avg:58.00ms
step:1377/1510 train_time:79894ms step_avg:58.02ms
step:1378/1510 train_time:79983ms step_avg:58.04ms
step:1379/1510 train_time:80066ms step_avg:58.06ms
step:1380/1510 train_time:80154ms step_avg:58.08ms
step:1381/1510 train_time:80236ms step_avg:58.10ms
step:1382/1510 train_time:80326ms step_avg:58.12ms
step:1383/1510 train_time:80410ms step_avg:58.14ms
step:1384/1510 train_time:80499ms step_avg:58.16ms
step:1385/1510 train_time:80583ms step_avg:58.18ms
step:1386/1510 train_time:80672ms step_avg:58.20ms
step:1387/1510 train_time:80754ms step_avg:58.22ms
step:1388/1510 train_time:80843ms step_avg:58.24ms
step:1389/1510 train_time:80926ms step_avg:58.26ms
step:1390/1510 train_time:81014ms step_avg:58.28ms
step:1391/1510 train_time:81096ms step_avg:58.30ms
step:1392/1510 train_time:81185ms step_avg:58.32ms
step:1393/1510 train_time:81268ms step_avg:58.34ms
step:1394/1510 train_time:81357ms step_avg:58.36ms
step:1395/1510 train_time:81440ms step_avg:58.38ms
step:1396/1510 train_time:81529ms step_avg:58.40ms
step:1397/1510 train_time:81612ms step_avg:58.42ms
step:1398/1510 train_time:81701ms step_avg:58.44ms
step:1399/1510 train_time:81785ms step_avg:58.46ms
step:1400/1510 train_time:81873ms step_avg:58.48ms
step:1401/1510 train_time:81956ms step_avg:58.50ms
step:1402/1510 train_time:82045ms step_avg:58.52ms
step:1403/1510 train_time:82128ms step_avg:58.54ms
step:1404/1510 train_time:82217ms step_avg:58.56ms
step:1405/1510 train_time:82301ms step_avg:58.58ms
step:1406/1510 train_time:82389ms step_avg:58.60ms
step:1407/1510 train_time:82472ms step_avg:58.62ms
step:1408/1510 train_time:82561ms step_avg:58.64ms
step:1409/1510 train_time:82645ms step_avg:58.65ms
step:1410/1510 train_time:82733ms step_avg:58.68ms
step:1411/1510 train_time:82816ms step_avg:58.69ms
step:1412/1510 train_time:82904ms step_avg:58.71ms
step:1413/1510 train_time:82987ms step_avg:58.73ms
step:1414/1510 train_time:83076ms step_avg:58.75ms
step:1415/1510 train_time:83159ms step_avg:58.77ms
step:1416/1510 train_time:83248ms step_avg:58.79ms
step:1417/1510 train_time:83331ms step_avg:58.81ms
step:1418/1510 train_time:83421ms step_avg:58.83ms
step:1419/1510 train_time:83505ms step_avg:58.85ms
step:1420/1510 train_time:83593ms step_avg:58.87ms
step:1421/1510 train_time:83677ms step_avg:58.89ms
step:1422/1510 train_time:83767ms step_avg:58.91ms
step:1423/1510 train_time:83850ms step_avg:58.92ms
step:1424/1510 train_time:83939ms step_avg:58.95ms
step:1425/1510 train_time:84021ms step_avg:58.96ms
step:1426/1510 train_time:84109ms step_avg:58.98ms
step:1427/1510 train_time:84192ms step_avg:59.00ms
step:1428/1510 train_time:84282ms step_avg:59.02ms
step:1429/1510 train_time:84365ms step_avg:59.04ms
step:1430/1510 train_time:84454ms step_avg:59.06ms
step:1431/1510 train_time:84537ms step_avg:59.08ms
step:1432/1510 train_time:84626ms step_avg:59.10ms
step:1433/1510 train_time:84709ms step_avg:59.11ms
step:1434/1510 train_time:84800ms step_avg:59.14ms
step:1435/1510 train_time:84883ms step_avg:59.15ms
step:1436/1510 train_time:84971ms step_avg:59.17ms
step:1437/1510 train_time:85054ms step_avg:59.19ms
step:1438/1510 train_time:85142ms step_avg:59.21ms
step:1439/1510 train_time:85225ms step_avg:59.23ms
step:1440/1510 train_time:85313ms step_avg:59.25ms
step:1441/1510 train_time:85396ms step_avg:59.26ms
step:1442/1510 train_time:85484ms step_avg:59.28ms
step:1443/1510 train_time:85567ms step_avg:59.30ms
step:1444/1510 train_time:85655ms step_avg:59.32ms
step:1445/1510 train_time:85739ms step_avg:59.33ms
step:1446/1510 train_time:85827ms step_avg:59.36ms
step:1447/1510 train_time:85909ms step_avg:59.37ms
step:1448/1510 train_time:85998ms step_avg:59.39ms
step:1449/1510 train_time:86082ms step_avg:59.41ms
step:1450/1510 train_time:86170ms step_avg:59.43ms
step:1451/1510 train_time:86253ms step_avg:59.44ms
step:1452/1510 train_time:86343ms step_avg:59.46ms
step:1453/1510 train_time:86426ms step_avg:59.48ms
step:1454/1510 train_time:86515ms step_avg:59.50ms
step:1455/1510 train_time:86600ms step_avg:59.52ms
step:1456/1510 train_time:86689ms step_avg:59.54ms
step:1457/1510 train_time:86772ms step_avg:59.56ms
step:1458/1510 train_time:86862ms step_avg:59.58ms
step:1459/1510 train_time:86944ms step_avg:59.59ms
step:1460/1510 train_time:87033ms step_avg:59.61ms
step:1461/1510 train_time:87116ms step_avg:59.63ms
step:1462/1510 train_time:87204ms step_avg:59.65ms
step:1463/1510 train_time:87287ms step_avg:59.66ms
step:1464/1510 train_time:87376ms step_avg:59.68ms
step:1465/1510 train_time:87458ms step_avg:59.70ms
step:1466/1510 train_time:87546ms step_avg:59.72ms
step:1467/1510 train_time:87628ms step_avg:59.73ms
step:1468/1510 train_time:87718ms step_avg:59.75ms
step:1469/1510 train_time:87801ms step_avg:59.77ms
step:1470/1510 train_time:87890ms step_avg:59.79ms
step:1471/1510 train_time:87976ms step_avg:59.81ms
step:1472/1510 train_time:88066ms step_avg:59.83ms
step:1473/1510 train_time:88148ms step_avg:59.84ms
step:1474/1510 train_time:88237ms step_avg:59.86ms
step:1475/1510 train_time:88321ms step_avg:59.88ms
step:1476/1510 train_time:88410ms step_avg:59.90ms
step:1477/1510 train_time:88494ms step_avg:59.91ms
step:1478/1510 train_time:88583ms step_avg:59.93ms
step:1479/1510 train_time:88666ms step_avg:59.95ms
step:1480/1510 train_time:88755ms step_avg:59.97ms
step:1481/1510 train_time:88838ms step_avg:59.99ms
step:1482/1510 train_time:88928ms step_avg:60.01ms
step:1483/1510 train_time:89013ms step_avg:60.02ms
step:1484/1510 train_time:89102ms step_avg:60.04ms
step:1485/1510 train_time:89185ms step_avg:60.06ms
step:1486/1510 train_time:89274ms step_avg:60.08ms
step:1487/1510 train_time:89357ms step_avg:60.09ms
step:1488/1510 train_time:89446ms step_avg:60.11ms
step:1489/1510 train_time:89529ms step_avg:60.13ms
step:1490/1510 train_time:89618ms step_avg:60.15ms
step:1491/1510 train_time:89702ms step_avg:60.16ms
step:1492/1510 train_time:89790ms step_avg:60.18ms
step:1493/1510 train_time:89874ms step_avg:60.20ms
step:1494/1510 train_time:89963ms step_avg:60.22ms
step:1495/1510 train_time:90046ms step_avg:60.23ms
step:1496/1510 train_time:90136ms step_avg:60.25ms
step:1497/1510 train_time:90220ms step_avg:60.27ms
step:1498/1510 train_time:90309ms step_avg:60.29ms
step:1499/1510 train_time:90393ms step_avg:60.30ms
step:1500/1510 train_time:90482ms step_avg:60.32ms
step:1500/1510 val_loss:3.2825 train_time:90579ms step_avg:60.39ms
step:1501/1510 train_time:90596ms step_avg:60.36ms
step:1502/1510 train_time:90660ms step_avg:60.36ms
step:1503/1510 train_time:90748ms step_avg:60.38ms
step:1504/1510 train_time:90838ms step_avg:60.40ms
step:1505/1510 train_time:90920ms step_avg:60.41ms
step:1506/1510 train_time:91009ms step_avg:60.43ms
step:1507/1510 train_time:91092ms step_avg:60.45ms
step:1508/1510 train_time:91180ms step_avg:60.46ms
step:1509/1510 train_time:91263ms step_avg:60.48ms
step:1510/1510 train_time:91352ms step_avg:60.50ms
step:1510/1510 val_loss:3.2783 train_time:91448ms step_avg:60.56ms
peak memory allocated: 31615 MiB reserved: 49160 MiB
