import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import copy
import glob
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
#torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.T.contiguous().T.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        param_groups = []
        for size in {p.numel() for p in params}:
            b = torch.empty(world_size, size, dtype=torch.bfloat16, device="cuda")
            group = dict(params=[p for p in params if p.numel() == size],
                         update_buffer=b, update_buffer_views=[b[i] for i in range(world_size)])
            param_groups.append(group)
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            update_buffer: Tensor = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(g_world.view_as(p_world),
                                 alpha=-group["lr"] * max(1, p_world.size(-2) / p_world.size(-1))**0.5)
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - group["momentum"])
                    g = g.lerp_(buf, group["momentum"]) if group["nesterov"] else buf
                    g = zeropower_via_newtonschulz5(g, steps=group["ns_steps"]).flatten()
                else:
                    g = update_buffer_views[self.rank]
                if base_i > 0:
                    update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=0.12).transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, max_seq_len, i) for i in range(num_layers)])
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128),
                                    use_fp8=True, x_s=(model_dim**0.5)/448, w_s=24/448, grad_s=1/448)
        self.lm_head.weight.detach().zero_() # @Grad62304977
        # Add learnable skip connection weights for decoder layers
        assert num_layers % 2 == 0
        self.skip_weights = nn.Parameter(torch.ones(num_layers//2))

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        # manual block mask creation by @YouJiacheng
        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all
        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)
        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
        # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2]] + [None] * (len(self.blocks) - 6) + [ve[0], ve[1], ve[2]]
        assert len(ve) == len(self.blocks)

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, long_bm, short_bm, short_bm, short_bm, long_bm]
        assert len(block_masks) == len(self.blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977

        # U-net design by @brendanh0gan
        skip_connections = []
        n = len(self.skip_weights)
        for i in range(len(self.blocks)):
            if i >= n:
                x = x + self.skip_weights[i - n] * skip_connections.pop()
            x = self.blocks[i](x, ve[i], x0, block_masks[i])
            if i < n:
                skip_connections.append(x)

        x = norm(x)
        logits = self.lm_head(x).float()
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits / (7.5 * x.size(-1)**0.5))
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq, reduction='sum' if self.training else 'mean')
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn't helpful.
        pos += batch_size
        yield inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    train_seq_len = 48*1024 # FlexAttention sequence length
    val_seq_len = 4*64*1024 # FlexAttention sequence length for validation
    # optimization
    num_iterations = 1770 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    # architecture
    vocab_size = 50257
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint = False
args = Hyperparameters()

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert world_size == 8 # this code is designed for 8xH100
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

########################################
#    Construct model and optimizer     #
########################################

model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,
                       max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()
for m in model.modules():
    if isinstance(m, nn.Embedding):
        m.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

# collect the parameters to optimize
hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and "embed" not in n]
embed_params = [p for n, p in model.named_parameters() if "embed" in n]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
adam_params = [dict(params=head_params, lr=0.22), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]
# small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
# discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95, rank=rank, world_size=world_size)
optimizers = [optimizer1, optimizer2]
for opt in optimizers:
    for group in opt.param_groups:
        group["initial_lr"] = group["lr"]

# learning rate schedule: stable then decay
def get_lr(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x < 1
    if x < 1 - args.cooldown_frac:
        return 1.0
    else:
        w = (1 - x) / args.cooldown_frac
        return w * 1.0 + (1 - w) * 0.1

# attention window size schedule: linearly increase
@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)
def get_window_size_blocks(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x <= 1
    # Linearly increase the block-wise sliding window size over training 128 -> 1792
    # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
    window_size = next_multiple_of_n(1728 * x, n=128)
    return get_window_size_blocks_helper(window_size)

model: nn.Module = torch.compile(model, dynamic=False)

########################################
#            Warmup kernels            #
########################################

# Warmup the training kernels, then re-initialize the state so we aren't cheating
warmup_steps = 10
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=[copy.deepcopy(opt.state_dict()) for opt in optimizers]) # save the initial state
for _ in range(warmup_steps):
    inputs = targets = torch.randint(0, args.vocab_size, size=(args.train_seq_len,), device="cuda")
    model(inputs.to(torch.int32), targets, get_window_size_blocks(0)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
    opt.load_state_dict(opt_state)
del initial_state

########################################
#        Training and validation       #
########################################

train_loader = distributed_data_generator(args.train_files, world_size * args.train_seq_len, rank, world_size)
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, get_window_size_blocks(step))
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    inputs, targets = next(train_loader)
    model(inputs, targets, get_window_size_blocks(step)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    # set optimization hyperparameters
    for opt in optimizers:
        for group in opt.param_groups:
            group["lr"] = group["initial_lr"] * get_lr(step)
    for group in optimizer2.param_groups:
        frac = min(step / 300, 1) # momentum warmup for muon
        group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers
    for opt in optimizers:
        opt.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.12.7 (main, May 24 2025, 20:59:58) [GCC 13.2.0]
Running PyTorch 2.8.0.dev20250524+cu126 compiled for CUDA 12.6
Sat May 24 21:13:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |
| N/A   31C    P0            118W /  700W |    5856MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:62:00.0 Off |                    0 |
| N/A   31C    P0            121W /  700W |    1518MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:63:00.0 Off |                    0 |
| N/A   32C    P0            119W /  700W |    1518MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:64:00.0 Off |                    0 |
| N/A   28C    P0            111W /  700W |    1518MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:6A:00.0 Off |                    0 |
| N/A   28C    P0            116W /  700W |    1518MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:6B:00.0 Off |                    0 |
| N/A   32C    P0            117W /  700W |    1518MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:6C:00.0 Off |                    0 |
| N/A   31C    P0            115W /  700W |    1518MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:6D:00.0 Off |                    0 |
| N/A   28C    P0            113W /  700W |    1518MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A           13252      C   /usr/local/bin/python                  1508MiB |
|    0   N/A  N/A           13253      C   /usr/local/bin/python                   614MiB |
|    0   N/A  N/A           13254      C   /usr/local/bin/python                   614MiB |
|    0   N/A  N/A           13255      C   /usr/local/bin/python                   614MiB |
|    0   N/A  N/A           13256      C   /usr/local/bin/python                   614MiB |
|    0   N/A  N/A           13257      C   /usr/local/bin/python                   614MiB |
|    0   N/A  N/A           13258      C   /usr/local/bin/python                   614MiB |
|    0   N/A  N/A           13259      C   /usr/local/bin/python                   614MiB |
|    1   N/A  N/A           13253      C   /usr/local/bin/python                  1508MiB |
|    2   N/A  N/A           13254      C   /usr/local/bin/python                  1508MiB |
|    3   N/A  N/A           13255      C   /usr/local/bin/python                  1508MiB |
|    4   N/A  N/A           13256      C   /usr/local/bin/python                  1508MiB |
|    5   N/A  N/A           13257      C   /usr/local/bin/python                  1508MiB |
|    6   N/A  N/A           13258      C   /usr/local/bin/python                  1508MiB |
|    7   N/A  N/A           13259      C   /usr/local/bin/python                  1508MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1770 val_loss:10.8258 train_time:0ms step_avg:0.03ms
step:1/1770 train_time:90ms step_avg:90.20ms
step:2/1770 train_time:162ms step_avg:81.06ms
step:3/1770 train_time:252ms step_avg:83.89ms
step:4/1770 train_time:347ms step_avg:86.63ms
step:5/1770 train_time:442ms step_avg:88.34ms
step:6/1770 train_time:537ms step_avg:89.51ms
step:7/1770 train_time:633ms step_avg:90.42ms
step:8/1770 train_time:730ms step_avg:91.22ms
step:9/1770 train_time:825ms step_avg:91.68ms
step:10/1770 train_time:921ms step_avg:92.10ms
step:11/1770 train_time:1016ms step_avg:92.39ms
step:12/1770 train_time:1113ms step_avg:92.74ms
step:13/1770 train_time:1211ms step_avg:93.19ms
step:14/1770 train_time:1309ms step_avg:93.47ms
step:15/1770 train_time:1405ms step_avg:93.64ms
step:16/1770 train_time:1500ms step_avg:93.77ms
step:17/1770 train_time:1596ms step_avg:93.88ms
step:18/1770 train_time:1693ms step_avg:94.04ms
step:19/1770 train_time:1789ms step_avg:94.14ms
step:20/1770 train_time:1884ms step_avg:94.20ms
step:21/1770 train_time:1980ms step_avg:94.28ms
step:22/1770 train_time:2075ms step_avg:94.32ms
step:23/1770 train_time:2170ms step_avg:94.36ms
step:24/1770 train_time:2267ms step_avg:94.45ms
step:25/1770 train_time:2363ms step_avg:94.52ms
step:26/1770 train_time:2459ms step_avg:94.58ms
step:27/1770 train_time:2556ms step_avg:94.65ms
step:28/1770 train_time:2651ms step_avg:94.70ms
step:29/1770 train_time:2747ms step_avg:94.73ms
step:30/1770 train_time:2843ms step_avg:94.76ms
step:31/1770 train_time:2939ms step_avg:94.79ms
step:32/1770 train_time:3034ms step_avg:94.82ms
step:33/1770 train_time:3131ms step_avg:94.88ms
step:34/1770 train_time:3227ms step_avg:94.90ms
step:35/1770 train_time:3322ms step_avg:94.92ms
step:36/1770 train_time:3418ms step_avg:94.95ms
step:37/1770 train_time:3514ms step_avg:94.97ms
step:38/1770 train_time:3610ms step_avg:95.01ms
step:39/1770 train_time:3706ms step_avg:95.03ms
step:40/1770 train_time:3802ms step_avg:95.06ms
step:41/1770 train_time:3898ms step_avg:95.07ms
step:42/1770 train_time:3993ms step_avg:95.08ms
step:43/1770 train_time:4090ms step_avg:95.12ms
step:44/1770 train_time:4186ms step_avg:95.14ms
step:45/1770 train_time:4282ms step_avg:95.16ms
step:46/1770 train_time:4378ms step_avg:95.17ms
step:47/1770 train_time:4473ms step_avg:95.18ms
step:48/1770 train_time:4570ms step_avg:95.20ms
step:49/1770 train_time:4666ms step_avg:95.23ms
step:50/1770 train_time:4762ms step_avg:95.25ms
step:51/1770 train_time:4858ms step_avg:95.26ms
step:52/1770 train_time:4954ms step_avg:95.27ms
step:53/1770 train_time:5049ms step_avg:95.27ms
step:54/1770 train_time:5144ms step_avg:95.26ms
step:55/1770 train_time:5240ms step_avg:95.27ms
step:56/1770 train_time:5336ms step_avg:95.28ms
step:57/1770 train_time:5433ms step_avg:95.32ms
step:58/1770 train_time:5530ms step_avg:95.34ms
step:59/1770 train_time:5625ms step_avg:95.34ms
step:60/1770 train_time:5721ms step_avg:95.36ms
step:61/1770 train_time:5818ms step_avg:95.37ms
step:62/1770 train_time:5914ms step_avg:95.39ms
step:63/1770 train_time:6010ms step_avg:95.40ms
step:64/1770 train_time:6106ms step_avg:95.40ms
step:65/1770 train_time:6201ms step_avg:95.41ms
step:66/1770 train_time:6297ms step_avg:95.41ms
step:67/1770 train_time:6393ms step_avg:95.42ms
step:68/1770 train_time:6489ms step_avg:95.43ms
step:69/1770 train_time:6586ms step_avg:95.45ms
step:70/1770 train_time:6682ms step_avg:95.46ms
step:71/1770 train_time:6778ms step_avg:95.46ms
step:72/1770 train_time:6874ms step_avg:95.47ms
step:73/1770 train_time:6970ms step_avg:95.48ms
step:74/1770 train_time:7066ms step_avg:95.48ms
step:75/1770 train_time:7161ms step_avg:95.48ms
step:76/1770 train_time:7257ms step_avg:95.48ms
step:77/1770 train_time:7352ms step_avg:95.49ms
step:78/1770 train_time:7448ms step_avg:95.48ms
step:79/1770 train_time:7544ms step_avg:95.49ms
step:80/1770 train_time:7640ms step_avg:95.50ms
step:81/1770 train_time:7735ms step_avg:95.50ms
step:82/1770 train_time:7831ms step_avg:95.49ms
step:83/1770 train_time:7928ms step_avg:95.51ms
step:84/1770 train_time:8023ms step_avg:95.51ms
step:85/1770 train_time:8119ms step_avg:95.51ms
step:86/1770 train_time:8215ms step_avg:95.52ms
step:87/1770 train_time:8310ms step_avg:95.52ms
step:88/1770 train_time:8406ms step_avg:95.52ms
step:89/1770 train_time:8502ms step_avg:95.53ms
step:90/1770 train_time:8598ms step_avg:95.53ms
step:91/1770 train_time:8694ms step_avg:95.54ms
step:92/1770 train_time:8791ms step_avg:95.55ms
step:93/1770 train_time:8887ms step_avg:95.56ms
step:94/1770 train_time:8983ms step_avg:95.56ms
step:95/1770 train_time:9078ms step_avg:95.56ms
step:96/1770 train_time:9174ms step_avg:95.56ms
step:97/1770 train_time:9269ms step_avg:95.56ms
step:98/1770 train_time:9366ms step_avg:95.57ms
step:99/1770 train_time:9461ms step_avg:95.57ms
step:100/1770 train_time:9556ms step_avg:95.56ms
step:101/1770 train_time:9652ms step_avg:95.57ms
step:102/1770 train_time:9749ms step_avg:95.57ms
step:103/1770 train_time:9844ms step_avg:95.58ms
step:104/1770 train_time:9940ms step_avg:95.58ms
step:105/1770 train_time:10036ms step_avg:95.58ms
step:106/1770 train_time:10132ms step_avg:95.58ms
step:107/1770 train_time:10227ms step_avg:95.58ms
step:108/1770 train_time:10323ms step_avg:95.58ms
step:109/1770 train_time:10419ms step_avg:95.59ms
step:110/1770 train_time:10514ms step_avg:95.59ms
step:111/1770 train_time:10610ms step_avg:95.59ms
step:112/1770 train_time:10706ms step_avg:95.59ms
step:113/1770 train_time:10802ms step_avg:95.59ms
step:114/1770 train_time:10898ms step_avg:95.59ms
step:115/1770 train_time:10994ms step_avg:95.60ms
step:116/1770 train_time:11091ms step_avg:95.61ms
step:117/1770 train_time:11188ms step_avg:95.62ms
step:118/1770 train_time:11284ms step_avg:95.63ms
step:119/1770 train_time:11380ms step_avg:95.63ms
step:120/1770 train_time:11476ms step_avg:95.63ms
step:121/1770 train_time:11572ms step_avg:95.63ms
step:122/1770 train_time:11668ms step_avg:95.64ms
step:123/1770 train_time:11763ms step_avg:95.64ms
step:124/1770 train_time:11859ms step_avg:95.63ms
step:125/1770 train_time:11953ms step_avg:95.63ms
step:125/1770 val_loss:4.6368 train_time:12044ms step_avg:96.35ms
step:126/1770 train_time:12072ms step_avg:95.81ms
step:127/1770 train_time:12149ms step_avg:95.66ms
step:128/1770 train_time:12256ms step_avg:95.75ms
step:129/1770 train_time:12354ms step_avg:95.77ms
step:130/1770 train_time:12450ms step_avg:95.77ms
step:131/1770 train_time:12546ms step_avg:95.77ms
step:132/1770 train_time:12641ms step_avg:95.76ms
step:133/1770 train_time:12736ms step_avg:95.76ms
step:134/1770 train_time:12832ms step_avg:95.76ms
step:135/1770 train_time:12927ms step_avg:95.76ms
step:136/1770 train_time:13023ms step_avg:95.76ms
step:137/1770 train_time:13119ms step_avg:95.76ms
step:138/1770 train_time:13216ms step_avg:95.77ms
step:139/1770 train_time:13313ms step_avg:95.78ms
step:140/1770 train_time:13410ms step_avg:95.79ms
step:141/1770 train_time:13508ms step_avg:95.80ms
step:142/1770 train_time:13606ms step_avg:95.81ms
step:143/1770 train_time:13702ms step_avg:95.82ms
step:144/1770 train_time:13799ms step_avg:95.83ms
step:145/1770 train_time:13894ms step_avg:95.82ms
step:146/1770 train_time:13990ms step_avg:95.83ms
step:147/1770 train_time:14087ms step_avg:95.83ms
step:148/1770 train_time:14184ms step_avg:95.83ms
step:149/1770 train_time:14280ms step_avg:95.84ms
step:150/1770 train_time:14376ms step_avg:95.84ms
step:151/1770 train_time:14473ms step_avg:95.85ms
step:152/1770 train_time:14569ms step_avg:95.85ms
step:153/1770 train_time:14666ms step_avg:95.86ms
step:154/1770 train_time:14763ms step_avg:95.87ms
step:155/1770 train_time:14860ms step_avg:95.87ms
step:156/1770 train_time:14956ms step_avg:95.87ms
step:157/1770 train_time:15053ms step_avg:95.88ms
step:158/1770 train_time:15149ms step_avg:95.88ms
step:159/1770 train_time:15246ms step_avg:95.88ms
step:160/1770 train_time:15341ms step_avg:95.88ms
step:161/1770 train_time:15438ms step_avg:95.89ms
step:162/1770 train_time:15533ms step_avg:95.89ms
step:163/1770 train_time:15630ms step_avg:95.89ms
step:164/1770 train_time:15727ms step_avg:95.90ms
step:165/1770 train_time:15823ms step_avg:95.90ms
step:166/1770 train_time:15920ms step_avg:95.90ms
step:167/1770 train_time:16017ms step_avg:95.91ms
step:168/1770 train_time:16113ms step_avg:95.91ms
step:169/1770 train_time:16210ms step_avg:95.92ms
step:170/1770 train_time:16308ms step_avg:95.93ms
step:171/1770 train_time:16405ms step_avg:95.94ms
step:172/1770 train_time:16502ms step_avg:95.94ms
step:173/1770 train_time:16598ms step_avg:95.94ms
step:174/1770 train_time:16694ms step_avg:95.94ms
step:175/1770 train_time:16791ms step_avg:95.95ms
step:176/1770 train_time:16888ms step_avg:95.95ms
step:177/1770 train_time:16985ms step_avg:95.96ms
step:178/1770 train_time:17081ms step_avg:95.96ms
step:179/1770 train_time:17177ms step_avg:95.96ms
step:180/1770 train_time:17274ms step_avg:95.97ms
step:181/1770 train_time:17371ms step_avg:95.97ms
step:182/1770 train_time:17468ms step_avg:95.98ms
step:183/1770 train_time:17566ms step_avg:95.99ms
step:184/1770 train_time:17663ms step_avg:95.99ms
step:185/1770 train_time:17758ms step_avg:95.99ms
step:186/1770 train_time:17854ms step_avg:95.99ms
step:187/1770 train_time:17951ms step_avg:95.99ms
step:188/1770 train_time:18050ms step_avg:96.01ms
step:189/1770 train_time:18146ms step_avg:96.01ms
step:190/1770 train_time:18243ms step_avg:96.02ms
step:191/1770 train_time:18339ms step_avg:96.02ms
step:192/1770 train_time:18435ms step_avg:96.02ms
step:193/1770 train_time:18531ms step_avg:96.02ms
step:194/1770 train_time:18628ms step_avg:96.02ms
step:195/1770 train_time:18724ms step_avg:96.02ms
step:196/1770 train_time:18820ms step_avg:96.02ms
step:197/1770 train_time:18916ms step_avg:96.02ms
step:198/1770 train_time:19013ms step_avg:96.02ms
step:199/1770 train_time:19110ms step_avg:96.03ms
step:200/1770 train_time:19207ms step_avg:96.04ms
step:201/1770 train_time:19305ms step_avg:96.05ms
step:202/1770 train_time:19402ms step_avg:96.05ms
step:203/1770 train_time:19498ms step_avg:96.05ms
step:204/1770 train_time:19594ms step_avg:96.05ms
step:205/1770 train_time:19691ms step_avg:96.05ms
step:206/1770 train_time:19787ms step_avg:96.05ms
step:207/1770 train_time:19884ms step_avg:96.06ms
step:208/1770 train_time:19980ms step_avg:96.06ms
step:209/1770 train_time:20077ms step_avg:96.06ms
step:210/1770 train_time:20173ms step_avg:96.06ms
step:211/1770 train_time:20270ms step_avg:96.06ms
step:212/1770 train_time:20367ms step_avg:96.07ms
step:213/1770 train_time:20463ms step_avg:96.07ms
step:214/1770 train_time:20559ms step_avg:96.07ms
step:215/1770 train_time:20656ms step_avg:96.07ms
step:216/1770 train_time:20752ms step_avg:96.07ms
step:217/1770 train_time:20848ms step_avg:96.07ms
step:218/1770 train_time:20945ms step_avg:96.08ms
step:219/1770 train_time:21042ms step_avg:96.08ms
step:220/1770 train_time:21138ms step_avg:96.08ms
step:221/1770 train_time:21234ms step_avg:96.08ms
step:222/1770 train_time:21331ms step_avg:96.09ms
step:223/1770 train_time:21429ms step_avg:96.09ms
step:224/1770 train_time:21526ms step_avg:96.10ms
step:225/1770 train_time:21622ms step_avg:96.10ms
step:226/1770 train_time:21719ms step_avg:96.10ms
step:227/1770 train_time:21815ms step_avg:96.10ms
step:228/1770 train_time:21911ms step_avg:96.10ms
step:229/1770 train_time:22008ms step_avg:96.10ms
step:230/1770 train_time:22105ms step_avg:96.11ms
step:231/1770 train_time:22202ms step_avg:96.11ms
step:232/1770 train_time:22298ms step_avg:96.11ms
step:233/1770 train_time:22394ms step_avg:96.11ms
step:234/1770 train_time:22492ms step_avg:96.12ms
step:235/1770 train_time:22588ms step_avg:96.12ms
step:236/1770 train_time:22684ms step_avg:96.12ms
step:237/1770 train_time:22781ms step_avg:96.12ms
step:238/1770 train_time:22877ms step_avg:96.12ms
step:239/1770 train_time:22973ms step_avg:96.12ms
step:240/1770 train_time:23070ms step_avg:96.12ms
step:241/1770 train_time:23166ms step_avg:96.13ms
step:242/1770 train_time:23262ms step_avg:96.12ms
step:243/1770 train_time:23358ms step_avg:96.12ms
step:244/1770 train_time:23454ms step_avg:96.12ms
step:245/1770 train_time:23551ms step_avg:96.12ms
step:246/1770 train_time:23648ms step_avg:96.13ms
step:247/1770 train_time:23745ms step_avg:96.13ms
step:248/1770 train_time:23842ms step_avg:96.14ms
step:249/1770 train_time:23939ms step_avg:96.14ms
step:250/1770 train_time:24035ms step_avg:96.14ms
step:250/1770 val_loss:4.0996 train_time:24126ms step_avg:96.51ms
step:251/1770 train_time:24155ms step_avg:96.23ms
step:252/1770 train_time:24235ms step_avg:96.17ms
step:253/1770 train_time:24335ms step_avg:96.18ms
step:254/1770 train_time:24431ms step_avg:96.19ms
step:255/1770 train_time:24529ms step_avg:96.19ms
step:256/1770 train_time:24624ms step_avg:96.19ms
step:257/1770 train_time:24719ms step_avg:96.18ms
step:258/1770 train_time:24815ms step_avg:96.18ms
step:259/1770 train_time:24912ms step_avg:96.18ms
step:260/1770 train_time:25008ms step_avg:96.18ms
step:261/1770 train_time:25104ms step_avg:96.18ms
step:262/1770 train_time:25200ms step_avg:96.18ms
step:263/1770 train_time:25297ms step_avg:96.18ms
step:264/1770 train_time:25393ms step_avg:96.19ms
step:265/1770 train_time:25491ms step_avg:96.19ms
step:266/1770 train_time:25588ms step_avg:96.20ms
step:267/1770 train_time:25685ms step_avg:96.20ms
step:268/1770 train_time:25782ms step_avg:96.20ms
step:269/1770 train_time:25878ms step_avg:96.20ms
step:270/1770 train_time:25975ms step_avg:96.20ms
step:271/1770 train_time:26073ms step_avg:96.21ms
step:272/1770 train_time:26170ms step_avg:96.21ms
step:273/1770 train_time:26267ms step_avg:96.22ms
step:274/1770 train_time:26363ms step_avg:96.22ms
step:275/1770 train_time:26460ms step_avg:96.22ms
step:276/1770 train_time:26557ms step_avg:96.22ms
step:277/1770 train_time:26653ms step_avg:96.22ms
step:278/1770 train_time:26750ms step_avg:96.22ms
step:279/1770 train_time:26847ms step_avg:96.22ms
step:280/1770 train_time:26944ms step_avg:96.23ms
step:281/1770 train_time:27040ms step_avg:96.23ms
step:282/1770 train_time:27138ms step_avg:96.23ms
step:283/1770 train_time:27235ms step_avg:96.24ms
step:284/1770 train_time:27333ms step_avg:96.24ms
step:285/1770 train_time:27431ms step_avg:96.25ms
step:286/1770 train_time:27529ms step_avg:96.25ms
step:287/1770 train_time:27625ms step_avg:96.25ms
step:288/1770 train_time:27722ms step_avg:96.26ms
step:289/1770 train_time:27819ms step_avg:96.26ms
step:290/1770 train_time:27915ms step_avg:96.26ms
step:291/1770 train_time:28012ms step_avg:96.26ms
step:292/1770 train_time:28110ms step_avg:96.27ms
step:293/1770 train_time:28207ms step_avg:96.27ms
step:294/1770 train_time:28304ms step_avg:96.27ms
step:295/1770 train_time:28402ms step_avg:96.28ms
step:296/1770 train_time:28498ms step_avg:96.28ms
step:297/1770 train_time:28597ms step_avg:96.29ms
step:298/1770 train_time:28694ms step_avg:96.29ms
step:299/1770 train_time:28792ms step_avg:96.30ms
step:300/1770 train_time:28889ms step_avg:96.30ms
step:301/1770 train_time:28986ms step_avg:96.30ms
step:302/1770 train_time:29083ms step_avg:96.30ms
step:303/1770 train_time:29180ms step_avg:96.30ms
step:304/1770 train_time:29277ms step_avg:96.31ms
step:305/1770 train_time:29374ms step_avg:96.31ms
step:306/1770 train_time:29471ms step_avg:96.31ms
step:307/1770 train_time:29568ms step_avg:96.31ms
step:308/1770 train_time:29665ms step_avg:96.31ms
step:309/1770 train_time:29762ms step_avg:96.32ms
step:310/1770 train_time:29859ms step_avg:96.32ms
step:311/1770 train_time:29955ms step_avg:96.32ms
step:312/1770 train_time:30052ms step_avg:96.32ms
step:313/1770 train_time:30149ms step_avg:96.32ms
step:314/1770 train_time:30246ms step_avg:96.32ms
step:315/1770 train_time:30343ms step_avg:96.33ms
step:316/1770 train_time:30440ms step_avg:96.33ms
step:317/1770 train_time:30537ms step_avg:96.33ms
step:318/1770 train_time:30634ms step_avg:96.33ms
step:319/1770 train_time:30732ms step_avg:96.34ms
step:320/1770 train_time:30829ms step_avg:96.34ms
step:321/1770 train_time:30926ms step_avg:96.34ms
step:322/1770 train_time:31023ms step_avg:96.34ms
step:323/1770 train_time:31120ms step_avg:96.35ms
step:324/1770 train_time:31217ms step_avg:96.35ms
step:325/1770 train_time:31315ms step_avg:96.35ms
step:326/1770 train_time:31412ms step_avg:96.36ms
step:327/1770 train_time:31509ms step_avg:96.36ms
step:328/1770 train_time:31606ms step_avg:96.36ms
step:329/1770 train_time:31703ms step_avg:96.36ms
step:330/1770 train_time:31800ms step_avg:96.36ms
step:331/1770 train_time:31897ms step_avg:96.37ms
step:332/1770 train_time:31994ms step_avg:96.37ms
step:333/1770 train_time:32091ms step_avg:96.37ms
step:334/1770 train_time:32188ms step_avg:96.37ms
step:335/1770 train_time:32284ms step_avg:96.37ms
step:336/1770 train_time:32381ms step_avg:96.37ms
step:337/1770 train_time:32478ms step_avg:96.37ms
step:338/1770 train_time:32575ms step_avg:96.38ms
step:339/1770 train_time:32674ms step_avg:96.38ms
step:340/1770 train_time:32772ms step_avg:96.39ms
step:341/1770 train_time:32869ms step_avg:96.39ms
step:342/1770 train_time:32966ms step_avg:96.39ms
step:343/1770 train_time:33063ms step_avg:96.39ms
step:344/1770 train_time:33160ms step_avg:96.40ms
step:345/1770 train_time:33256ms step_avg:96.39ms
step:346/1770 train_time:33353ms step_avg:96.40ms
step:347/1770 train_time:33450ms step_avg:96.40ms
step:348/1770 train_time:33547ms step_avg:96.40ms
step:349/1770 train_time:33643ms step_avg:96.40ms
step:350/1770 train_time:33741ms step_avg:96.40ms
step:351/1770 train_time:33838ms step_avg:96.40ms
step:352/1770 train_time:33935ms step_avg:96.41ms
step:353/1770 train_time:34034ms step_avg:96.41ms
step:354/1770 train_time:34132ms step_avg:96.42ms
step:355/1770 train_time:34229ms step_avg:96.42ms
step:356/1770 train_time:34326ms step_avg:96.42ms
step:357/1770 train_time:34423ms step_avg:96.42ms
step:358/1770 train_time:34519ms step_avg:96.42ms
step:359/1770 train_time:34615ms step_avg:96.42ms
step:360/1770 train_time:34714ms step_avg:96.43ms
step:361/1770 train_time:34811ms step_avg:96.43ms
step:362/1770 train_time:34908ms step_avg:96.43ms
step:363/1770 train_time:35005ms step_avg:96.43ms
step:364/1770 train_time:35103ms step_avg:96.44ms
step:365/1770 train_time:35200ms step_avg:96.44ms
step:366/1770 train_time:35297ms step_avg:96.44ms
step:367/1770 train_time:35395ms step_avg:96.44ms
step:368/1770 train_time:35493ms step_avg:96.45ms
step:369/1770 train_time:35590ms step_avg:96.45ms
step:370/1770 train_time:35687ms step_avg:96.45ms
step:371/1770 train_time:35784ms step_avg:96.45ms
step:372/1770 train_time:35880ms step_avg:96.45ms
step:373/1770 train_time:35978ms step_avg:96.46ms
step:374/1770 train_time:36075ms step_avg:96.46ms
step:375/1770 train_time:36173ms step_avg:96.46ms
step:375/1770 val_loss:3.9083 train_time:36266ms step_avg:96.71ms
step:376/1770 train_time:36294ms step_avg:96.53ms
step:377/1770 train_time:36375ms step_avg:96.49ms
step:378/1770 train_time:36478ms step_avg:96.50ms
step:379/1770 train_time:36576ms step_avg:96.51ms
step:380/1770 train_time:36673ms step_avg:96.51ms
step:381/1770 train_time:36770ms step_avg:96.51ms
step:382/1770 train_time:36866ms step_avg:96.51ms
step:383/1770 train_time:36962ms step_avg:96.51ms
step:384/1770 train_time:37058ms step_avg:96.51ms
step:385/1770 train_time:37155ms step_avg:96.51ms
step:386/1770 train_time:37253ms step_avg:96.51ms
step:387/1770 train_time:37351ms step_avg:96.51ms
step:388/1770 train_time:37448ms step_avg:96.52ms
step:389/1770 train_time:37546ms step_avg:96.52ms
step:390/1770 train_time:37643ms step_avg:96.52ms
step:391/1770 train_time:37740ms step_avg:96.52ms
step:392/1770 train_time:37837ms step_avg:96.52ms
step:393/1770 train_time:37933ms step_avg:96.52ms
step:394/1770 train_time:38030ms step_avg:96.52ms
step:395/1770 train_time:38127ms step_avg:96.52ms
step:396/1770 train_time:38226ms step_avg:96.53ms
step:397/1770 train_time:38327ms step_avg:96.54ms
step:398/1770 train_time:38427ms step_avg:96.55ms
step:399/1770 train_time:38527ms step_avg:96.56ms
step:400/1770 train_time:38627ms step_avg:96.57ms
step:401/1770 train_time:38727ms step_avg:96.58ms
step:402/1770 train_time:38826ms step_avg:96.58ms
step:403/1770 train_time:38925ms step_avg:96.59ms
step:404/1770 train_time:39025ms step_avg:96.60ms
step:405/1770 train_time:39125ms step_avg:96.60ms
step:406/1770 train_time:39225ms step_avg:96.61ms
step:407/1770 train_time:39324ms step_avg:96.62ms
step:408/1770 train_time:39424ms step_avg:96.63ms
step:409/1770 train_time:39523ms step_avg:96.63ms
step:410/1770 train_time:39622ms step_avg:96.64ms
step:411/1770 train_time:39721ms step_avg:96.65ms
step:412/1770 train_time:39820ms step_avg:96.65ms
step:413/1770 train_time:39919ms step_avg:96.66ms
step:414/1770 train_time:40018ms step_avg:96.66ms
step:415/1770 train_time:40117ms step_avg:96.67ms
step:416/1770 train_time:40216ms step_avg:96.67ms
step:417/1770 train_time:40315ms step_avg:96.68ms
step:418/1770 train_time:40415ms step_avg:96.69ms
step:419/1770 train_time:40516ms step_avg:96.70ms
step:420/1770 train_time:40616ms step_avg:96.71ms
step:421/1770 train_time:40717ms step_avg:96.71ms
step:422/1770 train_time:40818ms step_avg:96.72ms
step:423/1770 train_time:40916ms step_avg:96.73ms
step:424/1770 train_time:41017ms step_avg:96.74ms
step:425/1770 train_time:41115ms step_avg:96.74ms
step:426/1770 train_time:41215ms step_avg:96.75ms
step:427/1770 train_time:41314ms step_avg:96.75ms
step:428/1770 train_time:41414ms step_avg:96.76ms
step:429/1770 train_time:41513ms step_avg:96.77ms
step:430/1770 train_time:41613ms step_avg:96.77ms
step:431/1770 train_time:41714ms step_avg:96.78ms
step:432/1770 train_time:41815ms step_avg:96.79ms
step:433/1770 train_time:41914ms step_avg:96.80ms
step:434/1770 train_time:42015ms step_avg:96.81ms
step:435/1770 train_time:42115ms step_avg:96.82ms
step:436/1770 train_time:42214ms step_avg:96.82ms
step:437/1770 train_time:42314ms step_avg:96.83ms
step:438/1770 train_time:42413ms step_avg:96.83ms
step:439/1770 train_time:42513ms step_avg:96.84ms
step:440/1770 train_time:42614ms step_avg:96.85ms
step:441/1770 train_time:42714ms step_avg:96.86ms
step:442/1770 train_time:42815ms step_avg:96.87ms
step:443/1770 train_time:42916ms step_avg:96.87ms
step:444/1770 train_time:43015ms step_avg:96.88ms
step:445/1770 train_time:43115ms step_avg:96.89ms
step:446/1770 train_time:43215ms step_avg:96.89ms
step:447/1770 train_time:43315ms step_avg:96.90ms
step:448/1770 train_time:43414ms step_avg:96.91ms
step:449/1770 train_time:43514ms step_avg:96.91ms
step:450/1770 train_time:43614ms step_avg:96.92ms
step:451/1770 train_time:43714ms step_avg:96.93ms
step:452/1770 train_time:43815ms step_avg:96.94ms
step:453/1770 train_time:43915ms step_avg:96.94ms
step:454/1770 train_time:44016ms step_avg:96.95ms
step:455/1770 train_time:44116ms step_avg:96.96ms
step:456/1770 train_time:44216ms step_avg:96.97ms
step:457/1770 train_time:44316ms step_avg:96.97ms
step:458/1770 train_time:44416ms step_avg:96.98ms
step:459/1770 train_time:44517ms step_avg:96.99ms
step:460/1770 train_time:44616ms step_avg:96.99ms
step:461/1770 train_time:44715ms step_avg:97.00ms
step:462/1770 train_time:44816ms step_avg:97.00ms
step:463/1770 train_time:44916ms step_avg:97.01ms
step:464/1770 train_time:45016ms step_avg:97.02ms
step:465/1770 train_time:45116ms step_avg:97.02ms
step:466/1770 train_time:45216ms step_avg:97.03ms
step:467/1770 train_time:45316ms step_avg:97.04ms
step:468/1770 train_time:45416ms step_avg:97.04ms
step:469/1770 train_time:45517ms step_avg:97.05ms
step:470/1770 train_time:45617ms step_avg:97.06ms
step:471/1770 train_time:45716ms step_avg:97.06ms
step:472/1770 train_time:45816ms step_avg:97.07ms
step:473/1770 train_time:45916ms step_avg:97.07ms
step:474/1770 train_time:46016ms step_avg:97.08ms
step:475/1770 train_time:46116ms step_avg:97.09ms
step:476/1770 train_time:46216ms step_avg:97.09ms
step:477/1770 train_time:46315ms step_avg:97.10ms
step:478/1770 train_time:46415ms step_avg:97.10ms
step:479/1770 train_time:46515ms step_avg:97.11ms
step:480/1770 train_time:46615ms step_avg:97.11ms
step:481/1770 train_time:46714ms step_avg:97.12ms
step:482/1770 train_time:46814ms step_avg:97.12ms
step:483/1770 train_time:46914ms step_avg:97.13ms
step:484/1770 train_time:47014ms step_avg:97.14ms
step:485/1770 train_time:47114ms step_avg:97.14ms
step:486/1770 train_time:47215ms step_avg:97.15ms
step:487/1770 train_time:47315ms step_avg:97.16ms
step:488/1770 train_time:47415ms step_avg:97.16ms
step:489/1770 train_time:47515ms step_avg:97.17ms
step:490/1770 train_time:47614ms step_avg:97.17ms
step:491/1770 train_time:47714ms step_avg:97.18ms
step:492/1770 train_time:47814ms step_avg:97.18ms
step:493/1770 train_time:47914ms step_avg:97.19ms
step:494/1770 train_time:48014ms step_avg:97.19ms
step:495/1770 train_time:48114ms step_avg:97.20ms
step:496/1770 train_time:48214ms step_avg:97.21ms
step:497/1770 train_time:48315ms step_avg:97.21ms
step:498/1770 train_time:48415ms step_avg:97.22ms
step:499/1770 train_time:48516ms step_avg:97.23ms
step:500/1770 train_time:48616ms step_avg:97.23ms
step:500/1770 val_loss:3.7551 train_time:48710ms step_avg:97.42ms
step:501/1770 train_time:48738ms step_avg:97.28ms
step:502/1770 train_time:48825ms step_avg:97.26ms
step:503/1770 train_time:48929ms step_avg:97.27ms
step:504/1770 train_time:49029ms step_avg:97.28ms
step:505/1770 train_time:49128ms step_avg:97.28ms
step:506/1770 train_time:49227ms step_avg:97.29ms
step:507/1770 train_time:49326ms step_avg:97.29ms
step:508/1770 train_time:49425ms step_avg:97.29ms
step:509/1770 train_time:49524ms step_avg:97.30ms
step:510/1770 train_time:49622ms step_avg:97.30ms
step:511/1770 train_time:49722ms step_avg:97.30ms
step:512/1770 train_time:49823ms step_avg:97.31ms
step:513/1770 train_time:49924ms step_avg:97.32ms
step:514/1770 train_time:50023ms step_avg:97.32ms
step:515/1770 train_time:50124ms step_avg:97.33ms
step:516/1770 train_time:50223ms step_avg:97.33ms
step:517/1770 train_time:50324ms step_avg:97.34ms
step:518/1770 train_time:50424ms step_avg:97.34ms
step:519/1770 train_time:50522ms step_avg:97.35ms
step:520/1770 train_time:50622ms step_avg:97.35ms
step:521/1770 train_time:50721ms step_avg:97.35ms
step:522/1770 train_time:50820ms step_avg:97.36ms
step:523/1770 train_time:50920ms step_avg:97.36ms
step:524/1770 train_time:51020ms step_avg:97.37ms
step:525/1770 train_time:51121ms step_avg:97.37ms
step:526/1770 train_time:51221ms step_avg:97.38ms
step:527/1770 train_time:51321ms step_avg:97.38ms
step:528/1770 train_time:51422ms step_avg:97.39ms
step:529/1770 train_time:51522ms step_avg:97.39ms
step:530/1770 train_time:51621ms step_avg:97.40ms
step:531/1770 train_time:51721ms step_avg:97.40ms
step:532/1770 train_time:51821ms step_avg:97.41ms
step:533/1770 train_time:51921ms step_avg:97.41ms
step:534/1770 train_time:52021ms step_avg:97.42ms
step:535/1770 train_time:52121ms step_avg:97.42ms
step:536/1770 train_time:52221ms step_avg:97.43ms
step:537/1770 train_time:52321ms step_avg:97.43ms
step:538/1770 train_time:52421ms step_avg:97.44ms
step:539/1770 train_time:52521ms step_avg:97.44ms
step:540/1770 train_time:52622ms step_avg:97.45ms
step:541/1770 train_time:52722ms step_avg:97.45ms
step:542/1770 train_time:52823ms step_avg:97.46ms
step:543/1770 train_time:52923ms step_avg:97.46ms
step:544/1770 train_time:53022ms step_avg:97.47ms
step:545/1770 train_time:53122ms step_avg:97.47ms
step:546/1770 train_time:53221ms step_avg:97.47ms
step:547/1770 train_time:53321ms step_avg:97.48ms
step:548/1770 train_time:53421ms step_avg:97.48ms
step:549/1770 train_time:53521ms step_avg:97.49ms
step:550/1770 train_time:53622ms step_avg:97.49ms
step:551/1770 train_time:53722ms step_avg:97.50ms
step:552/1770 train_time:53821ms step_avg:97.50ms
step:553/1770 train_time:53922ms step_avg:97.51ms
step:554/1770 train_time:54022ms step_avg:97.51ms
step:555/1770 train_time:54121ms step_avg:97.52ms
step:556/1770 train_time:54221ms step_avg:97.52ms
step:557/1770 train_time:54321ms step_avg:97.52ms
step:558/1770 train_time:54421ms step_avg:97.53ms
step:559/1770 train_time:54522ms step_avg:97.53ms
step:560/1770 train_time:54621ms step_avg:97.54ms
step:561/1770 train_time:54721ms step_avg:97.54ms
step:562/1770 train_time:54822ms step_avg:97.55ms
step:563/1770 train_time:54922ms step_avg:97.55ms
step:564/1770 train_time:55022ms step_avg:97.56ms
step:565/1770 train_time:55121ms step_avg:97.56ms
step:566/1770 train_time:55221ms step_avg:97.56ms
step:567/1770 train_time:55320ms step_avg:97.57ms
step:568/1770 train_time:55420ms step_avg:97.57ms
step:569/1770 train_time:55520ms step_avg:97.57ms
step:570/1770 train_time:55620ms step_avg:97.58ms
step:571/1770 train_time:55720ms step_avg:97.58ms
step:572/1770 train_time:55821ms step_avg:97.59ms
step:573/1770 train_time:55921ms step_avg:97.59ms
step:574/1770 train_time:56021ms step_avg:97.60ms
step:575/1770 train_time:56121ms step_avg:97.60ms
step:576/1770 train_time:56221ms step_avg:97.61ms
step:577/1770 train_time:56321ms step_avg:97.61ms
step:578/1770 train_time:56421ms step_avg:97.61ms
step:579/1770 train_time:56521ms step_avg:97.62ms
step:580/1770 train_time:56621ms step_avg:97.62ms
step:581/1770 train_time:56721ms step_avg:97.63ms
step:582/1770 train_time:56821ms step_avg:97.63ms
step:583/1770 train_time:56921ms step_avg:97.63ms
step:584/1770 train_time:57021ms step_avg:97.64ms
step:585/1770 train_time:57122ms step_avg:97.64ms
step:586/1770 train_time:57221ms step_avg:97.65ms
step:587/1770 train_time:57321ms step_avg:97.65ms
step:588/1770 train_time:57421ms step_avg:97.66ms
step:589/1770 train_time:57521ms step_avg:97.66ms
step:590/1770 train_time:57621ms step_avg:97.66ms
step:591/1770 train_time:57721ms step_avg:97.67ms
step:592/1770 train_time:57821ms step_avg:97.67ms
step:593/1770 train_time:57921ms step_avg:97.67ms
step:594/1770 train_time:58021ms step_avg:97.68ms
step:595/1770 train_time:58120ms step_avg:97.68ms
step:596/1770 train_time:58220ms step_avg:97.68ms
step:597/1770 train_time:58320ms step_avg:97.69ms
step:598/1770 train_time:58421ms step_avg:97.69ms
step:599/1770 train_time:58520ms step_avg:97.70ms
step:600/1770 train_time:58620ms step_avg:97.70ms
step:601/1770 train_time:58720ms step_avg:97.70ms
step:602/1770 train_time:58820ms step_avg:97.71ms
step:603/1770 train_time:58920ms step_avg:97.71ms
step:604/1770 train_time:59021ms step_avg:97.72ms
step:605/1770 train_time:59121ms step_avg:97.72ms
step:606/1770 train_time:59221ms step_avg:97.72ms
step:607/1770 train_time:59321ms step_avg:97.73ms
step:608/1770 train_time:59421ms step_avg:97.73ms
step:609/1770 train_time:59521ms step_avg:97.74ms
step:610/1770 train_time:59621ms step_avg:97.74ms
step:611/1770 train_time:59721ms step_avg:97.74ms
step:612/1770 train_time:59820ms step_avg:97.75ms
step:613/1770 train_time:59920ms step_avg:97.75ms
step:614/1770 train_time:60021ms step_avg:97.75ms
step:615/1770 train_time:60122ms step_avg:97.76ms
step:616/1770 train_time:60223ms step_avg:97.76ms
step:617/1770 train_time:60324ms step_avg:97.77ms
step:618/1770 train_time:60423ms step_avg:97.77ms
step:619/1770 train_time:60524ms step_avg:97.78ms
step:620/1770 train_time:60624ms step_avg:97.78ms
step:621/1770 train_time:60724ms step_avg:97.78ms
step:622/1770 train_time:60824ms step_avg:97.79ms
step:623/1770 train_time:60923ms step_avg:97.79ms
step:624/1770 train_time:61023ms step_avg:97.79ms
step:625/1770 train_time:61122ms step_avg:97.80ms
step:625/1770 val_loss:3.6691 train_time:61216ms step_avg:97.95ms
step:626/1770 train_time:61244ms step_avg:97.83ms
step:627/1770 train_time:61328ms step_avg:97.81ms
step:628/1770 train_time:61429ms step_avg:97.82ms
step:629/1770 train_time:61530ms step_avg:97.82ms
step:630/1770 train_time:61629ms step_avg:97.82ms
step:631/1770 train_time:61729ms step_avg:97.83ms
step:632/1770 train_time:61829ms step_avg:97.83ms
step:633/1770 train_time:61928ms step_avg:97.83ms
step:634/1770 train_time:62028ms step_avg:97.84ms
step:635/1770 train_time:62127ms step_avg:97.84ms
step:636/1770 train_time:62228ms step_avg:97.84ms
step:637/1770 train_time:62329ms step_avg:97.85ms
step:638/1770 train_time:62430ms step_avg:97.85ms
step:639/1770 train_time:62531ms step_avg:97.86ms
step:640/1770 train_time:62631ms step_avg:97.86ms
step:641/1770 train_time:62731ms step_avg:97.86ms
step:642/1770 train_time:62830ms step_avg:97.87ms
step:643/1770 train_time:62930ms step_avg:97.87ms
step:644/1770 train_time:63030ms step_avg:97.87ms
step:645/1770 train_time:63129ms step_avg:97.87ms
step:646/1770 train_time:63229ms step_avg:97.88ms
step:647/1770 train_time:63330ms step_avg:97.88ms
step:648/1770 train_time:63431ms step_avg:97.89ms
step:649/1770 train_time:63531ms step_avg:97.89ms
step:650/1770 train_time:63631ms step_avg:97.89ms
step:651/1770 train_time:63731ms step_avg:97.90ms
step:652/1770 train_time:63831ms step_avg:97.90ms
step:653/1770 train_time:63930ms step_avg:97.90ms
step:654/1770 train_time:64030ms step_avg:97.90ms
step:655/1770 train_time:64129ms step_avg:97.91ms
step:656/1770 train_time:64229ms step_avg:97.91ms
step:657/1770 train_time:64329ms step_avg:97.91ms
step:658/1770 train_time:64431ms step_avg:97.92ms
step:659/1770 train_time:64532ms step_avg:97.92ms
step:660/1770 train_time:64634ms step_avg:97.93ms
step:661/1770 train_time:64735ms step_avg:97.93ms
step:662/1770 train_time:64836ms step_avg:97.94ms
step:663/1770 train_time:64939ms step_avg:97.95ms
step:664/1770 train_time:65043ms step_avg:97.96ms
step:665/1770 train_time:65144ms step_avg:97.96ms
step:666/1770 train_time:65246ms step_avg:97.97ms
step:667/1770 train_time:65347ms step_avg:97.97ms
step:668/1770 train_time:65448ms step_avg:97.98ms
step:669/1770 train_time:65549ms step_avg:97.98ms
step:670/1770 train_time:65651ms step_avg:97.99ms
step:671/1770 train_time:65752ms step_avg:97.99ms
step:672/1770 train_time:65854ms step_avg:98.00ms
step:673/1770 train_time:65956ms step_avg:98.00ms
step:674/1770 train_time:66057ms step_avg:98.01ms
step:675/1770 train_time:66159ms step_avg:98.01ms
step:676/1770 train_time:66263ms step_avg:98.02ms
step:677/1770 train_time:66366ms step_avg:98.03ms
step:678/1770 train_time:66467ms step_avg:98.03ms
step:679/1770 train_time:66567ms step_avg:98.04ms
step:680/1770 train_time:66669ms step_avg:98.04ms
step:681/1770 train_time:66770ms step_avg:98.05ms
step:682/1770 train_time:66872ms step_avg:98.05ms
step:683/1770 train_time:66975ms step_avg:98.06ms
step:684/1770 train_time:67076ms step_avg:98.06ms
step:685/1770 train_time:67177ms step_avg:98.07ms
step:686/1770 train_time:67279ms step_avg:98.07ms
step:687/1770 train_time:67382ms step_avg:98.08ms
step:688/1770 train_time:67484ms step_avg:98.09ms
step:689/1770 train_time:67586ms step_avg:98.09ms
step:690/1770 train_time:67687ms step_avg:98.10ms
step:691/1770 train_time:67788ms step_avg:98.10ms
step:692/1770 train_time:67889ms step_avg:98.11ms
step:693/1770 train_time:67991ms step_avg:98.11ms
step:694/1770 train_time:68093ms step_avg:98.12ms
step:695/1770 train_time:68194ms step_avg:98.12ms
step:696/1770 train_time:68297ms step_avg:98.13ms
step:697/1770 train_time:68398ms step_avg:98.13ms
step:698/1770 train_time:68499ms step_avg:98.14ms
step:699/1770 train_time:68602ms step_avg:98.14ms
step:700/1770 train_time:68705ms step_avg:98.15ms
step:701/1770 train_time:68807ms step_avg:98.16ms
step:702/1770 train_time:68908ms step_avg:98.16ms
step:703/1770 train_time:69010ms step_avg:98.16ms
step:704/1770 train_time:69111ms step_avg:98.17ms
step:705/1770 train_time:69213ms step_avg:98.17ms
step:706/1770 train_time:69315ms step_avg:98.18ms
step:707/1770 train_time:69416ms step_avg:98.18ms
step:708/1770 train_time:69517ms step_avg:98.19ms
step:709/1770 train_time:69619ms step_avg:98.19ms
step:710/1770 train_time:69722ms step_avg:98.20ms
step:711/1770 train_time:69824ms step_avg:98.21ms
step:712/1770 train_time:69926ms step_avg:98.21ms
step:713/1770 train_time:70027ms step_avg:98.22ms
step:714/1770 train_time:70129ms step_avg:98.22ms
step:715/1770 train_time:70230ms step_avg:98.22ms
step:716/1770 train_time:70331ms step_avg:98.23ms
step:717/1770 train_time:70432ms step_avg:98.23ms
step:718/1770 train_time:70535ms step_avg:98.24ms
step:719/1770 train_time:70636ms step_avg:98.24ms
step:720/1770 train_time:70738ms step_avg:98.25ms
step:721/1770 train_time:70840ms step_avg:98.25ms
step:722/1770 train_time:70943ms step_avg:98.26ms
step:723/1770 train_time:71045ms step_avg:98.26ms
step:724/1770 train_time:71147ms step_avg:98.27ms
step:725/1770 train_time:71248ms step_avg:98.27ms
step:726/1770 train_time:71349ms step_avg:98.28ms
step:727/1770 train_time:71450ms step_avg:98.28ms
step:728/1770 train_time:71551ms step_avg:98.28ms
step:729/1770 train_time:71654ms step_avg:98.29ms
step:730/1770 train_time:71755ms step_avg:98.29ms
step:731/1770 train_time:71856ms step_avg:98.30ms
step:732/1770 train_time:71959ms step_avg:98.31ms
step:733/1770 train_time:72062ms step_avg:98.31ms
step:734/1770 train_time:72165ms step_avg:98.32ms
step:735/1770 train_time:72266ms step_avg:98.32ms
step:736/1770 train_time:72368ms step_avg:98.33ms
step:737/1770 train_time:72468ms step_avg:98.33ms
step:738/1770 train_time:72570ms step_avg:98.33ms
step:739/1770 train_time:72673ms step_avg:98.34ms
step:740/1770 train_time:72774ms step_avg:98.34ms
step:741/1770 train_time:72876ms step_avg:98.35ms
step:742/1770 train_time:72977ms step_avg:98.35ms
step:743/1770 train_time:73078ms step_avg:98.36ms
step:744/1770 train_time:73181ms step_avg:98.36ms
step:745/1770 train_time:73283ms step_avg:98.37ms
step:746/1770 train_time:73385ms step_avg:98.37ms
step:747/1770 train_time:73486ms step_avg:98.37ms
step:748/1770 train_time:73587ms step_avg:98.38ms
step:749/1770 train_time:73688ms step_avg:98.38ms
step:750/1770 train_time:73790ms step_avg:98.39ms
step:750/1770 val_loss:3.6047 train_time:73886ms step_avg:98.51ms
step:751/1770 train_time:73914ms step_avg:98.42ms
step:752/1770 train_time:73999ms step_avg:98.40ms
step:753/1770 train_time:74103ms step_avg:98.41ms
step:754/1770 train_time:74204ms step_avg:98.41ms
step:755/1770 train_time:74305ms step_avg:98.42ms
step:756/1770 train_time:74406ms step_avg:98.42ms
step:757/1770 train_time:74508ms step_avg:98.42ms
step:758/1770 train_time:74609ms step_avg:98.43ms
step:759/1770 train_time:74710ms step_avg:98.43ms
step:760/1770 train_time:74812ms step_avg:98.44ms
step:761/1770 train_time:74915ms step_avg:98.44ms
step:762/1770 train_time:75017ms step_avg:98.45ms
step:763/1770 train_time:75120ms step_avg:98.45ms
step:764/1770 train_time:75221ms step_avg:98.46ms
step:765/1770 train_time:75322ms step_avg:98.46ms
step:766/1770 train_time:75423ms step_avg:98.46ms
step:767/1770 train_time:75525ms step_avg:98.47ms
step:768/1770 train_time:75627ms step_avg:98.47ms
step:769/1770 train_time:75728ms step_avg:98.48ms
step:770/1770 train_time:75830ms step_avg:98.48ms
step:771/1770 train_time:75933ms step_avg:98.49ms
step:772/1770 train_time:76036ms step_avg:98.49ms
step:773/1770 train_time:76138ms step_avg:98.50ms
step:774/1770 train_time:76240ms step_avg:98.50ms
step:775/1770 train_time:76342ms step_avg:98.51ms
step:776/1770 train_time:76443ms step_avg:98.51ms
step:777/1770 train_time:76544ms step_avg:98.51ms
step:778/1770 train_time:76646ms step_avg:98.52ms
step:779/1770 train_time:76747ms step_avg:98.52ms
step:780/1770 train_time:76849ms step_avg:98.52ms
step:781/1770 train_time:76952ms step_avg:98.53ms
step:782/1770 train_time:77054ms step_avg:98.54ms
step:783/1770 train_time:77157ms step_avg:98.54ms
step:784/1770 train_time:77257ms step_avg:98.54ms
step:785/1770 train_time:77359ms step_avg:98.55ms
step:786/1770 train_time:77460ms step_avg:98.55ms
step:787/1770 train_time:77563ms step_avg:98.55ms
step:788/1770 train_time:77664ms step_avg:98.56ms
step:789/1770 train_time:77765ms step_avg:98.56ms
step:790/1770 train_time:77866ms step_avg:98.56ms
step:791/1770 train_time:77968ms step_avg:98.57ms
step:792/1770 train_time:78072ms step_avg:98.58ms
step:793/1770 train_time:78174ms step_avg:98.58ms
step:794/1770 train_time:78277ms step_avg:98.59ms
step:795/1770 train_time:78379ms step_avg:98.59ms
step:796/1770 train_time:78482ms step_avg:98.60ms
step:797/1770 train_time:78584ms step_avg:98.60ms
step:798/1770 train_time:78686ms step_avg:98.60ms
step:799/1770 train_time:78787ms step_avg:98.61ms
step:800/1770 train_time:78889ms step_avg:98.61ms
step:801/1770 train_time:78991ms step_avg:98.62ms
step:802/1770 train_time:79094ms step_avg:98.62ms
step:803/1770 train_time:79196ms step_avg:98.63ms
step:804/1770 train_time:79298ms step_avg:98.63ms
step:805/1770 train_time:79400ms step_avg:98.63ms
step:806/1770 train_time:79503ms step_avg:98.64ms
step:807/1770 train_time:79605ms step_avg:98.64ms
step:808/1770 train_time:79707ms step_avg:98.65ms
step:809/1770 train_time:79809ms step_avg:98.65ms
step:810/1770 train_time:79911ms step_avg:98.66ms
step:811/1770 train_time:80013ms step_avg:98.66ms
step:812/1770 train_time:80115ms step_avg:98.66ms
step:813/1770 train_time:80216ms step_avg:98.67ms
step:814/1770 train_time:80317ms step_avg:98.67ms
step:815/1770 train_time:80419ms step_avg:98.67ms
step:816/1770 train_time:80520ms step_avg:98.68ms
step:817/1770 train_time:80622ms step_avg:98.68ms
step:818/1770 train_time:80724ms step_avg:98.68ms
step:819/1770 train_time:80826ms step_avg:98.69ms
step:820/1770 train_time:80928ms step_avg:98.69ms
step:821/1770 train_time:81030ms step_avg:98.70ms
step:822/1770 train_time:81133ms step_avg:98.70ms
step:823/1770 train_time:81236ms step_avg:98.71ms
step:824/1770 train_time:81337ms step_avg:98.71ms
step:825/1770 train_time:81439ms step_avg:98.71ms
step:826/1770 train_time:81541ms step_avg:98.72ms
step:827/1770 train_time:81643ms step_avg:98.72ms
step:828/1770 train_time:81745ms step_avg:98.73ms
step:829/1770 train_time:81847ms step_avg:98.73ms
step:830/1770 train_time:81949ms step_avg:98.73ms
step:831/1770 train_time:82051ms step_avg:98.74ms
step:832/1770 train_time:82154ms step_avg:98.74ms
step:833/1770 train_time:82258ms step_avg:98.75ms
step:834/1770 train_time:82359ms step_avg:98.75ms
step:835/1770 train_time:82461ms step_avg:98.76ms
step:836/1770 train_time:82563ms step_avg:98.76ms
step:837/1770 train_time:82664ms step_avg:98.76ms
step:838/1770 train_time:82766ms step_avg:98.77ms
step:839/1770 train_time:82867ms step_avg:98.77ms
step:840/1770 train_time:82969ms step_avg:98.77ms
step:841/1770 train_time:83071ms step_avg:98.78ms
step:842/1770 train_time:83174ms step_avg:98.78ms
step:843/1770 train_time:83276ms step_avg:98.79ms
step:844/1770 train_time:83380ms step_avg:98.79ms
step:845/1770 train_time:83481ms step_avg:98.79ms
step:846/1770 train_time:83583ms step_avg:98.80ms
step:847/1770 train_time:83684ms step_avg:98.80ms
step:848/1770 train_time:83786ms step_avg:98.80ms
step:849/1770 train_time:83888ms step_avg:98.81ms
step:850/1770 train_time:83989ms step_avg:98.81ms
step:851/1770 train_time:84091ms step_avg:98.81ms
step:852/1770 train_time:84193ms step_avg:98.82ms
step:853/1770 train_time:84296ms step_avg:98.82ms
step:854/1770 train_time:84398ms step_avg:98.83ms
step:855/1770 train_time:84499ms step_avg:98.83ms
step:856/1770 train_time:84601ms step_avg:98.83ms
step:857/1770 train_time:84703ms step_avg:98.84ms
step:858/1770 train_time:84805ms step_avg:98.84ms
step:859/1770 train_time:84906ms step_avg:98.84ms
step:860/1770 train_time:85009ms step_avg:98.85ms
step:861/1770 train_time:85111ms step_avg:98.85ms
step:862/1770 train_time:85214ms step_avg:98.86ms
step:863/1770 train_time:85316ms step_avg:98.86ms
step:864/1770 train_time:85418ms step_avg:98.86ms
step:865/1770 train_time:85520ms step_avg:98.87ms
step:866/1770 train_time:85623ms step_avg:98.87ms
step:867/1770 train_time:85725ms step_avg:98.88ms
step:868/1770 train_time:85826ms step_avg:98.88ms
step:869/1770 train_time:85929ms step_avg:98.88ms
step:870/1770 train_time:86031ms step_avg:98.89ms
step:871/1770 train_time:86134ms step_avg:98.89ms
step:872/1770 train_time:86235ms step_avg:98.89ms
step:873/1770 train_time:86337ms step_avg:98.90ms
step:874/1770 train_time:86439ms step_avg:98.90ms
step:875/1770 train_time:86541ms step_avg:98.90ms
step:875/1770 val_loss:3.5544 train_time:86638ms step_avg:99.01ms
step:876/1770 train_time:86666ms step_avg:98.93ms
step:877/1770 train_time:86754ms step_avg:98.92ms
step:878/1770 train_time:86858ms step_avg:98.93ms
step:879/1770 train_time:86959ms step_avg:98.93ms
step:880/1770 train_time:87061ms step_avg:98.93ms
step:881/1770 train_time:87163ms step_avg:98.94ms
step:882/1770 train_time:87264ms step_avg:98.94ms
step:883/1770 train_time:87366ms step_avg:98.94ms
step:884/1770 train_time:87467ms step_avg:98.94ms
step:885/1770 train_time:87568ms step_avg:98.95ms
step:886/1770 train_time:87671ms step_avg:98.95ms
step:887/1770 train_time:87774ms step_avg:98.96ms
step:888/1770 train_time:87879ms step_avg:98.96ms
step:889/1770 train_time:87982ms step_avg:98.97ms
step:890/1770 train_time:88083ms step_avg:98.97ms
step:891/1770 train_time:88185ms step_avg:98.97ms
step:892/1770 train_time:88286ms step_avg:98.98ms
step:893/1770 train_time:88388ms step_avg:98.98ms
step:894/1770 train_time:88489ms step_avg:98.98ms
step:895/1770 train_time:88592ms step_avg:98.98ms
step:896/1770 train_time:88693ms step_avg:98.99ms
step:897/1770 train_time:88796ms step_avg:98.99ms
step:898/1770 train_time:88899ms step_avg:99.00ms
step:899/1770 train_time:89001ms step_avg:99.00ms
step:900/1770 train_time:89103ms step_avg:99.00ms
step:901/1770 train_time:89205ms step_avg:99.01ms
step:902/1770 train_time:89307ms step_avg:99.01ms
step:903/1770 train_time:89408ms step_avg:99.01ms
step:904/1770 train_time:89510ms step_avg:99.02ms
step:905/1770 train_time:89613ms step_avg:99.02ms
step:906/1770 train_time:89715ms step_avg:99.02ms
step:907/1770 train_time:89816ms step_avg:99.03ms
step:908/1770 train_time:89918ms step_avg:99.03ms
step:909/1770 train_time:90020ms step_avg:99.03ms
step:910/1770 train_time:90122ms step_avg:99.03ms
step:911/1770 train_time:90224ms step_avg:99.04ms
step:912/1770 train_time:90326ms step_avg:99.04ms
step:913/1770 train_time:90429ms step_avg:99.05ms
step:914/1770 train_time:90530ms step_avg:99.05ms
step:915/1770 train_time:90633ms step_avg:99.05ms
step:916/1770 train_time:90736ms step_avg:99.06ms
step:917/1770 train_time:90838ms step_avg:99.06ms
step:918/1770 train_time:90940ms step_avg:99.06ms
step:919/1770 train_time:91042ms step_avg:99.07ms
step:920/1770 train_time:91146ms step_avg:99.07ms
step:921/1770 train_time:91249ms step_avg:99.08ms
step:922/1770 train_time:91353ms step_avg:99.08ms
step:923/1770 train_time:91457ms step_avg:99.09ms
step:924/1770 train_time:91559ms step_avg:99.09ms
step:925/1770 train_time:91663ms step_avg:99.10ms
step:926/1770 train_time:91766ms step_avg:99.10ms
step:927/1770 train_time:91870ms step_avg:99.10ms
step:928/1770 train_time:91974ms step_avg:99.11ms
step:929/1770 train_time:92078ms step_avg:99.11ms
step:930/1770 train_time:92180ms step_avg:99.12ms
step:931/1770 train_time:92284ms step_avg:99.12ms
step:932/1770 train_time:92387ms step_avg:99.13ms
step:933/1770 train_time:92490ms step_avg:99.13ms
step:934/1770 train_time:92594ms step_avg:99.14ms
step:935/1770 train_time:92698ms step_avg:99.14ms
step:936/1770 train_time:92801ms step_avg:99.15ms
step:937/1770 train_time:92905ms step_avg:99.15ms
step:938/1770 train_time:93008ms step_avg:99.16ms
step:939/1770 train_time:93110ms step_avg:99.16ms
step:940/1770 train_time:93215ms step_avg:99.16ms
step:941/1770 train_time:93318ms step_avg:99.17ms
step:942/1770 train_time:93421ms step_avg:99.17ms
step:943/1770 train_time:93524ms step_avg:99.18ms
step:944/1770 train_time:93628ms step_avg:99.18ms
step:945/1770 train_time:93732ms step_avg:99.19ms
step:946/1770 train_time:93837ms step_avg:99.19ms
step:947/1770 train_time:93939ms step_avg:99.20ms
step:948/1770 train_time:94043ms step_avg:99.20ms
step:949/1770 train_time:94146ms step_avg:99.21ms
step:950/1770 train_time:94249ms step_avg:99.21ms
step:951/1770 train_time:94354ms step_avg:99.22ms
step:952/1770 train_time:94458ms step_avg:99.22ms
step:953/1770 train_time:94560ms step_avg:99.22ms
step:954/1770 train_time:94665ms step_avg:99.23ms
step:955/1770 train_time:94768ms step_avg:99.23ms
step:956/1770 train_time:94872ms step_avg:99.24ms
step:957/1770 train_time:94976ms step_avg:99.24ms
step:958/1770 train_time:95079ms step_avg:99.25ms
step:959/1770 train_time:95181ms step_avg:99.25ms
step:960/1770 train_time:95285ms step_avg:99.25ms
step:961/1770 train_time:95388ms step_avg:99.26ms
step:962/1770 train_time:95491ms step_avg:99.26ms
step:963/1770 train_time:95594ms step_avg:99.27ms
step:964/1770 train_time:95698ms step_avg:99.27ms
step:965/1770 train_time:95802ms step_avg:99.28ms
step:966/1770 train_time:95905ms step_avg:99.28ms
step:967/1770 train_time:96008ms step_avg:99.28ms
step:968/1770 train_time:96112ms step_avg:99.29ms
step:969/1770 train_time:96215ms step_avg:99.29ms
step:970/1770 train_time:96318ms step_avg:99.30ms
step:971/1770 train_time:96421ms step_avg:99.30ms
step:972/1770 train_time:96525ms step_avg:99.31ms
step:973/1770 train_time:96628ms step_avg:99.31ms
step:974/1770 train_time:96731ms step_avg:99.31ms
step:975/1770 train_time:96834ms step_avg:99.32ms
step:976/1770 train_time:96938ms step_avg:99.32ms
step:977/1770 train_time:97042ms step_avg:99.33ms
step:978/1770 train_time:97146ms step_avg:99.33ms
step:979/1770 train_time:97249ms step_avg:99.34ms
step:980/1770 train_time:97353ms step_avg:99.34ms
step:981/1770 train_time:97456ms step_avg:99.34ms
step:982/1770 train_time:97559ms step_avg:99.35ms
step:983/1770 train_time:97662ms step_avg:99.35ms
step:984/1770 train_time:97765ms step_avg:99.35ms
step:985/1770 train_time:97868ms step_avg:99.36ms
step:986/1770 train_time:97972ms step_avg:99.36ms
step:987/1770 train_time:98076ms step_avg:99.37ms
step:988/1770 train_time:98179ms step_avg:99.37ms
step:989/1770 train_time:98283ms step_avg:99.38ms
step:990/1770 train_time:98386ms step_avg:99.38ms
step:991/1770 train_time:98489ms step_avg:99.38ms
step:992/1770 train_time:98593ms step_avg:99.39ms
step:993/1770 train_time:98697ms step_avg:99.39ms
step:994/1770 train_time:98800ms step_avg:99.40ms
step:995/1770 train_time:98904ms step_avg:99.40ms
step:996/1770 train_time:99007ms step_avg:99.40ms
step:997/1770 train_time:99110ms step_avg:99.41ms
step:998/1770 train_time:99214ms step_avg:99.41ms
step:999/1770 train_time:99318ms step_avg:99.42ms
step:1000/1770 train_time:99420ms step_avg:99.42ms
step:1000/1770 val_loss:3.5166 train_time:99519ms step_avg:99.52ms
step:1001/1770 train_time:99546ms step_avg:99.45ms
step:1002/1770 train_time:99637ms step_avg:99.44ms
step:1003/1770 train_time:99745ms step_avg:99.45ms
step:1004/1770 train_time:99848ms step_avg:99.45ms
step:1005/1770 train_time:99950ms step_avg:99.45ms
step:1006/1770 train_time:100053ms step_avg:99.46ms
step:1007/1770 train_time:100156ms step_avg:99.46ms
step:1008/1770 train_time:100258ms step_avg:99.46ms
step:1009/1770 train_time:100361ms step_avg:99.47ms
step:1010/1770 train_time:100464ms step_avg:99.47ms
step:1011/1770 train_time:100567ms step_avg:99.47ms
step:1012/1770 train_time:100673ms step_avg:99.48ms
step:1013/1770 train_time:100776ms step_avg:99.48ms
step:1014/1770 train_time:100879ms step_avg:99.49ms
step:1015/1770 train_time:100983ms step_avg:99.49ms
step:1016/1770 train_time:101086ms step_avg:99.49ms
step:1017/1770 train_time:101189ms step_avg:99.50ms
step:1018/1770 train_time:101292ms step_avg:99.50ms
step:1019/1770 train_time:101395ms step_avg:99.50ms
step:1020/1770 train_time:101498ms step_avg:99.51ms
step:1021/1770 train_time:101601ms step_avg:99.51ms
step:1022/1770 train_time:101705ms step_avg:99.52ms
step:1023/1770 train_time:101807ms step_avg:99.52ms
step:1024/1770 train_time:101913ms step_avg:99.52ms
step:1025/1770 train_time:102016ms step_avg:99.53ms
step:1026/1770 train_time:102119ms step_avg:99.53ms
step:1027/1770 train_time:102224ms step_avg:99.54ms
step:1028/1770 train_time:102327ms step_avg:99.54ms
step:1029/1770 train_time:102432ms step_avg:99.55ms
step:1030/1770 train_time:102536ms step_avg:99.55ms
step:1031/1770 train_time:102639ms step_avg:99.55ms
step:1032/1770 train_time:102742ms step_avg:99.56ms
step:1033/1770 train_time:102846ms step_avg:99.56ms
step:1034/1770 train_time:102949ms step_avg:99.56ms
step:1035/1770 train_time:103053ms step_avg:99.57ms
step:1036/1770 train_time:103156ms step_avg:99.57ms
step:1037/1770 train_time:103259ms step_avg:99.58ms
step:1038/1770 train_time:103363ms step_avg:99.58ms
step:1039/1770 train_time:103466ms step_avg:99.58ms
step:1040/1770 train_time:103571ms step_avg:99.59ms
step:1041/1770 train_time:103675ms step_avg:99.59ms
step:1042/1770 train_time:103778ms step_avg:99.59ms
step:1043/1770 train_time:103881ms step_avg:99.60ms
step:1044/1770 train_time:103985ms step_avg:99.60ms
step:1045/1770 train_time:104088ms step_avg:99.61ms
step:1046/1770 train_time:104191ms step_avg:99.61ms
step:1047/1770 train_time:104294ms step_avg:99.61ms
step:1048/1770 train_time:104397ms step_avg:99.62ms
step:1049/1770 train_time:104501ms step_avg:99.62ms
step:1050/1770 train_time:104605ms step_avg:99.62ms
step:1051/1770 train_time:104708ms step_avg:99.63ms
step:1052/1770 train_time:104812ms step_avg:99.63ms
step:1053/1770 train_time:104916ms step_avg:99.64ms
step:1054/1770 train_time:105020ms step_avg:99.64ms
step:1055/1770 train_time:105123ms step_avg:99.64ms
step:1056/1770 train_time:105227ms step_avg:99.65ms
step:1057/1770 train_time:105331ms step_avg:99.65ms
step:1058/1770 train_time:105437ms step_avg:99.66ms
step:1059/1770 train_time:105541ms step_avg:99.66ms
step:1060/1770 train_time:105644ms step_avg:99.66ms
step:1061/1770 train_time:105748ms step_avg:99.67ms
step:1062/1770 train_time:105853ms step_avg:99.67ms
step:1063/1770 train_time:105957ms step_avg:99.68ms
step:1064/1770 train_time:106061ms step_avg:99.68ms
step:1065/1770 train_time:106164ms step_avg:99.68ms
step:1066/1770 train_time:106268ms step_avg:99.69ms
step:1067/1770 train_time:106372ms step_avg:99.69ms
step:1068/1770 train_time:106477ms step_avg:99.70ms
step:1069/1770 train_time:106579ms step_avg:99.70ms
step:1070/1770 train_time:106683ms step_avg:99.70ms
step:1071/1770 train_time:106786ms step_avg:99.71ms
step:1072/1770 train_time:106890ms step_avg:99.71ms
step:1073/1770 train_time:106993ms step_avg:99.71ms
step:1074/1770 train_time:107097ms step_avg:99.72ms
step:1075/1770 train_time:107200ms step_avg:99.72ms
step:1076/1770 train_time:107305ms step_avg:99.73ms
step:1077/1770 train_time:107408ms step_avg:99.73ms
step:1078/1770 train_time:107514ms step_avg:99.73ms
step:1079/1770 train_time:107616ms step_avg:99.74ms
step:1080/1770 train_time:107719ms step_avg:99.74ms
step:1081/1770 train_time:107823ms step_avg:99.74ms
step:1082/1770 train_time:107926ms step_avg:99.75ms
step:1083/1770 train_time:108029ms step_avg:99.75ms
step:1084/1770 train_time:108133ms step_avg:99.75ms
step:1085/1770 train_time:108237ms step_avg:99.76ms
step:1086/1770 train_time:108340ms step_avg:99.76ms
step:1087/1770 train_time:108444ms step_avg:99.76ms
step:1088/1770 train_time:108547ms step_avg:99.77ms
step:1089/1770 train_time:108651ms step_avg:99.77ms
step:1090/1770 train_time:108754ms step_avg:99.77ms
step:1091/1770 train_time:108858ms step_avg:99.78ms
step:1092/1770 train_time:108961ms step_avg:99.78ms
step:1093/1770 train_time:109064ms step_avg:99.78ms
step:1094/1770 train_time:109169ms step_avg:99.79ms
step:1095/1770 train_time:109274ms step_avg:99.79ms
step:1096/1770 train_time:109377ms step_avg:99.80ms
step:1097/1770 train_time:109481ms step_avg:99.80ms
step:1098/1770 train_time:109584ms step_avg:99.80ms
step:1099/1770 train_time:109688ms step_avg:99.81ms
step:1100/1770 train_time:109792ms step_avg:99.81ms
step:1101/1770 train_time:109896ms step_avg:99.81ms
step:1102/1770 train_time:109999ms step_avg:99.82ms
step:1103/1770 train_time:110102ms step_avg:99.82ms
step:1104/1770 train_time:110206ms step_avg:99.82ms
step:1105/1770 train_time:110310ms step_avg:99.83ms
step:1106/1770 train_time:110415ms step_avg:99.83ms
step:1107/1770 train_time:110518ms step_avg:99.84ms
step:1108/1770 train_time:110621ms step_avg:99.84ms
step:1109/1770 train_time:110726ms step_avg:99.84ms
step:1110/1770 train_time:110830ms step_avg:99.85ms
step:1111/1770 train_time:110934ms step_avg:99.85ms
step:1112/1770 train_time:111038ms step_avg:99.85ms
step:1113/1770 train_time:111143ms step_avg:99.86ms
step:1114/1770 train_time:111246ms step_avg:99.86ms
step:1115/1770 train_time:111350ms step_avg:99.87ms
step:1116/1770 train_time:111452ms step_avg:99.87ms
step:1117/1770 train_time:111558ms step_avg:99.87ms
step:1118/1770 train_time:111661ms step_avg:99.88ms
step:1119/1770 train_time:111765ms step_avg:99.88ms
step:1120/1770 train_time:111869ms step_avg:99.88ms
step:1121/1770 train_time:111974ms step_avg:99.89ms
step:1122/1770 train_time:112077ms step_avg:99.89ms
step:1123/1770 train_time:112181ms step_avg:99.89ms
step:1124/1770 train_time:112284ms step_avg:99.90ms
step:1125/1770 train_time:112387ms step_avg:99.90ms
step:1125/1770 val_loss:3.4764 train_time:112485ms step_avg:99.99ms
step:1126/1770 train_time:112513ms step_avg:99.92ms
step:1127/1770 train_time:112602ms step_avg:99.91ms
step:1128/1770 train_time:112707ms step_avg:99.92ms
step:1129/1770 train_time:112811ms step_avg:99.92ms
step:1130/1770 train_time:112914ms step_avg:99.92ms
step:1131/1770 train_time:113017ms step_avg:99.93ms
step:1132/1770 train_time:113120ms step_avg:99.93ms
step:1133/1770 train_time:113223ms step_avg:99.93ms
step:1134/1770 train_time:113326ms step_avg:99.94ms
step:1135/1770 train_time:113429ms step_avg:99.94ms
step:1136/1770 train_time:113533ms step_avg:99.94ms
step:1137/1770 train_time:113638ms step_avg:99.95ms
step:1138/1770 train_time:113743ms step_avg:99.95ms
step:1139/1770 train_time:113849ms step_avg:99.96ms
step:1140/1770 train_time:113954ms step_avg:99.96ms
step:1141/1770 train_time:114057ms step_avg:99.96ms
step:1142/1770 train_time:114161ms step_avg:99.97ms
step:1143/1770 train_time:114263ms step_avg:99.97ms
step:1144/1770 train_time:114368ms step_avg:99.97ms
step:1145/1770 train_time:114471ms step_avg:99.97ms
step:1146/1770 train_time:114575ms step_avg:99.98ms
step:1147/1770 train_time:114678ms step_avg:99.98ms
step:1148/1770 train_time:114783ms step_avg:99.99ms
step:1149/1770 train_time:114889ms step_avg:99.99ms
step:1150/1770 train_time:114994ms step_avg:99.99ms
step:1151/1770 train_time:115097ms step_avg:100.00ms
step:1152/1770 train_time:115201ms step_avg:100.00ms
step:1153/1770 train_time:115304ms step_avg:100.00ms
step:1154/1770 train_time:115408ms step_avg:100.01ms
step:1155/1770 train_time:115512ms step_avg:100.01ms
step:1156/1770 train_time:115615ms step_avg:100.01ms
step:1157/1770 train_time:115720ms step_avg:100.02ms
step:1158/1770 train_time:115823ms step_avg:100.02ms
step:1159/1770 train_time:115928ms step_avg:100.02ms
step:1160/1770 train_time:116031ms step_avg:100.03ms
step:1161/1770 train_time:116135ms step_avg:100.03ms
step:1162/1770 train_time:116240ms step_avg:100.03ms
step:1163/1770 train_time:116343ms step_avg:100.04ms
step:1164/1770 train_time:116446ms step_avg:100.04ms
step:1165/1770 train_time:116550ms step_avg:100.04ms
step:1166/1770 train_time:116654ms step_avg:100.05ms
step:1167/1770 train_time:116757ms step_avg:100.05ms
step:1168/1770 train_time:116861ms step_avg:100.05ms
step:1169/1770 train_time:116965ms step_avg:100.06ms
step:1170/1770 train_time:117070ms step_avg:100.06ms
step:1171/1770 train_time:117174ms step_avg:100.06ms
step:1172/1770 train_time:117277ms step_avg:100.07ms
step:1173/1770 train_time:117380ms step_avg:100.07ms
step:1174/1770 train_time:117484ms step_avg:100.07ms
step:1175/1770 train_time:117589ms step_avg:100.08ms
step:1176/1770 train_time:117692ms step_avg:100.08ms
step:1177/1770 train_time:117795ms step_avg:100.08ms
step:1178/1770 train_time:117900ms step_avg:100.08ms
step:1179/1770 train_time:118003ms step_avg:100.09ms
step:1180/1770 train_time:118108ms step_avg:100.09ms
step:1181/1770 train_time:118211ms step_avg:100.09ms
step:1182/1770 train_time:118315ms step_avg:100.10ms
step:1183/1770 train_time:118420ms step_avg:100.10ms
step:1184/1770 train_time:118525ms step_avg:100.11ms
step:1185/1770 train_time:118629ms step_avg:100.11ms
step:1186/1770 train_time:118734ms step_avg:100.11ms
step:1187/1770 train_time:118839ms step_avg:100.12ms
step:1188/1770 train_time:118944ms step_avg:100.12ms
step:1189/1770 train_time:119050ms step_avg:100.13ms
step:1190/1770 train_time:119155ms step_avg:100.13ms
step:1191/1770 train_time:119260ms step_avg:100.13ms
step:1192/1770 train_time:119365ms step_avg:100.14ms
step:1193/1770 train_time:119469ms step_avg:100.14ms
step:1194/1770 train_time:119573ms step_avg:100.15ms
step:1195/1770 train_time:119677ms step_avg:100.15ms
step:1196/1770 train_time:119782ms step_avg:100.15ms
step:1197/1770 train_time:119888ms step_avg:100.16ms
step:1198/1770 train_time:119993ms step_avg:100.16ms
step:1199/1770 train_time:120098ms step_avg:100.17ms
step:1200/1770 train_time:120204ms step_avg:100.17ms
step:1201/1770 train_time:120311ms step_avg:100.18ms
step:1202/1770 train_time:120416ms step_avg:100.18ms
step:1203/1770 train_time:120521ms step_avg:100.18ms
step:1204/1770 train_time:120625ms step_avg:100.19ms
step:1205/1770 train_time:120730ms step_avg:100.19ms
step:1206/1770 train_time:120836ms step_avg:100.20ms
step:1207/1770 train_time:120942ms step_avg:100.20ms
step:1208/1770 train_time:121048ms step_avg:100.21ms
step:1209/1770 train_time:121153ms step_avg:100.21ms
step:1210/1770 train_time:121259ms step_avg:100.21ms
step:1211/1770 train_time:121365ms step_avg:100.22ms
step:1212/1770 train_time:121472ms step_avg:100.22ms
step:1213/1770 train_time:121576ms step_avg:100.23ms
step:1214/1770 train_time:121681ms step_avg:100.23ms
step:1215/1770 train_time:121785ms step_avg:100.23ms
step:1216/1770 train_time:121891ms step_avg:100.24ms
step:1217/1770 train_time:121996ms step_avg:100.24ms
step:1218/1770 train_time:122100ms step_avg:100.25ms
step:1219/1770 train_time:122205ms step_avg:100.25ms
step:1220/1770 train_time:122309ms step_avg:100.25ms
step:1221/1770 train_time:122414ms step_avg:100.26ms
step:1222/1770 train_time:122521ms step_avg:100.26ms
step:1223/1770 train_time:122625ms step_avg:100.27ms
step:1224/1770 train_time:122731ms step_avg:100.27ms
step:1225/1770 train_time:122835ms step_avg:100.27ms
step:1226/1770 train_time:122940ms step_avg:100.28ms
step:1227/1770 train_time:123045ms step_avg:100.28ms
step:1228/1770 train_time:123150ms step_avg:100.29ms
step:1229/1770 train_time:123255ms step_avg:100.29ms
step:1230/1770 train_time:123360ms step_avg:100.29ms
step:1231/1770 train_time:123465ms step_avg:100.30ms
step:1232/1770 train_time:123570ms step_avg:100.30ms
step:1233/1770 train_time:123674ms step_avg:100.30ms
step:1234/1770 train_time:123779ms step_avg:100.31ms
step:1235/1770 train_time:123884ms step_avg:100.31ms
step:1236/1770 train_time:123989ms step_avg:100.32ms
step:1237/1770 train_time:124094ms step_avg:100.32ms
step:1238/1770 train_time:124198ms step_avg:100.32ms
step:1239/1770 train_time:124302ms step_avg:100.32ms
step:1240/1770 train_time:124408ms step_avg:100.33ms
step:1241/1770 train_time:124513ms step_avg:100.33ms
step:1242/1770 train_time:124618ms step_avg:100.34ms
step:1243/1770 train_time:124723ms step_avg:100.34ms
step:1244/1770 train_time:124828ms step_avg:100.34ms
step:1245/1770 train_time:124932ms step_avg:100.35ms
step:1246/1770 train_time:125038ms step_avg:100.35ms
step:1247/1770 train_time:125142ms step_avg:100.35ms
step:1248/1770 train_time:125248ms step_avg:100.36ms
step:1249/1770 train_time:125352ms step_avg:100.36ms
step:1250/1770 train_time:125457ms step_avg:100.37ms
step:1250/1770 val_loss:3.4293 train_time:125558ms step_avg:100.45ms
step:1251/1770 train_time:125586ms step_avg:100.39ms
step:1252/1770 train_time:125675ms step_avg:100.38ms
step:1253/1770 train_time:125783ms step_avg:100.39ms
step:1254/1770 train_time:125887ms step_avg:100.39ms
step:1255/1770 train_time:125993ms step_avg:100.39ms
step:1256/1770 train_time:126098ms step_avg:100.40ms
step:1257/1770 train_time:126202ms step_avg:100.40ms
step:1258/1770 train_time:126307ms step_avg:100.40ms
step:1259/1770 train_time:126412ms step_avg:100.41ms
step:1260/1770 train_time:126516ms step_avg:100.41ms
step:1261/1770 train_time:126622ms step_avg:100.41ms
step:1262/1770 train_time:126727ms step_avg:100.42ms
step:1263/1770 train_time:126833ms step_avg:100.42ms
step:1264/1770 train_time:126939ms step_avg:100.43ms
step:1265/1770 train_time:127043ms step_avg:100.43ms
step:1266/1770 train_time:127148ms step_avg:100.43ms
step:1267/1770 train_time:127253ms step_avg:100.44ms
step:1268/1770 train_time:127358ms step_avg:100.44ms
step:1269/1770 train_time:127462ms step_avg:100.44ms
step:1270/1770 train_time:127567ms step_avg:100.45ms
step:1271/1770 train_time:127672ms step_avg:100.45ms
step:1272/1770 train_time:127778ms step_avg:100.45ms
step:1273/1770 train_time:127883ms step_avg:100.46ms
step:1274/1770 train_time:127988ms step_avg:100.46ms
step:1275/1770 train_time:128094ms step_avg:100.47ms
step:1276/1770 train_time:128198ms step_avg:100.47ms
step:1277/1770 train_time:128302ms step_avg:100.47ms
step:1278/1770 train_time:128407ms step_avg:100.48ms
step:1279/1770 train_time:128512ms step_avg:100.48ms
step:1280/1770 train_time:128617ms step_avg:100.48ms
step:1281/1770 train_time:128722ms step_avg:100.49ms
step:1282/1770 train_time:128828ms step_avg:100.49ms
step:1283/1770 train_time:128932ms step_avg:100.49ms
step:1284/1770 train_time:129037ms step_avg:100.50ms
step:1285/1770 train_time:129141ms step_avg:100.50ms
step:1286/1770 train_time:129246ms step_avg:100.50ms
step:1287/1770 train_time:129351ms step_avg:100.51ms
step:1288/1770 train_time:129456ms step_avg:100.51ms
step:1289/1770 train_time:129561ms step_avg:100.51ms
step:1290/1770 train_time:129665ms step_avg:100.52ms
step:1291/1770 train_time:129769ms step_avg:100.52ms
step:1292/1770 train_time:129875ms step_avg:100.52ms
step:1293/1770 train_time:129981ms step_avg:100.53ms
step:1294/1770 train_time:130085ms step_avg:100.53ms
step:1295/1770 train_time:130191ms step_avg:100.53ms
step:1296/1770 train_time:130297ms step_avg:100.54ms
step:1297/1770 train_time:130401ms step_avg:100.54ms
step:1298/1770 train_time:130506ms step_avg:100.54ms
step:1299/1770 train_time:130613ms step_avg:100.55ms
step:1300/1770 train_time:130716ms step_avg:100.55ms
step:1301/1770 train_time:130822ms step_avg:100.55ms
step:1302/1770 train_time:130927ms step_avg:100.56ms
step:1303/1770 train_time:131032ms step_avg:100.56ms
step:1304/1770 train_time:131137ms step_avg:100.56ms
step:1305/1770 train_time:131241ms step_avg:100.57ms
step:1306/1770 train_time:131346ms step_avg:100.57ms
step:1307/1770 train_time:131450ms step_avg:100.57ms
step:1308/1770 train_time:131555ms step_avg:100.58ms
step:1309/1770 train_time:131660ms step_avg:100.58ms
step:1310/1770 train_time:131765ms step_avg:100.58ms
step:1311/1770 train_time:131871ms step_avg:100.59ms
step:1312/1770 train_time:131976ms step_avg:100.59ms
step:1313/1770 train_time:132080ms step_avg:100.59ms
step:1314/1770 train_time:132184ms step_avg:100.60ms
step:1315/1770 train_time:132288ms step_avg:100.60ms
step:1316/1770 train_time:132393ms step_avg:100.60ms
step:1317/1770 train_time:132499ms step_avg:100.61ms
step:1318/1770 train_time:132606ms step_avg:100.61ms
step:1319/1770 train_time:132710ms step_avg:100.61ms
step:1320/1770 train_time:132814ms step_avg:100.62ms
step:1321/1770 train_time:132920ms step_avg:100.62ms
step:1322/1770 train_time:133027ms step_avg:100.63ms
step:1323/1770 train_time:133132ms step_avg:100.63ms
step:1324/1770 train_time:133237ms step_avg:100.63ms
step:1325/1770 train_time:133343ms step_avg:100.64ms
step:1326/1770 train_time:133448ms step_avg:100.64ms
step:1327/1770 train_time:133556ms step_avg:100.65ms
step:1328/1770 train_time:133660ms step_avg:100.65ms
step:1329/1770 train_time:133764ms step_avg:100.65ms
step:1330/1770 train_time:133869ms step_avg:100.65ms
step:1331/1770 train_time:133976ms step_avg:100.66ms
step:1332/1770 train_time:134080ms step_avg:100.66ms
step:1333/1770 train_time:134185ms step_avg:100.66ms
step:1334/1770 train_time:134289ms step_avg:100.67ms
step:1335/1770 train_time:134395ms step_avg:100.67ms
step:1336/1770 train_time:134499ms step_avg:100.67ms
step:1337/1770 train_time:134605ms step_avg:100.68ms
step:1338/1770 train_time:134710ms step_avg:100.68ms
step:1339/1770 train_time:134816ms step_avg:100.68ms
step:1340/1770 train_time:134921ms step_avg:100.69ms
step:1341/1770 train_time:135026ms step_avg:100.69ms
step:1342/1770 train_time:135131ms step_avg:100.69ms
step:1343/1770 train_time:135236ms step_avg:100.70ms
step:1344/1770 train_time:135340ms step_avg:100.70ms
step:1345/1770 train_time:135445ms step_avg:100.70ms
step:1346/1770 train_time:135550ms step_avg:100.71ms
step:1347/1770 train_time:135655ms step_avg:100.71ms
step:1348/1770 train_time:135761ms step_avg:100.71ms
step:1349/1770 train_time:135866ms step_avg:100.72ms
step:1350/1770 train_time:135971ms step_avg:100.72ms
step:1351/1770 train_time:136077ms step_avg:100.72ms
step:1352/1770 train_time:136182ms step_avg:100.73ms
step:1353/1770 train_time:136287ms step_avg:100.73ms
step:1354/1770 train_time:136392ms step_avg:100.73ms
step:1355/1770 train_time:136497ms step_avg:100.74ms
step:1356/1770 train_time:136602ms step_avg:100.74ms
step:1357/1770 train_time:136707ms step_avg:100.74ms
step:1358/1770 train_time:136813ms step_avg:100.75ms
step:1359/1770 train_time:136918ms step_avg:100.75ms
step:1360/1770 train_time:137025ms step_avg:100.75ms
step:1361/1770 train_time:137130ms step_avg:100.76ms
step:1362/1770 train_time:137236ms step_avg:100.76ms
step:1363/1770 train_time:137340ms step_avg:100.76ms
step:1364/1770 train_time:137445ms step_avg:100.77ms
step:1365/1770 train_time:137549ms step_avg:100.77ms
step:1366/1770 train_time:137654ms step_avg:100.77ms
step:1367/1770 train_time:137758ms step_avg:100.77ms
step:1368/1770 train_time:137863ms step_avg:100.78ms
step:1369/1770 train_time:137968ms step_avg:100.78ms
step:1370/1770 train_time:138074ms step_avg:100.78ms
step:1371/1770 train_time:138179ms step_avg:100.79ms
step:1372/1770 train_time:138284ms step_avg:100.79ms
step:1373/1770 train_time:138389ms step_avg:100.79ms
step:1374/1770 train_time:138497ms step_avg:100.80ms
step:1375/1770 train_time:138602ms step_avg:100.80ms
step:1375/1770 val_loss:3.3856 train_time:138701ms step_avg:100.87ms
step:1376/1770 train_time:138729ms step_avg:100.82ms
step:1377/1770 train_time:138819ms step_avg:100.81ms
step:1378/1770 train_time:138926ms step_avg:100.82ms
step:1379/1770 train_time:139031ms step_avg:100.82ms
step:1380/1770 train_time:139135ms step_avg:100.82ms
step:1381/1770 train_time:139240ms step_avg:100.83ms
step:1382/1770 train_time:139344ms step_avg:100.83ms
step:1383/1770 train_time:139449ms step_avg:100.83ms
step:1384/1770 train_time:139553ms step_avg:100.83ms
step:1385/1770 train_time:139658ms step_avg:100.84ms
step:1386/1770 train_time:139764ms step_avg:100.84ms
step:1387/1770 train_time:139869ms step_avg:100.84ms
step:1388/1770 train_time:139977ms step_avg:100.85ms
step:1389/1770 train_time:140081ms step_avg:100.85ms
step:1390/1770 train_time:140186ms step_avg:100.85ms
step:1391/1770 train_time:140290ms step_avg:100.86ms
step:1392/1770 train_time:140395ms step_avg:100.86ms
step:1393/1770 train_time:140500ms step_avg:100.86ms
step:1394/1770 train_time:140604ms step_avg:100.86ms
step:1395/1770 train_time:140709ms step_avg:100.87ms
step:1396/1770 train_time:140816ms step_avg:100.87ms
step:1397/1770 train_time:140922ms step_avg:100.87ms
step:1398/1770 train_time:141028ms step_avg:100.88ms
step:1399/1770 train_time:141133ms step_avg:100.88ms
step:1400/1770 train_time:141238ms step_avg:100.88ms
step:1401/1770 train_time:141343ms step_avg:100.89ms
step:1402/1770 train_time:141447ms step_avg:100.89ms
step:1403/1770 train_time:141551ms step_avg:100.89ms
step:1404/1770 train_time:141658ms step_avg:100.90ms
step:1405/1770 train_time:141763ms step_avg:100.90ms
step:1406/1770 train_time:141868ms step_avg:100.90ms
step:1407/1770 train_time:141974ms step_avg:100.91ms
step:1408/1770 train_time:142079ms step_avg:100.91ms
step:1409/1770 train_time:142185ms step_avg:100.91ms
step:1410/1770 train_time:142289ms step_avg:100.91ms
step:1411/1770 train_time:142395ms step_avg:100.92ms
step:1412/1770 train_time:142500ms step_avg:100.92ms
step:1413/1770 train_time:142605ms step_avg:100.92ms
step:1414/1770 train_time:142710ms step_avg:100.93ms
step:1415/1770 train_time:142816ms step_avg:100.93ms
step:1416/1770 train_time:142921ms step_avg:100.93ms
step:1417/1770 train_time:143026ms step_avg:100.94ms
step:1418/1770 train_time:143130ms step_avg:100.94ms
step:1419/1770 train_time:143237ms step_avg:100.94ms
step:1420/1770 train_time:143342ms step_avg:100.95ms
step:1421/1770 train_time:143446ms step_avg:100.95ms
step:1422/1770 train_time:143552ms step_avg:100.95ms
step:1423/1770 train_time:143658ms step_avg:100.95ms
step:1424/1770 train_time:143762ms step_avg:100.96ms
step:1425/1770 train_time:143867ms step_avg:100.96ms
step:1426/1770 train_time:143974ms step_avg:100.96ms
step:1427/1770 train_time:144079ms step_avg:100.97ms
step:1428/1770 train_time:144185ms step_avg:100.97ms
step:1429/1770 train_time:144289ms step_avg:100.97ms
step:1430/1770 train_time:144396ms step_avg:100.98ms
step:1431/1770 train_time:144501ms step_avg:100.98ms
step:1432/1770 train_time:144607ms step_avg:100.98ms
step:1433/1770 train_time:144712ms step_avg:100.99ms
step:1434/1770 train_time:144818ms step_avg:100.99ms
step:1435/1770 train_time:144923ms step_avg:100.99ms
step:1436/1770 train_time:145031ms step_avg:101.00ms
step:1437/1770 train_time:145137ms step_avg:101.00ms
step:1438/1770 train_time:145241ms step_avg:101.00ms
step:1439/1770 train_time:145345ms step_avg:101.00ms
step:1440/1770 train_time:145449ms step_avg:101.01ms
step:1441/1770 train_time:145556ms step_avg:101.01ms
step:1442/1770 train_time:145660ms step_avg:101.01ms
step:1443/1770 train_time:145766ms step_avg:101.02ms
step:1444/1770 train_time:145873ms step_avg:101.02ms
step:1445/1770 train_time:145978ms step_avg:101.02ms
step:1446/1770 train_time:146084ms step_avg:101.03ms
step:1447/1770 train_time:146190ms step_avg:101.03ms
step:1448/1770 train_time:146296ms step_avg:101.03ms
step:1449/1770 train_time:146404ms step_avg:101.04ms
step:1450/1770 train_time:146510ms step_avg:101.04ms
step:1451/1770 train_time:146617ms step_avg:101.05ms
step:1452/1770 train_time:146723ms step_avg:101.05ms
step:1453/1770 train_time:146828ms step_avg:101.05ms
step:1454/1770 train_time:146935ms step_avg:101.06ms
step:1455/1770 train_time:147042ms step_avg:101.06ms
step:1456/1770 train_time:147149ms step_avg:101.06ms
step:1457/1770 train_time:147255ms step_avg:101.07ms
step:1458/1770 train_time:147361ms step_avg:101.07ms
step:1459/1770 train_time:147468ms step_avg:101.07ms
step:1460/1770 train_time:147573ms step_avg:101.08ms
step:1461/1770 train_time:147680ms step_avg:101.08ms
step:1462/1770 train_time:147787ms step_avg:101.09ms
step:1463/1770 train_time:147895ms step_avg:101.09ms
step:1464/1770 train_time:148002ms step_avg:101.09ms
step:1465/1770 train_time:148108ms step_avg:101.10ms
step:1466/1770 train_time:148215ms step_avg:101.10ms
step:1467/1770 train_time:148321ms step_avg:101.10ms
step:1468/1770 train_time:148428ms step_avg:101.11ms
step:1469/1770 train_time:148534ms step_avg:101.11ms
step:1470/1770 train_time:148639ms step_avg:101.12ms
step:1471/1770 train_time:148746ms step_avg:101.12ms
step:1472/1770 train_time:148851ms step_avg:101.12ms
step:1473/1770 train_time:148961ms step_avg:101.13ms
step:1474/1770 train_time:149068ms step_avg:101.13ms
step:1475/1770 train_time:149174ms step_avg:101.13ms
step:1476/1770 train_time:149279ms step_avg:101.14ms
step:1477/1770 train_time:149388ms step_avg:101.14ms
step:1478/1770 train_time:149493ms step_avg:101.15ms
step:1479/1770 train_time:149600ms step_avg:101.15ms
step:1480/1770 train_time:149705ms step_avg:101.15ms
step:1481/1770 train_time:149815ms step_avg:101.16ms
step:1482/1770 train_time:149920ms step_avg:101.16ms
step:1483/1770 train_time:150026ms step_avg:101.16ms
step:1484/1770 train_time:150132ms step_avg:101.17ms
step:1485/1770 train_time:150237ms step_avg:101.17ms
step:1486/1770 train_time:150344ms step_avg:101.17ms
step:1487/1770 train_time:150449ms step_avg:101.18ms
step:1488/1770 train_time:150557ms step_avg:101.18ms
step:1489/1770 train_time:150664ms step_avg:101.18ms
step:1490/1770 train_time:150771ms step_avg:101.19ms
step:1491/1770 train_time:150878ms step_avg:101.19ms
step:1492/1770 train_time:150984ms step_avg:101.20ms
step:1493/1770 train_time:151093ms step_avg:101.20ms
step:1494/1770 train_time:151201ms step_avg:101.21ms
step:1495/1770 train_time:151307ms step_avg:101.21ms
step:1496/1770 train_time:151413ms step_avg:101.21ms
step:1497/1770 train_time:151518ms step_avg:101.21ms
step:1498/1770 train_time:151623ms step_avg:101.22ms
step:1499/1770 train_time:151729ms step_avg:101.22ms
step:1500/1770 train_time:151837ms step_avg:101.22ms
step:1500/1770 val_loss:3.3474 train_time:151938ms step_avg:101.29ms
step:1501/1770 train_time:151966ms step_avg:101.24ms
step:1502/1770 train_time:152061ms step_avg:101.24ms
step:1503/1770 train_time:152168ms step_avg:101.24ms
step:1504/1770 train_time:152274ms step_avg:101.25ms
step:1505/1770 train_time:152381ms step_avg:101.25ms
step:1506/1770 train_time:152487ms step_avg:101.25ms
step:1507/1770 train_time:152593ms step_avg:101.26ms
step:1508/1770 train_time:152699ms step_avg:101.26ms
step:1509/1770 train_time:152804ms step_avg:101.26ms
step:1510/1770 train_time:152910ms step_avg:101.26ms
step:1511/1770 train_time:153016ms step_avg:101.27ms
step:1512/1770 train_time:153122ms step_avg:101.27ms
step:1513/1770 train_time:153229ms step_avg:101.27ms
step:1514/1770 train_time:153334ms step_avg:101.28ms
step:1515/1770 train_time:153441ms step_avg:101.28ms
step:1516/1770 train_time:153547ms step_avg:101.28ms
step:1517/1770 train_time:153653ms step_avg:101.29ms
step:1518/1770 train_time:153761ms step_avg:101.29ms
step:1519/1770 train_time:153866ms step_avg:101.29ms
step:1520/1770 train_time:153974ms step_avg:101.30ms
step:1521/1770 train_time:154080ms step_avg:101.30ms
step:1522/1770 train_time:154186ms step_avg:101.30ms
step:1523/1770 train_time:154293ms step_avg:101.31ms
step:1524/1770 train_time:154401ms step_avg:101.31ms
step:1525/1770 train_time:154508ms step_avg:101.32ms
step:1526/1770 train_time:154614ms step_avg:101.32ms
step:1527/1770 train_time:154721ms step_avg:101.32ms
step:1528/1770 train_time:154828ms step_avg:101.33ms
step:1529/1770 train_time:154935ms step_avg:101.33ms
step:1530/1770 train_time:155043ms step_avg:101.34ms
step:1531/1770 train_time:155149ms step_avg:101.34ms
step:1532/1770 train_time:155255ms step_avg:101.34ms
step:1533/1770 train_time:155362ms step_avg:101.35ms
step:1534/1770 train_time:155469ms step_avg:101.35ms
step:1535/1770 train_time:155575ms step_avg:101.35ms
step:1536/1770 train_time:155682ms step_avg:101.36ms
step:1537/1770 train_time:155788ms step_avg:101.36ms
step:1538/1770 train_time:155895ms step_avg:101.36ms
step:1539/1770 train_time:156001ms step_avg:101.36ms
step:1540/1770 train_time:156109ms step_avg:101.37ms
step:1541/1770 train_time:156216ms step_avg:101.37ms
step:1542/1770 train_time:156322ms step_avg:101.38ms
step:1543/1770 train_time:156430ms step_avg:101.38ms
step:1544/1770 train_time:156536ms step_avg:101.38ms
step:1545/1770 train_time:156643ms step_avg:101.39ms
step:1546/1770 train_time:156750ms step_avg:101.39ms
step:1547/1770 train_time:156856ms step_avg:101.39ms
step:1548/1770 train_time:156962ms step_avg:101.40ms
step:1549/1770 train_time:157069ms step_avg:101.40ms
step:1550/1770 train_time:157175ms step_avg:101.40ms
step:1551/1770 train_time:157281ms step_avg:101.41ms
step:1552/1770 train_time:157389ms step_avg:101.41ms
step:1553/1770 train_time:157495ms step_avg:101.41ms
step:1554/1770 train_time:157601ms step_avg:101.42ms
step:1555/1770 train_time:157707ms step_avg:101.42ms
step:1556/1770 train_time:157813ms step_avg:101.42ms
step:1557/1770 train_time:157918ms step_avg:101.42ms
step:1558/1770 train_time:158024ms step_avg:101.43ms
step:1559/1770 train_time:158129ms step_avg:101.43ms
step:1560/1770 train_time:158235ms step_avg:101.43ms
step:1561/1770 train_time:158344ms step_avg:101.44ms
step:1562/1770 train_time:158450ms step_avg:101.44ms
step:1563/1770 train_time:158555ms step_avg:101.44ms
step:1564/1770 train_time:158662ms step_avg:101.45ms
step:1565/1770 train_time:158768ms step_avg:101.45ms
step:1566/1770 train_time:158874ms step_avg:101.45ms
step:1567/1770 train_time:158981ms step_avg:101.46ms
step:1568/1770 train_time:159087ms step_avg:101.46ms
step:1569/1770 train_time:159195ms step_avg:101.46ms
step:1570/1770 train_time:159301ms step_avg:101.47ms
step:1571/1770 train_time:159408ms step_avg:101.47ms
step:1572/1770 train_time:159515ms step_avg:101.47ms
step:1573/1770 train_time:159624ms step_avg:101.48ms
step:1574/1770 train_time:159731ms step_avg:101.48ms
step:1575/1770 train_time:159838ms step_avg:101.48ms
step:1576/1770 train_time:159944ms step_avg:101.49ms
step:1577/1770 train_time:160053ms step_avg:101.49ms
step:1578/1770 train_time:160161ms step_avg:101.50ms
step:1579/1770 train_time:160266ms step_avg:101.50ms
step:1580/1770 train_time:160373ms step_avg:101.50ms
step:1581/1770 train_time:160482ms step_avg:101.51ms
step:1582/1770 train_time:160589ms step_avg:101.51ms
step:1583/1770 train_time:160695ms step_avg:101.51ms
step:1584/1770 train_time:160802ms step_avg:101.52ms
step:1585/1770 train_time:160907ms step_avg:101.52ms
step:1586/1770 train_time:161016ms step_avg:101.52ms
step:1587/1770 train_time:161124ms step_avg:101.53ms
step:1588/1770 train_time:161230ms step_avg:101.53ms
step:1589/1770 train_time:161337ms step_avg:101.53ms
step:1590/1770 train_time:161443ms step_avg:101.54ms
step:1591/1770 train_time:161548ms step_avg:101.54ms
step:1592/1770 train_time:161655ms step_avg:101.54ms
step:1593/1770 train_time:161762ms step_avg:101.55ms
step:1594/1770 train_time:161868ms step_avg:101.55ms
step:1595/1770 train_time:161974ms step_avg:101.55ms
step:1596/1770 train_time:162082ms step_avg:101.56ms
step:1597/1770 train_time:162188ms step_avg:101.56ms
step:1598/1770 train_time:162294ms step_avg:101.56ms
step:1599/1770 train_time:162402ms step_avg:101.57ms
step:1600/1770 train_time:162510ms step_avg:101.57ms
step:1601/1770 train_time:162617ms step_avg:101.57ms
step:1602/1770 train_time:162723ms step_avg:101.58ms
step:1603/1770 train_time:162830ms step_avg:101.58ms
step:1604/1770 train_time:162935ms step_avg:101.58ms
step:1605/1770 train_time:163042ms step_avg:101.58ms
step:1606/1770 train_time:163148ms step_avg:101.59ms
step:1607/1770 train_time:163259ms step_avg:101.59ms
step:1608/1770 train_time:163366ms step_avg:101.60ms
step:1609/1770 train_time:163473ms step_avg:101.60ms
step:1610/1770 train_time:163579ms step_avg:101.60ms
step:1611/1770 train_time:163686ms step_avg:101.61ms
step:1612/1770 train_time:163794ms step_avg:101.61ms
step:1613/1770 train_time:163901ms step_avg:101.61ms
step:1614/1770 train_time:164007ms step_avg:101.62ms
step:1615/1770 train_time:164115ms step_avg:101.62ms
step:1616/1770 train_time:164222ms step_avg:101.62ms
step:1617/1770 train_time:164329ms step_avg:101.63ms
step:1618/1770 train_time:164437ms step_avg:101.63ms
step:1619/1770 train_time:164544ms step_avg:101.63ms
step:1620/1770 train_time:164652ms step_avg:101.64ms
step:1621/1770 train_time:164758ms step_avg:101.64ms
step:1622/1770 train_time:164865ms step_avg:101.64ms
step:1623/1770 train_time:164973ms step_avg:101.65ms
step:1624/1770 train_time:165078ms step_avg:101.65ms
step:1625/1770 train_time:165184ms step_avg:101.65ms
step:1625/1770 val_loss:3.3130 train_time:165286ms step_avg:101.71ms
step:1626/1770 train_time:165314ms step_avg:101.67ms
step:1627/1770 train_time:165407ms step_avg:101.66ms
step:1628/1770 train_time:165513ms step_avg:101.67ms
step:1629/1770 train_time:165618ms step_avg:101.67ms
step:1630/1770 train_time:165724ms step_avg:101.67ms
step:1631/1770 train_time:165831ms step_avg:101.67ms
step:1632/1770 train_time:165936ms step_avg:101.68ms
step:1633/1770 train_time:166043ms step_avg:101.68ms
step:1634/1770 train_time:166148ms step_avg:101.68ms
step:1635/1770 train_time:166254ms step_avg:101.68ms
step:1636/1770 train_time:166362ms step_avg:101.69ms
step:1637/1770 train_time:166469ms step_avg:101.69ms
step:1638/1770 train_time:166575ms step_avg:101.69ms
step:1639/1770 train_time:166682ms step_avg:101.70ms
step:1640/1770 train_time:166788ms step_avg:101.70ms
step:1641/1770 train_time:166895ms step_avg:101.70ms
step:1642/1770 train_time:167002ms step_avg:101.71ms
step:1643/1770 train_time:167108ms step_avg:101.71ms
step:1644/1770 train_time:167215ms step_avg:101.71ms
step:1645/1770 train_time:167321ms step_avg:101.72ms
step:1646/1770 train_time:167428ms step_avg:101.72ms
step:1647/1770 train_time:167536ms step_avg:101.72ms
step:1648/1770 train_time:167642ms step_avg:101.72ms
step:1649/1770 train_time:167748ms step_avg:101.73ms
step:1650/1770 train_time:167854ms step_avg:101.73ms
step:1651/1770 train_time:167960ms step_avg:101.73ms
step:1652/1770 train_time:168067ms step_avg:101.74ms
step:1653/1770 train_time:168173ms step_avg:101.74ms
step:1654/1770 train_time:168282ms step_avg:101.74ms
step:1655/1770 train_time:168389ms step_avg:101.75ms
step:1656/1770 train_time:168495ms step_avg:101.75ms
step:1657/1770 train_time:168601ms step_avg:101.75ms
step:1658/1770 train_time:168707ms step_avg:101.75ms
step:1659/1770 train_time:168816ms step_avg:101.76ms
step:1660/1770 train_time:168923ms step_avg:101.76ms
step:1661/1770 train_time:169028ms step_avg:101.76ms
step:1662/1770 train_time:169134ms step_avg:101.77ms
step:1663/1770 train_time:169240ms step_avg:101.77ms
step:1664/1770 train_time:169347ms step_avg:101.77ms
step:1665/1770 train_time:169453ms step_avg:101.77ms
step:1666/1770 train_time:169560ms step_avg:101.78ms
step:1667/1770 train_time:169665ms step_avg:101.78ms
step:1668/1770 train_time:169772ms step_avg:101.78ms
step:1669/1770 train_time:169877ms step_avg:101.78ms
step:1670/1770 train_time:169983ms step_avg:101.79ms
step:1671/1770 train_time:170090ms step_avg:101.79ms
step:1672/1770 train_time:170196ms step_avg:101.79ms
step:1673/1770 train_time:170305ms step_avg:101.80ms
step:1674/1770 train_time:170411ms step_avg:101.80ms
step:1675/1770 train_time:170517ms step_avg:101.80ms
step:1676/1770 train_time:170623ms step_avg:101.80ms
step:1677/1770 train_time:170732ms step_avg:101.81ms
step:1678/1770 train_time:170838ms step_avg:101.81ms
step:1679/1770 train_time:170944ms step_avg:101.81ms
step:1680/1770 train_time:171050ms step_avg:101.82ms
step:1681/1770 train_time:171156ms step_avg:101.82ms
step:1682/1770 train_time:171265ms step_avg:101.82ms
step:1683/1770 train_time:171372ms step_avg:101.83ms
step:1684/1770 train_time:171478ms step_avg:101.83ms
step:1685/1770 train_time:171583ms step_avg:101.83ms
step:1686/1770 train_time:171692ms step_avg:101.83ms
step:1687/1770 train_time:171801ms step_avg:101.84ms
step:1688/1770 train_time:171907ms step_avg:101.84ms
step:1689/1770 train_time:172013ms step_avg:101.84ms
step:1690/1770 train_time:172118ms step_avg:101.84ms
step:1691/1770 train_time:172224ms step_avg:101.85ms
step:1692/1770 train_time:172333ms step_avg:101.85ms
step:1693/1770 train_time:172440ms step_avg:101.85ms
step:1694/1770 train_time:172546ms step_avg:101.86ms
step:1695/1770 train_time:172653ms step_avg:101.86ms
step:1696/1770 train_time:172759ms step_avg:101.86ms
step:1697/1770 train_time:172868ms step_avg:101.87ms
step:1698/1770 train_time:172973ms step_avg:101.87ms
step:1699/1770 train_time:173078ms step_avg:101.87ms
step:1700/1770 train_time:173184ms step_avg:101.87ms
step:1701/1770 train_time:173290ms step_avg:101.88ms
step:1702/1770 train_time:173397ms step_avg:101.88ms
step:1703/1770 train_time:173502ms step_avg:101.88ms
step:1704/1770 train_time:173611ms step_avg:101.88ms
step:1705/1770 train_time:173717ms step_avg:101.89ms
step:1706/1770 train_time:173823ms step_avg:101.89ms
step:1707/1770 train_time:173933ms step_avg:101.89ms
step:1708/1770 train_time:174040ms step_avg:101.90ms
step:1709/1770 train_time:174147ms step_avg:101.90ms
step:1710/1770 train_time:174258ms step_avg:101.91ms
step:1711/1770 train_time:174369ms step_avg:101.91ms
step:1712/1770 train_time:174476ms step_avg:101.91ms
step:1713/1770 train_time:174583ms step_avg:101.92ms
step:1714/1770 train_time:174688ms step_avg:101.92ms
step:1715/1770 train_time:174796ms step_avg:101.92ms
step:1716/1770 train_time:174905ms step_avg:101.93ms
step:1717/1770 train_time:175012ms step_avg:101.93ms
step:1718/1770 train_time:175119ms step_avg:101.93ms
step:1719/1770 train_time:175226ms step_avg:101.94ms
step:1720/1770 train_time:175335ms step_avg:101.94ms
step:1721/1770 train_time:175443ms step_avg:101.94ms
step:1722/1770 train_time:175552ms step_avg:101.95ms
step:1723/1770 train_time:175661ms step_avg:101.95ms
step:1724/1770 train_time:175770ms step_avg:101.95ms
step:1725/1770 train_time:175879ms step_avg:101.96ms
step:1726/1770 train_time:175986ms step_avg:101.96ms
step:1727/1770 train_time:176095ms step_avg:101.97ms
step:1728/1770 train_time:176205ms step_avg:101.97ms
step:1729/1770 train_time:176313ms step_avg:101.97ms
step:1730/1770 train_time:176420ms step_avg:101.98ms
step:1731/1770 train_time:176529ms step_avg:101.98ms
step:1732/1770 train_time:176636ms step_avg:101.98ms
step:1733/1770 train_time:176745ms step_avg:101.99ms
step:1734/1770 train_time:176852ms step_avg:101.99ms
step:1735/1770 train_time:176959ms step_avg:101.99ms
step:1736/1770 train_time:177066ms step_avg:102.00ms
step:1737/1770 train_time:177174ms step_avg:102.00ms
step:1738/1770 train_time:177282ms step_avg:102.00ms
step:1739/1770 train_time:177389ms step_avg:102.01ms
step:1740/1770 train_time:177496ms step_avg:102.01ms
step:1741/1770 train_time:177604ms step_avg:102.01ms
step:1742/1770 train_time:177714ms step_avg:102.02ms
step:1743/1770 train_time:177820ms step_avg:102.02ms
step:1744/1770 train_time:177927ms step_avg:102.02ms
step:1745/1770 train_time:178035ms step_avg:102.03ms
step:1746/1770 train_time:178146ms step_avg:102.03ms
step:1747/1770 train_time:178252ms step_avg:102.03ms
step:1748/1770 train_time:178361ms step_avg:102.04ms
step:1749/1770 train_time:178468ms step_avg:102.04ms
step:1750/1770 train_time:178575ms step_avg:102.04ms
step:1750/1770 val_loss:3.2860 train_time:178678ms step_avg:102.10ms
step:1751/1770 train_time:178705ms step_avg:102.06ms
step:1752/1770 train_time:178798ms step_avg:102.05ms
step:1753/1770 train_time:178904ms step_avg:102.06ms
step:1754/1770 train_time:179011ms step_avg:102.06ms
step:1755/1770 train_time:179118ms step_avg:102.06ms
step:1756/1770 train_time:179226ms step_avg:102.06ms
step:1757/1770 train_time:179333ms step_avg:102.07ms
step:1758/1770 train_time:179439ms step_avg:102.07ms
step:1759/1770 train_time:179547ms step_avg:102.07ms
step:1760/1770 train_time:179655ms step_avg:102.08ms
step:1761/1770 train_time:179763ms step_avg:102.08ms
step:1762/1770 train_time:179872ms step_avg:102.08ms
step:1763/1770 train_time:179978ms step_avg:102.09ms
step:1764/1770 train_time:180085ms step_avg:102.09ms
step:1765/1770 train_time:180193ms step_avg:102.09ms
step:1766/1770 train_time:180302ms step_avg:102.10ms
step:1767/1770 train_time:180408ms step_avg:102.10ms
step:1768/1770 train_time:180516ms step_avg:102.10ms
step:1769/1770 train_time:180621ms step_avg:102.10ms
step:1770/1770 train_time:180728ms step_avg:102.11ms
step:1770/1770 val_loss:3.2830 train_time:180832ms step_avg:102.17ms
peak memory allocated: 30724 MiB reserved: 45392 MiB
