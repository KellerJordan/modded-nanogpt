import os
import sys

# Read the current file and the kernels file code ASAP, for logging
with open(sys.argv[0], 'r') as f:
    code = f.read()
with open(os.path.join(os.path.dirname(sys.argv[0]), 'triton_kernels.py'), 'r') as f:
    code += f"\n\n{'-'*40}\n# triton_kernels.py\n{'-'*40}\n\n"
    code += f.read()

import copy
import glob
import math
import threading
import time
import uuid
from dataclasses import dataclass
from itertools import accumulate, pairwise
from pathlib import Path
import gc

os.environ["PYTORCH_ALLOC_CONF"] = "expandable_segments:True"
import torch
import triton

torch.empty(
    1, device=f"cuda:{os.environ['LOCAL_RANK']}", requires_grad=True
).backward()  # prevents a bug on some systems
import torch._dynamo as dynamo
import torch.distributed as dist
import torch.nn.functional as F

# torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min
from kernels import get_kernel
from torch import Tensor, nn

from triton_kernels import XXT, ba_plus_cAA, FusedLinearReLUSquareFunction, FusedSoftcappedCrossEntropy

dynamo.config.recompile_limit = 64

# -----------------------------------------------------------------------------
# Distributed training setup
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert 8 % world_size == 0, "world_size must be a divisor of 8"
grad_accum_steps = 8 // world_size
grad_scale = 2 / grad_accum_steps # consistent grad magnitudes between different num_devices
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng
# Transposed layout by @ChrisJMcCormick allows for faster gradient accumulation.

@torch.library.custom_op("nanogpt::mm_t", mutates_args=())
def mm_t_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    """Computes y = x @ w with F8 weights stored as (in_features, out_features)."""
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        assert x.shape[1] == w.shape[0]  # x: (batch, in), w: (in, out)

        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)

        # _scaled_mm requires column-major B. w_f8 is row-major (in, out).
        # .T.contiguous().T creates a column-major view without changing logical shape.
        w_f8_col_major = w_f8.T.contiguous().T

        out = torch._scaled_mm(
            x_f8,
            w_f8_col_major,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_t_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[0]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_t_backward", mutates_args=())
def mm_t_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()

        x_scale = grad.new_tensor(x_s, dtype=torch.float32)
        w_scale = grad.new_tensor(w_s, dtype=torch.float32)
        grad_scale = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)

        # grad_x = grad @ w.T
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=grad_scale,
            scale_b=w_scale,
            use_fast_accum=False,
        )

        # grad_w = x.T @ grad
        # Result is (in, out), naturally matching weight storage. No final .T needed.
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_scale,
            scale_b=grad_scale,
            use_fast_accum=False,
        )

        return grad_x, grad_w

    grad_x, grad_w = impl(g, x_f8, w_f8)

    return grad_x, grad_w

@mm_t_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward_t(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_t_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context_t(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_t_op.register_autograd(backward_t, setup_context=setup_context_t)

# -----------------------------------------------------------------------------
# Polar Express

# Computed for num_iters=5, safety_factor=2e-2, cushion=2
polar_express_coeffs = [
    (8.156554524902461, -22.48329292557795, 15.878769915207462),
    (4.042929935166739, -2.808917465908714, 0.5000178451051316),
    (3.8916678022926607, -2.772484153217685, 0.5060648178503393),
    (3.285753657755655, -2.3681294933425376, 0.46449024233003106),
    (2.3465413258596377, -1.7097828382687081, 0.42323551169305323)
]

@torch.compile(dynamic=False, fullgraph=True) # Must use dynamic=False or else it's much slower
def polar_express(G: torch.Tensor, split_baddbmm: bool = False):
    """
    Polar Express Sign Method: https://arxiv.org/pdf/2505.16932
    by Noah Amsel, David Persson, Christopher Musco, Robert M. Gower.
    """
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) * (1 + 2e-2) + 1e-6)

    # Allocate buffers
    X = X.contiguous()
    A = torch.empty((*X.shape[:-1], X.size(-2)), device=X.device, dtype=X.dtype)
    B = torch.empty_like(A)
    C = torch.empty_like(X)

    # Select batched vs unbatched
    if split_baddbmm:
        BX_matmul = torch.bmm if X.ndim > 2 else torch.mm
    else:
        aX_plus_BX = torch.baddbmm if X.ndim > 2 else torch.addmm

    # Perform the iterations
    for a, b, c in polar_express_coeffs:
        XXT(X, out=A)  # A = X @ X.mT
        ba_plus_cAA(A, alpha=c, beta=b, out=B)  # B = b * A + c * A @ A

        # Referencing X twice causes pytorch to make a defensive copy,
        # resulting in a cudaMemcpyAsync in baddbmm.
        # For large matrices (i.e., the mlp weights), it's faster to split
        # the operation into two kernels to avoid this.
        if split_baddbmm:
            BX_matmul(B, X, out=C)  # C = B @ X
            C.add_(X, alpha=a)      # C = C + a*X  (in-place, X only read)
        else:
            aX_plus_BX(X, B, X, beta=a, out=C)  # C = a * X + B @ X

        X, C = C, X  # Swap references to avoid unnecessary copies

    if G.size(-2) > G.size(-1):
        X = X.mT
    return X


# -----------------------------------------------------------------------------
# Combined NorMuon + Adam Optimizer

@dataclass
class ParamConfig:
    """Per-parameter configuration for NorMuonAndAdam optimizer."""
    label: str
    optim: str  # "adam" or "normuon"
    comms: str  # "none", "replicated", or "sharded"
    adam_betas: tuple[float, float] | None
    lr_mul: float
    wd_mul: float
    lr: float
    initial_lr: float
    weight_decay: float
    # Adam-specific
    eps: float | None = None
    # NorMuon-specific
    reshape: tuple | None = None
    chunk_size: int | None = None
    momentum: float | None = None
    beta2: float | None = None
    per_matrix_lr_mul: list[float] | None = None


class NorMuonAndAdam:
    """
    Combined optimizer that handles both NorMuon (for projection matrices) and
    Adam (for embeddings/scalars/gate weights).

    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, Muon uses a Newton-Schulz iteration (replaced
    here with Polar Express), which has the advantage that it can be stably run in bfloat16 on the GPU.

    Muon is applied only to the projection matrices in the attention and MLP layers, and is not recommended
    for embeddings, scalars, or individual weight vectors (e.g., bias terms or gate weights).

    Differences from standard Muon:
    - Newton-Shulz is replaced with Polar Express for the orthogonalization step
    - NorMuon adds a low-rank variance estimator similar to Adafactor. https://arxiv.org/pdf/2510.05491
    - Cautious weight decay, a gated version of decoupled weight decay
    - Mantissa tracking for precision

    Adam (for embeddings/scalars/gates):
    - Standard Adam with bias correction
    - Cautious weight decay

    Configuration:
    Unlike torch.optim.Optimizer, this class uses per-parameter configs from a `param_table` dict
    and does not include parameter "groups". All parameters require a .label attribute, and a
    corresponding entry in the param_table to specify their hyperparameters (lr_mul, wd_mul, adam_betas, etc.).

    Communication and ordering:
    Gradient communication is explicitly scheduled rather than hook-driven.
    Reductions are launched in `scatter_order`, while update math and final
    gathers are executed in `work_order`. These orders are independent and
    must each contain every parameter label exactly once.

    Two communication modes are supported per parameter:
    - 'replicated': Gradients are all-reduced and each rank computes the full update.
    - 'sharded': Gradients are reduce-scattered, each rank updates its shard,
      and results are all-gathered.

    Adam parameters may be freely sharded. NorMuon operates on full matrices; sharding is
    supported by grouping matrices into parameter banks. NorMuon parameters must have a
    `.reshape` attribute that reshapes the bank so that the leading dimension is divisible
    by world_size.

    # Contributors include @YouJiacheng, @KonstantinWilleke, @alexrgilbert, @adricarda,
    # @tuttyfrutyee, @vdlad, @ryanyang0, @vagrawal, @varunneal, @chrisjmccormick
    """
    def __init__(self, named_params, param_table: dict, scatter_order: list, work_order: list,
                 adam_defaults: dict, normuon_defaults: dict):
        self.world_size = dist.get_world_size() if dist.is_initialized() else 1

        # Store defaults for each optimizer type
        self.adam_defaults = adam_defaults
        self.normuon_defaults = normuon_defaults
        self.param_table = param_table
        self.scatter_order = scatter_order
        self.work_order = work_order

        # Collect params by label and build config
        self.param_cfgs: dict[nn.Parameter, ParamConfig] = {}
        self.param_states: dict[nn.Parameter, dict] = {}
        self._param_by_label: dict[str, nn.Parameter] = {}
        for name, param in named_params:
            label = getattr(param, "label", None)
            assert label is not None and label in param_table  # all params must have valid label
            assert label not in self._param_by_label  # exactly one param per label
            self._param_by_label[label] = param
            self._build_param_cfg(param, label)

        # Assert scatter_order and work_order match present labels exactly
        present = set(self._param_by_label.keys())
        assert set(scatter_order) == present and set(work_order) == present

        # Handle world_size=1: overwrite comms to "none"
        if self.world_size == 1:
            for p_cfg in self.param_cfgs.values():
                p_cfg.comms = "none"

        # Initialize state for all params
        self._init_state()

        # 0-D CPU tensors to avoid recompilation
        self._step_size_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")
        self._eff_wd_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")
        self._eff_lr_t = torch.tensor(0.0, dtype=torch.float32, device="cpu")

        # Track async operations
        self._reduce_futures: dict[nn.Parameter, tuple] = {}

        # Embed/lm_head tying state
        self.split_embed = False
        self._lm_head_param = self._param_by_label.get("lm_head")
        self._embed_param = self._param_by_label.get("embed")

    def _build_param_cfg(self, param: nn.Parameter, label: str):
        """Build config for a single parameter from param_table."""
        table_entry = self.param_table[label]
        optim = table_entry["optim"]
        comms = table_entry["comms"]
        adam_betas = table_entry.get("adam_betas")
        lr_mul = table_entry.get("lr_mul", 1.0)
        wd_mul = table_entry.get("wd_mul", 1.0)

        if optim == "adam":
            chunk_size = param.shape[0] // self.world_size if comms == "sharded" else None
            p_cfg = ParamConfig(
                label=label,
                optim=optim,
                comms=comms,
                adam_betas=tuple(adam_betas) if adam_betas else None,
                lr_mul=lr_mul,
                wd_mul=wd_mul,
                lr=self.adam_defaults["lr"],
                initial_lr=self.adam_defaults["lr"],
                weight_decay=self.adam_defaults["weight_decay"],
                eps=self.adam_defaults["eps"],
                chunk_size=chunk_size,
            )
        elif optim == "normuon":
            reshape = getattr(param, "reshape", None)
            if reshape is None:
                raise ValueError(f"NorMuon param {label} must have .reshape attribute")
            if reshape[0] % self.world_size != 0:
                raise ValueError(f"reshape[0]={reshape[0]} must be divisible by world_size")

            chunk_size = reshape[0] // self.world_size
            chunk_shape = (chunk_size, *reshape[1:])
            # Shape-based LR multiplier for NorMuon
            shape_mult = max(1.0, chunk_shape[-2] / chunk_shape[-1]) ** 0.5 if len(chunk_shape) >= 2 else 1.0
            lr_mul = shape_mult * lr_mul

            # Per-matrix LR multipliers for MLP c_proj (2x LR on odd indices)
            per_matrix_lr_mul = None
            if label == "mlp":
                rank = dist.get_rank() if dist.is_initialized() else 0
                start_idx = rank * chunk_size
                per_matrix_lr_mul = []
                for i in range(chunk_size):
                    global_idx = start_idx + i
                    is_c_proj = (global_idx % 2 == 1)
                    per_matrix_lr_mul.append(2.0 if is_c_proj else 1.0)

            p_cfg = ParamConfig(
                label=label,
                optim=optim,
                comms=comms,
                adam_betas=tuple(adam_betas) if adam_betas else None,
                lr_mul=lr_mul,
                wd_mul=wd_mul,
                lr=self.normuon_defaults["lr"],
                initial_lr=self.normuon_defaults["lr"],
                weight_decay=self.normuon_defaults["weight_decay"],
                reshape=reshape,
                chunk_size=chunk_size,
                momentum=self.normuon_defaults["momentum"],
                beta2=self.normuon_defaults["beta2"],
                per_matrix_lr_mul=per_matrix_lr_mul,
            )
        else:
            raise ValueError(f"Unknown optim type: {optim}")

        self.param_cfgs[param] = p_cfg

    def _init_state(self):
        """Initialize optimizer state for all parameters."""
        for param, p_cfg in self.param_cfgs.items():
            if p_cfg.optim == "adam":
                # Sharded params use chunk state, replicated use full state
                if p_cfg.comms == "sharded":
                    chunk = param[:p_cfg.chunk_size]
                else:
                    chunk = param
                exp_avg = torch.zeros_like(chunk, dtype=torch.float32, device=param.device)
                self.param_states[param] = dict(step=0, exp_avg=exp_avg, exp_avg_sq=torch.zeros_like(exp_avg))

            elif p_cfg.optim == "normuon":
                chunk_shape = (p_cfg.chunk_size, *p_cfg.reshape[1:])

                # Momentum buffer (FP32 for precision)
                momentum_buffer = torch.zeros(
                    chunk_shape, dtype=torch.float32, device=param.device
                )

                # Second momentum buffer - reduced along one dimension
                if chunk_shape[-2] >= chunk_shape[-1]:
                    second_mom_shape = (*chunk_shape[:-1], 1)
                else:
                    second_mom_shape = (*chunk_shape[:-2], 1, chunk_shape[-1])
                second_momentum_buffer = torch.zeros(
                    second_mom_shape, dtype=torch.float32, device=param.device
                )

                # Mantissa buffer for precision tracking
                mantissa = torch.zeros(
                    chunk_shape, dtype=torch.uint16, device=param.device
                )

                self.param_states[param] = dict(
                    momentum_buffer=momentum_buffer,
                    second_momentum_buffer=second_momentum_buffer,
                    mantissa=mantissa,
                )

    # -----------------------------------
    # Reduce/Gather operations

    def _launch_reduce(self, param: nn.Parameter, grad: Tensor):
        """Launch async reduce for a parameter based on its comms policy."""
        p_cfg = self.param_cfgs[param]

        if p_cfg.comms == "none":
            if p_cfg.optim == "normuon":
                # NorMuon needs reshaped gradient even without communication
                grad = grad.view(p_cfg.reshape)
            self._reduce_futures[param] = (None, grad)
        elif p_cfg.comms == "replicated":
            future = dist.all_reduce(grad, op=dist.ReduceOp.AVG, async_op=True).get_future()
            self._reduce_futures[param] = (future, grad)
        elif p_cfg.comms == "sharded":
            if p_cfg.optim == "normuon":
                # NorMuon: reshape before reduce_scatter
                grad_reshaped = grad.view(p_cfg.reshape)
                grad_chunk = torch.empty(
                    (p_cfg.chunk_size, *grad_reshaped.shape[1:]),
                    dtype=grad.dtype,
                    device=grad.device
                )
                future = dist.reduce_scatter_tensor(
                    grad_chunk, grad_reshaped.contiguous(), op=dist.ReduceOp.AVG, async_op=True
                ).get_future()
                self._reduce_futures[param] = (future, grad_chunk)
            else:
                # Adam: simple reduce_scatter
                grad_chunk = torch.empty_like(grad[:p_cfg.chunk_size])
                future = dist.reduce_scatter_tensor(
                    grad_chunk, grad, op=dist.ReduceOp.AVG, async_op=True
                ).get_future()
                self._reduce_futures[param] = (future, grad_chunk)

    def _launch_gather(self, param: nn.Parameter, p_slice: Tensor) -> "torch.futures.Future":
        """Launch async all_gather for a sharded parameter."""
        p_cfg = self.param_cfgs[param]
        if p_cfg.optim == "normuon":
            full_param = param.data.view(p_cfg.reshape)
            assert full_param.is_contiguous()
            return dist.all_gather_into_tensor(
                full_param, p_slice.contiguous(), async_op=True
            ).get_future()
        else:
            return dist.all_gather_into_tensor(
                param, p_slice.contiguous(), async_op=True
            ).get_future()

    # -----------------------------------
    # State management

    def reset(self):
        """Reset NorMuon momentum buffers and split_embed state (called on training reset)."""
        self.split_embed = False
        for param, p_cfg in self.param_cfgs.items():
            if p_cfg.optim == "normuon":
                p_state = self.param_states[param]
                p_state["momentum_buffer"].zero_()
                p_state["mantissa"].zero_()
                p_state["second_momentum_buffer"].zero_()

    def copy_lm_state_to_embed(self):
        """
        Copy the optimizer state from the lm_head to the embed at the untie point.
        This requires an all-gather + reshard because of different sharding:
        - lm_head (768, 50304) is sharded to (96, 50304) per rank (along model_dim)
        - embed (50304, 768) is sharded to (6288, 768) per rank (along vocab_size)

        We all-gather the lm_head momentum, transpose it, then each rank takes their
        embed shard to get the correct momentum state.
        """
        lm_head = self._lm_head_param
        embed = self._embed_param
        lm_state = self.param_states[lm_head]
        embed_state = self.param_states[embed]
        lm_cfg = self.param_cfgs[lm_head]
        embed_cfg = self.param_cfgs[embed]

        embed_state['step'] = lm_state['step'] # Preserve step count for bias correction

        # Copy optimizer state with all-gather + transpose + reshard
        if self.world_size > 1:
            rank = dist.get_rank()
            lm_chunk_size = lm_cfg.chunk_size  # 96
            embed_chunk_size = embed_cfg.chunk_size  # 6288

            # All-gather lm_head momentum to get full (768, 50304) tensor
            for key in ["exp_avg", "exp_avg_sq"]:
                lm_chunk = lm_state[key]  # (96, 50304)
                full_lm = torch.empty(lm_head.shape[0], lm_head.shape[1], dtype=lm_chunk.dtype, device=lm_chunk.device)
                dist.all_gather_into_tensor(full_lm, lm_chunk.contiguous())
                embed_state[key].copy_(full_lm.T[rank * embed_chunk_size:(rank + 1) * embed_chunk_size])
        else:
            # Single GPU: simple transpose
            for key in ["exp_avg", "exp_avg_sq"]:
                embed_state[key].copy_(lm_state[key].T)

        # Mark as split
        self.split_embed = True

    def state_dict(self):
        """Return the optimizer state as a dict."""
        return {
            "param_states": {id(p): s for p, s in self.param_states.items()},
            "param_cfgs": {id(p): s for p, s in self.param_cfgs.items()},
        }

    def load_state_dict(self, state_dict):
        """Load optimizer state from a dict."""
        # Build id->param mapping
        id_to_param = {id(p): p for p in self.param_cfgs.keys()}

        # Load state, preserving dtypes
        for param_id, saved_p_state in state_dict["param_states"].items():
            if param_id in id_to_param:
                param = id_to_param[param_id]
                p_state = self.param_states[param]
                for k, v in saved_p_state.items():
                    if isinstance(v, torch.Tensor) and k in p_state:
                        target_dtype = p_state[k].dtype
                        p_state[k] = v.to(dtype=target_dtype, device=p_state[k].device)
                    else:
                        p_state[k] = v

    # -----------------------------------
    # Unified optimizer step with explicit ordering

    @torch.no_grad()
    def step(self, do_adam: bool = True):
        """
        Combined optimizer step with explicit ordering.

        Args:
            do_adam: If True, update Adam params. NorMuon params always updated.

        Flow:
        1. Scatter phase: Launch reduces in scatter_order
        2. Work phase: Process updates in work_order
           - Wait for reduce, compute update, launch gather
        3. Finalize phase: Wait for gathers

        While the embeddings are tied:
        - Comms and update math are only done on lm_head.
        - We add embed.grad.T into lm_head.grad before comms.
        - After lm_head gather, we copy lm_head.data.T --> embed.data
        """
        rank = dist.get_rank() if dist.is_initialized() else 0
        lm_param, embed_param = self._lm_head_param, self._embed_param

        # ===== Phase 1: Launch reduces in scatter_order =====
        for label in self.scatter_order:
            param = self._param_by_label[label]
            p_cfg = self.param_cfgs[param]

            if p_cfg.optim == "adam" and not do_adam:
                continue
            if param.grad is None:
                continue

            # lm_head when tied: aggregate embed.grad.T (transposed shapes)
            if label == "lm_head" and do_adam and not self.split_embed:
                if embed_param is not None and embed_param.grad is not None:
                    param.grad.add_(embed_param.grad.T)

            # Skip embed when tied (copied from lm_head after gather)
            if label == "embed" and not self.split_embed:
                continue

            self._launch_reduce(param, param.grad)

        # ===== Phase 2: Process updates in work_order =====
        gather_futures = []
        lm_head_gather_future = None

        for label in self.work_order:
            param = self._param_by_label[label]
            if param not in self._reduce_futures:
                continue

            p_cfg = self.param_cfgs[param]
            if p_cfg.optim == "adam" and not do_adam:
                continue
            # Wait for reduce
            future, grad_chunk = self._reduce_futures[param]
            if future is not None:
                future.wait()
            # Apply update based on optim type
            if p_cfg.optim == "adam":
                p_slice = self._adam_update(param, grad_chunk, p_cfg, rank)
            else:
                p_slice = self._normuon_update(param, grad_chunk, p_cfg, rank)
            # Launch gather for sharded params
            if p_cfg.comms == "sharded" and self.world_size > 1:
                gather_fut = self._launch_gather(param, p_slice)
                if label == "lm_head":
                    lm_head_gather_future = gather_fut
                else:
                    gather_futures.append(gather_fut)

        # ===== Phase 3: Wait for gathers, sync embed if tied =====
        # Wait for lm_head gather first so we can copy to embed while other gathers complete
        if lm_head_gather_future is not None:
            lm_head_gather_future.wait()

        # When tied: copy lm_head.T to embed
        if do_adam and not self.split_embed and embed_param is not None and lm_param is not None:
            embed_param.data.copy_(lm_param.data.T)

        # Wait for remaining gathers
        for fut in gather_futures:
            fut.wait()

        self._reduce_futures.clear()

        # Clear grads for updated params
        for param, p_cfg in self.param_cfgs.items():
            if p_cfg.optim == "adam" and not do_adam:
                continue  # Don't clear Adam grads on even steps
            param.grad = None

    # -----------------------------------
    # Adam update

    def _adam_update(self, param: nn.Parameter, grad_chunk: Tensor, p_cfg: ParamConfig, rank: int) -> Tensor:
        """Apply Adam update to a parameter. Returns the updated p_slice."""
        beta1, beta2 = p_cfg.adam_betas
        lr = p_cfg.lr * p_cfg.lr_mul

        # Get parameter slice
        if p_cfg.comms == "sharded":
            p_slice = param[rank * p_cfg.chunk_size:(rank + 1) * p_cfg.chunk_size]
        else:
            p_slice = param

        p_state = self.param_states[param]
        p_state["step"] += 1
        t = p_state["step"]

        bias1, bias2 = 1 - beta1 ** t, 1 - beta2 ** t
        self._step_size_t.fill_(lr * (bias2 ** 0.5 / bias1))
        self._eff_wd_t.fill_(lr * lr * p_cfg.weight_decay * p_cfg.wd_mul)

        NorMuonAndAdam._adam_update_step(
            p_slice, grad_chunk, p_state["exp_avg"], p_state["exp_avg_sq"],
            beta1, beta2, p_cfg.eps, self._step_size_t, self._eff_wd_t
        )

        return p_slice

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _adam_update_step(p_slice, g_slice, exp_avg, exp_avg_sq, beta1, beta2, eps, step_size_t, eff_wd_t):
        """Compiled Adam update step."""
        exp_avg.mul_(beta1).add_(g_slice, alpha=1 - beta1)
        exp_avg_sq.mul_(beta2).addcmul_(g_slice, g_slice, value=1 - beta2)
        update = exp_avg.div(exp_avg_sq.sqrt().add_(eps)).mul_(step_size_t)
        # Cautious weight decay
        mask = (update * p_slice) > 0
        update.addcmul_(p_slice, mask, value=eff_wd_t)
        p_slice.add_(other=update, alpha=-1.0)

    # -----------------------------------
    # NorMuon update

    def _normuon_update(self, param: nn.Parameter, grad_chunk: Tensor, p_cfg: ParamConfig, rank: int) -> Tensor:
        """Apply NorMuon update to a parameter. Returns the updated p_slice."""
        chunk_shape = grad_chunk.shape

        p_state = self.param_states[param]
        grad_chunk = grad_chunk.float()  # FP32 for momentum

        # Momentum update
        momentum_buffer = p_state["momentum_buffer"]
        momentum_buffer.lerp_(grad_chunk, 1 - p_cfg.momentum)
        updated_grads = grad_chunk.lerp_(momentum_buffer, p_cfg.momentum)

        self._eff_lr_t.fill_(p_cfg.lr_mul * p_cfg.lr)
        self._eff_wd_t.fill_(p_cfg.wd_mul * p_cfg.weight_decay * p_cfg.lr)

        # Polar Express orthogonalization
        is_large_matrix = chunk_shape[-2] > 1024
        v_chunk = polar_express(updated_grads, split_baddbmm=is_large_matrix)

        # Variance reduction
        red_dim = -1 if chunk_shape[-2] >= chunk_shape[-1] else -2
        v_chunk = NorMuonAndAdam._apply_normuon_variance_reduction(
            v_chunk, p_state["second_momentum_buffer"], p_cfg.beta2, red_dim
        )

        # Update parameter, in place, with cautious weight decay
        param_view = param.data.view(p_cfg.reshape)
        p_slice = param_view[rank * p_cfg.chunk_size:(rank + 1) * p_cfg.chunk_size]

        # MLP has per-matrix LR multipliers (c_proj gets 2x LR)
        if p_cfg.per_matrix_lr_mul is not None:
            for mat_idx in range(p_cfg.chunk_size):
                self._eff_lr_t.fill_(p_cfg.lr_mul * p_cfg.per_matrix_lr_mul[mat_idx] * p_cfg.lr)
                self._eff_wd_t.fill_(p_cfg.wd_mul * p_cfg.weight_decay * p_cfg.lr)
                NorMuonAndAdam._cautious_wd_and_update_inplace(
                    p_slice[mat_idx].view(torch.uint16), p_state["mantissa"][mat_idx], v_chunk[mat_idx],
                    self._eff_wd_t, self._eff_lr_t
                )
        else:
            NorMuonAndAdam._cautious_wd_and_update_inplace(
                p_slice.view(torch.uint16), p_state["mantissa"], v_chunk,
                self._eff_wd_t, self._eff_lr_t
            )

        return p_slice

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _cautious_wd_and_update_inplace(p, mantissa, grad, wd_tensor, lr_tensor):
        """
        Cautious weight decay + parameter update. wd_tensor and lr_tensor are 0-D CPU tensors.
        Mantissa is tracked to enable higher precision updates on bfloat16 parameters.
        bfloat16 format: 1 sign bit + 8 exponent bits + 7 mantissa bits = 16 bits total
        float32 format: 1 sign bit + 8 exponent bits + 23 mantissa bits = 32 bits total
        """
        assert p.dtype == mantissa.dtype == torch.uint16
        grad = grad.float()
        wd_factor = wd_tensor.to(torch.float32)
        lr_factor = lr_tensor.to(torch.float32)
        p_precise_raw = (p.to(torch.uint32) << 16) | mantissa.to(torch.uint32)
        p_precise = p_precise_raw.view(torch.float32)
        mask = (grad * p_precise) >= 0
        p_precise.copy_(p_precise - (p_precise * mask * wd_factor * lr_factor) - (grad * lr_factor))
        p.copy_((p_precise_raw >> 16).to(torch.uint16))
        mantissa.copy_(p_precise_raw.to(torch.uint16))

    @staticmethod
    @torch.compile(dynamic=False, fullgraph=True)
    def _apply_normuon_variance_reduction(v_chunk, second_momentum_buffer, beta2, red_dim):
        """NorMuon variance reduction. Algebraically fuses the normalization steps to minimize memory ops."""
        v_mean = v_chunk.float().square().mean(dim=red_dim, keepdim=True)
        red_dim_size = v_chunk.size(red_dim)
        v_norm_sq = v_mean.sum(dim=(-2, -1), keepdim=True).mul_(red_dim_size)
        v_norm = v_norm_sq.sqrt_()
        second_momentum_buffer.lerp_(v_mean.to(dtype=second_momentum_buffer.dtype), 1 - beta2)
        step_size = second_momentum_buffer.clamp_min(1e-10).rsqrt_()
        scaled_sq_sum = (v_mean * red_dim_size) * step_size.float().square()
        v_norm_new = scaled_sq_sum.sum(dim=(-2, -1), keepdim=True).sqrt_()
        final_scale = step_size * (v_norm / v_norm_new.clamp_min_(1e-10))
        return v_chunk.mul_(final_scale.type_as(v_chunk))

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))


class CastedLinearT(nn.Module):
    """
    Linear layer with transposed weight storage (in_features, out_features) which
    addresses the slow kernel that was used for gradient accumulation. @chrisjmccormick
    """
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

        self.weight = nn.Parameter(torch.empty(in_features, out_features, dtype=torch.bfloat16))
        self.reset_parameters()

    def reset_parameters(self) -> None:
        with torch.no_grad():
            nn.init.zeros_(self.weight) # @Grad62304977 and others

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out = torch.ops.nanogpt.mm_t(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return x @ self.weight.type_as(x)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

class Yarn(nn.Module):
    def __init__(self, head_dim, max_seq_len, paired=False):
        super().__init__()
        self.head_dim = head_dim
        self.max_seq_len = max_seq_len
        self.paired = paired
        self.reset()

    def rotary(self, x_BTHD):
        assert self.factor1.size(0) >= x_BTHD.size(-3)
        factor1, factor2 = (
            self.factor1[None, : x_BTHD.size(-3), None, :],
            self.factor2[None, : x_BTHD.size(-3), None, :],
        )
        x_flip = x_BTHD.view(*x_BTHD.shape[:-1], x_BTHD.shape[-1] // 2, 2).flip(-1).view(x_BTHD.shape)
        return factor1 * x_BTHD + factor2 * x_flip

    def reset(self):
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=self.head_dim//4, dtype=torch.float32, device=device)
        angular_freq = angular_freq.repeat_interleave(2)
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(self.head_dim//2)])
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=device)
        if not self.paired:
            theta = torch.outer(t, angular_freq)
            self.factor1 = nn.Buffer(
                theta.cos().to(torch.bfloat16), persistent=False
            )
            self.factor2 = nn.Buffer(
                theta.sin().to(torch.bfloat16), persistent=False
            )
        else:
            t_even = 2 * t
            t_odd = 2 * t + 1
            theta1 = torch.outer(t_even, angular_freq)
            theta2 = torch.outer(t_odd, angular_freq)
            self.factor1 = nn.Buffer(
                torch.cat((theta1.cos(), theta2.cos()), dim=-1).to(torch.bfloat16),
                persistent=False
            )
            self.factor2 = nn.Buffer(
                torch.cat((theta1.sin(), theta2.sin()), dim=-1).to(torch.bfloat16),
                persistent=False
            )
        self.factor2[..., 1::2] *= -1
        self.angular_freq = angular_freq
        # start with 0.1, inspired by 0.12 from @leloykun and learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        self.attn_scale = 0.1

    def apply(self, old_window: int, new_window: int, alpha: int=1, beta: int=32):
        rotations = old_window * self.angular_freq / (2 * torch.pi)
        scaling_factor = old_window / new_window
        interpolation_weight = torch.clamp((rotations - alpha) / (beta - alpha), 0, 1)
        self.angular_freq *= scaling_factor + interpolation_weight * (1 - scaling_factor)
        t = torch.arange(2*self.max_seq_len, dtype=torch.float32, device=self.angular_freq.device)
        if not self.paired:
            theta = torch.outer(t, self.angular_freq)
            self.factor1.copy_(theta.cos())
            self.factor2.copy_(theta.sin())
        else:
            t_even = 2 * t
            t_odd = 2 * t + 1
            theta1 = torch.outer(t_even, self.angular_freq)
            theta2 = torch.outer(t_odd, self.angular_freq)
            self.factor1.copy_(torch.cat((theta1.cos(), theta2.cos()), dim=-1))
            self.factor2.copy_(torch.cat((theta1.sin(), theta2.sin()), dim=-1))
        self.factor2[..., 1::2] *= -1
        self.attn_scale *= 0.2 * math.log(new_window / old_window) + 1

@dataclass
class AttnArgs:
    ve: torch.Tensor
    sa_lambdas: torch.Tensor
    seqlens: torch.Tensor
    bm_size: int
    yarn: Yarn
    key_offset: bool
    attn_gate_w: torch.Tensor
    ve_gate_w: torch.Tensor

flash_attn_interface = get_kernel('varunneal/flash-attention-3').flash_attn_interface

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, head_dim: int, num_heads: int, paired: bool = False):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        self.dim = dim
        self.hdim = num_heads * head_dim
        self.paired = paired
        assert self.hdim == self.dim, "num_heads * head_dim must equal model_dim"
        # Weights are stored in parameter banks and passed via forward()

    def forward(self, x: Tensor, attn_args: AttnArgs, qkvo_w: Tensor):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "varlen sequences requires B == 1"
        assert T % 16 == 0
        # unpack attention args
        yarn = attn_args.yarn
        ve, sa_lambdas, key_offset = attn_args.ve, attn_args.sa_lambdas, attn_args.key_offset
        seqlens, bm_size = attn_args.seqlens, attn_args.bm_size
        # sparse gated attention to enable context based no-op by @classiclarryd
        # only include gates on layers with value embeds used on forward pass
        attn_gate_w, ve_gate_w = attn_args.attn_gate_w, attn_args.ve_gate_w

        q, k, v = F.linear(x, sa_lambdas[0] * qkvo_w[:self.dim * 3].type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        max_len = args.train_max_seq_len if self.training else (args.val_batch_size // (grad_accum_steps * world_size))

        q, k = norm(q), norm(k) # QK norm @Grad62304977

        if not self.paired:
            q, k = yarn.rotary(q), yarn.rotary(k)

            if key_offset:
                # shift keys forward for the stationary head dims. Enables 1-layer induction.
                k[:, 1:, :, self.head_dim // 2:] = k[:, :-1, :, self.head_dim // 2:]

            if ve is not None:
                ve_gate_out = 2 * torch.sigmoid(F.linear(torch.cat([x[..., :6], ve[None, ..., :6]], dim=-1), ve_gate_w)).view(B, T, self.num_heads, 1)
                v = v + ve_gate_out * ve.view_as(v) # @ KoszarskyB & @Grad62304977

        else:
            # Paired heads: adjacent heads' queries attend to each other's keys.
            # Two copies of the input stream are interleaved to achieve this, which:
            # - doubles the length of each sequence
            # - halves the effective window size
            q = q.view(B, T, self.num_heads // 2, self.head_dim * 2)
            k = k.view(B, T, self.num_heads // 2, self.head_dim * 2)
            v = v.reshape(B, T * 2, self.num_heads // 2, self.head_dim)

            q, k = yarn.rotary(q), yarn.rotary(k)

            q = q.view(B, T * 2, self.num_heads // 2, self.head_dim)
            k = k.view(B, T * 2, self.num_heads // 2, self.head_dim)

            if ve is not None:
                ve_gate_out = 2 * torch.sigmoid(F.linear(x[..., :12], ve_gate_w)).view(B, T * 2, self.num_heads // 2, 1)
                v = v + ve_gate_out * ve.view_as(v)

            seqlens = 2 * seqlens
            max_len = 2 * max_len

        # use flash_attn over flex_attn @varunneal. flash_attn_varlen suggested by @YouJiacheng
        y = flash_attn_interface.flash_attn_varlen_func(q[0], k[0], v[0], cu_seqlens_q=seqlens, cu_seqlens_k=seqlens,
                                                        max_seqlen_q=max_len, max_seqlen_k=max_len,
                                                        causal=True, softmax_scale=yarn.attn_scale, window_size=(bm_size, 0))
        y = y.view(B, T, self.num_heads, self.head_dim)
        y = y * torch.sigmoid(F.linear(x[..., :12], attn_gate_w)).view(B, T, self.num_heads, 1)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = F.linear(y, sa_lambdas[1] * qkvo_w[self.dim * 3:].type_as(y))  # sa_lambdas[1] pre-multiplied to O @shenberg
        return y

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        # Weights are stored in parameter banks and passed via forward()

    def forward(self, x: Tensor, c_fc: Tensor, c_proj: Tensor):
        # relu(x)^2:
        # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        # Fused triton kernel for relu(x @ W1.T)^2 @ W2.T
        return FusedLinearReLUSquareFunction.apply(x, c_fc, c_proj)

class Block(nn.Module):
    def __init__(self, dim: int, head_dim: int, num_heads: int, has_attn: bool, has_mlp: bool, use_paired_head: bool):
        super().__init__()
        # skip attention of blocks.6 (the 7th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, head_dim, num_heads, paired=use_paired_head) if has_attn else None
        # skip MLP blocks for first MLP layer by @EmelyanenkoK
        self.mlp = MLP() if has_mlp else None

    def forward(self, x: Tensor, attn_args: AttnArgs, qkvo_w: Tensor = None, c_fc: Tensor = None, c_proj: Tensor = None):
        if self.attn is not None:
            x = x + self.attn(norm(x), attn_args, qkvo_w)
        if self.mlp is not None:
            x = x + self.mlp(norm(x), c_fc, c_proj)
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

@dataclass
class ForwardScheduleConfig:
    mtp_weights: torch.Tensor
    ws_short: int
    ws_long: int

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, head_dim: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.num_layers = num_layers
        self.vocab_size = next_multiple_of_n(vocab_size, n=128)

        self.smear_gate = nn.Linear(12, 1, bias=False)
        nn.init.zeros_(self.smear_gate.weight)
        self.smear_gate.weight.label = 'smear_gate'

        self.skip_gate = nn.Linear(12, 1, bias=False)
        nn.init.zeros_(self.skip_gate.weight)
        self.skip_gate.weight.label = 'skip_gate'

        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.Parameter(0.01 * torch.randn(5 * self.vocab_size, model_dim, dtype=torch.bfloat16))
        self.value_embeds.label = 'value_embed'

        # parameter banks for attention and value embedding gate weights
        self.attn_gate_bank = nn.Parameter(torch.zeros(10, num_heads, 12)) # 10 layers
        self.attn_gate_bank.label = 'attn_gate_bank'
        self.ve_gate_bank = nn.Parameter(torch.zeros(5, num_heads, 12)) # 5 unique gates
        self.ve_gate_bank.label = 've_gate_bank'

        # -----------------------------------
        # Parameter banks for sharded optimization, by @chrisjmccormick

        # Identify which layers have attention/MLP
        # Attention is skipped in layer 6 by @YouJiacheng
        self.attn_layer_indices = [i for i in range(num_layers) if i != 6]
        # All layers have MLP (At 11 layers--dropped first layer @EmelyanenkoK)
        self.mlp_layer_indices = list(range(num_layers))

        hdim = num_heads * head_dim
        mlp_hdim = 4 * model_dim

        # Create index mappings: layer_idx -> bank_idx
        self.layer_to_attn_idx = {layer_idx: bank_idx for bank_idx, layer_idx in enumerate(self.attn_layer_indices)}
        self.layer_to_mlp_idx = {layer_idx: bank_idx for bank_idx, layer_idx in enumerate(self.mlp_layer_indices)}

        # Attention bank: stores QKVO weights for all attention layers
        # merged QKVO weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        # Simplified layout by @chrisjmccormick
        # Shape: (num_attn_layers, 4*model_dim, hdim) = (10, 3072, 768)
        # Reshape for sharding: (40, 768, 768) for even distribution across 8 GPUs
        self.attn_bank = nn.Parameter(torch.empty(len(self.attn_layer_indices), 4 * model_dim, hdim))
        self.attn_bank.label = 'attn'
        self.attn_bank.reshape = (len(self.attn_layer_indices) * 4, hdim, hdim)  # (40, 768, 768)

        # MLP bank: stores c_fc and c_proj for all MLP layers
        # Shape: (num_mlp_layers + padding, 2, mlp_hdim, model_dim) = (12, 2, 3072, 768)
        # We add 1 padding layer (index 11) to get 12*2=24 matrices for even distribution across 8 GPUs
        # Reshape for sharding: (24, 3072, 768)
        num_mlp_with_padding = len(self.mlp_layer_indices) + 1  # 11 + 1 = 12
        self.mlp_bank = nn.Parameter(torch.empty(num_mlp_with_padding, 2, mlp_hdim, model_dim))
        self.mlp_bank.label = 'mlp'
        self.mlp_bank.reshape = (num_mlp_with_padding * 2, mlp_hdim, model_dim)  # (24, 3072, 768)

        # improved init scale by @YouJiacheng and @srashedll
        std = 0.5 * model_dim ** -0.5
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.attn_bank.uniform_(-bound, bound)
            self.mlp_bank[:, 0, :, :].uniform_(-bound, bound)  # c_fc
            self.mlp_bank[:, 1, :, :].zero_()  # c_proj - zero init suggested by @Grad62304977

        # Create blocks with has_attn/has_mlp flags
        self.paired_head_layers = [0, 2, 5, 9]
        self.blocks = nn.ModuleList([
            Block(model_dim, head_dim, num_heads,
                  has_attn=(i in self.layer_to_attn_idx),
                  has_mlp=(i in self.layer_to_mlp_idx),
                  use_paired_head=(i in self.paired_head_layers))
            for i in range(num_layers)
        ])
        self.yarn = Yarn(head_dim, max_seq_len)
        self.yarn_paired_head = Yarn(head_dim, max_seq_len, paired=True)
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        use_fp8 = not os.environ.get("DISABLE_FP8", False)
        # Transposed weight storage for faster gradient accumulation
        self.lm_head = CastedLinearT(model_dim, self.vocab_size, use_fp8=use_fp8, x_s=100/448, w_s=1.6/448, grad_s=grad_scale * 0.75/448)

        nn.init.normal_(self.lm_head.weight, mean=0, std=0.005)
        self.lm_head.weight.label = 'lm_head'

        self.embed = nn.Embedding(self.vocab_size, model_dim)
        self.embed.weight.label = 'embed'
        with torch.no_grad():
            self.embed.weight.copy_(self.lm_head.weight.T)

        self.bigram_embed = nn.Embedding(args.bigram_vocab_size, model_dim)
        self.bigram_embed.weight.label = 'bigram_embed'
        nn.init.zeros_(self.bigram_embed.weight)

        # x0_lambdas separated out for different optimizer treatment (no beta smoothing)
        self.x0_lambdas = nn.Parameter(torch.zeros(num_layers))
        self.x0_lambdas.label = 'x0_lambdas'

        pad = (-num_layers * 3 - 3) % dist.get_world_size()  # updated: 3*num_layers instead of 4*
        self.scalars = nn.Parameter(
            torch.cat(
                [
                    1.1 * torch.ones(num_layers),  # resid lambdas. 1.1 init such that layer i weight is i^(num_layers-i).
                    *[torch.tensor([0.5, 1.0]) for _ in range(num_layers)],  # SA lambdas
                    0.1 * torch.ones(num_layers), # bigram lambdas
                    torch.zeros(1), # smear_lambda
                    0.5*torch.ones(1), # backout_lambda
                    -1.5 * torch.ones(1),  # skip_lambda -> σ(-1.5) ≈ 0.18
                    torch.ones(pad),
                ]
            )
        )
        self.scalars.label = 'scalars'

    def forward(self, input_seq: Tensor, target_seq: Tensor, seqlens: Tensor, bigram_input_seq: Tensor, schedule_cfg: ForwardScheduleConfig):
        assert input_seq.ndim == 1

        # unpack schedule_cfg
        mtp_weights, ws_short, ws_long = schedule_cfg.mtp_weights, schedule_cfg.ws_short, schedule_cfg.ws_long

        # set configs
        skip_connections = []
        skip_in = [3] # long attention window on layer 3
        skip_out = [6] # no attn op on layer 6
        x_backout = None
        backout_layer = 7

        # set lambdas
        resid_lambdas = self.scalars[: 1 * self.num_layers]
        x0_lambdas = self.x0_lambdas
        sa_lambdas = self.scalars[1 * self.num_layers: 3 * self.num_layers].view(-1, 2)
        bigram_lambdas = self.scalars[3 * self.num_layers: 4 * self.num_layers]
        smear_lambda = self.scalars[4 * self.num_layers]
        backout_lambda = self.scalars[4 * self.num_layers+1]
        skip_lambda = self.scalars[4 * self.num_layers+2]

        # set block masks and key shift
        bm_sizes = [ws_short, ws_short, ws_short, ws_long, ws_short, ws_short, None, ws_short, ws_short, ws_short, ws_long]
        assert len(bm_sizes) == self.num_layers
        key_offset = [b==ws_long for b in bm_sizes] # apply partial key offset to long windows

        # Embedding lookup - embed is synced from lm_head during tied phase by optimizer
        x = self.embed(input_seq)
        x0_bigram = self.bigram_embed(bigram_input_seq)[None]

        # Value embeddings - always computed (not precomputed)
        ve = self.value_embeds.view(5, self.vocab_size, -1)[:, input_seq]
        # 01 ... 234 structure on token value embeddings by @photomz
        ve = [None] + [ve[0], ve[1]] + [None] * (self.num_layers - 6) + [ve[2], ve[3], ve[4]]
        assert len(ve) == self.num_layers

        # smear token embed forward 1 position @classiclarryd
        smear_gate_out = smear_lambda * torch.sigmoid(self.smear_gate(x[1:, :self.smear_gate.weight.size(-1)]))
        x = torch.cat([x[:1], x[1:] + smear_gate_out * x[:-1]])
        x = x0 = norm(x[None])

        # unbind gate banks to avoid select_backwards kernel
        ag = [w.bfloat16() for w in self.attn_gate_bank.unbind(0)]
        veg = [w.bfloat16() for w in self.ve_gate_bank.unbind(0)]
        attn_gates = ag[:6] + [None] + ag[6:]
        ve_gates = [None] + [veg[0], veg[1]] + [None] * (self.num_layers - 6) + [veg[2], veg[3], veg[4]]
        assert len(attn_gates) == self.num_layers
        assert len(ve_gates) == self.num_layers

        # unbind weight banks to avoid select_backwards kernel
        attn_weights = self.attn_bank.unbind(0)  # tuple of [4*dim, hdim] tensors
        mlp_fcs = self.mlp_bank[:, 0, :, :].unbind(0)  # tuple of [mlp_hdim, dim] tensors
        mlp_projs = self.mlp_bank[:, 1, :, :].unbind(0)  # tuple of [mlp_hdim, dim] tensors

        for i in range(self.num_layers):
            yarn = self.yarn_paired_head if i in self.paired_head_layers else self.yarn
            attn_args = AttnArgs(
                ve=ve[i],
                sa_lambdas=sa_lambdas[i],
                seqlens=seqlens,
                bm_size=bm_sizes[i],
                yarn=yarn,
                key_offset=key_offset[i],
                attn_gate_w=attn_gates[i],
                ve_gate_w=ve_gates[i]
            )
            if i in skip_out:
                skip_gate_out = torch.sigmoid(skip_lambda) * 2 * torch.sigmoid(self.skip_gate(x0[..., :self.skip_gate.weight.size(-1)]))
                x = x + skip_gate_out * skip_connections.pop()
            if i == 0:
                x = (resid_lambdas[0] + x0_lambdas[0]) * x + bigram_lambdas[0] * x0_bigram
            else:
                x = resid_lambdas[i] * x + x0_lambdas[i] * x0 + bigram_lambdas[i] * x0_bigram

            # Get weights for this layer from banks
            qkvo_w = attn_weights[self.layer_to_attn_idx[i]] if i in self.layer_to_attn_idx else None
            c_fc = mlp_fcs[self.layer_to_mlp_idx[i]] if i in self.layer_to_mlp_idx else None
            c_proj = mlp_projs[self.layer_to_mlp_idx[i]] if i in self.layer_to_mlp_idx else None

            x = self.blocks[i](x, attn_args, qkvo_w, c_fc, c_proj)
            if i in skip_in:
                skip_connections.append(x)
            if i == backout_layer:
                x_backout = x

        # back out contributions from first 7 layers that are only required for downstream context and not direct prediction
        x -= backout_lambda * x_backout
        x = norm(x)
        logits = self.lm_head(x)
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15
        # @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1). @classiclarryd updated to 23*sigmoid((logits+5)/7.5)
        if self.training:
            losses = FusedSoftcappedCrossEntropy.apply(logits.view(-1, logits.size(-1)), target_seq, mtp_weights, 23.0, 5.0, 7.5)
            loss = losses.sum()
        else:
            logits = 23 * torch.sigmoid((logits + 5) / 7.5)
            logits_for_loss = logits.float()
            loss = F.cross_entropy(logits_for_loss.view(-1, logits_for_loss.size(-1)), target_seq, reduction="mean")
        return loss
# -----------------------------------------------------------------------------
# Distributed data loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

BOS_ID = 50256

class Shard:
    def __init__(self, tokens: Tensor, world_size: int = 1):
        self.tokens = tokens
        self.size = tokens.numel()
        self.world_size = world_size
        self.i = 0

        # Partial index now, full index async
        self.bos_idx = (tokens[:6_000_000] == BOS_ID).nonzero(as_tuple=True)[0].to(torch.int64).cpu().numpy()
        self._full_idx = None
        self._loader_thread = None
        self._ready = threading.Event()
        self._loader_thread = threading.Thread(target=self._scan)
        self._loader_thread.start()

    def _scan(self):
        self._full_idx = (self.tokens == BOS_ID).nonzero(as_tuple=True)[0].to(torch.int64).cpu().numpy()
        self._ready.set()

    def _maybe_switch(self):
        # Switch to full index as soon as async scan completes
        if self.bos_idx is not self._full_idx and self._ready.is_set():
            self._loader_thread.join()
            self.bos_idx = self._full_idx

    def next_batch(self, num_tokens_local: int, max_seq_len: int):
        self._maybe_switch()
        n = len(self.bos_idx)
        starts = [[] for _ in range(self.world_size)]
        ends = [[] for _ in range(self.world_size)]

        idx = self.i
        for r in range(self.world_size):
            cur_len = 0
            while cur_len <= num_tokens_local:
                if idx >= n:
                    raise StopIteration(f"Insufficient BOS ahead; hit tail of shard.")
                cur = self.bos_idx[idx]
                starts[r].append(cur)
                end = min(self.bos_idx[idx + 1] if idx + 1 < n else self.size,
                          cur + max_seq_len,
                          cur + num_tokens_local - cur_len + 1)
                ends[r].append(end)
                cur_len += end - cur
                idx += 1

            assert cur_len == num_tokens_local + 1
        self.i = idx
        return starts, ends

    @staticmethod
    def load_async(file: Path, world_size: int = 1):
        """Returns getter function for async shard loading"""
        result = {}
        ready = threading.Event()
        def load():
            tokens = _load_data_shard(file)
            result['shard'] = Shard(tokens, world_size)
            ready.set()
        thread = threading.Thread(target=load)
        thread.start()
        def get():
            ready.wait()
            thread.join()
            return result['shard']
        return get

def get_bigram_hash(x):
    """
    Computes bigram hash for each position using [prev_token, curr_token].
    Multiply by arbitary large ints to get even spread over int32 range.
    Position 0 is mapped to the reserved index (vocab_size - 1).
    BOS_tokens within the batch will hash based on last token of prior doc. Masking this ran slower and showed no improvement.
    """
    rand_int_1 = 36313
    rand_int_2 = 27191
    mod = args.bigram_vocab_size-1
    x = x.to(torch.int32).clone()
    x[0] = mod
    x[1:] = torch.bitwise_xor(rand_int_1 * x[1:], rand_int_2 * x[:-1]) % mod
    return x

def distributed_data_generator(filename_pattern: str, num_tokens: int, max_seq_len: int, grad_accum_steps: int = 1, align_to_bos: bool = True):
    # align_to_bos: each sequence begins with Beginning of Sequence token, sequences truncated to max_seq_len
    rank = dist.get_rank() if dist.is_initialized() else 0
    world_size = dist.get_world_size() if dist.is_initialized() else 1
    assert num_tokens % (world_size * grad_accum_steps) == 0, "Batch size must be divisible by world size"
    num_tokens = num_tokens // grad_accum_steps

    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    if not files:
        raise FileNotFoundError(f"No files found for pattern: {filename_pattern}")

    file_iter = iter(files)  # Use itertools.cycle(files) for multi-epoch training
    tokens = _load_data_shard(next(file_iter))
    if align_to_bos:
        shard = Shard(tokens, world_size)
        next_shard_getter = Shard.load_async(next(file_iter), world_size)
    else:
        pos = 0  # for unaligned case

    while True:
        num_tokens_local = num_tokens // world_size
        max_num_docs = next_multiple_of_n(num_tokens_local // 300, n=128)  # median doc length is ~400

        if align_to_bos:
            try:
                seq_starts, seq_ends = shard.next_batch(num_tokens_local, max_seq_len)
                start_idxs, end_idxs = torch.tensor(seq_starts[rank]), torch.tensor(seq_ends[rank])
            except StopIteration:
                # This shard is exhausted, load the next one in the next loop iteration.
                shard = next_shard_getter()
                tokens = shard.tokens
                try:
                    next_shard_getter = Shard.load_async(next(file_iter), world_size)
                except StopIteration:
                    next_shard_getter = None  # no more shards to preload
                continue

            buf = torch.cat([tokens[i:j] for i, j in zip(start_idxs, end_idxs)])
            _inputs = buf[:-1]
            _targets = buf[1:]
            end_idxs[-1] -= 1  # last document was too long to account for _targets offset
            cum_lengths = (end_idxs - start_idxs).cumsum(0)

        else:
            if pos + num_tokens + 1 >= len(tokens):  # should not occur for val data
                tokens, pos = _load_data_shard(next(file_iter)), 0

            pos_local = pos + rank * num_tokens_local
            buf = tokens[pos_local: pos_local + num_tokens_local + 1]
            _inputs = buf[:-1].view(num_tokens_local, )
            _targets = buf[1:].view(num_tokens_local, )

            cum_lengths = torch.nonzero(_inputs == BOS_ID)[:, 0]
            pos += num_tokens


        _cum_lengths = torch.full((max_num_docs,), num_tokens_local)
        _cum_lengths[0] = 0
        _cum_lengths[1:len(cum_lengths) + 1] = cum_lengths

        # Cast to int32 on CPU before transfer to avoid dtype conversion during .to()
        _inputs = _inputs.to(dtype=torch.int32)
        _targets = _targets.to(dtype=torch.int64)
        _cum_lengths = _cum_lengths.to(dtype=torch.int32)
        _bigram_inputs = get_bigram_hash(_inputs)

        new_params = yield (
            _inputs.to(device="cuda", non_blocking=True),
            _targets.to(device="cuda", non_blocking=True),
            _cum_lengths.to(device="cuda", non_blocking=True),
            _bigram_inputs.to(device="cuda", non_blocking=True)
        )

        if new_params is not None:
            # makes it possible for generator to receive new (num_tokens, max_seq_len, grad_accum_steps) via .send()
            new_num_tokens, new_max_seq_len, new_grad_accum_steps = new_params
            assert new_num_tokens % (world_size * new_grad_accum_steps) == 0, "Num tokens must be divisible by world size"
            num_tokens = new_num_tokens // new_grad_accum_steps
            max_seq_len = new_max_seq_len

# -----------------------------------------------------------------------------
# Training Management

@dataclass
class Hyperparameters:
    # data
    data_path = os.environ.get("DATA_PATH", ".")
    train_files: str = os.path.join(data_path, "data/fineweb10B/fineweb_train_*.bin") # input .bin to train on
    val_files: str = os.path.join(data_path, "data/fineweb10B/fineweb_val_*.bin") # input .bin to eval validation loss on
    val_tokens: int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # batch sizes
    train_max_seq_len: int = 128 * 16
    val_batch_size: int = 4 * 64 * 1024 * 8
    # schedule
    num_scheduled_iterations: int = 1507  # number of steps to complete lr and ws schedule
    num_extension_iterations: int = 40  # number of steps to continue training at final lr and ws
    # evaluation and logging
    run_id: str = f"{uuid.uuid4()}"
    val_loss_every: int = 250  # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint: bool = False
    # bigram hash embedding
    bigram_vocab_size: int = 50304 * 5

args = Hyperparameters()

@dataclass
class TrainingStage:
    lr_mul: float
    batch_size: int
    window_sizes: tuple[int, int]  # (short, long) in block units
    mtp_weights_start: list[float]
    mtp_weights_end: list[float]
    duration: float = None

class TrainingSchedule:
    """
    Training schedule initialized via TRAINING_STAGES
        1. Multi Token Prediction schedule of [1, 0.5, 0.25->0] -> [1, 0.5->0] -> [1] @varunneal
        2. Sliding Attention window schedule of [1,3] -> [3,7] -> [5,11] -> [6,13]
        3. YaRN updates to RoPE on window changes
        4. Split embed and lm head at 2/3 of training
        5. Batch size schedule of 8 -> 16 -> 24
        6. Post training extension of long windows from 13 to 20
    """

    def __init__(self, stages: list[TrainingStage], scheduled_iterations: int, extension_iterations: int,
                 cooldown_frac: float = 0.5, split_embed_stage: int = 2, ws_post_yarn_ext: int = 20):
        self.stages = stages
        self.scheduled_iterations = scheduled_iterations
        self.cooldown_frac = cooldown_frac
        # increase final validation ws, used for YaRN extension and short window size @classiclarryd
        self.ws_post_yarn_ext = ws_post_yarn_ext

        self.total_steps = self.scheduled_iterations + extension_iterations

        # Build stage boundaries (last is extension stage)
        ends = [0] + [round(c * scheduled_iterations) for c in accumulate(s.duration for s in stages[:-1])] + [self.total_steps]
        assert self.scheduled_iterations == ends[-2]
        self.boundaries = list(pairwise(ends))

        # Split embed at specified stage (ensure odd step for Adam)
        self.split_step = self.boundaries[split_embed_stage][0] | 1

        # Precompute MTP weights for all steps
        self.mtp_weights = []
        for step in range(self.total_steps + 1):
            stage, t = self.lookup(step)
            w = [a + (b - a) * t for a, b in zip(stage.mtp_weights_start, stage.mtp_weights_end)]
            self.mtp_weights.append(torch.tensor(w, device=device))

    def lookup(self, step: int) -> tuple[TrainingStage, float]:
        # Returns stage and % of the way through that stage
        for i, (start, end) in enumerate(self.boundaries):
            if step < end:
                t = (step - start) / (end - start)
                return self.stages[i], t
        return self.stages[-1], 1.0

    def get_lr(self, step: int) -> float:
        # learning rate schedule: tied to batch size schedule, with cooldown at the end
        stage, _ = self.lookup(step)
        lr = stage.lr_mul
        cd_start = int(self.scheduled_iterations * (1 - self.cooldown_frac))
        if step >= cd_start:
            t = min(1.0, (step - cd_start) / (self.scheduled_iterations - cd_start))
            lr = lr * (1 - t) + 0.1 * t
        return lr

# window_sizes are in units of `block_size` tokens (defined in TrainingManager)
TRAINING_STAGES = [
    TrainingStage(duration=1/3, batch_size=8 * 2048 * 8, window_sizes=(1, 3), lr_mul=1.0,
                  mtp_weights_start=[1.0, 0.5, 0.25], mtp_weights_end=[1.0, 0.5, 0.0]),
    TrainingStage(duration=1/3, batch_size=16 * 2048 * 8, window_sizes=(3, 7), lr_mul=1.52,  # (16/8)**0.6
                  mtp_weights_start=[1.0, 0.5], mtp_weights_end=[1.0, 0.0]),
    TrainingStage(duration=1/3, batch_size=24 * 2048 * 8, window_sizes=(5, 11), lr_mul=1.73,  # (24/8)**0.5
                  mtp_weights_start=[1.0], mtp_weights_end=[1.0]),
    # extension stage
    TrainingStage(batch_size=24 * 2048 * 8, window_sizes=(6, 13), lr_mul=1.0,  # lr_mul is not used
                  mtp_weights_start=[1.0], mtp_weights_end=[1.0]),
]

training_schedule = TrainingSchedule(TRAINING_STAGES, args.num_scheduled_iterations, args.num_extension_iterations, cooldown_frac=0.55)

def get_muon_momentum(step: int, muon_warmup_steps=300, muon_cooldown_steps=50, momentum_min=0.85, momentum_max=0.95):
    # warmup phase: linearly increase momentum from min to max
    # cooldown phase: linearly decrease momentum from max to min
    momentum_cd_start = training_schedule.total_steps - muon_cooldown_steps
    if step < muon_warmup_steps:
        frac = step / muon_warmup_steps
        momentum = momentum_min + frac * (momentum_max - momentum_min)
    elif step > momentum_cd_start:
        frac = (step - momentum_cd_start) / muon_cooldown_steps
        momentum = momentum_max - frac * (momentum_max - momentum_min)
    else:
        momentum = momentum_max
    return momentum

class TrainingManager():
    """
    Manages the NorMuonAndAdam for all parameters with explicit ordering.
        1. Scalars are given higher momentum terms to smooth learning @ChrisJMcCormick
        2. Adam optimizers are only stepped on odd steps @classiclarryd
        3. Explicit scatter_order and work_order for communication scheduling (no backward hooks)
        4. Muon has a linear momentum warmup and cooldown schedule
        5. Learning rates follow a linear decay schedule
        6. Embed is tied to lm_head until split step (2/3 of training), then untied @classiclarryd
    """
    def __init__(self, model):
        self.model = model
        self.block_size = 128

        # - Ordering dictates when to launch reduce/reduce_scatter operations
        # - "sharded" parameters use reduce_scatter/all_gather and "replicated" ones use all_reduce
        # - lr_mul and wd_mul are per-parameter learning rate and weight decay multipliers
        self.param_table = {
            "attn":           {"optim": "normuon", "comms": "sharded",    "adam_betas": None},
            "mlp":            {"optim": "normuon", "comms": "sharded",    "adam_betas": None},
            "scalars":        {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99], "lr_mul": 5.0,  "wd_mul": 0.0},
            "value_embed":    {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.75, 0.95], "lr_mul": 75.,  "wd_mul": 5.0},
            "bigram_embed":   {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.75, 0.95], "lr_mul": 75.,  "wd_mul": 5.0},
            "smear_gate":     {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99], "lr_mul": 0.01, "wd_mul": 0.0},
            "skip_gate":      {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99], "lr_mul": 0.05, "wd_mul": 0.0},
            "attn_gate_bank": {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99]},
            "ve_gate_bank":   {"optim": "adam",    "comms": "replicated", "adam_betas": [0.9,  0.99]},
            "x0_lambdas":     {"optim": "adam",    "comms": "replicated", "adam_betas": [0.65, 0.95], "lr_mul": 5.0,  "wd_mul": 0.0},
            "lm_head":        {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.5,  0.95], "wd_mul": 150.},
            "embed":          {"optim": "adam",    "comms": "sharded",    "adam_betas": [0.5,  0.95], "wd_mul": 150.},
        }

        # - Process smaller/faster params first while large reduces complete
        # - lm_head must complete before embed sync (when tied)
        self.work_order = [
            "scalars", "smear_gate", "skip_gate", "attn_gate_bank", "ve_gate_bank", "x0_lambdas",  # Small, fast
            "value_embed", "bigram_embed",  # Medium
            "lm_head", "embed",   # lm_head must complete before embed sync (when tied)
            "attn", "mlp",        # Large, polar express - process last to maximize overlap
        ]

        adam_defaults = dict(
            lr=0.008,
            eps=1e-10,
            weight_decay=0.005,
        )

        normuon_defaults = dict(
            lr=0.023,
            momentum=0.95,
            beta2=0.95,
            weight_decay=1.2,
        )

        self.optimizer = NorMuonAndAdam(
            model.named_parameters(),
            param_table=self.param_table,
            scatter_order=list(self.param_table.keys()),  # Dict order defines scatter priority
            work_order=self.work_order,
            adam_defaults=adam_defaults,
            normuon_defaults=normuon_defaults,
        )

        # Split embed from lm_head at 2/3 of training (on an odd step so Adam updates)
        self.split_step = training_schedule.split_step

        self.reset()

    def apply_final_ws_ext(self):
        self.ws_long = training_schedule.ws_post_yarn_ext

    def get_forward_args(self):
        return ForwardScheduleConfig(
            mtp_weights = self.mtp_weights,
            ws_short = self.ws_short * self.block_size,
            ws_long = self.ws_long * self.block_size
        )

    def _is_adam_step(self, step: int):
        """Adam params are only updated on odd steps."""
        return step % 2 == 1

    def get_transition_steps(self):
        return [start for start, _ in training_schedule.boundaries[1:]]

    def advance_schedule(self, step: int):
        stage, _ = training_schedule.lookup(step)
        self.ws_short, new_ws_long = stage.window_sizes
        if new_ws_long != self.ws_long:
            self.model.yarn.apply(self.ws_long * self.block_size, new_ws_long * self.block_size)
            self.model.yarn_paired_head.apply(self.ws_long * self.block_size, new_ws_long * self.block_size)

        new_batch_size = stage.batch_size
        if new_batch_size != self.batch_size:
            self.train_loader_send_args = (new_batch_size, args.train_max_seq_len, grad_accum_steps)
            self.batch_size = new_batch_size
        else:
            self.train_loader_send_args = None

        self.ws_long = new_ws_long
        self.mtp_weights = training_schedule.mtp_weights[step]

    def step_optimizers(self, step: int):
        step_lr = training_schedule.get_lr(step)
        muon_momentum = get_muon_momentum(step)
        do_adam = self._is_adam_step(step)

        # Update learning rates and momentum for all params
        for param, p_cfg in self.optimizer.param_cfgs.items():
            p_cfg.lr = p_cfg.initial_lr * step_lr
            if p_cfg.optim == "normuon":
                p_cfg.momentum = muon_momentum

        # Step optimizer with do_adam flag
        self.optimizer.step(do_adam=do_adam)

        # At split step: copy lm_head optimizer state to embed and mark as split
        if step == self.split_step:
            self.optimizer.copy_lm_state_to_embed()

    def reset(self, state=None):
        if state is not None:
            self.optimizer.load_state_dict(state)

        # Reset NorMuon momentum buffers and split_embed state
        self.optimizer.reset()

        stage, _ = training_schedule.lookup(0)
        self.ws_short, self.ws_long = stage.window_sizes
        self.batch_size = stage.batch_size
        self.model.yarn.reset()
        self.model.yarn_paired_head.reset()

    def get_state(self):
        return copy.deepcopy(self.optimizer.state_dict())

# -----------------------------------------------------------------------------
# int main

# begin logging
logfile = None
if master_process:
    run_id = args.run_id
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
print0(f"Running Triton version {triton.__version__}")

def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

model: nn.Module = GPT(
    vocab_size=50257,
    num_layers=11,
    num_heads=6,
    head_dim=128,
    model_dim=768,
    max_seq_len=args.val_batch_size // (grad_accum_steps * world_size)
).cuda()
for m in model.modules():
    if isinstance(m, (nn.Embedding, nn.Linear)):
        m.weight.data = m.weight.data.bfloat16()
model.attn_gate_bank.data = model.attn_gate_bank.data.bfloat16()
model.ve_gate_bank.data = model.ve_gate_bank.data.bfloat16()
model.attn_bank.data = model.attn_bank.data.bfloat16()
model.mlp_bank.data = model.mlp_bank.data.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

model: nn.Module = torch.compile(model, dynamic=False, fullgraph=True)
training_manager = TrainingManager(model)

########################################
#            Warmup kernels            #
########################################
print0("Compiling model and warming up kernels (~7 minutes on first execution)", console=True)
# Warmup the training kernels, then re-initialize the state so we aren't cheating
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizer=training_manager.get_state()) # save the initial state
train_loader = distributed_data_generator(args.train_files, TRAINING_STAGES[0].batch_size, args.train_max_seq_len, grad_accum_steps=grad_accum_steps)
val_loader = distributed_data_generator(args.val_files, args.val_batch_size, -1, grad_accum_steps=grad_accum_steps, align_to_bos=False)

transition_steps = training_manager.get_transition_steps()
# first few steps plus transitions
warmup_steps = sorted({0, 1, 2} | set(s + offset for s in transition_steps for offset in [-1, 0, 1] if s + offset >= 0))
print0(f"Sampling steps {warmup_steps} for warmup", console=True)
for step in warmup_steps:
    training_manager.advance_schedule(step)
    model.eval()
    with torch.no_grad():
        inputs, targets, cum_seqlens, bigram_inputs = next(val_loader)
        model(inputs, targets, cum_seqlens, bigram_inputs, training_manager.get_forward_args())
    model.train()
    for idx in range(grad_accum_steps):
        send_args = training_manager.train_loader_send_args
        inputs, targets, cum_seqlens, bigram_inputs = train_loader.send(send_args)
        (model(inputs, targets, cum_seqlens, bigram_inputs, training_manager.get_forward_args()) * grad_scale).backward()
    training_manager.step_optimizers(step)
print0("Resetting Model", console=True)
model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
training_manager.reset(initial_state["optimizer"])
del val_loader, train_loader, initial_state
model.train()

########################################
#        Training and validation       #
########################################
train_loader = distributed_data_generator(args.train_files, TRAINING_STAGES[0].batch_size, args.train_max_seq_len, grad_accum_steps=grad_accum_steps)

gc.collect()

training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = training_schedule.total_steps
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    training_manager.advance_schedule(step)
    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        if last_step:
            training_manager.apply_final_ws_ext()
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        assert args.val_tokens % args.val_batch_size == 0
        val_steps = grad_accum_steps * args.val_tokens // args.val_batch_size
        val_loader = distributed_data_generator(args.val_files, args.val_batch_size, -1, grad_accum_steps=grad_accum_steps, align_to_bos=False)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets, cum_seqlens, bigram_inputs = next(val_loader)
                val_loss += model(inputs, targets, cum_seqlens, bigram_inputs, training_manager.get_forward_args())
        val_loss /= val_steps
        del val_loader
        dist.reduce(val_loss, 0, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizer=training_manager.get_state())
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    for idx in range(grad_accum_steps):
        inputs, targets, cum_seqlens, bigram_inputs = train_loader.send(training_manager.train_loader_send_args)
        (model(inputs, targets, cum_seqlens, bigram_inputs, training_manager.get_forward_args()) * grad_scale).backward()
    training_manager.step_optimizers(step)

    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()


----------------------------------------
# triton_kernels.py
----------------------------------------

import torch
import triton
import triton.language as tl
from triton.tools.tensor_descriptor import TensorDescriptor

# -----------------------------------------------------------------------------
# Triton kernel for symmetric matrix multiplication by @byronxu99

@triton.jit
def _pid_to_block(
    pid,
    M,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
):
    # Split output matrix into blocks of size (BLOCK_SIZE_M, BLOCK_SIZE_N)
    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(M, BLOCK_SIZE_N)

    # Map PID to a single matrix in batch
    batch_idx = pid // (num_pid_m * num_pid_n)
    pid = pid % (num_pid_m * num_pid_n)

    # Map PID to 2D grid of blocks
    pid_m = pid // num_pid_n
    pid_n = pid % num_pid_n
    pid_m, pid_n = tl.swizzle2d(pid_m, pid_n, num_pid_m, num_pid_n, GROUP_SIZE_M)

    m_idx = pid_m * BLOCK_SIZE_M
    n_idx = pid_n * BLOCK_SIZE_N
    return batch_idx, m_idx, n_idx

@triton.jit
def XXT_kernel(
    A_ptr, C_ptr,
    M, K,
    a_stride_b, a_stride_r, a_stride_c,
    c_stride_b, c_stride_r, c_stride_c,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
    LOWER_UPPER: tl.constexpr,
):
    pid = tl.program_id(axis=0)
    batch_idx, m_idx, n_idx = _pid_to_block(
        pid, M, BLOCK_SIZE_M, BLOCK_SIZE_N, GROUP_SIZE_M
    )

    # Skip blocks that don't need to be computed
    skip_block_below_diag = (LOWER_UPPER == 0) and (n_idx + BLOCK_SIZE_N <= m_idx)
    skip_block_above_diag = (LOWER_UPPER != 0) and (m_idx + BLOCK_SIZE_M <= n_idx)
    if skip_block_below_diag or skip_block_above_diag:
        return

    # Index into one matrix of batch
    A_ptr += batch_idx * a_stride_b
    C_ptr += batch_idx * c_stride_b

    # Create pointer arrays for A and A.T
    offs_m = (m_idx + tl.arange(0, BLOCK_SIZE_M)) % M
    offs_n = (n_idx + tl.arange(0, BLOCK_SIZE_N)) % M
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    a_ptrs = A_ptr + (offs_m[:, None] * a_stride_r + offs_k[None, :] * a_stride_c)
    at_ptrs = A_ptr + (offs_k[:, None] * a_stride_c + offs_n[None, :] * a_stride_r)

    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)

    # Accumulate over blocks of K
    for k in tl.range(0, tl.cdiv(K, BLOCK_SIZE_K)):
        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)
        at = tl.load(at_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)
        accumulator = tl.dot(a, at, accumulator)
        a_ptrs += BLOCK_SIZE_K * a_stride_c
        at_ptrs += BLOCK_SIZE_K * a_stride_c

    out_dtype = C_ptr.dtype.element_ty
    output = accumulator.to(out_dtype)

    # Store block of C
    offs_cm = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_cn = n_idx + tl.arange(0, BLOCK_SIZE_N)
    c_ptrs = C_ptr + (offs_cm[:, None] * c_stride_r + offs_cn[None, :] * c_stride_c)
    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < M)
    tl.store(c_ptrs, output, mask=c_mask)

    # Store block of C mirrored across the diagonal
    c_ptrs_t = C_ptr + (offs_cn[:, None] * c_stride_r + offs_cm[None, :] * c_stride_c)
    c_mask_t = (offs_cn[:, None] < M) & (offs_cm[None, :] < M)
    tl.store(c_ptrs_t, output.T, mask=c_mask_t)

def XXT(A: torch.Tensor, out: torch.Tensor):
    """
    Launch Triton kernel to compute C = A @ A.T
    """
    assert A.ndim == 2 or A.ndim == 3
    M, K = A.shape[-2:]
    assert out.size(-2) == M, "Output matrix has incorrect shape"
    assert out.size(-1) == M, "Output matrix has incorrect shape"

    batch_size = A.size(0) if A.ndim == 3 else 1
    input_batch_stride = A.stride(0) if A.ndim == 3 else 0
    output_batch_stride = out.stride(0) if out.ndim == 3 else 0

    # Hardcoded configs based on H100 autotuning
    if K == 768:
        BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 128, 128, 64
        num_stages, num_warps = 4, 4
    else:
        BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 64, 128, 128
        num_stages, num_warps = 4, 4

    grid = (batch_size * triton.cdiv(M, BLOCK_SIZE_M) * triton.cdiv(M, BLOCK_SIZE_N),)
    XXT_kernel[grid](
        A_ptr=A,
        C_ptr=out,
        M=M,
        K=K,
        a_stride_b=input_batch_stride,
        a_stride_r=A.stride(-2),
        a_stride_c=A.stride(-1),
        c_stride_b=output_batch_stride,
        c_stride_r=out.stride(-2),
        c_stride_c=out.stride(-1),
        BLOCK_SIZE_M=BLOCK_SIZE_M,
        BLOCK_SIZE_N=BLOCK_SIZE_N,
        BLOCK_SIZE_K=BLOCK_SIZE_K,
        GROUP_SIZE_M=8,
        LOWER_UPPER=1,
        num_stages=num_stages,
        num_warps=num_warps,
    )
    return out

@triton.jit
def ba_plus_cAA_kernel(
    A_ptr, C_ptr,
    M,
    a_stride_b, a_stride_r, a_stride_c,
    c_stride_b, c_stride_r, c_stride_c,
    alpha, beta,
    BLOCK_SIZE_M: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr,
    LOWER_UPPER: tl.constexpr,
):
    # This is mostly duplicated from XXT_kernel, but also loads and adds a block of A
    # Performance is slightly slower than XXT_kernel, so we use two separate kernels
    pid = tl.program_id(axis=0)
    batch_idx, m_idx, n_idx = _pid_to_block(
        pid, M, BLOCK_SIZE_M, BLOCK_SIZE_N, GROUP_SIZE_M
    )

    # Skip blocks that don't need to be computed
    skip_block_below_diag = (LOWER_UPPER == 0) and (n_idx + BLOCK_SIZE_N <= m_idx)
    skip_block_above_diag = (LOWER_UPPER != 0) and (m_idx + BLOCK_SIZE_M <= n_idx)
    if skip_block_below_diag or skip_block_above_diag:
        return

    # Index into one matrix of batch
    A_ptr += batch_idx * a_stride_b
    C_ptr += batch_idx * c_stride_b

    # Create pointer arrays for A and A.T
    offs_m = (m_idx + tl.arange(0, BLOCK_SIZE_M)) % M
    offs_n = (n_idx + tl.arange(0, BLOCK_SIZE_N)) % M
    offs_k = tl.arange(0, BLOCK_SIZE_K)
    a_ptrs = A_ptr + (offs_m[:, None] * a_stride_r + offs_k[None, :] * a_stride_c)
    at_ptrs = A_ptr + (offs_k[:, None] * a_stride_c + offs_n[None, :] * a_stride_r)

    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)

    # Accumulate over blocks of K
    for k in tl.range(0, tl.cdiv(M, BLOCK_SIZE_K)):
        a = tl.load(a_ptrs, mask=offs_k[None, :] < M - k * BLOCK_SIZE_K, other=0.0)
        at = tl.load(at_ptrs, mask=offs_k[:, None] < M - k * BLOCK_SIZE_K, other=0.0)
        accumulator = tl.dot(a, at, accumulator)
        a_ptrs += BLOCK_SIZE_K * a_stride_c
        at_ptrs += BLOCK_SIZE_K * a_stride_c

    # Load block of A to add (corresponds to the current block of C)
    offs_am = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_an = n_idx + tl.arange(0, BLOCK_SIZE_N)
    a_add_ptrs = A_ptr + (offs_am[:, None] * a_stride_r + offs_an[None, :] * a_stride_c)
    a_add_mask = (offs_am[:, None] < M) & (offs_an[None, :] < M)
    a_add = tl.load(a_add_ptrs, mask=a_add_mask, other=0.0).to(tl.float32)

    # Apply alpha and beta
    accumulator *= alpha
    accumulator += a_add * beta

    out_dtype = C_ptr.dtype.element_ty
    output = accumulator.to(out_dtype)

    # Store block of C
    offs_cm = m_idx + tl.arange(0, BLOCK_SIZE_M)
    offs_cn = n_idx + tl.arange(0, BLOCK_SIZE_N)
    c_ptrs = C_ptr + (offs_cm[:, None] * c_stride_r + offs_cn[None, :] * c_stride_c)
    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < M)
    tl.store(c_ptrs, output, mask=c_mask)

    # Store block of C mirrored across the diagonal
    c_ptrs_t = C_ptr + (offs_cn[:, None] * c_stride_r + offs_cm[None, :] * c_stride_c)
    c_mask_t = (offs_cn[:, None] < M) & (offs_cm[None, :] < M)
    tl.store(c_ptrs_t, output.T, mask=c_mask_t)

def ba_plus_cAA(A: torch.Tensor, alpha: float, beta: float, out: torch.Tensor):
    """
    Launch Triton kernel to compute C = alpha * A @ A.T + beta * A
    """
    assert A.ndim == 2 or A.ndim == 3
    M, K = A.shape[-2:]
    assert M == K, "Input matrix must be square"
    assert out.size(-2) == M
    assert out.size(-1) == M

    batch_size = A.size(0) if A.ndim == 3 else 1
    input_batch_stride = A.stride(0) if A.ndim == 3 else 0
    output_batch_stride = out.stride(0) if out.ndim == 3 else 0

    # Hardcoded config based on H100 autotuning (M=768)
    BLOCK_SIZE_M, BLOCK_SIZE_N, BLOCK_SIZE_K = 128, 128, 64
    num_stages, num_warps = 4, 4

    grid = (batch_size * triton.cdiv(M, BLOCK_SIZE_M) * triton.cdiv(M, BLOCK_SIZE_N),)
    ba_plus_cAA_kernel[grid](
        A_ptr=A,
        C_ptr=out,
        M=M,
        a_stride_b=input_batch_stride,
        a_stride_r=A.stride(-2),
        a_stride_c=A.stride(-1),
        c_stride_b=output_batch_stride,
        c_stride_r=out.stride(-2),
        c_stride_c=out.stride(-1),
        alpha=alpha,
        beta=beta,
        BLOCK_SIZE_M=BLOCK_SIZE_M,
        BLOCK_SIZE_N=BLOCK_SIZE_N,
        BLOCK_SIZE_K=BLOCK_SIZE_K,
        GROUP_SIZE_M=8,
        LOWER_UPPER=1,
        num_stages=num_stages,
        num_warps=num_warps,
    )
    return out

# -----------------------------------------------------------------------------
# Triton kernel for MLP: relu(x @ W1.T)^2, by @andrewbriand, @jrauvola

@triton.jit
def linear_relu_square_kernel(a_desc, b_desc, c_desc, aux_desc,
                                 M, N, K,
                                 BLOCK_SIZE_M: tl.constexpr,
                                 BLOCK_SIZE_N: tl.constexpr,
                                 BLOCK_SIZE_K: tl.constexpr,
                                 GROUP_SIZE_M: tl.constexpr,
                                 NUM_SMS: tl.constexpr,
                                 FORWARD: tl.constexpr,
                                 ):
    dtype = tl.bfloat16
    start_pid = tl.program_id(axis=0)
    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
    k_tiles = tl.cdiv(K, BLOCK_SIZE_K)
    num_tiles = num_pid_m * num_pid_n

    tile_id_c = start_pid - NUM_SMS
    num_pid_in_group = GROUP_SIZE_M * num_pid_n

    for tile_id in tl.range(start_pid, num_tiles, NUM_SMS, flatten=True):
        pid_m = tile_id // num_pid_n
        pid_n = tile_id % num_pid_n
        offs_am = pid_m * BLOCK_SIZE_M
        offs_bn = pid_n * BLOCK_SIZE_N

        accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
        for ki in range(k_tiles):
            offs_k = ki * BLOCK_SIZE_K
            a = a_desc.load([offs_am, offs_k])
            b = b_desc.load([offs_bn, offs_k])
            accumulator = tl.dot(a, b.T, accumulator)

        tile_id_c += NUM_SMS
        pid_m = tile_id // num_pid_n
        pid_n = tile_id % num_pid_n
        offs_am_c = pid_m * BLOCK_SIZE_M
        offs_bn_c = pid_n * BLOCK_SIZE_N

        acc = tl.reshape(accumulator, (BLOCK_SIZE_M, 2, BLOCK_SIZE_N // 2))
        acc = tl.permute(acc, (0, 2, 1))
        acc0, acc1 = tl.split(acc)

        c0 = acc0.to(dtype)
        if not FORWARD:
            c0_pre = aux_desc.load([offs_am_c, offs_bn_c])
            c0 = 2 * c0 * tl.where(c0_pre > 0, c0_pre, 0)

        c_desc.store([offs_am_c, offs_bn_c], c0)

        if FORWARD:
            c0_post = tl.maximum(c0, 0)
            c0_post = c0_post * c0_post
            aux_desc.store([offs_am_c, offs_bn_c], c0_post)

        c1 = acc1.to(dtype)
        if not FORWARD:
            c1_pre = aux_desc.load([offs_am_c, offs_bn_c + BLOCK_SIZE_N // 2])
            c1 = 2 * c1 * tl.where(c1_pre > 0, c1_pre, 0)

        c_desc.store([offs_am_c, offs_bn_c + BLOCK_SIZE_N // 2], c1)

        if FORWARD:
            c1_post = tl.maximum(c1, 0)
            c1_post = c1_post * c1_post
            aux_desc.store([offs_am_c, offs_bn_c + BLOCK_SIZE_N // 2], c1_post)


def linear_relu_square(a, b, aux=None):
    M, K = a.shape
    N, K = b.shape
    dtype = a.dtype

    c = torch.empty((M, N), device=a.device, dtype=dtype)

    FORWARD = False
    if aux is None:
        FORWARD = True
        aux = torch.empty((M, N), device=a.device, dtype=dtype)

    NUM_SMS = torch.cuda.get_device_properties("cuda").multi_processor_count

    BLOCK_SIZE_M = 128
    BLOCK_SIZE_N = 256
    BLOCK_SIZE_K = 64
    num_stages = 4 if FORWARD else 3
    num_warps = 8

    a_desc = TensorDescriptor.from_tensor(a, [BLOCK_SIZE_M, BLOCK_SIZE_K])
    b_desc = TensorDescriptor.from_tensor(b, [BLOCK_SIZE_N, BLOCK_SIZE_K])
    c_desc = TensorDescriptor.from_tensor(c, [BLOCK_SIZE_M, BLOCK_SIZE_N // 2])
    aux_desc = TensorDescriptor.from_tensor(aux, [BLOCK_SIZE_M, BLOCK_SIZE_N // 2])

    def grid(META):
        return (min(
            NUM_SMS,
            triton.cdiv(M, BLOCK_SIZE_M) * triton.cdiv(N, BLOCK_SIZE_N),
        ), )

    linear_relu_square_kernel[grid](
        a_desc, b_desc, c_desc, aux_desc,
        M, N, K,
        BLOCK_SIZE_M=BLOCK_SIZE_M,
        BLOCK_SIZE_N=BLOCK_SIZE_N,
        BLOCK_SIZE_K=BLOCK_SIZE_K,
        GROUP_SIZE_M=1,
        NUM_SMS=NUM_SMS,
        FORWARD=FORWARD,
        num_stages=num_stages,
        num_warps=num_warps
    )

    if FORWARD:
        return c, aux
    else:
        return c

class FusedLinearReLUSquareFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, W1, W2):
        pre, post = linear_relu_square(x.view((-1, x.shape[-1])), W1)
        x3 = post @ W2
        ctx.save_for_backward(x, W1, W2, pre, post)
        return x3.view(x.shape)

    @staticmethod
    def backward(ctx, grad_output):
        x, W1, W2, pre, post = ctx.saved_tensors
        dW2 = post.T @ grad_output
        dpre = linear_relu_square(grad_output.view((-1, grad_output.shape[-1])), W2, aux=pre)
        dW1 = dpre.T @ x
        dx = dpre @ W1
        return dx.view(x.shape), dW1, dW2

# -----------------------------------------------------------------------------
# Fused Softcapped Cross Entropy


@triton.jit
def fused_softcapped_entropy_fwd_kernel(
    logits_ptr, losses_ptr, lse_ptr, targets_ptr, mtp_weights_ptr,
    stride_logits_n, stride_logits_v,
    n_rows, n_cols, n_predict,
    A, B, C,
    BLOCK_SIZE: tl.constexpr
):
    row_idx = tl.program_id(0).to(tl.int64)
    logits_row_ptr = logits_ptr + row_idx * stride_logits_n

    max_val = -float('inf')
    sum_exp = 0.0

    for off in range(0, n_cols, BLOCK_SIZE):
        cols = off + tl.arange(0, BLOCK_SIZE)
        mask = cols < n_cols
        val = tl.load(logits_row_ptr + cols, mask=mask, other=-float('inf')).to(tl.float32)
        z = A * tl.sigmoid((val + B) / C)
        z = tl.where(mask, z, -float('inf'))
        curr_max = tl.max(z, axis=0)
        new_max = tl.maximum(max_val, curr_max)
        sum_exp = sum_exp * tl.exp(max_val - new_max) + tl.sum(tl.exp(z - new_max), axis=0)
        max_val = new_max

    lse = max_val + tl.log(sum_exp)
    tl.store(lse_ptr + row_idx, lse)

    total_loss = 0.0
    for k in range(n_predict):
        target_idx = row_idx + k
        if target_idx < n_rows:
            weight = tl.load(mtp_weights_ptr + k)
            if weight > 0:
                target = tl.load(targets_ptr + target_idx).to(tl.int32)
                if target >= 0 and target < n_cols:
                    val_target = tl.load(logits_row_ptr + target).to(tl.float32)
                    z_target = A * tl.sigmoid((val_target + B) / C)
                    total_loss += weight * (lse - z_target)

    tl.store(losses_ptr + row_idx, total_loss)

@triton.jit
def fused_softcapped_entropy_bwd_kernel(
    grad_input_ptr, grad_output_ptr, lse_ptr, logits_ptr, targets_ptr, mtp_weights_ptr,
    stride_logits_n, stride_logits_v, stride_grad_n, stride_grad_v,
    n_rows, n_cols, n_predict,
    A, B, C,
    BLOCK_SIZE: tl.constexpr
):
    row_idx = tl.program_id(0).to(tl.int64)

    logits_row_ptr = logits_ptr + row_idx * stride_logits_n
    grad_row_ptr = grad_input_ptr + row_idx * stride_grad_n

    lse = tl.load(lse_ptr + row_idx)
    grad_loss = tl.load(grad_output_ptr + row_idx)

    S_w = 0.0
    for k in range(n_predict):
        if row_idx + k < n_rows:
            S_w += tl.load(mtp_weights_ptr + k)

    for off in range(0, n_cols, BLOCK_SIZE):
        cols = off + tl.arange(0, BLOCK_SIZE)
        mask = cols < n_cols
        val = tl.load(logits_row_ptr + cols, mask=mask, other=0.0).to(tl.float32)
        u = (val + B) / C
        sigmoid_u = tl.sigmoid(u)
        z = A * sigmoid_u
        p = tl.exp(z - lse)

        term1 = S_w * p
        term2 = tl.zeros([BLOCK_SIZE], dtype=tl.float32)
        for k in range(n_predict):
            if row_idx + k < n_rows:
                target = tl.load(targets_ptr + row_idx + k).to(tl.int32)
                weight = tl.load(mtp_weights_ptr + k)
                term2 += tl.where(cols == target, weight, 0.0)

        grad_z = grad_loss * (term1 - term2)
        dz_dx = (1.0 / C) * z * (1.0 - sigmoid_u)
        grad_x = grad_z * dz_dx
        tl.store(grad_row_ptr + cols, grad_x.to(tl.bfloat16), mask=mask)

class FusedSoftcappedCrossEntropy(torch.autograd.Function):
    @staticmethod
    def forward(ctx, logits, targets, mtp_weights, A=23.0, B=5.0, C=7.5):
        n_rows, n_cols = logits.shape
        if mtp_weights is None:
             mtp_weights = torch.tensor([1.0], device=logits.device, dtype=torch.float32)
        n_predict = mtp_weights.shape[0]

        losses = torch.empty(n_rows, dtype=torch.float32, device=logits.device)
        lse = torch.empty(n_rows, dtype=torch.float32, device=logits.device)

        logits = logits.contiguous()
        targets = targets.contiguous()
        mtp_weights = mtp_weights.contiguous()

        grid = (n_rows,)
        fused_softcapped_entropy_fwd_kernel[grid](
            logits, losses, lse, targets, mtp_weights,
            logits.stride(0), logits.stride(1),
            n_rows, n_cols, n_predict,
            A, B, C,
            BLOCK_SIZE=1024,
            num_warps=8,
            num_stages=4
        )

        ctx.save_for_backward(logits, targets, mtp_weights, lse)
        ctx.params = (A, B, C)
        return losses

    @staticmethod
    def backward(ctx, grad_output):
        logits, targets, mtp_weights, lse = ctx.saved_tensors
        A, B, C = ctx.params
        n_rows, n_cols = logits.shape
        n_predict = mtp_weights.shape[0]

        grad_input = torch.empty((n_rows, n_cols), dtype=torch.bfloat16, device=logits.device)
        grad_output = grad_output.contiguous()

        grid = (n_rows,)
        fused_softcapped_entropy_bwd_kernel[grid](
            grad_input, grad_output, lse, logits, targets, mtp_weights,
            logits.stride(0), logits.stride(1), grad_input.stride(0), grad_input.stride(1),
            n_rows, n_cols, n_predict,
            A, B, C,
            BLOCK_SIZE=1024,
            num_warps=8,
            num_stages=4
        )
        return grad_input, None, None, None, None, None

====================================================================================================
Running Python 3.10.12 (main, Jan  8 2026, 06:52:19) [GCC 11.4.0]
Running PyTorch 2.10.0.dev20251210+cu126 compiled for CUDA 12.6
Running Triton version 3.6.0
Tue Feb  3 09:15:01 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                    0 |
| N/A   41C    P0            128W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                    0 |
| N/A   31C    P0            119W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   28C    P0            114W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   39C    P0            125W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   40C    P0            129W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   31C    P0            129W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   37C    P0            123W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   29C    P0            123W /  700W |    1520MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A    157175      C   /usr/bin/python3                             1510MiB |
|    1   N/A  N/A    157176      C   /usr/bin/python3                             1510MiB |
|    2   N/A  N/A    157177      C   /usr/bin/python3                             1510MiB |
|    3   N/A  N/A    157178      C   /usr/bin/python3                             1510MiB |
|    4   N/A  N/A    157179      C   /usr/bin/python3                             1510MiB |
|    5   N/A  N/A    157180      C   /usr/bin/python3                             1510MiB |
|    6   N/A  N/A    157181      C   /usr/bin/python3                             1510MiB |
|    7   N/A  N/A    157182      C   /usr/bin/python3                             1510MiB |
+-----------------------------------------------------------------------------------------+

====================================================================================================
Compiling model and warming up kernels (~7 minutes on first execution)
Sampling steps [0, 1, 2, 501, 502, 503, 1004, 1005, 1006, 1506, 1507, 1508] for warmup
Resetting Model
step:0/1547 val_loss:10.8271 train_time:0ms step_avg:0.03ms
step:1/1547 train_time:93ms step_avg:92.64ms
step:2/1547 train_time:116ms step_avg:57.97ms
step:3/1547 train_time:136ms step_avg:45.37ms
step:4/1547 train_time:158ms step_avg:39.61ms
step:5/1547 train_time:188ms step_avg:37.70ms
step:6/1547 train_time:227ms step_avg:37.76ms
step:7/1547 train_time:257ms step_avg:36.72ms
step:8/1547 train_time:295ms step_avg:36.88ms
step:9/1547 train_time:325ms step_avg:36.14ms
step:10/1547 train_time:363ms step_avg:36.31ms
step:11/1547 train_time:394ms step_avg:35.78ms
step:12/1547 train_time:431ms step_avg:35.96ms
step:13/1547 train_time:462ms step_avg:35.52ms
step:14/1547 train_time:500ms step_avg:35.69ms
step:15/1547 train_time:530ms step_avg:35.34ms
step:16/1547 train_time:568ms step_avg:35.48ms
step:17/1547 train_time:598ms step_avg:35.20ms
step:18/1547 train_time:636ms step_avg:35.35ms
step:19/1547 train_time:667ms step_avg:35.09ms
step:20/1547 train_time:705ms step_avg:35.24ms
step:21/1547 train_time:735ms step_avg:35.00ms
step:22/1547 train_time:772ms step_avg:35.11ms
step:23/1547 train_time:803ms step_avg:34.92ms
step:24/1547 train_time:840ms step_avg:35.02ms
step:25/1547 train_time:872ms step_avg:34.86ms
step:26/1547 train_time:909ms step_avg:34.97ms
step:27/1547 train_time:940ms step_avg:34.82ms
step:28/1547 train_time:977ms step_avg:34.90ms
step:29/1547 train_time:1008ms step_avg:34.77ms
step:30/1547 train_time:1046ms step_avg:34.86ms
step:31/1547 train_time:1077ms step_avg:34.74ms
step:32/1547 train_time:1114ms step_avg:34.82ms
step:33/1547 train_time:1146ms step_avg:34.72ms
step:34/1547 train_time:1183ms step_avg:34.80ms
step:35/1547 train_time:1215ms step_avg:34.72ms
step:36/1547 train_time:1253ms step_avg:34.82ms
step:37/1547 train_time:1284ms step_avg:34.71ms
step:38/1547 train_time:1322ms step_avg:34.79ms
step:39/1547 train_time:1353ms step_avg:34.69ms
step:40/1547 train_time:1391ms step_avg:34.78ms
step:41/1547 train_time:1422ms step_avg:34.68ms
step:42/1547 train_time:1460ms step_avg:34.75ms
step:43/1547 train_time:1491ms step_avg:34.67ms
step:44/1547 train_time:1529ms step_avg:34.74ms
step:45/1547 train_time:1559ms step_avg:34.65ms
step:46/1547 train_time:1597ms step_avg:34.72ms
step:47/1547 train_time:1628ms step_avg:34.64ms
step:48/1547 train_time:1666ms step_avg:34.71ms
step:49/1547 train_time:1697ms step_avg:34.63ms
step:50/1547 train_time:1734ms step_avg:34.69ms
step:51/1547 train_time:1765ms step_avg:34.61ms
step:52/1547 train_time:1803ms step_avg:34.66ms
step:53/1547 train_time:1834ms step_avg:34.60ms
step:54/1547 train_time:1871ms step_avg:34.64ms
step:55/1547 train_time:1902ms step_avg:34.57ms
step:56/1547 train_time:1939ms step_avg:34.63ms
step:57/1547 train_time:1970ms step_avg:34.56ms
step:58/1547 train_time:2007ms step_avg:34.61ms
step:59/1547 train_time:2038ms step_avg:34.55ms
step:60/1547 train_time:2076ms step_avg:34.59ms
step:61/1547 train_time:2107ms step_avg:34.54ms
step:62/1547 train_time:2145ms step_avg:34.60ms
step:63/1547 train_time:2175ms step_avg:34.53ms
step:64/1547 train_time:2213ms step_avg:34.58ms
step:65/1547 train_time:2244ms step_avg:34.52ms
step:66/1547 train_time:2282ms step_avg:34.57ms
step:67/1547 train_time:2313ms step_avg:34.52ms
step:68/1547 train_time:2351ms step_avg:34.57ms
step:69/1547 train_time:2382ms step_avg:34.52ms
step:70/1547 train_time:2419ms step_avg:34.56ms
step:71/1547 train_time:2450ms step_avg:34.51ms
step:72/1547 train_time:2488ms step_avg:34.56ms
step:73/1547 train_time:2519ms step_avg:34.50ms
step:74/1547 train_time:2556ms step_avg:34.55ms
step:75/1547 train_time:2587ms step_avg:34.50ms
step:76/1547 train_time:2625ms step_avg:34.54ms
step:77/1547 train_time:2655ms step_avg:34.48ms
step:78/1547 train_time:2693ms step_avg:34.53ms
step:79/1547 train_time:2724ms step_avg:34.48ms
step:80/1547 train_time:2762ms step_avg:34.52ms
step:81/1547 train_time:2793ms step_avg:34.48ms
step:82/1547 train_time:2830ms step_avg:34.51ms
step:83/1547 train_time:2861ms step_avg:34.46ms
step:84/1547 train_time:2898ms step_avg:34.50ms
step:85/1547 train_time:2929ms step_avg:34.46ms
step:86/1547 train_time:2967ms step_avg:34.50ms
step:87/1547 train_time:2997ms step_avg:34.45ms
step:88/1547 train_time:3035ms step_avg:34.49ms
step:89/1547 train_time:3065ms step_avg:34.44ms
step:90/1547 train_time:3103ms step_avg:34.48ms
step:91/1547 train_time:3134ms step_avg:34.44ms
step:92/1547 train_time:3171ms step_avg:34.47ms
step:93/1547 train_time:3202ms step_avg:34.43ms
step:94/1547 train_time:3239ms step_avg:34.46ms
step:95/1547 train_time:3270ms step_avg:34.42ms
step:96/1547 train_time:3308ms step_avg:34.46ms
step:97/1547 train_time:3338ms step_avg:34.42ms
step:98/1547 train_time:3376ms step_avg:34.45ms
step:99/1547 train_time:3407ms step_avg:34.42ms
step:100/1547 train_time:3445ms step_avg:34.45ms
step:101/1547 train_time:3476ms step_avg:34.42ms
step:102/1547 train_time:3514ms step_avg:34.45ms
step:103/1547 train_time:3544ms step_avg:34.41ms
step:104/1547 train_time:3582ms step_avg:34.44ms
step:105/1547 train_time:3613ms step_avg:34.41ms
step:106/1547 train_time:3651ms step_avg:34.44ms
step:107/1547 train_time:3681ms step_avg:34.40ms
step:108/1547 train_time:3719ms step_avg:34.43ms
step:109/1547 train_time:3749ms step_avg:34.40ms
step:110/1547 train_time:3787ms step_avg:34.43ms
step:111/1547 train_time:3818ms step_avg:34.39ms
step:112/1547 train_time:3855ms step_avg:34.42ms
step:113/1547 train_time:3886ms step_avg:34.39ms
step:114/1547 train_time:3924ms step_avg:34.42ms
step:115/1547 train_time:3955ms step_avg:34.39ms
step:116/1547 train_time:3993ms step_avg:34.42ms
step:117/1547 train_time:4024ms step_avg:34.39ms
step:118/1547 train_time:4062ms step_avg:34.42ms
step:119/1547 train_time:4092ms step_avg:34.39ms
step:120/1547 train_time:4130ms step_avg:34.41ms
step:121/1547 train_time:4160ms step_avg:34.38ms
step:122/1547 train_time:4198ms step_avg:34.41ms
step:123/1547 train_time:4229ms step_avg:34.38ms
step:124/1547 train_time:4266ms step_avg:34.40ms
step:125/1547 train_time:4297ms step_avg:34.38ms
step:126/1547 train_time:4335ms step_avg:34.40ms
step:127/1547 train_time:4366ms step_avg:34.38ms
step:128/1547 train_time:4403ms step_avg:34.40ms
step:129/1547 train_time:4434ms step_avg:34.37ms
step:130/1547 train_time:4472ms step_avg:34.40ms
step:131/1547 train_time:4503ms step_avg:34.37ms
step:132/1547 train_time:4541ms step_avg:34.40ms
step:133/1547 train_time:4572ms step_avg:34.38ms
step:134/1547 train_time:4610ms step_avg:34.40ms
step:135/1547 train_time:4641ms step_avg:34.38ms
step:136/1547 train_time:4678ms step_avg:34.40ms
step:137/1547 train_time:4709ms step_avg:34.38ms
step:138/1547 train_time:4747ms step_avg:34.40ms
step:139/1547 train_time:4778ms step_avg:34.37ms
step:140/1547 train_time:4815ms step_avg:34.40ms
step:141/1547 train_time:4846ms step_avg:34.37ms
step:142/1547 train_time:4884ms step_avg:34.39ms
step:143/1547 train_time:4914ms step_avg:34.37ms
step:144/1547 train_time:4952ms step_avg:34.39ms
step:145/1547 train_time:4983ms step_avg:34.36ms
step:146/1547 train_time:5020ms step_avg:34.39ms
step:147/1547 train_time:5051ms step_avg:34.36ms
step:148/1547 train_time:5089ms step_avg:34.39ms
step:149/1547 train_time:5120ms step_avg:34.36ms
step:150/1547 train_time:5157ms step_avg:34.38ms
step:151/1547 train_time:5188ms step_avg:34.36ms
step:152/1547 train_time:5225ms step_avg:34.37ms
step:153/1547 train_time:5256ms step_avg:34.36ms
step:154/1547 train_time:5294ms step_avg:34.38ms
step:155/1547 train_time:5325ms step_avg:34.35ms
step:156/1547 train_time:5363ms step_avg:34.38ms
step:157/1547 train_time:5393ms step_avg:34.35ms
step:158/1547 train_time:5431ms step_avg:34.37ms
step:159/1547 train_time:5462ms step_avg:34.35ms
step:160/1547 train_time:5499ms step_avg:34.37ms
step:161/1547 train_time:5530ms step_avg:34.35ms
step:162/1547 train_time:5568ms step_avg:34.37ms
step:163/1547 train_time:5598ms step_avg:34.34ms
step:164/1547 train_time:5636ms step_avg:34.36ms
step:165/1547 train_time:5666ms step_avg:34.34ms
step:166/1547 train_time:5705ms step_avg:34.36ms
step:167/1547 train_time:5736ms step_avg:34.35ms
step:168/1547 train_time:5773ms step_avg:34.36ms
step:169/1547 train_time:5804ms step_avg:34.35ms
step:170/1547 train_time:5842ms step_avg:34.37ms
step:171/1547 train_time:5873ms step_avg:34.35ms
step:172/1547 train_time:5911ms step_avg:34.36ms
step:173/1547 train_time:5941ms step_avg:34.34ms
step:174/1547 train_time:5979ms step_avg:34.36ms
step:175/1547 train_time:6010ms step_avg:34.34ms
step:176/1547 train_time:6048ms step_avg:34.36ms
step:177/1547 train_time:6078ms step_avg:34.34ms
step:178/1547 train_time:6116ms step_avg:34.36ms
step:179/1547 train_time:6146ms step_avg:34.34ms
step:180/1547 train_time:6185ms step_avg:34.36ms
step:181/1547 train_time:6215ms step_avg:34.34ms
step:182/1547 train_time:6253ms step_avg:34.36ms
step:183/1547 train_time:6283ms step_avg:34.33ms
step:184/1547 train_time:6321ms step_avg:34.35ms
step:185/1547 train_time:6351ms step_avg:34.33ms
step:186/1547 train_time:6389ms step_avg:34.35ms
step:187/1547 train_time:6419ms step_avg:34.33ms
step:188/1547 train_time:6456ms step_avg:34.34ms
step:189/1547 train_time:6487ms step_avg:34.32ms
step:190/1547 train_time:6525ms step_avg:34.34ms
step:191/1547 train_time:6555ms step_avg:34.32ms
step:192/1547 train_time:6593ms step_avg:34.34ms
step:193/1547 train_time:6624ms step_avg:34.32ms
step:194/1547 train_time:6662ms step_avg:34.34ms
step:195/1547 train_time:6692ms step_avg:34.32ms
step:196/1547 train_time:6730ms step_avg:34.34ms
step:197/1547 train_time:6760ms step_avg:34.32ms
step:198/1547 train_time:6798ms step_avg:34.33ms
step:199/1547 train_time:6828ms step_avg:34.31ms
step:200/1547 train_time:6866ms step_avg:34.33ms
step:201/1547 train_time:6897ms step_avg:34.31ms
step:202/1547 train_time:6935ms step_avg:34.33ms
step:203/1547 train_time:6966ms step_avg:34.31ms
step:204/1547 train_time:7004ms step_avg:34.33ms
step:205/1547 train_time:7034ms step_avg:34.31ms
step:206/1547 train_time:7072ms step_avg:34.33ms
step:207/1547 train_time:7103ms step_avg:34.31ms
step:208/1547 train_time:7140ms step_avg:34.33ms
step:209/1547 train_time:7171ms step_avg:34.31ms
step:210/1547 train_time:7209ms step_avg:34.33ms
step:211/1547 train_time:7240ms step_avg:34.31ms
step:212/1547 train_time:7278ms step_avg:34.33ms
step:213/1547 train_time:7308ms step_avg:34.31ms
step:214/1547 train_time:7346ms step_avg:34.33ms
step:215/1547 train_time:7376ms step_avg:34.31ms
step:216/1547 train_time:7414ms step_avg:34.33ms
step:217/1547 train_time:7445ms step_avg:34.31ms
step:218/1547 train_time:7482ms step_avg:34.32ms
step:219/1547 train_time:7513ms step_avg:34.31ms
step:220/1547 train_time:7551ms step_avg:34.32ms
step:221/1547 train_time:7581ms step_avg:34.30ms
step:222/1547 train_time:7619ms step_avg:34.32ms
step:223/1547 train_time:7649ms step_avg:34.30ms
step:224/1547 train_time:7687ms step_avg:34.32ms
step:225/1547 train_time:7717ms step_avg:34.30ms
step:226/1547 train_time:7755ms step_avg:34.31ms
step:227/1547 train_time:7786ms step_avg:34.30ms
step:228/1547 train_time:7823ms step_avg:34.31ms
step:229/1547 train_time:7854ms step_avg:34.30ms
step:230/1547 train_time:7892ms step_avg:34.31ms
step:231/1547 train_time:7923ms step_avg:34.30ms
step:232/1547 train_time:7961ms step_avg:34.32ms
step:233/1547 train_time:7992ms step_avg:34.30ms
step:234/1547 train_time:8030ms step_avg:34.31ms
step:235/1547 train_time:8060ms step_avg:34.30ms
step:236/1547 train_time:8097ms step_avg:34.31ms
step:237/1547 train_time:8128ms step_avg:34.29ms
step:238/1547 train_time:8165ms step_avg:34.31ms
step:239/1547 train_time:8196ms step_avg:34.29ms
step:240/1547 train_time:8234ms step_avg:34.31ms
step:241/1547 train_time:8265ms step_avg:34.29ms
step:242/1547 train_time:8302ms step_avg:34.31ms
step:243/1547 train_time:8334ms step_avg:34.30ms
step:244/1547 train_time:8371ms step_avg:34.31ms
step:245/1547 train_time:8402ms step_avg:34.30ms
step:246/1547 train_time:8440ms step_avg:34.31ms
step:247/1547 train_time:8470ms step_avg:34.29ms
step:248/1547 train_time:8508ms step_avg:34.30ms
step:249/1547 train_time:8539ms step_avg:34.29ms
step:250/1547 train_time:8576ms step_avg:34.30ms
step:250/1547 val_loss:4.5444 train_time:8625ms step_avg:34.50ms
step:251/1547 train_time:8644ms step_avg:34.44ms
step:252/1547 train_time:8663ms step_avg:34.38ms
step:253/1547 train_time:8679ms step_avg:34.31ms
step:254/1547 train_time:8716ms step_avg:34.32ms
step:255/1547 train_time:8748ms step_avg:34.31ms
step:256/1547 train_time:8787ms step_avg:34.33ms
step:257/1547 train_time:8819ms step_avg:34.32ms
step:258/1547 train_time:8857ms step_avg:34.33ms
step:259/1547 train_time:8888ms step_avg:34.32ms
step:260/1547 train_time:8925ms step_avg:34.33ms
step:261/1547 train_time:8956ms step_avg:34.32ms
step:262/1547 train_time:8994ms step_avg:34.33ms
step:263/1547 train_time:9024ms step_avg:34.31ms
step:264/1547 train_time:9062ms step_avg:34.33ms
step:265/1547 train_time:9093ms step_avg:34.31ms
step:266/1547 train_time:9130ms step_avg:34.32ms
step:267/1547 train_time:9161ms step_avg:34.31ms
step:268/1547 train_time:9198ms step_avg:34.32ms
step:269/1547 train_time:9228ms step_avg:34.31ms
step:270/1547 train_time:9266ms step_avg:34.32ms
step:271/1547 train_time:9297ms step_avg:34.30ms
step:272/1547 train_time:9334ms step_avg:34.32ms
step:273/1547 train_time:9364ms step_avg:34.30ms
step:274/1547 train_time:9402ms step_avg:34.31ms
step:275/1547 train_time:9432ms step_avg:34.30ms
step:276/1547 train_time:9469ms step_avg:34.31ms
step:277/1547 train_time:9500ms step_avg:34.30ms
step:278/1547 train_time:9537ms step_avg:34.31ms
step:279/1547 train_time:9568ms step_avg:34.29ms
step:280/1547 train_time:9606ms step_avg:34.31ms
step:281/1547 train_time:9637ms step_avg:34.29ms
step:282/1547 train_time:9674ms step_avg:34.30ms
step:283/1547 train_time:9705ms step_avg:34.29ms
step:284/1547 train_time:9742ms step_avg:34.30ms
step:285/1547 train_time:9774ms step_avg:34.29ms
step:286/1547 train_time:9811ms step_avg:34.30ms
step:287/1547 train_time:9842ms step_avg:34.29ms
step:288/1547 train_time:9880ms step_avg:34.31ms
step:289/1547 train_time:9911ms step_avg:34.29ms
step:290/1547 train_time:9949ms step_avg:34.31ms
step:291/1547 train_time:9979ms step_avg:34.29ms
step:292/1547 train_time:10017ms step_avg:34.30ms
step:293/1547 train_time:10047ms step_avg:34.29ms
step:294/1547 train_time:10085ms step_avg:34.30ms
step:295/1547 train_time:10116ms step_avg:34.29ms
step:296/1547 train_time:10154ms step_avg:34.30ms
step:297/1547 train_time:10184ms step_avg:34.29ms
step:298/1547 train_time:10223ms step_avg:34.30ms
step:299/1547 train_time:10254ms step_avg:34.29ms
step:300/1547 train_time:10291ms step_avg:34.30ms
step:301/1547 train_time:10322ms step_avg:34.29ms
step:302/1547 train_time:10359ms step_avg:34.30ms
step:303/1547 train_time:10389ms step_avg:34.29ms
step:304/1547 train_time:10426ms step_avg:34.30ms
step:305/1547 train_time:10457ms step_avg:34.29ms
step:306/1547 train_time:10494ms step_avg:34.29ms
step:307/1547 train_time:10525ms step_avg:34.28ms
step:308/1547 train_time:10562ms step_avg:34.29ms
step:309/1547 train_time:10593ms step_avg:34.28ms
step:310/1547 train_time:10631ms step_avg:34.29ms
step:311/1547 train_time:10661ms step_avg:34.28ms
step:312/1547 train_time:10698ms step_avg:34.29ms
step:313/1547 train_time:10729ms step_avg:34.28ms
step:314/1547 train_time:10766ms step_avg:34.29ms
step:315/1547 train_time:10797ms step_avg:34.28ms
step:316/1547 train_time:10835ms step_avg:34.29ms
step:317/1547 train_time:10866ms step_avg:34.28ms
step:318/1547 train_time:10903ms step_avg:34.29ms
step:319/1547 train_time:10935ms step_avg:34.28ms
step:320/1547 train_time:10972ms step_avg:34.29ms
step:321/1547 train_time:11003ms step_avg:34.28ms
step:322/1547 train_time:11040ms step_avg:34.28ms
step:323/1547 train_time:11070ms step_avg:34.27ms
step:324/1547 train_time:11107ms step_avg:34.28ms
step:325/1547 train_time:11138ms step_avg:34.27ms
step:326/1547 train_time:11176ms step_avg:34.28ms
step:327/1547 train_time:11207ms step_avg:34.27ms
step:328/1547 train_time:11244ms step_avg:34.28ms
step:329/1547 train_time:11275ms step_avg:34.27ms
step:330/1547 train_time:11313ms step_avg:34.28ms
step:331/1547 train_time:11344ms step_avg:34.27ms
step:332/1547 train_time:11381ms step_avg:34.28ms
step:333/1547 train_time:11412ms step_avg:34.27ms
step:334/1547 train_time:11450ms step_avg:34.28ms
step:335/1547 train_time:11480ms step_avg:34.27ms
step:336/1547 train_time:11518ms step_avg:34.28ms
step:337/1547 train_time:11548ms step_avg:34.27ms
step:338/1547 train_time:11585ms step_avg:34.28ms
step:339/1547 train_time:11616ms step_avg:34.27ms
step:340/1547 train_time:11653ms step_avg:34.27ms
step:341/1547 train_time:11684ms step_avg:34.26ms
step:342/1547 train_time:11721ms step_avg:34.27ms
step:343/1547 train_time:11752ms step_avg:34.26ms
step:344/1547 train_time:11789ms step_avg:34.27ms
step:345/1547 train_time:11819ms step_avg:34.26ms
step:346/1547 train_time:11857ms step_avg:34.27ms
step:347/1547 train_time:11888ms step_avg:34.26ms
step:348/1547 train_time:11926ms step_avg:34.27ms
step:349/1547 train_time:11957ms step_avg:34.26ms
step:350/1547 train_time:11994ms step_avg:34.27ms
step:351/1547 train_time:12025ms step_avg:34.26ms
step:352/1547 train_time:12063ms step_avg:34.27ms
step:353/1547 train_time:12094ms step_avg:34.26ms
step:354/1547 train_time:12132ms step_avg:34.27ms
step:355/1547 train_time:12162ms step_avg:34.26ms
step:356/1547 train_time:12200ms step_avg:34.27ms
step:357/1547 train_time:12231ms step_avg:34.26ms
step:358/1547 train_time:12269ms step_avg:34.27ms
step:359/1547 train_time:12300ms step_avg:34.26ms
step:360/1547 train_time:12337ms step_avg:34.27ms
step:361/1547 train_time:12368ms step_avg:34.26ms
step:362/1547 train_time:12406ms step_avg:34.27ms
step:363/1547 train_time:12437ms step_avg:34.26ms
step:364/1547 train_time:12475ms step_avg:34.27ms
step:365/1547 train_time:12505ms step_avg:34.26ms
step:366/1547 train_time:12542ms step_avg:34.27ms
step:367/1547 train_time:12573ms step_avg:34.26ms
step:368/1547 train_time:12610ms step_avg:34.27ms
step:369/1547 train_time:12641ms step_avg:34.26ms
step:370/1547 train_time:12678ms step_avg:34.26ms
step:371/1547 train_time:12709ms step_avg:34.26ms
step:372/1547 train_time:12746ms step_avg:34.26ms
step:373/1547 train_time:12777ms step_avg:34.26ms
step:374/1547 train_time:12815ms step_avg:34.26ms
step:375/1547 train_time:12846ms step_avg:34.26ms
step:376/1547 train_time:12883ms step_avg:34.26ms
step:377/1547 train_time:12914ms step_avg:34.26ms
step:378/1547 train_time:12952ms step_avg:34.26ms
step:379/1547 train_time:12983ms step_avg:34.26ms
step:380/1547 train_time:13021ms step_avg:34.26ms
step:381/1547 train_time:13052ms step_avg:34.26ms
step:382/1547 train_time:13090ms step_avg:34.27ms
step:383/1547 train_time:13121ms step_avg:34.26ms
step:384/1547 train_time:13158ms step_avg:34.27ms
step:385/1547 train_time:13189ms step_avg:34.26ms
step:386/1547 train_time:13226ms step_avg:34.26ms
step:387/1547 train_time:13257ms step_avg:34.26ms
step:388/1547 train_time:13295ms step_avg:34.26ms
step:389/1547 train_time:13325ms step_avg:34.26ms
step:390/1547 train_time:13363ms step_avg:34.26ms
step:391/1547 train_time:13394ms step_avg:34.25ms
step:392/1547 train_time:13431ms step_avg:34.26ms
step:393/1547 train_time:13462ms step_avg:34.25ms
step:394/1547 train_time:13499ms step_avg:34.26ms
step:395/1547 train_time:13531ms step_avg:34.25ms
step:396/1547 train_time:13568ms step_avg:34.26ms
step:397/1547 train_time:13599ms step_avg:34.25ms
step:398/1547 train_time:13636ms step_avg:34.26ms
step:399/1547 train_time:13667ms step_avg:34.25ms
step:400/1547 train_time:13704ms step_avg:34.26ms
step:401/1547 train_time:13735ms step_avg:34.25ms
step:402/1547 train_time:13772ms step_avg:34.26ms
step:403/1547 train_time:13803ms step_avg:34.25ms
step:404/1547 train_time:13840ms step_avg:34.26ms
step:405/1547 train_time:13871ms step_avg:34.25ms
step:406/1547 train_time:13908ms step_avg:34.26ms
step:407/1547 train_time:13939ms step_avg:34.25ms
step:408/1547 train_time:13976ms step_avg:34.26ms
step:409/1547 train_time:14008ms step_avg:34.25ms
step:410/1547 train_time:14045ms step_avg:34.26ms
step:411/1547 train_time:14076ms step_avg:34.25ms
step:412/1547 train_time:14113ms step_avg:34.26ms
step:413/1547 train_time:14144ms step_avg:34.25ms
step:414/1547 train_time:14182ms step_avg:34.26ms
step:415/1547 train_time:14213ms step_avg:34.25ms
step:416/1547 train_time:14250ms step_avg:34.25ms
step:417/1547 train_time:14280ms step_avg:34.25ms
step:418/1547 train_time:14318ms step_avg:34.25ms
step:419/1547 train_time:14349ms step_avg:34.25ms
step:420/1547 train_time:14386ms step_avg:34.25ms
step:421/1547 train_time:14417ms step_avg:34.25ms
step:422/1547 train_time:14455ms step_avg:34.25ms
step:423/1547 train_time:14486ms step_avg:34.24ms
step:424/1547 train_time:14523ms step_avg:34.25ms
step:425/1547 train_time:14554ms step_avg:34.25ms
step:426/1547 train_time:14592ms step_avg:34.25ms
step:427/1547 train_time:14622ms step_avg:34.24ms
step:428/1547 train_time:14659ms step_avg:34.25ms
step:429/1547 train_time:14690ms step_avg:34.24ms
step:430/1547 train_time:14728ms step_avg:34.25ms
step:431/1547 train_time:14758ms step_avg:34.24ms
step:432/1547 train_time:14795ms step_avg:34.25ms
step:433/1547 train_time:14826ms step_avg:34.24ms
step:434/1547 train_time:14863ms step_avg:34.25ms
step:435/1547 train_time:14894ms step_avg:34.24ms
step:436/1547 train_time:14931ms step_avg:34.25ms
step:437/1547 train_time:14962ms step_avg:34.24ms
step:438/1547 train_time:14999ms step_avg:34.24ms
step:439/1547 train_time:15029ms step_avg:34.24ms
step:440/1547 train_time:15067ms step_avg:34.24ms
step:441/1547 train_time:15098ms step_avg:34.24ms
step:442/1547 train_time:15136ms step_avg:34.24ms
step:443/1547 train_time:15166ms step_avg:34.24ms
step:444/1547 train_time:15204ms step_avg:34.24ms
step:445/1547 train_time:15234ms step_avg:34.23ms
step:446/1547 train_time:15272ms step_avg:34.24ms
step:447/1547 train_time:15302ms step_avg:34.23ms
step:448/1547 train_time:15340ms step_avg:34.24ms
step:449/1547 train_time:15370ms step_avg:34.23ms
step:450/1547 train_time:15408ms step_avg:34.24ms
step:451/1547 train_time:15439ms step_avg:34.23ms
step:452/1547 train_time:15476ms step_avg:34.24ms
step:453/1547 train_time:15507ms step_avg:34.23ms
step:454/1547 train_time:15544ms step_avg:34.24ms
step:455/1547 train_time:15575ms step_avg:34.23ms
step:456/1547 train_time:15612ms step_avg:34.24ms
step:457/1547 train_time:15643ms step_avg:34.23ms
step:458/1547 train_time:15680ms step_avg:34.24ms
step:459/1547 train_time:15711ms step_avg:34.23ms
step:460/1547 train_time:15749ms step_avg:34.24ms
step:461/1547 train_time:15779ms step_avg:34.23ms
step:462/1547 train_time:15817ms step_avg:34.24ms
step:463/1547 train_time:15847ms step_avg:34.23ms
step:464/1547 train_time:15885ms step_avg:34.23ms
step:465/1547 train_time:15916ms step_avg:34.23ms
step:466/1547 train_time:15953ms step_avg:34.23ms
step:467/1547 train_time:15984ms step_avg:34.23ms
step:468/1547 train_time:16021ms step_avg:34.23ms
step:469/1547 train_time:16052ms step_avg:34.23ms
step:470/1547 train_time:16089ms step_avg:34.23ms
step:471/1547 train_time:16120ms step_avg:34.22ms
step:472/1547 train_time:16157ms step_avg:34.23ms
step:473/1547 train_time:16188ms step_avg:34.22ms
step:474/1547 train_time:16226ms step_avg:34.23ms
step:475/1547 train_time:16257ms step_avg:34.23ms
step:476/1547 train_time:16295ms step_avg:34.23ms
step:477/1547 train_time:16326ms step_avg:34.23ms
step:478/1547 train_time:16363ms step_avg:34.23ms
step:479/1547 train_time:16394ms step_avg:34.23ms
step:480/1547 train_time:16431ms step_avg:34.23ms
step:481/1547 train_time:16462ms step_avg:34.22ms
step:482/1547 train_time:16499ms step_avg:34.23ms
step:483/1547 train_time:16530ms step_avg:34.22ms
step:484/1547 train_time:16567ms step_avg:34.23ms
step:485/1547 train_time:16598ms step_avg:34.22ms
step:486/1547 train_time:16636ms step_avg:34.23ms
step:487/1547 train_time:16666ms step_avg:34.22ms
step:488/1547 train_time:16704ms step_avg:34.23ms
step:489/1547 train_time:16734ms step_avg:34.22ms
step:490/1547 train_time:16772ms step_avg:34.23ms
step:491/1547 train_time:16802ms step_avg:34.22ms
step:492/1547 train_time:16839ms step_avg:34.23ms
step:493/1547 train_time:16870ms step_avg:34.22ms
step:494/1547 train_time:16908ms step_avg:34.23ms
step:495/1547 train_time:16938ms step_avg:34.22ms
step:496/1547 train_time:16975ms step_avg:34.22ms
step:497/1547 train_time:17006ms step_avg:34.22ms
step:498/1547 train_time:17044ms step_avg:34.22ms
step:499/1547 train_time:17075ms step_avg:34.22ms
step:500/1547 train_time:17113ms step_avg:34.23ms
step:500/1547 val_loss:4.2213 train_time:17162ms step_avg:34.32ms
step:501/1547 train_time:17181ms step_avg:34.29ms
step:502/1547 train_time:17200ms step_avg:34.26ms
step:503/1547 train_time:17259ms step_avg:34.31ms
step:504/1547 train_time:17317ms step_avg:34.36ms
step:505/1547 train_time:17381ms step_avg:34.42ms
step:506/1547 train_time:17439ms step_avg:34.47ms
step:507/1547 train_time:17502ms step_avg:34.52ms
step:508/1547 train_time:17561ms step_avg:34.57ms
step:509/1547 train_time:17623ms step_avg:34.62ms
step:510/1547 train_time:17682ms step_avg:34.67ms
step:511/1547 train_time:17744ms step_avg:34.72ms
step:512/1547 train_time:17802ms step_avg:34.77ms
step:513/1547 train_time:17864ms step_avg:34.82ms
step:514/1547 train_time:17922ms step_avg:34.87ms
step:515/1547 train_time:17985ms step_avg:34.92ms
step:516/1547 train_time:18044ms step_avg:34.97ms
step:517/1547 train_time:18108ms step_avg:35.03ms
step:518/1547 train_time:18169ms step_avg:35.08ms
step:519/1547 train_time:18235ms step_avg:35.13ms
step:520/1547 train_time:18294ms step_avg:35.18ms
step:521/1547 train_time:18358ms step_avg:35.24ms
step:522/1547 train_time:18416ms step_avg:35.28ms
step:523/1547 train_time:18480ms step_avg:35.33ms
step:524/1547 train_time:18538ms step_avg:35.38ms
step:525/1547 train_time:18601ms step_avg:35.43ms
step:526/1547 train_time:18659ms step_avg:35.47ms
step:527/1547 train_time:18722ms step_avg:35.52ms
step:528/1547 train_time:18781ms step_avg:35.57ms
step:529/1547 train_time:18844ms step_avg:35.62ms
step:530/1547 train_time:18902ms step_avg:35.66ms
step:531/1547 train_time:18964ms step_avg:35.71ms
step:532/1547 train_time:19023ms step_avg:35.76ms
step:533/1547 train_time:19087ms step_avg:35.81ms
step:534/1547 train_time:19147ms step_avg:35.86ms
step:535/1547 train_time:19210ms step_avg:35.91ms
step:536/1547 train_time:19270ms step_avg:35.95ms
step:537/1547 train_time:19334ms step_avg:36.00ms
step:538/1547 train_time:19392ms step_avg:36.05ms
step:539/1547 train_time:19456ms step_avg:36.10ms
step:540/1547 train_time:19514ms step_avg:36.14ms
step:541/1547 train_time:19578ms step_avg:36.19ms
step:542/1547 train_time:19638ms step_avg:36.23ms
step:543/1547 train_time:19701ms step_avg:36.28ms
step:544/1547 train_time:19760ms step_avg:36.32ms
step:545/1547 train_time:19822ms step_avg:36.37ms
step:546/1547 train_time:19880ms step_avg:36.41ms
step:547/1547 train_time:19942ms step_avg:36.46ms
step:548/1547 train_time:20000ms step_avg:36.50ms
step:549/1547 train_time:20063ms step_avg:36.55ms
step:550/1547 train_time:20122ms step_avg:36.59ms
step:551/1547 train_time:20187ms step_avg:36.64ms
step:552/1547 train_time:20246ms step_avg:36.68ms
step:553/1547 train_time:20311ms step_avg:36.73ms
step:554/1547 train_time:20370ms step_avg:36.77ms
step:555/1547 train_time:20433ms step_avg:36.82ms
step:556/1547 train_time:20492ms step_avg:36.86ms
step:557/1547 train_time:20555ms step_avg:36.90ms
step:558/1547 train_time:20615ms step_avg:36.94ms
step:559/1547 train_time:20678ms step_avg:36.99ms
step:560/1547 train_time:20736ms step_avg:37.03ms
step:561/1547 train_time:20799ms step_avg:37.08ms
step:562/1547 train_time:20857ms step_avg:37.11ms
step:563/1547 train_time:20921ms step_avg:37.16ms
step:564/1547 train_time:20982ms step_avg:37.20ms
step:565/1547 train_time:21045ms step_avg:37.25ms
step:566/1547 train_time:21103ms step_avg:37.29ms
step:567/1547 train_time:21166ms step_avg:37.33ms
step:568/1547 train_time:21224ms step_avg:37.37ms
step:569/1547 train_time:21287ms step_avg:37.41ms
step:570/1547 train_time:21346ms step_avg:37.45ms
step:571/1547 train_time:21410ms step_avg:37.50ms
step:572/1547 train_time:21469ms step_avg:37.53ms
step:573/1547 train_time:21532ms step_avg:37.58ms
step:574/1547 train_time:21591ms step_avg:37.61ms
step:575/1547 train_time:21654ms step_avg:37.66ms
step:576/1547 train_time:21714ms step_avg:37.70ms
step:577/1547 train_time:21778ms step_avg:37.74ms
step:578/1547 train_time:21837ms step_avg:37.78ms
step:579/1547 train_time:21900ms step_avg:37.82ms
step:580/1547 train_time:21958ms step_avg:37.86ms
step:581/1547 train_time:22022ms step_avg:37.90ms
step:582/1547 train_time:22081ms step_avg:37.94ms
step:583/1547 train_time:22144ms step_avg:37.98ms
step:584/1547 train_time:22202ms step_avg:38.02ms
step:585/1547 train_time:22265ms step_avg:38.06ms
step:586/1547 train_time:22324ms step_avg:38.10ms
step:587/1547 train_time:22388ms step_avg:38.14ms
step:588/1547 train_time:22447ms step_avg:38.18ms
step:589/1547 train_time:22511ms step_avg:38.22ms
step:590/1547 train_time:22569ms step_avg:38.25ms
step:591/1547 train_time:22633ms step_avg:38.30ms
step:592/1547 train_time:22692ms step_avg:38.33ms
step:593/1547 train_time:22755ms step_avg:38.37ms
step:594/1547 train_time:22814ms step_avg:38.41ms
step:595/1547 train_time:22878ms step_avg:38.45ms
step:596/1547 train_time:22937ms step_avg:38.49ms
step:597/1547 train_time:23001ms step_avg:38.53ms
step:598/1547 train_time:23059ms step_avg:38.56ms
step:599/1547 train_time:23123ms step_avg:38.60ms
step:600/1547 train_time:23181ms step_avg:38.63ms
step:601/1547 train_time:23243ms step_avg:38.67ms
step:602/1547 train_time:23302ms step_avg:38.71ms
step:603/1547 train_time:23365ms step_avg:38.75ms
step:604/1547 train_time:23424ms step_avg:38.78ms
step:605/1547 train_time:23487ms step_avg:38.82ms
step:606/1547 train_time:23547ms step_avg:38.86ms
step:607/1547 train_time:23612ms step_avg:38.90ms
step:608/1547 train_time:23671ms step_avg:38.93ms
step:609/1547 train_time:23735ms step_avg:38.97ms
step:610/1547 train_time:23793ms step_avg:39.01ms
step:611/1547 train_time:23858ms step_avg:39.05ms
step:612/1547 train_time:23917ms step_avg:39.08ms
step:613/1547 train_time:23980ms step_avg:39.12ms
step:614/1547 train_time:24039ms step_avg:39.15ms
step:615/1547 train_time:24101ms step_avg:39.19ms
step:616/1547 train_time:24160ms step_avg:39.22ms
step:617/1547 train_time:24223ms step_avg:39.26ms
step:618/1547 train_time:24281ms step_avg:39.29ms
step:619/1547 train_time:24344ms step_avg:39.33ms
step:620/1547 train_time:24402ms step_avg:39.36ms
step:621/1547 train_time:24466ms step_avg:39.40ms
step:622/1547 train_time:24525ms step_avg:39.43ms
step:623/1547 train_time:24588ms step_avg:39.47ms
step:624/1547 train_time:24648ms step_avg:39.50ms
step:625/1547 train_time:24713ms step_avg:39.54ms
step:626/1547 train_time:24773ms step_avg:39.57ms
step:627/1547 train_time:24836ms step_avg:39.61ms
step:628/1547 train_time:24896ms step_avg:39.64ms
step:629/1547 train_time:24961ms step_avg:39.68ms
step:630/1547 train_time:25020ms step_avg:39.71ms
step:631/1547 train_time:25083ms step_avg:39.75ms
step:632/1547 train_time:25141ms step_avg:39.78ms
step:633/1547 train_time:25204ms step_avg:39.82ms
step:634/1547 train_time:25262ms step_avg:39.85ms
step:635/1547 train_time:25325ms step_avg:39.88ms
step:636/1547 train_time:25383ms step_avg:39.91ms
step:637/1547 train_time:25446ms step_avg:39.95ms
step:638/1547 train_time:25505ms step_avg:39.98ms
step:639/1547 train_time:25569ms step_avg:40.01ms
step:640/1547 train_time:25627ms step_avg:40.04ms
step:641/1547 train_time:25692ms step_avg:40.08ms
step:642/1547 train_time:25752ms step_avg:40.11ms
step:643/1547 train_time:25815ms step_avg:40.15ms
step:644/1547 train_time:25874ms step_avg:40.18ms
step:645/1547 train_time:25937ms step_avg:40.21ms
step:646/1547 train_time:25996ms step_avg:40.24ms
step:647/1547 train_time:26060ms step_avg:40.28ms
step:648/1547 train_time:26119ms step_avg:40.31ms
step:649/1547 train_time:26182ms step_avg:40.34ms
step:650/1547 train_time:26240ms step_avg:40.37ms
step:651/1547 train_time:26306ms step_avg:40.41ms
step:652/1547 train_time:26365ms step_avg:40.44ms
step:653/1547 train_time:26428ms step_avg:40.47ms
step:654/1547 train_time:26486ms step_avg:40.50ms
step:655/1547 train_time:26550ms step_avg:40.53ms
step:656/1547 train_time:26609ms step_avg:40.56ms
step:657/1547 train_time:26673ms step_avg:40.60ms
step:658/1547 train_time:26732ms step_avg:40.63ms
step:659/1547 train_time:26797ms step_avg:40.66ms
step:660/1547 train_time:26856ms step_avg:40.69ms
step:661/1547 train_time:26919ms step_avg:40.72ms
step:662/1547 train_time:26977ms step_avg:40.75ms
step:663/1547 train_time:27041ms step_avg:40.79ms
step:664/1547 train_time:27100ms step_avg:40.81ms
step:665/1547 train_time:27163ms step_avg:40.85ms
step:666/1547 train_time:27223ms step_avg:40.88ms
step:667/1547 train_time:27285ms step_avg:40.91ms
step:668/1547 train_time:27343ms step_avg:40.93ms
step:669/1547 train_time:27406ms step_avg:40.97ms
step:670/1547 train_time:27465ms step_avg:40.99ms
step:671/1547 train_time:27528ms step_avg:41.03ms
step:672/1547 train_time:27587ms step_avg:41.05ms
step:673/1547 train_time:27652ms step_avg:41.09ms
step:674/1547 train_time:27712ms step_avg:41.12ms
step:675/1547 train_time:27776ms step_avg:41.15ms
step:676/1547 train_time:27835ms step_avg:41.18ms
step:677/1547 train_time:27898ms step_avg:41.21ms
step:678/1547 train_time:27956ms step_avg:41.23ms
step:679/1547 train_time:28019ms step_avg:41.27ms
step:680/1547 train_time:28078ms step_avg:41.29ms
step:681/1547 train_time:28142ms step_avg:41.33ms
step:682/1547 train_time:28200ms step_avg:41.35ms
step:683/1547 train_time:28263ms step_avg:41.38ms
step:684/1547 train_time:28322ms step_avg:41.41ms
step:685/1547 train_time:28385ms step_avg:41.44ms
step:686/1547 train_time:28444ms step_avg:41.46ms
step:687/1547 train_time:28507ms step_avg:41.50ms
step:688/1547 train_time:28567ms step_avg:41.52ms
step:689/1547 train_time:28630ms step_avg:41.55ms
step:690/1547 train_time:28689ms step_avg:41.58ms
step:691/1547 train_time:28754ms step_avg:41.61ms
step:692/1547 train_time:28813ms step_avg:41.64ms
step:693/1547 train_time:28876ms step_avg:41.67ms
step:694/1547 train_time:28934ms step_avg:41.69ms
step:695/1547 train_time:28997ms step_avg:41.72ms
step:696/1547 train_time:29055ms step_avg:41.75ms
step:697/1547 train_time:29119ms step_avg:41.78ms
step:698/1547 train_time:29178ms step_avg:41.80ms
step:699/1547 train_time:29241ms step_avg:41.83ms
step:700/1547 train_time:29299ms step_avg:41.86ms
step:701/1547 train_time:29363ms step_avg:41.89ms
step:702/1547 train_time:29423ms step_avg:41.91ms
step:703/1547 train_time:29485ms step_avg:41.94ms
step:704/1547 train_time:29544ms step_avg:41.97ms
step:705/1547 train_time:29607ms step_avg:42.00ms
step:706/1547 train_time:29667ms step_avg:42.02ms
step:707/1547 train_time:29731ms step_avg:42.05ms
step:708/1547 train_time:29790ms step_avg:42.08ms
step:709/1547 train_time:29855ms step_avg:42.11ms
step:710/1547 train_time:29914ms step_avg:42.13ms
step:711/1547 train_time:29976ms step_avg:42.16ms
step:712/1547 train_time:30035ms step_avg:42.18ms
step:713/1547 train_time:30098ms step_avg:42.21ms
step:714/1547 train_time:30157ms step_avg:42.24ms
step:715/1547 train_time:30220ms step_avg:42.27ms
step:716/1547 train_time:30279ms step_avg:42.29ms
step:717/1547 train_time:30343ms step_avg:42.32ms
step:718/1547 train_time:30402ms step_avg:42.34ms
step:719/1547 train_time:30467ms step_avg:42.37ms
step:720/1547 train_time:30527ms step_avg:42.40ms
step:721/1547 train_time:30590ms step_avg:42.43ms
step:722/1547 train_time:30649ms step_avg:42.45ms
step:723/1547 train_time:30713ms step_avg:42.48ms
step:724/1547 train_time:30771ms step_avg:42.50ms
step:725/1547 train_time:30835ms step_avg:42.53ms
step:726/1547 train_time:30894ms step_avg:42.55ms
step:727/1547 train_time:30957ms step_avg:42.58ms
step:728/1547 train_time:31015ms step_avg:42.60ms
step:729/1547 train_time:31077ms step_avg:42.63ms
step:730/1547 train_time:31136ms step_avg:42.65ms
step:731/1547 train_time:31199ms step_avg:42.68ms
step:732/1547 train_time:31257ms step_avg:42.70ms
step:733/1547 train_time:31321ms step_avg:42.73ms
step:734/1547 train_time:31379ms step_avg:42.75ms
step:735/1547 train_time:31442ms step_avg:42.78ms
step:736/1547 train_time:31503ms step_avg:42.80ms
step:737/1547 train_time:31566ms step_avg:42.83ms
step:738/1547 train_time:31625ms step_avg:42.85ms
step:739/1547 train_time:31688ms step_avg:42.88ms
step:740/1547 train_time:31747ms step_avg:42.90ms
step:741/1547 train_time:31811ms step_avg:42.93ms
step:742/1547 train_time:31869ms step_avg:42.95ms
step:743/1547 train_time:31933ms step_avg:42.98ms
step:744/1547 train_time:31991ms step_avg:43.00ms
step:745/1547 train_time:32054ms step_avg:43.03ms
step:746/1547 train_time:32113ms step_avg:43.05ms
step:747/1547 train_time:32176ms step_avg:43.07ms
step:748/1547 train_time:32237ms step_avg:43.10ms
step:749/1547 train_time:32299ms step_avg:43.12ms
step:750/1547 train_time:32359ms step_avg:43.15ms
step:750/1547 val_loss:3.8877 train_time:32404ms step_avg:43.21ms
step:751/1547 train_time:32424ms step_avg:43.17ms
step:752/1547 train_time:32483ms step_avg:43.20ms
step:753/1547 train_time:32551ms step_avg:43.23ms
step:754/1547 train_time:32612ms step_avg:43.25ms
step:755/1547 train_time:32674ms step_avg:43.28ms
step:756/1547 train_time:32734ms step_avg:43.30ms
step:757/1547 train_time:32796ms step_avg:43.32ms
step:758/1547 train_time:32854ms step_avg:43.34ms
step:759/1547 train_time:32917ms step_avg:43.37ms
step:760/1547 train_time:32975ms step_avg:43.39ms
step:761/1547 train_time:33038ms step_avg:43.41ms
step:762/1547 train_time:33096ms step_avg:43.43ms
step:763/1547 train_time:33159ms step_avg:43.46ms
step:764/1547 train_time:33218ms step_avg:43.48ms
step:765/1547 train_time:33280ms step_avg:43.50ms
step:766/1547 train_time:33339ms step_avg:43.52ms
step:767/1547 train_time:33404ms step_avg:43.55ms
step:768/1547 train_time:33463ms step_avg:43.57ms
step:769/1547 train_time:33527ms step_avg:43.60ms
step:770/1547 train_time:33586ms step_avg:43.62ms
step:771/1547 train_time:33651ms step_avg:43.65ms
step:772/1547 train_time:33710ms step_avg:43.67ms
step:773/1547 train_time:33773ms step_avg:43.69ms
step:774/1547 train_time:33832ms step_avg:43.71ms
step:775/1547 train_time:33896ms step_avg:43.74ms
step:776/1547 train_time:33955ms step_avg:43.76ms
step:777/1547 train_time:34019ms step_avg:43.78ms
step:778/1547 train_time:34077ms step_avg:43.80ms
step:779/1547 train_time:34139ms step_avg:43.82ms
step:780/1547 train_time:34198ms step_avg:43.84ms
step:781/1547 train_time:34260ms step_avg:43.87ms
step:782/1547 train_time:34319ms step_avg:43.89ms
step:783/1547 train_time:34383ms step_avg:43.91ms
step:784/1547 train_time:34442ms step_avg:43.93ms
step:785/1547 train_time:34505ms step_avg:43.96ms
step:786/1547 train_time:34564ms step_avg:43.97ms
step:787/1547 train_time:34627ms step_avg:44.00ms
step:788/1547 train_time:34686ms step_avg:44.02ms
step:789/1547 train_time:34749ms step_avg:44.04ms
step:790/1547 train_time:34807ms step_avg:44.06ms
step:791/1547 train_time:34871ms step_avg:44.08ms
step:792/1547 train_time:34930ms step_avg:44.10ms
step:793/1547 train_time:34995ms step_avg:44.13ms
step:794/1547 train_time:35054ms step_avg:44.15ms
step:795/1547 train_time:35117ms step_avg:44.17ms
step:796/1547 train_time:35175ms step_avg:44.19ms
step:797/1547 train_time:35239ms step_avg:44.21ms
step:798/1547 train_time:35298ms step_avg:44.23ms
step:799/1547 train_time:35362ms step_avg:44.26ms
step:800/1547 train_time:35421ms step_avg:44.28ms
step:801/1547 train_time:35484ms step_avg:44.30ms
step:802/1547 train_time:35544ms step_avg:44.32ms
step:803/1547 train_time:35608ms step_avg:44.34ms
step:804/1547 train_time:35667ms step_avg:44.36ms
step:805/1547 train_time:35731ms step_avg:44.39ms
step:806/1547 train_time:35790ms step_avg:44.40ms
step:807/1547 train_time:35853ms step_avg:44.43ms
step:808/1547 train_time:35912ms step_avg:44.44ms
step:809/1547 train_time:35975ms step_avg:44.47ms
step:810/1547 train_time:36033ms step_avg:44.49ms
step:811/1547 train_time:36096ms step_avg:44.51ms
step:812/1547 train_time:36156ms step_avg:44.53ms
step:813/1547 train_time:36219ms step_avg:44.55ms
step:814/1547 train_time:36279ms step_avg:44.57ms
step:815/1547 train_time:36342ms step_avg:44.59ms
step:816/1547 train_time:36401ms step_avg:44.61ms
step:817/1547 train_time:36465ms step_avg:44.63ms
step:818/1547 train_time:36523ms step_avg:44.65ms
step:819/1547 train_time:36587ms step_avg:44.67ms
step:820/1547 train_time:36646ms step_avg:44.69ms
step:821/1547 train_time:36709ms step_avg:44.71ms
step:822/1547 train_time:36768ms step_avg:44.73ms
step:823/1547 train_time:36831ms step_avg:44.75ms
step:824/1547 train_time:36889ms step_avg:44.77ms
step:825/1547 train_time:36951ms step_avg:44.79ms
step:826/1547 train_time:37009ms step_avg:44.80ms
step:827/1547 train_time:37072ms step_avg:44.83ms
step:828/1547 train_time:37132ms step_avg:44.84ms
step:829/1547 train_time:37195ms step_avg:44.87ms
step:830/1547 train_time:37254ms step_avg:44.88ms
step:831/1547 train_time:37318ms step_avg:44.91ms
step:832/1547 train_time:37378ms step_avg:44.93ms
step:833/1547 train_time:37443ms step_avg:44.95ms
step:834/1547 train_time:37502ms step_avg:44.97ms
step:835/1547 train_time:37566ms step_avg:44.99ms
step:836/1547 train_time:37625ms step_avg:45.01ms
step:837/1547 train_time:37689ms step_avg:45.03ms
step:838/1547 train_time:37747ms step_avg:45.04ms
step:839/1547 train_time:37811ms step_avg:45.07ms
step:840/1547 train_time:37869ms step_avg:45.08ms
step:841/1547 train_time:37931ms step_avg:45.10ms
step:842/1547 train_time:37989ms step_avg:45.12ms
step:843/1547 train_time:38051ms step_avg:45.14ms
step:844/1547 train_time:38109ms step_avg:45.15ms
step:845/1547 train_time:38173ms step_avg:45.18ms
step:846/1547 train_time:38233ms step_avg:45.19ms
step:847/1547 train_time:38296ms step_avg:45.21ms
step:848/1547 train_time:38355ms step_avg:45.23ms
step:849/1547 train_time:38421ms step_avg:45.25ms
step:850/1547 train_time:38480ms step_avg:45.27ms
step:851/1547 train_time:38544ms step_avg:45.29ms
step:852/1547 train_time:38603ms step_avg:45.31ms
step:853/1547 train_time:38667ms step_avg:45.33ms
step:854/1547 train_time:38726ms step_avg:45.35ms
step:855/1547 train_time:38789ms step_avg:45.37ms
step:856/1547 train_time:38849ms step_avg:45.38ms
step:857/1547 train_time:38912ms step_avg:45.40ms
step:858/1547 train_time:38970ms step_avg:45.42ms
step:859/1547 train_time:39033ms step_avg:45.44ms
step:860/1547 train_time:39091ms step_avg:45.46ms
step:861/1547 train_time:39155ms step_avg:45.48ms
step:862/1547 train_time:39214ms step_avg:45.49ms
step:863/1547 train_time:39278ms step_avg:45.51ms
step:864/1547 train_time:39337ms step_avg:45.53ms
step:865/1547 train_time:39403ms step_avg:45.55ms
step:866/1547 train_time:39460ms step_avg:45.57ms
step:867/1547 train_time:39524ms step_avg:45.59ms
step:868/1547 train_time:39583ms step_avg:45.60ms
step:869/1547 train_time:39646ms step_avg:45.62ms
step:870/1547 train_time:39704ms step_avg:45.64ms
step:871/1547 train_time:39768ms step_avg:45.66ms
step:872/1547 train_time:39828ms step_avg:45.67ms
step:873/1547 train_time:39891ms step_avg:45.69ms
step:874/1547 train_time:39950ms step_avg:45.71ms
step:875/1547 train_time:40012ms step_avg:45.73ms
step:876/1547 train_time:40071ms step_avg:45.74ms
step:877/1547 train_time:40133ms step_avg:45.76ms
step:878/1547 train_time:40191ms step_avg:45.78ms
step:879/1547 train_time:40255ms step_avg:45.80ms
step:880/1547 train_time:40314ms step_avg:45.81ms
step:881/1547 train_time:40380ms step_avg:45.83ms
step:882/1547 train_time:40439ms step_avg:45.85ms
step:883/1547 train_time:40502ms step_avg:45.87ms
step:884/1547 train_time:40562ms step_avg:45.88ms
step:885/1547 train_time:40625ms step_avg:45.90ms
step:886/1547 train_time:40684ms step_avg:45.92ms
step:887/1547 train_time:40747ms step_avg:45.94ms
step:888/1547 train_time:40806ms step_avg:45.95ms
step:889/1547 train_time:40869ms step_avg:45.97ms
step:890/1547 train_time:40928ms step_avg:45.99ms
step:891/1547 train_time:40991ms step_avg:46.01ms
step:892/1547 train_time:41049ms step_avg:46.02ms
step:893/1547 train_time:41110ms step_avg:46.04ms
step:894/1547 train_time:41169ms step_avg:46.05ms
step:895/1547 train_time:41232ms step_avg:46.07ms
step:896/1547 train_time:41291ms step_avg:46.08ms
step:897/1547 train_time:41355ms step_avg:46.10ms
step:898/1547 train_time:41414ms step_avg:46.12ms
step:899/1547 train_time:41479ms step_avg:46.14ms
step:900/1547 train_time:41538ms step_avg:46.15ms
step:901/1547 train_time:41601ms step_avg:46.17ms
step:902/1547 train_time:41661ms step_avg:46.19ms
step:903/1547 train_time:41724ms step_avg:46.21ms
step:904/1547 train_time:41782ms step_avg:46.22ms
step:905/1547 train_time:41845ms step_avg:46.24ms
step:906/1547 train_time:41904ms step_avg:46.25ms
step:907/1547 train_time:41968ms step_avg:46.27ms
step:908/1547 train_time:42026ms step_avg:46.28ms
step:909/1547 train_time:42089ms step_avg:46.30ms
step:910/1547 train_time:42148ms step_avg:46.32ms
step:911/1547 train_time:42210ms step_avg:46.33ms
step:912/1547 train_time:42269ms step_avg:46.35ms
step:913/1547 train_time:42332ms step_avg:46.37ms
step:914/1547 train_time:42391ms step_avg:46.38ms
step:915/1547 train_time:42456ms step_avg:46.40ms
step:916/1547 train_time:42515ms step_avg:46.41ms
step:917/1547 train_time:42579ms step_avg:46.43ms
step:918/1547 train_time:42638ms step_avg:46.45ms
step:919/1547 train_time:42701ms step_avg:46.46ms
step:920/1547 train_time:42760ms step_avg:46.48ms
step:921/1547 train_time:42824ms step_avg:46.50ms
step:922/1547 train_time:42883ms step_avg:46.51ms
step:923/1547 train_time:42946ms step_avg:46.53ms
step:924/1547 train_time:43004ms step_avg:46.54ms
step:925/1547 train_time:43068ms step_avg:46.56ms
step:926/1547 train_time:43128ms step_avg:46.57ms
step:927/1547 train_time:43191ms step_avg:46.59ms
step:928/1547 train_time:43249ms step_avg:46.60ms
step:929/1547 train_time:43312ms step_avg:46.62ms
step:930/1547 train_time:43370ms step_avg:46.63ms
step:931/1547 train_time:43434ms step_avg:46.65ms
step:932/1547 train_time:43496ms step_avg:46.67ms
step:933/1547 train_time:43558ms step_avg:46.69ms
step:934/1547 train_time:43616ms step_avg:46.70ms
step:935/1547 train_time:43679ms step_avg:46.72ms
step:936/1547 train_time:43739ms step_avg:46.73ms
step:937/1547 train_time:43802ms step_avg:46.75ms
step:938/1547 train_time:43861ms step_avg:46.76ms
step:939/1547 train_time:43924ms step_avg:46.78ms
step:940/1547 train_time:43983ms step_avg:46.79ms
step:941/1547 train_time:44047ms step_avg:46.81ms
step:942/1547 train_time:44107ms step_avg:46.82ms
step:943/1547 train_time:44170ms step_avg:46.84ms
step:944/1547 train_time:44228ms step_avg:46.85ms
step:945/1547 train_time:44291ms step_avg:46.87ms
step:946/1547 train_time:44349ms step_avg:46.88ms
step:947/1547 train_time:44412ms step_avg:46.90ms
step:948/1547 train_time:44472ms step_avg:46.91ms
step:949/1547 train_time:44535ms step_avg:46.93ms
step:950/1547 train_time:44594ms step_avg:46.94ms
step:951/1547 train_time:44657ms step_avg:46.96ms
step:952/1547 train_time:44716ms step_avg:46.97ms
step:953/1547 train_time:44780ms step_avg:46.99ms
step:954/1547 train_time:44838ms step_avg:47.00ms
step:955/1547 train_time:44902ms step_avg:47.02ms
step:956/1547 train_time:44961ms step_avg:47.03ms
step:957/1547 train_time:45024ms step_avg:47.05ms
step:958/1547 train_time:45084ms step_avg:47.06ms
step:959/1547 train_time:45148ms step_avg:47.08ms
step:960/1547 train_time:45207ms step_avg:47.09ms
step:961/1547 train_time:45269ms step_avg:47.11ms
step:962/1547 train_time:45326ms step_avg:47.12ms
step:963/1547 train_time:45389ms step_avg:47.13ms
step:964/1547 train_time:45447ms step_avg:47.14ms
step:965/1547 train_time:45509ms step_avg:47.16ms
step:966/1547 train_time:45568ms step_avg:47.17ms
step:967/1547 train_time:45632ms step_avg:47.19ms
step:968/1547 train_time:45692ms step_avg:47.20ms
step:969/1547 train_time:45757ms step_avg:47.22ms
step:970/1547 train_time:45816ms step_avg:47.23ms
step:971/1547 train_time:45880ms step_avg:47.25ms
step:972/1547 train_time:45939ms step_avg:47.26ms
step:973/1547 train_time:46003ms step_avg:47.28ms
step:974/1547 train_time:46062ms step_avg:47.29ms
step:975/1547 train_time:46125ms step_avg:47.31ms
step:976/1547 train_time:46182ms step_avg:47.32ms
step:977/1547 train_time:46245ms step_avg:47.33ms
step:978/1547 train_time:46304ms step_avg:47.35ms
step:979/1547 train_time:46367ms step_avg:47.36ms
step:980/1547 train_time:46426ms step_avg:47.37ms
step:981/1547 train_time:46489ms step_avg:47.39ms
step:982/1547 train_time:46546ms step_avg:47.40ms
step:983/1547 train_time:46609ms step_avg:47.42ms
step:984/1547 train_time:46667ms step_avg:47.43ms
step:985/1547 train_time:46731ms step_avg:47.44ms
step:986/1547 train_time:46791ms step_avg:47.46ms
step:987/1547 train_time:46855ms step_avg:47.47ms
step:988/1547 train_time:46914ms step_avg:47.48ms
step:989/1547 train_time:46978ms step_avg:47.50ms
step:990/1547 train_time:47038ms step_avg:47.51ms
step:991/1547 train_time:47100ms step_avg:47.53ms
step:992/1547 train_time:47161ms step_avg:47.54ms
step:993/1547 train_time:47224ms step_avg:47.56ms
step:994/1547 train_time:47284ms step_avg:47.57ms
step:995/1547 train_time:47347ms step_avg:47.58ms
step:996/1547 train_time:47406ms step_avg:47.60ms
step:997/1547 train_time:47469ms step_avg:47.61ms
step:998/1547 train_time:47528ms step_avg:47.62ms
step:999/1547 train_time:47589ms step_avg:47.64ms
step:1000/1547 train_time:47648ms step_avg:47.65ms
step:1000/1547 val_loss:3.5680 train_time:47694ms step_avg:47.69ms
step:1001/1547 train_time:47713ms step_avg:47.67ms
step:1002/1547 train_time:47772ms step_avg:47.68ms
step:1003/1547 train_time:47839ms step_avg:47.70ms
step:1004/1547 train_time:47899ms step_avg:47.71ms
step:1005/1547 train_time:47962ms step_avg:47.72ms
step:1006/1547 train_time:48032ms step_avg:47.75ms
step:1007/1547 train_time:48119ms step_avg:47.78ms
step:1008/1547 train_time:48202ms step_avg:47.82ms
step:1009/1547 train_time:48290ms step_avg:47.86ms
step:1010/1547 train_time:48374ms step_avg:47.89ms
step:1011/1547 train_time:48461ms step_avg:47.93ms
step:1012/1547 train_time:48547ms step_avg:47.97ms
step:1013/1547 train_time:48636ms step_avg:48.01ms
step:1014/1547 train_time:48723ms step_avg:48.05ms
step:1015/1547 train_time:48815ms step_avg:48.09ms
step:1016/1547 train_time:48900ms step_avg:48.13ms
step:1017/1547 train_time:48990ms step_avg:48.17ms
step:1018/1547 train_time:49075ms step_avg:48.21ms
step:1019/1547 train_time:49163ms step_avg:48.25ms
step:1020/1547 train_time:49248ms step_avg:48.28ms
step:1021/1547 train_time:49337ms step_avg:48.32ms
step:1022/1547 train_time:49423ms step_avg:48.36ms
step:1023/1547 train_time:49511ms step_avg:48.40ms
step:1024/1547 train_time:49597ms step_avg:48.43ms
step:1025/1547 train_time:49686ms step_avg:48.47ms
step:1026/1547 train_time:49773ms step_avg:48.51ms
step:1027/1547 train_time:49864ms step_avg:48.55ms
step:1028/1547 train_time:49949ms step_avg:48.59ms
step:1029/1547 train_time:50038ms step_avg:48.63ms
step:1030/1547 train_time:50123ms step_avg:48.66ms
step:1031/1547 train_time:50212ms step_avg:48.70ms
step:1032/1547 train_time:50296ms step_avg:48.74ms
step:1033/1547 train_time:50384ms step_avg:48.77ms
step:1034/1547 train_time:50469ms step_avg:48.81ms
step:1035/1547 train_time:50558ms step_avg:48.85ms
step:1036/1547 train_time:50642ms step_avg:48.88ms
step:1037/1547 train_time:50732ms step_avg:48.92ms
step:1038/1547 train_time:50818ms step_avg:48.96ms
step:1039/1547 train_time:50908ms step_avg:49.00ms
step:1040/1547 train_time:50993ms step_avg:49.03ms
step:1041/1547 train_time:51083ms step_avg:49.07ms
step:1042/1547 train_time:51168ms step_avg:49.11ms
step:1043/1547 train_time:51257ms step_avg:49.14ms
step:1044/1547 train_time:51342ms step_avg:49.18ms
step:1045/1547 train_time:51431ms step_avg:49.22ms
step:1046/1547 train_time:51516ms step_avg:49.25ms
step:1047/1547 train_time:51604ms step_avg:49.29ms
step:1048/1547 train_time:51689ms step_avg:49.32ms
step:1049/1547 train_time:51780ms step_avg:49.36ms
step:1050/1547 train_time:51865ms step_avg:49.40ms
step:1051/1547 train_time:51955ms step_avg:49.43ms
step:1052/1547 train_time:52040ms step_avg:49.47ms
step:1053/1547 train_time:52128ms step_avg:49.50ms
step:1054/1547 train_time:52213ms step_avg:49.54ms
step:1055/1547 train_time:52303ms step_avg:49.58ms
step:1056/1547 train_time:52388ms step_avg:49.61ms
step:1057/1547 train_time:52479ms step_avg:49.65ms
step:1058/1547 train_time:52564ms step_avg:49.68ms
step:1059/1547 train_time:52653ms step_avg:49.72ms
step:1060/1547 train_time:52739ms step_avg:49.75ms
step:1061/1547 train_time:52829ms step_avg:49.79ms
step:1062/1547 train_time:52914ms step_avg:49.82ms
step:1063/1547 train_time:53002ms step_avg:49.86ms
step:1064/1547 train_time:53087ms step_avg:49.89ms
step:1065/1547 train_time:53176ms step_avg:49.93ms
step:1066/1547 train_time:53262ms step_avg:49.96ms
step:1067/1547 train_time:53353ms step_avg:50.00ms
step:1068/1547 train_time:53438ms step_avg:50.04ms
step:1069/1547 train_time:53525ms step_avg:50.07ms
step:1070/1547 train_time:53611ms step_avg:50.10ms
step:1071/1547 train_time:53699ms step_avg:50.14ms
step:1072/1547 train_time:53785ms step_avg:50.17ms
step:1073/1547 train_time:53874ms step_avg:50.21ms
step:1074/1547 train_time:53960ms step_avg:50.24ms
step:1075/1547 train_time:54049ms step_avg:50.28ms
step:1076/1547 train_time:54134ms step_avg:50.31ms
step:1077/1547 train_time:54223ms step_avg:50.35ms
step:1078/1547 train_time:54308ms step_avg:50.38ms
step:1079/1547 train_time:54398ms step_avg:50.42ms
step:1080/1547 train_time:54481ms step_avg:50.45ms
step:1081/1547 train_time:54571ms step_avg:50.48ms
step:1082/1547 train_time:54656ms step_avg:50.51ms
step:1083/1547 train_time:54745ms step_avg:50.55ms
step:1084/1547 train_time:54832ms step_avg:50.58ms
step:1085/1547 train_time:54922ms step_avg:50.62ms
step:1086/1547 train_time:55007ms step_avg:50.65ms
step:1087/1547 train_time:55101ms step_avg:50.69ms
step:1088/1547 train_time:55183ms step_avg:50.72ms
step:1089/1547 train_time:55271ms step_avg:50.75ms
step:1090/1547 train_time:55356ms step_avg:50.78ms
step:1091/1547 train_time:55444ms step_avg:50.82ms
step:1092/1547 train_time:55529ms step_avg:50.85ms
step:1093/1547 train_time:55618ms step_avg:50.89ms
step:1094/1547 train_time:55703ms step_avg:50.92ms
step:1095/1547 train_time:55792ms step_avg:50.95ms
step:1096/1547 train_time:55877ms step_avg:50.98ms
step:1097/1547 train_time:55966ms step_avg:51.02ms
step:1098/1547 train_time:56051ms step_avg:51.05ms
step:1099/1547 train_time:56141ms step_avg:51.08ms
step:1100/1547 train_time:56225ms step_avg:51.11ms
step:1101/1547 train_time:56314ms step_avg:51.15ms
step:1102/1547 train_time:56399ms step_avg:51.18ms
step:1103/1547 train_time:56488ms step_avg:51.21ms
step:1104/1547 train_time:56573ms step_avg:51.24ms
step:1105/1547 train_time:56662ms step_avg:51.28ms
step:1106/1547 train_time:56749ms step_avg:51.31ms
step:1107/1547 train_time:56838ms step_avg:51.34ms
step:1108/1547 train_time:56924ms step_avg:51.38ms
step:1109/1547 train_time:57013ms step_avg:51.41ms
step:1110/1547 train_time:57098ms step_avg:51.44ms
step:1111/1547 train_time:57187ms step_avg:51.47ms
step:1112/1547 train_time:57272ms step_avg:51.50ms
step:1113/1547 train_time:57362ms step_avg:51.54ms
step:1114/1547 train_time:57447ms step_avg:51.57ms
step:1115/1547 train_time:57536ms step_avg:51.60ms
step:1116/1547 train_time:57621ms step_avg:51.63ms
step:1117/1547 train_time:57711ms step_avg:51.67ms
step:1118/1547 train_time:57796ms step_avg:51.70ms
step:1119/1547 train_time:57885ms step_avg:51.73ms
step:1120/1547 train_time:57971ms step_avg:51.76ms
step:1121/1547 train_time:58060ms step_avg:51.79ms
step:1122/1547 train_time:58144ms step_avg:51.82ms
step:1123/1547 train_time:58233ms step_avg:51.86ms
step:1124/1547 train_time:58318ms step_avg:51.88ms
step:1125/1547 train_time:58406ms step_avg:51.92ms
step:1126/1547 train_time:58492ms step_avg:51.95ms
step:1127/1547 train_time:58583ms step_avg:51.98ms
step:1128/1547 train_time:58668ms step_avg:52.01ms
step:1129/1547 train_time:58758ms step_avg:52.04ms
step:1130/1547 train_time:58843ms step_avg:52.07ms
step:1131/1547 train_time:58932ms step_avg:52.11ms
step:1132/1547 train_time:59016ms step_avg:52.13ms
step:1133/1547 train_time:59106ms step_avg:52.17ms
step:1134/1547 train_time:59190ms step_avg:52.20ms
step:1135/1547 train_time:59279ms step_avg:52.23ms
step:1136/1547 train_time:59366ms step_avg:52.26ms
step:1137/1547 train_time:59455ms step_avg:52.29ms
step:1138/1547 train_time:59540ms step_avg:52.32ms
step:1139/1547 train_time:59628ms step_avg:52.35ms
step:1140/1547 train_time:59713ms step_avg:52.38ms
step:1141/1547 train_time:59803ms step_avg:52.41ms
step:1142/1547 train_time:59888ms step_avg:52.44ms
step:1143/1547 train_time:59979ms step_avg:52.48ms
step:1144/1547 train_time:60064ms step_avg:52.50ms
step:1145/1547 train_time:60152ms step_avg:52.53ms
step:1146/1547 train_time:60239ms step_avg:52.56ms
step:1147/1547 train_time:60327ms step_avg:52.60ms
step:1148/1547 train_time:60413ms step_avg:52.62ms
step:1149/1547 train_time:60501ms step_avg:52.66ms
step:1150/1547 train_time:60587ms step_avg:52.68ms
step:1151/1547 train_time:60676ms step_avg:52.72ms
step:1152/1547 train_time:60761ms step_avg:52.74ms
step:1153/1547 train_time:60850ms step_avg:52.78ms
step:1154/1547 train_time:60935ms step_avg:52.80ms
step:1155/1547 train_time:61027ms step_avg:52.84ms
step:1156/1547 train_time:61111ms step_avg:52.86ms
step:1157/1547 train_time:61201ms step_avg:52.90ms
step:1158/1547 train_time:61285ms step_avg:52.92ms
step:1159/1547 train_time:61375ms step_avg:52.95ms
step:1160/1547 train_time:61459ms step_avg:52.98ms
step:1161/1547 train_time:61547ms step_avg:53.01ms
step:1162/1547 train_time:61633ms step_avg:53.04ms
step:1163/1547 train_time:61722ms step_avg:53.07ms
step:1164/1547 train_time:61807ms step_avg:53.10ms
step:1165/1547 train_time:61895ms step_avg:53.13ms
step:1166/1547 train_time:61980ms step_avg:53.16ms
step:1167/1547 train_time:62069ms step_avg:53.19ms
step:1168/1547 train_time:62154ms step_avg:53.21ms
step:1169/1547 train_time:62246ms step_avg:53.25ms
step:1170/1547 train_time:62332ms step_avg:53.28ms
step:1171/1547 train_time:62421ms step_avg:53.31ms
step:1172/1547 train_time:62505ms step_avg:53.33ms
step:1173/1547 train_time:62594ms step_avg:53.36ms
step:1174/1547 train_time:62678ms step_avg:53.39ms
step:1175/1547 train_time:62767ms step_avg:53.42ms
step:1176/1547 train_time:62852ms step_avg:53.45ms
step:1177/1547 train_time:62941ms step_avg:53.48ms
step:1178/1547 train_time:63026ms step_avg:53.50ms
step:1179/1547 train_time:63117ms step_avg:53.53ms
step:1180/1547 train_time:63202ms step_avg:53.56ms
step:1181/1547 train_time:63291ms step_avg:53.59ms
step:1182/1547 train_time:63377ms step_avg:53.62ms
step:1183/1547 train_time:63466ms step_avg:53.65ms
step:1184/1547 train_time:63552ms step_avg:53.68ms
step:1185/1547 train_time:63640ms step_avg:53.70ms
step:1186/1547 train_time:63725ms step_avg:53.73ms
step:1187/1547 train_time:63815ms step_avg:53.76ms
step:1188/1547 train_time:63900ms step_avg:53.79ms
step:1189/1547 train_time:63988ms step_avg:53.82ms
step:1190/1547 train_time:64073ms step_avg:53.84ms
step:1191/1547 train_time:64166ms step_avg:53.88ms
step:1192/1547 train_time:64251ms step_avg:53.90ms
step:1193/1547 train_time:64341ms step_avg:53.93ms
step:1194/1547 train_time:64426ms step_avg:53.96ms
step:1195/1547 train_time:64515ms step_avg:53.99ms
step:1196/1547 train_time:64600ms step_avg:54.01ms
step:1197/1547 train_time:64688ms step_avg:54.04ms
step:1198/1547 train_time:64773ms step_avg:54.07ms
step:1199/1547 train_time:64862ms step_avg:54.10ms
step:1200/1547 train_time:64946ms step_avg:54.12ms
step:1201/1547 train_time:65035ms step_avg:54.15ms
step:1202/1547 train_time:65122ms step_avg:54.18ms
step:1203/1547 train_time:65212ms step_avg:54.21ms
step:1204/1547 train_time:65297ms step_avg:54.23ms
step:1205/1547 train_time:65385ms step_avg:54.26ms
step:1206/1547 train_time:65471ms step_avg:54.29ms
step:1207/1547 train_time:65559ms step_avg:54.32ms
step:1208/1547 train_time:65643ms step_avg:54.34ms
step:1209/1547 train_time:65733ms step_avg:54.37ms
step:1210/1547 train_time:65818ms step_avg:54.40ms
step:1211/1547 train_time:65908ms step_avg:54.42ms
step:1212/1547 train_time:65994ms step_avg:54.45ms
step:1213/1547 train_time:66084ms step_avg:54.48ms
step:1214/1547 train_time:66169ms step_avg:54.51ms
step:1215/1547 train_time:66259ms step_avg:54.53ms
step:1216/1547 train_time:66344ms step_avg:54.56ms
step:1217/1547 train_time:66432ms step_avg:54.59ms
step:1218/1547 train_time:66518ms step_avg:54.61ms
step:1219/1547 train_time:66606ms step_avg:54.64ms
step:1220/1547 train_time:66692ms step_avg:54.67ms
step:1221/1547 train_time:66781ms step_avg:54.69ms
step:1222/1547 train_time:66866ms step_avg:54.72ms
step:1223/1547 train_time:66957ms step_avg:54.75ms
step:1224/1547 train_time:67041ms step_avg:54.77ms
step:1225/1547 train_time:67131ms step_avg:54.80ms
step:1226/1547 train_time:67215ms step_avg:54.82ms
step:1227/1547 train_time:67306ms step_avg:54.85ms
step:1228/1547 train_time:67391ms step_avg:54.88ms
step:1229/1547 train_time:67480ms step_avg:54.91ms
step:1230/1547 train_time:67564ms step_avg:54.93ms
step:1231/1547 train_time:67654ms step_avg:54.96ms
step:1232/1547 train_time:67740ms step_avg:54.98ms
step:1233/1547 train_time:67829ms step_avg:55.01ms
step:1234/1547 train_time:67914ms step_avg:55.04ms
step:1235/1547 train_time:68005ms step_avg:55.06ms
step:1236/1547 train_time:68088ms step_avg:55.09ms
step:1237/1547 train_time:68176ms step_avg:55.11ms
step:1238/1547 train_time:68261ms step_avg:55.14ms
step:1239/1547 train_time:68350ms step_avg:55.17ms
step:1240/1547 train_time:68436ms step_avg:55.19ms
step:1241/1547 train_time:68527ms step_avg:55.22ms
step:1242/1547 train_time:68612ms step_avg:55.24ms
step:1243/1547 train_time:68701ms step_avg:55.27ms
step:1244/1547 train_time:68786ms step_avg:55.29ms
step:1245/1547 train_time:68875ms step_avg:55.32ms
step:1246/1547 train_time:68961ms step_avg:55.35ms
step:1247/1547 train_time:69049ms step_avg:55.37ms
step:1248/1547 train_time:69134ms step_avg:55.40ms
step:1249/1547 train_time:69223ms step_avg:55.42ms
step:1250/1547 train_time:69308ms step_avg:55.45ms
step:1250/1547 val_loss:3.3955 train_time:69381ms step_avg:55.50ms
step:1251/1547 train_time:69401ms step_avg:55.48ms
step:1252/1547 train_time:69487ms step_avg:55.50ms
step:1253/1547 train_time:69583ms step_avg:55.53ms
step:1254/1547 train_time:69670ms step_avg:55.56ms
step:1255/1547 train_time:69759ms step_avg:55.58ms
step:1256/1547 train_time:69844ms step_avg:55.61ms
step:1257/1547 train_time:69932ms step_avg:55.63ms
step:1258/1547 train_time:70016ms step_avg:55.66ms
step:1259/1547 train_time:70104ms step_avg:55.68ms
step:1260/1547 train_time:70188ms step_avg:55.70ms
step:1261/1547 train_time:70276ms step_avg:55.73ms
step:1262/1547 train_time:70361ms step_avg:55.75ms
step:1263/1547 train_time:70452ms step_avg:55.78ms
step:1264/1547 train_time:70540ms step_avg:55.81ms
step:1265/1547 train_time:70630ms step_avg:55.83ms
step:1266/1547 train_time:70715ms step_avg:55.86ms
step:1267/1547 train_time:70804ms step_avg:55.88ms
step:1268/1547 train_time:70890ms step_avg:55.91ms
step:1269/1547 train_time:70978ms step_avg:55.93ms
step:1270/1547 train_time:71064ms step_avg:55.96ms
step:1271/1547 train_time:71152ms step_avg:55.98ms
step:1272/1547 train_time:71236ms step_avg:56.00ms
step:1273/1547 train_time:71325ms step_avg:56.03ms
step:1274/1547 train_time:71410ms step_avg:56.05ms
step:1275/1547 train_time:71501ms step_avg:56.08ms
step:1276/1547 train_time:71586ms step_avg:56.10ms
step:1277/1547 train_time:71676ms step_avg:56.13ms
step:1278/1547 train_time:71761ms step_avg:56.15ms
step:1279/1547 train_time:71850ms step_avg:56.18ms
step:1280/1547 train_time:71935ms step_avg:56.20ms
step:1281/1547 train_time:72025ms step_avg:56.23ms
step:1282/1547 train_time:72111ms step_avg:56.25ms
step:1283/1547 train_time:72201ms step_avg:56.28ms
step:1284/1547 train_time:72284ms step_avg:56.30ms
step:1285/1547 train_time:72373ms step_avg:56.32ms
step:1286/1547 train_time:72460ms step_avg:56.34ms
step:1287/1547 train_time:72549ms step_avg:56.37ms
step:1288/1547 train_time:72635ms step_avg:56.39ms
step:1289/1547 train_time:72725ms step_avg:56.42ms
step:1290/1547 train_time:72810ms step_avg:56.44ms
step:1291/1547 train_time:72900ms step_avg:56.47ms
step:1292/1547 train_time:72985ms step_avg:56.49ms
step:1293/1547 train_time:73074ms step_avg:56.51ms
step:1294/1547 train_time:73158ms step_avg:56.54ms
step:1295/1547 train_time:73248ms step_avg:56.56ms
step:1296/1547 train_time:73333ms step_avg:56.58ms
step:1297/1547 train_time:73421ms step_avg:56.61ms
step:1298/1547 train_time:73507ms step_avg:56.63ms
step:1299/1547 train_time:73596ms step_avg:56.66ms
step:1300/1547 train_time:73682ms step_avg:56.68ms
step:1301/1547 train_time:73771ms step_avg:56.70ms
step:1302/1547 train_time:73856ms step_avg:56.73ms
step:1303/1547 train_time:73945ms step_avg:56.75ms
step:1304/1547 train_time:74031ms step_avg:56.77ms
step:1305/1547 train_time:74120ms step_avg:56.80ms
step:1306/1547 train_time:74205ms step_avg:56.82ms
step:1307/1547 train_time:74294ms step_avg:56.84ms
step:1308/1547 train_time:74379ms step_avg:56.86ms
step:1309/1547 train_time:74468ms step_avg:56.89ms
step:1310/1547 train_time:74553ms step_avg:56.91ms
step:1311/1547 train_time:74641ms step_avg:56.93ms
step:1312/1547 train_time:74726ms step_avg:56.96ms
step:1313/1547 train_time:74816ms step_avg:56.98ms
step:1314/1547 train_time:74901ms step_avg:57.00ms
step:1315/1547 train_time:74992ms step_avg:57.03ms
step:1316/1547 train_time:75077ms step_avg:57.05ms
step:1317/1547 train_time:75166ms step_avg:57.07ms
step:1318/1547 train_time:75250ms step_avg:57.09ms
step:1319/1547 train_time:75338ms step_avg:57.12ms
step:1320/1547 train_time:75423ms step_avg:57.14ms
step:1321/1547 train_time:75512ms step_avg:57.16ms
step:1322/1547 train_time:75597ms step_avg:57.18ms
step:1323/1547 train_time:75687ms step_avg:57.21ms
step:1324/1547 train_time:75772ms step_avg:57.23ms
step:1325/1547 train_time:75862ms step_avg:57.25ms
step:1326/1547 train_time:75946ms step_avg:57.27ms
step:1327/1547 train_time:76035ms step_avg:57.30ms
step:1328/1547 train_time:76120ms step_avg:57.32ms
step:1329/1547 train_time:76209ms step_avg:57.34ms
step:1330/1547 train_time:76293ms step_avg:57.36ms
step:1331/1547 train_time:76383ms step_avg:57.39ms
step:1332/1547 train_time:76468ms step_avg:57.41ms
step:1333/1547 train_time:76557ms step_avg:57.43ms
step:1334/1547 train_time:76643ms step_avg:57.45ms
step:1335/1547 train_time:76734ms step_avg:57.48ms
step:1336/1547 train_time:76819ms step_avg:57.50ms
step:1337/1547 train_time:76910ms step_avg:57.52ms
step:1338/1547 train_time:76994ms step_avg:57.54ms
step:1339/1547 train_time:77083ms step_avg:57.57ms
step:1340/1547 train_time:77167ms step_avg:57.59ms
step:1341/1547 train_time:77257ms step_avg:57.61ms
step:1342/1547 train_time:77341ms step_avg:57.63ms
step:1343/1547 train_time:77430ms step_avg:57.65ms
step:1344/1547 train_time:77515ms step_avg:57.67ms
step:1345/1547 train_time:77606ms step_avg:57.70ms
step:1346/1547 train_time:77692ms step_avg:57.72ms
step:1347/1547 train_time:77782ms step_avg:57.74ms
step:1348/1547 train_time:77868ms step_avg:57.77ms
step:1349/1547 train_time:77958ms step_avg:57.79ms
step:1350/1547 train_time:78043ms step_avg:57.81ms
step:1351/1547 train_time:78131ms step_avg:57.83ms
step:1352/1547 train_time:78215ms step_avg:57.85ms
step:1353/1547 train_time:78303ms step_avg:57.87ms
step:1354/1547 train_time:78389ms step_avg:57.89ms
step:1355/1547 train_time:78478ms step_avg:57.92ms
step:1356/1547 train_time:78565ms step_avg:57.94ms
step:1357/1547 train_time:78655ms step_avg:57.96ms
step:1358/1547 train_time:78740ms step_avg:57.98ms
step:1359/1547 train_time:78827ms step_avg:58.00ms
step:1360/1547 train_time:78913ms step_avg:58.02ms
step:1361/1547 train_time:79002ms step_avg:58.05ms
step:1362/1547 train_time:79087ms step_avg:58.07ms
step:1363/1547 train_time:79178ms step_avg:58.09ms
step:1364/1547 train_time:79263ms step_avg:58.11ms
step:1365/1547 train_time:79351ms step_avg:58.13ms
step:1366/1547 train_time:79436ms step_avg:58.15ms
step:1367/1547 train_time:79526ms step_avg:58.18ms
step:1368/1547 train_time:79611ms step_avg:58.20ms
step:1369/1547 train_time:79701ms step_avg:58.22ms
step:1370/1547 train_time:79788ms step_avg:58.24ms
step:1371/1547 train_time:79878ms step_avg:58.26ms
step:1372/1547 train_time:79963ms step_avg:58.28ms
step:1373/1547 train_time:80052ms step_avg:58.30ms
step:1374/1547 train_time:80138ms step_avg:58.32ms
step:1375/1547 train_time:80225ms step_avg:58.35ms
step:1376/1547 train_time:80310ms step_avg:58.36ms
step:1377/1547 train_time:80399ms step_avg:58.39ms
step:1378/1547 train_time:80484ms step_avg:58.41ms
step:1379/1547 train_time:80573ms step_avg:58.43ms
step:1380/1547 train_time:80662ms step_avg:58.45ms
step:1381/1547 train_time:80751ms step_avg:58.47ms
step:1382/1547 train_time:80837ms step_avg:58.49ms
step:1383/1547 train_time:80927ms step_avg:58.52ms
step:1384/1547 train_time:81012ms step_avg:58.53ms
step:1385/1547 train_time:81099ms step_avg:58.56ms
step:1386/1547 train_time:81184ms step_avg:58.57ms
step:1387/1547 train_time:81274ms step_avg:58.60ms
step:1388/1547 train_time:81358ms step_avg:58.62ms
step:1389/1547 train_time:81448ms step_avg:58.64ms
step:1390/1547 train_time:81534ms step_avg:58.66ms
step:1391/1547 train_time:81626ms step_avg:58.68ms
step:1392/1547 train_time:81710ms step_avg:58.70ms
step:1393/1547 train_time:81799ms step_avg:58.72ms
step:1394/1547 train_time:81883ms step_avg:58.74ms
step:1395/1547 train_time:81971ms step_avg:58.76ms
step:1396/1547 train_time:82057ms step_avg:58.78ms
step:1397/1547 train_time:82146ms step_avg:58.80ms
step:1398/1547 train_time:82231ms step_avg:58.82ms
step:1399/1547 train_time:82320ms step_avg:58.84ms
step:1400/1547 train_time:82404ms step_avg:58.86ms
step:1401/1547 train_time:82493ms step_avg:58.88ms
step:1402/1547 train_time:82578ms step_avg:58.90ms
step:1403/1547 train_time:82668ms step_avg:58.92ms
step:1404/1547 train_time:82753ms step_avg:58.94ms
step:1405/1547 train_time:82843ms step_avg:58.96ms
step:1406/1547 train_time:82929ms step_avg:58.98ms
step:1407/1547 train_time:83019ms step_avg:59.00ms
step:1408/1547 train_time:83104ms step_avg:59.02ms
step:1409/1547 train_time:83193ms step_avg:59.04ms
step:1410/1547 train_time:83279ms step_avg:59.06ms
step:1411/1547 train_time:83368ms step_avg:59.08ms
step:1412/1547 train_time:83451ms step_avg:59.10ms
step:1413/1547 train_time:83541ms step_avg:59.12ms
step:1414/1547 train_time:83626ms step_avg:59.14ms
step:1415/1547 train_time:83716ms step_avg:59.16ms
step:1416/1547 train_time:83800ms step_avg:59.18ms
step:1417/1547 train_time:83890ms step_avg:59.20ms
step:1418/1547 train_time:83976ms step_avg:59.22ms
step:1419/1547 train_time:84066ms step_avg:59.24ms
step:1420/1547 train_time:84152ms step_avg:59.26ms
step:1421/1547 train_time:84241ms step_avg:59.28ms
step:1422/1547 train_time:84325ms step_avg:59.30ms
step:1423/1547 train_time:84412ms step_avg:59.32ms
step:1424/1547 train_time:84497ms step_avg:59.34ms
step:1425/1547 train_time:84586ms step_avg:59.36ms
step:1426/1547 train_time:84671ms step_avg:59.38ms
step:1427/1547 train_time:84760ms step_avg:59.40ms
step:1428/1547 train_time:84845ms step_avg:59.42ms
step:1429/1547 train_time:84934ms step_avg:59.44ms
step:1430/1547 train_time:85019ms step_avg:59.45ms
step:1431/1547 train_time:85108ms step_avg:59.47ms
step:1432/1547 train_time:85193ms step_avg:59.49ms
step:1433/1547 train_time:85283ms step_avg:59.51ms
step:1434/1547 train_time:85367ms step_avg:59.53ms
step:1435/1547 train_time:85457ms step_avg:59.55ms
step:1436/1547 train_time:85541ms step_avg:59.57ms
step:1437/1547 train_time:85630ms step_avg:59.59ms
step:1438/1547 train_time:85715ms step_avg:59.61ms
step:1439/1547 train_time:85804ms step_avg:59.63ms
step:1440/1547 train_time:85889ms step_avg:59.65ms
step:1441/1547 train_time:85979ms step_avg:59.67ms
step:1442/1547 train_time:86064ms step_avg:59.68ms
step:1443/1547 train_time:86153ms step_avg:59.70ms
step:1444/1547 train_time:86239ms step_avg:59.72ms
step:1445/1547 train_time:86329ms step_avg:59.74ms
step:1446/1547 train_time:86413ms step_avg:59.76ms
step:1447/1547 train_time:86503ms step_avg:59.78ms
step:1448/1547 train_time:86587ms step_avg:59.80ms
step:1449/1547 train_time:86676ms step_avg:59.82ms
step:1450/1547 train_time:86761ms step_avg:59.84ms
step:1451/1547 train_time:86852ms step_avg:59.86ms
step:1452/1547 train_time:86938ms step_avg:59.87ms
step:1453/1547 train_time:87027ms step_avg:59.89ms
step:1454/1547 train_time:87113ms step_avg:59.91ms
step:1455/1547 train_time:87201ms step_avg:59.93ms
step:1456/1547 train_time:87287ms step_avg:59.95ms
step:1457/1547 train_time:87376ms step_avg:59.97ms
step:1458/1547 train_time:87460ms step_avg:59.99ms
step:1459/1547 train_time:87549ms step_avg:60.01ms
step:1460/1547 train_time:87633ms step_avg:60.02ms
step:1461/1547 train_time:87723ms step_avg:60.04ms
step:1462/1547 train_time:87809ms step_avg:60.06ms
step:1463/1547 train_time:87898ms step_avg:60.08ms
step:1464/1547 train_time:87982ms step_avg:60.10ms
step:1465/1547 train_time:88071ms step_avg:60.12ms
step:1466/1547 train_time:88157ms step_avg:60.13ms
step:1467/1547 train_time:88246ms step_avg:60.15ms
step:1468/1547 train_time:88331ms step_avg:60.17ms
step:1469/1547 train_time:88421ms step_avg:60.19ms
step:1470/1547 train_time:88506ms step_avg:60.21ms
step:1471/1547 train_time:88596ms step_avg:60.23ms
step:1472/1547 train_time:88680ms step_avg:60.24ms
step:1473/1547 train_time:88769ms step_avg:60.26ms
step:1474/1547 train_time:88853ms step_avg:60.28ms
step:1475/1547 train_time:88943ms step_avg:60.30ms
step:1476/1547 train_time:89028ms step_avg:60.32ms
step:1477/1547 train_time:89118ms step_avg:60.34ms
step:1478/1547 train_time:89202ms step_avg:60.35ms
step:1479/1547 train_time:89292ms step_avg:60.37ms
step:1480/1547 train_time:89377ms step_avg:60.39ms
step:1481/1547 train_time:89466ms step_avg:60.41ms
step:1482/1547 train_time:89551ms step_avg:60.43ms
step:1483/1547 train_time:89640ms step_avg:60.45ms
step:1484/1547 train_time:89725ms step_avg:60.46ms
step:1485/1547 train_time:89814ms step_avg:60.48ms
step:1486/1547 train_time:89899ms step_avg:60.50ms
step:1487/1547 train_time:89987ms step_avg:60.52ms
step:1488/1547 train_time:90073ms step_avg:60.53ms
step:1489/1547 train_time:90162ms step_avg:60.55ms
step:1490/1547 train_time:90248ms step_avg:60.57ms
step:1491/1547 train_time:90337ms step_avg:60.59ms
step:1492/1547 train_time:90422ms step_avg:60.60ms
step:1493/1547 train_time:90511ms step_avg:60.62ms
step:1494/1547 train_time:90596ms step_avg:60.64ms
step:1495/1547 train_time:90686ms step_avg:60.66ms
step:1496/1547 train_time:90771ms step_avg:60.68ms
step:1497/1547 train_time:90860ms step_avg:60.69ms
step:1498/1547 train_time:90946ms step_avg:60.71ms
step:1499/1547 train_time:91034ms step_avg:60.73ms
step:1500/1547 train_time:91119ms step_avg:60.75ms
step:1500/1547 val_loss:3.2927 train_time:91193ms step_avg:60.80ms
step:1501/1547 train_time:91212ms step_avg:60.77ms
step:1502/1547 train_time:91299ms step_avg:60.78ms
step:1503/1547 train_time:91394ms step_avg:60.81ms
step:1504/1547 train_time:91482ms step_avg:60.83ms
step:1505/1547 train_time:91571ms step_avg:60.84ms
step:1506/1547 train_time:91655ms step_avg:60.86ms
step:1507/1547 train_time:91743ms step_avg:60.88ms
step:1508/1547 train_time:91835ms step_avg:60.90ms
step:1509/1547 train_time:91921ms step_avg:60.91ms
step:1510/1547 train_time:92004ms step_avg:60.93ms
step:1511/1547 train_time:92092ms step_avg:60.95ms
step:1512/1547 train_time:92178ms step_avg:60.96ms
step:1513/1547 train_time:92268ms step_avg:60.98ms
step:1514/1547 train_time:92357ms step_avg:61.00ms
step:1515/1547 train_time:92449ms step_avg:61.02ms
step:1516/1547 train_time:92535ms step_avg:61.04ms
step:1517/1547 train_time:92628ms step_avg:61.06ms
step:1518/1547 train_time:92713ms step_avg:61.08ms
step:1519/1547 train_time:92802ms step_avg:61.09ms
step:1520/1547 train_time:92886ms step_avg:61.11ms
step:1521/1547 train_time:92974ms step_avg:61.13ms
step:1522/1547 train_time:93057ms step_avg:61.14ms
step:1523/1547 train_time:93146ms step_avg:61.16ms
step:1524/1547 train_time:93232ms step_avg:61.18ms
step:1525/1547 train_time:93324ms step_avg:61.20ms
step:1526/1547 train_time:93411ms step_avg:61.21ms
step:1527/1547 train_time:93503ms step_avg:61.23ms
step:1528/1547 train_time:93589ms step_avg:61.25ms
step:1529/1547 train_time:93680ms step_avg:61.27ms
step:1530/1547 train_time:93765ms step_avg:61.28ms
step:1531/1547 train_time:93854ms step_avg:61.30ms
step:1532/1547 train_time:93939ms step_avg:61.32ms
step:1533/1547 train_time:94028ms step_avg:61.34ms
step:1534/1547 train_time:94113ms step_avg:61.35ms
step:1535/1547 train_time:94202ms step_avg:61.37ms
step:1536/1547 train_time:94287ms step_avg:61.39ms
step:1537/1547 train_time:94378ms step_avg:61.40ms
step:1538/1547 train_time:94464ms step_avg:61.42ms
step:1539/1547 train_time:94553ms step_avg:61.44ms
step:1540/1547 train_time:94640ms step_avg:61.45ms
step:1541/1547 train_time:94730ms step_avg:61.47ms
step:1542/1547 train_time:94815ms step_avg:61.49ms
step:1543/1547 train_time:94904ms step_avg:61.51ms
step:1544/1547 train_time:94989ms step_avg:61.52ms
step:1545/1547 train_time:95078ms step_avg:61.54ms
step:1546/1547 train_time:95162ms step_avg:61.55ms
step:1547/1547 train_time:95251ms step_avg:61.57ms
step:1547/1547 val_loss:3.2783 train_time:95319ms step_avg:61.62ms
peak memory allocated: 31507 MiB reserved: 46582 MiB
