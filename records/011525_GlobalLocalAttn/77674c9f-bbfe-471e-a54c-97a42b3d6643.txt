import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask: torch.Tensor):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            # indices = (~dense_mask).argsort(dim=-1, descending=False, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_masks(sliding_window_num_blocks: int):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            short_sliding_window_num_blocks = sliding_window_num_blocks // 2
            return (
                BlockMask.from_kv_blocks(
                    kv_num_blocks,
                    kv_indices,
                    full_kv_num_blocks,
                    full_kv_indices,
                    BLOCK_SIZE=BLOCK_SIZE,
                    mask_mod=document_causal,
                ),
                BlockMask.from_kv_blocks(
                    torch.clamp_max(kv_num_blocks, torch.clamp_min(short_sliding_window_num_blocks - full_kv_num_blocks, 1)),
                    kv_indices,
                    torch.clamp_max(full_kv_num_blocks, short_sliding_window_num_blocks - 1),
                    full_kv_indices,
                    BLOCK_SIZE=BLOCK_SIZE,
                    mask_mod=document_causal,
                ),
            )

        # Long-short SWA block masks by @leloykun & @YouJiacheng
        long_swa_block_mask, short_swa_block_mask = create_doc_swc_block_masks(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        is_long_block_mask = [True, False, False, False, True, False]
        for i in range(self.num_encoder_layers):
            block_mask = long_swa_block_mask if is_long_block_mask[i] else short_swa_block_mask
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        is_long_block_mask = list(reversed(is_long_block_mask))
        for i in range(self.num_decoder_layers):
            block_mask = long_swa_block_mask if is_long_block_mask[i] else short_swa_block_mask
            x = x + self.skip_weights[i] * skip_connections.pop()
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1405 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250110+cu126 compiled for CUDA 12.6
Wed Jan 15 19:22:42 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   31C    P0             116W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   27C    P0             111W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   26C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   30C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   30C    P0             115W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   27C    P0             112W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   29C    P0             112W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   26C    P0             111W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1405 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1405 train_time:28159ms step_avg:nanms
step:2/1405 train_time:28254ms step_avg:nanms
step:3/1405 train_time:28445ms step_avg:nanms
step:4/1405 train_time:28576ms step_avg:nanms
step:5/1405 train_time:28709ms step_avg:nanms
step:6/1405 train_time:28841ms step_avg:nanms
step:7/1405 train_time:28973ms step_avg:nanms
step:8/1405 train_time:29105ms step_avg:nanms
step:9/1405 train_time:29237ms step_avg:nanms
step:10/1405 train_time:29374ms step_avg:nanms
step:11/1405 train_time:136ms step_avg:nanms
step:12/1405 train_time:271ms step_avg:nanms
step:13/1405 train_time:403ms step_avg:134.38ms
step:14/1405 train_time:536ms step_avg:134.03ms
step:15/1405 train_time:668ms step_avg:133.62ms
step:16/1405 train_time:801ms step_avg:133.48ms
step:17/1405 train_time:935ms step_avg:133.53ms
step:18/1405 train_time:1071ms step_avg:133.87ms
step:19/1405 train_time:1205ms step_avg:133.84ms
step:20/1405 train_time:1340ms step_avg:133.97ms
step:21/1405 train_time:1473ms step_avg:133.95ms
step:22/1405 train_time:1608ms step_avg:133.97ms
step:23/1405 train_time:1740ms step_avg:133.86ms
step:24/1405 train_time:1874ms step_avg:133.86ms
step:25/1405 train_time:2009ms step_avg:133.93ms
step:26/1405 train_time:2143ms step_avg:133.91ms
step:27/1405 train_time:2276ms step_avg:133.89ms
step:28/1405 train_time:2410ms step_avg:133.91ms
step:29/1405 train_time:2545ms step_avg:133.94ms
step:30/1405 train_time:2680ms step_avg:134.02ms
step:31/1405 train_time:2814ms step_avg:133.99ms
step:32/1405 train_time:2948ms step_avg:133.98ms
step:33/1405 train_time:3081ms step_avg:133.96ms
step:34/1405 train_time:3215ms step_avg:133.95ms
step:35/1405 train_time:3348ms step_avg:133.92ms
step:36/1405 train_time:3481ms step_avg:133.89ms
step:37/1405 train_time:3615ms step_avg:133.89ms
step:38/1405 train_time:3749ms step_avg:133.88ms
step:39/1405 train_time:3882ms step_avg:133.88ms
step:40/1405 train_time:4017ms step_avg:133.90ms
step:41/1405 train_time:4151ms step_avg:133.90ms
step:42/1405 train_time:4284ms step_avg:133.88ms
step:43/1405 train_time:4419ms step_avg:133.90ms
step:44/1405 train_time:4553ms step_avg:133.90ms
step:45/1405 train_time:4687ms step_avg:133.91ms
step:46/1405 train_time:4822ms step_avg:133.94ms
step:47/1405 train_time:4956ms step_avg:133.95ms
step:48/1405 train_time:5091ms step_avg:133.98ms
step:49/1405 train_time:5224ms step_avg:133.95ms
step:50/1405 train_time:5359ms step_avg:133.97ms
step:51/1405 train_time:5492ms step_avg:133.96ms
step:52/1405 train_time:5627ms step_avg:133.97ms
step:53/1405 train_time:5760ms step_avg:133.95ms
step:54/1405 train_time:5894ms step_avg:133.95ms
step:55/1405 train_time:6027ms step_avg:133.94ms
step:56/1405 train_time:6161ms step_avg:133.93ms
step:57/1405 train_time:6295ms step_avg:133.94ms
step:58/1405 train_time:6430ms step_avg:133.95ms
step:59/1405 train_time:6563ms step_avg:133.93ms
step:60/1405 train_time:6697ms step_avg:133.94ms
step:61/1405 train_time:6833ms step_avg:133.98ms
step:62/1405 train_time:6969ms step_avg:134.02ms
step:63/1405 train_time:7102ms step_avg:133.99ms
step:64/1405 train_time:7235ms step_avg:133.97ms
step:65/1405 train_time:7370ms step_avg:134.00ms
step:66/1405 train_time:7504ms step_avg:133.99ms
step:67/1405 train_time:7638ms step_avg:134.00ms
step:68/1405 train_time:7772ms step_avg:134.00ms
step:69/1405 train_time:7905ms step_avg:133.99ms
step:70/1405 train_time:8039ms step_avg:133.99ms
step:71/1405 train_time:8174ms step_avg:134.00ms
step:72/1405 train_time:8308ms step_avg:133.99ms
step:73/1405 train_time:8441ms step_avg:133.98ms
step:74/1405 train_time:8575ms step_avg:133.98ms
step:75/1405 train_time:8709ms step_avg:133.99ms
step:76/1405 train_time:8842ms step_avg:133.97ms
step:77/1405 train_time:8975ms step_avg:133.96ms
step:78/1405 train_time:9109ms step_avg:133.96ms
step:79/1405 train_time:9243ms step_avg:133.95ms
step:80/1405 train_time:9376ms step_avg:133.94ms
step:81/1405 train_time:9509ms step_avg:133.93ms
step:82/1405 train_time:9642ms step_avg:133.92ms
step:83/1405 train_time:9777ms step_avg:133.93ms
step:84/1405 train_time:9911ms step_avg:133.94ms
step:85/1405 train_time:10045ms step_avg:133.93ms
step:86/1405 train_time:10177ms step_avg:133.91ms
step:87/1405 train_time:10312ms step_avg:133.92ms
step:88/1405 train_time:10446ms step_avg:133.92ms
step:89/1405 train_time:10580ms step_avg:133.93ms
step:90/1405 train_time:10714ms step_avg:133.93ms
step:91/1405 train_time:10847ms step_avg:133.92ms
step:92/1405 train_time:10981ms step_avg:133.91ms
step:93/1405 train_time:11115ms step_avg:133.91ms
step:94/1405 train_time:11248ms step_avg:133.90ms
step:95/1405 train_time:11382ms step_avg:133.90ms
step:96/1405 train_time:11516ms step_avg:133.90ms
step:97/1405 train_time:11652ms step_avg:133.93ms
step:98/1405 train_time:11786ms step_avg:133.93ms
step:99/1405 train_time:11921ms step_avg:133.94ms
step:100/1405 train_time:12054ms step_avg:133.94ms
step:101/1405 train_time:12188ms step_avg:133.94ms
step:102/1405 train_time:12322ms step_avg:133.93ms
step:103/1405 train_time:12456ms step_avg:133.94ms
step:104/1405 train_time:12591ms step_avg:133.95ms
step:105/1405 train_time:12725ms step_avg:133.95ms
step:106/1405 train_time:12860ms step_avg:133.96ms
step:107/1405 train_time:12994ms step_avg:133.96ms
step:108/1405 train_time:13130ms step_avg:133.98ms
step:109/1405 train_time:13264ms step_avg:133.98ms
step:110/1405 train_time:13398ms step_avg:133.98ms
step:111/1405 train_time:13533ms step_avg:133.99ms
step:112/1405 train_time:13669ms step_avg:134.01ms
step:113/1405 train_time:13804ms step_avg:134.02ms
step:114/1405 train_time:13938ms step_avg:134.02ms
step:115/1405 train_time:14074ms step_avg:134.04ms
step:116/1405 train_time:14209ms step_avg:134.05ms
step:117/1405 train_time:14344ms step_avg:134.05ms
step:118/1405 train_time:14478ms step_avg:134.06ms
step:119/1405 train_time:14613ms step_avg:134.07ms
step:120/1405 train_time:14748ms step_avg:134.08ms
step:121/1405 train_time:14882ms step_avg:134.08ms
step:122/1405 train_time:15017ms step_avg:134.08ms
step:123/1405 train_time:15153ms step_avg:134.10ms
step:124/1405 train_time:15288ms step_avg:134.11ms
step:125/1405 train_time:15424ms step_avg:134.12ms
step:125/1405 val_loss:4.4596 train_time:15488ms step_avg:134.68ms
step:126/1405 train_time:15564ms step_avg:134.17ms
step:127/1405 train_time:15702ms step_avg:134.20ms
step:128/1405 train_time:15837ms step_avg:134.22ms
step:129/1405 train_time:15971ms step_avg:134.21ms
step:130/1405 train_time:16104ms step_avg:134.20ms
step:131/1405 train_time:16239ms step_avg:134.20ms
step:132/1405 train_time:16372ms step_avg:134.20ms
step:133/1405 train_time:16508ms step_avg:134.22ms
step:134/1405 train_time:16645ms step_avg:134.23ms
step:135/1405 train_time:16781ms step_avg:134.25ms
step:136/1405 train_time:16917ms step_avg:134.26ms
step:137/1405 train_time:17052ms step_avg:134.27ms
step:138/1405 train_time:17188ms step_avg:134.28ms
step:139/1405 train_time:17322ms step_avg:134.28ms
step:140/1405 train_time:17457ms step_avg:134.29ms
step:141/1405 train_time:17594ms step_avg:134.31ms
step:142/1405 train_time:17731ms step_avg:134.32ms
step:143/1405 train_time:17867ms step_avg:134.34ms
step:144/1405 train_time:18003ms step_avg:134.35ms
step:145/1405 train_time:18138ms step_avg:134.36ms
step:146/1405 train_time:18274ms step_avg:134.37ms
step:147/1405 train_time:18409ms step_avg:134.37ms
step:148/1405 train_time:18545ms step_avg:134.38ms
step:149/1405 train_time:18682ms step_avg:134.40ms
step:150/1405 train_time:18819ms step_avg:134.42ms
step:151/1405 train_time:18955ms step_avg:134.43ms
step:152/1405 train_time:19090ms step_avg:134.43ms
step:153/1405 train_time:19225ms step_avg:134.44ms
step:154/1405 train_time:19360ms step_avg:134.45ms
step:155/1405 train_time:19495ms step_avg:134.45ms
step:156/1405 train_time:19630ms step_avg:134.45ms
step:157/1405 train_time:19766ms step_avg:134.46ms
step:158/1405 train_time:19901ms step_avg:134.47ms
step:159/1405 train_time:20037ms step_avg:134.48ms
step:160/1405 train_time:20172ms step_avg:134.48ms
step:161/1405 train_time:20306ms step_avg:134.48ms
step:162/1405 train_time:20442ms step_avg:134.49ms
step:163/1405 train_time:20579ms step_avg:134.50ms
step:164/1405 train_time:20714ms step_avg:134.51ms
step:165/1405 train_time:20850ms step_avg:134.52ms
step:166/1405 train_time:20985ms step_avg:134.52ms
step:167/1405 train_time:21121ms step_avg:134.53ms
step:168/1405 train_time:21256ms step_avg:134.53ms
step:169/1405 train_time:21391ms step_avg:134.54ms
step:170/1405 train_time:21526ms step_avg:134.54ms
step:171/1405 train_time:21662ms step_avg:134.55ms
step:172/1405 train_time:21798ms step_avg:134.55ms
step:173/1405 train_time:21934ms step_avg:134.56ms
step:174/1405 train_time:22071ms step_avg:134.58ms
step:175/1405 train_time:22205ms step_avg:134.58ms
step:176/1405 train_time:22341ms step_avg:134.58ms
step:177/1405 train_time:22476ms step_avg:134.58ms
step:178/1405 train_time:22611ms step_avg:134.59ms
step:179/1405 train_time:22747ms step_avg:134.60ms
step:180/1405 train_time:22882ms step_avg:134.60ms
step:181/1405 train_time:23018ms step_avg:134.61ms
step:182/1405 train_time:23155ms step_avg:134.62ms
step:183/1405 train_time:23291ms step_avg:134.63ms
step:184/1405 train_time:23425ms step_avg:134.63ms
step:185/1405 train_time:23560ms step_avg:134.63ms
step:186/1405 train_time:23696ms step_avg:134.64ms
step:187/1405 train_time:23831ms step_avg:134.64ms
step:188/1405 train_time:23966ms step_avg:134.64ms
step:189/1405 train_time:24102ms step_avg:134.65ms
step:190/1405 train_time:24238ms step_avg:134.66ms
step:191/1405 train_time:24414ms step_avg:134.89ms
step:192/1405 train_time:24549ms step_avg:134.88ms
step:193/1405 train_time:24684ms step_avg:134.88ms
step:194/1405 train_time:24819ms step_avg:134.88ms
step:195/1405 train_time:24953ms step_avg:134.88ms
step:196/1405 train_time:25088ms step_avg:134.88ms
step:197/1405 train_time:25223ms step_avg:134.88ms
step:198/1405 train_time:25364ms step_avg:134.91ms
step:199/1405 train_time:25501ms step_avg:134.93ms
step:200/1405 train_time:25637ms step_avg:134.93ms
step:201/1405 train_time:25771ms step_avg:134.93ms
step:202/1405 train_time:25907ms step_avg:134.93ms
step:203/1405 train_time:26043ms step_avg:134.94ms
step:204/1405 train_time:26179ms step_avg:134.94ms
step:205/1405 train_time:26315ms step_avg:134.95ms
step:206/1405 train_time:26453ms step_avg:134.97ms
step:207/1405 train_time:26591ms step_avg:134.98ms
step:208/1405 train_time:26726ms step_avg:134.98ms
step:209/1405 train_time:26862ms step_avg:134.99ms
step:210/1405 train_time:26998ms step_avg:134.99ms
step:211/1405 train_time:27133ms step_avg:134.99ms
step:212/1405 train_time:27270ms step_avg:135.00ms
step:213/1405 train_time:27406ms step_avg:135.01ms
step:214/1405 train_time:27544ms step_avg:135.02ms
step:215/1405 train_time:27682ms step_avg:135.03ms
step:216/1405 train_time:27817ms step_avg:135.03ms
step:217/1405 train_time:27954ms step_avg:135.04ms
step:218/1405 train_time:28091ms step_avg:135.05ms
step:219/1405 train_time:28227ms step_avg:135.06ms
step:220/1405 train_time:28363ms step_avg:135.06ms
step:221/1405 train_time:28500ms step_avg:135.07ms
step:222/1405 train_time:28637ms step_avg:135.08ms
step:223/1405 train_time:28774ms step_avg:135.09ms
step:224/1405 train_time:28911ms step_avg:135.10ms
step:225/1405 train_time:29048ms step_avg:135.11ms
step:226/1405 train_time:29184ms step_avg:135.11ms
step:227/1405 train_time:29321ms step_avg:135.12ms
step:228/1405 train_time:29456ms step_avg:135.12ms
step:229/1405 train_time:29593ms step_avg:135.13ms
step:230/1405 train_time:29730ms step_avg:135.14ms
step:231/1405 train_time:29868ms step_avg:135.15ms
step:232/1405 train_time:30005ms step_avg:135.16ms
step:233/1405 train_time:30142ms step_avg:135.17ms
step:234/1405 train_time:30278ms step_avg:135.17ms
step:235/1405 train_time:30414ms step_avg:135.17ms
step:236/1405 train_time:30550ms step_avg:135.18ms
step:237/1405 train_time:30687ms step_avg:135.19ms
step:238/1405 train_time:30825ms step_avg:135.20ms
step:239/1405 train_time:30961ms step_avg:135.20ms
step:240/1405 train_time:31099ms step_avg:135.21ms
step:241/1405 train_time:31235ms step_avg:135.22ms
step:242/1405 train_time:31372ms step_avg:135.22ms
step:243/1405 train_time:31509ms step_avg:135.23ms
step:244/1405 train_time:31646ms step_avg:135.24ms
step:245/1405 train_time:31783ms step_avg:135.25ms
step:246/1405 train_time:31922ms step_avg:135.26ms
step:247/1405 train_time:32060ms step_avg:135.27ms
step:248/1405 train_time:32196ms step_avg:135.28ms
step:249/1405 train_time:32333ms step_avg:135.28ms
step:250/1405 train_time:32469ms step_avg:135.29ms
step:250/1405 val_loss:3.9861 train_time:32534ms step_avg:135.56ms
step:251/1405 train_time:32611ms step_avg:135.31ms
step:252/1405 train_time:32750ms step_avg:135.33ms
step:253/1405 train_time:32886ms step_avg:135.33ms
step:254/1405 train_time:33022ms step_avg:135.34ms
step:255/1405 train_time:33157ms step_avg:135.34ms
step:256/1405 train_time:33294ms step_avg:135.34ms
step:257/1405 train_time:33430ms step_avg:135.34ms
step:258/1405 train_time:33567ms step_avg:135.35ms
step:259/1405 train_time:33706ms step_avg:135.37ms
step:260/1405 train_time:33843ms step_avg:135.37ms
step:261/1405 train_time:33980ms step_avg:135.38ms
step:262/1405 train_time:34115ms step_avg:135.38ms
step:263/1405 train_time:34251ms step_avg:135.38ms
step:264/1405 train_time:34387ms step_avg:135.38ms
step:265/1405 train_time:34525ms step_avg:135.39ms
step:266/1405 train_time:34663ms step_avg:135.40ms
step:267/1405 train_time:34800ms step_avg:135.41ms
step:268/1405 train_time:34936ms step_avg:135.41ms
step:269/1405 train_time:35073ms step_avg:135.42ms
step:270/1405 train_time:35211ms step_avg:135.43ms
step:271/1405 train_time:35347ms step_avg:135.43ms
step:272/1405 train_time:35484ms step_avg:135.43ms
step:273/1405 train_time:35620ms step_avg:135.44ms
step:274/1405 train_time:35757ms step_avg:135.44ms
step:275/1405 train_time:35895ms step_avg:135.45ms
step:276/1405 train_time:36034ms step_avg:135.46ms
step:277/1405 train_time:36171ms step_avg:135.47ms
step:278/1405 train_time:36309ms step_avg:135.48ms
step:279/1405 train_time:36446ms step_avg:135.49ms
step:280/1405 train_time:36583ms step_avg:135.49ms
step:281/1405 train_time:36718ms step_avg:135.49ms
step:282/1405 train_time:36854ms step_avg:135.49ms
step:283/1405 train_time:36992ms step_avg:135.50ms
step:284/1405 train_time:37129ms step_avg:135.51ms
step:285/1405 train_time:37267ms step_avg:135.52ms
step:286/1405 train_time:37405ms step_avg:135.53ms
step:287/1405 train_time:37542ms step_avg:135.53ms
step:288/1405 train_time:37678ms step_avg:135.53ms
step:289/1405 train_time:37814ms step_avg:135.53ms
step:290/1405 train_time:37950ms step_avg:135.54ms
step:291/1405 train_time:38088ms step_avg:135.54ms
step:292/1405 train_time:38225ms step_avg:135.55ms
step:293/1405 train_time:38362ms step_avg:135.55ms
step:294/1405 train_time:38498ms step_avg:135.56ms
step:295/1405 train_time:38634ms step_avg:135.56ms
step:296/1405 train_time:38771ms step_avg:135.56ms
step:297/1405 train_time:38908ms step_avg:135.57ms
step:298/1405 train_time:39046ms step_avg:135.57ms
step:299/1405 train_time:39182ms step_avg:135.58ms
step:300/1405 train_time:39319ms step_avg:135.58ms
step:301/1405 train_time:39456ms step_avg:135.59ms
step:302/1405 train_time:39592ms step_avg:135.59ms
step:303/1405 train_time:39729ms step_avg:135.59ms
step:304/1405 train_time:39866ms step_avg:135.60ms
step:305/1405 train_time:40003ms step_avg:135.60ms
step:306/1405 train_time:40140ms step_avg:135.61ms
step:307/1405 train_time:40276ms step_avg:135.61ms
step:308/1405 train_time:40413ms step_avg:135.62ms
step:309/1405 train_time:40550ms step_avg:135.62ms
step:310/1405 train_time:40687ms step_avg:135.62ms
step:311/1405 train_time:40824ms step_avg:135.63ms
step:312/1405 train_time:40961ms step_avg:135.63ms
step:313/1405 train_time:41099ms step_avg:135.64ms
step:314/1405 train_time:41236ms step_avg:135.65ms
step:315/1405 train_time:41377ms step_avg:135.66ms
step:316/1405 train_time:41516ms step_avg:135.67ms
step:317/1405 train_time:41656ms step_avg:135.69ms
step:318/1405 train_time:41795ms step_avg:135.70ms
step:319/1405 train_time:41935ms step_avg:135.71ms
step:320/1405 train_time:42074ms step_avg:135.72ms
step:321/1405 train_time:42214ms step_avg:135.74ms
step:322/1405 train_time:42354ms step_avg:135.75ms
step:323/1405 train_time:42494ms step_avg:135.76ms
step:324/1405 train_time:42634ms step_avg:135.78ms
step:325/1405 train_time:42773ms step_avg:135.79ms
step:326/1405 train_time:42912ms step_avg:135.80ms
step:327/1405 train_time:43051ms step_avg:135.81ms
step:328/1405 train_time:43190ms step_avg:135.82ms
step:329/1405 train_time:43330ms step_avg:135.83ms
step:330/1405 train_time:43470ms step_avg:135.84ms
step:331/1405 train_time:43609ms step_avg:135.85ms
step:332/1405 train_time:43748ms step_avg:135.86ms
step:333/1405 train_time:43888ms step_avg:135.88ms
step:334/1405 train_time:44027ms step_avg:135.88ms
step:335/1405 train_time:44166ms step_avg:135.90ms
step:336/1405 train_time:44306ms step_avg:135.91ms
step:337/1405 train_time:44446ms step_avg:135.92ms
step:338/1405 train_time:44586ms step_avg:135.93ms
step:339/1405 train_time:44725ms step_avg:135.94ms
step:340/1405 train_time:44866ms step_avg:135.96ms
step:341/1405 train_time:45006ms step_avg:135.97ms
step:342/1405 train_time:45146ms step_avg:135.98ms
step:343/1405 train_time:45285ms step_avg:135.99ms
step:344/1405 train_time:45426ms step_avg:136.01ms
step:345/1405 train_time:45565ms step_avg:136.02ms
step:346/1405 train_time:45706ms step_avg:136.03ms
step:347/1405 train_time:45845ms step_avg:136.04ms
step:348/1405 train_time:45985ms step_avg:136.05ms
step:349/1405 train_time:46125ms step_avg:136.06ms
step:350/1405 train_time:46265ms step_avg:136.07ms
step:351/1405 train_time:46404ms step_avg:136.08ms
step:352/1405 train_time:46543ms step_avg:136.09ms
step:353/1405 train_time:46684ms step_avg:136.11ms
step:354/1405 train_time:46825ms step_avg:136.12ms
step:355/1405 train_time:46964ms step_avg:136.13ms
step:356/1405 train_time:47104ms step_avg:136.14ms
step:357/1405 train_time:47243ms step_avg:136.15ms
step:358/1405 train_time:47383ms step_avg:136.16ms
step:359/1405 train_time:47522ms step_avg:136.17ms
step:360/1405 train_time:47661ms step_avg:136.18ms
step:361/1405 train_time:47800ms step_avg:136.18ms
step:362/1405 train_time:47938ms step_avg:136.19ms
step:363/1405 train_time:48078ms step_avg:136.20ms
step:364/1405 train_time:48217ms step_avg:136.21ms
step:365/1405 train_time:48356ms step_avg:136.21ms
step:366/1405 train_time:48495ms step_avg:136.22ms
step:367/1405 train_time:48636ms step_avg:136.23ms
step:368/1405 train_time:48776ms step_avg:136.25ms
step:369/1405 train_time:48916ms step_avg:136.26ms
step:370/1405 train_time:49055ms step_avg:136.26ms
step:371/1405 train_time:49194ms step_avg:136.27ms
step:372/1405 train_time:49334ms step_avg:136.28ms
step:373/1405 train_time:49473ms step_avg:136.29ms
step:374/1405 train_time:49613ms step_avg:136.30ms
step:375/1405 train_time:49752ms step_avg:136.31ms
step:375/1405 val_loss:3.7842 train_time:49819ms step_avg:136.49ms
step:376/1405 train_time:49895ms step_avg:136.32ms
step:377/1405 train_time:50036ms step_avg:136.34ms
step:378/1405 train_time:50175ms step_avg:136.35ms
step:379/1405 train_time:50313ms step_avg:136.35ms
step:380/1405 train_time:50452ms step_avg:136.36ms
step:381/1405 train_time:50630ms step_avg:136.47ms
step:382/1405 train_time:50769ms step_avg:136.48ms
step:383/1405 train_time:50908ms step_avg:136.48ms
step:384/1405 train_time:51046ms step_avg:136.49ms
step:385/1405 train_time:51183ms step_avg:136.49ms
step:386/1405 train_time:51322ms step_avg:136.49ms
step:387/1405 train_time:51461ms step_avg:136.50ms
step:388/1405 train_time:51604ms step_avg:136.52ms
step:389/1405 train_time:51745ms step_avg:136.53ms
step:390/1405 train_time:51884ms step_avg:136.54ms
step:391/1405 train_time:52023ms step_avg:136.54ms
step:392/1405 train_time:52162ms step_avg:136.55ms
step:393/1405 train_time:52302ms step_avg:136.56ms
step:394/1405 train_time:52441ms step_avg:136.56ms
step:395/1405 train_time:52582ms step_avg:136.58ms
step:396/1405 train_time:52724ms step_avg:136.59ms
step:397/1405 train_time:52863ms step_avg:136.60ms
step:398/1405 train_time:53001ms step_avg:136.60ms
step:399/1405 train_time:53140ms step_avg:136.61ms
step:400/1405 train_time:53279ms step_avg:136.61ms
step:401/1405 train_time:53417ms step_avg:136.62ms
step:402/1405 train_time:53557ms step_avg:136.63ms
step:403/1405 train_time:53697ms step_avg:136.63ms
step:404/1405 train_time:53836ms step_avg:136.64ms
step:405/1405 train_time:53975ms step_avg:136.65ms
step:406/1405 train_time:54114ms step_avg:136.65ms
step:407/1405 train_time:54253ms step_avg:136.66ms
step:408/1405 train_time:54392ms step_avg:136.66ms
step:409/1405 train_time:54531ms step_avg:136.67ms
step:410/1405 train_time:54671ms step_avg:136.68ms
step:411/1405 train_time:54810ms step_avg:136.68ms
step:412/1405 train_time:54951ms step_avg:136.69ms
step:413/1405 train_time:55090ms step_avg:136.70ms
step:414/1405 train_time:55230ms step_avg:136.71ms
step:415/1405 train_time:55369ms step_avg:136.71ms
step:416/1405 train_time:55508ms step_avg:136.72ms
step:417/1405 train_time:55648ms step_avg:136.73ms
step:418/1405 train_time:55786ms step_avg:136.73ms
step:419/1405 train_time:55926ms step_avg:136.74ms
step:420/1405 train_time:56066ms step_avg:136.75ms
step:421/1405 train_time:56206ms step_avg:136.75ms
step:422/1405 train_time:56345ms step_avg:136.76ms
step:423/1405 train_time:56484ms step_avg:136.77ms
step:424/1405 train_time:56624ms step_avg:136.77ms
step:425/1405 train_time:56765ms step_avg:136.78ms
step:426/1405 train_time:56905ms step_avg:136.79ms
step:427/1405 train_time:57045ms step_avg:136.80ms
step:428/1405 train_time:57184ms step_avg:136.81ms
step:429/1405 train_time:57325ms step_avg:136.81ms
step:430/1405 train_time:57466ms step_avg:136.82ms
step:431/1405 train_time:57606ms step_avg:136.83ms
step:432/1405 train_time:57745ms step_avg:136.84ms
step:433/1405 train_time:57885ms step_avg:136.84ms
step:434/1405 train_time:58025ms step_avg:136.85ms
step:435/1405 train_time:58165ms step_avg:136.86ms
step:436/1405 train_time:58306ms step_avg:136.87ms
step:437/1405 train_time:58446ms step_avg:136.88ms
step:438/1405 train_time:58585ms step_avg:136.88ms
step:439/1405 train_time:58726ms step_avg:136.89ms
step:440/1405 train_time:58865ms step_avg:136.90ms
step:441/1405 train_time:59006ms step_avg:136.90ms
step:442/1405 train_time:59146ms step_avg:136.91ms
step:443/1405 train_time:59286ms step_avg:136.92ms
step:444/1405 train_time:59425ms step_avg:136.92ms
step:445/1405 train_time:59565ms step_avg:136.93ms
step:446/1405 train_time:59706ms step_avg:136.94ms
step:447/1405 train_time:59845ms step_avg:136.95ms
step:448/1405 train_time:59986ms step_avg:136.96ms
step:449/1405 train_time:60125ms step_avg:136.96ms
step:450/1405 train_time:60265ms step_avg:136.97ms
step:451/1405 train_time:60406ms step_avg:136.98ms
step:452/1405 train_time:60546ms step_avg:136.98ms
step:453/1405 train_time:60685ms step_avg:136.99ms
step:454/1405 train_time:60826ms step_avg:137.00ms
step:455/1405 train_time:60966ms step_avg:137.00ms
step:456/1405 train_time:61107ms step_avg:137.01ms
step:457/1405 train_time:61246ms step_avg:137.02ms
step:458/1405 train_time:61385ms step_avg:137.02ms
step:459/1405 train_time:61525ms step_avg:137.03ms
step:460/1405 train_time:61665ms step_avg:137.03ms
step:461/1405 train_time:61805ms step_avg:137.04ms
step:462/1405 train_time:61946ms step_avg:137.05ms
step:463/1405 train_time:62086ms step_avg:137.05ms
step:464/1405 train_time:62226ms step_avg:137.06ms
step:465/1405 train_time:62367ms step_avg:137.07ms
step:466/1405 train_time:62507ms step_avg:137.08ms
step:467/1405 train_time:62646ms step_avg:137.08ms
step:468/1405 train_time:62786ms step_avg:137.09ms
step:469/1405 train_time:62926ms step_avg:137.09ms
step:470/1405 train_time:63066ms step_avg:137.10ms
step:471/1405 train_time:63206ms step_avg:137.11ms
step:472/1405 train_time:63346ms step_avg:137.11ms
step:473/1405 train_time:63485ms step_avg:137.12ms
step:474/1405 train_time:63625ms step_avg:137.12ms
step:475/1405 train_time:63765ms step_avg:137.13ms
step:476/1405 train_time:63906ms step_avg:137.14ms
step:477/1405 train_time:64045ms step_avg:137.14ms
step:478/1405 train_time:64186ms step_avg:137.15ms
step:479/1405 train_time:64326ms step_avg:137.16ms
step:480/1405 train_time:64465ms step_avg:137.16ms
step:481/1405 train_time:64606ms step_avg:137.17ms
step:482/1405 train_time:64746ms step_avg:137.17ms
step:483/1405 train_time:64887ms step_avg:137.18ms
step:484/1405 train_time:65028ms step_avg:137.19ms
step:485/1405 train_time:65169ms step_avg:137.20ms
step:486/1405 train_time:65310ms step_avg:137.20ms
step:487/1405 train_time:65449ms step_avg:137.21ms
step:488/1405 train_time:65590ms step_avg:137.22ms
step:489/1405 train_time:65732ms step_avg:137.23ms
step:490/1405 train_time:65872ms step_avg:137.23ms
step:491/1405 train_time:66012ms step_avg:137.24ms
step:492/1405 train_time:66152ms step_avg:137.24ms
step:493/1405 train_time:66291ms step_avg:137.25ms
step:494/1405 train_time:66432ms step_avg:137.26ms
step:495/1405 train_time:66572ms step_avg:137.26ms
step:496/1405 train_time:66712ms step_avg:137.27ms
step:497/1405 train_time:66853ms step_avg:137.27ms
step:498/1405 train_time:66993ms step_avg:137.28ms
step:499/1405 train_time:67133ms step_avg:137.29ms
step:500/1405 train_time:67272ms step_avg:137.29ms
step:500/1405 val_loss:3.6642 train_time:67338ms step_avg:137.42ms
step:501/1405 train_time:67414ms step_avg:137.30ms
step:502/1405 train_time:67554ms step_avg:137.30ms
step:503/1405 train_time:67694ms step_avg:137.31ms
step:504/1405 train_time:67833ms step_avg:137.31ms
step:505/1405 train_time:67972ms step_avg:137.32ms
step:506/1405 train_time:68111ms step_avg:137.32ms
step:507/1405 train_time:68250ms step_avg:137.32ms
step:508/1405 train_time:68393ms step_avg:137.34ms
step:509/1405 train_time:68534ms step_avg:137.34ms
step:510/1405 train_time:68674ms step_avg:137.35ms
step:511/1405 train_time:68815ms step_avg:137.35ms
step:512/1405 train_time:68954ms step_avg:137.36ms
step:513/1405 train_time:69095ms step_avg:137.37ms
step:514/1405 train_time:69234ms step_avg:137.37ms
step:515/1405 train_time:69373ms step_avg:137.37ms
step:516/1405 train_time:69513ms step_avg:137.38ms
step:517/1405 train_time:69654ms step_avg:137.39ms
step:518/1405 train_time:69795ms step_avg:137.39ms
step:519/1405 train_time:69934ms step_avg:137.40ms
step:520/1405 train_time:70074ms step_avg:137.40ms
step:521/1405 train_time:70213ms step_avg:137.40ms
step:522/1405 train_time:70354ms step_avg:137.41ms
step:523/1405 train_time:70496ms step_avg:137.42ms
step:524/1405 train_time:70638ms step_avg:137.43ms
step:525/1405 train_time:70781ms step_avg:137.44ms
step:526/1405 train_time:70923ms step_avg:137.45ms
step:527/1405 train_time:71066ms step_avg:137.46ms
step:528/1405 train_time:71207ms step_avg:137.46ms
step:529/1405 train_time:71349ms step_avg:137.47ms
step:530/1405 train_time:71492ms step_avg:137.48ms
step:531/1405 train_time:71634ms step_avg:137.49ms
step:532/1405 train_time:71775ms step_avg:137.50ms
step:533/1405 train_time:71918ms step_avg:137.51ms
step:534/1405 train_time:72061ms step_avg:137.52ms
step:535/1405 train_time:72201ms step_avg:137.53ms
step:536/1405 train_time:72343ms step_avg:137.53ms
step:537/1405 train_time:72486ms step_avg:137.54ms
step:538/1405 train_time:72627ms step_avg:137.55ms
step:539/1405 train_time:72769ms step_avg:137.56ms
step:540/1405 train_time:72912ms step_avg:137.57ms
step:541/1405 train_time:73054ms step_avg:137.58ms
step:542/1405 train_time:73195ms step_avg:137.59ms
step:543/1405 train_time:73338ms step_avg:137.59ms
step:544/1405 train_time:73480ms step_avg:137.60ms
step:545/1405 train_time:73623ms step_avg:137.61ms
step:546/1405 train_time:73765ms step_avg:137.62ms
step:547/1405 train_time:73907ms step_avg:137.63ms
step:548/1405 train_time:74049ms step_avg:137.64ms
step:549/1405 train_time:74192ms step_avg:137.65ms
step:550/1405 train_time:74335ms step_avg:137.66ms
step:551/1405 train_time:74476ms step_avg:137.66ms
step:552/1405 train_time:74618ms step_avg:137.67ms
step:553/1405 train_time:74760ms step_avg:137.68ms
step:554/1405 train_time:74902ms step_avg:137.69ms
step:555/1405 train_time:75044ms step_avg:137.70ms
step:556/1405 train_time:75187ms step_avg:137.70ms
step:557/1405 train_time:75329ms step_avg:137.71ms
step:558/1405 train_time:75470ms step_avg:137.72ms
step:559/1405 train_time:75613ms step_avg:137.73ms
step:560/1405 train_time:75754ms step_avg:137.74ms
step:561/1405 train_time:75896ms step_avg:137.74ms
step:562/1405 train_time:76038ms step_avg:137.75ms
step:563/1405 train_time:76180ms step_avg:137.76ms
step:564/1405 train_time:76321ms step_avg:137.76ms
step:565/1405 train_time:76463ms step_avg:137.77ms
step:566/1405 train_time:76606ms step_avg:137.78ms
step:567/1405 train_time:76749ms step_avg:137.79ms
step:568/1405 train_time:76891ms step_avg:137.80ms
step:569/1405 train_time:77033ms step_avg:137.81ms
step:570/1405 train_time:77176ms step_avg:137.81ms
step:571/1405 train_time:77357ms step_avg:137.89ms
step:572/1405 train_time:77498ms step_avg:137.90ms
step:573/1405 train_time:77639ms step_avg:137.90ms
step:574/1405 train_time:77781ms step_avg:137.91ms
step:575/1405 train_time:77922ms step_avg:137.91ms
step:576/1405 train_time:78063ms step_avg:137.92ms
step:577/1405 train_time:78204ms step_avg:137.93ms
step:578/1405 train_time:78351ms step_avg:137.94ms
step:579/1405 train_time:78494ms step_avg:137.95ms
step:580/1405 train_time:78636ms step_avg:137.96ms
step:581/1405 train_time:78778ms step_avg:137.96ms
step:582/1405 train_time:78918ms step_avg:137.97ms
step:583/1405 train_time:79060ms step_avg:137.97ms
step:584/1405 train_time:79201ms step_avg:137.98ms
step:585/1405 train_time:79344ms step_avg:137.99ms
step:586/1405 train_time:79488ms step_avg:138.00ms
step:587/1405 train_time:79631ms step_avg:138.01ms
step:588/1405 train_time:79772ms step_avg:138.01ms
step:589/1405 train_time:79914ms step_avg:138.02ms
step:590/1405 train_time:80056ms step_avg:138.03ms
step:591/1405 train_time:80198ms step_avg:138.03ms
step:592/1405 train_time:80340ms step_avg:138.04ms
step:593/1405 train_time:80483ms step_avg:138.05ms
step:594/1405 train_time:80626ms step_avg:138.06ms
step:595/1405 train_time:80769ms step_avg:138.07ms
step:596/1405 train_time:80911ms step_avg:138.07ms
step:597/1405 train_time:81053ms step_avg:138.08ms
step:598/1405 train_time:81195ms step_avg:138.09ms
step:599/1405 train_time:81337ms step_avg:138.09ms
step:600/1405 train_time:81478ms step_avg:138.10ms
step:601/1405 train_time:81621ms step_avg:138.11ms
step:602/1405 train_time:81762ms step_avg:138.11ms
step:603/1405 train_time:81905ms step_avg:138.12ms
step:604/1405 train_time:82047ms step_avg:138.13ms
step:605/1405 train_time:82189ms step_avg:138.13ms
step:606/1405 train_time:82332ms step_avg:138.14ms
step:607/1405 train_time:82473ms step_avg:138.15ms
step:608/1405 train_time:82616ms step_avg:138.15ms
step:609/1405 train_time:82758ms step_avg:138.16ms
step:610/1405 train_time:82900ms step_avg:138.17ms
step:611/1405 train_time:83042ms step_avg:138.17ms
step:612/1405 train_time:83184ms step_avg:138.18ms
step:613/1405 train_time:83326ms step_avg:138.19ms
step:614/1405 train_time:83468ms step_avg:138.19ms
step:615/1405 train_time:83610ms step_avg:138.20ms
step:616/1405 train_time:83754ms step_avg:138.21ms
step:617/1405 train_time:83895ms step_avg:138.21ms
step:618/1405 train_time:84038ms step_avg:138.22ms
step:619/1405 train_time:84180ms step_avg:138.23ms
step:620/1405 train_time:84323ms step_avg:138.23ms
step:621/1405 train_time:84467ms step_avg:138.24ms
step:622/1405 train_time:84610ms step_avg:138.25ms
step:623/1405 train_time:84753ms step_avg:138.26ms
step:624/1405 train_time:84895ms step_avg:138.26ms
step:625/1405 train_time:85037ms step_avg:138.27ms
step:625/1405 val_loss:3.5810 train_time:85104ms step_avg:138.38ms
step:626/1405 train_time:85180ms step_avg:138.28ms
step:627/1405 train_time:85323ms step_avg:138.29ms
step:628/1405 train_time:85466ms step_avg:138.29ms
step:629/1405 train_time:85608ms step_avg:138.30ms
step:630/1405 train_time:85750ms step_avg:138.31ms
step:631/1405 train_time:85892ms step_avg:138.31ms
step:632/1405 train_time:86034ms step_avg:138.32ms
step:633/1405 train_time:86178ms step_avg:138.33ms
step:634/1405 train_time:86322ms step_avg:138.34ms
step:635/1405 train_time:86465ms step_avg:138.34ms
step:636/1405 train_time:86610ms step_avg:138.35ms
step:637/1405 train_time:86751ms step_avg:138.36ms
step:638/1405 train_time:86893ms step_avg:138.36ms
step:639/1405 train_time:87035ms step_avg:138.37ms
step:640/1405 train_time:87179ms step_avg:138.38ms
step:641/1405 train_time:87323ms step_avg:138.39ms
step:642/1405 train_time:87467ms step_avg:138.40ms
step:643/1405 train_time:87610ms step_avg:138.40ms
step:644/1405 train_time:87752ms step_avg:138.41ms
step:645/1405 train_time:87894ms step_avg:138.42ms
step:646/1405 train_time:88036ms step_avg:138.42ms
step:647/1405 train_time:88178ms step_avg:138.43ms
step:648/1405 train_time:88321ms step_avg:138.43ms
step:649/1405 train_time:88464ms step_avg:138.44ms
step:650/1405 train_time:88606ms step_avg:138.45ms
step:651/1405 train_time:88751ms step_avg:138.46ms
step:652/1405 train_time:88895ms step_avg:138.47ms
step:653/1405 train_time:89037ms step_avg:138.47ms
step:654/1405 train_time:89180ms step_avg:138.48ms
step:655/1405 train_time:89323ms step_avg:138.49ms
step:656/1405 train_time:89464ms step_avg:138.49ms
step:657/1405 train_time:89607ms step_avg:138.50ms
step:658/1405 train_time:89749ms step_avg:138.50ms
step:659/1405 train_time:89892ms step_avg:138.51ms
step:660/1405 train_time:90035ms step_avg:138.52ms
step:661/1405 train_time:90177ms step_avg:138.52ms
step:662/1405 train_time:90319ms step_avg:138.53ms
step:663/1405 train_time:90460ms step_avg:138.53ms
step:664/1405 train_time:90604ms step_avg:138.54ms
step:665/1405 train_time:90746ms step_avg:138.54ms
step:666/1405 train_time:90890ms step_avg:138.55ms
step:667/1405 train_time:91033ms step_avg:138.56ms
step:668/1405 train_time:91175ms step_avg:138.56ms
step:669/1405 train_time:91317ms step_avg:138.57ms
step:670/1405 train_time:91460ms step_avg:138.58ms
step:671/1405 train_time:91603ms step_avg:138.58ms
step:672/1405 train_time:91745ms step_avg:138.59ms
step:673/1405 train_time:91888ms step_avg:138.59ms
step:674/1405 train_time:92032ms step_avg:138.60ms
step:675/1405 train_time:92174ms step_avg:138.61ms
step:676/1405 train_time:92317ms step_avg:138.61ms
step:677/1405 train_time:92460ms step_avg:138.62ms
step:678/1405 train_time:92602ms step_avg:138.63ms
step:679/1405 train_time:92745ms step_avg:138.63ms
step:680/1405 train_time:92888ms step_avg:138.64ms
step:681/1405 train_time:93032ms step_avg:138.65ms
step:682/1405 train_time:93175ms step_avg:138.65ms
step:683/1405 train_time:93317ms step_avg:138.66ms
step:684/1405 train_time:93460ms step_avg:138.66ms
step:685/1405 train_time:93602ms step_avg:138.67ms
step:686/1405 train_time:93744ms step_avg:138.67ms
step:687/1405 train_time:93886ms step_avg:138.68ms
step:688/1405 train_time:94029ms step_avg:138.69ms
step:689/1405 train_time:94173ms step_avg:138.69ms
step:690/1405 train_time:94315ms step_avg:138.70ms
step:691/1405 train_time:94458ms step_avg:138.71ms
step:692/1405 train_time:94601ms step_avg:138.71ms
step:693/1405 train_time:94743ms step_avg:138.72ms
step:694/1405 train_time:94886ms step_avg:138.72ms
step:695/1405 train_time:95028ms step_avg:138.73ms
step:696/1405 train_time:95170ms step_avg:138.73ms
step:697/1405 train_time:95312ms step_avg:138.74ms
step:698/1405 train_time:95455ms step_avg:138.74ms
step:699/1405 train_time:95599ms step_avg:138.75ms
step:700/1405 train_time:95741ms step_avg:138.76ms
step:701/1405 train_time:95884ms step_avg:138.76ms
step:702/1405 train_time:96026ms step_avg:138.77ms
step:703/1405 train_time:96168ms step_avg:138.77ms
step:704/1405 train_time:96311ms step_avg:138.78ms
step:705/1405 train_time:96454ms step_avg:138.78ms
step:706/1405 train_time:96597ms step_avg:138.79ms
step:707/1405 train_time:96740ms step_avg:138.80ms
step:708/1405 train_time:96882ms step_avg:138.80ms
step:709/1405 train_time:97025ms step_avg:138.81ms
step:710/1405 train_time:97168ms step_avg:138.81ms
step:711/1405 train_time:97312ms step_avg:138.82ms
step:712/1405 train_time:97454ms step_avg:138.82ms
step:713/1405 train_time:97597ms step_avg:138.83ms
step:714/1405 train_time:97740ms step_avg:138.84ms
step:715/1405 train_time:97882ms step_avg:138.84ms
step:716/1405 train_time:98025ms step_avg:138.85ms
step:717/1405 train_time:98169ms step_avg:138.85ms
step:718/1405 train_time:98311ms step_avg:138.86ms
step:719/1405 train_time:98452ms step_avg:138.86ms
step:720/1405 train_time:98595ms step_avg:138.87ms
step:721/1405 train_time:98738ms step_avg:138.87ms
step:722/1405 train_time:98880ms step_avg:138.88ms
step:723/1405 train_time:99022ms step_avg:138.88ms
step:724/1405 train_time:99165ms step_avg:138.89ms
step:725/1405 train_time:99307ms step_avg:138.89ms
step:726/1405 train_time:99449ms step_avg:138.90ms
step:727/1405 train_time:99593ms step_avg:138.90ms
step:728/1405 train_time:99734ms step_avg:138.91ms
step:729/1405 train_time:99878ms step_avg:138.91ms
step:730/1405 train_time:100021ms step_avg:138.92ms
step:731/1405 train_time:100166ms step_avg:138.93ms
step:732/1405 train_time:100311ms step_avg:138.93ms
step:733/1405 train_time:100455ms step_avg:138.94ms
step:734/1405 train_time:100599ms step_avg:138.95ms
step:735/1405 train_time:100743ms step_avg:138.96ms
step:736/1405 train_time:100887ms step_avg:138.96ms
step:737/1405 train_time:101033ms step_avg:138.97ms
step:738/1405 train_time:101177ms step_avg:138.98ms
step:739/1405 train_time:101321ms step_avg:138.99ms
step:740/1405 train_time:101466ms step_avg:139.00ms
step:741/1405 train_time:101611ms step_avg:139.00ms
step:742/1405 train_time:101755ms step_avg:139.01ms
step:743/1405 train_time:101900ms step_avg:139.02ms
step:744/1405 train_time:102044ms step_avg:139.02ms
step:745/1405 train_time:102188ms step_avg:139.03ms
step:746/1405 train_time:102334ms step_avg:139.04ms
step:747/1405 train_time:102478ms step_avg:139.05ms
step:748/1405 train_time:102623ms step_avg:139.06ms
step:749/1405 train_time:102767ms step_avg:139.06ms
step:750/1405 train_time:102912ms step_avg:139.07ms
step:750/1405 val_loss:3.5265 train_time:102981ms step_avg:139.16ms
step:751/1405 train_time:103058ms step_avg:139.08ms
step:752/1405 train_time:103203ms step_avg:139.09ms
step:753/1405 train_time:103348ms step_avg:139.10ms
step:754/1405 train_time:103492ms step_avg:139.10ms
step:755/1405 train_time:103636ms step_avg:139.11ms
step:756/1405 train_time:103779ms step_avg:139.11ms
step:757/1405 train_time:103923ms step_avg:139.12ms
step:758/1405 train_time:104069ms step_avg:139.13ms
step:759/1405 train_time:104215ms step_avg:139.14ms
step:760/1405 train_time:104359ms step_avg:139.15ms
step:761/1405 train_time:104541ms step_avg:139.20ms
step:762/1405 train_time:104685ms step_avg:139.21ms
step:763/1405 train_time:104829ms step_avg:139.22ms
step:764/1405 train_time:104973ms step_avg:139.22ms
step:765/1405 train_time:105118ms step_avg:139.23ms
step:766/1405 train_time:105262ms step_avg:139.23ms
step:767/1405 train_time:105408ms step_avg:139.24ms
step:768/1405 train_time:105554ms step_avg:139.25ms
step:769/1405 train_time:105698ms step_avg:139.26ms
step:770/1405 train_time:105843ms step_avg:139.27ms
step:771/1405 train_time:105986ms step_avg:139.27ms
step:772/1405 train_time:106131ms step_avg:139.28ms
step:773/1405 train_time:106275ms step_avg:139.29ms
step:774/1405 train_time:106420ms step_avg:139.29ms
step:775/1405 train_time:106565ms step_avg:139.30ms
step:776/1405 train_time:106710ms step_avg:139.31ms
step:777/1405 train_time:106855ms step_avg:139.32ms
step:778/1405 train_time:106999ms step_avg:139.32ms
step:779/1405 train_time:107144ms step_avg:139.33ms
step:780/1405 train_time:107288ms step_avg:139.34ms
step:781/1405 train_time:107433ms step_avg:139.34ms
step:782/1405 train_time:107578ms step_avg:139.35ms
step:783/1405 train_time:107722ms step_avg:139.36ms
step:784/1405 train_time:107866ms step_avg:139.36ms
step:785/1405 train_time:108011ms step_avg:139.37ms
step:786/1405 train_time:108157ms step_avg:139.38ms
step:787/1405 train_time:108301ms step_avg:139.38ms
step:788/1405 train_time:108446ms step_avg:139.39ms
step:789/1405 train_time:108590ms step_avg:139.40ms
step:790/1405 train_time:108734ms step_avg:139.40ms
step:791/1405 train_time:108878ms step_avg:139.41ms
step:792/1405 train_time:109023ms step_avg:139.42ms
step:793/1405 train_time:109168ms step_avg:139.42ms
step:794/1405 train_time:109312ms step_avg:139.43ms
step:795/1405 train_time:109458ms step_avg:139.44ms
step:796/1405 train_time:109603ms step_avg:139.44ms
step:797/1405 train_time:109748ms step_avg:139.45ms
step:798/1405 train_time:109893ms step_avg:139.46ms
step:799/1405 train_time:110037ms step_avg:139.46ms
step:800/1405 train_time:110181ms step_avg:139.47ms
step:801/1405 train_time:110325ms step_avg:139.48ms
step:802/1405 train_time:110471ms step_avg:139.48ms
step:803/1405 train_time:110616ms step_avg:139.49ms
step:804/1405 train_time:110760ms step_avg:139.50ms
step:805/1405 train_time:110904ms step_avg:139.50ms
step:806/1405 train_time:111048ms step_avg:139.51ms
step:807/1405 train_time:111192ms step_avg:139.51ms
step:808/1405 train_time:111336ms step_avg:139.52ms
step:809/1405 train_time:111480ms step_avg:139.52ms
step:810/1405 train_time:111625ms step_avg:139.53ms
step:811/1405 train_time:111771ms step_avg:139.54ms
step:812/1405 train_time:111915ms step_avg:139.55ms
step:813/1405 train_time:112058ms step_avg:139.55ms
step:814/1405 train_time:112202ms step_avg:139.56ms
step:815/1405 train_time:112346ms step_avg:139.56ms
step:816/1405 train_time:112491ms step_avg:139.57ms
step:817/1405 train_time:112635ms step_avg:139.57ms
step:818/1405 train_time:112780ms step_avg:139.58ms
step:819/1405 train_time:112924ms step_avg:139.58ms
step:820/1405 train_time:113068ms step_avg:139.59ms
step:821/1405 train_time:113212ms step_avg:139.59ms
step:822/1405 train_time:113356ms step_avg:139.60ms
step:823/1405 train_time:113501ms step_avg:139.61ms
step:824/1405 train_time:113645ms step_avg:139.61ms
step:825/1405 train_time:113791ms step_avg:139.62ms
step:826/1405 train_time:113936ms step_avg:139.63ms
step:827/1405 train_time:114079ms step_avg:139.63ms
step:828/1405 train_time:114223ms step_avg:139.64ms
step:829/1405 train_time:114368ms step_avg:139.64ms
step:830/1405 train_time:114514ms step_avg:139.65ms
step:831/1405 train_time:114658ms step_avg:139.66ms
step:832/1405 train_time:114802ms step_avg:139.66ms
step:833/1405 train_time:114945ms step_avg:139.67ms
step:834/1405 train_time:115090ms step_avg:139.67ms
step:835/1405 train_time:115234ms step_avg:139.68ms
step:836/1405 train_time:115379ms step_avg:139.68ms
step:837/1405 train_time:115523ms step_avg:139.69ms
step:838/1405 train_time:115667ms step_avg:139.69ms
step:839/1405 train_time:115812ms step_avg:139.70ms
step:840/1405 train_time:115956ms step_avg:139.71ms
step:841/1405 train_time:116101ms step_avg:139.71ms
step:842/1405 train_time:116246ms step_avg:139.72ms
step:843/1405 train_time:116392ms step_avg:139.73ms
step:844/1405 train_time:116537ms step_avg:139.73ms
step:845/1405 train_time:116680ms step_avg:139.74ms
step:846/1405 train_time:116825ms step_avg:139.74ms
step:847/1405 train_time:116970ms step_avg:139.75ms
step:848/1405 train_time:117115ms step_avg:139.75ms
step:849/1405 train_time:117259ms step_avg:139.76ms
step:850/1405 train_time:117404ms step_avg:139.77ms
step:851/1405 train_time:117550ms step_avg:139.77ms
step:852/1405 train_time:117696ms step_avg:139.78ms
step:853/1405 train_time:117839ms step_avg:139.79ms
step:854/1405 train_time:117983ms step_avg:139.79ms
step:855/1405 train_time:118128ms step_avg:139.80ms
step:856/1405 train_time:118274ms step_avg:139.80ms
step:857/1405 train_time:118419ms step_avg:139.81ms
step:858/1405 train_time:118564ms step_avg:139.82ms
step:859/1405 train_time:118710ms step_avg:139.82ms
step:860/1405 train_time:118853ms step_avg:139.83ms
step:861/1405 train_time:118998ms step_avg:139.83ms
step:862/1405 train_time:119143ms step_avg:139.84ms
step:863/1405 train_time:119287ms step_avg:139.84ms
step:864/1405 train_time:119434ms step_avg:139.85ms
step:865/1405 train_time:119577ms step_avg:139.86ms
step:866/1405 train_time:119724ms step_avg:139.86ms
step:867/1405 train_time:119870ms step_avg:139.87ms
step:868/1405 train_time:120013ms step_avg:139.88ms
step:869/1405 train_time:120157ms step_avg:139.88ms
step:870/1405 train_time:120303ms step_avg:139.89ms
step:871/1405 train_time:120450ms step_avg:139.90ms
step:872/1405 train_time:120594ms step_avg:139.90ms
step:873/1405 train_time:120739ms step_avg:139.91ms
step:874/1405 train_time:120884ms step_avg:139.91ms
step:875/1405 train_time:121028ms step_avg:139.92ms
step:875/1405 val_loss:3.4776 train_time:121097ms step_avg:140.00ms
step:876/1405 train_time:121175ms step_avg:139.92ms
step:877/1405 train_time:121319ms step_avg:139.93ms
step:878/1405 train_time:121464ms step_avg:139.94ms
step:879/1405 train_time:121608ms step_avg:139.94ms
step:880/1405 train_time:121751ms step_avg:139.94ms
step:881/1405 train_time:121895ms step_avg:139.95ms
step:882/1405 train_time:122040ms step_avg:139.95ms
step:883/1405 train_time:122186ms step_avg:139.96ms
step:884/1405 train_time:122331ms step_avg:139.97ms
step:885/1405 train_time:122476ms step_avg:139.97ms
step:886/1405 train_time:122621ms step_avg:139.98ms
step:887/1405 train_time:122765ms step_avg:139.98ms
step:888/1405 train_time:122910ms step_avg:139.99ms
step:889/1405 train_time:123054ms step_avg:139.99ms
step:890/1405 train_time:123199ms step_avg:140.00ms
step:891/1405 train_time:123345ms step_avg:140.01ms
step:892/1405 train_time:123489ms step_avg:140.01ms
step:893/1405 train_time:123633ms step_avg:140.01ms
step:894/1405 train_time:123778ms step_avg:140.02ms
step:895/1405 train_time:123924ms step_avg:140.03ms
step:896/1405 train_time:124068ms step_avg:140.03ms
step:897/1405 train_time:124212ms step_avg:140.04ms
step:898/1405 train_time:124357ms step_avg:140.04ms
step:899/1405 train_time:124503ms step_avg:140.05ms
step:900/1405 train_time:124648ms step_avg:140.05ms
step:901/1405 train_time:124793ms step_avg:140.06ms
step:902/1405 train_time:124937ms step_avg:140.06ms
step:903/1405 train_time:125082ms step_avg:140.07ms
step:904/1405 train_time:125227ms step_avg:140.08ms
step:905/1405 train_time:125371ms step_avg:140.08ms
step:906/1405 train_time:125517ms step_avg:140.09ms
step:907/1405 train_time:125664ms step_avg:140.09ms
step:908/1405 train_time:125807ms step_avg:140.10ms
step:909/1405 train_time:125953ms step_avg:140.10ms
step:910/1405 train_time:126100ms step_avg:140.11ms
step:911/1405 train_time:126245ms step_avg:140.12ms
step:912/1405 train_time:126389ms step_avg:140.12ms
step:913/1405 train_time:126534ms step_avg:140.13ms
step:914/1405 train_time:126678ms step_avg:140.13ms
step:915/1405 train_time:126823ms step_avg:140.14ms
step:916/1405 train_time:126968ms step_avg:140.14ms
step:917/1405 train_time:127112ms step_avg:140.15ms
step:918/1405 train_time:127256ms step_avg:140.15ms
step:919/1405 train_time:127403ms step_avg:140.16ms
step:920/1405 train_time:127548ms step_avg:140.16ms
step:921/1405 train_time:127692ms step_avg:140.17ms
step:922/1405 train_time:127836ms step_avg:140.17ms
step:923/1405 train_time:127981ms step_avg:140.18ms
step:924/1405 train_time:128125ms step_avg:140.18ms
step:925/1405 train_time:128269ms step_avg:140.19ms
step:926/1405 train_time:128414ms step_avg:140.19ms
step:927/1405 train_time:128559ms step_avg:140.20ms
step:928/1405 train_time:128705ms step_avg:140.20ms
step:929/1405 train_time:128849ms step_avg:140.21ms
step:930/1405 train_time:128994ms step_avg:140.21ms
step:931/1405 train_time:129138ms step_avg:140.21ms
step:932/1405 train_time:129283ms step_avg:140.22ms
step:933/1405 train_time:129427ms step_avg:140.22ms
step:934/1405 train_time:129571ms step_avg:140.23ms
step:935/1405 train_time:129715ms step_avg:140.23ms
step:936/1405 train_time:129859ms step_avg:140.24ms
step:937/1405 train_time:130005ms step_avg:140.24ms
step:938/1405 train_time:130149ms step_avg:140.25ms
step:939/1405 train_time:130296ms step_avg:140.25ms
step:940/1405 train_time:130442ms step_avg:140.26ms
step:941/1405 train_time:130589ms step_avg:140.27ms
step:942/1405 train_time:130733ms step_avg:140.27ms
step:943/1405 train_time:130878ms step_avg:140.28ms
step:944/1405 train_time:131027ms step_avg:140.29ms
step:945/1405 train_time:131172ms step_avg:140.29ms
step:946/1405 train_time:131320ms step_avg:140.30ms
step:947/1405 train_time:131467ms step_avg:140.31ms
step:948/1405 train_time:131613ms step_avg:140.31ms
step:949/1405 train_time:131760ms step_avg:140.32ms
step:950/1405 train_time:131906ms step_avg:140.33ms
step:951/1405 train_time:132092ms step_avg:140.37ms
step:952/1405 train_time:132236ms step_avg:140.38ms
step:953/1405 train_time:132383ms step_avg:140.38ms
step:954/1405 train_time:132529ms step_avg:140.39ms
step:955/1405 train_time:132673ms step_avg:140.39ms
step:956/1405 train_time:132820ms step_avg:140.40ms
step:957/1405 train_time:132967ms step_avg:140.41ms
step:958/1405 train_time:133115ms step_avg:140.42ms
step:959/1405 train_time:133264ms step_avg:140.43ms
step:960/1405 train_time:133409ms step_avg:140.43ms
step:961/1405 train_time:133554ms step_avg:140.44ms
step:962/1405 train_time:133701ms step_avg:140.44ms
step:963/1405 train_time:133849ms step_avg:140.45ms
step:964/1405 train_time:133995ms step_avg:140.46ms
step:965/1405 train_time:134142ms step_avg:140.46ms
step:966/1405 train_time:134288ms step_avg:140.47ms
step:967/1405 train_time:134434ms step_avg:140.47ms
step:968/1405 train_time:134578ms step_avg:140.48ms
step:969/1405 train_time:134726ms step_avg:140.49ms
step:970/1405 train_time:134872ms step_avg:140.49ms
step:971/1405 train_time:135018ms step_avg:140.50ms
step:972/1405 train_time:135164ms step_avg:140.50ms
step:973/1405 train_time:135310ms step_avg:140.51ms
step:974/1405 train_time:135456ms step_avg:140.51ms
step:975/1405 train_time:135602ms step_avg:140.52ms
step:976/1405 train_time:135749ms step_avg:140.53ms
step:977/1405 train_time:135894ms step_avg:140.53ms
step:978/1405 train_time:136042ms step_avg:140.54ms
step:979/1405 train_time:136187ms step_avg:140.54ms
step:980/1405 train_time:136333ms step_avg:140.55ms
step:981/1405 train_time:136479ms step_avg:140.56ms
step:982/1405 train_time:136625ms step_avg:140.56ms
step:983/1405 train_time:136771ms step_avg:140.57ms
step:984/1405 train_time:136917ms step_avg:140.57ms
step:985/1405 train_time:137065ms step_avg:140.58ms
step:986/1405 train_time:137211ms step_avg:140.58ms
step:987/1405 train_time:137355ms step_avg:140.59ms
step:988/1405 train_time:137502ms step_avg:140.59ms
step:989/1405 train_time:137648ms step_avg:140.60ms
step:990/1405 train_time:137794ms step_avg:140.61ms
step:991/1405 train_time:137943ms step_avg:140.61ms
step:992/1405 train_time:138090ms step_avg:140.62ms
step:993/1405 train_time:138240ms step_avg:140.63ms
step:994/1405 train_time:138387ms step_avg:140.64ms
step:995/1405 train_time:138532ms step_avg:140.64ms
step:996/1405 train_time:138678ms step_avg:140.65ms
step:997/1405 train_time:138825ms step_avg:140.65ms
step:998/1405 train_time:138969ms step_avg:140.66ms
step:999/1405 train_time:139114ms step_avg:140.66ms
step:1000/1405 train_time:139261ms step_avg:140.67ms
step:1000/1405 val_loss:3.4118 train_time:139331ms step_avg:140.74ms
step:1001/1405 train_time:139408ms step_avg:140.67ms
step:1002/1405 train_time:139554ms step_avg:140.68ms
step:1003/1405 train_time:139701ms step_avg:140.69ms
step:1004/1405 train_time:139847ms step_avg:140.69ms
step:1005/1405 train_time:139992ms step_avg:140.70ms
step:1006/1405 train_time:140137ms step_avg:140.70ms
step:1007/1405 train_time:140283ms step_avg:140.71ms
step:1008/1405 train_time:140432ms step_avg:140.71ms
step:1009/1405 train_time:140581ms step_avg:140.72ms
step:1010/1405 train_time:140728ms step_avg:140.73ms
step:1011/1405 train_time:140873ms step_avg:140.73ms
step:1012/1405 train_time:141018ms step_avg:140.74ms
step:1013/1405 train_time:141164ms step_avg:140.74ms
step:1014/1405 train_time:141310ms step_avg:140.75ms
step:1015/1405 train_time:141456ms step_avg:140.75ms
step:1016/1405 train_time:141603ms step_avg:140.76ms
step:1017/1405 train_time:141750ms step_avg:140.76ms
step:1018/1405 train_time:141896ms step_avg:140.77ms
step:1019/1405 train_time:142042ms step_avg:140.78ms
step:1020/1405 train_time:142189ms step_avg:140.78ms
step:1021/1405 train_time:142334ms step_avg:140.79ms
step:1022/1405 train_time:142481ms step_avg:140.79ms
step:1023/1405 train_time:142627ms step_avg:140.80ms
step:1024/1405 train_time:142774ms step_avg:140.80ms
step:1025/1405 train_time:142920ms step_avg:140.81ms
step:1026/1405 train_time:143067ms step_avg:140.81ms
step:1027/1405 train_time:143212ms step_avg:140.82ms
step:1028/1405 train_time:143359ms step_avg:140.82ms
step:1029/1405 train_time:143507ms step_avg:140.83ms
step:1030/1405 train_time:143653ms step_avg:140.84ms
step:1031/1405 train_time:143798ms step_avg:140.84ms
step:1032/1405 train_time:143944ms step_avg:140.85ms
step:1033/1405 train_time:144090ms step_avg:140.85ms
step:1034/1405 train_time:144236ms step_avg:140.86ms
step:1035/1405 train_time:144383ms step_avg:140.86ms
step:1036/1405 train_time:144530ms step_avg:140.87ms
step:1037/1405 train_time:144676ms step_avg:140.87ms
step:1038/1405 train_time:144823ms step_avg:140.88ms
step:1039/1405 train_time:144968ms step_avg:140.88ms
step:1040/1405 train_time:145114ms step_avg:140.89ms
step:1041/1405 train_time:145259ms step_avg:140.89ms
step:1042/1405 train_time:145406ms step_avg:140.90ms
step:1043/1405 train_time:145552ms step_avg:140.90ms
step:1044/1405 train_time:145701ms step_avg:140.91ms
step:1045/1405 train_time:145847ms step_avg:140.92ms
step:1046/1405 train_time:145994ms step_avg:140.92ms
step:1047/1405 train_time:146139ms step_avg:140.92ms
step:1048/1405 train_time:146287ms step_avg:140.93ms
step:1049/1405 train_time:146433ms step_avg:140.94ms
step:1050/1405 train_time:146580ms step_avg:140.94ms
step:1051/1405 train_time:146727ms step_avg:140.95ms
step:1052/1405 train_time:146874ms step_avg:140.95ms
step:1053/1405 train_time:147020ms step_avg:140.96ms
step:1054/1405 train_time:147167ms step_avg:140.96ms
step:1055/1405 train_time:147313ms step_avg:140.97ms
step:1056/1405 train_time:147460ms step_avg:140.98ms
step:1057/1405 train_time:147607ms step_avg:140.98ms
step:1058/1405 train_time:147754ms step_avg:140.99ms
step:1059/1405 train_time:147903ms step_avg:140.99ms
step:1060/1405 train_time:148050ms step_avg:141.00ms
step:1061/1405 train_time:148195ms step_avg:141.00ms
step:1062/1405 train_time:148343ms step_avg:141.01ms
step:1063/1405 train_time:148489ms step_avg:141.02ms
step:1064/1405 train_time:148635ms step_avg:141.02ms
step:1065/1405 train_time:148782ms step_avg:141.03ms
step:1066/1405 train_time:148928ms step_avg:141.03ms
step:1067/1405 train_time:149076ms step_avg:141.04ms
step:1068/1405 train_time:149224ms step_avg:141.04ms
step:1069/1405 train_time:149370ms step_avg:141.05ms
step:1070/1405 train_time:149518ms step_avg:141.05ms
step:1071/1405 train_time:149666ms step_avg:141.06ms
step:1072/1405 train_time:149811ms step_avg:141.06ms
step:1073/1405 train_time:149956ms step_avg:141.07ms
step:1074/1405 train_time:150103ms step_avg:141.07ms
step:1075/1405 train_time:150250ms step_avg:141.08ms
step:1076/1405 train_time:150395ms step_avg:141.08ms
step:1077/1405 train_time:150543ms step_avg:141.09ms
step:1078/1405 train_time:150692ms step_avg:141.10ms
step:1079/1405 train_time:150840ms step_avg:141.10ms
step:1080/1405 train_time:150987ms step_avg:141.11ms
step:1081/1405 train_time:151132ms step_avg:141.11ms
step:1082/1405 train_time:151278ms step_avg:141.12ms
step:1083/1405 train_time:151425ms step_avg:141.12ms
step:1084/1405 train_time:151572ms step_avg:141.13ms
step:1085/1405 train_time:151719ms step_avg:141.13ms
step:1086/1405 train_time:151866ms step_avg:141.14ms
step:1087/1405 train_time:152011ms step_avg:141.14ms
step:1088/1405 train_time:152157ms step_avg:141.15ms
step:1089/1405 train_time:152304ms step_avg:141.15ms
step:1090/1405 train_time:152453ms step_avg:141.16ms
step:1091/1405 train_time:152601ms step_avg:141.17ms
step:1092/1405 train_time:152748ms step_avg:141.17ms
step:1093/1405 train_time:152895ms step_avg:141.18ms
step:1094/1405 train_time:153043ms step_avg:141.18ms
step:1095/1405 train_time:153188ms step_avg:141.19ms
step:1096/1405 train_time:153334ms step_avg:141.19ms
step:1097/1405 train_time:153483ms step_avg:141.20ms
step:1098/1405 train_time:153629ms step_avg:141.20ms
step:1099/1405 train_time:153776ms step_avg:141.21ms
step:1100/1405 train_time:153922ms step_avg:141.21ms
step:1101/1405 train_time:154068ms step_avg:141.22ms
step:1102/1405 train_time:154215ms step_avg:141.22ms
step:1103/1405 train_time:154363ms step_avg:141.23ms
step:1104/1405 train_time:154510ms step_avg:141.23ms
step:1105/1405 train_time:154658ms step_avg:141.24ms
step:1106/1405 train_time:154806ms step_avg:141.25ms
step:1107/1405 train_time:154951ms step_avg:141.25ms
step:1108/1405 train_time:155099ms step_avg:141.26ms
step:1109/1405 train_time:155246ms step_avg:141.26ms
step:1110/1405 train_time:155393ms step_avg:141.27ms
step:1111/1405 train_time:155540ms step_avg:141.27ms
step:1112/1405 train_time:155686ms step_avg:141.28ms
step:1113/1405 train_time:155831ms step_avg:141.28ms
step:1114/1405 train_time:155978ms step_avg:141.28ms
step:1115/1405 train_time:156126ms step_avg:141.29ms
step:1116/1405 train_time:156271ms step_avg:141.29ms
step:1117/1405 train_time:156418ms step_avg:141.30ms
step:1118/1405 train_time:156567ms step_avg:141.31ms
step:1119/1405 train_time:156712ms step_avg:141.31ms
step:1120/1405 train_time:156858ms step_avg:141.31ms
step:1121/1405 train_time:157006ms step_avg:141.32ms
step:1122/1405 train_time:157151ms step_avg:141.32ms
step:1123/1405 train_time:157297ms step_avg:141.33ms
step:1124/1405 train_time:157444ms step_avg:141.33ms
step:1125/1405 train_time:157591ms step_avg:141.34ms
step:1125/1405 val_loss:3.3592 train_time:157662ms step_avg:141.40ms
step:1126/1405 train_time:157738ms step_avg:141.34ms
step:1127/1405 train_time:157886ms step_avg:141.35ms
step:1128/1405 train_time:158031ms step_avg:141.35ms
step:1129/1405 train_time:158177ms step_avg:141.36ms
step:1130/1405 train_time:158325ms step_avg:141.36ms
step:1131/1405 train_time:158470ms step_avg:141.37ms
step:1132/1405 train_time:158616ms step_avg:141.37ms
step:1133/1405 train_time:158765ms step_avg:141.38ms
step:1134/1405 train_time:158912ms step_avg:141.38ms
step:1135/1405 train_time:159059ms step_avg:141.39ms
step:1136/1405 train_time:159208ms step_avg:141.39ms
step:1137/1405 train_time:159353ms step_avg:141.40ms
step:1138/1405 train_time:159501ms step_avg:141.40ms
step:1139/1405 train_time:159647ms step_avg:141.41ms
step:1140/1405 train_time:159795ms step_avg:141.41ms
step:1141/1405 train_time:159978ms step_avg:141.45ms
step:1142/1405 train_time:160123ms step_avg:141.45ms
step:1143/1405 train_time:160269ms step_avg:141.46ms
step:1144/1405 train_time:160414ms step_avg:141.46ms
step:1145/1405 train_time:160560ms step_avg:141.46ms
step:1146/1405 train_time:160708ms step_avg:141.47ms
step:1147/1405 train_time:160856ms step_avg:141.47ms
step:1148/1405 train_time:161005ms step_avg:141.48ms
step:1149/1405 train_time:161153ms step_avg:141.49ms
step:1150/1405 train_time:161301ms step_avg:141.49ms
step:1151/1405 train_time:161451ms step_avg:141.50ms
step:1152/1405 train_time:161600ms step_avg:141.51ms
step:1153/1405 train_time:161749ms step_avg:141.51ms
step:1154/1405 train_time:161896ms step_avg:141.52ms
step:1155/1405 train_time:162046ms step_avg:141.52ms
step:1156/1405 train_time:162195ms step_avg:141.53ms
step:1157/1405 train_time:162345ms step_avg:141.54ms
step:1158/1405 train_time:162492ms step_avg:141.54ms
step:1159/1405 train_time:162639ms step_avg:141.55ms
step:1160/1405 train_time:162787ms step_avg:141.55ms
step:1161/1405 train_time:162935ms step_avg:141.56ms
step:1162/1405 train_time:163084ms step_avg:141.57ms
step:1163/1405 train_time:163231ms step_avg:141.57ms
step:1164/1405 train_time:163379ms step_avg:141.58ms
step:1165/1405 train_time:163527ms step_avg:141.58ms
step:1166/1405 train_time:163675ms step_avg:141.59ms
step:1167/1405 train_time:163823ms step_avg:141.59ms
step:1168/1405 train_time:163971ms step_avg:141.60ms
step:1169/1405 train_time:164119ms step_avg:141.60ms
step:1170/1405 train_time:164268ms step_avg:141.61ms
step:1171/1405 train_time:164416ms step_avg:141.62ms
step:1172/1405 train_time:164564ms step_avg:141.62ms
step:1173/1405 train_time:164712ms step_avg:141.63ms
step:1174/1405 train_time:164864ms step_avg:141.64ms
step:1175/1405 train_time:165011ms step_avg:141.64ms
step:1176/1405 train_time:165160ms step_avg:141.65ms
step:1177/1405 train_time:165309ms step_avg:141.65ms
step:1178/1405 train_time:165457ms step_avg:141.66ms
step:1179/1405 train_time:165604ms step_avg:141.66ms
step:1180/1405 train_time:165756ms step_avg:141.67ms
step:1181/1405 train_time:165905ms step_avg:141.68ms
step:1182/1405 train_time:166052ms step_avg:141.68ms
step:1183/1405 train_time:166201ms step_avg:141.69ms
step:1184/1405 train_time:166348ms step_avg:141.69ms
step:1185/1405 train_time:166497ms step_avg:141.70ms
step:1186/1405 train_time:166646ms step_avg:141.71ms
step:1187/1405 train_time:166798ms step_avg:141.71ms
step:1188/1405 train_time:166946ms step_avg:141.72ms
step:1189/1405 train_time:167093ms step_avg:141.72ms
step:1190/1405 train_time:167241ms step_avg:141.73ms
step:1191/1405 train_time:167390ms step_avg:141.74ms
step:1192/1405 train_time:167537ms step_avg:141.74ms
step:1193/1405 train_time:167685ms step_avg:141.75ms
step:1194/1405 train_time:167831ms step_avg:141.75ms
step:1195/1405 train_time:167978ms step_avg:141.75ms
step:1196/1405 train_time:168128ms step_avg:141.76ms
step:1197/1405 train_time:168275ms step_avg:141.77ms
step:1198/1405 train_time:168426ms step_avg:141.77ms
step:1199/1405 train_time:168572ms step_avg:141.78ms
step:1200/1405 train_time:168722ms step_avg:141.78ms
step:1201/1405 train_time:168869ms step_avg:141.79ms
step:1202/1405 train_time:169023ms step_avg:141.80ms
step:1203/1405 train_time:169172ms step_avg:141.80ms
step:1204/1405 train_time:169322ms step_avg:141.81ms
step:1205/1405 train_time:169469ms step_avg:141.82ms
step:1206/1405 train_time:169617ms step_avg:141.82ms
step:1207/1405 train_time:169765ms step_avg:141.83ms
step:1208/1405 train_time:169913ms step_avg:141.83ms
step:1209/1405 train_time:170062ms step_avg:141.84ms
step:1210/1405 train_time:170211ms step_avg:141.84ms
step:1211/1405 train_time:170359ms step_avg:141.85ms
step:1212/1405 train_time:170507ms step_avg:141.85ms
step:1213/1405 train_time:170656ms step_avg:141.86ms
step:1214/1405 train_time:170808ms step_avg:141.87ms
step:1215/1405 train_time:170956ms step_avg:141.87ms
step:1216/1405 train_time:171103ms step_avg:141.88ms
step:1217/1405 train_time:171250ms step_avg:141.88ms
step:1218/1405 train_time:171397ms step_avg:141.88ms
step:1219/1405 train_time:171545ms step_avg:141.89ms
step:1220/1405 train_time:171693ms step_avg:141.89ms
step:1221/1405 train_time:171841ms step_avg:141.90ms
step:1222/1405 train_time:171988ms step_avg:141.90ms
step:1223/1405 train_time:172136ms step_avg:141.91ms
step:1224/1405 train_time:172286ms step_avg:141.92ms
step:1225/1405 train_time:172433ms step_avg:141.92ms
step:1226/1405 train_time:172582ms step_avg:141.93ms
step:1227/1405 train_time:172731ms step_avg:141.93ms
step:1228/1405 train_time:172879ms step_avg:141.94ms
step:1229/1405 train_time:173027ms step_avg:141.94ms
step:1230/1405 train_time:173176ms step_avg:141.95ms
step:1231/1405 train_time:173326ms step_avg:141.95ms
step:1232/1405 train_time:173474ms step_avg:141.96ms
step:1233/1405 train_time:173624ms step_avg:141.97ms
step:1234/1405 train_time:173770ms step_avg:141.97ms
step:1235/1405 train_time:173918ms step_avg:141.97ms
step:1236/1405 train_time:174067ms step_avg:141.98ms
step:1237/1405 train_time:174215ms step_avg:141.98ms
step:1238/1405 train_time:174366ms step_avg:141.99ms
step:1239/1405 train_time:174514ms step_avg:142.00ms
step:1240/1405 train_time:174663ms step_avg:142.00ms
step:1241/1405 train_time:174811ms step_avg:142.01ms
step:1242/1405 train_time:174959ms step_avg:142.01ms
step:1243/1405 train_time:175108ms step_avg:142.02ms
step:1244/1405 train_time:175255ms step_avg:142.02ms
step:1245/1405 train_time:175404ms step_avg:142.03ms
step:1246/1405 train_time:175551ms step_avg:142.03ms
step:1247/1405 train_time:175700ms step_avg:142.04ms
step:1248/1405 train_time:175847ms step_avg:142.04ms
step:1249/1405 train_time:175994ms step_avg:142.05ms
step:1250/1405 train_time:176144ms step_avg:142.05ms
step:1250/1405 val_loss:3.3115 train_time:176216ms step_avg:142.11ms
step:1251/1405 train_time:176295ms step_avg:142.06ms
step:1252/1405 train_time:176443ms step_avg:142.06ms
step:1253/1405 train_time:176591ms step_avg:142.07ms
step:1254/1405 train_time:176738ms step_avg:142.07ms
step:1255/1405 train_time:176888ms step_avg:142.08ms
step:1256/1405 train_time:177036ms step_avg:142.08ms
step:1257/1405 train_time:177183ms step_avg:142.09ms
step:1258/1405 train_time:177334ms step_avg:142.09ms
step:1259/1405 train_time:177483ms step_avg:142.10ms
step:1260/1405 train_time:177630ms step_avg:142.10ms
step:1261/1405 train_time:177780ms step_avg:142.11ms
step:1262/1405 train_time:177928ms step_avg:142.11ms
step:1263/1405 train_time:178077ms step_avg:142.12ms
step:1264/1405 train_time:178224ms step_avg:142.12ms
step:1265/1405 train_time:178373ms step_avg:142.13ms
step:1266/1405 train_time:178521ms step_avg:142.13ms
step:1267/1405 train_time:178668ms step_avg:142.14ms
step:1268/1405 train_time:178818ms step_avg:142.14ms
step:1269/1405 train_time:178968ms step_avg:142.15ms
step:1270/1405 train_time:179118ms step_avg:142.16ms
step:1271/1405 train_time:179264ms step_avg:142.16ms
step:1272/1405 train_time:179413ms step_avg:142.17ms
step:1273/1405 train_time:179561ms step_avg:142.17ms
step:1274/1405 train_time:179708ms step_avg:142.17ms
step:1275/1405 train_time:179858ms step_avg:142.18ms
step:1276/1405 train_time:180005ms step_avg:142.18ms
step:1277/1405 train_time:180156ms step_avg:142.19ms
step:1278/1405 train_time:180302ms step_avg:142.19ms
step:1279/1405 train_time:180452ms step_avg:142.20ms
step:1280/1405 train_time:180602ms step_avg:142.21ms
step:1281/1405 train_time:180750ms step_avg:142.21ms
step:1282/1405 train_time:180898ms step_avg:142.22ms
step:1283/1405 train_time:181046ms step_avg:142.22ms
step:1284/1405 train_time:181195ms step_avg:142.23ms
step:1285/1405 train_time:181341ms step_avg:142.23ms
step:1286/1405 train_time:181488ms step_avg:142.23ms
step:1287/1405 train_time:181637ms step_avg:142.24ms
step:1288/1405 train_time:181785ms step_avg:142.24ms
step:1289/1405 train_time:181935ms step_avg:142.25ms
step:1290/1405 train_time:182084ms step_avg:142.25ms
step:1291/1405 train_time:182233ms step_avg:142.26ms
step:1292/1405 train_time:182381ms step_avg:142.26ms
step:1293/1405 train_time:182531ms step_avg:142.27ms
step:1294/1405 train_time:182680ms step_avg:142.27ms
step:1295/1405 train_time:182828ms step_avg:142.28ms
step:1296/1405 train_time:182977ms step_avg:142.28ms
step:1297/1405 train_time:183124ms step_avg:142.29ms
step:1298/1405 train_time:183273ms step_avg:142.29ms
step:1299/1405 train_time:183421ms step_avg:142.30ms
step:1300/1405 train_time:183570ms step_avg:142.30ms
step:1301/1405 train_time:183718ms step_avg:142.31ms
step:1302/1405 train_time:183867ms step_avg:142.31ms
step:1303/1405 train_time:184018ms step_avg:142.32ms
step:1304/1405 train_time:184166ms step_avg:142.32ms
step:1305/1405 train_time:184315ms step_avg:142.33ms
step:1306/1405 train_time:184463ms step_avg:142.33ms
step:1307/1405 train_time:184610ms step_avg:142.34ms
step:1308/1405 train_time:184760ms step_avg:142.34ms
step:1309/1405 train_time:184910ms step_avg:142.35ms
step:1310/1405 train_time:185059ms step_avg:142.35ms
step:1311/1405 train_time:185206ms step_avg:142.36ms
step:1312/1405 train_time:185355ms step_avg:142.36ms
step:1313/1405 train_time:185503ms step_avg:142.37ms
step:1314/1405 train_time:185651ms step_avg:142.37ms
step:1315/1405 train_time:185802ms step_avg:142.38ms
step:1316/1405 train_time:185950ms step_avg:142.38ms
step:1317/1405 train_time:186098ms step_avg:142.39ms
step:1318/1405 train_time:186247ms step_avg:142.39ms
step:1319/1405 train_time:186397ms step_avg:142.40ms
step:1320/1405 train_time:186544ms step_avg:142.40ms
step:1321/1405 train_time:186693ms step_avg:142.41ms
step:1322/1405 train_time:186842ms step_avg:142.41ms
step:1323/1405 train_time:186990ms step_avg:142.41ms
step:1324/1405 train_time:187139ms step_avg:142.42ms
step:1325/1405 train_time:187289ms step_avg:142.43ms
step:1326/1405 train_time:187439ms step_avg:142.43ms
step:1327/1405 train_time:187586ms step_avg:142.43ms
step:1328/1405 train_time:187735ms step_avg:142.44ms
step:1329/1405 train_time:187887ms step_avg:142.45ms
step:1330/1405 train_time:188038ms step_avg:142.45ms
step:1331/1405 train_time:188227ms step_avg:142.49ms
step:1332/1405 train_time:188379ms step_avg:142.50ms
step:1333/1405 train_time:188527ms step_avg:142.50ms
step:1334/1405 train_time:188674ms step_avg:142.50ms
step:1335/1405 train_time:188820ms step_avg:142.51ms
step:1336/1405 train_time:188969ms step_avg:142.51ms
step:1337/1405 train_time:189118ms step_avg:142.52ms
step:1338/1405 train_time:189266ms step_avg:142.52ms
step:1339/1405 train_time:189417ms step_avg:142.53ms
step:1340/1405 train_time:189566ms step_avg:142.53ms
step:1341/1405 train_time:189715ms step_avg:142.54ms
step:1342/1405 train_time:189862ms step_avg:142.54ms
step:1343/1405 train_time:190009ms step_avg:142.54ms
step:1344/1405 train_time:190157ms step_avg:142.55ms
step:1345/1405 train_time:190306ms step_avg:142.55ms
step:1346/1405 train_time:190454ms step_avg:142.56ms
step:1347/1405 train_time:190602ms step_avg:142.56ms
step:1348/1405 train_time:190752ms step_avg:142.56ms
step:1349/1405 train_time:190899ms step_avg:142.57ms
step:1350/1405 train_time:191047ms step_avg:142.57ms
step:1351/1405 train_time:191197ms step_avg:142.58ms
step:1352/1405 train_time:191347ms step_avg:142.58ms
step:1353/1405 train_time:191496ms step_avg:142.59ms
step:1354/1405 train_time:191644ms step_avg:142.59ms
step:1355/1405 train_time:191794ms step_avg:142.60ms
step:1356/1405 train_time:191942ms step_avg:142.60ms
step:1357/1405 train_time:192093ms step_avg:142.61ms
step:1358/1405 train_time:192242ms step_avg:142.61ms
step:1359/1405 train_time:192392ms step_avg:142.62ms
step:1360/1405 train_time:192541ms step_avg:142.62ms
step:1361/1405 train_time:192693ms step_avg:142.63ms
step:1362/1405 train_time:192843ms step_avg:142.64ms
step:1363/1405 train_time:192995ms step_avg:142.64ms
step:1364/1405 train_time:193146ms step_avg:142.65ms
step:1365/1405 train_time:193293ms step_avg:142.65ms
step:1366/1405 train_time:193443ms step_avg:142.66ms
step:1367/1405 train_time:193592ms step_avg:142.66ms
step:1368/1405 train_time:193742ms step_avg:142.67ms
step:1369/1405 train_time:193895ms step_avg:142.67ms
step:1370/1405 train_time:194044ms step_avg:142.68ms
step:1371/1405 train_time:194195ms step_avg:142.69ms
step:1372/1405 train_time:194344ms step_avg:142.69ms
step:1373/1405 train_time:194494ms step_avg:142.70ms
step:1374/1405 train_time:194644ms step_avg:142.70ms
step:1375/1405 train_time:194792ms step_avg:142.71ms
step:1375/1405 val_loss:3.2808 train_time:194864ms step_avg:142.76ms
step:1376/1405 train_time:194943ms step_avg:142.71ms
step:1377/1405 train_time:195092ms step_avg:142.72ms
step:1378/1405 train_time:195243ms step_avg:142.72ms
step:1379/1405 train_time:195391ms step_avg:142.73ms
step:1380/1405 train_time:195542ms step_avg:142.73ms
step:1381/1405 train_time:195692ms step_avg:142.74ms
step:1382/1405 train_time:195842ms step_avg:142.74ms
step:1383/1405 train_time:195992ms step_avg:142.75ms
step:1384/1405 train_time:196144ms step_avg:142.75ms
step:1385/1405 train_time:196291ms step_avg:142.76ms
step:1386/1405 train_time:196442ms step_avg:142.76ms
step:1387/1405 train_time:196591ms step_avg:142.77ms
step:1388/1405 train_time:196741ms step_avg:142.77ms
step:1389/1405 train_time:196889ms step_avg:142.78ms
step:1390/1405 train_time:197039ms step_avg:142.78ms
step:1391/1405 train_time:197187ms step_avg:142.79ms
step:1392/1405 train_time:197337ms step_avg:142.79ms
step:1393/1405 train_time:197487ms step_avg:142.80ms
step:1394/1405 train_time:197636ms step_avg:142.80ms
step:1395/1405 train_time:197785ms step_avg:142.81ms
step:1396/1405 train_time:197934ms step_avg:142.81ms
step:1397/1405 train_time:198084ms step_avg:142.81ms
step:1398/1405 train_time:198233ms step_avg:142.82ms
step:1399/1405 train_time:198382ms step_avg:142.82ms
step:1400/1405 train_time:198533ms step_avg:142.83ms
step:1401/1405 train_time:198682ms step_avg:142.83ms
step:1402/1405 train_time:198830ms step_avg:142.84ms
step:1403/1405 train_time:198982ms step_avg:142.84ms
step:1404/1405 train_time:199130ms step_avg:142.85ms
step:1405/1405 train_time:199280ms step_avg:142.85ms
step:1405/1405 val_loss:3.2782 train_time:199353ms step_avg:142.91ms
peak memory consumption: 31567 MiB
