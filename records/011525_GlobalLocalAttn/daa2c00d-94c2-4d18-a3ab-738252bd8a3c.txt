import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask: torch.Tensor):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            # indices = (~dense_mask).argsort(dim=-1, descending=False, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_masks(sliding_window_num_blocks: int):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            short_sliding_window_num_blocks = sliding_window_num_blocks // 2
            return (
                BlockMask.from_kv_blocks(
                    kv_num_blocks,
                    kv_indices,
                    full_kv_num_blocks,
                    full_kv_indices,
                    BLOCK_SIZE=BLOCK_SIZE,
                    mask_mod=document_causal,
                ),
                BlockMask.from_kv_blocks(
                    torch.clamp_max(kv_num_blocks, torch.clamp_min(short_sliding_window_num_blocks - full_kv_num_blocks, 1)),
                    kv_indices,
                    torch.clamp_max(full_kv_num_blocks, short_sliding_window_num_blocks - 1),
                    full_kv_indices,
                    BLOCK_SIZE=BLOCK_SIZE,
                    mask_mod=document_causal,
                ),
            )

        # Long-short SWA block masks by @leloykun & @YouJiacheng
        long_swa_block_mask, short_swa_block_mask = create_doc_swc_block_masks(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        is_long_block_mask = [True, False, False, False, True, False]
        for i in range(self.num_encoder_layers):
            block_mask = long_swa_block_mask if is_long_block_mask[i] else short_swa_block_mask
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        is_long_block_mask = list(reversed(is_long_block_mask))
        for i in range(self.num_decoder_layers):
            block_mask = long_swa_block_mask if is_long_block_mask[i] else short_swa_block_mask
            x = x + self.skip_weights[i] * skip_connections.pop()
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1405 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250110+cu126 compiled for CUDA 12.6
Wed Jan 15 19:28:10 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   33C    P0             118W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   27C    P0             112W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   26C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   32C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   33C    P0             116W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   28C    P0             111W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   32C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   27C    P0             111W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1405 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1405 train_time:28190ms step_avg:nanms
step:2/1405 train_time:28337ms step_avg:nanms
step:3/1405 train_time:28528ms step_avg:nanms
step:4/1405 train_time:28660ms step_avg:nanms
step:5/1405 train_time:28793ms step_avg:nanms
step:6/1405 train_time:28925ms step_avg:nanms
step:7/1405 train_time:29056ms step_avg:nanms
step:8/1405 train_time:29189ms step_avg:nanms
step:9/1405 train_time:29322ms step_avg:nanms
step:10/1405 train_time:29459ms step_avg:nanms
step:11/1405 train_time:135ms step_avg:nanms
step:12/1405 train_time:268ms step_avg:nanms
step:13/1405 train_time:402ms step_avg:134.01ms
step:14/1405 train_time:534ms step_avg:133.57ms
step:15/1405 train_time:668ms step_avg:133.60ms
step:16/1405 train_time:800ms step_avg:133.34ms
step:17/1405 train_time:935ms step_avg:133.54ms
step:18/1405 train_time:1068ms step_avg:133.56ms
step:19/1405 train_time:1202ms step_avg:133.57ms
step:20/1405 train_time:1337ms step_avg:133.66ms
step:21/1405 train_time:1471ms step_avg:133.69ms
step:22/1405 train_time:1604ms step_avg:133.68ms
step:23/1405 train_time:1738ms step_avg:133.66ms
step:24/1405 train_time:1871ms step_avg:133.65ms
step:25/1405 train_time:2007ms step_avg:133.78ms
step:26/1405 train_time:2140ms step_avg:133.77ms
step:27/1405 train_time:2276ms step_avg:133.87ms
step:28/1405 train_time:2409ms step_avg:133.85ms
step:29/1405 train_time:2543ms step_avg:133.85ms
step:30/1405 train_time:2676ms step_avg:133.82ms
step:31/1405 train_time:2811ms step_avg:133.84ms
step:32/1405 train_time:2946ms step_avg:133.93ms
step:33/1405 train_time:3079ms step_avg:133.85ms
step:34/1405 train_time:3213ms step_avg:133.88ms
step:35/1405 train_time:3348ms step_avg:133.94ms
step:36/1405 train_time:3482ms step_avg:133.91ms
step:37/1405 train_time:3615ms step_avg:133.90ms
step:38/1405 train_time:3748ms step_avg:133.85ms
step:39/1405 train_time:3881ms step_avg:133.83ms
step:40/1405 train_time:4016ms step_avg:133.85ms
step:41/1405 train_time:4150ms step_avg:133.86ms
step:42/1405 train_time:4284ms step_avg:133.86ms
step:43/1405 train_time:4418ms step_avg:133.88ms
step:44/1405 train_time:4552ms step_avg:133.87ms
step:45/1405 train_time:4686ms step_avg:133.87ms
step:46/1405 train_time:4819ms step_avg:133.85ms
step:47/1405 train_time:4954ms step_avg:133.89ms
step:48/1405 train_time:5088ms step_avg:133.89ms
step:49/1405 train_time:5223ms step_avg:133.92ms
step:50/1405 train_time:5357ms step_avg:133.91ms
step:51/1405 train_time:5491ms step_avg:133.93ms
step:52/1405 train_time:5625ms step_avg:133.93ms
step:53/1405 train_time:5759ms step_avg:133.92ms
step:54/1405 train_time:5892ms step_avg:133.91ms
step:55/1405 train_time:6027ms step_avg:133.94ms
step:56/1405 train_time:6162ms step_avg:133.95ms
step:57/1405 train_time:6295ms step_avg:133.94ms
step:58/1405 train_time:6430ms step_avg:133.97ms
step:59/1405 train_time:6563ms step_avg:133.94ms
step:60/1405 train_time:6696ms step_avg:133.92ms
step:61/1405 train_time:6831ms step_avg:133.94ms
step:62/1405 train_time:6965ms step_avg:133.95ms
step:63/1405 train_time:7098ms step_avg:133.93ms
step:64/1405 train_time:7232ms step_avg:133.93ms
step:65/1405 train_time:7367ms step_avg:133.95ms
step:66/1405 train_time:7501ms step_avg:133.95ms
step:67/1405 train_time:7635ms step_avg:133.94ms
step:68/1405 train_time:7770ms step_avg:133.97ms
step:69/1405 train_time:7904ms step_avg:133.97ms
step:70/1405 train_time:8040ms step_avg:134.00ms
step:71/1405 train_time:8173ms step_avg:133.98ms
step:72/1405 train_time:8307ms step_avg:133.98ms
step:73/1405 train_time:8441ms step_avg:133.99ms
step:74/1405 train_time:8576ms step_avg:134.00ms
step:75/1405 train_time:8711ms step_avg:134.01ms
step:76/1405 train_time:8845ms step_avg:134.01ms
step:77/1405 train_time:8980ms step_avg:134.02ms
step:78/1405 train_time:9113ms step_avg:134.01ms
step:79/1405 train_time:9247ms step_avg:134.02ms
step:80/1405 train_time:9382ms step_avg:134.02ms
step:81/1405 train_time:9517ms step_avg:134.04ms
step:82/1405 train_time:9650ms step_avg:134.03ms
step:83/1405 train_time:9785ms step_avg:134.04ms
step:84/1405 train_time:9920ms step_avg:134.05ms
step:85/1405 train_time:10053ms step_avg:134.05ms
step:86/1405 train_time:10188ms step_avg:134.05ms
step:87/1405 train_time:10321ms step_avg:134.04ms
step:88/1405 train_time:10456ms step_avg:134.06ms
step:89/1405 train_time:10590ms step_avg:134.05ms
step:90/1405 train_time:10723ms step_avg:134.04ms
step:91/1405 train_time:10858ms step_avg:134.05ms
step:92/1405 train_time:10992ms step_avg:134.05ms
step:93/1405 train_time:11128ms step_avg:134.07ms
step:94/1405 train_time:11261ms step_avg:134.06ms
step:95/1405 train_time:11396ms step_avg:134.07ms
step:96/1405 train_time:11531ms step_avg:134.08ms
step:97/1405 train_time:11665ms step_avg:134.08ms
step:98/1405 train_time:11798ms step_avg:134.07ms
step:99/1405 train_time:11933ms step_avg:134.08ms
step:100/1405 train_time:12068ms step_avg:134.09ms
step:101/1405 train_time:12202ms step_avg:134.08ms
step:102/1405 train_time:12336ms step_avg:134.08ms
step:103/1405 train_time:12470ms step_avg:134.09ms
step:104/1405 train_time:12604ms step_avg:134.09ms
step:105/1405 train_time:12738ms step_avg:134.08ms
step:106/1405 train_time:12872ms step_avg:134.09ms
step:107/1405 train_time:13007ms step_avg:134.10ms
step:108/1405 train_time:13142ms step_avg:134.10ms
step:109/1405 train_time:13278ms step_avg:134.12ms
step:110/1405 train_time:13413ms step_avg:134.13ms
step:111/1405 train_time:13550ms step_avg:134.16ms
step:112/1405 train_time:13686ms step_avg:134.18ms
step:113/1405 train_time:13821ms step_avg:134.18ms
step:114/1405 train_time:13956ms step_avg:134.19ms
step:115/1405 train_time:14092ms step_avg:134.21ms
step:116/1405 train_time:14226ms step_avg:134.21ms
step:117/1405 train_time:14361ms step_avg:134.22ms
step:118/1405 train_time:14496ms step_avg:134.22ms
step:119/1405 train_time:14633ms step_avg:134.24ms
step:120/1405 train_time:14768ms step_avg:134.26ms
step:121/1405 train_time:14903ms step_avg:134.26ms
step:122/1405 train_time:15038ms step_avg:134.27ms
step:123/1405 train_time:15173ms step_avg:134.27ms
step:124/1405 train_time:15308ms step_avg:134.28ms
step:125/1405 train_time:15443ms step_avg:134.28ms
step:125/1405 val_loss:4.4484 train_time:15507ms step_avg:134.84ms
step:126/1405 train_time:15583ms step_avg:134.33ms
step:127/1405 train_time:15721ms step_avg:134.37ms
step:128/1405 train_time:15856ms step_avg:134.37ms
step:129/1405 train_time:15990ms step_avg:134.37ms
step:130/1405 train_time:16125ms step_avg:134.37ms
step:131/1405 train_time:16259ms step_avg:134.37ms
step:132/1405 train_time:16394ms step_avg:134.37ms
step:133/1405 train_time:16529ms step_avg:134.38ms
step:134/1405 train_time:16667ms step_avg:134.41ms
step:135/1405 train_time:16805ms step_avg:134.44ms
step:136/1405 train_time:16941ms step_avg:134.45ms
step:137/1405 train_time:17076ms step_avg:134.46ms
step:138/1405 train_time:17211ms step_avg:134.46ms
step:139/1405 train_time:17346ms step_avg:134.46ms
step:140/1405 train_time:17481ms step_avg:134.47ms
step:141/1405 train_time:17617ms step_avg:134.48ms
step:142/1405 train_time:17753ms step_avg:134.49ms
step:143/1405 train_time:17889ms step_avg:134.50ms
step:144/1405 train_time:18025ms step_avg:134.52ms
step:145/1405 train_time:18161ms step_avg:134.52ms
step:146/1405 train_time:18296ms step_avg:134.53ms
step:147/1405 train_time:18431ms step_avg:134.53ms
step:148/1405 train_time:18568ms step_avg:134.55ms
step:149/1405 train_time:18704ms step_avg:134.56ms
step:150/1405 train_time:18841ms step_avg:134.58ms
step:151/1405 train_time:18977ms step_avg:134.59ms
step:152/1405 train_time:19114ms step_avg:134.61ms
step:153/1405 train_time:19250ms step_avg:134.61ms
step:154/1405 train_time:19385ms step_avg:134.62ms
step:155/1405 train_time:19521ms step_avg:134.63ms
step:156/1405 train_time:19656ms step_avg:134.63ms
step:157/1405 train_time:19793ms step_avg:134.65ms
step:158/1405 train_time:19929ms step_avg:134.66ms
step:159/1405 train_time:20066ms step_avg:134.67ms
step:160/1405 train_time:20201ms step_avg:134.67ms
step:161/1405 train_time:20336ms step_avg:134.67ms
step:162/1405 train_time:20472ms step_avg:134.68ms
step:163/1405 train_time:20607ms step_avg:134.69ms
step:164/1405 train_time:20744ms step_avg:134.70ms
step:165/1405 train_time:20879ms step_avg:134.71ms
step:166/1405 train_time:21015ms step_avg:134.71ms
step:167/1405 train_time:21150ms step_avg:134.71ms
step:168/1405 train_time:21286ms step_avg:134.72ms
step:169/1405 train_time:21422ms step_avg:134.73ms
step:170/1405 train_time:21558ms step_avg:134.74ms
step:171/1405 train_time:21695ms step_avg:134.75ms
step:172/1405 train_time:21830ms step_avg:134.75ms
step:173/1405 train_time:21966ms step_avg:134.76ms
step:174/1405 train_time:22103ms step_avg:134.77ms
step:175/1405 train_time:22237ms step_avg:134.77ms
step:176/1405 train_time:22373ms step_avg:134.78ms
step:177/1405 train_time:22509ms step_avg:134.78ms
step:178/1405 train_time:22646ms step_avg:134.80ms
step:179/1405 train_time:22780ms step_avg:134.80ms
step:180/1405 train_time:22916ms step_avg:134.80ms
step:181/1405 train_time:23052ms step_avg:134.81ms
step:182/1405 train_time:23188ms step_avg:134.82ms
step:183/1405 train_time:23325ms step_avg:134.83ms
step:184/1405 train_time:23460ms step_avg:134.83ms
step:185/1405 train_time:23596ms step_avg:134.83ms
step:186/1405 train_time:23732ms step_avg:134.84ms
step:187/1405 train_time:23868ms step_avg:134.84ms
step:188/1405 train_time:24004ms step_avg:134.85ms
step:189/1405 train_time:24140ms step_avg:134.86ms
step:190/1405 train_time:24275ms step_avg:134.86ms
step:191/1405 train_time:24458ms step_avg:135.13ms
step:192/1405 train_time:24594ms step_avg:135.13ms
step:193/1405 train_time:24729ms step_avg:135.13ms
step:194/1405 train_time:24864ms step_avg:135.13ms
step:195/1405 train_time:24997ms step_avg:135.12ms
step:196/1405 train_time:25132ms step_avg:135.12ms
step:197/1405 train_time:25267ms step_avg:135.12ms
step:198/1405 train_time:25408ms step_avg:135.15ms
step:199/1405 train_time:25545ms step_avg:135.16ms
step:200/1405 train_time:25680ms step_avg:135.16ms
step:201/1405 train_time:25815ms step_avg:135.16ms
step:202/1405 train_time:25950ms step_avg:135.16ms
step:203/1405 train_time:26086ms step_avg:135.16ms
step:204/1405 train_time:26221ms step_avg:135.16ms
step:205/1405 train_time:26356ms step_avg:135.16ms
step:206/1405 train_time:26494ms step_avg:135.17ms
step:207/1405 train_time:26630ms step_avg:135.18ms
step:208/1405 train_time:26766ms step_avg:135.18ms
step:209/1405 train_time:26902ms step_avg:135.19ms
step:210/1405 train_time:27039ms step_avg:135.20ms
step:211/1405 train_time:27175ms step_avg:135.20ms
step:212/1405 train_time:27311ms step_avg:135.20ms
step:213/1405 train_time:27448ms step_avg:135.21ms
step:214/1405 train_time:27587ms step_avg:135.23ms
step:215/1405 train_time:27723ms step_avg:135.23ms
step:216/1405 train_time:27859ms step_avg:135.24ms
step:217/1405 train_time:27996ms step_avg:135.25ms
step:218/1405 train_time:28133ms step_avg:135.25ms
step:219/1405 train_time:28269ms step_avg:135.26ms
step:220/1405 train_time:28407ms step_avg:135.27ms
step:221/1405 train_time:28543ms step_avg:135.27ms
step:222/1405 train_time:28679ms step_avg:135.28ms
step:223/1405 train_time:28814ms step_avg:135.28ms
step:224/1405 train_time:28951ms step_avg:135.28ms
step:225/1405 train_time:29088ms step_avg:135.29ms
step:226/1405 train_time:29224ms step_avg:135.30ms
step:227/1405 train_time:29359ms step_avg:135.30ms
step:228/1405 train_time:29496ms step_avg:135.30ms
step:229/1405 train_time:29634ms step_avg:135.31ms
step:230/1405 train_time:29769ms step_avg:135.32ms
step:231/1405 train_time:29907ms step_avg:135.32ms
step:232/1405 train_time:30044ms step_avg:135.33ms
step:233/1405 train_time:30181ms step_avg:135.34ms
step:234/1405 train_time:30316ms step_avg:135.34ms
step:235/1405 train_time:30453ms step_avg:135.35ms
step:236/1405 train_time:30589ms step_avg:135.35ms
step:237/1405 train_time:30726ms step_avg:135.36ms
step:238/1405 train_time:30862ms step_avg:135.36ms
step:239/1405 train_time:30999ms step_avg:135.37ms
step:240/1405 train_time:31136ms step_avg:135.38ms
step:241/1405 train_time:31273ms step_avg:135.38ms
step:242/1405 train_time:31410ms step_avg:135.39ms
step:243/1405 train_time:31548ms step_avg:135.40ms
step:244/1405 train_time:31684ms step_avg:135.40ms
step:245/1405 train_time:31820ms step_avg:135.40ms
step:246/1405 train_time:31955ms step_avg:135.40ms
step:247/1405 train_time:32092ms step_avg:135.41ms
step:248/1405 train_time:32229ms step_avg:135.41ms
step:249/1405 train_time:32366ms step_avg:135.42ms
step:250/1405 train_time:32503ms step_avg:135.43ms
step:250/1405 val_loss:3.9901 train_time:32568ms step_avg:135.70ms
step:251/1405 train_time:32644ms step_avg:135.45ms
step:252/1405 train_time:32785ms step_avg:135.47ms
step:253/1405 train_time:32923ms step_avg:135.49ms
step:254/1405 train_time:33060ms step_avg:135.49ms
step:255/1405 train_time:33196ms step_avg:135.49ms
step:256/1405 train_time:33331ms step_avg:135.49ms
step:257/1405 train_time:33467ms step_avg:135.49ms
step:258/1405 train_time:33605ms step_avg:135.51ms
step:259/1405 train_time:33743ms step_avg:135.52ms
step:260/1405 train_time:33882ms step_avg:135.53ms
step:261/1405 train_time:34019ms step_avg:135.54ms
step:262/1405 train_time:34156ms step_avg:135.54ms
step:263/1405 train_time:34291ms step_avg:135.54ms
step:264/1405 train_time:34428ms step_avg:135.54ms
step:265/1405 train_time:34565ms step_avg:135.55ms
step:266/1405 train_time:34701ms step_avg:135.55ms
step:267/1405 train_time:34841ms step_avg:135.57ms
step:268/1405 train_time:34977ms step_avg:135.57ms
step:269/1405 train_time:35114ms step_avg:135.58ms
step:270/1405 train_time:35251ms step_avg:135.58ms
step:271/1405 train_time:35387ms step_avg:135.58ms
step:272/1405 train_time:35524ms step_avg:135.59ms
step:273/1405 train_time:35661ms step_avg:135.59ms
step:274/1405 train_time:35797ms step_avg:135.60ms
step:275/1405 train_time:35934ms step_avg:135.60ms
step:276/1405 train_time:36071ms step_avg:135.60ms
step:277/1405 train_time:36208ms step_avg:135.61ms
step:278/1405 train_time:36345ms step_avg:135.62ms
step:279/1405 train_time:36482ms step_avg:135.62ms
step:280/1405 train_time:36620ms step_avg:135.63ms
step:281/1405 train_time:36756ms step_avg:135.63ms
step:282/1405 train_time:36892ms step_avg:135.63ms
step:283/1405 train_time:37029ms step_avg:135.64ms
step:284/1405 train_time:37166ms step_avg:135.64ms
step:285/1405 train_time:37303ms step_avg:135.65ms
step:286/1405 train_time:37440ms step_avg:135.65ms
step:287/1405 train_time:37578ms step_avg:135.66ms
step:288/1405 train_time:37713ms step_avg:135.66ms
step:289/1405 train_time:37850ms step_avg:135.66ms
step:290/1405 train_time:37986ms step_avg:135.66ms
step:291/1405 train_time:38123ms step_avg:135.67ms
step:292/1405 train_time:38261ms step_avg:135.68ms
step:293/1405 train_time:38398ms step_avg:135.68ms
step:294/1405 train_time:38536ms step_avg:135.69ms
step:295/1405 train_time:38672ms step_avg:135.69ms
step:296/1405 train_time:38810ms step_avg:135.70ms
step:297/1405 train_time:38947ms step_avg:135.70ms
step:298/1405 train_time:39083ms step_avg:135.70ms
step:299/1405 train_time:39221ms step_avg:135.71ms
step:300/1405 train_time:39357ms step_avg:135.71ms
step:301/1405 train_time:39494ms step_avg:135.72ms
step:302/1405 train_time:39631ms step_avg:135.72ms
step:303/1405 train_time:39767ms step_avg:135.72ms
step:304/1405 train_time:39904ms step_avg:135.73ms
step:305/1405 train_time:40042ms step_avg:135.73ms
step:306/1405 train_time:40179ms step_avg:135.74ms
step:307/1405 train_time:40318ms step_avg:135.75ms
step:308/1405 train_time:40454ms step_avg:135.75ms
step:309/1405 train_time:40592ms step_avg:135.76ms
step:310/1405 train_time:40729ms step_avg:135.76ms
step:311/1405 train_time:40866ms step_avg:135.77ms
step:312/1405 train_time:41003ms step_avg:135.77ms
step:313/1405 train_time:41141ms step_avg:135.78ms
step:314/1405 train_time:41279ms step_avg:135.79ms
step:315/1405 train_time:41419ms step_avg:135.80ms
step:316/1405 train_time:41558ms step_avg:135.81ms
step:317/1405 train_time:41699ms step_avg:135.83ms
step:318/1405 train_time:41839ms step_avg:135.84ms
step:319/1405 train_time:41977ms step_avg:135.85ms
step:320/1405 train_time:42116ms step_avg:135.86ms
step:321/1405 train_time:42254ms step_avg:135.87ms
step:322/1405 train_time:42393ms step_avg:135.88ms
step:323/1405 train_time:42534ms step_avg:135.89ms
step:324/1405 train_time:42673ms step_avg:135.90ms
step:325/1405 train_time:42812ms step_avg:135.91ms
step:326/1405 train_time:42952ms step_avg:135.92ms
step:327/1405 train_time:43091ms step_avg:135.93ms
step:328/1405 train_time:43232ms step_avg:135.95ms
step:329/1405 train_time:43372ms step_avg:135.96ms
step:330/1405 train_time:43512ms step_avg:135.97ms
step:331/1405 train_time:43651ms step_avg:135.99ms
step:332/1405 train_time:43792ms step_avg:136.00ms
step:333/1405 train_time:43931ms step_avg:136.01ms
step:334/1405 train_time:44069ms step_avg:136.02ms
step:335/1405 train_time:44209ms step_avg:136.03ms
step:336/1405 train_time:44349ms step_avg:136.04ms
step:337/1405 train_time:44490ms step_avg:136.05ms
step:338/1405 train_time:44630ms step_avg:136.07ms
step:339/1405 train_time:44769ms step_avg:136.08ms
step:340/1405 train_time:44909ms step_avg:136.09ms
step:341/1405 train_time:45049ms step_avg:136.10ms
step:342/1405 train_time:45188ms step_avg:136.11ms
step:343/1405 train_time:45326ms step_avg:136.11ms
step:344/1405 train_time:45466ms step_avg:136.12ms
step:345/1405 train_time:45606ms step_avg:136.14ms
step:346/1405 train_time:45745ms step_avg:136.15ms
step:347/1405 train_time:45884ms step_avg:136.15ms
step:348/1405 train_time:46024ms step_avg:136.17ms
step:349/1405 train_time:46165ms step_avg:136.18ms
step:350/1405 train_time:46304ms step_avg:136.19ms
step:351/1405 train_time:46443ms step_avg:136.20ms
step:352/1405 train_time:46583ms step_avg:136.21ms
step:353/1405 train_time:46724ms step_avg:136.22ms
step:354/1405 train_time:46863ms step_avg:136.23ms
step:355/1405 train_time:47002ms step_avg:136.24ms
step:356/1405 train_time:47142ms step_avg:136.25ms
step:357/1405 train_time:47281ms step_avg:136.26ms
step:358/1405 train_time:47420ms step_avg:136.26ms
step:359/1405 train_time:47558ms step_avg:136.27ms
step:360/1405 train_time:47698ms step_avg:136.28ms
step:361/1405 train_time:47838ms step_avg:136.29ms
step:362/1405 train_time:47976ms step_avg:136.30ms
step:363/1405 train_time:48116ms step_avg:136.31ms
step:364/1405 train_time:48256ms step_avg:136.32ms
step:365/1405 train_time:48396ms step_avg:136.33ms
step:366/1405 train_time:48534ms step_avg:136.33ms
step:367/1405 train_time:48674ms step_avg:136.34ms
step:368/1405 train_time:48813ms step_avg:136.35ms
step:369/1405 train_time:48953ms step_avg:136.36ms
step:370/1405 train_time:49093ms step_avg:136.37ms
step:371/1405 train_time:49232ms step_avg:136.38ms
step:372/1405 train_time:49372ms step_avg:136.39ms
step:373/1405 train_time:49511ms step_avg:136.39ms
step:374/1405 train_time:49651ms step_avg:136.40ms
step:375/1405 train_time:49790ms step_avg:136.41ms
step:375/1405 val_loss:3.7874 train_time:49856ms step_avg:136.59ms
step:376/1405 train_time:49932ms step_avg:136.43ms
step:377/1405 train_time:50074ms step_avg:136.44ms
step:378/1405 train_time:50214ms step_avg:136.45ms
step:379/1405 train_time:50353ms step_avg:136.46ms
step:380/1405 train_time:50492ms step_avg:136.46ms
step:381/1405 train_time:50679ms step_avg:136.60ms
step:382/1405 train_time:50817ms step_avg:136.61ms
step:383/1405 train_time:50957ms step_avg:136.61ms
step:384/1405 train_time:51095ms step_avg:136.62ms
step:385/1405 train_time:51234ms step_avg:136.62ms
step:386/1405 train_time:51372ms step_avg:136.63ms
step:387/1405 train_time:51513ms step_avg:136.64ms
step:388/1405 train_time:51655ms step_avg:136.65ms
step:389/1405 train_time:51794ms step_avg:136.66ms
step:390/1405 train_time:51935ms step_avg:136.67ms
step:391/1405 train_time:52073ms step_avg:136.67ms
step:392/1405 train_time:52211ms step_avg:136.68ms
step:393/1405 train_time:52350ms step_avg:136.68ms
step:394/1405 train_time:52489ms step_avg:136.69ms
step:395/1405 train_time:52630ms step_avg:136.70ms
step:396/1405 train_time:52770ms step_avg:136.71ms
step:397/1405 train_time:52910ms step_avg:136.72ms
step:398/1405 train_time:53050ms step_avg:136.73ms
step:399/1405 train_time:53189ms step_avg:136.73ms
step:400/1405 train_time:53330ms step_avg:136.74ms
step:401/1405 train_time:53468ms step_avg:136.75ms
step:402/1405 train_time:53608ms step_avg:136.75ms
step:403/1405 train_time:53748ms step_avg:136.76ms
step:404/1405 train_time:53888ms step_avg:136.77ms
step:405/1405 train_time:54027ms step_avg:136.78ms
step:406/1405 train_time:54166ms step_avg:136.78ms
step:407/1405 train_time:54305ms step_avg:136.79ms
step:408/1405 train_time:54444ms step_avg:136.79ms
step:409/1405 train_time:54585ms step_avg:136.80ms
step:410/1405 train_time:54725ms step_avg:136.81ms
step:411/1405 train_time:54865ms step_avg:136.82ms
step:412/1405 train_time:55005ms step_avg:136.83ms
step:413/1405 train_time:55144ms step_avg:136.83ms
step:414/1405 train_time:55284ms step_avg:136.84ms
step:415/1405 train_time:55424ms step_avg:136.85ms
step:416/1405 train_time:55564ms step_avg:136.86ms
step:417/1405 train_time:55703ms step_avg:136.86ms
step:418/1405 train_time:55843ms step_avg:136.87ms
step:419/1405 train_time:55984ms step_avg:136.88ms
step:420/1405 train_time:56124ms step_avg:136.89ms
step:421/1405 train_time:56264ms step_avg:136.90ms
step:422/1405 train_time:56404ms step_avg:136.90ms
step:423/1405 train_time:56545ms step_avg:136.91ms
step:424/1405 train_time:56685ms step_avg:136.92ms
step:425/1405 train_time:56825ms step_avg:136.93ms
step:426/1405 train_time:56965ms step_avg:136.94ms
step:427/1405 train_time:57105ms step_avg:136.94ms
step:428/1405 train_time:57245ms step_avg:136.95ms
step:429/1405 train_time:57386ms step_avg:136.96ms
step:430/1405 train_time:57526ms step_avg:136.97ms
step:431/1405 train_time:57666ms step_avg:136.97ms
step:432/1405 train_time:57807ms step_avg:136.98ms
step:433/1405 train_time:57947ms step_avg:136.99ms
step:434/1405 train_time:58088ms step_avg:137.00ms
step:435/1405 train_time:58228ms step_avg:137.01ms
step:436/1405 train_time:58368ms step_avg:137.01ms
step:437/1405 train_time:58509ms step_avg:137.02ms
step:438/1405 train_time:58649ms step_avg:137.03ms
step:439/1405 train_time:58789ms step_avg:137.04ms
step:440/1405 train_time:58930ms step_avg:137.05ms
step:441/1405 train_time:59071ms step_avg:137.05ms
step:442/1405 train_time:59211ms step_avg:137.06ms
step:443/1405 train_time:59352ms step_avg:137.07ms
step:444/1405 train_time:59493ms step_avg:137.08ms
step:445/1405 train_time:59633ms step_avg:137.09ms
step:446/1405 train_time:59773ms step_avg:137.09ms
step:447/1405 train_time:59914ms step_avg:137.10ms
step:448/1405 train_time:60055ms step_avg:137.11ms
step:449/1405 train_time:60196ms step_avg:137.12ms
step:450/1405 train_time:60336ms step_avg:137.13ms
step:451/1405 train_time:60476ms step_avg:137.13ms
step:452/1405 train_time:60615ms step_avg:137.14ms
step:453/1405 train_time:60756ms step_avg:137.15ms
step:454/1405 train_time:60895ms step_avg:137.15ms
step:455/1405 train_time:61034ms step_avg:137.16ms
step:456/1405 train_time:61174ms step_avg:137.16ms
step:457/1405 train_time:61315ms step_avg:137.17ms
step:458/1405 train_time:61456ms step_avg:137.18ms
step:459/1405 train_time:61595ms step_avg:137.18ms
step:460/1405 train_time:61736ms step_avg:137.19ms
step:461/1405 train_time:61876ms step_avg:137.20ms
step:462/1405 train_time:62017ms step_avg:137.21ms
step:463/1405 train_time:62156ms step_avg:137.21ms
step:464/1405 train_time:62297ms step_avg:137.22ms
step:465/1405 train_time:62436ms step_avg:137.22ms
step:466/1405 train_time:62575ms step_avg:137.23ms
step:467/1405 train_time:62715ms step_avg:137.23ms
step:468/1405 train_time:62855ms step_avg:137.24ms
step:469/1405 train_time:62995ms step_avg:137.24ms
step:470/1405 train_time:63136ms step_avg:137.25ms
step:471/1405 train_time:63276ms step_avg:137.26ms
step:472/1405 train_time:63416ms step_avg:137.26ms
step:473/1405 train_time:63556ms step_avg:137.27ms
step:474/1405 train_time:63696ms step_avg:137.28ms
step:475/1405 train_time:63836ms step_avg:137.28ms
step:476/1405 train_time:63976ms step_avg:137.29ms
step:477/1405 train_time:64116ms step_avg:137.29ms
step:478/1405 train_time:64255ms step_avg:137.30ms
step:479/1405 train_time:64394ms step_avg:137.30ms
step:480/1405 train_time:64534ms step_avg:137.31ms
step:481/1405 train_time:64675ms step_avg:137.31ms
step:482/1405 train_time:64814ms step_avg:137.32ms
step:483/1405 train_time:64956ms step_avg:137.33ms
step:484/1405 train_time:65096ms step_avg:137.33ms
step:485/1405 train_time:65236ms step_avg:137.34ms
step:486/1405 train_time:65376ms step_avg:137.34ms
step:487/1405 train_time:65517ms step_avg:137.35ms
step:488/1405 train_time:65657ms step_avg:137.36ms
step:489/1405 train_time:65796ms step_avg:137.36ms
step:490/1405 train_time:65937ms step_avg:137.37ms
step:491/1405 train_time:66078ms step_avg:137.38ms
step:492/1405 train_time:66217ms step_avg:137.38ms
step:493/1405 train_time:66357ms step_avg:137.39ms
step:494/1405 train_time:66497ms step_avg:137.39ms
step:495/1405 train_time:66637ms step_avg:137.40ms
step:496/1405 train_time:66777ms step_avg:137.40ms
step:497/1405 train_time:66916ms step_avg:137.40ms
step:498/1405 train_time:67057ms step_avg:137.41ms
step:499/1405 train_time:67197ms step_avg:137.42ms
step:500/1405 train_time:67337ms step_avg:137.42ms
step:500/1405 val_loss:3.6663 train_time:67403ms step_avg:137.56ms
step:501/1405 train_time:67479ms step_avg:137.43ms
step:502/1405 train_time:67621ms step_avg:137.44ms
step:503/1405 train_time:67761ms step_avg:137.45ms
step:504/1405 train_time:67900ms step_avg:137.45ms
step:505/1405 train_time:68040ms step_avg:137.45ms
step:506/1405 train_time:68179ms step_avg:137.46ms
step:507/1405 train_time:68318ms step_avg:137.46ms
step:508/1405 train_time:68459ms step_avg:137.47ms
step:509/1405 train_time:68601ms step_avg:137.48ms
step:510/1405 train_time:68743ms step_avg:137.49ms
step:511/1405 train_time:68884ms step_avg:137.49ms
step:512/1405 train_time:69023ms step_avg:137.50ms
step:513/1405 train_time:69163ms step_avg:137.50ms
step:514/1405 train_time:69301ms step_avg:137.50ms
step:515/1405 train_time:69441ms step_avg:137.51ms
step:516/1405 train_time:69582ms step_avg:137.51ms
step:517/1405 train_time:69724ms step_avg:137.52ms
step:518/1405 train_time:69864ms step_avg:137.53ms
step:519/1405 train_time:70005ms step_avg:137.53ms
step:520/1405 train_time:70145ms step_avg:137.54ms
step:521/1405 train_time:70284ms step_avg:137.54ms
step:522/1405 train_time:70424ms step_avg:137.55ms
step:523/1405 train_time:70568ms step_avg:137.56ms
step:524/1405 train_time:70709ms step_avg:137.57ms
step:525/1405 train_time:70852ms step_avg:137.58ms
step:526/1405 train_time:70994ms step_avg:137.59ms
step:527/1405 train_time:71136ms step_avg:137.59ms
step:528/1405 train_time:71277ms step_avg:137.60ms
step:529/1405 train_time:71419ms step_avg:137.61ms
step:530/1405 train_time:71561ms step_avg:137.62ms
step:531/1405 train_time:71704ms step_avg:137.63ms
step:532/1405 train_time:71847ms step_avg:137.64ms
step:533/1405 train_time:71990ms step_avg:137.65ms
step:534/1405 train_time:72132ms step_avg:137.66ms
step:535/1405 train_time:72273ms step_avg:137.66ms
step:536/1405 train_time:72415ms step_avg:137.67ms
step:537/1405 train_time:72556ms step_avg:137.68ms
step:538/1405 train_time:72698ms step_avg:137.69ms
step:539/1405 train_time:72842ms step_avg:137.70ms
step:540/1405 train_time:72985ms step_avg:137.71ms
step:541/1405 train_time:73127ms step_avg:137.72ms
step:542/1405 train_time:73269ms step_avg:137.72ms
step:543/1405 train_time:73412ms step_avg:137.73ms
step:544/1405 train_time:73554ms step_avg:137.74ms
step:545/1405 train_time:73697ms step_avg:137.75ms
step:546/1405 train_time:73839ms step_avg:137.76ms
step:547/1405 train_time:73981ms step_avg:137.77ms
step:548/1405 train_time:74123ms step_avg:137.78ms
step:549/1405 train_time:74265ms step_avg:137.78ms
step:550/1405 train_time:74408ms step_avg:137.79ms
step:551/1405 train_time:74550ms step_avg:137.80ms
step:552/1405 train_time:74692ms step_avg:137.81ms
step:553/1405 train_time:74835ms step_avg:137.82ms
step:554/1405 train_time:74977ms step_avg:137.82ms
step:555/1405 train_time:75119ms step_avg:137.83ms
step:556/1405 train_time:75263ms step_avg:137.84ms
step:557/1405 train_time:75405ms step_avg:137.85ms
step:558/1405 train_time:75548ms step_avg:137.86ms
step:559/1405 train_time:75690ms step_avg:137.87ms
step:560/1405 train_time:75831ms step_avg:137.88ms
step:561/1405 train_time:75974ms step_avg:137.88ms
step:562/1405 train_time:76116ms step_avg:137.89ms
step:563/1405 train_time:76259ms step_avg:137.90ms
step:564/1405 train_time:76401ms step_avg:137.91ms
step:565/1405 train_time:76543ms step_avg:137.91ms
step:566/1405 train_time:76684ms step_avg:137.92ms
step:567/1405 train_time:76827ms step_avg:137.93ms
step:568/1405 train_time:76969ms step_avg:137.94ms
step:569/1405 train_time:77112ms step_avg:137.95ms
step:570/1405 train_time:77254ms step_avg:137.95ms
step:571/1405 train_time:77442ms step_avg:138.04ms
step:572/1405 train_time:77584ms step_avg:138.05ms
step:573/1405 train_time:77726ms step_avg:138.06ms
step:574/1405 train_time:77868ms step_avg:138.06ms
step:575/1405 train_time:78011ms step_avg:138.07ms
step:576/1405 train_time:78153ms step_avg:138.08ms
step:577/1405 train_time:78297ms step_avg:138.09ms
step:578/1405 train_time:78440ms step_avg:138.10ms
step:579/1405 train_time:78582ms step_avg:138.11ms
step:580/1405 train_time:78724ms step_avg:138.11ms
step:581/1405 train_time:78866ms step_avg:138.12ms
step:582/1405 train_time:79008ms step_avg:138.13ms
step:583/1405 train_time:79150ms step_avg:138.13ms
step:584/1405 train_time:79293ms step_avg:138.14ms
step:585/1405 train_time:79436ms step_avg:138.15ms
step:586/1405 train_time:79577ms step_avg:138.15ms
step:587/1405 train_time:79719ms step_avg:138.16ms
step:588/1405 train_time:79861ms step_avg:138.17ms
step:589/1405 train_time:80002ms step_avg:138.17ms
step:590/1405 train_time:80145ms step_avg:138.18ms
step:591/1405 train_time:80287ms step_avg:138.19ms
step:592/1405 train_time:80431ms step_avg:138.20ms
step:593/1405 train_time:80574ms step_avg:138.21ms
step:594/1405 train_time:80716ms step_avg:138.21ms
step:595/1405 train_time:80858ms step_avg:138.22ms
step:596/1405 train_time:81000ms step_avg:138.23ms
step:597/1405 train_time:81142ms step_avg:138.23ms
step:598/1405 train_time:81284ms step_avg:138.24ms
step:599/1405 train_time:81427ms step_avg:138.25ms
step:600/1405 train_time:81570ms step_avg:138.25ms
step:601/1405 train_time:81713ms step_avg:138.26ms
step:602/1405 train_time:81855ms step_avg:138.27ms
step:603/1405 train_time:81998ms step_avg:138.28ms
step:604/1405 train_time:82140ms step_avg:138.28ms
step:605/1405 train_time:82282ms step_avg:138.29ms
step:606/1405 train_time:82424ms step_avg:138.30ms
step:607/1405 train_time:82566ms step_avg:138.30ms
step:608/1405 train_time:82709ms step_avg:138.31ms
step:609/1405 train_time:82851ms step_avg:138.32ms
step:610/1405 train_time:82993ms step_avg:138.32ms
step:611/1405 train_time:83135ms step_avg:138.33ms
step:612/1405 train_time:83277ms step_avg:138.33ms
step:613/1405 train_time:83419ms step_avg:138.34ms
step:614/1405 train_time:83561ms step_avg:138.35ms
step:615/1405 train_time:83704ms step_avg:138.35ms
step:616/1405 train_time:83846ms step_avg:138.36ms
step:617/1405 train_time:83988ms step_avg:138.37ms
step:618/1405 train_time:84130ms step_avg:138.37ms
step:619/1405 train_time:84273ms step_avg:138.38ms
step:620/1405 train_time:84416ms step_avg:138.39ms
step:621/1405 train_time:84558ms step_avg:138.39ms
step:622/1405 train_time:84700ms step_avg:138.40ms
step:623/1405 train_time:84842ms step_avg:138.40ms
step:624/1405 train_time:84985ms step_avg:138.41ms
step:625/1405 train_time:85127ms step_avg:138.42ms
step:625/1405 val_loss:3.5839 train_time:85195ms step_avg:138.53ms
step:626/1405 train_time:85271ms step_avg:138.43ms
step:627/1405 train_time:85415ms step_avg:138.44ms
step:628/1405 train_time:85558ms step_avg:138.44ms
step:629/1405 train_time:85700ms step_avg:138.45ms
step:630/1405 train_time:85842ms step_avg:138.45ms
step:631/1405 train_time:85983ms step_avg:138.46ms
step:632/1405 train_time:86125ms step_avg:138.47ms
step:633/1405 train_time:86269ms step_avg:138.47ms
step:634/1405 train_time:86412ms step_avg:138.48ms
step:635/1405 train_time:86554ms step_avg:138.49ms
step:636/1405 train_time:86697ms step_avg:138.49ms
step:637/1405 train_time:86839ms step_avg:138.50ms
step:638/1405 train_time:86980ms step_avg:138.50ms
step:639/1405 train_time:87122ms step_avg:138.51ms
step:640/1405 train_time:87265ms step_avg:138.52ms
step:641/1405 train_time:87410ms step_avg:138.53ms
step:642/1405 train_time:87552ms step_avg:138.53ms
step:643/1405 train_time:87695ms step_avg:138.54ms
step:644/1405 train_time:87837ms step_avg:138.54ms
step:645/1405 train_time:87979ms step_avg:138.55ms
step:646/1405 train_time:88121ms step_avg:138.55ms
step:647/1405 train_time:88263ms step_avg:138.56ms
step:648/1405 train_time:88407ms step_avg:138.57ms
step:649/1405 train_time:88549ms step_avg:138.57ms
step:650/1405 train_time:88692ms step_avg:138.58ms
step:651/1405 train_time:88835ms step_avg:138.59ms
step:652/1405 train_time:88978ms step_avg:138.59ms
step:653/1405 train_time:89119ms step_avg:138.60ms
step:654/1405 train_time:89264ms step_avg:138.61ms
step:655/1405 train_time:89406ms step_avg:138.61ms
step:656/1405 train_time:89549ms step_avg:138.62ms
step:657/1405 train_time:89692ms step_avg:138.63ms
step:658/1405 train_time:89834ms step_avg:138.63ms
step:659/1405 train_time:89977ms step_avg:138.64ms
step:660/1405 train_time:90120ms step_avg:138.65ms
step:661/1405 train_time:90264ms step_avg:138.65ms
step:662/1405 train_time:90406ms step_avg:138.66ms
step:663/1405 train_time:90549ms step_avg:138.67ms
step:664/1405 train_time:90692ms step_avg:138.67ms
step:665/1405 train_time:90834ms step_avg:138.68ms
step:666/1405 train_time:90977ms step_avg:138.68ms
step:667/1405 train_time:91120ms step_avg:138.69ms
step:668/1405 train_time:91263ms step_avg:138.70ms
step:669/1405 train_time:91407ms step_avg:138.71ms
step:670/1405 train_time:91550ms step_avg:138.71ms
step:671/1405 train_time:91694ms step_avg:138.72ms
step:672/1405 train_time:91836ms step_avg:138.73ms
step:673/1405 train_time:91981ms step_avg:138.73ms
step:674/1405 train_time:92122ms step_avg:138.74ms
step:675/1405 train_time:92265ms step_avg:138.75ms
step:676/1405 train_time:92408ms step_avg:138.75ms
step:677/1405 train_time:92551ms step_avg:138.76ms
step:678/1405 train_time:92693ms step_avg:138.76ms
step:679/1405 train_time:92835ms step_avg:138.77ms
step:680/1405 train_time:92978ms step_avg:138.77ms
step:681/1405 train_time:93121ms step_avg:138.78ms
step:682/1405 train_time:93263ms step_avg:138.78ms
step:683/1405 train_time:93407ms step_avg:138.79ms
step:684/1405 train_time:93549ms step_avg:138.80ms
step:685/1405 train_time:93693ms step_avg:138.80ms
step:686/1405 train_time:93835ms step_avg:138.81ms
step:687/1405 train_time:93978ms step_avg:138.82ms
step:688/1405 train_time:94121ms step_avg:138.82ms
step:689/1405 train_time:94265ms step_avg:138.83ms
step:690/1405 train_time:94409ms step_avg:138.84ms
step:691/1405 train_time:94551ms step_avg:138.84ms
step:692/1405 train_time:94694ms step_avg:138.85ms
step:693/1405 train_time:94836ms step_avg:138.85ms
step:694/1405 train_time:94981ms step_avg:138.86ms
step:695/1405 train_time:95123ms step_avg:138.87ms
step:696/1405 train_time:95265ms step_avg:138.87ms
step:697/1405 train_time:95409ms step_avg:138.88ms
step:698/1405 train_time:95552ms step_avg:138.88ms
step:699/1405 train_time:95694ms step_avg:138.89ms
step:700/1405 train_time:95838ms step_avg:138.90ms
step:701/1405 train_time:95980ms step_avg:138.90ms
step:702/1405 train_time:96122ms step_avg:138.90ms
step:703/1405 train_time:96265ms step_avg:138.91ms
step:704/1405 train_time:96408ms step_avg:138.92ms
step:705/1405 train_time:96551ms step_avg:138.92ms
step:706/1405 train_time:96695ms step_avg:138.93ms
step:707/1405 train_time:96837ms step_avg:138.93ms
step:708/1405 train_time:96979ms step_avg:138.94ms
step:709/1405 train_time:97121ms step_avg:138.94ms
step:710/1405 train_time:97263ms step_avg:138.95ms
step:711/1405 train_time:97407ms step_avg:138.95ms
step:712/1405 train_time:97550ms step_avg:138.96ms
step:713/1405 train_time:97693ms step_avg:138.97ms
step:714/1405 train_time:97836ms step_avg:138.97ms
step:715/1405 train_time:97980ms step_avg:138.98ms
step:716/1405 train_time:98124ms step_avg:138.99ms
step:717/1405 train_time:98266ms step_avg:138.99ms
step:718/1405 train_time:98408ms step_avg:138.99ms
step:719/1405 train_time:98550ms step_avg:139.00ms
step:720/1405 train_time:98693ms step_avg:139.00ms
step:721/1405 train_time:98836ms step_avg:139.01ms
step:722/1405 train_time:98979ms step_avg:139.02ms
step:723/1405 train_time:99122ms step_avg:139.02ms
step:724/1405 train_time:99265ms step_avg:139.03ms
step:725/1405 train_time:99408ms step_avg:139.03ms
step:726/1405 train_time:99550ms step_avg:139.04ms
step:727/1405 train_time:99693ms step_avg:139.04ms
step:728/1405 train_time:99836ms step_avg:139.05ms
step:729/1405 train_time:99979ms step_avg:139.05ms
step:730/1405 train_time:100122ms step_avg:139.06ms
step:731/1405 train_time:100267ms step_avg:139.07ms
step:732/1405 train_time:100411ms step_avg:139.07ms
step:733/1405 train_time:100555ms step_avg:139.08ms
step:734/1405 train_time:100700ms step_avg:139.09ms
step:735/1405 train_time:100845ms step_avg:139.10ms
step:736/1405 train_time:100988ms step_avg:139.10ms
step:737/1405 train_time:101133ms step_avg:139.11ms
step:738/1405 train_time:101278ms step_avg:139.12ms
step:739/1405 train_time:101424ms step_avg:139.13ms
step:740/1405 train_time:101568ms step_avg:139.13ms
step:741/1405 train_time:101712ms step_avg:139.14ms
step:742/1405 train_time:101857ms step_avg:139.15ms
step:743/1405 train_time:102001ms step_avg:139.16ms
step:744/1405 train_time:102146ms step_avg:139.16ms
step:745/1405 train_time:102291ms step_avg:139.17ms
step:746/1405 train_time:102436ms step_avg:139.18ms
step:747/1405 train_time:102581ms step_avg:139.19ms
step:748/1405 train_time:102725ms step_avg:139.19ms
step:749/1405 train_time:102870ms step_avg:139.20ms
step:750/1405 train_time:103014ms step_avg:139.21ms
step:750/1405 val_loss:3.5312 train_time:103084ms step_avg:139.30ms
step:751/1405 train_time:103162ms step_avg:139.22ms
step:752/1405 train_time:103308ms step_avg:139.23ms
step:753/1405 train_time:103452ms step_avg:139.24ms
step:754/1405 train_time:103595ms step_avg:139.24ms
step:755/1405 train_time:103739ms step_avg:139.25ms
step:756/1405 train_time:103884ms step_avg:139.25ms
step:757/1405 train_time:104028ms step_avg:139.26ms
step:758/1405 train_time:104173ms step_avg:139.27ms
step:759/1405 train_time:104318ms step_avg:139.28ms
step:760/1405 train_time:104463ms step_avg:139.28ms
step:761/1405 train_time:104655ms step_avg:139.35ms
step:762/1405 train_time:104798ms step_avg:139.36ms
step:763/1405 train_time:104942ms step_avg:139.37ms
step:764/1405 train_time:105087ms step_avg:139.37ms
step:765/1405 train_time:105231ms step_avg:139.38ms
step:766/1405 train_time:105374ms step_avg:139.38ms
step:767/1405 train_time:105519ms step_avg:139.39ms
step:768/1405 train_time:105668ms step_avg:139.40ms
step:769/1405 train_time:105811ms step_avg:139.41ms
step:770/1405 train_time:105956ms step_avg:139.42ms
step:771/1405 train_time:106100ms step_avg:139.42ms
step:772/1405 train_time:106245ms step_avg:139.43ms
step:773/1405 train_time:106390ms step_avg:139.44ms
step:774/1405 train_time:106534ms step_avg:139.44ms
step:775/1405 train_time:106679ms step_avg:139.45ms
step:776/1405 train_time:106825ms step_avg:139.46ms
step:777/1405 train_time:106970ms step_avg:139.47ms
step:778/1405 train_time:107114ms step_avg:139.47ms
step:779/1405 train_time:107258ms step_avg:139.48ms
step:780/1405 train_time:107403ms step_avg:139.48ms
step:781/1405 train_time:107548ms step_avg:139.49ms
step:782/1405 train_time:107694ms step_avg:139.50ms
step:783/1405 train_time:107838ms step_avg:139.51ms
step:784/1405 train_time:107983ms step_avg:139.51ms
step:785/1405 train_time:108127ms step_avg:139.52ms
step:786/1405 train_time:108271ms step_avg:139.52ms
step:787/1405 train_time:108415ms step_avg:139.53ms
step:788/1405 train_time:108560ms step_avg:139.54ms
step:789/1405 train_time:108705ms step_avg:139.54ms
step:790/1405 train_time:108850ms step_avg:139.55ms
step:791/1405 train_time:108994ms step_avg:139.56ms
step:792/1405 train_time:109139ms step_avg:139.56ms
step:793/1405 train_time:109283ms step_avg:139.57ms
step:794/1405 train_time:109428ms step_avg:139.58ms
step:795/1405 train_time:109573ms step_avg:139.58ms
step:796/1405 train_time:109718ms step_avg:139.59ms
step:797/1405 train_time:109863ms step_avg:139.60ms
step:798/1405 train_time:110009ms step_avg:139.61ms
step:799/1405 train_time:110153ms step_avg:139.61ms
step:800/1405 train_time:110298ms step_avg:139.62ms
step:801/1405 train_time:110443ms step_avg:139.62ms
step:802/1405 train_time:110587ms step_avg:139.63ms
step:803/1405 train_time:110731ms step_avg:139.64ms
step:804/1405 train_time:110875ms step_avg:139.64ms
step:805/1405 train_time:111020ms step_avg:139.65ms
step:806/1405 train_time:111165ms step_avg:139.65ms
step:807/1405 train_time:111309ms step_avg:139.66ms
step:808/1405 train_time:111453ms step_avg:139.67ms
step:809/1405 train_time:111597ms step_avg:139.67ms
step:810/1405 train_time:111743ms step_avg:139.68ms
step:811/1405 train_time:111888ms step_avg:139.69ms
step:812/1405 train_time:112033ms step_avg:139.69ms
step:813/1405 train_time:112177ms step_avg:139.70ms
step:814/1405 train_time:112322ms step_avg:139.70ms
step:815/1405 train_time:112467ms step_avg:139.71ms
step:816/1405 train_time:112611ms step_avg:139.72ms
step:817/1405 train_time:112755ms step_avg:139.72ms
step:818/1405 train_time:112899ms step_avg:139.73ms
step:819/1405 train_time:113044ms step_avg:139.73ms
step:820/1405 train_time:113188ms step_avg:139.74ms
step:821/1405 train_time:113332ms step_avg:139.74ms
step:822/1405 train_time:113476ms step_avg:139.75ms
step:823/1405 train_time:113623ms step_avg:139.76ms
step:824/1405 train_time:113767ms step_avg:139.76ms
step:825/1405 train_time:113911ms step_avg:139.77ms
step:826/1405 train_time:114056ms step_avg:139.78ms
step:827/1405 train_time:114201ms step_avg:139.78ms
step:828/1405 train_time:114346ms step_avg:139.79ms
step:829/1405 train_time:114491ms step_avg:139.79ms
step:830/1405 train_time:114636ms step_avg:139.80ms
step:831/1405 train_time:114781ms step_avg:139.81ms
step:832/1405 train_time:114925ms step_avg:139.81ms
step:833/1405 train_time:115070ms step_avg:139.82ms
step:834/1405 train_time:115214ms step_avg:139.82ms
step:835/1405 train_time:115359ms step_avg:139.83ms
step:836/1405 train_time:115504ms step_avg:139.84ms
step:837/1405 train_time:115650ms step_avg:139.84ms
step:838/1405 train_time:115795ms step_avg:139.85ms
step:839/1405 train_time:115939ms step_avg:139.85ms
step:840/1405 train_time:116085ms step_avg:139.86ms
step:841/1405 train_time:116230ms step_avg:139.87ms
step:842/1405 train_time:116376ms step_avg:139.87ms
step:843/1405 train_time:116521ms step_avg:139.88ms
step:844/1405 train_time:116665ms step_avg:139.89ms
step:845/1405 train_time:116809ms step_avg:139.89ms
step:846/1405 train_time:116955ms step_avg:139.90ms
step:847/1405 train_time:117100ms step_avg:139.90ms
step:848/1405 train_time:117245ms step_avg:139.91ms
step:849/1405 train_time:117390ms step_avg:139.92ms
step:850/1405 train_time:117536ms step_avg:139.92ms
step:851/1405 train_time:117681ms step_avg:139.93ms
step:852/1405 train_time:117828ms step_avg:139.94ms
step:853/1405 train_time:117972ms step_avg:139.94ms
step:854/1405 train_time:118117ms step_avg:139.95ms
step:855/1405 train_time:118261ms step_avg:139.95ms
step:856/1405 train_time:118406ms step_avg:139.96ms
step:857/1405 train_time:118552ms step_avg:139.97ms
step:858/1405 train_time:118697ms step_avg:139.97ms
step:859/1405 train_time:118844ms step_avg:139.98ms
step:860/1405 train_time:118988ms step_avg:139.99ms
step:861/1405 train_time:119133ms step_avg:139.99ms
step:862/1405 train_time:119277ms step_avg:140.00ms
step:863/1405 train_time:119421ms step_avg:140.00ms
step:864/1405 train_time:119567ms step_avg:140.01ms
step:865/1405 train_time:119713ms step_avg:140.01ms
step:866/1405 train_time:119859ms step_avg:140.02ms
step:867/1405 train_time:120006ms step_avg:140.03ms
step:868/1405 train_time:120150ms step_avg:140.04ms
step:869/1405 train_time:120295ms step_avg:140.04ms
step:870/1405 train_time:120441ms step_avg:140.05ms
step:871/1405 train_time:120585ms step_avg:140.05ms
step:872/1405 train_time:120730ms step_avg:140.06ms
step:873/1405 train_time:120875ms step_avg:140.06ms
step:874/1405 train_time:121020ms step_avg:140.07ms
step:875/1405 train_time:121167ms step_avg:140.08ms
step:875/1405 val_loss:3.4792 train_time:121236ms step_avg:140.16ms
step:876/1405 train_time:121312ms step_avg:140.08ms
step:877/1405 train_time:121458ms step_avg:140.09ms
step:878/1405 train_time:121603ms step_avg:140.10ms
step:879/1405 train_time:121748ms step_avg:140.10ms
step:880/1405 train_time:121891ms step_avg:140.10ms
step:881/1405 train_time:122034ms step_avg:140.11ms
step:882/1405 train_time:122179ms step_avg:140.11ms
step:883/1405 train_time:122326ms step_avg:140.12ms
step:884/1405 train_time:122472ms step_avg:140.13ms
step:885/1405 train_time:122618ms step_avg:140.14ms
step:886/1405 train_time:122763ms step_avg:140.14ms
step:887/1405 train_time:122907ms step_avg:140.14ms
step:888/1405 train_time:123052ms step_avg:140.15ms
step:889/1405 train_time:123197ms step_avg:140.16ms
step:890/1405 train_time:123342ms step_avg:140.16ms
step:891/1405 train_time:123489ms step_avg:140.17ms
step:892/1405 train_time:123634ms step_avg:140.17ms
step:893/1405 train_time:123778ms step_avg:140.18ms
step:894/1405 train_time:123923ms step_avg:140.18ms
step:895/1405 train_time:124069ms step_avg:140.19ms
step:896/1405 train_time:124213ms step_avg:140.19ms
step:897/1405 train_time:124358ms step_avg:140.20ms
step:898/1405 train_time:124504ms step_avg:140.21ms
step:899/1405 train_time:124650ms step_avg:140.21ms
step:900/1405 train_time:124796ms step_avg:140.22ms
step:901/1405 train_time:124941ms step_avg:140.23ms
step:902/1405 train_time:125086ms step_avg:140.23ms
step:903/1405 train_time:125231ms step_avg:140.24ms
step:904/1405 train_time:125375ms step_avg:140.24ms
step:905/1405 train_time:125520ms step_avg:140.25ms
step:906/1405 train_time:125665ms step_avg:140.25ms
step:907/1405 train_time:125811ms step_avg:140.26ms
step:908/1405 train_time:125955ms step_avg:140.26ms
step:909/1405 train_time:126100ms step_avg:140.27ms
step:910/1405 train_time:126248ms step_avg:140.28ms
step:911/1405 train_time:126392ms step_avg:140.28ms
step:912/1405 train_time:126537ms step_avg:140.28ms
step:913/1405 train_time:126682ms step_avg:140.29ms
step:914/1405 train_time:126828ms step_avg:140.30ms
step:915/1405 train_time:126973ms step_avg:140.30ms
step:916/1405 train_time:127118ms step_avg:140.31ms
step:917/1405 train_time:127263ms step_avg:140.31ms
step:918/1405 train_time:127409ms step_avg:140.32ms
step:919/1405 train_time:127555ms step_avg:140.32ms
step:920/1405 train_time:127700ms step_avg:140.33ms
step:921/1405 train_time:127846ms step_avg:140.34ms
step:922/1405 train_time:127991ms step_avg:140.34ms
step:923/1405 train_time:128134ms step_avg:140.34ms
step:924/1405 train_time:128278ms step_avg:140.35ms
step:925/1405 train_time:128424ms step_avg:140.35ms
step:926/1405 train_time:128570ms step_avg:140.36ms
step:927/1405 train_time:128715ms step_avg:140.36ms
step:928/1405 train_time:128859ms step_avg:140.37ms
step:929/1405 train_time:129004ms step_avg:140.37ms
step:930/1405 train_time:129149ms step_avg:140.38ms
step:931/1405 train_time:129293ms step_avg:140.38ms
step:932/1405 train_time:129438ms step_avg:140.39ms
step:933/1405 train_time:129584ms step_avg:140.39ms
step:934/1405 train_time:129730ms step_avg:140.40ms
step:935/1405 train_time:129874ms step_avg:140.40ms
step:936/1405 train_time:130018ms step_avg:140.41ms
step:937/1405 train_time:130163ms step_avg:140.41ms
step:938/1405 train_time:130310ms step_avg:140.42ms
step:939/1405 train_time:130458ms step_avg:140.43ms
step:940/1405 train_time:130606ms step_avg:140.44ms
step:941/1405 train_time:130753ms step_avg:140.44ms
step:942/1405 train_time:130898ms step_avg:140.45ms
step:943/1405 train_time:131045ms step_avg:140.46ms
step:944/1405 train_time:131192ms step_avg:140.46ms
step:945/1405 train_time:131339ms step_avg:140.47ms
step:946/1405 train_time:131486ms step_avg:140.48ms
step:947/1405 train_time:131633ms step_avg:140.48ms
step:948/1405 train_time:131780ms step_avg:140.49ms
step:949/1405 train_time:131928ms step_avg:140.50ms
step:950/1405 train_time:132074ms step_avg:140.50ms
step:951/1405 train_time:132267ms step_avg:140.56ms
step:952/1405 train_time:132413ms step_avg:140.57ms
step:953/1405 train_time:132559ms step_avg:140.57ms
step:954/1405 train_time:132706ms step_avg:140.58ms
step:955/1405 train_time:132851ms step_avg:140.58ms
step:956/1405 train_time:132998ms step_avg:140.59ms
step:957/1405 train_time:133144ms step_avg:140.60ms
step:958/1405 train_time:133292ms step_avg:140.60ms
step:959/1405 train_time:133439ms step_avg:140.61ms
step:960/1405 train_time:133587ms step_avg:140.62ms
step:961/1405 train_time:133733ms step_avg:140.62ms
step:962/1405 train_time:133878ms step_avg:140.63ms
step:963/1405 train_time:134027ms step_avg:140.64ms
step:964/1405 train_time:134174ms step_avg:140.64ms
step:965/1405 train_time:134319ms step_avg:140.65ms
step:966/1405 train_time:134467ms step_avg:140.66ms
step:967/1405 train_time:134612ms step_avg:140.66ms
step:968/1405 train_time:134758ms step_avg:140.67ms
step:969/1405 train_time:134906ms step_avg:140.67ms
step:970/1405 train_time:135052ms step_avg:140.68ms
step:971/1405 train_time:135199ms step_avg:140.69ms
step:972/1405 train_time:135346ms step_avg:140.69ms
step:973/1405 train_time:135493ms step_avg:140.70ms
step:974/1405 train_time:135640ms step_avg:140.71ms
step:975/1405 train_time:135787ms step_avg:140.71ms
step:976/1405 train_time:135932ms step_avg:140.72ms
step:977/1405 train_time:136078ms step_avg:140.72ms
step:978/1405 train_time:136225ms step_avg:140.73ms
step:979/1405 train_time:136371ms step_avg:140.73ms
step:980/1405 train_time:136517ms step_avg:140.74ms
step:981/1405 train_time:136663ms step_avg:140.74ms
step:982/1405 train_time:136810ms step_avg:140.75ms
step:983/1405 train_time:136956ms step_avg:140.76ms
step:984/1405 train_time:137103ms step_avg:140.76ms
step:985/1405 train_time:137250ms step_avg:140.77ms
step:986/1405 train_time:137398ms step_avg:140.78ms
step:987/1405 train_time:137546ms step_avg:140.78ms
step:988/1405 train_time:137692ms step_avg:140.79ms
step:989/1405 train_time:137839ms step_avg:140.80ms
step:990/1405 train_time:137986ms step_avg:140.80ms
step:991/1405 train_time:138133ms step_avg:140.81ms
step:992/1405 train_time:138280ms step_avg:140.82ms
step:993/1405 train_time:138429ms step_avg:140.82ms
step:994/1405 train_time:138575ms step_avg:140.83ms
step:995/1405 train_time:138722ms step_avg:140.83ms
step:996/1405 train_time:138869ms step_avg:140.84ms
step:997/1405 train_time:139015ms step_avg:140.85ms
step:998/1405 train_time:139160ms step_avg:140.85ms
step:999/1405 train_time:139307ms step_avg:140.86ms
step:1000/1405 train_time:139453ms step_avg:140.86ms
step:1000/1405 val_loss:3.4137 train_time:139523ms step_avg:140.93ms
step:1001/1405 train_time:139600ms step_avg:140.87ms
step:1002/1405 train_time:139745ms step_avg:140.87ms
step:1003/1405 train_time:139893ms step_avg:140.88ms
step:1004/1405 train_time:140039ms step_avg:140.88ms
step:1005/1405 train_time:140185ms step_avg:140.89ms
step:1006/1405 train_time:140330ms step_avg:140.89ms
step:1007/1405 train_time:140476ms step_avg:140.90ms
step:1008/1405 train_time:140625ms step_avg:140.91ms
step:1009/1405 train_time:140775ms step_avg:140.92ms
step:1010/1405 train_time:140921ms step_avg:140.92ms
step:1011/1405 train_time:141068ms step_avg:140.93ms
step:1012/1405 train_time:141214ms step_avg:140.93ms
step:1013/1405 train_time:141359ms step_avg:140.94ms
step:1014/1405 train_time:141505ms step_avg:140.94ms
step:1015/1405 train_time:141652ms step_avg:140.95ms
step:1016/1405 train_time:141802ms step_avg:140.96ms
step:1017/1405 train_time:141947ms step_avg:140.96ms
step:1018/1405 train_time:142095ms step_avg:140.97ms
step:1019/1405 train_time:142240ms step_avg:140.97ms
step:1020/1405 train_time:142387ms step_avg:140.98ms
step:1021/1405 train_time:142534ms step_avg:140.98ms
step:1022/1405 train_time:142679ms step_avg:140.99ms
step:1023/1405 train_time:142826ms step_avg:140.99ms
step:1024/1405 train_time:142974ms step_avg:141.00ms
step:1025/1405 train_time:143121ms step_avg:141.01ms
step:1026/1405 train_time:143268ms step_avg:141.01ms
step:1027/1405 train_time:143414ms step_avg:141.02ms
step:1028/1405 train_time:143560ms step_avg:141.02ms
step:1029/1405 train_time:143708ms step_avg:141.03ms
step:1030/1405 train_time:143856ms step_avg:141.04ms
step:1031/1405 train_time:144000ms step_avg:141.04ms
step:1032/1405 train_time:144147ms step_avg:141.04ms
step:1033/1405 train_time:144295ms step_avg:141.05ms
step:1034/1405 train_time:144441ms step_avg:141.06ms
step:1035/1405 train_time:144589ms step_avg:141.06ms
step:1036/1405 train_time:144735ms step_avg:141.07ms
step:1037/1405 train_time:144882ms step_avg:141.07ms
step:1038/1405 train_time:145028ms step_avg:141.08ms
step:1039/1405 train_time:145175ms step_avg:141.08ms
step:1040/1405 train_time:145321ms step_avg:141.09ms
step:1041/1405 train_time:145469ms step_avg:141.09ms
step:1042/1405 train_time:145618ms step_avg:141.10ms
step:1043/1405 train_time:145763ms step_avg:141.11ms
step:1044/1405 train_time:145912ms step_avg:141.11ms
step:1045/1405 train_time:146058ms step_avg:141.12ms
step:1046/1405 train_time:146204ms step_avg:141.12ms
step:1047/1405 train_time:146351ms step_avg:141.13ms
step:1048/1405 train_time:146497ms step_avg:141.13ms
step:1049/1405 train_time:146644ms step_avg:141.14ms
step:1050/1405 train_time:146792ms step_avg:141.15ms
step:1051/1405 train_time:146939ms step_avg:141.15ms
step:1052/1405 train_time:147086ms step_avg:141.16ms
step:1053/1405 train_time:147233ms step_avg:141.16ms
step:1054/1405 train_time:147378ms step_avg:141.17ms
step:1055/1405 train_time:147525ms step_avg:141.17ms
step:1056/1405 train_time:147672ms step_avg:141.18ms
step:1057/1405 train_time:147819ms step_avg:141.18ms
step:1058/1405 train_time:147967ms step_avg:141.19ms
step:1059/1405 train_time:148116ms step_avg:141.20ms
step:1060/1405 train_time:148263ms step_avg:141.20ms
step:1061/1405 train_time:148412ms step_avg:141.21ms
step:1062/1405 train_time:148559ms step_avg:141.22ms
step:1063/1405 train_time:148705ms step_avg:141.22ms
step:1064/1405 train_time:148851ms step_avg:141.23ms
step:1065/1405 train_time:148999ms step_avg:141.23ms
step:1066/1405 train_time:149148ms step_avg:141.24ms
step:1067/1405 train_time:149296ms step_avg:141.25ms
step:1068/1405 train_time:149443ms step_avg:141.25ms
step:1069/1405 train_time:149592ms step_avg:141.26ms
step:1070/1405 train_time:149738ms step_avg:141.26ms
step:1071/1405 train_time:149886ms step_avg:141.27ms
step:1072/1405 train_time:150034ms step_avg:141.28ms
step:1073/1405 train_time:150180ms step_avg:141.28ms
step:1074/1405 train_time:150326ms step_avg:141.28ms
step:1075/1405 train_time:150475ms step_avg:141.29ms
step:1076/1405 train_time:150620ms step_avg:141.29ms
step:1077/1405 train_time:150766ms step_avg:141.30ms
step:1078/1405 train_time:150917ms step_avg:141.31ms
step:1079/1405 train_time:151064ms step_avg:141.31ms
step:1080/1405 train_time:151213ms step_avg:141.32ms
step:1081/1405 train_time:151359ms step_avg:141.33ms
step:1082/1405 train_time:151506ms step_avg:141.33ms
step:1083/1405 train_time:151653ms step_avg:141.34ms
step:1084/1405 train_time:151800ms step_avg:141.34ms
step:1085/1405 train_time:151947ms step_avg:141.35ms
step:1086/1405 train_time:152095ms step_avg:141.35ms
step:1087/1405 train_time:152242ms step_avg:141.36ms
step:1088/1405 train_time:152389ms step_avg:141.36ms
step:1089/1405 train_time:152537ms step_avg:141.37ms
step:1090/1405 train_time:152684ms step_avg:141.37ms
step:1091/1405 train_time:152831ms step_avg:141.38ms
step:1092/1405 train_time:152979ms step_avg:141.39ms
step:1093/1405 train_time:153125ms step_avg:141.39ms
step:1094/1405 train_time:153273ms step_avg:141.40ms
step:1095/1405 train_time:153418ms step_avg:141.40ms
step:1096/1405 train_time:153566ms step_avg:141.41ms
step:1097/1405 train_time:153715ms step_avg:141.41ms
step:1098/1405 train_time:153861ms step_avg:141.42ms
step:1099/1405 train_time:154007ms step_avg:141.42ms
step:1100/1405 train_time:154154ms step_avg:141.43ms
step:1101/1405 train_time:154301ms step_avg:141.43ms
step:1102/1405 train_time:154448ms step_avg:141.44ms
step:1103/1405 train_time:154597ms step_avg:141.44ms
step:1104/1405 train_time:154744ms step_avg:141.45ms
step:1105/1405 train_time:154892ms step_avg:141.45ms
step:1106/1405 train_time:155039ms step_avg:141.46ms
step:1107/1405 train_time:155186ms step_avg:141.46ms
step:1108/1405 train_time:155335ms step_avg:141.47ms
step:1109/1405 train_time:155480ms step_avg:141.47ms
step:1110/1405 train_time:155628ms step_avg:141.48ms
step:1111/1405 train_time:155776ms step_avg:141.49ms
step:1112/1405 train_time:155922ms step_avg:141.49ms
step:1113/1405 train_time:156069ms step_avg:141.49ms
step:1114/1405 train_time:156216ms step_avg:141.50ms
step:1115/1405 train_time:156362ms step_avg:141.50ms
step:1116/1405 train_time:156509ms step_avg:141.51ms
step:1117/1405 train_time:156656ms step_avg:141.51ms
step:1118/1405 train_time:156803ms step_avg:141.52ms
step:1119/1405 train_time:156950ms step_avg:141.52ms
step:1120/1405 train_time:157097ms step_avg:141.53ms
step:1121/1405 train_time:157245ms step_avg:141.53ms
step:1122/1405 train_time:157392ms step_avg:141.54ms
step:1123/1405 train_time:157538ms step_avg:141.54ms
step:1124/1405 train_time:157686ms step_avg:141.55ms
step:1125/1405 train_time:157833ms step_avg:141.55ms
step:1125/1405 val_loss:3.3612 train_time:157904ms step_avg:141.62ms
step:1126/1405 train_time:157981ms step_avg:141.56ms
step:1127/1405 train_time:158128ms step_avg:141.57ms
step:1128/1405 train_time:158274ms step_avg:141.57ms
step:1129/1405 train_time:158421ms step_avg:141.57ms
step:1130/1405 train_time:158567ms step_avg:141.58ms
step:1131/1405 train_time:158713ms step_avg:141.58ms
step:1132/1405 train_time:158860ms step_avg:141.59ms
step:1133/1405 train_time:159009ms step_avg:141.59ms
step:1134/1405 train_time:159156ms step_avg:141.60ms
step:1135/1405 train_time:159304ms step_avg:141.60ms
step:1136/1405 train_time:159452ms step_avg:141.61ms
step:1137/1405 train_time:159598ms step_avg:141.61ms
step:1138/1405 train_time:159746ms step_avg:141.62ms
step:1139/1405 train_time:159892ms step_avg:141.62ms
step:1140/1405 train_time:160040ms step_avg:141.63ms
step:1141/1405 train_time:160232ms step_avg:141.67ms
step:1142/1405 train_time:160378ms step_avg:141.68ms
step:1143/1405 train_time:160525ms step_avg:141.68ms
step:1144/1405 train_time:160670ms step_avg:141.68ms
step:1145/1405 train_time:160816ms step_avg:141.69ms
step:1146/1405 train_time:160964ms step_avg:141.69ms
step:1147/1405 train_time:161113ms step_avg:141.70ms
step:1148/1405 train_time:161262ms step_avg:141.71ms
step:1149/1405 train_time:161410ms step_avg:141.71ms
step:1150/1405 train_time:161557ms step_avg:141.72ms
step:1151/1405 train_time:161708ms step_avg:141.72ms
step:1152/1405 train_time:161856ms step_avg:141.73ms
step:1153/1405 train_time:162007ms step_avg:141.74ms
step:1154/1405 train_time:162154ms step_avg:141.74ms
step:1155/1405 train_time:162303ms step_avg:141.75ms
step:1156/1405 train_time:162453ms step_avg:141.76ms
step:1157/1405 train_time:162602ms step_avg:141.76ms
step:1158/1405 train_time:162749ms step_avg:141.77ms
step:1159/1405 train_time:162897ms step_avg:141.77ms
step:1160/1405 train_time:163046ms step_avg:141.78ms
step:1161/1405 train_time:163195ms step_avg:141.79ms
step:1162/1405 train_time:163345ms step_avg:141.79ms
step:1163/1405 train_time:163493ms step_avg:141.80ms
step:1164/1405 train_time:163642ms step_avg:141.80ms
step:1165/1405 train_time:163789ms step_avg:141.81ms
step:1166/1405 train_time:163937ms step_avg:141.81ms
step:1167/1405 train_time:164086ms step_avg:141.82ms
step:1168/1405 train_time:164234ms step_avg:141.83ms
step:1169/1405 train_time:164383ms step_avg:141.83ms
step:1170/1405 train_time:164531ms step_avg:141.84ms
step:1171/1405 train_time:164680ms step_avg:141.84ms
step:1172/1405 train_time:164827ms step_avg:141.85ms
step:1173/1405 train_time:164976ms step_avg:141.85ms
step:1174/1405 train_time:165128ms step_avg:141.86ms
step:1175/1405 train_time:165276ms step_avg:141.87ms
step:1176/1405 train_time:165426ms step_avg:141.88ms
step:1177/1405 train_time:165578ms step_avg:141.88ms
step:1178/1405 train_time:165726ms step_avg:141.89ms
step:1179/1405 train_time:165873ms step_avg:141.89ms
step:1180/1405 train_time:166026ms step_avg:141.90ms
step:1181/1405 train_time:166173ms step_avg:141.91ms
step:1182/1405 train_time:166323ms step_avg:141.91ms
step:1183/1405 train_time:166470ms step_avg:141.92ms
step:1184/1405 train_time:166619ms step_avg:141.92ms
step:1185/1405 train_time:166768ms step_avg:141.93ms
step:1186/1405 train_time:166917ms step_avg:141.94ms
step:1187/1405 train_time:167070ms step_avg:141.95ms
step:1188/1405 train_time:167216ms step_avg:141.95ms
step:1189/1405 train_time:167366ms step_avg:141.96ms
step:1190/1405 train_time:167513ms step_avg:141.96ms
step:1191/1405 train_time:167664ms step_avg:141.97ms
step:1192/1405 train_time:167810ms step_avg:141.97ms
step:1193/1405 train_time:167958ms step_avg:141.98ms
step:1194/1405 train_time:168107ms step_avg:141.98ms
step:1195/1405 train_time:168255ms step_avg:141.99ms
step:1196/1405 train_time:168403ms step_avg:141.99ms
step:1197/1405 train_time:168552ms step_avg:142.00ms
step:1198/1405 train_time:168703ms step_avg:142.01ms
step:1199/1405 train_time:168851ms step_avg:142.01ms
step:1200/1405 train_time:168999ms step_avg:142.02ms
step:1201/1405 train_time:169148ms step_avg:142.02ms
step:1202/1405 train_time:169301ms step_avg:142.03ms
step:1203/1405 train_time:169450ms step_avg:142.04ms
step:1204/1405 train_time:169600ms step_avg:142.04ms
step:1205/1405 train_time:169749ms step_avg:142.05ms
step:1206/1405 train_time:169897ms step_avg:142.05ms
step:1207/1405 train_time:170045ms step_avg:142.06ms
step:1208/1405 train_time:170194ms step_avg:142.06ms
step:1209/1405 train_time:170343ms step_avg:142.07ms
step:1210/1405 train_time:170491ms step_avg:142.08ms
step:1211/1405 train_time:170639ms step_avg:142.08ms
step:1212/1405 train_time:170788ms step_avg:142.09ms
step:1213/1405 train_time:170936ms step_avg:142.09ms
step:1214/1405 train_time:171086ms step_avg:142.10ms
step:1215/1405 train_time:171233ms step_avg:142.10ms
step:1216/1405 train_time:171381ms step_avg:142.11ms
step:1217/1405 train_time:171529ms step_avg:142.11ms
step:1218/1405 train_time:171677ms step_avg:142.12ms
step:1219/1405 train_time:171826ms step_avg:142.12ms
step:1220/1405 train_time:171973ms step_avg:142.13ms
step:1221/1405 train_time:172121ms step_avg:142.13ms
step:1222/1405 train_time:172269ms step_avg:142.14ms
step:1223/1405 train_time:172417ms step_avg:142.14ms
step:1224/1405 train_time:172567ms step_avg:142.15ms
step:1225/1405 train_time:172716ms step_avg:142.15ms
step:1226/1405 train_time:172865ms step_avg:142.16ms
step:1227/1405 train_time:173014ms step_avg:142.16ms
step:1228/1405 train_time:173162ms step_avg:142.17ms
step:1229/1405 train_time:173310ms step_avg:142.17ms
step:1230/1405 train_time:173460ms step_avg:142.18ms
step:1231/1405 train_time:173610ms step_avg:142.19ms
step:1232/1405 train_time:173760ms step_avg:142.19ms
step:1233/1405 train_time:173908ms step_avg:142.20ms
step:1234/1405 train_time:174055ms step_avg:142.20ms
step:1235/1405 train_time:174205ms step_avg:142.21ms
step:1236/1405 train_time:174353ms step_avg:142.21ms
step:1237/1405 train_time:174501ms step_avg:142.22ms
step:1238/1405 train_time:174651ms step_avg:142.22ms
step:1239/1405 train_time:174800ms step_avg:142.23ms
step:1240/1405 train_time:174949ms step_avg:142.23ms
step:1241/1405 train_time:175099ms step_avg:142.24ms
step:1242/1405 train_time:175248ms step_avg:142.25ms
step:1243/1405 train_time:175397ms step_avg:142.25ms
step:1244/1405 train_time:175546ms step_avg:142.26ms
step:1245/1405 train_time:175693ms step_avg:142.26ms
step:1246/1405 train_time:175842ms step_avg:142.27ms
step:1247/1405 train_time:175990ms step_avg:142.27ms
step:1248/1405 train_time:176139ms step_avg:142.28ms
step:1249/1405 train_time:176287ms step_avg:142.28ms
step:1250/1405 train_time:176434ms step_avg:142.29ms
step:1250/1405 val_loss:3.3131 train_time:176507ms step_avg:142.34ms
step:1251/1405 train_time:176586ms step_avg:142.29ms
step:1252/1405 train_time:176734ms step_avg:142.30ms
step:1253/1405 train_time:176882ms step_avg:142.30ms
step:1254/1405 train_time:177027ms step_avg:142.30ms
step:1255/1405 train_time:177178ms step_avg:142.31ms
step:1256/1405 train_time:177326ms step_avg:142.32ms
step:1257/1405 train_time:177475ms step_avg:142.32ms
step:1258/1405 train_time:177626ms step_avg:142.33ms
step:1259/1405 train_time:177774ms step_avg:142.33ms
step:1260/1405 train_time:177922ms step_avg:142.34ms
step:1261/1405 train_time:178070ms step_avg:142.34ms
step:1262/1405 train_time:178221ms step_avg:142.35ms
step:1263/1405 train_time:178369ms step_avg:142.35ms
step:1264/1405 train_time:178518ms step_avg:142.36ms
step:1265/1405 train_time:178665ms step_avg:142.36ms
step:1266/1405 train_time:178815ms step_avg:142.37ms
step:1267/1405 train_time:178963ms step_avg:142.37ms
step:1268/1405 train_time:179112ms step_avg:142.38ms
step:1269/1405 train_time:179263ms step_avg:142.39ms
step:1270/1405 train_time:179411ms step_avg:142.39ms
step:1271/1405 train_time:179561ms step_avg:142.40ms
step:1272/1405 train_time:179708ms step_avg:142.40ms
step:1273/1405 train_time:179857ms step_avg:142.40ms
step:1274/1405 train_time:180004ms step_avg:142.41ms
step:1275/1405 train_time:180155ms step_avg:142.42ms
step:1276/1405 train_time:180303ms step_avg:142.42ms
step:1277/1405 train_time:180452ms step_avg:142.42ms
step:1278/1405 train_time:180600ms step_avg:142.43ms
step:1279/1405 train_time:180748ms step_avg:142.43ms
step:1280/1405 train_time:180899ms step_avg:142.44ms
step:1281/1405 train_time:181047ms step_avg:142.44ms
step:1282/1405 train_time:181195ms step_avg:142.45ms
step:1283/1405 train_time:181345ms step_avg:142.45ms
step:1284/1405 train_time:181493ms step_avg:142.46ms
step:1285/1405 train_time:181644ms step_avg:142.47ms
step:1286/1405 train_time:181792ms step_avg:142.47ms
step:1287/1405 train_time:181940ms step_avg:142.47ms
step:1288/1405 train_time:182088ms step_avg:142.48ms
step:1289/1405 train_time:182239ms step_avg:142.49ms
step:1290/1405 train_time:182389ms step_avg:142.49ms
step:1291/1405 train_time:182539ms step_avg:142.50ms
step:1292/1405 train_time:182687ms step_avg:142.50ms
step:1293/1405 train_time:182838ms step_avg:142.51ms
step:1294/1405 train_time:182986ms step_avg:142.51ms
step:1295/1405 train_time:183135ms step_avg:142.52ms
step:1296/1405 train_time:183284ms step_avg:142.52ms
step:1297/1405 train_time:183432ms step_avg:142.53ms
step:1298/1405 train_time:183581ms step_avg:142.53ms
step:1299/1405 train_time:183730ms step_avg:142.54ms
step:1300/1405 train_time:183879ms step_avg:142.54ms
step:1301/1405 train_time:184026ms step_avg:142.55ms
step:1302/1405 train_time:184175ms step_avg:142.55ms
step:1303/1405 train_time:184325ms step_avg:142.56ms
step:1304/1405 train_time:184475ms step_avg:142.56ms
step:1305/1405 train_time:184624ms step_avg:142.57ms
step:1306/1405 train_time:184774ms step_avg:142.57ms
step:1307/1405 train_time:184923ms step_avg:142.58ms
step:1308/1405 train_time:185073ms step_avg:142.58ms
step:1309/1405 train_time:185223ms step_avg:142.59ms
step:1310/1405 train_time:185372ms step_avg:142.59ms
step:1311/1405 train_time:185520ms step_avg:142.60ms
step:1312/1405 train_time:185668ms step_avg:142.60ms
step:1313/1405 train_time:185816ms step_avg:142.61ms
step:1314/1405 train_time:185967ms step_avg:142.61ms
step:1315/1405 train_time:186116ms step_avg:142.62ms
step:1316/1405 train_time:186265ms step_avg:142.62ms
step:1317/1405 train_time:186411ms step_avg:142.63ms
step:1318/1405 train_time:186563ms step_avg:142.63ms
step:1319/1405 train_time:186710ms step_avg:142.64ms
step:1320/1405 train_time:186860ms step_avg:142.64ms
step:1321/1405 train_time:187008ms step_avg:142.65ms
step:1322/1405 train_time:187160ms step_avg:142.65ms
step:1323/1405 train_time:187307ms step_avg:142.66ms
step:1324/1405 train_time:187455ms step_avg:142.66ms
step:1325/1405 train_time:187604ms step_avg:142.66ms
step:1326/1405 train_time:187754ms step_avg:142.67ms
step:1327/1405 train_time:187904ms step_avg:142.68ms
step:1328/1405 train_time:188051ms step_avg:142.68ms
step:1329/1405 train_time:188205ms step_avg:142.69ms
step:1330/1405 train_time:188354ms step_avg:142.69ms
step:1331/1405 train_time:188547ms step_avg:142.73ms
step:1332/1405 train_time:188700ms step_avg:142.74ms
step:1333/1405 train_time:188847ms step_avg:142.74ms
step:1334/1405 train_time:188994ms step_avg:142.74ms
step:1335/1405 train_time:189143ms step_avg:142.75ms
step:1336/1405 train_time:189291ms step_avg:142.75ms
step:1337/1405 train_time:189442ms step_avg:142.76ms
step:1338/1405 train_time:189591ms step_avg:142.76ms
step:1339/1405 train_time:189740ms step_avg:142.77ms
step:1340/1405 train_time:189890ms step_avg:142.77ms
step:1341/1405 train_time:190039ms step_avg:142.78ms
step:1342/1405 train_time:190188ms step_avg:142.78ms
step:1343/1405 train_time:190335ms step_avg:142.79ms
step:1344/1405 train_time:190484ms step_avg:142.79ms
step:1345/1405 train_time:190633ms step_avg:142.80ms
step:1346/1405 train_time:190781ms step_avg:142.80ms
step:1347/1405 train_time:190930ms step_avg:142.80ms
step:1348/1405 train_time:191078ms step_avg:142.81ms
step:1349/1405 train_time:191226ms step_avg:142.81ms
step:1350/1405 train_time:191374ms step_avg:142.82ms
step:1351/1405 train_time:191524ms step_avg:142.82ms
step:1352/1405 train_time:191673ms step_avg:142.83ms
step:1353/1405 train_time:191823ms step_avg:142.83ms
step:1354/1405 train_time:191971ms step_avg:142.84ms
step:1355/1405 train_time:192121ms step_avg:142.84ms
step:1356/1405 train_time:192269ms step_avg:142.84ms
step:1357/1405 train_time:192422ms step_avg:142.85ms
step:1358/1405 train_time:192571ms step_avg:142.86ms
step:1359/1405 train_time:192720ms step_avg:142.86ms
step:1360/1405 train_time:192870ms step_avg:142.87ms
step:1361/1405 train_time:193022ms step_avg:142.87ms
step:1362/1405 train_time:193172ms step_avg:142.88ms
step:1363/1405 train_time:193324ms step_avg:142.89ms
step:1364/1405 train_time:193474ms step_avg:142.89ms
step:1365/1405 train_time:193622ms step_avg:142.89ms
step:1366/1405 train_time:193771ms step_avg:142.90ms
step:1367/1405 train_time:193921ms step_avg:142.90ms
step:1368/1405 train_time:194072ms step_avg:142.91ms
step:1369/1405 train_time:194225ms step_avg:142.92ms
step:1370/1405 train_time:194376ms step_avg:142.92ms
step:1371/1405 train_time:194525ms step_avg:142.93ms
step:1372/1405 train_time:194676ms step_avg:142.93ms
step:1373/1405 train_time:194824ms step_avg:142.94ms
step:1374/1405 train_time:194976ms step_avg:142.94ms
step:1375/1405 train_time:195125ms step_avg:142.95ms
step:1375/1405 val_loss:3.2822 train_time:195199ms step_avg:143.00ms
step:1376/1405 train_time:195278ms step_avg:142.96ms
step:1377/1405 train_time:195429ms step_avg:142.96ms
step:1378/1405 train_time:195577ms step_avg:142.97ms
step:1379/1405 train_time:195728ms step_avg:142.97ms
step:1380/1405 train_time:195876ms step_avg:142.98ms
step:1381/1405 train_time:196027ms step_avg:142.98ms
step:1382/1405 train_time:196177ms step_avg:142.99ms
step:1383/1405 train_time:196329ms step_avg:142.99ms
step:1384/1405 train_time:196480ms step_avg:143.00ms
step:1385/1405 train_time:196629ms step_avg:143.00ms
step:1386/1405 train_time:196777ms step_avg:143.01ms
step:1387/1405 train_time:196928ms step_avg:143.01ms
step:1388/1405 train_time:197076ms step_avg:143.02ms
step:1389/1405 train_time:197228ms step_avg:143.02ms
step:1390/1405 train_time:197378ms step_avg:143.03ms
step:1391/1405 train_time:197528ms step_avg:143.03ms
step:1392/1405 train_time:197679ms step_avg:143.04ms
step:1393/1405 train_time:197829ms step_avg:143.04ms
step:1394/1405 train_time:197977ms step_avg:143.05ms
step:1395/1405 train_time:198128ms step_avg:143.05ms
step:1396/1405 train_time:198277ms step_avg:143.06ms
step:1397/1405 train_time:198429ms step_avg:143.06ms
step:1398/1405 train_time:198578ms step_avg:143.07ms
step:1399/1405 train_time:198727ms step_avg:143.07ms
step:1400/1405 train_time:198877ms step_avg:143.08ms
step:1401/1405 train_time:199026ms step_avg:143.08ms
step:1402/1405 train_time:199176ms step_avg:143.09ms
step:1403/1405 train_time:199328ms step_avg:143.09ms
step:1404/1405 train_time:199477ms step_avg:143.10ms
step:1405/1405 train_time:199627ms step_avg:143.10ms
step:1405/1405 val_loss:3.2795 train_time:199699ms step_avg:143.15ms
peak memory consumption: 31565 MiB
