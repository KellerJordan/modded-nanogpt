import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask: torch.Tensor):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            # indices = (~dense_mask).argsort(dim=-1, descending=False, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_masks(sliding_window_num_blocks: int):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            short_sliding_window_num_blocks = sliding_window_num_blocks // 2
            return (
                BlockMask.from_kv_blocks(
                    kv_num_blocks,
                    kv_indices,
                    full_kv_num_blocks,
                    full_kv_indices,
                    BLOCK_SIZE=BLOCK_SIZE,
                    mask_mod=document_causal,
                ),
                BlockMask.from_kv_blocks(
                    torch.clamp_max(kv_num_blocks, torch.clamp_min(short_sliding_window_num_blocks - full_kv_num_blocks, 1)),
                    kv_indices,
                    torch.clamp_max(full_kv_num_blocks, short_sliding_window_num_blocks - 1),
                    full_kv_indices,
                    BLOCK_SIZE=BLOCK_SIZE,
                    mask_mod=document_causal,
                ),
            )

        # Long-short SWA block masks by @leloykun & @YouJiacheng
        long_swa_block_mask, short_swa_block_mask = create_doc_swc_block_masks(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        is_long_block_mask = [True, False, False, False, True, False]
        for i in range(self.num_encoder_layers):
            block_mask = long_swa_block_mask if is_long_block_mask[i] else short_swa_block_mask
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        is_long_block_mask = list(reversed(is_long_block_mask))
        for i in range(self.num_decoder_layers):
            block_mask = long_swa_block_mask if is_long_block_mask[i] else short_swa_block_mask
            x = x + self.skip_weights[i] * skip_connections.pop()
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1405 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250110+cu126 compiled for CUDA 12.6
Wed Jan 15 19:34:24 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   31C    P0             116W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   27C    P0             112W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   26C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   31C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   31C    P0             115W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   28C    P0             111W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   30C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   26C    P0             110W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1405 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1405 train_time:28395ms step_avg:nanms
step:2/1405 train_time:28580ms step_avg:nanms
step:3/1405 train_time:28768ms step_avg:nanms
step:4/1405 train_time:28900ms step_avg:nanms
step:5/1405 train_time:29033ms step_avg:nanms
step:6/1405 train_time:29166ms step_avg:nanms
step:7/1405 train_time:29296ms step_avg:nanms
step:8/1405 train_time:29430ms step_avg:nanms
step:9/1405 train_time:29563ms step_avg:nanms
step:10/1405 train_time:29701ms step_avg:nanms
step:11/1405 train_time:135ms step_avg:nanms
step:12/1405 train_time:269ms step_avg:nanms
step:13/1405 train_time:403ms step_avg:134.50ms
step:14/1405 train_time:536ms step_avg:134.08ms
step:15/1405 train_time:668ms step_avg:133.68ms
step:16/1405 train_time:803ms step_avg:133.77ms
step:17/1405 train_time:936ms step_avg:133.73ms
step:18/1405 train_time:1072ms step_avg:133.97ms
step:19/1405 train_time:1206ms step_avg:133.96ms
step:20/1405 train_time:1340ms step_avg:134.01ms
step:21/1405 train_time:1473ms step_avg:133.95ms
step:22/1405 train_time:1607ms step_avg:133.95ms
step:23/1405 train_time:1740ms step_avg:133.81ms
step:24/1405 train_time:1874ms step_avg:133.86ms
step:25/1405 train_time:2008ms step_avg:133.85ms
step:26/1405 train_time:2141ms step_avg:133.84ms
step:27/1405 train_time:2275ms step_avg:133.84ms
step:28/1405 train_time:2409ms step_avg:133.85ms
step:29/1405 train_time:2543ms step_avg:133.83ms
step:30/1405 train_time:2677ms step_avg:133.86ms
step:31/1405 train_time:2811ms step_avg:133.86ms
step:32/1405 train_time:2946ms step_avg:133.90ms
step:33/1405 train_time:3079ms step_avg:133.88ms
step:34/1405 train_time:3213ms step_avg:133.89ms
step:35/1405 train_time:3348ms step_avg:133.94ms
step:36/1405 train_time:3481ms step_avg:133.89ms
step:37/1405 train_time:3615ms step_avg:133.89ms
step:38/1405 train_time:3750ms step_avg:133.94ms
step:39/1405 train_time:3884ms step_avg:133.95ms
step:40/1405 train_time:4019ms step_avg:133.95ms
step:41/1405 train_time:4151ms step_avg:133.92ms
step:42/1405 train_time:4286ms step_avg:133.94ms
step:43/1405 train_time:4420ms step_avg:133.92ms
step:44/1405 train_time:4553ms step_avg:133.92ms
step:45/1405 train_time:4687ms step_avg:133.92ms
step:46/1405 train_time:4821ms step_avg:133.91ms
step:47/1405 train_time:4954ms step_avg:133.90ms
step:48/1405 train_time:5089ms step_avg:133.93ms
step:49/1405 train_time:5224ms step_avg:133.94ms
step:50/1405 train_time:5356ms step_avg:133.90ms
step:51/1405 train_time:5490ms step_avg:133.90ms
step:52/1405 train_time:5624ms step_avg:133.91ms
step:53/1405 train_time:5758ms step_avg:133.92ms
step:54/1405 train_time:5893ms step_avg:133.94ms
step:55/1405 train_time:6027ms step_avg:133.94ms
step:56/1405 train_time:6161ms step_avg:133.93ms
step:57/1405 train_time:6295ms step_avg:133.94ms
step:58/1405 train_time:6428ms step_avg:133.93ms
step:59/1405 train_time:6562ms step_avg:133.92ms
step:60/1405 train_time:6696ms step_avg:133.92ms
step:61/1405 train_time:6831ms step_avg:133.93ms
step:62/1405 train_time:6964ms step_avg:133.93ms
step:63/1405 train_time:7098ms step_avg:133.92ms
step:64/1405 train_time:7231ms step_avg:133.91ms
step:65/1405 train_time:7365ms step_avg:133.91ms
step:66/1405 train_time:7499ms step_avg:133.90ms
step:67/1405 train_time:7632ms step_avg:133.90ms
step:68/1405 train_time:7767ms step_avg:133.91ms
step:69/1405 train_time:7901ms step_avg:133.91ms
step:70/1405 train_time:8034ms step_avg:133.90ms
step:71/1405 train_time:8167ms step_avg:133.89ms
step:72/1405 train_time:8300ms step_avg:133.88ms
step:73/1405 train_time:8435ms step_avg:133.90ms
step:74/1405 train_time:8570ms step_avg:133.91ms
step:75/1405 train_time:8705ms step_avg:133.92ms
step:76/1405 train_time:8837ms step_avg:133.90ms
step:77/1405 train_time:8972ms step_avg:133.90ms
step:78/1405 train_time:9107ms step_avg:133.93ms
step:79/1405 train_time:9241ms step_avg:133.93ms
step:80/1405 train_time:9374ms step_avg:133.92ms
step:81/1405 train_time:9509ms step_avg:133.93ms
step:82/1405 train_time:9643ms step_avg:133.93ms
step:83/1405 train_time:9776ms step_avg:133.92ms
step:84/1405 train_time:9910ms step_avg:133.92ms
step:85/1405 train_time:10045ms step_avg:133.93ms
step:86/1405 train_time:10179ms step_avg:133.94ms
step:87/1405 train_time:10313ms step_avg:133.94ms
step:88/1405 train_time:10446ms step_avg:133.92ms
step:89/1405 train_time:10580ms step_avg:133.92ms
step:90/1405 train_time:10713ms step_avg:133.92ms
step:91/1405 train_time:10847ms step_avg:133.92ms
step:92/1405 train_time:10981ms step_avg:133.92ms
step:93/1405 train_time:11117ms step_avg:133.94ms
step:94/1405 train_time:11251ms step_avg:133.94ms
step:95/1405 train_time:11385ms step_avg:133.95ms
step:96/1405 train_time:11518ms step_avg:133.93ms
step:97/1405 train_time:11652ms step_avg:133.93ms
step:98/1405 train_time:11786ms step_avg:133.94ms
step:99/1405 train_time:11920ms step_avg:133.93ms
step:100/1405 train_time:12054ms step_avg:133.94ms
step:101/1405 train_time:12189ms step_avg:133.94ms
step:102/1405 train_time:12324ms step_avg:133.95ms
step:103/1405 train_time:12459ms step_avg:133.96ms
step:104/1405 train_time:12593ms step_avg:133.97ms
step:105/1405 train_time:12727ms step_avg:133.97ms
step:106/1405 train_time:12861ms step_avg:133.97ms
step:107/1405 train_time:12996ms step_avg:133.98ms
step:108/1405 train_time:13131ms step_avg:133.99ms
step:109/1405 train_time:13267ms step_avg:134.01ms
step:110/1405 train_time:13401ms step_avg:134.01ms
step:111/1405 train_time:13536ms step_avg:134.02ms
step:112/1405 train_time:13672ms step_avg:134.04ms
step:113/1405 train_time:13808ms step_avg:134.06ms
step:114/1405 train_time:13942ms step_avg:134.06ms
step:115/1405 train_time:14077ms step_avg:134.07ms
step:116/1405 train_time:14213ms step_avg:134.08ms
step:117/1405 train_time:14348ms step_avg:134.09ms
step:118/1405 train_time:14482ms step_avg:134.09ms
step:119/1405 train_time:14617ms step_avg:134.10ms
step:120/1405 train_time:14751ms step_avg:134.10ms
step:121/1405 train_time:14886ms step_avg:134.11ms
step:122/1405 train_time:15021ms step_avg:134.11ms
step:123/1405 train_time:15157ms step_avg:134.13ms
step:124/1405 train_time:15292ms step_avg:134.14ms
step:125/1405 train_time:15428ms step_avg:134.16ms
step:125/1405 val_loss:4.4190 train_time:15493ms step_avg:134.72ms
step:126/1405 train_time:15569ms step_avg:134.21ms
step:127/1405 train_time:15706ms step_avg:134.24ms
step:128/1405 train_time:15842ms step_avg:134.26ms
step:129/1405 train_time:15977ms step_avg:134.26ms
step:130/1405 train_time:16111ms step_avg:134.26ms
step:131/1405 train_time:16245ms step_avg:134.25ms
step:132/1405 train_time:16379ms step_avg:134.25ms
step:133/1405 train_time:16515ms step_avg:134.27ms
step:134/1405 train_time:16652ms step_avg:134.29ms
step:135/1405 train_time:16789ms step_avg:134.31ms
step:136/1405 train_time:16923ms step_avg:134.31ms
step:137/1405 train_time:17059ms step_avg:134.32ms
step:138/1405 train_time:17194ms step_avg:134.32ms
step:139/1405 train_time:17329ms step_avg:134.34ms
step:140/1405 train_time:17463ms step_avg:134.33ms
step:141/1405 train_time:17599ms step_avg:134.34ms
step:142/1405 train_time:17735ms step_avg:134.36ms
step:143/1405 train_time:17872ms step_avg:134.37ms
step:144/1405 train_time:18007ms step_avg:134.38ms
step:145/1405 train_time:18143ms step_avg:134.39ms
step:146/1405 train_time:18278ms step_avg:134.40ms
step:147/1405 train_time:18413ms step_avg:134.40ms
step:148/1405 train_time:18549ms step_avg:134.41ms
step:149/1405 train_time:18684ms step_avg:134.42ms
step:150/1405 train_time:18820ms step_avg:134.43ms
step:151/1405 train_time:18956ms step_avg:134.44ms
step:152/1405 train_time:19093ms step_avg:134.46ms
step:153/1405 train_time:19229ms step_avg:134.47ms
step:154/1405 train_time:19364ms step_avg:134.47ms
step:155/1405 train_time:19499ms step_avg:134.48ms
step:156/1405 train_time:19636ms step_avg:134.49ms
step:157/1405 train_time:19771ms step_avg:134.50ms
step:158/1405 train_time:19906ms step_avg:134.50ms
step:159/1405 train_time:20042ms step_avg:134.51ms
step:160/1405 train_time:20177ms step_avg:134.52ms
step:161/1405 train_time:20313ms step_avg:134.53ms
step:162/1405 train_time:20448ms step_avg:134.53ms
step:163/1405 train_time:20584ms step_avg:134.54ms
step:164/1405 train_time:20720ms step_avg:134.54ms
step:165/1405 train_time:20856ms step_avg:134.55ms
step:166/1405 train_time:20992ms step_avg:134.57ms
step:167/1405 train_time:21129ms step_avg:134.58ms
step:168/1405 train_time:21263ms step_avg:134.58ms
step:169/1405 train_time:21398ms step_avg:134.58ms
step:170/1405 train_time:21535ms step_avg:134.59ms
step:171/1405 train_time:21670ms step_avg:134.60ms
step:172/1405 train_time:21805ms step_avg:134.60ms
step:173/1405 train_time:21941ms step_avg:134.61ms
step:174/1405 train_time:22078ms step_avg:134.62ms
step:175/1405 train_time:22213ms step_avg:134.62ms
step:176/1405 train_time:22349ms step_avg:134.63ms
step:177/1405 train_time:22485ms step_avg:134.64ms
step:178/1405 train_time:22621ms step_avg:134.65ms
step:179/1405 train_time:22756ms step_avg:134.65ms
step:180/1405 train_time:22893ms step_avg:134.67ms
step:181/1405 train_time:23029ms step_avg:134.67ms
step:182/1405 train_time:23165ms step_avg:134.68ms
step:183/1405 train_time:23301ms step_avg:134.69ms
step:184/1405 train_time:23437ms step_avg:134.70ms
step:185/1405 train_time:23573ms step_avg:134.70ms
step:186/1405 train_time:23710ms step_avg:134.71ms
step:187/1405 train_time:23846ms step_avg:134.72ms
step:188/1405 train_time:23983ms step_avg:134.73ms
step:189/1405 train_time:24119ms step_avg:134.74ms
step:190/1405 train_time:24254ms step_avg:134.75ms
step:191/1405 train_time:24431ms step_avg:134.98ms
step:192/1405 train_time:24566ms step_avg:134.98ms
step:193/1405 train_time:24700ms step_avg:134.97ms
step:194/1405 train_time:24835ms step_avg:134.97ms
step:195/1405 train_time:24970ms step_avg:134.97ms
step:196/1405 train_time:25105ms step_avg:134.98ms
step:197/1405 train_time:25241ms step_avg:134.98ms
step:198/1405 train_time:25380ms step_avg:135.00ms
step:199/1405 train_time:25516ms step_avg:135.01ms
step:200/1405 train_time:25653ms step_avg:135.02ms
step:201/1405 train_time:25788ms step_avg:135.02ms
step:202/1405 train_time:25923ms step_avg:135.01ms
step:203/1405 train_time:26058ms step_avg:135.02ms
step:204/1405 train_time:26194ms step_avg:135.02ms
step:205/1405 train_time:26331ms step_avg:135.03ms
step:206/1405 train_time:26468ms step_avg:135.04ms
step:207/1405 train_time:26605ms step_avg:135.05ms
step:208/1405 train_time:26742ms step_avg:135.06ms
step:209/1405 train_time:26877ms step_avg:135.06ms
step:210/1405 train_time:27014ms step_avg:135.07ms
step:211/1405 train_time:27150ms step_avg:135.07ms
step:212/1405 train_time:27286ms step_avg:135.08ms
step:213/1405 train_time:27423ms step_avg:135.09ms
step:214/1405 train_time:27560ms step_avg:135.10ms
step:215/1405 train_time:27697ms step_avg:135.11ms
step:216/1405 train_time:27832ms step_avg:135.11ms
step:217/1405 train_time:27967ms step_avg:135.11ms
step:218/1405 train_time:28104ms step_avg:135.11ms
step:219/1405 train_time:28240ms step_avg:135.12ms
step:220/1405 train_time:28377ms step_avg:135.13ms
step:221/1405 train_time:28515ms step_avg:135.14ms
step:222/1405 train_time:28652ms step_avg:135.15ms
step:223/1405 train_time:28790ms step_avg:135.16ms
step:224/1405 train_time:28925ms step_avg:135.17ms
step:225/1405 train_time:29063ms step_avg:135.18ms
step:226/1405 train_time:29199ms step_avg:135.18ms
step:227/1405 train_time:29336ms step_avg:135.19ms
step:228/1405 train_time:29472ms step_avg:135.19ms
step:229/1405 train_time:29609ms step_avg:135.20ms
step:230/1405 train_time:29746ms step_avg:135.21ms
step:231/1405 train_time:29883ms step_avg:135.22ms
step:232/1405 train_time:30020ms step_avg:135.23ms
step:233/1405 train_time:30156ms step_avg:135.23ms
step:234/1405 train_time:30294ms step_avg:135.24ms
step:235/1405 train_time:30431ms step_avg:135.25ms
step:236/1405 train_time:30567ms step_avg:135.25ms
step:237/1405 train_time:30704ms step_avg:135.26ms
step:238/1405 train_time:30840ms step_avg:135.26ms
step:239/1405 train_time:30977ms step_avg:135.27ms
step:240/1405 train_time:31113ms step_avg:135.28ms
step:241/1405 train_time:31250ms step_avg:135.28ms
step:242/1405 train_time:31384ms step_avg:135.28ms
step:243/1405 train_time:31522ms step_avg:135.29ms
step:244/1405 train_time:31660ms step_avg:135.30ms
step:245/1405 train_time:31796ms step_avg:135.30ms
step:246/1405 train_time:31933ms step_avg:135.31ms
step:247/1405 train_time:32069ms step_avg:135.31ms
step:248/1405 train_time:32205ms step_avg:135.32ms
step:249/1405 train_time:32343ms step_avg:135.33ms
step:250/1405 train_time:32478ms step_avg:135.33ms
step:250/1405 val_loss:3.9811 train_time:32543ms step_avg:135.60ms
step:251/1405 train_time:32618ms step_avg:135.35ms
step:252/1405 train_time:32758ms step_avg:135.36ms
step:253/1405 train_time:32895ms step_avg:135.37ms
step:254/1405 train_time:33030ms step_avg:135.37ms
step:255/1405 train_time:33166ms step_avg:135.37ms
step:256/1405 train_time:33301ms step_avg:135.37ms
step:257/1405 train_time:33436ms step_avg:135.37ms
step:258/1405 train_time:33573ms step_avg:135.37ms
step:259/1405 train_time:33711ms step_avg:135.38ms
step:260/1405 train_time:33849ms step_avg:135.40ms
step:261/1405 train_time:33986ms step_avg:135.40ms
step:262/1405 train_time:34122ms step_avg:135.41ms
step:263/1405 train_time:34257ms step_avg:135.40ms
step:264/1405 train_time:34394ms step_avg:135.41ms
step:265/1405 train_time:34530ms step_avg:135.41ms
step:266/1405 train_time:34666ms step_avg:135.41ms
step:267/1405 train_time:34804ms step_avg:135.42ms
step:268/1405 train_time:34940ms step_avg:135.43ms
step:269/1405 train_time:35076ms step_avg:135.43ms
step:270/1405 train_time:35212ms step_avg:135.43ms
step:271/1405 train_time:35348ms step_avg:135.43ms
step:272/1405 train_time:35485ms step_avg:135.44ms
step:273/1405 train_time:35622ms step_avg:135.45ms
step:274/1405 train_time:35758ms step_avg:135.45ms
step:275/1405 train_time:35896ms step_avg:135.46ms
step:276/1405 train_time:36032ms step_avg:135.46ms
step:277/1405 train_time:36169ms step_avg:135.46ms
step:278/1405 train_time:36306ms step_avg:135.47ms
step:279/1405 train_time:36443ms step_avg:135.48ms
step:280/1405 train_time:36578ms step_avg:135.47ms
step:281/1405 train_time:36715ms step_avg:135.48ms
step:282/1405 train_time:36851ms step_avg:135.48ms
step:283/1405 train_time:36988ms step_avg:135.49ms
step:284/1405 train_time:37126ms step_avg:135.50ms
step:285/1405 train_time:37265ms step_avg:135.51ms
step:286/1405 train_time:37401ms step_avg:135.51ms
step:287/1405 train_time:37536ms step_avg:135.51ms
step:288/1405 train_time:37674ms step_avg:135.52ms
step:289/1405 train_time:37812ms step_avg:135.53ms
step:290/1405 train_time:37948ms step_avg:135.53ms
step:291/1405 train_time:38085ms step_avg:135.53ms
step:292/1405 train_time:38221ms step_avg:135.54ms
step:293/1405 train_time:38358ms step_avg:135.54ms
step:294/1405 train_time:38494ms step_avg:135.54ms
step:295/1405 train_time:38631ms step_avg:135.55ms
step:296/1405 train_time:38768ms step_avg:135.55ms
step:297/1405 train_time:38906ms step_avg:135.56ms
step:298/1405 train_time:39043ms step_avg:135.57ms
step:299/1405 train_time:39179ms step_avg:135.57ms
step:300/1405 train_time:39315ms step_avg:135.57ms
step:301/1405 train_time:39452ms step_avg:135.57ms
step:302/1405 train_time:39589ms step_avg:135.58ms
step:303/1405 train_time:39726ms step_avg:135.58ms
step:304/1405 train_time:39862ms step_avg:135.58ms
step:305/1405 train_time:39997ms step_avg:135.58ms
step:306/1405 train_time:40134ms step_avg:135.59ms
step:307/1405 train_time:40271ms step_avg:135.59ms
step:308/1405 train_time:40407ms step_avg:135.59ms
step:309/1405 train_time:40544ms step_avg:135.60ms
step:310/1405 train_time:40681ms step_avg:135.60ms
step:311/1405 train_time:40816ms step_avg:135.60ms
step:312/1405 train_time:40953ms step_avg:135.61ms
step:313/1405 train_time:41090ms step_avg:135.61ms
step:314/1405 train_time:41228ms step_avg:135.62ms
step:315/1405 train_time:41367ms step_avg:135.63ms
step:316/1405 train_time:41507ms step_avg:135.64ms
step:317/1405 train_time:41647ms step_avg:135.66ms
step:318/1405 train_time:41785ms step_avg:135.67ms
step:319/1405 train_time:41925ms step_avg:135.68ms
step:320/1405 train_time:42065ms step_avg:135.69ms
step:321/1405 train_time:42203ms step_avg:135.70ms
step:322/1405 train_time:42342ms step_avg:135.71ms
step:323/1405 train_time:42481ms step_avg:135.72ms
step:324/1405 train_time:42620ms step_avg:135.73ms
step:325/1405 train_time:42760ms step_avg:135.75ms
step:326/1405 train_time:42899ms step_avg:135.76ms
step:327/1405 train_time:43039ms step_avg:135.77ms
step:328/1405 train_time:43177ms step_avg:135.78ms
step:329/1405 train_time:43316ms step_avg:135.79ms
step:330/1405 train_time:43455ms step_avg:135.80ms
step:331/1405 train_time:43595ms step_avg:135.81ms
step:332/1405 train_time:43734ms step_avg:135.82ms
step:333/1405 train_time:43873ms step_avg:135.83ms
step:334/1405 train_time:44012ms step_avg:135.84ms
step:335/1405 train_time:44151ms step_avg:135.85ms
step:336/1405 train_time:44291ms step_avg:135.86ms
step:337/1405 train_time:44429ms step_avg:135.87ms
step:338/1405 train_time:44568ms step_avg:135.88ms
step:339/1405 train_time:44708ms step_avg:135.89ms
step:340/1405 train_time:44848ms step_avg:135.90ms
step:341/1405 train_time:44987ms step_avg:135.91ms
step:342/1405 train_time:45125ms step_avg:135.92ms
step:343/1405 train_time:45264ms step_avg:135.93ms
step:344/1405 train_time:45403ms step_avg:135.94ms
step:345/1405 train_time:45543ms step_avg:135.95ms
step:346/1405 train_time:45682ms step_avg:135.96ms
step:347/1405 train_time:45822ms step_avg:135.97ms
step:348/1405 train_time:45959ms step_avg:135.97ms
step:349/1405 train_time:46100ms step_avg:135.99ms
step:350/1405 train_time:46239ms step_avg:136.00ms
step:351/1405 train_time:46378ms step_avg:136.01ms
step:352/1405 train_time:46517ms step_avg:136.02ms
step:353/1405 train_time:46656ms step_avg:136.02ms
step:354/1405 train_time:46796ms step_avg:136.04ms
step:355/1405 train_time:46936ms step_avg:136.05ms
step:356/1405 train_time:47076ms step_avg:136.06ms
step:357/1405 train_time:47215ms step_avg:136.07ms
step:358/1405 train_time:47354ms step_avg:136.07ms
step:359/1405 train_time:47493ms step_avg:136.08ms
step:360/1405 train_time:47632ms step_avg:136.09ms
step:361/1405 train_time:47772ms step_avg:136.10ms
step:362/1405 train_time:47912ms step_avg:136.11ms
step:363/1405 train_time:48051ms step_avg:136.12ms
step:364/1405 train_time:48191ms step_avg:136.13ms
step:365/1405 train_time:48329ms step_avg:136.14ms
step:366/1405 train_time:48468ms step_avg:136.15ms
step:367/1405 train_time:48608ms step_avg:136.16ms
step:368/1405 train_time:48748ms step_avg:136.17ms
step:369/1405 train_time:48887ms step_avg:136.18ms
step:370/1405 train_time:49026ms step_avg:136.18ms
step:371/1405 train_time:49165ms step_avg:136.19ms
step:372/1405 train_time:49305ms step_avg:136.20ms
step:373/1405 train_time:49444ms step_avg:136.21ms
step:374/1405 train_time:49583ms step_avg:136.22ms
step:375/1405 train_time:49722ms step_avg:136.22ms
step:375/1405 val_loss:3.7822 train_time:49787ms step_avg:136.40ms
step:376/1405 train_time:49865ms step_avg:136.24ms
step:377/1405 train_time:50005ms step_avg:136.25ms
step:378/1405 train_time:50145ms step_avg:136.26ms
step:379/1405 train_time:50283ms step_avg:136.27ms
step:380/1405 train_time:50421ms step_avg:136.27ms
step:381/1405 train_time:50596ms step_avg:136.38ms
step:382/1405 train_time:50735ms step_avg:136.38ms
step:383/1405 train_time:50874ms step_avg:136.39ms
step:384/1405 train_time:51013ms step_avg:136.40ms
step:385/1405 train_time:51151ms step_avg:136.40ms
step:386/1405 train_time:51289ms step_avg:136.41ms
step:387/1405 train_time:51429ms step_avg:136.42ms
step:388/1405 train_time:51573ms step_avg:136.44ms
step:389/1405 train_time:51711ms step_avg:136.44ms
step:390/1405 train_time:51849ms step_avg:136.45ms
step:391/1405 train_time:51987ms step_avg:136.45ms
step:392/1405 train_time:52126ms step_avg:136.46ms
step:393/1405 train_time:52265ms step_avg:136.46ms
step:394/1405 train_time:52404ms step_avg:136.47ms
step:395/1405 train_time:52544ms step_avg:136.48ms
step:396/1405 train_time:52683ms step_avg:136.49ms
step:397/1405 train_time:52823ms step_avg:136.49ms
step:398/1405 train_time:52962ms step_avg:136.50ms
step:399/1405 train_time:53102ms step_avg:136.51ms
step:400/1405 train_time:53241ms step_avg:136.52ms
step:401/1405 train_time:53381ms step_avg:136.52ms
step:402/1405 train_time:53521ms step_avg:136.53ms
step:403/1405 train_time:53661ms step_avg:136.54ms
step:404/1405 train_time:53800ms step_avg:136.55ms
step:405/1405 train_time:53940ms step_avg:136.56ms
step:406/1405 train_time:54080ms step_avg:136.57ms
step:407/1405 train_time:54219ms step_avg:136.57ms
step:408/1405 train_time:54359ms step_avg:136.58ms
step:409/1405 train_time:54499ms step_avg:136.59ms
step:410/1405 train_time:54638ms step_avg:136.59ms
step:411/1405 train_time:54778ms step_avg:136.60ms
step:412/1405 train_time:54917ms step_avg:136.61ms
step:413/1405 train_time:55057ms step_avg:136.62ms
step:414/1405 train_time:55195ms step_avg:136.62ms
step:415/1405 train_time:55334ms step_avg:136.63ms
step:416/1405 train_time:55474ms step_avg:136.63ms
step:417/1405 train_time:55614ms step_avg:136.64ms
step:418/1405 train_time:55753ms step_avg:136.65ms
step:419/1405 train_time:55892ms step_avg:136.66ms
step:420/1405 train_time:56032ms step_avg:136.66ms
step:421/1405 train_time:56171ms step_avg:136.67ms
step:422/1405 train_time:56311ms step_avg:136.68ms
step:423/1405 train_time:56451ms step_avg:136.68ms
step:424/1405 train_time:56590ms step_avg:136.69ms
step:425/1405 train_time:56730ms step_avg:136.70ms
step:426/1405 train_time:56869ms step_avg:136.71ms
step:427/1405 train_time:57009ms step_avg:136.71ms
step:428/1405 train_time:57150ms step_avg:136.72ms
step:429/1405 train_time:57290ms step_avg:136.73ms
step:430/1405 train_time:57430ms step_avg:136.74ms
step:431/1405 train_time:57570ms step_avg:136.75ms
step:432/1405 train_time:57709ms step_avg:136.75ms
step:433/1405 train_time:57847ms step_avg:136.76ms
step:434/1405 train_time:57987ms step_avg:136.76ms
step:435/1405 train_time:58127ms step_avg:136.77ms
step:436/1405 train_time:58268ms step_avg:136.78ms
step:437/1405 train_time:58408ms step_avg:136.79ms
step:438/1405 train_time:58548ms step_avg:136.79ms
step:439/1405 train_time:58688ms step_avg:136.80ms
step:440/1405 train_time:58828ms step_avg:136.81ms
step:441/1405 train_time:58967ms step_avg:136.81ms
step:442/1405 train_time:59107ms step_avg:136.82ms
step:443/1405 train_time:59248ms step_avg:136.83ms
step:444/1405 train_time:59389ms step_avg:136.84ms
step:445/1405 train_time:59528ms step_avg:136.85ms
step:446/1405 train_time:59668ms step_avg:136.85ms
step:447/1405 train_time:59807ms step_avg:136.86ms
step:448/1405 train_time:59946ms step_avg:136.86ms
step:449/1405 train_time:60087ms step_avg:136.87ms
step:450/1405 train_time:60227ms step_avg:136.88ms
step:451/1405 train_time:60367ms step_avg:136.89ms
step:452/1405 train_time:60508ms step_avg:136.90ms
step:453/1405 train_time:60648ms step_avg:136.90ms
step:454/1405 train_time:60789ms step_avg:136.91ms
step:455/1405 train_time:60928ms step_avg:136.92ms
step:456/1405 train_time:61068ms step_avg:136.92ms
step:457/1405 train_time:61208ms step_avg:136.93ms
step:458/1405 train_time:61348ms step_avg:136.94ms
step:459/1405 train_time:61488ms step_avg:136.95ms
step:460/1405 train_time:61628ms step_avg:136.95ms
step:461/1405 train_time:61768ms step_avg:136.96ms
step:462/1405 train_time:61908ms step_avg:136.96ms
step:463/1405 train_time:62048ms step_avg:136.97ms
step:464/1405 train_time:62188ms step_avg:136.98ms
step:465/1405 train_time:62329ms step_avg:136.99ms
step:466/1405 train_time:62470ms step_avg:137.00ms
step:467/1405 train_time:62610ms step_avg:137.00ms
step:468/1405 train_time:62749ms step_avg:137.01ms
step:469/1405 train_time:62888ms step_avg:137.01ms
step:470/1405 train_time:63028ms step_avg:137.02ms
step:471/1405 train_time:63168ms step_avg:137.02ms
step:472/1405 train_time:63309ms step_avg:137.03ms
step:473/1405 train_time:63448ms step_avg:137.04ms
step:474/1405 train_time:63589ms step_avg:137.04ms
step:475/1405 train_time:63729ms step_avg:137.05ms
step:476/1405 train_time:63869ms step_avg:137.06ms
step:477/1405 train_time:64009ms step_avg:137.06ms
step:478/1405 train_time:64150ms step_avg:137.07ms
step:479/1405 train_time:64289ms step_avg:137.08ms
step:480/1405 train_time:64429ms step_avg:137.08ms
step:481/1405 train_time:64570ms step_avg:137.09ms
step:482/1405 train_time:64710ms step_avg:137.10ms
step:483/1405 train_time:64850ms step_avg:137.10ms
step:484/1405 train_time:64990ms step_avg:137.11ms
step:485/1405 train_time:65129ms step_avg:137.11ms
step:486/1405 train_time:65269ms step_avg:137.12ms
step:487/1405 train_time:65410ms step_avg:137.13ms
step:488/1405 train_time:65549ms step_avg:137.13ms
step:489/1405 train_time:65689ms step_avg:137.14ms
step:490/1405 train_time:65829ms step_avg:137.14ms
step:491/1405 train_time:65969ms step_avg:137.15ms
step:492/1405 train_time:66110ms step_avg:137.16ms
step:493/1405 train_time:66250ms step_avg:137.16ms
step:494/1405 train_time:66390ms step_avg:137.17ms
step:495/1405 train_time:66531ms step_avg:137.18ms
step:496/1405 train_time:66671ms step_avg:137.18ms
step:497/1405 train_time:66811ms step_avg:137.19ms
step:498/1405 train_time:66951ms step_avg:137.19ms
step:499/1405 train_time:67091ms step_avg:137.20ms
step:500/1405 train_time:67229ms step_avg:137.20ms
step:500/1405 val_loss:3.6602 train_time:67295ms step_avg:137.34ms
step:501/1405 train_time:67372ms step_avg:137.21ms
step:502/1405 train_time:67512ms step_avg:137.22ms
step:503/1405 train_time:67653ms step_avg:137.23ms
step:504/1405 train_time:67793ms step_avg:137.23ms
step:505/1405 train_time:67933ms step_avg:137.24ms
step:506/1405 train_time:68071ms step_avg:137.24ms
step:507/1405 train_time:68211ms step_avg:137.24ms
step:508/1405 train_time:68352ms step_avg:137.25ms
step:509/1405 train_time:68494ms step_avg:137.26ms
step:510/1405 train_time:68634ms step_avg:137.27ms
step:511/1405 train_time:68773ms step_avg:137.27ms
step:512/1405 train_time:68912ms step_avg:137.27ms
step:513/1405 train_time:69052ms step_avg:137.28ms
step:514/1405 train_time:69192ms step_avg:137.29ms
step:515/1405 train_time:69333ms step_avg:137.29ms
step:516/1405 train_time:69473ms step_avg:137.30ms
step:517/1405 train_time:69615ms step_avg:137.31ms
step:518/1405 train_time:69755ms step_avg:137.31ms
step:519/1405 train_time:69896ms step_avg:137.32ms
step:520/1405 train_time:70035ms step_avg:137.32ms
step:521/1405 train_time:70175ms step_avg:137.33ms
step:522/1405 train_time:70317ms step_avg:137.34ms
step:523/1405 train_time:70459ms step_avg:137.35ms
step:524/1405 train_time:70602ms step_avg:137.36ms
step:525/1405 train_time:70742ms step_avg:137.36ms
step:526/1405 train_time:70885ms step_avg:137.37ms
step:527/1405 train_time:71027ms step_avg:137.38ms
step:528/1405 train_time:71170ms step_avg:137.39ms
step:529/1405 train_time:71311ms step_avg:137.40ms
step:530/1405 train_time:71455ms step_avg:137.41ms
step:531/1405 train_time:71597ms step_avg:137.42ms
step:532/1405 train_time:71739ms step_avg:137.43ms
step:533/1405 train_time:71883ms step_avg:137.44ms
step:534/1405 train_time:72024ms step_avg:137.45ms
step:535/1405 train_time:72167ms step_avg:137.46ms
step:536/1405 train_time:72309ms step_avg:137.47ms
step:537/1405 train_time:72451ms step_avg:137.48ms
step:538/1405 train_time:72596ms step_avg:137.49ms
step:539/1405 train_time:72737ms step_avg:137.50ms
step:540/1405 train_time:72880ms step_avg:137.51ms
step:541/1405 train_time:73021ms step_avg:137.52ms
step:542/1405 train_time:73164ms step_avg:137.53ms
step:543/1405 train_time:73305ms step_avg:137.53ms
step:544/1405 train_time:73448ms step_avg:137.54ms
step:545/1405 train_time:73590ms step_avg:137.55ms
step:546/1405 train_time:73731ms step_avg:137.56ms
step:547/1405 train_time:73873ms step_avg:137.57ms
step:548/1405 train_time:74016ms step_avg:137.58ms
step:549/1405 train_time:74158ms step_avg:137.58ms
step:550/1405 train_time:74300ms step_avg:137.59ms
step:551/1405 train_time:74442ms step_avg:137.60ms
step:552/1405 train_time:74584ms step_avg:137.61ms
step:553/1405 train_time:74727ms step_avg:137.62ms
step:554/1405 train_time:74869ms step_avg:137.63ms
step:555/1405 train_time:75011ms step_avg:137.63ms
step:556/1405 train_time:75153ms step_avg:137.64ms
step:557/1405 train_time:75295ms step_avg:137.65ms
step:558/1405 train_time:75436ms step_avg:137.66ms
step:559/1405 train_time:75578ms step_avg:137.66ms
step:560/1405 train_time:75720ms step_avg:137.67ms
step:561/1405 train_time:75863ms step_avg:137.68ms
step:562/1405 train_time:76006ms step_avg:137.69ms
step:563/1405 train_time:76147ms step_avg:137.70ms
step:564/1405 train_time:76289ms step_avg:137.71ms
step:565/1405 train_time:76431ms step_avg:137.71ms
step:566/1405 train_time:76572ms step_avg:137.72ms
step:567/1405 train_time:76714ms step_avg:137.73ms
step:568/1405 train_time:76856ms step_avg:137.74ms
step:569/1405 train_time:76998ms step_avg:137.74ms
step:570/1405 train_time:77140ms step_avg:137.75ms
step:571/1405 train_time:77320ms step_avg:137.83ms
step:572/1405 train_time:77460ms step_avg:137.83ms
step:573/1405 train_time:77602ms step_avg:137.84ms
step:574/1405 train_time:77743ms step_avg:137.84ms
step:575/1405 train_time:77884ms step_avg:137.85ms
step:576/1405 train_time:78026ms step_avg:137.85ms
step:577/1405 train_time:78168ms step_avg:137.86ms
step:578/1405 train_time:78313ms step_avg:137.88ms
step:579/1405 train_time:78456ms step_avg:137.88ms
step:580/1405 train_time:78598ms step_avg:137.89ms
step:581/1405 train_time:78740ms step_avg:137.90ms
step:582/1405 train_time:78882ms step_avg:137.91ms
step:583/1405 train_time:79023ms step_avg:137.91ms
step:584/1405 train_time:79166ms step_avg:137.92ms
step:585/1405 train_time:79310ms step_avg:137.93ms
step:586/1405 train_time:79453ms step_avg:137.94ms
step:587/1405 train_time:79596ms step_avg:137.95ms
step:588/1405 train_time:79737ms step_avg:137.95ms
step:589/1405 train_time:79878ms step_avg:137.96ms
step:590/1405 train_time:80019ms step_avg:137.96ms
step:591/1405 train_time:80161ms step_avg:137.97ms
step:592/1405 train_time:80304ms step_avg:137.98ms
step:593/1405 train_time:80446ms step_avg:137.99ms
step:594/1405 train_time:80590ms step_avg:138.00ms
step:595/1405 train_time:80733ms step_avg:138.01ms
step:596/1405 train_time:80875ms step_avg:138.01ms
step:597/1405 train_time:81017ms step_avg:138.02ms
step:598/1405 train_time:81158ms step_avg:138.02ms
step:599/1405 train_time:81301ms step_avg:138.03ms
step:600/1405 train_time:81443ms step_avg:138.04ms
step:601/1405 train_time:81585ms step_avg:138.05ms
step:602/1405 train_time:81727ms step_avg:138.05ms
step:603/1405 train_time:81870ms step_avg:138.06ms
step:604/1405 train_time:82013ms step_avg:138.07ms
step:605/1405 train_time:82156ms step_avg:138.08ms
step:606/1405 train_time:82299ms step_avg:138.08ms
step:607/1405 train_time:82440ms step_avg:138.09ms
step:608/1405 train_time:82581ms step_avg:138.09ms
step:609/1405 train_time:82722ms step_avg:138.10ms
step:610/1405 train_time:82864ms step_avg:138.11ms
step:611/1405 train_time:83006ms step_avg:138.11ms
step:612/1405 train_time:83149ms step_avg:138.12ms
step:613/1405 train_time:83291ms step_avg:138.13ms
step:614/1405 train_time:83434ms step_avg:138.14ms
step:615/1405 train_time:83576ms step_avg:138.14ms
step:616/1405 train_time:83719ms step_avg:138.15ms
step:617/1405 train_time:83861ms step_avg:138.16ms
step:618/1405 train_time:84002ms step_avg:138.16ms
step:619/1405 train_time:84144ms step_avg:138.17ms
step:620/1405 train_time:84287ms step_avg:138.17ms
step:621/1405 train_time:84429ms step_avg:138.18ms
step:622/1405 train_time:84571ms step_avg:138.19ms
step:623/1405 train_time:84713ms step_avg:138.19ms
step:624/1405 train_time:84856ms step_avg:138.20ms
step:625/1405 train_time:84998ms step_avg:138.21ms
step:625/1405 val_loss:3.5786 train_time:85066ms step_avg:138.32ms
step:626/1405 train_time:85142ms step_avg:138.22ms
step:627/1405 train_time:85286ms step_avg:138.23ms
step:628/1405 train_time:85429ms step_avg:138.23ms
step:629/1405 train_time:85571ms step_avg:138.24ms
step:630/1405 train_time:85713ms step_avg:138.25ms
step:631/1405 train_time:85856ms step_avg:138.25ms
step:632/1405 train_time:85997ms step_avg:138.26ms
step:633/1405 train_time:86141ms step_avg:138.27ms
step:634/1405 train_time:86283ms step_avg:138.27ms
step:635/1405 train_time:86425ms step_avg:138.28ms
step:636/1405 train_time:86568ms step_avg:138.29ms
step:637/1405 train_time:86711ms step_avg:138.29ms
step:638/1405 train_time:86854ms step_avg:138.30ms
step:639/1405 train_time:86997ms step_avg:138.31ms
step:640/1405 train_time:87139ms step_avg:138.32ms
step:641/1405 train_time:87282ms step_avg:138.32ms
step:642/1405 train_time:87425ms step_avg:138.33ms
step:643/1405 train_time:87568ms step_avg:138.34ms
step:644/1405 train_time:87710ms step_avg:138.34ms
step:645/1405 train_time:87852ms step_avg:138.35ms
step:646/1405 train_time:87994ms step_avg:138.35ms
step:647/1405 train_time:88136ms step_avg:138.36ms
step:648/1405 train_time:88279ms step_avg:138.37ms
step:649/1405 train_time:88421ms step_avg:138.37ms
step:650/1405 train_time:88564ms step_avg:138.38ms
step:651/1405 train_time:88707ms step_avg:138.39ms
step:652/1405 train_time:88850ms step_avg:138.40ms
step:653/1405 train_time:88993ms step_avg:138.40ms
step:654/1405 train_time:89136ms step_avg:138.41ms
step:655/1405 train_time:89278ms step_avg:138.41ms
step:656/1405 train_time:89420ms step_avg:138.42ms
step:657/1405 train_time:89563ms step_avg:138.43ms
step:658/1405 train_time:89705ms step_avg:138.43ms
step:659/1405 train_time:89848ms step_avg:138.44ms
step:660/1405 train_time:89991ms step_avg:138.45ms
step:661/1405 train_time:90134ms step_avg:138.46ms
step:662/1405 train_time:90276ms step_avg:138.46ms
step:663/1405 train_time:90418ms step_avg:138.47ms
step:664/1405 train_time:90561ms step_avg:138.47ms
step:665/1405 train_time:90704ms step_avg:138.48ms
step:666/1405 train_time:90847ms step_avg:138.49ms
step:667/1405 train_time:90989ms step_avg:138.49ms
step:668/1405 train_time:91132ms step_avg:138.50ms
step:669/1405 train_time:91275ms step_avg:138.51ms
step:670/1405 train_time:91418ms step_avg:138.51ms
step:671/1405 train_time:91561ms step_avg:138.52ms
step:672/1405 train_time:91704ms step_avg:138.53ms
step:673/1405 train_time:91847ms step_avg:138.53ms
step:674/1405 train_time:91988ms step_avg:138.54ms
step:675/1405 train_time:92131ms step_avg:138.54ms
step:676/1405 train_time:92275ms step_avg:138.55ms
step:677/1405 train_time:92417ms step_avg:138.56ms
step:678/1405 train_time:92560ms step_avg:138.56ms
step:679/1405 train_time:92703ms step_avg:138.57ms
step:680/1405 train_time:92846ms step_avg:138.58ms
step:681/1405 train_time:92988ms step_avg:138.58ms
step:682/1405 train_time:93133ms step_avg:138.59ms
step:683/1405 train_time:93275ms step_avg:138.60ms
step:684/1405 train_time:93418ms step_avg:138.60ms
step:685/1405 train_time:93561ms step_avg:138.61ms
step:686/1405 train_time:93704ms step_avg:138.61ms
step:687/1405 train_time:93846ms step_avg:138.62ms
step:688/1405 train_time:93989ms step_avg:138.63ms
step:689/1405 train_time:94133ms step_avg:138.63ms
step:690/1405 train_time:94276ms step_avg:138.64ms
step:691/1405 train_time:94418ms step_avg:138.65ms
step:692/1405 train_time:94560ms step_avg:138.65ms
step:693/1405 train_time:94703ms step_avg:138.66ms
step:694/1405 train_time:94845ms step_avg:138.66ms
step:695/1405 train_time:94989ms step_avg:138.67ms
step:696/1405 train_time:95132ms step_avg:138.68ms
step:697/1405 train_time:95276ms step_avg:138.68ms
step:698/1405 train_time:95417ms step_avg:138.69ms
step:699/1405 train_time:95560ms step_avg:138.69ms
step:700/1405 train_time:95703ms step_avg:138.70ms
step:701/1405 train_time:95845ms step_avg:138.70ms
step:702/1405 train_time:95988ms step_avg:138.71ms
step:703/1405 train_time:96130ms step_avg:138.72ms
step:704/1405 train_time:96274ms step_avg:138.72ms
step:705/1405 train_time:96418ms step_avg:138.73ms
step:706/1405 train_time:96560ms step_avg:138.74ms
step:707/1405 train_time:96703ms step_avg:138.74ms
step:708/1405 train_time:96845ms step_avg:138.75ms
step:709/1405 train_time:96988ms step_avg:138.75ms
step:710/1405 train_time:97131ms step_avg:138.76ms
step:711/1405 train_time:97274ms step_avg:138.77ms
step:712/1405 train_time:97416ms step_avg:138.77ms
step:713/1405 train_time:97559ms step_avg:138.78ms
step:714/1405 train_time:97702ms step_avg:138.78ms
step:715/1405 train_time:97845ms step_avg:138.79ms
step:716/1405 train_time:97988ms step_avg:138.79ms
step:717/1405 train_time:98131ms step_avg:138.80ms
step:718/1405 train_time:98274ms step_avg:138.81ms
step:719/1405 train_time:98416ms step_avg:138.81ms
step:720/1405 train_time:98559ms step_avg:138.82ms
step:721/1405 train_time:98702ms step_avg:138.82ms
step:722/1405 train_time:98845ms step_avg:138.83ms
step:723/1405 train_time:98988ms step_avg:138.83ms
step:724/1405 train_time:99132ms step_avg:138.84ms
step:725/1405 train_time:99275ms step_avg:138.85ms
step:726/1405 train_time:99417ms step_avg:138.85ms
step:727/1405 train_time:99561ms step_avg:138.86ms
step:728/1405 train_time:99703ms step_avg:138.86ms
step:729/1405 train_time:99846ms step_avg:138.87ms
step:730/1405 train_time:99990ms step_avg:138.87ms
step:731/1405 train_time:100136ms step_avg:138.88ms
step:732/1405 train_time:100281ms step_avg:138.89ms
step:733/1405 train_time:100424ms step_avg:138.90ms
step:734/1405 train_time:100568ms step_avg:138.91ms
step:735/1405 train_time:100714ms step_avg:138.92ms
step:736/1405 train_time:100859ms step_avg:138.92ms
step:737/1405 train_time:101004ms step_avg:138.93ms
step:738/1405 train_time:101148ms step_avg:138.94ms
step:739/1405 train_time:101293ms step_avg:138.95ms
step:740/1405 train_time:101439ms step_avg:138.96ms
step:741/1405 train_time:101582ms step_avg:138.96ms
step:742/1405 train_time:101726ms step_avg:138.97ms
step:743/1405 train_time:101871ms step_avg:138.98ms
step:744/1405 train_time:102016ms step_avg:138.99ms
step:745/1405 train_time:102161ms step_avg:138.99ms
step:746/1405 train_time:102305ms step_avg:139.00ms
step:747/1405 train_time:102448ms step_avg:139.01ms
step:748/1405 train_time:102593ms step_avg:139.01ms
step:749/1405 train_time:102737ms step_avg:139.02ms
step:750/1405 train_time:102882ms step_avg:139.03ms
step:750/1405 val_loss:3.5257 train_time:102951ms step_avg:139.12ms
step:751/1405 train_time:103028ms step_avg:139.04ms
step:752/1405 train_time:103175ms step_avg:139.05ms
step:753/1405 train_time:103318ms step_avg:139.06ms
step:754/1405 train_time:103461ms step_avg:139.06ms
step:755/1405 train_time:103606ms step_avg:139.07ms
step:756/1405 train_time:103751ms step_avg:139.08ms
step:757/1405 train_time:103895ms step_avg:139.08ms
step:758/1405 train_time:104041ms step_avg:139.09ms
step:759/1405 train_time:104187ms step_avg:139.10ms
step:760/1405 train_time:104332ms step_avg:139.11ms
step:761/1405 train_time:104516ms step_avg:139.17ms
step:762/1405 train_time:104658ms step_avg:139.17ms
step:763/1405 train_time:104802ms step_avg:139.18ms
step:764/1405 train_time:104946ms step_avg:139.19ms
step:765/1405 train_time:105091ms step_avg:139.19ms
step:766/1405 train_time:105235ms step_avg:139.20ms
step:767/1405 train_time:105379ms step_avg:139.21ms
step:768/1405 train_time:105524ms step_avg:139.21ms
step:769/1405 train_time:105671ms step_avg:139.22ms
step:770/1405 train_time:105816ms step_avg:139.23ms
step:771/1405 train_time:105959ms step_avg:139.24ms
step:772/1405 train_time:106102ms step_avg:139.24ms
step:773/1405 train_time:106247ms step_avg:139.25ms
step:774/1405 train_time:106392ms step_avg:139.26ms
step:775/1405 train_time:106536ms step_avg:139.26ms
step:776/1405 train_time:106681ms step_avg:139.27ms
step:777/1405 train_time:106826ms step_avg:139.28ms
step:778/1405 train_time:106972ms step_avg:139.29ms
step:779/1405 train_time:107117ms step_avg:139.29ms
step:780/1405 train_time:107262ms step_avg:139.30ms
step:781/1405 train_time:107405ms step_avg:139.31ms
step:782/1405 train_time:107550ms step_avg:139.31ms
step:783/1405 train_time:107694ms step_avg:139.32ms
step:784/1405 train_time:107839ms step_avg:139.33ms
step:785/1405 train_time:107984ms step_avg:139.33ms
step:786/1405 train_time:108129ms step_avg:139.34ms
step:787/1405 train_time:108274ms step_avg:139.35ms
step:788/1405 train_time:108417ms step_avg:139.35ms
step:789/1405 train_time:108561ms step_avg:139.36ms
step:790/1405 train_time:108705ms step_avg:139.37ms
step:791/1405 train_time:108850ms step_avg:139.37ms
step:792/1405 train_time:108996ms step_avg:139.38ms
step:793/1405 train_time:109140ms step_avg:139.39ms
step:794/1405 train_time:109285ms step_avg:139.39ms
step:795/1405 train_time:109431ms step_avg:139.40ms
step:796/1405 train_time:109577ms step_avg:139.41ms
step:797/1405 train_time:109721ms step_avg:139.42ms
step:798/1405 train_time:109865ms step_avg:139.42ms
step:799/1405 train_time:110011ms step_avg:139.43ms
step:800/1405 train_time:110156ms step_avg:139.44ms
step:801/1405 train_time:110301ms step_avg:139.44ms
step:802/1405 train_time:110446ms step_avg:139.45ms
step:803/1405 train_time:110590ms step_avg:139.46ms
step:804/1405 train_time:110736ms step_avg:139.47ms
step:805/1405 train_time:110880ms step_avg:139.47ms
step:806/1405 train_time:111024ms step_avg:139.48ms
step:807/1405 train_time:111168ms step_avg:139.48ms
step:808/1405 train_time:111312ms step_avg:139.49ms
step:809/1405 train_time:111456ms step_avg:139.49ms
step:810/1405 train_time:111600ms step_avg:139.50ms
step:811/1405 train_time:111746ms step_avg:139.51ms
step:812/1405 train_time:111892ms step_avg:139.52ms
step:813/1405 train_time:112036ms step_avg:139.52ms
step:814/1405 train_time:112180ms step_avg:139.53ms
step:815/1405 train_time:112325ms step_avg:139.53ms
step:816/1405 train_time:112470ms step_avg:139.54ms
step:817/1405 train_time:112615ms step_avg:139.55ms
step:818/1405 train_time:112760ms step_avg:139.55ms
step:819/1405 train_time:112904ms step_avg:139.56ms
step:820/1405 train_time:113049ms step_avg:139.57ms
step:821/1405 train_time:113193ms step_avg:139.57ms
step:822/1405 train_time:113337ms step_avg:139.58ms
step:823/1405 train_time:113482ms step_avg:139.58ms
step:824/1405 train_time:113625ms step_avg:139.59ms
step:825/1405 train_time:113771ms step_avg:139.60ms
step:826/1405 train_time:113917ms step_avg:139.60ms
step:827/1405 train_time:114059ms step_avg:139.61ms
step:828/1405 train_time:114204ms step_avg:139.61ms
step:829/1405 train_time:114348ms step_avg:139.62ms
step:830/1405 train_time:114493ms step_avg:139.63ms
step:831/1405 train_time:114638ms step_avg:139.63ms
step:832/1405 train_time:114782ms step_avg:139.64ms
step:833/1405 train_time:114929ms step_avg:139.65ms
step:834/1405 train_time:115074ms step_avg:139.65ms
step:835/1405 train_time:115218ms step_avg:139.66ms
step:836/1405 train_time:115364ms step_avg:139.67ms
step:837/1405 train_time:115508ms step_avg:139.67ms
step:838/1405 train_time:115654ms step_avg:139.68ms
step:839/1405 train_time:115797ms step_avg:139.68ms
step:840/1405 train_time:115942ms step_avg:139.69ms
step:841/1405 train_time:116086ms step_avg:139.69ms
step:842/1405 train_time:116233ms step_avg:139.70ms
step:843/1405 train_time:116378ms step_avg:139.71ms
step:844/1405 train_time:116521ms step_avg:139.71ms
step:845/1405 train_time:116665ms step_avg:139.72ms
step:846/1405 train_time:116811ms step_avg:139.73ms
step:847/1405 train_time:116956ms step_avg:139.73ms
step:848/1405 train_time:117102ms step_avg:139.74ms
step:849/1405 train_time:117247ms step_avg:139.75ms
step:850/1405 train_time:117393ms step_avg:139.75ms
step:851/1405 train_time:117537ms step_avg:139.76ms
step:852/1405 train_time:117682ms step_avg:139.77ms
step:853/1405 train_time:117828ms step_avg:139.77ms
step:854/1405 train_time:117973ms step_avg:139.78ms
step:855/1405 train_time:118117ms step_avg:139.78ms
step:856/1405 train_time:118263ms step_avg:139.79ms
step:857/1405 train_time:118409ms step_avg:139.80ms
step:858/1405 train_time:118555ms step_avg:139.81ms
step:859/1405 train_time:118700ms step_avg:139.81ms
step:860/1405 train_time:118844ms step_avg:139.82ms
step:861/1405 train_time:118990ms step_avg:139.82ms
step:862/1405 train_time:119135ms step_avg:139.83ms
step:863/1405 train_time:119279ms step_avg:139.83ms
step:864/1405 train_time:119423ms step_avg:139.84ms
step:865/1405 train_time:119568ms step_avg:139.85ms
step:866/1405 train_time:119714ms step_avg:139.85ms
step:867/1405 train_time:119859ms step_avg:139.86ms
step:868/1405 train_time:120002ms step_avg:139.86ms
step:869/1405 train_time:120147ms step_avg:139.87ms
step:870/1405 train_time:120292ms step_avg:139.87ms
step:871/1405 train_time:120437ms step_avg:139.88ms
step:872/1405 train_time:120581ms step_avg:139.89ms
step:873/1405 train_time:120725ms step_avg:139.89ms
step:874/1405 train_time:120873ms step_avg:139.90ms
step:875/1405 train_time:121017ms step_avg:139.90ms
step:875/1405 val_loss:3.4754 train_time:121087ms step_avg:139.98ms
step:876/1405 train_time:121163ms step_avg:139.91ms
step:877/1405 train_time:121309ms step_avg:139.92ms
step:878/1405 train_time:121453ms step_avg:139.92ms
step:879/1405 train_time:121597ms step_avg:139.93ms
step:880/1405 train_time:121742ms step_avg:139.93ms
step:881/1405 train_time:121886ms step_avg:139.94ms
step:882/1405 train_time:122031ms step_avg:139.94ms
step:883/1405 train_time:122175ms step_avg:139.95ms
step:884/1405 train_time:122320ms step_avg:139.95ms
step:885/1405 train_time:122467ms step_avg:139.96ms
step:886/1405 train_time:122611ms step_avg:139.97ms
step:887/1405 train_time:122755ms step_avg:139.97ms
step:888/1405 train_time:122900ms step_avg:139.98ms
step:889/1405 train_time:123046ms step_avg:139.98ms
step:890/1405 train_time:123192ms step_avg:139.99ms
step:891/1405 train_time:123336ms step_avg:140.00ms
step:892/1405 train_time:123481ms step_avg:140.00ms
step:893/1405 train_time:123627ms step_avg:140.01ms
step:894/1405 train_time:123772ms step_avg:140.01ms
step:895/1405 train_time:123916ms step_avg:140.02ms
step:896/1405 train_time:124061ms step_avg:140.02ms
step:897/1405 train_time:124208ms step_avg:140.03ms
step:898/1405 train_time:124352ms step_avg:140.04ms
step:899/1405 train_time:124498ms step_avg:140.04ms
step:900/1405 train_time:124643ms step_avg:140.05ms
step:901/1405 train_time:124788ms step_avg:140.05ms
step:902/1405 train_time:124932ms step_avg:140.06ms
step:903/1405 train_time:125076ms step_avg:140.06ms
step:904/1405 train_time:125222ms step_avg:140.07ms
step:905/1405 train_time:125368ms step_avg:140.08ms
step:906/1405 train_time:125513ms step_avg:140.08ms
step:907/1405 train_time:125659ms step_avg:140.09ms
step:908/1405 train_time:125804ms step_avg:140.09ms
step:909/1405 train_time:125949ms step_avg:140.10ms
step:910/1405 train_time:126093ms step_avg:140.10ms
step:911/1405 train_time:126238ms step_avg:140.11ms
step:912/1405 train_time:126382ms step_avg:140.11ms
step:913/1405 train_time:126528ms step_avg:140.12ms
step:914/1405 train_time:126672ms step_avg:140.12ms
step:915/1405 train_time:126816ms step_avg:140.13ms
step:916/1405 train_time:126961ms step_avg:140.13ms
step:917/1405 train_time:127106ms step_avg:140.14ms
step:918/1405 train_time:127251ms step_avg:140.14ms
step:919/1405 train_time:127399ms step_avg:140.15ms
step:920/1405 train_time:127544ms step_avg:140.16ms
step:921/1405 train_time:127689ms step_avg:140.16ms
step:922/1405 train_time:127833ms step_avg:140.17ms
step:923/1405 train_time:127976ms step_avg:140.17ms
step:924/1405 train_time:128121ms step_avg:140.18ms
step:925/1405 train_time:128266ms step_avg:140.18ms
step:926/1405 train_time:128412ms step_avg:140.19ms
step:927/1405 train_time:128556ms step_avg:140.19ms
step:928/1405 train_time:128701ms step_avg:140.20ms
step:929/1405 train_time:128847ms step_avg:140.20ms
step:930/1405 train_time:128992ms step_avg:140.21ms
step:931/1405 train_time:129137ms step_avg:140.21ms
step:932/1405 train_time:129284ms step_avg:140.22ms
step:933/1405 train_time:129429ms step_avg:140.23ms
step:934/1405 train_time:129573ms step_avg:140.23ms
step:935/1405 train_time:129719ms step_avg:140.24ms
step:936/1405 train_time:129864ms step_avg:140.24ms
step:937/1405 train_time:130010ms step_avg:140.25ms
step:938/1405 train_time:130155ms step_avg:140.25ms
step:939/1405 train_time:130303ms step_avg:140.26ms
step:940/1405 train_time:130451ms step_avg:140.27ms
step:941/1405 train_time:130596ms step_avg:140.28ms
step:942/1405 train_time:130742ms step_avg:140.28ms
step:943/1405 train_time:130888ms step_avg:140.29ms
step:944/1405 train_time:131035ms step_avg:140.29ms
step:945/1405 train_time:131181ms step_avg:140.30ms
step:946/1405 train_time:131329ms step_avg:140.31ms
step:947/1405 train_time:131474ms step_avg:140.31ms
step:948/1405 train_time:131621ms step_avg:140.32ms
step:949/1405 train_time:131769ms step_avg:140.33ms
step:950/1405 train_time:131915ms step_avg:140.34ms
step:951/1405 train_time:132100ms step_avg:140.38ms
step:952/1405 train_time:132247ms step_avg:140.39ms
step:953/1405 train_time:132392ms step_avg:140.39ms
step:954/1405 train_time:132538ms step_avg:140.40ms
step:955/1405 train_time:132683ms step_avg:140.41ms
step:956/1405 train_time:132829ms step_avg:140.41ms
step:957/1405 train_time:132974ms step_avg:140.42ms
step:958/1405 train_time:133124ms step_avg:140.43ms
step:959/1405 train_time:133272ms step_avg:140.43ms
step:960/1405 train_time:133418ms step_avg:140.44ms
step:961/1405 train_time:133565ms step_avg:140.45ms
step:962/1405 train_time:133711ms step_avg:140.45ms
step:963/1405 train_time:133859ms step_avg:140.46ms
step:964/1405 train_time:134009ms step_avg:140.47ms
step:965/1405 train_time:134155ms step_avg:140.48ms
step:966/1405 train_time:134301ms step_avg:140.48ms
step:967/1405 train_time:134449ms step_avg:140.49ms
step:968/1405 train_time:134593ms step_avg:140.49ms
step:969/1405 train_time:134741ms step_avg:140.50ms
step:970/1405 train_time:134888ms step_avg:140.51ms
step:971/1405 train_time:135035ms step_avg:140.51ms
step:972/1405 train_time:135182ms step_avg:140.52ms
step:973/1405 train_time:135329ms step_avg:140.53ms
step:974/1405 train_time:135475ms step_avg:140.53ms
step:975/1405 train_time:135621ms step_avg:140.54ms
step:976/1405 train_time:135768ms step_avg:140.55ms
step:977/1405 train_time:135913ms step_avg:140.55ms
step:978/1405 train_time:136060ms step_avg:140.56ms
step:979/1405 train_time:136208ms step_avg:140.57ms
step:980/1405 train_time:136354ms step_avg:140.57ms
step:981/1405 train_time:136499ms step_avg:140.58ms
step:982/1405 train_time:136645ms step_avg:140.58ms
step:983/1405 train_time:136793ms step_avg:140.59ms
step:984/1405 train_time:136938ms step_avg:140.59ms
step:985/1405 train_time:137086ms step_avg:140.60ms
step:986/1405 train_time:137235ms step_avg:140.61ms
step:987/1405 train_time:137381ms step_avg:140.62ms
step:988/1405 train_time:137528ms step_avg:140.62ms
step:989/1405 train_time:137674ms step_avg:140.63ms
step:990/1405 train_time:137821ms step_avg:140.63ms
step:991/1405 train_time:137968ms step_avg:140.64ms
step:992/1405 train_time:138115ms step_avg:140.65ms
step:993/1405 train_time:138264ms step_avg:140.66ms
step:994/1405 train_time:138411ms step_avg:140.66ms
step:995/1405 train_time:138557ms step_avg:140.67ms
step:996/1405 train_time:138701ms step_avg:140.67ms
step:997/1405 train_time:138849ms step_avg:140.68ms
step:998/1405 train_time:138995ms step_avg:140.68ms
step:999/1405 train_time:139141ms step_avg:140.69ms
step:1000/1405 train_time:139288ms step_avg:140.69ms
step:1000/1405 val_loss:3.4114 train_time:139358ms step_avg:140.77ms
step:1001/1405 train_time:139434ms step_avg:140.70ms
step:1002/1405 train_time:139581ms step_avg:140.71ms
step:1003/1405 train_time:139728ms step_avg:140.71ms
step:1004/1405 train_time:139875ms step_avg:140.72ms
step:1005/1405 train_time:140020ms step_avg:140.72ms
step:1006/1405 train_time:140166ms step_avg:140.73ms
step:1007/1405 train_time:140313ms step_avg:140.73ms
step:1008/1405 train_time:140461ms step_avg:140.74ms
step:1009/1405 train_time:140611ms step_avg:140.75ms
step:1010/1405 train_time:140757ms step_avg:140.76ms
step:1011/1405 train_time:140902ms step_avg:140.76ms
step:1012/1405 train_time:141049ms step_avg:140.77ms
step:1013/1405 train_time:141195ms step_avg:140.77ms
step:1014/1405 train_time:141341ms step_avg:140.78ms
step:1015/1405 train_time:141489ms step_avg:140.79ms
step:1016/1405 train_time:141636ms step_avg:140.79ms
step:1017/1405 train_time:141782ms step_avg:140.80ms
step:1018/1405 train_time:141930ms step_avg:140.80ms
step:1019/1405 train_time:142075ms step_avg:140.81ms
step:1020/1405 train_time:142222ms step_avg:140.81ms
step:1021/1405 train_time:142368ms step_avg:140.82ms
step:1022/1405 train_time:142514ms step_avg:140.82ms
step:1023/1405 train_time:142661ms step_avg:140.83ms
step:1024/1405 train_time:142809ms step_avg:140.84ms
step:1025/1405 train_time:142956ms step_avg:140.84ms
step:1026/1405 train_time:143101ms step_avg:140.85ms
step:1027/1405 train_time:143249ms step_avg:140.85ms
step:1028/1405 train_time:143395ms step_avg:140.86ms
step:1029/1405 train_time:143541ms step_avg:140.86ms
step:1030/1405 train_time:143688ms step_avg:140.87ms
step:1031/1405 train_time:143834ms step_avg:140.88ms
step:1032/1405 train_time:143980ms step_avg:140.88ms
step:1033/1405 train_time:144126ms step_avg:140.89ms
step:1034/1405 train_time:144273ms step_avg:140.89ms
step:1035/1405 train_time:144419ms step_avg:140.90ms
step:1036/1405 train_time:144566ms step_avg:140.90ms
step:1037/1405 train_time:144713ms step_avg:140.91ms
step:1038/1405 train_time:144859ms step_avg:140.91ms
step:1039/1405 train_time:145007ms step_avg:140.92ms
step:1040/1405 train_time:145152ms step_avg:140.92ms
step:1041/1405 train_time:145299ms step_avg:140.93ms
step:1042/1405 train_time:145445ms step_avg:140.94ms
step:1043/1405 train_time:145592ms step_avg:140.94ms
step:1044/1405 train_time:145739ms step_avg:140.95ms
step:1045/1405 train_time:145887ms step_avg:140.95ms
step:1046/1405 train_time:146033ms step_avg:140.96ms
step:1047/1405 train_time:146180ms step_avg:140.96ms
step:1048/1405 train_time:146328ms step_avg:140.97ms
step:1049/1405 train_time:146475ms step_avg:140.98ms
step:1050/1405 train_time:146621ms step_avg:140.98ms
step:1051/1405 train_time:146769ms step_avg:140.99ms
step:1052/1405 train_time:146916ms step_avg:140.99ms
step:1053/1405 train_time:147062ms step_avg:141.00ms
step:1054/1405 train_time:147210ms step_avg:141.01ms
step:1055/1405 train_time:147356ms step_avg:141.01ms
step:1056/1405 train_time:147503ms step_avg:141.02ms
step:1057/1405 train_time:147650ms step_avg:141.02ms
step:1058/1405 train_time:147797ms step_avg:141.03ms
step:1059/1405 train_time:147946ms step_avg:141.04ms
step:1060/1405 train_time:148094ms step_avg:141.04ms
step:1061/1405 train_time:148239ms step_avg:141.05ms
step:1062/1405 train_time:148387ms step_avg:141.05ms
step:1063/1405 train_time:148533ms step_avg:141.06ms
step:1064/1405 train_time:148679ms step_avg:141.06ms
step:1065/1405 train_time:148826ms step_avg:141.07ms
step:1066/1405 train_time:148973ms step_avg:141.07ms
step:1067/1405 train_time:149120ms step_avg:141.08ms
step:1068/1405 train_time:149267ms step_avg:141.08ms
step:1069/1405 train_time:149416ms step_avg:141.09ms
step:1070/1405 train_time:149562ms step_avg:141.10ms
step:1071/1405 train_time:149710ms step_avg:141.10ms
step:1072/1405 train_time:149857ms step_avg:141.11ms
step:1073/1405 train_time:150003ms step_avg:141.11ms
step:1074/1405 train_time:150149ms step_avg:141.12ms
step:1075/1405 train_time:150295ms step_avg:141.12ms
step:1076/1405 train_time:150441ms step_avg:141.13ms
step:1077/1405 train_time:150589ms step_avg:141.13ms
step:1078/1405 train_time:150739ms step_avg:141.14ms
step:1079/1405 train_time:150888ms step_avg:141.15ms
step:1080/1405 train_time:151035ms step_avg:141.15ms
step:1081/1405 train_time:151181ms step_avg:141.16ms
step:1082/1405 train_time:151329ms step_avg:141.17ms
step:1083/1405 train_time:151475ms step_avg:141.17ms
step:1084/1405 train_time:151623ms step_avg:141.18ms
step:1085/1405 train_time:151770ms step_avg:141.18ms
step:1086/1405 train_time:151917ms step_avg:141.19ms
step:1087/1405 train_time:152064ms step_avg:141.19ms
step:1088/1405 train_time:152212ms step_avg:141.20ms
step:1089/1405 train_time:152360ms step_avg:141.20ms
step:1090/1405 train_time:152508ms step_avg:141.21ms
step:1091/1405 train_time:152656ms step_avg:141.22ms
step:1092/1405 train_time:152801ms step_avg:141.22ms
step:1093/1405 train_time:152949ms step_avg:141.23ms
step:1094/1405 train_time:153096ms step_avg:141.23ms
step:1095/1405 train_time:153242ms step_avg:141.24ms
step:1096/1405 train_time:153391ms step_avg:141.24ms
step:1097/1405 train_time:153537ms step_avg:141.25ms
step:1098/1405 train_time:153683ms step_avg:141.25ms
step:1099/1405 train_time:153830ms step_avg:141.26ms
step:1100/1405 train_time:153976ms step_avg:141.26ms
step:1101/1405 train_time:154123ms step_avg:141.27ms
step:1102/1405 train_time:154271ms step_avg:141.27ms
step:1103/1405 train_time:154419ms step_avg:141.28ms
step:1104/1405 train_time:154565ms step_avg:141.28ms
step:1105/1405 train_time:154714ms step_avg:141.29ms
step:1106/1405 train_time:154861ms step_avg:141.30ms
step:1107/1405 train_time:155008ms step_avg:141.30ms
step:1108/1405 train_time:155155ms step_avg:141.31ms
step:1109/1405 train_time:155301ms step_avg:141.31ms
step:1110/1405 train_time:155449ms step_avg:141.32ms
step:1111/1405 train_time:155596ms step_avg:141.32ms
step:1112/1405 train_time:155742ms step_avg:141.33ms
step:1113/1405 train_time:155889ms step_avg:141.33ms
step:1114/1405 train_time:156035ms step_avg:141.34ms
step:1115/1405 train_time:156181ms step_avg:141.34ms
step:1116/1405 train_time:156328ms step_avg:141.35ms
step:1117/1405 train_time:156477ms step_avg:141.35ms
step:1118/1405 train_time:156625ms step_avg:141.36ms
step:1119/1405 train_time:156772ms step_avg:141.36ms
step:1120/1405 train_time:156919ms step_avg:141.37ms
step:1121/1405 train_time:157066ms step_avg:141.37ms
step:1122/1405 train_time:157212ms step_avg:141.38ms
step:1123/1405 train_time:157358ms step_avg:141.38ms
step:1124/1405 train_time:157505ms step_avg:141.39ms
step:1125/1405 train_time:157652ms step_avg:141.39ms
step:1125/1405 val_loss:3.3583 train_time:157723ms step_avg:141.46ms
step:1126/1405 train_time:157801ms step_avg:141.40ms
step:1127/1405 train_time:157947ms step_avg:141.40ms
step:1128/1405 train_time:158094ms step_avg:141.41ms
step:1129/1405 train_time:158239ms step_avg:141.41ms
step:1130/1405 train_time:158385ms step_avg:141.42ms
step:1131/1405 train_time:158532ms step_avg:141.42ms
step:1132/1405 train_time:158679ms step_avg:141.42ms
step:1133/1405 train_time:158827ms step_avg:141.43ms
step:1134/1405 train_time:158976ms step_avg:141.44ms
step:1135/1405 train_time:159121ms step_avg:141.44ms
step:1136/1405 train_time:159271ms step_avg:141.45ms
step:1137/1405 train_time:159417ms step_avg:141.45ms
step:1138/1405 train_time:159563ms step_avg:141.46ms
step:1139/1405 train_time:159711ms step_avg:141.46ms
step:1140/1405 train_time:159860ms step_avg:141.47ms
step:1141/1405 train_time:160049ms step_avg:141.51ms
step:1142/1405 train_time:160196ms step_avg:141.52ms
step:1143/1405 train_time:160342ms step_avg:141.52ms
step:1144/1405 train_time:160488ms step_avg:141.52ms
step:1145/1405 train_time:160634ms step_avg:141.53ms
step:1146/1405 train_time:160781ms step_avg:141.53ms
step:1147/1405 train_time:160931ms step_avg:141.54ms
step:1148/1405 train_time:161079ms step_avg:141.55ms
step:1149/1405 train_time:161228ms step_avg:141.55ms
step:1150/1405 train_time:161375ms step_avg:141.56ms
step:1151/1405 train_time:161525ms step_avg:141.56ms
step:1152/1405 train_time:161674ms step_avg:141.57ms
step:1153/1405 train_time:161823ms step_avg:141.58ms
step:1154/1405 train_time:161972ms step_avg:141.58ms
step:1155/1405 train_time:162120ms step_avg:141.59ms
step:1156/1405 train_time:162272ms step_avg:141.60ms
step:1157/1405 train_time:162420ms step_avg:141.60ms
step:1158/1405 train_time:162569ms step_avg:141.61ms
step:1159/1405 train_time:162717ms step_avg:141.62ms
step:1160/1405 train_time:162864ms step_avg:141.62ms
step:1161/1405 train_time:163013ms step_avg:141.63ms
step:1162/1405 train_time:163161ms step_avg:141.63ms
step:1163/1405 train_time:163311ms step_avg:141.64ms
step:1164/1405 train_time:163459ms step_avg:141.65ms
step:1165/1405 train_time:163606ms step_avg:141.65ms
step:1166/1405 train_time:163754ms step_avg:141.66ms
step:1167/1405 train_time:163902ms step_avg:141.66ms
step:1168/1405 train_time:164051ms step_avg:141.67ms
step:1169/1405 train_time:164199ms step_avg:141.67ms
step:1170/1405 train_time:164348ms step_avg:141.68ms
step:1171/1405 train_time:164497ms step_avg:141.69ms
step:1172/1405 train_time:164645ms step_avg:141.69ms
step:1173/1405 train_time:164795ms step_avg:141.70ms
step:1174/1405 train_time:164948ms step_avg:141.71ms
step:1175/1405 train_time:165096ms step_avg:141.71ms
step:1176/1405 train_time:165245ms step_avg:141.72ms
step:1177/1405 train_time:165396ms step_avg:141.73ms
step:1178/1405 train_time:165544ms step_avg:141.73ms
step:1179/1405 train_time:165692ms step_avg:141.74ms
step:1180/1405 train_time:165845ms step_avg:141.75ms
step:1181/1405 train_time:165994ms step_avg:141.75ms
step:1182/1405 train_time:166141ms step_avg:141.76ms
step:1183/1405 train_time:166291ms step_avg:141.77ms
step:1184/1405 train_time:166439ms step_avg:141.77ms
step:1185/1405 train_time:166589ms step_avg:141.78ms
step:1186/1405 train_time:166737ms step_avg:141.78ms
step:1187/1405 train_time:166889ms step_avg:141.79ms
step:1188/1405 train_time:167036ms step_avg:141.80ms
step:1189/1405 train_time:167183ms step_avg:141.80ms
step:1190/1405 train_time:167333ms step_avg:141.81ms
step:1191/1405 train_time:167481ms step_avg:141.81ms
step:1192/1405 train_time:167630ms step_avg:141.82ms
step:1193/1405 train_time:167777ms step_avg:141.82ms
step:1194/1405 train_time:167925ms step_avg:141.83ms
step:1195/1405 train_time:168074ms step_avg:141.83ms
step:1196/1405 train_time:168222ms step_avg:141.84ms
step:1197/1405 train_time:168371ms step_avg:141.85ms
step:1198/1405 train_time:168521ms step_avg:141.85ms
step:1199/1405 train_time:168670ms step_avg:141.86ms
step:1200/1405 train_time:168817ms step_avg:141.86ms
step:1201/1405 train_time:168964ms step_avg:141.87ms
step:1202/1405 train_time:169119ms step_avg:141.88ms
step:1203/1405 train_time:169268ms step_avg:141.88ms
step:1204/1405 train_time:169417ms step_avg:141.89ms
step:1205/1405 train_time:169565ms step_avg:141.90ms
step:1206/1405 train_time:169714ms step_avg:141.90ms
step:1207/1405 train_time:169861ms step_avg:141.91ms
step:1208/1405 train_time:170010ms step_avg:141.91ms
step:1209/1405 train_time:170158ms step_avg:141.92ms
step:1210/1405 train_time:170308ms step_avg:141.92ms
step:1211/1405 train_time:170456ms step_avg:141.93ms
step:1212/1405 train_time:170604ms step_avg:141.93ms
step:1213/1405 train_time:170754ms step_avg:141.94ms
step:1214/1405 train_time:170903ms step_avg:141.95ms
step:1215/1405 train_time:171051ms step_avg:141.95ms
step:1216/1405 train_time:171198ms step_avg:141.96ms
step:1217/1405 train_time:171347ms step_avg:141.96ms
step:1218/1405 train_time:171494ms step_avg:141.97ms
step:1219/1405 train_time:171642ms step_avg:141.97ms
step:1220/1405 train_time:171790ms step_avg:141.98ms
step:1221/1405 train_time:171938ms step_avg:141.98ms
step:1222/1405 train_time:172086ms step_avg:141.98ms
step:1223/1405 train_time:172236ms step_avg:141.99ms
step:1224/1405 train_time:172386ms step_avg:142.00ms
step:1225/1405 train_time:172536ms step_avg:142.00ms
step:1226/1405 train_time:172684ms step_avg:142.01ms
step:1227/1405 train_time:172834ms step_avg:142.02ms
step:1228/1405 train_time:172981ms step_avg:142.02ms
step:1229/1405 train_time:173130ms step_avg:142.03ms
step:1230/1405 train_time:173278ms step_avg:142.03ms
step:1231/1405 train_time:173427ms step_avg:142.04ms
step:1232/1405 train_time:173576ms step_avg:142.04ms
step:1233/1405 train_time:173724ms step_avg:142.05ms
step:1234/1405 train_time:173871ms step_avg:142.05ms
step:1235/1405 train_time:174018ms step_avg:142.06ms
step:1236/1405 train_time:174166ms step_avg:142.06ms
step:1237/1405 train_time:174314ms step_avg:142.07ms
step:1238/1405 train_time:174467ms step_avg:142.07ms
step:1239/1405 train_time:174615ms step_avg:142.08ms
step:1240/1405 train_time:174763ms step_avg:142.08ms
step:1241/1405 train_time:174915ms step_avg:142.09ms
step:1242/1405 train_time:175061ms step_avg:142.10ms
step:1243/1405 train_time:175210ms step_avg:142.10ms
step:1244/1405 train_time:175357ms step_avg:142.10ms
step:1245/1405 train_time:175505ms step_avg:142.11ms
step:1246/1405 train_time:175654ms step_avg:142.11ms
step:1247/1405 train_time:175801ms step_avg:142.12ms
step:1248/1405 train_time:175950ms step_avg:142.12ms
step:1249/1405 train_time:176099ms step_avg:142.13ms
step:1250/1405 train_time:176246ms step_avg:142.13ms
step:1250/1405 val_loss:3.3113 train_time:176319ms step_avg:142.19ms
step:1251/1405 train_time:176399ms step_avg:142.14ms
step:1252/1405 train_time:176548ms step_avg:142.15ms
step:1253/1405 train_time:176696ms step_avg:142.15ms
step:1254/1405 train_time:176844ms step_avg:142.16ms
step:1255/1405 train_time:176994ms step_avg:142.16ms
step:1256/1405 train_time:177142ms step_avg:142.17ms
step:1257/1405 train_time:177289ms step_avg:142.17ms
step:1258/1405 train_time:177440ms step_avg:142.18ms
step:1259/1405 train_time:177589ms step_avg:142.18ms
step:1260/1405 train_time:177736ms step_avg:142.19ms
step:1261/1405 train_time:177885ms step_avg:142.19ms
step:1262/1405 train_time:178033ms step_avg:142.20ms
step:1263/1405 train_time:178183ms step_avg:142.21ms
step:1264/1405 train_time:178331ms step_avg:142.21ms
step:1265/1405 train_time:178479ms step_avg:142.21ms
step:1266/1405 train_time:178627ms step_avg:142.22ms
step:1267/1405 train_time:178775ms step_avg:142.22ms
step:1268/1405 train_time:178924ms step_avg:142.23ms
step:1269/1405 train_time:179075ms step_avg:142.24ms
step:1270/1405 train_time:179224ms step_avg:142.24ms
step:1271/1405 train_time:179372ms step_avg:142.25ms
step:1272/1405 train_time:179521ms step_avg:142.25ms
step:1273/1405 train_time:179667ms step_avg:142.25ms
step:1274/1405 train_time:179814ms step_avg:142.26ms
step:1275/1405 train_time:179964ms step_avg:142.26ms
step:1276/1405 train_time:180111ms step_avg:142.27ms
step:1277/1405 train_time:180261ms step_avg:142.27ms
step:1278/1405 train_time:180409ms step_avg:142.28ms
step:1279/1405 train_time:180558ms step_avg:142.28ms
step:1280/1405 train_time:180707ms step_avg:142.29ms
step:1281/1405 train_time:180856ms step_avg:142.29ms
step:1282/1405 train_time:181004ms step_avg:142.30ms
step:1283/1405 train_time:181152ms step_avg:142.30ms
step:1284/1405 train_time:181302ms step_avg:142.31ms
step:1285/1405 train_time:181449ms step_avg:142.31ms
step:1286/1405 train_time:181598ms step_avg:142.32ms
step:1287/1405 train_time:181745ms step_avg:142.32ms
step:1288/1405 train_time:181894ms step_avg:142.33ms
step:1289/1405 train_time:182045ms step_avg:142.33ms
step:1290/1405 train_time:182197ms step_avg:142.34ms
step:1291/1405 train_time:182346ms step_avg:142.35ms
step:1292/1405 train_time:182495ms step_avg:142.35ms
step:1293/1405 train_time:182644ms step_avg:142.36ms
step:1294/1405 train_time:182792ms step_avg:142.36ms
step:1295/1405 train_time:182942ms step_avg:142.37ms
step:1296/1405 train_time:183089ms step_avg:142.37ms
step:1297/1405 train_time:183239ms step_avg:142.38ms
step:1298/1405 train_time:183387ms step_avg:142.38ms
step:1299/1405 train_time:183535ms step_avg:142.39ms
step:1300/1405 train_time:183684ms step_avg:142.39ms
step:1301/1405 train_time:183831ms step_avg:142.39ms
step:1302/1405 train_time:183981ms step_avg:142.40ms
step:1303/1405 train_time:184130ms step_avg:142.41ms
step:1304/1405 train_time:184280ms step_avg:142.41ms
step:1305/1405 train_time:184428ms step_avg:142.42ms
step:1306/1405 train_time:184578ms step_avg:142.42ms
step:1307/1405 train_time:184725ms step_avg:142.43ms
step:1308/1405 train_time:184875ms step_avg:142.43ms
step:1309/1405 train_time:185024ms step_avg:142.44ms
step:1310/1405 train_time:185174ms step_avg:142.44ms
step:1311/1405 train_time:185323ms step_avg:142.45ms
step:1312/1405 train_time:185470ms step_avg:142.45ms
step:1313/1405 train_time:185619ms step_avg:142.46ms
step:1314/1405 train_time:185767ms step_avg:142.46ms
step:1315/1405 train_time:185917ms step_avg:142.47ms
step:1316/1405 train_time:186065ms step_avg:142.47ms
step:1317/1405 train_time:186213ms step_avg:142.47ms
step:1318/1405 train_time:186365ms step_avg:142.48ms
step:1319/1405 train_time:186513ms step_avg:142.49ms
step:1320/1405 train_time:186662ms step_avg:142.49ms
step:1321/1405 train_time:186809ms step_avg:142.49ms
step:1322/1405 train_time:186960ms step_avg:142.50ms
step:1323/1405 train_time:187109ms step_avg:142.51ms
step:1324/1405 train_time:187258ms step_avg:142.51ms
step:1325/1405 train_time:187407ms step_avg:142.51ms
step:1326/1405 train_time:187557ms step_avg:142.52ms
step:1327/1405 train_time:187706ms step_avg:142.53ms
step:1328/1405 train_time:187854ms step_avg:142.53ms
step:1329/1405 train_time:188009ms step_avg:142.54ms
step:1330/1405 train_time:188159ms step_avg:142.54ms
step:1331/1405 train_time:188349ms step_avg:142.58ms
step:1332/1405 train_time:188497ms step_avg:142.59ms
step:1333/1405 train_time:188645ms step_avg:142.59ms
step:1334/1405 train_time:188792ms step_avg:142.59ms
step:1335/1405 train_time:188939ms step_avg:142.60ms
step:1336/1405 train_time:189087ms step_avg:142.60ms
step:1337/1405 train_time:189237ms step_avg:142.61ms
step:1338/1405 train_time:189386ms step_avg:142.61ms
step:1339/1405 train_time:189535ms step_avg:142.62ms
step:1340/1405 train_time:189684ms step_avg:142.62ms
step:1341/1405 train_time:189831ms step_avg:142.62ms
step:1342/1405 train_time:189980ms step_avg:142.63ms
step:1343/1405 train_time:190127ms step_avg:142.63ms
step:1344/1405 train_time:190274ms step_avg:142.63ms
step:1345/1405 train_time:190423ms step_avg:142.64ms
step:1346/1405 train_time:190571ms step_avg:142.64ms
step:1347/1405 train_time:190721ms step_avg:142.65ms
step:1348/1405 train_time:190867ms step_avg:142.65ms
step:1349/1405 train_time:191015ms step_avg:142.66ms
step:1350/1405 train_time:191164ms step_avg:142.66ms
step:1351/1405 train_time:191311ms step_avg:142.66ms
step:1352/1405 train_time:191462ms step_avg:142.67ms
step:1353/1405 train_time:191611ms step_avg:142.67ms
step:1354/1405 train_time:191761ms step_avg:142.68ms
step:1355/1405 train_time:191909ms step_avg:142.68ms
step:1356/1405 train_time:192059ms step_avg:142.69ms
step:1357/1405 train_time:192209ms step_avg:142.69ms
step:1358/1405 train_time:192359ms step_avg:142.70ms
step:1359/1405 train_time:192508ms step_avg:142.70ms
step:1360/1405 train_time:192659ms step_avg:142.71ms
step:1361/1405 train_time:192811ms step_avg:142.72ms
step:1362/1405 train_time:192963ms step_avg:142.72ms
step:1363/1405 train_time:193113ms step_avg:142.73ms
step:1364/1405 train_time:193263ms step_avg:142.73ms
step:1365/1405 train_time:193410ms step_avg:142.74ms
step:1366/1405 train_time:193560ms step_avg:142.74ms
step:1367/1405 train_time:193710ms step_avg:142.75ms
step:1368/1405 train_time:193862ms step_avg:142.76ms
step:1369/1405 train_time:194015ms step_avg:142.76ms
step:1370/1405 train_time:194167ms step_avg:142.77ms
step:1371/1405 train_time:194317ms step_avg:142.78ms
step:1372/1405 train_time:194468ms step_avg:142.78ms
step:1373/1405 train_time:194617ms step_avg:142.79ms
step:1374/1405 train_time:194768ms step_avg:142.79ms
step:1375/1405 train_time:194918ms step_avg:142.80ms
step:1375/1405 val_loss:3.2804 train_time:194990ms step_avg:142.85ms
step:1376/1405 train_time:195068ms step_avg:142.80ms
step:1377/1405 train_time:195217ms step_avg:142.81ms
step:1378/1405 train_time:195366ms step_avg:142.81ms
step:1379/1405 train_time:195515ms step_avg:142.82ms
step:1380/1405 train_time:195666ms step_avg:142.82ms
step:1381/1405 train_time:195816ms step_avg:142.83ms
step:1382/1405 train_time:195965ms step_avg:142.83ms
step:1383/1405 train_time:196116ms step_avg:142.84ms
step:1384/1405 train_time:196268ms step_avg:142.84ms
step:1385/1405 train_time:196417ms step_avg:142.85ms
step:1386/1405 train_time:196567ms step_avg:142.85ms
step:1387/1405 train_time:196720ms step_avg:142.86ms
step:1388/1405 train_time:196868ms step_avg:142.86ms
step:1389/1405 train_time:197019ms step_avg:142.87ms
step:1390/1405 train_time:197168ms step_avg:142.88ms
step:1391/1405 train_time:197317ms step_avg:142.88ms
step:1392/1405 train_time:197468ms step_avg:142.89ms
step:1393/1405 train_time:197617ms step_avg:142.89ms
step:1394/1405 train_time:197767ms step_avg:142.89ms
step:1395/1405 train_time:197916ms step_avg:142.90ms
step:1396/1405 train_time:198065ms step_avg:142.90ms
step:1397/1405 train_time:198213ms step_avg:142.91ms
step:1398/1405 train_time:198364ms step_avg:142.91ms
step:1399/1405 train_time:198512ms step_avg:142.92ms
step:1400/1405 train_time:198665ms step_avg:142.92ms
step:1401/1405 train_time:198812ms step_avg:142.93ms
step:1402/1405 train_time:198961ms step_avg:142.93ms
step:1403/1405 train_time:199113ms step_avg:142.94ms
step:1404/1405 train_time:199262ms step_avg:142.94ms
step:1405/1405 train_time:199412ms step_avg:142.95ms
step:1405/1405 val_loss:3.2778 train_time:199487ms step_avg:143.00ms
peak memory consumption: 31565 MiB
