import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask: torch.Tensor):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_masks(sliding_window_num_blocks: int):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            global_block_mask = BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
            local_window_bm = q_idx - kv_idx < max(1, sliding_window_num_blocks // 2)
            local_window_full_bm = local_window_bm
            local_nonzero_bm = causal_bm & local_window_bm & document_bm
            local_full_bm = causal_full_bm & local_window_full_bm & document_full_bm
            local_kv_num_blocks, local_kv_indices = dense_to_ordered(local_nonzero_bm & ~local_full_bm)
            local_full_kv_num_blocks, local_full_kv_indices = dense_to_ordered(local_full_bm)
            local_block_mask = BlockMask.from_kv_blocks(
                local_kv_num_blocks,
                local_kv_indices,
                local_full_kv_num_blocks,
                local_full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
            return global_block_mask, local_block_mask

        global_block_mask, local_block_mask = create_doc_swc_block_masks(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            block_mask = global_block_mask if i % 2 == 0 else local_block_mask
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            block_mask = local_block_mask if i % 2 == 0 else global_block_mask
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1405 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250110+cu126 compiled for CUDA 12.6
Wed Jan 15 09:16:54 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   38C    P0             126W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   32C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   29C    P0             117W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   37C    P0             129W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   38C    P0             123W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   30C    P0             115W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   36C    P0             116W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   29C    P0             117W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1405 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1405 train_time:27927ms step_avg:nanms
step:2/1405 train_time:28002ms step_avg:nanms
step:3/1405 train_time:28205ms step_avg:nanms
step:4/1405 train_time:28337ms step_avg:nanms
step:5/1405 train_time:28471ms step_avg:nanms
step:6/1405 train_time:28605ms step_avg:nanms
step:7/1405 train_time:28738ms step_avg:nanms
step:8/1405 train_time:28873ms step_avg:nanms
step:9/1405 train_time:29008ms step_avg:nanms
step:10/1405 train_time:29145ms step_avg:nanms
step:11/1405 train_time:137ms step_avg:nanms
step:12/1405 train_time:273ms step_avg:nanms
step:13/1405 train_time:408ms step_avg:135.91ms
step:14/1405 train_time:542ms step_avg:135.49ms
step:15/1405 train_time:676ms step_avg:135.11ms
step:16/1405 train_time:810ms step_avg:134.92ms
step:17/1405 train_time:946ms step_avg:135.18ms
step:18/1405 train_time:1084ms step_avg:135.53ms
step:19/1405 train_time:1220ms step_avg:135.54ms
step:20/1405 train_time:1355ms step_avg:135.49ms
step:21/1405 train_time:1490ms step_avg:135.48ms
step:22/1405 train_time:1626ms step_avg:135.53ms
step:23/1405 train_time:1762ms step_avg:135.57ms
step:24/1405 train_time:1896ms step_avg:135.45ms
step:25/1405 train_time:2033ms step_avg:135.50ms
step:26/1405 train_time:2168ms step_avg:135.49ms
step:27/1405 train_time:2304ms step_avg:135.52ms
step:28/1405 train_time:2439ms step_avg:135.49ms
step:29/1405 train_time:2574ms step_avg:135.46ms
step:30/1405 train_time:2708ms step_avg:135.40ms
step:31/1405 train_time:2845ms step_avg:135.47ms
step:32/1405 train_time:2979ms step_avg:135.42ms
step:33/1405 train_time:3116ms step_avg:135.46ms
step:34/1405 train_time:3251ms step_avg:135.46ms
step:35/1405 train_time:3388ms step_avg:135.53ms
step:36/1405 train_time:3523ms step_avg:135.51ms
step:37/1405 train_time:3658ms step_avg:135.49ms
step:38/1405 train_time:3793ms step_avg:135.46ms
step:39/1405 train_time:3929ms step_avg:135.49ms
step:40/1405 train_time:4063ms step_avg:135.44ms
step:41/1405 train_time:4199ms step_avg:135.45ms
step:42/1405 train_time:4334ms step_avg:135.45ms
step:43/1405 train_time:4470ms step_avg:135.46ms
step:44/1405 train_time:4605ms step_avg:135.43ms
step:45/1405 train_time:4742ms step_avg:135.48ms
step:46/1405 train_time:4876ms step_avg:135.45ms
step:47/1405 train_time:5011ms step_avg:135.45ms
step:48/1405 train_time:5146ms step_avg:135.42ms
step:49/1405 train_time:5282ms step_avg:135.44ms
step:50/1405 train_time:5418ms step_avg:135.44ms
step:51/1405 train_time:5553ms step_avg:135.43ms
step:52/1405 train_time:5688ms step_avg:135.43ms
step:53/1405 train_time:5823ms step_avg:135.42ms
step:54/1405 train_time:5958ms step_avg:135.40ms
step:55/1405 train_time:6093ms step_avg:135.40ms
step:56/1405 train_time:6229ms step_avg:135.42ms
step:57/1405 train_time:6365ms step_avg:135.43ms
step:58/1405 train_time:6500ms step_avg:135.41ms
step:59/1405 train_time:6635ms step_avg:135.41ms
step:60/1405 train_time:6771ms step_avg:135.42ms
step:61/1405 train_time:6905ms step_avg:135.40ms
step:62/1405 train_time:7041ms step_avg:135.41ms
step:63/1405 train_time:7176ms step_avg:135.39ms
step:64/1405 train_time:7311ms step_avg:135.38ms
step:65/1405 train_time:7446ms step_avg:135.38ms
step:66/1405 train_time:7582ms step_avg:135.39ms
step:67/1405 train_time:7716ms step_avg:135.37ms
step:68/1405 train_time:7852ms step_avg:135.38ms
step:69/1405 train_time:7988ms step_avg:135.39ms
step:70/1405 train_time:8122ms step_avg:135.37ms
step:71/1405 train_time:8257ms step_avg:135.36ms
step:72/1405 train_time:8392ms step_avg:135.35ms
step:73/1405 train_time:8527ms step_avg:135.35ms
step:74/1405 train_time:8662ms step_avg:135.34ms
step:75/1405 train_time:8798ms step_avg:135.36ms
step:76/1405 train_time:8935ms step_avg:135.38ms
step:77/1405 train_time:9072ms step_avg:135.41ms
step:78/1405 train_time:9207ms step_avg:135.39ms
step:79/1405 train_time:9344ms step_avg:135.42ms
step:80/1405 train_time:9478ms step_avg:135.40ms
step:81/1405 train_time:9613ms step_avg:135.39ms
step:82/1405 train_time:9748ms step_avg:135.39ms
step:83/1405 train_time:9885ms step_avg:135.41ms
step:84/1405 train_time:10022ms step_avg:135.43ms
step:85/1405 train_time:10156ms step_avg:135.42ms
step:86/1405 train_time:10293ms step_avg:135.44ms
step:87/1405 train_time:10430ms step_avg:135.45ms
step:88/1405 train_time:10565ms step_avg:135.45ms
step:89/1405 train_time:10701ms step_avg:135.45ms
step:90/1405 train_time:10837ms step_avg:135.46ms
step:91/1405 train_time:10974ms step_avg:135.48ms
step:92/1405 train_time:11110ms step_avg:135.49ms
step:93/1405 train_time:11247ms step_avg:135.50ms
step:94/1405 train_time:11383ms step_avg:135.51ms
step:95/1405 train_time:11519ms step_avg:135.52ms
step:96/1405 train_time:11655ms step_avg:135.52ms
step:97/1405 train_time:11792ms step_avg:135.53ms
step:98/1405 train_time:11928ms step_avg:135.54ms
step:99/1405 train_time:12063ms step_avg:135.54ms
step:100/1405 train_time:12198ms step_avg:135.53ms
step:101/1405 train_time:12335ms step_avg:135.55ms
step:102/1405 train_time:12473ms step_avg:135.58ms
step:103/1405 train_time:12608ms step_avg:135.57ms
step:104/1405 train_time:12745ms step_avg:135.58ms
step:105/1405 train_time:12880ms step_avg:135.58ms
step:106/1405 train_time:13016ms step_avg:135.58ms
step:107/1405 train_time:13153ms step_avg:135.60ms
step:108/1405 train_time:13291ms step_avg:135.62ms
step:109/1405 train_time:13429ms step_avg:135.65ms
step:110/1405 train_time:13567ms step_avg:135.67ms
step:111/1405 train_time:13704ms step_avg:135.68ms
step:112/1405 train_time:13842ms step_avg:135.71ms
step:113/1405 train_time:13978ms step_avg:135.71ms
step:114/1405 train_time:14116ms step_avg:135.73ms
step:115/1405 train_time:14253ms step_avg:135.74ms
step:116/1405 train_time:14391ms step_avg:135.77ms
step:117/1405 train_time:14529ms step_avg:135.79ms
step:118/1405 train_time:14666ms step_avg:135.80ms
step:119/1405 train_time:14803ms step_avg:135.81ms
step:120/1405 train_time:14942ms step_avg:135.83ms
step:121/1405 train_time:15080ms step_avg:135.86ms
step:122/1405 train_time:15219ms step_avg:135.89ms
step:123/1405 train_time:15357ms step_avg:135.90ms
step:124/1405 train_time:15495ms step_avg:135.92ms
step:125/1405 train_time:15631ms step_avg:135.92ms
step:125/1405 val_loss:4.4027 train_time:15698ms step_avg:136.51ms
step:126/1405 train_time:15773ms step_avg:135.97ms
step:127/1405 train_time:15915ms step_avg:136.02ms
step:128/1405 train_time:16053ms step_avg:136.04ms
step:129/1405 train_time:16189ms step_avg:136.04ms
step:130/1405 train_time:16326ms step_avg:136.05ms
step:131/1405 train_time:16462ms step_avg:136.05ms
step:132/1405 train_time:16599ms step_avg:136.05ms
step:133/1405 train_time:16737ms step_avg:136.07ms
step:134/1405 train_time:16878ms step_avg:136.11ms
step:135/1405 train_time:17021ms step_avg:136.17ms
step:136/1405 train_time:17160ms step_avg:136.19ms
step:137/1405 train_time:17296ms step_avg:136.19ms
step:138/1405 train_time:17434ms step_avg:136.20ms
step:139/1405 train_time:17571ms step_avg:136.21ms
step:140/1405 train_time:17710ms step_avg:136.23ms
step:141/1405 train_time:17846ms step_avg:136.23ms
step:142/1405 train_time:17985ms step_avg:136.25ms
step:143/1405 train_time:18126ms step_avg:136.28ms
step:144/1405 train_time:18265ms step_avg:136.31ms
step:145/1405 train_time:18401ms step_avg:136.31ms
step:146/1405 train_time:18539ms step_avg:136.32ms
step:147/1405 train_time:18676ms step_avg:136.32ms
step:148/1405 train_time:18814ms step_avg:136.33ms
step:149/1405 train_time:18951ms step_avg:136.34ms
step:150/1405 train_time:19093ms step_avg:136.38ms
step:151/1405 train_time:19232ms step_avg:136.40ms
step:152/1405 train_time:19371ms step_avg:136.42ms
step:153/1405 train_time:19510ms step_avg:136.43ms
step:154/1405 train_time:19646ms step_avg:136.43ms
step:155/1405 train_time:19784ms step_avg:136.44ms
step:156/1405 train_time:19924ms step_avg:136.46ms
step:157/1405 train_time:20062ms step_avg:136.47ms
step:158/1405 train_time:20201ms step_avg:136.50ms
step:159/1405 train_time:20339ms step_avg:136.50ms
step:160/1405 train_time:20477ms step_avg:136.52ms
step:161/1405 train_time:20615ms step_avg:136.52ms
step:162/1405 train_time:20753ms step_avg:136.53ms
step:163/1405 train_time:20892ms step_avg:136.55ms
step:164/1405 train_time:21031ms step_avg:136.57ms
step:165/1405 train_time:21171ms step_avg:136.59ms
step:166/1405 train_time:21310ms step_avg:136.60ms
step:167/1405 train_time:21447ms step_avg:136.61ms
step:168/1405 train_time:21586ms step_avg:136.62ms
step:169/1405 train_time:21724ms step_avg:136.63ms
step:170/1405 train_time:21863ms step_avg:136.64ms
step:171/1405 train_time:22001ms step_avg:136.65ms
step:172/1405 train_time:22140ms step_avg:136.66ms
step:173/1405 train_time:22279ms step_avg:136.68ms
step:174/1405 train_time:22417ms step_avg:136.69ms
step:175/1405 train_time:22554ms step_avg:136.69ms
step:176/1405 train_time:22696ms step_avg:136.72ms
step:177/1405 train_time:22834ms step_avg:136.73ms
step:178/1405 train_time:22973ms step_avg:136.74ms
step:179/1405 train_time:23112ms step_avg:136.76ms
step:180/1405 train_time:23250ms step_avg:136.76ms
step:181/1405 train_time:23388ms step_avg:136.77ms
step:182/1405 train_time:23528ms step_avg:136.79ms
step:183/1405 train_time:23667ms step_avg:136.80ms
step:184/1405 train_time:23806ms step_avg:136.82ms
step:185/1405 train_time:23944ms step_avg:136.82ms
step:186/1405 train_time:24084ms step_avg:136.84ms
step:187/1405 train_time:24222ms step_avg:136.85ms
step:188/1405 train_time:24360ms step_avg:136.86ms
step:189/1405 train_time:24501ms step_avg:136.88ms
step:190/1405 train_time:24638ms step_avg:136.88ms
step:191/1405 train_time:24823ms step_avg:137.14ms
step:192/1405 train_time:24960ms step_avg:137.14ms
step:193/1405 train_time:25097ms step_avg:137.14ms
step:194/1405 train_time:25233ms step_avg:137.14ms
step:195/1405 train_time:25369ms step_avg:137.13ms
step:196/1405 train_time:25506ms step_avg:137.13ms
step:197/1405 train_time:25642ms step_avg:137.12ms
step:198/1405 train_time:25785ms step_avg:137.15ms
step:199/1405 train_time:25925ms step_avg:137.17ms
step:200/1405 train_time:26062ms step_avg:137.17ms
step:201/1405 train_time:26199ms step_avg:137.17ms
step:202/1405 train_time:26337ms step_avg:137.17ms
step:203/1405 train_time:26474ms step_avg:137.17ms
step:204/1405 train_time:26612ms step_avg:137.17ms
step:205/1405 train_time:26749ms step_avg:137.18ms
step:206/1405 train_time:26892ms step_avg:137.20ms
step:207/1405 train_time:27032ms step_avg:137.22ms
step:208/1405 train_time:27172ms step_avg:137.23ms
step:209/1405 train_time:27309ms step_avg:137.23ms
step:210/1405 train_time:27447ms step_avg:137.23ms
step:211/1405 train_time:27587ms step_avg:137.25ms
step:212/1405 train_time:27726ms step_avg:137.26ms
step:213/1405 train_time:27866ms step_avg:137.27ms
step:214/1405 train_time:28006ms step_avg:137.29ms
step:215/1405 train_time:28145ms step_avg:137.29ms
step:216/1405 train_time:28285ms step_avg:137.31ms
step:217/1405 train_time:28425ms step_avg:137.32ms
step:218/1405 train_time:28563ms step_avg:137.32ms
step:219/1405 train_time:28703ms step_avg:137.34ms
step:220/1405 train_time:28842ms step_avg:137.34ms
step:221/1405 train_time:28982ms step_avg:137.36ms
step:222/1405 train_time:29122ms step_avg:137.37ms
step:223/1405 train_time:29261ms step_avg:137.38ms
step:224/1405 train_time:29399ms step_avg:137.38ms
step:225/1405 train_time:29538ms step_avg:137.39ms
step:226/1405 train_time:29676ms step_avg:137.39ms
step:227/1405 train_time:29816ms step_avg:137.40ms
step:228/1405 train_time:29954ms step_avg:137.40ms
step:229/1405 train_time:30094ms step_avg:137.42ms
step:230/1405 train_time:30235ms step_avg:137.43ms
step:231/1405 train_time:30374ms step_avg:137.44ms
step:232/1405 train_time:30514ms step_avg:137.45ms
step:233/1405 train_time:30651ms step_avg:137.45ms
step:234/1405 train_time:30791ms step_avg:137.46ms
step:235/1405 train_time:30931ms step_avg:137.47ms
step:236/1405 train_time:31070ms step_avg:137.48ms
step:237/1405 train_time:31211ms step_avg:137.49ms
step:238/1405 train_time:31350ms step_avg:137.50ms
step:239/1405 train_time:31490ms step_avg:137.51ms
step:240/1405 train_time:31630ms step_avg:137.52ms
step:241/1405 train_time:31770ms step_avg:137.53ms
step:242/1405 train_time:31909ms step_avg:137.54ms
step:243/1405 train_time:32047ms step_avg:137.54ms
step:244/1405 train_time:32189ms step_avg:137.56ms
step:245/1405 train_time:32328ms step_avg:137.57ms
step:246/1405 train_time:32466ms step_avg:137.57ms
step:247/1405 train_time:32607ms step_avg:137.58ms
step:248/1405 train_time:32745ms step_avg:137.58ms
step:249/1405 train_time:32886ms step_avg:137.60ms
step:250/1405 train_time:33026ms step_avg:137.61ms
step:250/1405 val_loss:3.9749 train_time:33092ms step_avg:137.88ms
step:251/1405 train_time:33165ms step_avg:137.61ms
step:252/1405 train_time:33308ms step_avg:137.64ms
step:253/1405 train_time:33448ms step_avg:137.65ms
step:254/1405 train_time:33587ms step_avg:137.65ms
step:255/1405 train_time:33725ms step_avg:137.65ms
step:256/1405 train_time:33862ms step_avg:137.65ms
step:257/1405 train_time:34003ms step_avg:137.67ms
step:258/1405 train_time:34144ms step_avg:137.68ms
step:259/1405 train_time:34286ms step_avg:137.69ms
step:260/1405 train_time:34426ms step_avg:137.70ms
step:261/1405 train_time:34564ms step_avg:137.71ms
step:262/1405 train_time:34704ms step_avg:137.71ms
step:263/1405 train_time:34840ms step_avg:137.71ms
step:264/1405 train_time:34979ms step_avg:137.71ms
step:265/1405 train_time:35119ms step_avg:137.72ms
step:266/1405 train_time:35260ms step_avg:137.73ms
step:267/1405 train_time:35399ms step_avg:137.74ms
step:268/1405 train_time:35539ms step_avg:137.75ms
step:269/1405 train_time:35678ms step_avg:137.75ms
step:270/1405 train_time:35817ms step_avg:137.76ms
step:271/1405 train_time:35956ms step_avg:137.76ms
step:272/1405 train_time:36096ms step_avg:137.77ms
step:273/1405 train_time:36237ms step_avg:137.78ms
step:274/1405 train_time:36375ms step_avg:137.79ms
step:275/1405 train_time:36515ms step_avg:137.79ms
step:276/1405 train_time:36655ms step_avg:137.80ms
step:277/1405 train_time:36796ms step_avg:137.81ms
step:278/1405 train_time:36934ms step_avg:137.82ms
step:279/1405 train_time:37072ms step_avg:137.81ms
step:280/1405 train_time:37213ms step_avg:137.83ms
step:281/1405 train_time:37353ms step_avg:137.83ms
step:282/1405 train_time:37491ms step_avg:137.83ms
step:283/1405 train_time:37632ms step_avg:137.84ms
step:284/1405 train_time:37770ms step_avg:137.85ms
step:285/1405 train_time:37911ms step_avg:137.86ms
step:286/1405 train_time:38051ms step_avg:137.86ms
step:287/1405 train_time:38192ms step_avg:137.88ms
step:288/1405 train_time:38333ms step_avg:137.89ms
step:289/1405 train_time:38471ms step_avg:137.89ms
step:290/1405 train_time:38610ms step_avg:137.89ms
step:291/1405 train_time:38749ms step_avg:137.90ms
step:292/1405 train_time:38888ms step_avg:137.90ms
step:293/1405 train_time:39027ms step_avg:137.91ms
step:294/1405 train_time:39166ms step_avg:137.91ms
step:295/1405 train_time:39308ms step_avg:137.92ms
step:296/1405 train_time:39446ms step_avg:137.92ms
step:297/1405 train_time:39586ms step_avg:137.93ms
step:298/1405 train_time:39726ms step_avg:137.94ms
step:299/1405 train_time:39864ms step_avg:137.94ms
step:300/1405 train_time:40005ms step_avg:137.95ms
step:301/1405 train_time:40144ms step_avg:137.95ms
step:302/1405 train_time:40285ms step_avg:137.96ms
step:303/1405 train_time:40425ms step_avg:137.97ms
step:304/1405 train_time:40564ms step_avg:137.97ms
step:305/1405 train_time:40704ms step_avg:137.98ms
step:306/1405 train_time:40843ms step_avg:137.98ms
step:307/1405 train_time:40984ms step_avg:137.99ms
step:308/1405 train_time:41124ms step_avg:138.00ms
step:309/1405 train_time:41264ms step_avg:138.01ms
step:310/1405 train_time:41404ms step_avg:138.01ms
step:311/1405 train_time:41545ms step_avg:138.02ms
step:312/1405 train_time:41685ms step_avg:138.03ms
step:313/1405 train_time:41824ms step_avg:138.03ms
step:314/1405 train_time:41963ms step_avg:138.04ms
step:315/1405 train_time:42108ms step_avg:138.06ms
step:316/1405 train_time:42249ms step_avg:138.07ms
step:317/1405 train_time:42392ms step_avg:138.09ms
step:318/1405 train_time:42535ms step_avg:138.10ms
step:319/1405 train_time:42678ms step_avg:138.12ms
step:320/1405 train_time:42820ms step_avg:138.13ms
step:321/1405 train_time:42961ms step_avg:138.14ms
step:322/1405 train_time:43104ms step_avg:138.15ms
step:323/1405 train_time:43245ms step_avg:138.16ms
step:324/1405 train_time:43387ms step_avg:138.18ms
step:325/1405 train_time:43529ms step_avg:138.19ms
step:326/1405 train_time:43671ms step_avg:138.20ms
step:327/1405 train_time:43811ms step_avg:138.21ms
step:328/1405 train_time:43954ms step_avg:138.22ms
step:329/1405 train_time:44098ms step_avg:138.24ms
step:330/1405 train_time:44240ms step_avg:138.25ms
step:331/1405 train_time:44383ms step_avg:138.26ms
step:332/1405 train_time:44525ms step_avg:138.28ms
step:333/1405 train_time:44666ms step_avg:138.29ms
step:334/1405 train_time:44809ms step_avg:138.30ms
step:335/1405 train_time:44950ms step_avg:138.31ms
step:336/1405 train_time:45095ms step_avg:138.33ms
step:337/1405 train_time:45237ms step_avg:138.34ms
step:338/1405 train_time:45379ms step_avg:138.35ms
step:339/1405 train_time:45522ms step_avg:138.36ms
step:340/1405 train_time:45663ms step_avg:138.37ms
step:341/1405 train_time:45805ms step_avg:138.38ms
step:342/1405 train_time:45947ms step_avg:138.39ms
step:343/1405 train_time:46089ms step_avg:138.41ms
step:344/1405 train_time:46231ms step_avg:138.42ms
step:345/1405 train_time:46372ms step_avg:138.42ms
step:346/1405 train_time:46515ms step_avg:138.44ms
step:347/1405 train_time:46658ms step_avg:138.45ms
step:348/1405 train_time:46800ms step_avg:138.46ms
step:349/1405 train_time:46942ms step_avg:138.47ms
step:350/1405 train_time:47085ms step_avg:138.49ms
step:351/1405 train_time:47227ms step_avg:138.49ms
step:352/1405 train_time:47367ms step_avg:138.50ms
step:353/1405 train_time:47510ms step_avg:138.51ms
step:354/1405 train_time:47651ms step_avg:138.52ms
step:355/1405 train_time:47793ms step_avg:138.53ms
step:356/1405 train_time:47938ms step_avg:138.55ms
step:357/1405 train_time:48079ms step_avg:138.56ms
step:358/1405 train_time:48220ms step_avg:138.56ms
step:359/1405 train_time:48361ms step_avg:138.57ms
step:360/1405 train_time:48504ms step_avg:138.58ms
step:361/1405 train_time:48646ms step_avg:138.59ms
step:362/1405 train_time:48789ms step_avg:138.60ms
step:363/1405 train_time:48931ms step_avg:138.62ms
step:364/1405 train_time:49073ms step_avg:138.62ms
step:365/1405 train_time:49215ms step_avg:138.63ms
step:366/1405 train_time:49357ms step_avg:138.64ms
step:367/1405 train_time:49500ms step_avg:138.66ms
step:368/1405 train_time:49644ms step_avg:138.67ms
step:369/1405 train_time:49787ms step_avg:138.68ms
step:370/1405 train_time:49931ms step_avg:138.70ms
step:371/1405 train_time:50072ms step_avg:138.70ms
step:372/1405 train_time:50214ms step_avg:138.71ms
step:373/1405 train_time:50356ms step_avg:138.72ms
step:374/1405 train_time:50499ms step_avg:138.73ms
step:375/1405 train_time:50639ms step_avg:138.74ms
step:375/1405 val_loss:3.7798 train_time:50708ms step_avg:138.93ms
step:376/1405 train_time:50783ms step_avg:138.75ms
step:377/1405 train_time:50930ms step_avg:138.77ms
step:378/1405 train_time:51071ms step_avg:138.78ms
step:379/1405 train_time:51212ms step_avg:138.79ms
step:380/1405 train_time:51353ms step_avg:138.79ms
step:381/1405 train_time:51536ms step_avg:138.91ms
step:382/1405 train_time:51684ms step_avg:138.93ms
step:383/1405 train_time:51826ms step_avg:138.94ms
step:384/1405 train_time:51966ms step_avg:138.95ms
step:385/1405 train_time:52109ms step_avg:138.96ms
step:386/1405 train_time:52249ms step_avg:138.96ms
step:387/1405 train_time:52392ms step_avg:138.97ms
step:388/1405 train_time:52537ms step_avg:138.99ms
step:389/1405 train_time:52680ms step_avg:139.00ms
step:390/1405 train_time:52823ms step_avg:139.01ms
step:391/1405 train_time:52964ms step_avg:139.01ms
step:392/1405 train_time:53105ms step_avg:139.02ms
step:393/1405 train_time:53246ms step_avg:139.02ms
step:394/1405 train_time:53389ms step_avg:139.03ms
step:395/1405 train_time:53533ms step_avg:139.05ms
step:396/1405 train_time:53676ms step_avg:139.06ms
step:397/1405 train_time:53820ms step_avg:139.07ms
step:398/1405 train_time:53961ms step_avg:139.08ms
step:399/1405 train_time:54104ms step_avg:139.08ms
step:400/1405 train_time:54245ms step_avg:139.09ms
step:401/1405 train_time:54388ms step_avg:139.10ms
step:402/1405 train_time:54531ms step_avg:139.11ms
step:403/1405 train_time:54672ms step_avg:139.11ms
step:404/1405 train_time:54816ms step_avg:139.13ms
step:405/1405 train_time:54958ms step_avg:139.13ms
step:406/1405 train_time:55100ms step_avg:139.14ms
step:407/1405 train_time:55242ms step_avg:139.15ms
step:408/1405 train_time:55383ms step_avg:139.15ms
step:409/1405 train_time:55525ms step_avg:139.16ms
step:410/1405 train_time:55666ms step_avg:139.17ms
step:411/1405 train_time:55811ms step_avg:139.18ms
step:412/1405 train_time:55954ms step_avg:139.19ms
step:413/1405 train_time:56096ms step_avg:139.19ms
step:414/1405 train_time:56237ms step_avg:139.20ms
step:415/1405 train_time:56380ms step_avg:139.21ms
step:416/1405 train_time:56521ms step_avg:139.21ms
step:417/1405 train_time:56662ms step_avg:139.22ms
step:418/1405 train_time:56805ms step_avg:139.23ms
step:419/1405 train_time:56948ms step_avg:139.24ms
step:420/1405 train_time:57091ms step_avg:139.25ms
step:421/1405 train_time:57233ms step_avg:139.25ms
step:422/1405 train_time:57374ms step_avg:139.26ms
step:423/1405 train_time:57517ms step_avg:139.27ms
step:424/1405 train_time:57661ms step_avg:139.28ms
step:425/1405 train_time:57805ms step_avg:139.29ms
step:426/1405 train_time:57947ms step_avg:139.30ms
step:427/1405 train_time:58090ms step_avg:139.30ms
step:428/1405 train_time:58232ms step_avg:139.31ms
step:429/1405 train_time:58374ms step_avg:139.32ms
step:430/1405 train_time:58518ms step_avg:139.33ms
step:431/1405 train_time:58662ms step_avg:139.34ms
step:432/1405 train_time:58804ms step_avg:139.35ms
step:433/1405 train_time:58945ms step_avg:139.35ms
step:434/1405 train_time:59089ms step_avg:139.36ms
step:435/1405 train_time:59231ms step_avg:139.37ms
step:436/1405 train_time:59372ms step_avg:139.37ms
step:437/1405 train_time:59515ms step_avg:139.38ms
step:438/1405 train_time:59659ms step_avg:139.39ms
step:439/1405 train_time:59803ms step_avg:139.40ms
step:440/1405 train_time:59945ms step_avg:139.41ms
step:441/1405 train_time:60088ms step_avg:139.41ms
step:442/1405 train_time:60230ms step_avg:139.42ms
step:443/1405 train_time:60372ms step_avg:139.43ms
step:444/1405 train_time:60516ms step_avg:139.44ms
step:445/1405 train_time:60661ms step_avg:139.45ms
step:446/1405 train_time:60804ms step_avg:139.46ms
step:447/1405 train_time:60947ms step_avg:139.47ms
step:448/1405 train_time:61090ms step_avg:139.47ms
step:449/1405 train_time:61233ms step_avg:139.48ms
step:450/1405 train_time:61375ms step_avg:139.49ms
step:451/1405 train_time:61520ms step_avg:139.50ms
step:452/1405 train_time:61663ms step_avg:139.51ms
step:453/1405 train_time:61807ms step_avg:139.52ms
step:454/1405 train_time:61949ms step_avg:139.53ms
step:455/1405 train_time:62091ms step_avg:139.53ms
step:456/1405 train_time:62233ms step_avg:139.54ms
step:457/1405 train_time:62374ms step_avg:139.54ms
step:458/1405 train_time:62521ms step_avg:139.55ms
step:459/1405 train_time:62664ms step_avg:139.56ms
step:460/1405 train_time:62807ms step_avg:139.57ms
step:461/1405 train_time:62951ms step_avg:139.58ms
step:462/1405 train_time:63093ms step_avg:139.59ms
step:463/1405 train_time:63235ms step_avg:139.59ms
step:464/1405 train_time:63377ms step_avg:139.60ms
step:465/1405 train_time:63522ms step_avg:139.61ms
step:466/1405 train_time:63664ms step_avg:139.61ms
step:467/1405 train_time:63808ms step_avg:139.62ms
step:468/1405 train_time:63950ms step_avg:139.63ms
step:469/1405 train_time:64093ms step_avg:139.64ms
step:470/1405 train_time:64234ms step_avg:139.64ms
step:471/1405 train_time:64376ms step_avg:139.65ms
step:472/1405 train_time:64520ms step_avg:139.65ms
step:473/1405 train_time:64663ms step_avg:139.66ms
step:474/1405 train_time:64807ms step_avg:139.67ms
step:475/1405 train_time:64950ms step_avg:139.68ms
step:476/1405 train_time:65093ms step_avg:139.69ms
step:477/1405 train_time:65238ms step_avg:139.70ms
step:478/1405 train_time:65380ms step_avg:139.70ms
step:479/1405 train_time:65523ms step_avg:139.71ms
step:480/1405 train_time:65665ms step_avg:139.71ms
step:481/1405 train_time:65808ms step_avg:139.72ms
step:482/1405 train_time:65953ms step_avg:139.73ms
step:483/1405 train_time:66097ms step_avg:139.74ms
step:484/1405 train_time:66240ms step_avg:139.75ms
step:485/1405 train_time:66382ms step_avg:139.75ms
step:486/1405 train_time:66526ms step_avg:139.76ms
step:487/1405 train_time:66668ms step_avg:139.77ms
step:488/1405 train_time:66811ms step_avg:139.77ms
step:489/1405 train_time:66955ms step_avg:139.78ms
step:490/1405 train_time:67100ms step_avg:139.79ms
step:491/1405 train_time:67242ms step_avg:139.80ms
step:492/1405 train_time:67383ms step_avg:139.80ms
step:493/1405 train_time:67527ms step_avg:139.81ms
step:494/1405 train_time:67670ms step_avg:139.81ms
step:495/1405 train_time:67813ms step_avg:139.82ms
step:496/1405 train_time:67958ms step_avg:139.83ms
step:497/1405 train_time:68103ms step_avg:139.84ms
step:498/1405 train_time:68246ms step_avg:139.85ms
step:499/1405 train_time:68388ms step_avg:139.85ms
step:500/1405 train_time:68531ms step_avg:139.86ms
step:500/1405 val_loss:3.6622 train_time:68600ms step_avg:140.00ms
step:501/1405 train_time:68676ms step_avg:139.87ms
step:502/1405 train_time:68822ms step_avg:139.88ms
step:503/1405 train_time:68965ms step_avg:139.89ms
step:504/1405 train_time:69108ms step_avg:139.90ms
step:505/1405 train_time:69249ms step_avg:139.90ms
step:506/1405 train_time:69391ms step_avg:139.90ms
step:507/1405 train_time:69534ms step_avg:139.91ms
step:508/1405 train_time:69677ms step_avg:139.91ms
step:509/1405 train_time:69823ms step_avg:139.93ms
step:510/1405 train_time:69966ms step_avg:139.93ms
step:511/1405 train_time:70108ms step_avg:139.94ms
step:512/1405 train_time:70252ms step_avg:139.94ms
step:513/1405 train_time:70393ms step_avg:139.95ms
step:514/1405 train_time:70537ms step_avg:139.95ms
step:515/1405 train_time:70681ms step_avg:139.96ms
step:516/1405 train_time:70827ms step_avg:139.97ms
step:517/1405 train_time:70969ms step_avg:139.98ms
step:518/1405 train_time:71112ms step_avg:139.98ms
step:519/1405 train_time:71256ms step_avg:139.99ms
step:520/1405 train_time:71400ms step_avg:140.00ms
step:521/1405 train_time:71542ms step_avg:140.00ms
step:522/1405 train_time:71685ms step_avg:140.01ms
step:523/1405 train_time:71830ms step_avg:140.02ms
step:524/1405 train_time:71974ms step_avg:140.03ms
step:525/1405 train_time:72122ms step_avg:140.04ms
step:526/1405 train_time:72268ms step_avg:140.05ms
step:527/1405 train_time:72413ms step_avg:140.06ms
step:528/1405 train_time:72557ms step_avg:140.07ms
step:529/1405 train_time:72703ms step_avg:140.08ms
step:530/1405 train_time:72848ms step_avg:140.09ms
step:531/1405 train_time:72992ms step_avg:140.10ms
step:532/1405 train_time:73138ms step_avg:140.11ms
step:533/1405 train_time:73283ms step_avg:140.12ms
step:534/1405 train_time:73431ms step_avg:140.13ms
step:535/1405 train_time:73575ms step_avg:140.14ms
step:536/1405 train_time:73720ms step_avg:140.15ms
step:537/1405 train_time:73865ms step_avg:140.16ms
step:538/1405 train_time:74011ms step_avg:140.17ms
step:539/1405 train_time:74155ms step_avg:140.18ms
step:540/1405 train_time:74300ms step_avg:140.19ms
step:541/1405 train_time:74446ms step_avg:140.20ms
step:542/1405 train_time:74591ms step_avg:140.21ms
step:543/1405 train_time:74735ms step_avg:140.22ms
step:544/1405 train_time:74880ms step_avg:140.22ms
step:545/1405 train_time:75027ms step_avg:140.24ms
step:546/1405 train_time:75172ms step_avg:140.25ms
step:547/1405 train_time:75317ms step_avg:140.26ms
step:548/1405 train_time:75464ms step_avg:140.27ms
step:549/1405 train_time:75610ms step_avg:140.28ms
step:550/1405 train_time:75754ms step_avg:140.28ms
step:551/1405 train_time:75899ms step_avg:140.29ms
step:552/1405 train_time:76045ms step_avg:140.30ms
step:553/1405 train_time:76190ms step_avg:140.31ms
step:554/1405 train_time:76335ms step_avg:140.32ms
step:555/1405 train_time:76481ms step_avg:140.33ms
step:556/1405 train_time:76626ms step_avg:140.34ms
step:557/1405 train_time:76771ms step_avg:140.35ms
step:558/1405 train_time:76916ms step_avg:140.36ms
step:559/1405 train_time:77061ms step_avg:140.37ms
step:560/1405 train_time:77207ms step_avg:140.38ms
step:561/1405 train_time:77351ms step_avg:140.38ms
step:562/1405 train_time:77497ms step_avg:140.39ms
step:563/1405 train_time:77643ms step_avg:140.40ms
step:564/1405 train_time:77788ms step_avg:140.41ms
step:565/1405 train_time:77933ms step_avg:140.42ms
step:566/1405 train_time:78078ms step_avg:140.43ms
step:567/1405 train_time:78224ms step_avg:140.44ms
step:568/1405 train_time:78369ms step_avg:140.45ms
step:569/1405 train_time:78515ms step_avg:140.46ms
step:570/1405 train_time:78660ms step_avg:140.46ms
step:571/1405 train_time:78848ms step_avg:140.55ms
step:572/1405 train_time:78996ms step_avg:140.56ms
step:573/1405 train_time:79141ms step_avg:140.57ms
step:574/1405 train_time:79285ms step_avg:140.58ms
step:575/1405 train_time:79429ms step_avg:140.58ms
step:576/1405 train_time:79572ms step_avg:140.59ms
step:577/1405 train_time:79718ms step_avg:140.60ms
step:578/1405 train_time:79868ms step_avg:140.61ms
step:579/1405 train_time:80014ms step_avg:140.62ms
step:580/1405 train_time:80158ms step_avg:140.63ms
step:581/1405 train_time:80304ms step_avg:140.64ms
step:582/1405 train_time:80448ms step_avg:140.64ms
step:583/1405 train_time:80592ms step_avg:140.65ms
step:584/1405 train_time:80738ms step_avg:140.66ms
step:585/1405 train_time:80885ms step_avg:140.67ms
step:586/1405 train_time:81031ms step_avg:140.68ms
step:587/1405 train_time:81176ms step_avg:140.69ms
step:588/1405 train_time:81322ms step_avg:140.70ms
step:589/1405 train_time:81467ms step_avg:140.70ms
step:590/1405 train_time:81612ms step_avg:140.71ms
step:591/1405 train_time:81757ms step_avg:140.72ms
step:592/1405 train_time:81906ms step_avg:140.73ms
step:593/1405 train_time:82051ms step_avg:140.74ms
step:594/1405 train_time:82195ms step_avg:140.75ms
step:595/1405 train_time:82340ms step_avg:140.75ms
step:596/1405 train_time:82485ms step_avg:140.76ms
step:597/1405 train_time:82630ms step_avg:140.77ms
step:598/1405 train_time:82773ms step_avg:140.77ms
step:599/1405 train_time:82920ms step_avg:140.78ms
step:600/1405 train_time:83065ms step_avg:140.79ms
step:601/1405 train_time:83210ms step_avg:140.80ms
step:602/1405 train_time:83353ms step_avg:140.80ms
step:603/1405 train_time:83499ms step_avg:140.81ms
step:604/1405 train_time:83645ms step_avg:140.82ms
step:605/1405 train_time:83790ms step_avg:140.82ms
step:606/1405 train_time:83935ms step_avg:140.83ms
step:607/1405 train_time:84080ms step_avg:140.84ms
step:608/1405 train_time:84226ms step_avg:140.85ms
step:609/1405 train_time:84370ms step_avg:140.85ms
step:610/1405 train_time:84516ms step_avg:140.86ms
step:611/1405 train_time:84661ms step_avg:140.87ms
step:612/1405 train_time:84806ms step_avg:140.87ms
step:613/1405 train_time:84951ms step_avg:140.88ms
step:614/1405 train_time:85095ms step_avg:140.89ms
step:615/1405 train_time:85241ms step_avg:140.89ms
step:616/1405 train_time:85387ms step_avg:140.90ms
step:617/1405 train_time:85532ms step_avg:140.91ms
step:618/1405 train_time:85677ms step_avg:140.92ms
step:619/1405 train_time:85825ms step_avg:140.93ms
step:620/1405 train_time:85968ms step_avg:140.93ms
step:621/1405 train_time:86114ms step_avg:140.94ms
step:622/1405 train_time:86260ms step_avg:140.95ms
step:623/1405 train_time:86406ms step_avg:140.96ms
step:624/1405 train_time:86551ms step_avg:140.96ms
step:625/1405 train_time:86698ms step_avg:140.97ms
step:625/1405 val_loss:3.5786 train_time:86770ms step_avg:141.09ms
step:626/1405 train_time:86846ms step_avg:140.98ms
step:627/1405 train_time:86995ms step_avg:141.00ms
step:628/1405 train_time:87141ms step_avg:141.01ms
step:629/1405 train_time:87287ms step_avg:141.01ms
step:630/1405 train_time:87431ms step_avg:141.02ms
step:631/1405 train_time:87575ms step_avg:141.02ms
step:632/1405 train_time:87721ms step_avg:141.03ms
step:633/1405 train_time:87868ms step_avg:141.04ms
step:634/1405 train_time:88016ms step_avg:141.05ms
step:635/1405 train_time:88162ms step_avg:141.06ms
step:636/1405 train_time:88309ms step_avg:141.07ms
step:637/1405 train_time:88453ms step_avg:141.07ms
step:638/1405 train_time:88598ms step_avg:141.08ms
step:639/1405 train_time:88744ms step_avg:141.09ms
step:640/1405 train_time:88890ms step_avg:141.10ms
step:641/1405 train_time:89036ms step_avg:141.10ms
step:642/1405 train_time:89183ms step_avg:141.11ms
step:643/1405 train_time:89330ms step_avg:141.12ms
step:644/1405 train_time:89476ms step_avg:141.13ms
step:645/1405 train_time:89621ms step_avg:141.14ms
step:646/1405 train_time:89768ms step_avg:141.14ms
step:647/1405 train_time:89913ms step_avg:141.15ms
step:648/1405 train_time:90061ms step_avg:141.16ms
step:649/1405 train_time:90210ms step_avg:141.17ms
step:650/1405 train_time:90356ms step_avg:141.18ms
step:651/1405 train_time:90505ms step_avg:141.19ms
step:652/1405 train_time:90650ms step_avg:141.20ms
step:653/1405 train_time:90795ms step_avg:141.20ms
step:654/1405 train_time:90941ms step_avg:141.21ms
step:655/1405 train_time:91088ms step_avg:141.22ms
step:656/1405 train_time:91234ms step_avg:141.23ms
step:657/1405 train_time:91379ms step_avg:141.23ms
step:658/1405 train_time:91526ms step_avg:141.24ms
step:659/1405 train_time:91672ms step_avg:141.25ms
step:660/1405 train_time:91816ms step_avg:141.26ms
step:661/1405 train_time:91961ms step_avg:141.26ms
step:662/1405 train_time:92110ms step_avg:141.27ms
step:663/1405 train_time:92255ms step_avg:141.28ms
step:664/1405 train_time:92404ms step_avg:141.29ms
step:665/1405 train_time:92548ms step_avg:141.29ms
step:666/1405 train_time:92695ms step_avg:141.30ms
step:667/1405 train_time:92839ms step_avg:141.31ms
step:668/1405 train_time:92985ms step_avg:141.31ms
step:669/1405 train_time:93133ms step_avg:141.32ms
step:670/1405 train_time:93281ms step_avg:141.33ms
step:671/1405 train_time:93428ms step_avg:141.34ms
step:672/1405 train_time:93574ms step_avg:141.35ms
step:673/1405 train_time:93720ms step_avg:141.36ms
step:674/1405 train_time:93865ms step_avg:141.36ms
step:675/1405 train_time:94011ms step_avg:141.37ms
step:676/1405 train_time:94157ms step_avg:141.38ms
step:677/1405 train_time:94305ms step_avg:141.39ms
step:678/1405 train_time:94451ms step_avg:141.39ms
step:679/1405 train_time:94597ms step_avg:141.40ms
step:680/1405 train_time:94743ms step_avg:141.41ms
step:681/1405 train_time:94890ms step_avg:141.42ms
step:682/1405 train_time:95034ms step_avg:141.42ms
step:683/1405 train_time:95180ms step_avg:141.43ms
step:684/1405 train_time:95326ms step_avg:141.43ms
step:685/1405 train_time:95472ms step_avg:141.44ms
step:686/1405 train_time:95618ms step_avg:141.45ms
step:687/1405 train_time:95764ms step_avg:141.45ms
step:688/1405 train_time:95911ms step_avg:141.46ms
step:689/1405 train_time:96055ms step_avg:141.47ms
step:690/1405 train_time:96203ms step_avg:141.48ms
step:691/1405 train_time:96348ms step_avg:141.48ms
step:692/1405 train_time:96494ms step_avg:141.49ms
step:693/1405 train_time:96639ms step_avg:141.49ms
step:694/1405 train_time:96786ms step_avg:141.50ms
step:695/1405 train_time:96932ms step_avg:141.51ms
step:696/1405 train_time:97077ms step_avg:141.51ms
step:697/1405 train_time:97225ms step_avg:141.52ms
step:698/1405 train_time:97371ms step_avg:141.53ms
step:699/1405 train_time:97517ms step_avg:141.53ms
step:700/1405 train_time:97662ms step_avg:141.54ms
step:701/1405 train_time:97808ms step_avg:141.55ms
step:702/1405 train_time:97952ms step_avg:141.55ms
step:703/1405 train_time:98099ms step_avg:141.56ms
step:704/1405 train_time:98245ms step_avg:141.56ms
step:705/1405 train_time:98392ms step_avg:141.57ms
step:706/1405 train_time:98540ms step_avg:141.58ms
step:707/1405 train_time:98687ms step_avg:141.59ms
step:708/1405 train_time:98832ms step_avg:141.59ms
step:709/1405 train_time:98978ms step_avg:141.60ms
step:710/1405 train_time:99125ms step_avg:141.61ms
step:711/1405 train_time:99272ms step_avg:141.61ms
step:712/1405 train_time:99417ms step_avg:141.62ms
step:713/1405 train_time:99565ms step_avg:141.63ms
step:714/1405 train_time:99711ms step_avg:141.64ms
step:715/1405 train_time:99856ms step_avg:141.64ms
step:716/1405 train_time:100004ms step_avg:141.65ms
step:717/1405 train_time:100149ms step_avg:141.65ms
step:718/1405 train_time:100294ms step_avg:141.66ms
step:719/1405 train_time:100438ms step_avg:141.66ms
step:720/1405 train_time:100586ms step_avg:141.67ms
step:721/1405 train_time:100732ms step_avg:141.68ms
step:722/1405 train_time:100879ms step_avg:141.68ms
step:723/1405 train_time:101025ms step_avg:141.69ms
step:724/1405 train_time:101171ms step_avg:141.70ms
step:725/1405 train_time:101317ms step_avg:141.70ms
step:726/1405 train_time:101462ms step_avg:141.71ms
step:727/1405 train_time:101610ms step_avg:141.72ms
step:728/1405 train_time:101755ms step_avg:141.72ms
step:729/1405 train_time:101900ms step_avg:141.72ms
step:730/1405 train_time:102049ms step_avg:141.74ms
step:731/1405 train_time:102196ms step_avg:141.74ms
step:732/1405 train_time:102343ms step_avg:141.75ms
step:733/1405 train_time:102490ms step_avg:141.76ms
step:734/1405 train_time:102637ms step_avg:141.76ms
step:735/1405 train_time:102786ms step_avg:141.77ms
step:736/1405 train_time:102933ms step_avg:141.78ms
step:737/1405 train_time:103080ms step_avg:141.79ms
step:738/1405 train_time:103230ms step_avg:141.80ms
step:739/1405 train_time:103378ms step_avg:141.81ms
step:740/1405 train_time:103527ms step_avg:141.82ms
step:741/1405 train_time:103674ms step_avg:141.82ms
step:742/1405 train_time:103821ms step_avg:141.83ms
step:743/1405 train_time:103968ms step_avg:141.84ms
step:744/1405 train_time:104115ms step_avg:141.85ms
step:745/1405 train_time:104264ms step_avg:141.86ms
step:746/1405 train_time:104412ms step_avg:141.86ms
step:747/1405 train_time:104559ms step_avg:141.87ms
step:748/1405 train_time:104708ms step_avg:141.88ms
step:749/1405 train_time:104855ms step_avg:141.89ms
step:750/1405 train_time:105005ms step_avg:141.90ms
step:750/1405 val_loss:3.5265 train_time:105076ms step_avg:142.00ms
step:751/1405 train_time:105153ms step_avg:141.91ms
step:752/1405 train_time:105304ms step_avg:141.92ms
step:753/1405 train_time:105449ms step_avg:141.92ms
step:754/1405 train_time:105596ms step_avg:141.93ms
step:755/1405 train_time:105743ms step_avg:141.94ms
step:756/1405 train_time:105889ms step_avg:141.94ms
step:757/1405 train_time:106037ms step_avg:141.95ms
step:758/1405 train_time:106185ms step_avg:141.96ms
step:759/1405 train_time:106334ms step_avg:141.97ms
step:760/1405 train_time:106482ms step_avg:141.98ms
step:761/1405 train_time:106672ms step_avg:142.04ms
step:762/1405 train_time:106822ms step_avg:142.05ms
step:763/1405 train_time:106969ms step_avg:142.06ms
step:764/1405 train_time:107116ms step_avg:142.06ms
step:765/1405 train_time:107263ms step_avg:142.07ms
step:766/1405 train_time:107410ms step_avg:142.08ms
step:767/1405 train_time:107561ms step_avg:142.09ms
step:768/1405 train_time:107709ms step_avg:142.10ms
step:769/1405 train_time:107858ms step_avg:142.11ms
step:770/1405 train_time:108004ms step_avg:142.11ms
step:771/1405 train_time:108152ms step_avg:142.12ms
step:772/1405 train_time:108300ms step_avg:142.13ms
step:773/1405 train_time:108447ms step_avg:142.13ms
step:774/1405 train_time:108596ms step_avg:142.14ms
step:775/1405 train_time:108744ms step_avg:142.15ms
step:776/1405 train_time:108893ms step_avg:142.16ms
step:777/1405 train_time:109042ms step_avg:142.17ms
step:778/1405 train_time:109189ms step_avg:142.17ms
step:779/1405 train_time:109336ms step_avg:142.18ms
step:780/1405 train_time:109484ms step_avg:142.19ms
step:781/1405 train_time:109634ms step_avg:142.20ms
step:782/1405 train_time:109782ms step_avg:142.20ms
step:783/1405 train_time:109927ms step_avg:142.21ms
step:784/1405 train_time:110074ms step_avg:142.21ms
step:785/1405 train_time:110221ms step_avg:142.22ms
step:786/1405 train_time:110369ms step_avg:142.23ms
step:787/1405 train_time:110516ms step_avg:142.23ms
step:788/1405 train_time:110665ms step_avg:142.24ms
step:789/1405 train_time:110813ms step_avg:142.25ms
step:790/1405 train_time:110962ms step_avg:142.26ms
step:791/1405 train_time:111107ms step_avg:142.26ms
step:792/1405 train_time:111255ms step_avg:142.27ms
step:793/1405 train_time:111403ms step_avg:142.28ms
step:794/1405 train_time:111550ms step_avg:142.28ms
step:795/1405 train_time:111700ms step_avg:142.29ms
step:796/1405 train_time:111848ms step_avg:142.30ms
step:797/1405 train_time:111999ms step_avg:142.31ms
step:798/1405 train_time:112145ms step_avg:142.32ms
step:799/1405 train_time:112296ms step_avg:142.33ms
step:800/1405 train_time:112444ms step_avg:142.33ms
step:801/1405 train_time:112593ms step_avg:142.34ms
step:802/1405 train_time:112741ms step_avg:142.35ms
step:803/1405 train_time:112888ms step_avg:142.36ms
step:804/1405 train_time:113035ms step_avg:142.36ms
step:805/1405 train_time:113185ms step_avg:142.37ms
step:806/1405 train_time:113331ms step_avg:142.38ms
step:807/1405 train_time:113478ms step_avg:142.38ms
step:808/1405 train_time:113625ms step_avg:142.39ms
step:809/1405 train_time:113773ms step_avg:142.39ms
step:810/1405 train_time:113920ms step_avg:142.40ms
step:811/1405 train_time:114068ms step_avg:142.41ms
step:812/1405 train_time:114216ms step_avg:142.41ms
step:813/1405 train_time:114365ms step_avg:142.42ms
step:814/1405 train_time:114512ms step_avg:142.43ms
step:815/1405 train_time:114660ms step_avg:142.44ms
step:816/1405 train_time:114806ms step_avg:142.44ms
step:817/1405 train_time:114954ms step_avg:142.45ms
step:818/1405 train_time:115101ms step_avg:142.45ms
step:819/1405 train_time:115249ms step_avg:142.46ms
step:820/1405 train_time:115398ms step_avg:142.47ms
step:821/1405 train_time:115545ms step_avg:142.47ms
step:822/1405 train_time:115692ms step_avg:142.48ms
step:823/1405 train_time:115842ms step_avg:142.49ms
step:824/1405 train_time:115988ms step_avg:142.49ms
step:825/1405 train_time:116136ms step_avg:142.50ms
step:826/1405 train_time:116285ms step_avg:142.51ms
step:827/1405 train_time:116431ms step_avg:142.51ms
step:828/1405 train_time:116580ms step_avg:142.52ms
step:829/1405 train_time:116725ms step_avg:142.52ms
step:830/1405 train_time:116872ms step_avg:142.53ms
step:831/1405 train_time:117019ms step_avg:142.53ms
step:832/1405 train_time:117167ms step_avg:142.54ms
step:833/1405 train_time:117314ms step_avg:142.54ms
step:834/1405 train_time:117462ms step_avg:142.55ms
step:835/1405 train_time:117610ms step_avg:142.56ms
step:836/1405 train_time:117761ms step_avg:142.57ms
step:837/1405 train_time:117908ms step_avg:142.57ms
step:838/1405 train_time:118056ms step_avg:142.58ms
step:839/1405 train_time:118204ms step_avg:142.59ms
step:840/1405 train_time:118350ms step_avg:142.59ms
step:841/1405 train_time:118502ms step_avg:142.60ms
step:842/1405 train_time:118650ms step_avg:142.61ms
step:843/1405 train_time:118799ms step_avg:142.62ms
step:844/1405 train_time:118946ms step_avg:142.62ms
step:845/1405 train_time:119093ms step_avg:142.63ms
step:846/1405 train_time:119241ms step_avg:142.63ms
step:847/1405 train_time:119390ms step_avg:142.64ms
step:848/1405 train_time:119539ms step_avg:142.65ms
step:849/1405 train_time:119689ms step_avg:142.66ms
step:850/1405 train_time:119839ms step_avg:142.67ms
step:851/1405 train_time:119986ms step_avg:142.67ms
step:852/1405 train_time:120134ms step_avg:142.68ms
step:853/1405 train_time:120282ms step_avg:142.68ms
step:854/1405 train_time:120429ms step_avg:142.69ms
step:855/1405 train_time:120577ms step_avg:142.69ms
step:856/1405 train_time:120724ms step_avg:142.70ms
step:857/1405 train_time:120873ms step_avg:142.71ms
step:858/1405 train_time:121024ms step_avg:142.72ms
step:859/1405 train_time:121173ms step_avg:142.72ms
step:860/1405 train_time:121323ms step_avg:142.73ms
step:861/1405 train_time:121470ms step_avg:142.74ms
step:862/1405 train_time:121618ms step_avg:142.74ms
step:863/1405 train_time:121766ms step_avg:142.75ms
step:864/1405 train_time:121916ms step_avg:142.76ms
step:865/1405 train_time:122064ms step_avg:142.76ms
step:866/1405 train_time:122214ms step_avg:142.77ms
step:867/1405 train_time:122362ms step_avg:142.78ms
step:868/1405 train_time:122509ms step_avg:142.78ms
step:869/1405 train_time:122658ms step_avg:142.79ms
step:870/1405 train_time:122806ms step_avg:142.80ms
step:871/1405 train_time:122955ms step_avg:142.80ms
step:872/1405 train_time:123103ms step_avg:142.81ms
step:873/1405 train_time:123248ms step_avg:142.81ms
step:874/1405 train_time:123398ms step_avg:142.82ms
step:875/1405 train_time:123546ms step_avg:142.83ms
step:875/1405 val_loss:3.4772 train_time:123618ms step_avg:142.91ms
step:876/1405 train_time:123695ms step_avg:142.83ms
step:877/1405 train_time:123845ms step_avg:142.84ms
step:878/1405 train_time:123993ms step_avg:142.85ms
step:879/1405 train_time:124141ms step_avg:142.85ms
step:880/1405 train_time:124289ms step_avg:142.86ms
step:881/1405 train_time:124435ms step_avg:142.86ms
step:882/1405 train_time:124586ms step_avg:142.87ms
step:883/1405 train_time:124735ms step_avg:142.88ms
step:884/1405 train_time:124887ms step_avg:142.89ms
step:885/1405 train_time:125034ms step_avg:142.90ms
step:886/1405 train_time:125183ms step_avg:142.90ms
step:887/1405 train_time:125330ms step_avg:142.91ms
step:888/1405 train_time:125480ms step_avg:142.92ms
step:889/1405 train_time:125629ms step_avg:142.92ms
step:890/1405 train_time:125777ms step_avg:142.93ms
step:891/1405 train_time:125926ms step_avg:142.94ms
step:892/1405 train_time:126074ms step_avg:142.94ms
step:893/1405 train_time:126221ms step_avg:142.95ms
step:894/1405 train_time:126370ms step_avg:142.95ms
step:895/1405 train_time:126518ms step_avg:142.96ms
step:896/1405 train_time:126667ms step_avg:142.97ms
step:897/1405 train_time:126816ms step_avg:142.97ms
step:898/1405 train_time:126965ms step_avg:142.98ms
step:899/1405 train_time:127112ms step_avg:142.98ms
step:900/1405 train_time:127258ms step_avg:142.99ms
step:901/1405 train_time:127409ms step_avg:143.00ms
step:902/1405 train_time:127555ms step_avg:143.00ms
step:903/1405 train_time:127703ms step_avg:143.00ms
step:904/1405 train_time:127852ms step_avg:143.01ms
step:905/1405 train_time:127999ms step_avg:143.02ms
step:906/1405 train_time:128150ms step_avg:143.02ms
step:907/1405 train_time:128297ms step_avg:143.03ms
step:908/1405 train_time:128447ms step_avg:143.04ms
step:909/1405 train_time:128595ms step_avg:143.04ms
step:910/1405 train_time:128748ms step_avg:143.05ms
step:911/1405 train_time:128894ms step_avg:143.06ms
step:912/1405 train_time:129043ms step_avg:143.06ms
step:913/1405 train_time:129193ms step_avg:143.07ms
step:914/1405 train_time:129342ms step_avg:143.08ms
step:915/1405 train_time:129491ms step_avg:143.08ms
step:916/1405 train_time:129639ms step_avg:143.09ms
step:917/1405 train_time:129788ms step_avg:143.10ms
step:918/1405 train_time:129937ms step_avg:143.10ms
step:919/1405 train_time:130086ms step_avg:143.11ms
step:920/1405 train_time:130233ms step_avg:143.11ms
step:921/1405 train_time:130381ms step_avg:143.12ms
step:922/1405 train_time:130531ms step_avg:143.13ms
step:923/1405 train_time:130681ms step_avg:143.13ms
step:924/1405 train_time:130830ms step_avg:143.14ms
step:925/1405 train_time:130979ms step_avg:143.15ms
step:926/1405 train_time:131129ms step_avg:143.15ms
step:927/1405 train_time:131276ms step_avg:143.16ms
step:928/1405 train_time:131425ms step_avg:143.16ms
step:929/1405 train_time:131573ms step_avg:143.17ms
step:930/1405 train_time:131721ms step_avg:143.18ms
step:931/1405 train_time:131869ms step_avg:143.18ms
step:932/1405 train_time:132018ms step_avg:143.19ms
step:933/1405 train_time:132168ms step_avg:143.19ms
step:934/1405 train_time:132317ms step_avg:143.20ms
step:935/1405 train_time:132466ms step_avg:143.21ms
step:936/1405 train_time:132614ms step_avg:143.21ms
step:937/1405 train_time:132764ms step_avg:143.22ms
step:938/1405 train_time:132913ms step_avg:143.22ms
step:939/1405 train_time:133064ms step_avg:143.23ms
step:940/1405 train_time:133212ms step_avg:143.24ms
step:941/1405 train_time:133363ms step_avg:143.25ms
step:942/1405 train_time:133511ms step_avg:143.25ms
step:943/1405 train_time:133661ms step_avg:143.26ms
step:944/1405 train_time:133813ms step_avg:143.27ms
step:945/1405 train_time:133965ms step_avg:143.28ms
step:946/1405 train_time:134117ms step_avg:143.29ms
step:947/1405 train_time:134268ms step_avg:143.30ms
step:948/1405 train_time:134417ms step_avg:143.30ms
step:949/1405 train_time:134570ms step_avg:143.31ms
step:950/1405 train_time:134718ms step_avg:143.32ms
step:951/1405 train_time:134914ms step_avg:143.37ms
step:952/1405 train_time:135063ms step_avg:143.38ms
step:953/1405 train_time:135212ms step_avg:143.38ms
step:954/1405 train_time:135360ms step_avg:143.39ms
step:955/1405 train_time:135509ms step_avg:143.40ms
step:956/1405 train_time:135657ms step_avg:143.40ms
step:957/1405 train_time:135809ms step_avg:143.41ms
step:958/1405 train_time:135962ms step_avg:143.42ms
step:959/1405 train_time:136113ms step_avg:143.43ms
step:960/1405 train_time:136264ms step_avg:143.44ms
step:961/1405 train_time:136413ms step_avg:143.44ms
step:962/1405 train_time:136563ms step_avg:143.45ms
step:963/1405 train_time:136713ms step_avg:143.46ms
step:964/1405 train_time:136863ms step_avg:143.46ms
step:965/1405 train_time:137013ms step_avg:143.47ms
step:966/1405 train_time:137162ms step_avg:143.48ms
step:967/1405 train_time:137311ms step_avg:143.48ms
step:968/1405 train_time:137460ms step_avg:143.49ms
step:969/1405 train_time:137610ms step_avg:143.49ms
step:970/1405 train_time:137759ms step_avg:143.50ms
step:971/1405 train_time:137910ms step_avg:143.51ms
step:972/1405 train_time:138060ms step_avg:143.51ms
step:973/1405 train_time:138209ms step_avg:143.52ms
step:974/1405 train_time:138359ms step_avg:143.53ms
step:975/1405 train_time:138510ms step_avg:143.53ms
step:976/1405 train_time:138657ms step_avg:143.54ms
step:977/1405 train_time:138808ms step_avg:143.54ms
step:978/1405 train_time:138958ms step_avg:143.55ms
step:979/1405 train_time:139109ms step_avg:143.56ms
step:980/1405 train_time:139256ms step_avg:143.56ms
step:981/1405 train_time:139407ms step_avg:143.57ms
step:982/1405 train_time:139556ms step_avg:143.58ms
step:983/1405 train_time:139704ms step_avg:143.58ms
step:984/1405 train_time:139852ms step_avg:143.59ms
step:985/1405 train_time:140001ms step_avg:143.59ms
step:986/1405 train_time:140151ms step_avg:143.60ms
step:987/1405 train_time:140299ms step_avg:143.60ms
step:988/1405 train_time:140450ms step_avg:143.61ms
step:989/1405 train_time:140600ms step_avg:143.62ms
step:990/1405 train_time:140750ms step_avg:143.62ms
step:991/1405 train_time:140897ms step_avg:143.63ms
step:992/1405 train_time:141048ms step_avg:143.63ms
step:993/1405 train_time:141201ms step_avg:143.64ms
step:994/1405 train_time:141352ms step_avg:143.65ms
step:995/1405 train_time:141499ms step_avg:143.65ms
step:996/1405 train_time:141649ms step_avg:143.66ms
step:997/1405 train_time:141798ms step_avg:143.67ms
step:998/1405 train_time:141949ms step_avg:143.67ms
step:999/1405 train_time:142098ms step_avg:143.68ms
step:1000/1405 train_time:142249ms step_avg:143.69ms
step:1000/1405 val_loss:3.4119 train_time:142322ms step_avg:143.76ms
step:1001/1405 train_time:142400ms step_avg:143.69ms
step:1002/1405 train_time:142550ms step_avg:143.70ms
step:1003/1405 train_time:142703ms step_avg:143.71ms
step:1004/1405 train_time:142852ms step_avg:143.71ms
step:1005/1405 train_time:143001ms step_avg:143.72ms
step:1006/1405 train_time:143148ms step_avg:143.72ms
step:1007/1405 train_time:143302ms step_avg:143.73ms
step:1008/1405 train_time:143451ms step_avg:143.74ms
step:1009/1405 train_time:143605ms step_avg:143.75ms
step:1010/1405 train_time:143752ms step_avg:143.75ms
step:1011/1405 train_time:143903ms step_avg:143.76ms
step:1012/1405 train_time:144051ms step_avg:143.76ms
step:1013/1405 train_time:144202ms step_avg:143.77ms
step:1014/1405 train_time:144350ms step_avg:143.78ms
step:1015/1405 train_time:144501ms step_avg:143.78ms
step:1016/1405 train_time:144649ms step_avg:143.79ms
step:1017/1405 train_time:144799ms step_avg:143.79ms
step:1018/1405 train_time:144948ms step_avg:143.80ms
step:1019/1405 train_time:145099ms step_avg:143.80ms
step:1020/1405 train_time:145248ms step_avg:143.81ms
step:1021/1405 train_time:145399ms step_avg:143.82ms
step:1022/1405 train_time:145549ms step_avg:143.82ms
step:1023/1405 train_time:145698ms step_avg:143.83ms
step:1024/1405 train_time:145847ms step_avg:143.83ms
step:1025/1405 train_time:145997ms step_avg:143.84ms
step:1026/1405 train_time:146146ms step_avg:143.84ms
step:1027/1405 train_time:146296ms step_avg:143.85ms
step:1028/1405 train_time:146446ms step_avg:143.86ms
step:1029/1405 train_time:146595ms step_avg:143.86ms
step:1030/1405 train_time:146744ms step_avg:143.87ms
step:1031/1405 train_time:146891ms step_avg:143.87ms
step:1032/1405 train_time:147041ms step_avg:143.88ms
step:1033/1405 train_time:147190ms step_avg:143.88ms
step:1034/1405 train_time:147341ms step_avg:143.89ms
step:1035/1405 train_time:147491ms step_avg:143.89ms
step:1036/1405 train_time:147642ms step_avg:143.90ms
step:1037/1405 train_time:147791ms step_avg:143.91ms
step:1038/1405 train_time:147941ms step_avg:143.91ms
step:1039/1405 train_time:148089ms step_avg:143.92ms
step:1040/1405 train_time:148239ms step_avg:143.92ms
step:1041/1405 train_time:148388ms step_avg:143.93ms
step:1042/1405 train_time:148537ms step_avg:143.93ms
step:1043/1405 train_time:148686ms step_avg:143.94ms
step:1044/1405 train_time:148836ms step_avg:143.94ms
step:1045/1405 train_time:148988ms step_avg:143.95ms
step:1046/1405 train_time:149136ms step_avg:143.95ms
step:1047/1405 train_time:149287ms step_avg:143.96ms
step:1048/1405 train_time:149437ms step_avg:143.97ms
step:1049/1405 train_time:149588ms step_avg:143.97ms
step:1050/1405 train_time:149738ms step_avg:143.98ms
step:1051/1405 train_time:149889ms step_avg:143.99ms
step:1052/1405 train_time:150040ms step_avg:143.99ms
step:1053/1405 train_time:150189ms step_avg:144.00ms
step:1054/1405 train_time:150340ms step_avg:144.00ms
step:1055/1405 train_time:150489ms step_avg:144.01ms
step:1056/1405 train_time:150639ms step_avg:144.01ms
step:1057/1405 train_time:150790ms step_avg:144.02ms
step:1058/1405 train_time:150941ms step_avg:144.03ms
step:1059/1405 train_time:151091ms step_avg:144.03ms
step:1060/1405 train_time:151241ms step_avg:144.04ms
step:1061/1405 train_time:151391ms step_avg:144.04ms
step:1062/1405 train_time:151543ms step_avg:144.05ms
step:1063/1405 train_time:151694ms step_avg:144.06ms
step:1064/1405 train_time:151844ms step_avg:144.06ms
step:1065/1405 train_time:151995ms step_avg:144.07ms
step:1066/1405 train_time:152149ms step_avg:144.08ms
step:1067/1405 train_time:152299ms step_avg:144.09ms
step:1068/1405 train_time:152448ms step_avg:144.09ms
step:1069/1405 train_time:152600ms step_avg:144.10ms
step:1070/1405 train_time:152748ms step_avg:144.10ms
step:1071/1405 train_time:152900ms step_avg:144.11ms
step:1072/1405 train_time:153048ms step_avg:144.11ms
step:1073/1405 train_time:153198ms step_avg:144.12ms
step:1074/1405 train_time:153348ms step_avg:144.12ms
step:1075/1405 train_time:153499ms step_avg:144.13ms
step:1076/1405 train_time:153648ms step_avg:144.13ms
step:1077/1405 train_time:153797ms step_avg:144.14ms
step:1078/1405 train_time:153950ms step_avg:144.15ms
step:1079/1405 train_time:154101ms step_avg:144.15ms
step:1080/1405 train_time:154251ms step_avg:144.16ms
step:1081/1405 train_time:154402ms step_avg:144.17ms
step:1082/1405 train_time:154551ms step_avg:144.17ms
step:1083/1405 train_time:154703ms step_avg:144.18ms
step:1084/1405 train_time:154853ms step_avg:144.18ms
step:1085/1405 train_time:155005ms step_avg:144.19ms
step:1086/1405 train_time:155156ms step_avg:144.20ms
step:1087/1405 train_time:155308ms step_avg:144.20ms
step:1088/1405 train_time:155457ms step_avg:144.21ms
step:1089/1405 train_time:155609ms step_avg:144.22ms
step:1090/1405 train_time:155760ms step_avg:144.22ms
step:1091/1405 train_time:155910ms step_avg:144.23ms
step:1092/1405 train_time:156060ms step_avg:144.23ms
step:1093/1405 train_time:156211ms step_avg:144.24ms
step:1094/1405 train_time:156363ms step_avg:144.25ms
step:1095/1405 train_time:156513ms step_avg:144.25ms
step:1096/1405 train_time:156667ms step_avg:144.26ms
step:1097/1405 train_time:156815ms step_avg:144.26ms
step:1098/1405 train_time:156967ms step_avg:144.27ms
step:1099/1405 train_time:157116ms step_avg:144.28ms
step:1100/1405 train_time:157265ms step_avg:144.28ms
step:1101/1405 train_time:157413ms step_avg:144.28ms
step:1102/1405 train_time:157564ms step_avg:144.29ms
step:1103/1405 train_time:157713ms step_avg:144.29ms
step:1104/1405 train_time:157862ms step_avg:144.30ms
step:1105/1405 train_time:158011ms step_avg:144.30ms
step:1106/1405 train_time:158162ms step_avg:144.31ms
step:1107/1405 train_time:158312ms step_avg:144.31ms
step:1108/1405 train_time:158463ms step_avg:144.32ms
step:1109/1405 train_time:158611ms step_avg:144.32ms
step:1110/1405 train_time:158761ms step_avg:144.33ms
step:1111/1405 train_time:158911ms step_avg:144.33ms
step:1112/1405 train_time:159062ms step_avg:144.34ms
step:1113/1405 train_time:159213ms step_avg:144.35ms
step:1114/1405 train_time:159365ms step_avg:144.35ms
step:1115/1405 train_time:159515ms step_avg:144.36ms
step:1116/1405 train_time:159664ms step_avg:144.36ms
step:1117/1405 train_time:159813ms step_avg:144.37ms
step:1118/1405 train_time:159967ms step_avg:144.37ms
step:1119/1405 train_time:160119ms step_avg:144.38ms
step:1120/1405 train_time:160269ms step_avg:144.39ms
step:1121/1405 train_time:160418ms step_avg:144.39ms
step:1122/1405 train_time:160567ms step_avg:144.39ms
step:1123/1405 train_time:160715ms step_avg:144.40ms
step:1124/1405 train_time:160866ms step_avg:144.40ms
step:1125/1405 train_time:161015ms step_avg:144.41ms
step:1125/1405 val_loss:3.3584 train_time:161088ms step_avg:144.47ms
step:1126/1405 train_time:161164ms step_avg:144.41ms
step:1127/1405 train_time:161316ms step_avg:144.42ms
step:1128/1405 train_time:161465ms step_avg:144.42ms
step:1129/1405 train_time:161616ms step_avg:144.43ms
step:1130/1405 train_time:161764ms step_avg:144.43ms
step:1131/1405 train_time:161916ms step_avg:144.44ms
step:1132/1405 train_time:162064ms step_avg:144.44ms
step:1133/1405 train_time:162217ms step_avg:144.45ms
step:1134/1405 train_time:162368ms step_avg:144.46ms
step:1135/1405 train_time:162518ms step_avg:144.46ms
step:1136/1405 train_time:162669ms step_avg:144.47ms
step:1137/1405 train_time:162817ms step_avg:144.47ms
step:1138/1405 train_time:162966ms step_avg:144.47ms
step:1139/1405 train_time:163117ms step_avg:144.48ms
step:1140/1405 train_time:163268ms step_avg:144.48ms
step:1141/1405 train_time:163461ms step_avg:144.53ms
step:1142/1405 train_time:163615ms step_avg:144.54ms
step:1143/1405 train_time:163766ms step_avg:144.54ms
step:1144/1405 train_time:163917ms step_avg:144.55ms
step:1145/1405 train_time:164063ms step_avg:144.55ms
step:1146/1405 train_time:164214ms step_avg:144.55ms
step:1147/1405 train_time:164366ms step_avg:144.56ms
step:1148/1405 train_time:164519ms step_avg:144.57ms
step:1149/1405 train_time:164670ms step_avg:144.57ms
step:1150/1405 train_time:164820ms step_avg:144.58ms
step:1151/1405 train_time:164972ms step_avg:144.59ms
step:1152/1405 train_time:165122ms step_avg:144.59ms
step:1153/1405 train_time:165273ms step_avg:144.60ms
step:1154/1405 train_time:165424ms step_avg:144.60ms
step:1155/1405 train_time:165577ms step_avg:144.61ms
step:1156/1405 train_time:165730ms step_avg:144.62ms
step:1157/1405 train_time:165884ms step_avg:144.62ms
step:1158/1405 train_time:166037ms step_avg:144.63ms
step:1159/1405 train_time:166188ms step_avg:144.64ms
step:1160/1405 train_time:166338ms step_avg:144.64ms
step:1161/1405 train_time:166490ms step_avg:144.65ms
step:1162/1405 train_time:166642ms step_avg:144.65ms
step:1163/1405 train_time:166793ms step_avg:144.66ms
step:1164/1405 train_time:166943ms step_avg:144.67ms
step:1165/1405 train_time:167094ms step_avg:144.67ms
step:1166/1405 train_time:167246ms step_avg:144.68ms
step:1167/1405 train_time:167397ms step_avg:144.68ms
step:1168/1405 train_time:167549ms step_avg:144.69ms
step:1169/1405 train_time:167702ms step_avg:144.70ms
step:1170/1405 train_time:167855ms step_avg:144.70ms
step:1171/1405 train_time:168006ms step_avg:144.71ms
step:1172/1405 train_time:168159ms step_avg:144.72ms
step:1173/1405 train_time:168310ms step_avg:144.72ms
step:1174/1405 train_time:168464ms step_avg:144.73ms
step:1175/1405 train_time:168619ms step_avg:144.74ms
step:1176/1405 train_time:168775ms step_avg:144.75ms
step:1177/1405 train_time:168931ms step_avg:144.76ms
step:1178/1405 train_time:169082ms step_avg:144.76ms
step:1179/1405 train_time:169235ms step_avg:144.77ms
step:1180/1405 train_time:169390ms step_avg:144.78ms
step:1181/1405 train_time:169542ms step_avg:144.78ms
step:1182/1405 train_time:169693ms step_avg:144.79ms
step:1183/1405 train_time:169842ms step_avg:144.79ms
step:1184/1405 train_time:169994ms step_avg:144.80ms
step:1185/1405 train_time:170147ms step_avg:144.81ms
step:1186/1405 train_time:170299ms step_avg:144.81ms
step:1187/1405 train_time:170453ms step_avg:144.82ms
step:1188/1405 train_time:170602ms step_avg:144.82ms
step:1189/1405 train_time:170756ms step_avg:144.83ms
step:1190/1405 train_time:170908ms step_avg:144.84ms
step:1191/1405 train_time:171061ms step_avg:144.84ms
step:1192/1405 train_time:171212ms step_avg:144.85ms
step:1193/1405 train_time:171363ms step_avg:144.85ms
step:1194/1405 train_time:171515ms step_avg:144.86ms
step:1195/1405 train_time:171664ms step_avg:144.86ms
step:1196/1405 train_time:171819ms step_avg:144.87ms
step:1197/1405 train_time:171971ms step_avg:144.88ms
step:1198/1405 train_time:172125ms step_avg:144.89ms
step:1199/1405 train_time:172277ms step_avg:144.89ms
step:1200/1405 train_time:172428ms step_avg:144.90ms
step:1201/1405 train_time:172580ms step_avg:144.90ms
step:1202/1405 train_time:172738ms step_avg:144.91ms
step:1203/1405 train_time:172890ms step_avg:144.92ms
step:1204/1405 train_time:173041ms step_avg:144.93ms
step:1205/1405 train_time:173192ms step_avg:144.93ms
step:1206/1405 train_time:173344ms step_avg:144.94ms
step:1207/1405 train_time:173497ms step_avg:144.94ms
step:1208/1405 train_time:173649ms step_avg:144.95ms
step:1209/1405 train_time:173800ms step_avg:144.95ms
step:1210/1405 train_time:173954ms step_avg:144.96ms
step:1211/1405 train_time:174105ms step_avg:144.97ms
step:1212/1405 train_time:174258ms step_avg:144.97ms
step:1213/1405 train_time:174408ms step_avg:144.98ms
step:1214/1405 train_time:174560ms step_avg:144.98ms
step:1215/1405 train_time:174711ms step_avg:144.99ms
step:1216/1405 train_time:174862ms step_avg:144.99ms
step:1217/1405 train_time:175012ms step_avg:145.00ms
step:1218/1405 train_time:175161ms step_avg:145.00ms
step:1219/1405 train_time:175313ms step_avg:145.01ms
step:1220/1405 train_time:175462ms step_avg:145.01ms
step:1221/1405 train_time:175612ms step_avg:145.01ms
step:1222/1405 train_time:175764ms step_avg:145.02ms
step:1223/1405 train_time:175917ms step_avg:145.03ms
step:1224/1405 train_time:176069ms step_avg:145.03ms
step:1225/1405 train_time:176220ms step_avg:145.04ms
step:1226/1405 train_time:176371ms step_avg:145.04ms
step:1227/1405 train_time:176525ms step_avg:145.05ms
step:1228/1405 train_time:176677ms step_avg:145.05ms
step:1229/1405 train_time:176826ms step_avg:145.06ms
step:1230/1405 train_time:176981ms step_avg:145.07ms
step:1231/1405 train_time:177132ms step_avg:145.07ms
step:1232/1405 train_time:177283ms step_avg:145.08ms
step:1233/1405 train_time:177434ms step_avg:145.08ms
step:1234/1405 train_time:177583ms step_avg:145.08ms
step:1235/1405 train_time:177734ms step_avg:145.09ms
step:1236/1405 train_time:177885ms step_avg:145.09ms
step:1237/1405 train_time:178038ms step_avg:145.10ms
step:1238/1405 train_time:178192ms step_avg:145.11ms
step:1239/1405 train_time:178343ms step_avg:145.11ms
step:1240/1405 train_time:178498ms step_avg:145.12ms
step:1241/1405 train_time:178654ms step_avg:145.13ms
step:1242/1405 train_time:178803ms step_avg:145.13ms
step:1243/1405 train_time:178957ms step_avg:145.14ms
step:1244/1405 train_time:179107ms step_avg:145.14ms
step:1245/1405 train_time:179261ms step_avg:145.15ms
step:1246/1405 train_time:179412ms step_avg:145.16ms
step:1247/1405 train_time:179565ms step_avg:145.16ms
step:1248/1405 train_time:179717ms step_avg:145.17ms
step:1249/1405 train_time:179867ms step_avg:145.17ms
step:1250/1405 train_time:180018ms step_avg:145.18ms
step:1250/1405 val_loss:3.3113 train_time:180093ms step_avg:145.24ms
step:1251/1405 train_time:180173ms step_avg:145.18ms
step:1252/1405 train_time:180326ms step_avg:145.19ms
step:1253/1405 train_time:180476ms step_avg:145.19ms
step:1254/1405 train_time:180625ms step_avg:145.20ms
step:1255/1405 train_time:180782ms step_avg:145.21ms
step:1256/1405 train_time:180933ms step_avg:145.21ms
step:1257/1405 train_time:181084ms step_avg:145.22ms
step:1258/1405 train_time:181239ms step_avg:145.22ms
step:1259/1405 train_time:181392ms step_avg:145.23ms
step:1260/1405 train_time:181542ms step_avg:145.23ms
step:1261/1405 train_time:181694ms step_avg:145.24ms
step:1262/1405 train_time:181848ms step_avg:145.25ms
step:1263/1405 train_time:182000ms step_avg:145.25ms
step:1264/1405 train_time:182148ms step_avg:145.25ms
step:1265/1405 train_time:182302ms step_avg:145.26ms
step:1266/1405 train_time:182453ms step_avg:145.27ms
step:1267/1405 train_time:182605ms step_avg:145.27ms
step:1268/1405 train_time:182757ms step_avg:145.28ms
step:1269/1405 train_time:182911ms step_avg:145.28ms
step:1270/1405 train_time:183064ms step_avg:145.29ms
step:1271/1405 train_time:183216ms step_avg:145.29ms
step:1272/1405 train_time:183368ms step_avg:145.30ms
step:1273/1405 train_time:183521ms step_avg:145.31ms
step:1274/1405 train_time:183669ms step_avg:145.31ms
step:1275/1405 train_time:183821ms step_avg:145.31ms
step:1276/1405 train_time:183971ms step_avg:145.32ms
step:1277/1405 train_time:184124ms step_avg:145.32ms
step:1278/1405 train_time:184274ms step_avg:145.33ms
step:1279/1405 train_time:184426ms step_avg:145.33ms
step:1280/1405 train_time:184582ms step_avg:145.34ms
step:1281/1405 train_time:184734ms step_avg:145.35ms
step:1282/1405 train_time:184884ms step_avg:145.35ms
step:1283/1405 train_time:185035ms step_avg:145.35ms
step:1284/1405 train_time:185188ms step_avg:145.36ms
step:1285/1405 train_time:185340ms step_avg:145.36ms
step:1286/1405 train_time:185493ms step_avg:145.37ms
step:1287/1405 train_time:185644ms step_avg:145.37ms
step:1288/1405 train_time:185796ms step_avg:145.38ms
step:1289/1405 train_time:185950ms step_avg:145.39ms
step:1290/1405 train_time:186104ms step_avg:145.39ms
step:1291/1405 train_time:186257ms step_avg:145.40ms
step:1292/1405 train_time:186409ms step_avg:145.40ms
step:1293/1405 train_time:186563ms step_avg:145.41ms
step:1294/1405 train_time:186715ms step_avg:145.42ms
step:1295/1405 train_time:186866ms step_avg:145.42ms
step:1296/1405 train_time:187018ms step_avg:145.43ms
step:1297/1405 train_time:187172ms step_avg:145.43ms
step:1298/1405 train_time:187325ms step_avg:145.44ms
step:1299/1405 train_time:187477ms step_avg:145.44ms
step:1300/1405 train_time:187628ms step_avg:145.45ms
step:1301/1405 train_time:187779ms step_avg:145.45ms
step:1302/1405 train_time:187931ms step_avg:145.46ms
step:1303/1405 train_time:188085ms step_avg:145.46ms
step:1304/1405 train_time:188238ms step_avg:145.47ms
step:1305/1405 train_time:188388ms step_avg:145.47ms
step:1306/1405 train_time:188542ms step_avg:145.48ms
step:1307/1405 train_time:188692ms step_avg:145.48ms
step:1308/1405 train_time:188845ms step_avg:145.49ms
step:1309/1405 train_time:188996ms step_avg:145.49ms
step:1310/1405 train_time:189146ms step_avg:145.50ms
step:1311/1405 train_time:189298ms step_avg:145.50ms
step:1312/1405 train_time:189447ms step_avg:145.50ms
step:1313/1405 train_time:189599ms step_avg:145.51ms
step:1314/1405 train_time:189752ms step_avg:145.52ms
step:1315/1405 train_time:189905ms step_avg:145.52ms
step:1316/1405 train_time:190054ms step_avg:145.52ms
step:1317/1405 train_time:190205ms step_avg:145.53ms
step:1318/1405 train_time:190358ms step_avg:145.53ms
step:1319/1405 train_time:190509ms step_avg:145.54ms
step:1320/1405 train_time:190663ms step_avg:145.54ms
step:1321/1405 train_time:190817ms step_avg:145.55ms
step:1322/1405 train_time:190970ms step_avg:145.56ms
step:1323/1405 train_time:191124ms step_avg:145.56ms
step:1324/1405 train_time:191274ms step_avg:145.57ms
step:1325/1405 train_time:191426ms step_avg:145.57ms
step:1326/1405 train_time:191581ms step_avg:145.58ms
step:1327/1405 train_time:191731ms step_avg:145.58ms
step:1328/1405 train_time:191883ms step_avg:145.59ms
step:1329/1405 train_time:192044ms step_avg:145.60ms
step:1330/1405 train_time:192197ms step_avg:145.60ms
step:1331/1405 train_time:192389ms step_avg:145.64ms
step:1332/1405 train_time:192545ms step_avg:145.65ms
step:1333/1405 train_time:192696ms step_avg:145.65ms
step:1334/1405 train_time:192845ms step_avg:145.65ms
step:1335/1405 train_time:192996ms step_avg:145.66ms
step:1336/1405 train_time:193150ms step_avg:145.66ms
step:1337/1405 train_time:193304ms step_avg:145.67ms
step:1338/1405 train_time:193457ms step_avg:145.68ms
step:1339/1405 train_time:193610ms step_avg:145.68ms
step:1340/1405 train_time:193762ms step_avg:145.69ms
step:1341/1405 train_time:193911ms step_avg:145.69ms
step:1342/1405 train_time:194064ms step_avg:145.69ms
step:1343/1405 train_time:194215ms step_avg:145.70ms
step:1344/1405 train_time:194365ms step_avg:145.70ms
step:1345/1405 train_time:194517ms step_avg:145.71ms
step:1346/1405 train_time:194670ms step_avg:145.71ms
step:1347/1405 train_time:194823ms step_avg:145.72ms
step:1348/1405 train_time:194973ms step_avg:145.72ms
step:1349/1405 train_time:195126ms step_avg:145.73ms
step:1350/1405 train_time:195278ms step_avg:145.73ms
step:1351/1405 train_time:195429ms step_avg:145.73ms
step:1352/1405 train_time:195583ms step_avg:145.74ms
step:1353/1405 train_time:195737ms step_avg:145.75ms
step:1354/1405 train_time:195889ms step_avg:145.75ms
step:1355/1405 train_time:196044ms step_avg:145.76ms
step:1356/1405 train_time:196197ms step_avg:145.76ms
step:1357/1405 train_time:196350ms step_avg:145.77ms
step:1358/1405 train_time:196504ms step_avg:145.77ms
step:1359/1405 train_time:196657ms step_avg:145.78ms
step:1360/1405 train_time:196812ms step_avg:145.79ms
step:1361/1405 train_time:196966ms step_avg:145.79ms
step:1362/1405 train_time:197120ms step_avg:145.80ms
step:1363/1405 train_time:197276ms step_avg:145.81ms
step:1364/1405 train_time:197429ms step_avg:145.81ms
step:1365/1405 train_time:197582ms step_avg:145.82ms
step:1366/1405 train_time:197733ms step_avg:145.82ms
step:1367/1405 train_time:197887ms step_avg:145.83ms
step:1368/1405 train_time:198041ms step_avg:145.83ms
step:1369/1405 train_time:198199ms step_avg:145.84ms
step:1370/1405 train_time:198352ms step_avg:145.85ms
step:1371/1405 train_time:198504ms step_avg:145.85ms
step:1372/1405 train_time:198659ms step_avg:145.86ms
step:1373/1405 train_time:198810ms step_avg:145.86ms
step:1374/1405 train_time:198964ms step_avg:145.87ms
step:1375/1405 train_time:199116ms step_avg:145.87ms
step:1375/1405 val_loss:3.2806 train_time:199190ms step_avg:145.93ms
step:1376/1405 train_time:199267ms step_avg:145.88ms
step:1377/1405 train_time:199422ms step_avg:145.88ms
step:1378/1405 train_time:199573ms step_avg:145.89ms
step:1379/1405 train_time:199727ms step_avg:145.89ms
step:1380/1405 train_time:199879ms step_avg:145.90ms
step:1381/1405 train_time:200033ms step_avg:145.90ms
step:1382/1405 train_time:200187ms step_avg:145.91ms
step:1383/1405 train_time:200342ms step_avg:145.92ms
step:1384/1405 train_time:200498ms step_avg:145.92ms
step:1385/1405 train_time:200651ms step_avg:145.93ms
step:1386/1405 train_time:200806ms step_avg:145.93ms
step:1387/1405 train_time:200960ms step_avg:145.94ms
step:1388/1405 train_time:201111ms step_avg:145.94ms
step:1389/1405 train_time:201269ms step_avg:145.95ms
step:1390/1405 train_time:201420ms step_avg:145.96ms
step:1391/1405 train_time:201573ms step_avg:145.96ms
step:1392/1405 train_time:201728ms step_avg:145.97ms
step:1393/1405 train_time:201881ms step_avg:145.97ms
step:1394/1405 train_time:202033ms step_avg:145.98ms
step:1395/1405 train_time:202187ms step_avg:145.98ms
step:1396/1405 train_time:202339ms step_avg:145.99ms
step:1397/1405 train_time:202489ms step_avg:145.99ms
step:1398/1405 train_time:202644ms step_avg:146.00ms
step:1399/1405 train_time:202794ms step_avg:146.00ms
step:1400/1405 train_time:202953ms step_avg:146.01ms
step:1401/1405 train_time:203105ms step_avg:146.01ms
step:1402/1405 train_time:203257ms step_avg:146.02ms
step:1403/1405 train_time:203411ms step_avg:146.02ms
step:1404/1405 train_time:203565ms step_avg:146.03ms
step:1405/1405 train_time:203718ms step_avg:146.03ms
step:1405/1405 val_loss:3.2781 train_time:203794ms step_avg:146.09ms
peak memory consumption: 31569 MiB
