import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask: torch.Tensor):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_masks(sliding_window_num_blocks: int):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            global_block_mask = BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
            local_window_bm = q_idx - kv_idx < max(1, sliding_window_num_blocks // 2)
            local_window_full_bm = local_window_bm
            local_nonzero_bm = causal_bm & local_window_bm & document_bm
            local_full_bm = causal_full_bm & local_window_full_bm & document_full_bm
            local_kv_num_blocks, local_kv_indices = dense_to_ordered(local_nonzero_bm & ~local_full_bm)
            local_full_kv_num_blocks, local_full_kv_indices = dense_to_ordered(local_full_bm)
            local_block_mask = BlockMask.from_kv_blocks(
                local_kv_num_blocks,
                local_kv_indices,
                local_full_kv_num_blocks,
                local_full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
            return global_block_mask, local_block_mask

        global_block_mask, local_block_mask = create_doc_swc_block_masks(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            block_mask = global_block_mask if i % 2 == 0 else local_block_mask
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            block_mask = local_block_mask if i % 2 == 0 else global_block_mask
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1405 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250110+cu126 compiled for CUDA 12.6
Wed Jan 15 09:40:41 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   39C    P0             126W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   32C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   29C    P0             117W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   37C    P0             129W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   38C    P0             123W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   30C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   37C    P0             116W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   29C    P0             117W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1405 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1405 train_time:28016ms step_avg:nanms
step:2/1405 train_time:28084ms step_avg:nanms
step:3/1405 train_time:28273ms step_avg:nanms
step:4/1405 train_time:28406ms step_avg:nanms
step:5/1405 train_time:28539ms step_avg:nanms
step:6/1405 train_time:28673ms step_avg:nanms
step:7/1405 train_time:28805ms step_avg:nanms
step:8/1405 train_time:28940ms step_avg:nanms
step:9/1405 train_time:29075ms step_avg:nanms
step:10/1405 train_time:29217ms step_avg:nanms
step:11/1405 train_time:136ms step_avg:nanms
step:12/1405 train_time:271ms step_avg:nanms
step:13/1405 train_time:405ms step_avg:134.89ms
step:14/1405 train_time:540ms step_avg:135.12ms
step:15/1405 train_time:674ms step_avg:134.76ms
step:16/1405 train_time:808ms step_avg:134.70ms
step:17/1405 train_time:945ms step_avg:134.94ms
step:18/1405 train_time:1081ms step_avg:135.14ms
step:19/1405 train_time:1216ms step_avg:135.12ms
step:20/1405 train_time:1350ms step_avg:135.00ms
step:21/1405 train_time:1485ms step_avg:134.99ms
step:22/1405 train_time:1621ms step_avg:135.07ms
step:23/1405 train_time:1757ms step_avg:135.13ms
step:24/1405 train_time:1894ms step_avg:135.28ms
step:25/1405 train_time:2029ms step_avg:135.26ms
step:26/1405 train_time:2165ms step_avg:135.34ms
step:27/1405 train_time:2302ms step_avg:135.44ms
step:28/1405 train_time:2438ms step_avg:135.42ms
step:29/1405 train_time:2572ms step_avg:135.37ms
step:30/1405 train_time:2707ms step_avg:135.33ms
step:31/1405 train_time:2843ms step_avg:135.37ms
step:32/1405 train_time:2979ms step_avg:135.41ms
step:33/1405 train_time:3112ms step_avg:135.31ms
step:34/1405 train_time:3248ms step_avg:135.34ms
step:35/1405 train_time:3383ms step_avg:135.33ms
step:36/1405 train_time:3520ms step_avg:135.39ms
step:37/1405 train_time:3655ms step_avg:135.37ms
step:38/1405 train_time:3791ms step_avg:135.39ms
step:39/1405 train_time:3926ms step_avg:135.38ms
step:40/1405 train_time:4063ms step_avg:135.44ms
step:41/1405 train_time:4199ms step_avg:135.44ms
step:42/1405 train_time:4334ms step_avg:135.45ms
step:43/1405 train_time:4468ms step_avg:135.40ms
step:44/1405 train_time:4604ms step_avg:135.41ms
step:45/1405 train_time:4739ms step_avg:135.41ms
step:46/1405 train_time:4874ms step_avg:135.39ms
step:47/1405 train_time:5009ms step_avg:135.38ms
step:48/1405 train_time:5146ms step_avg:135.41ms
step:49/1405 train_time:5281ms step_avg:135.42ms
step:50/1405 train_time:5416ms step_avg:135.41ms
step:51/1405 train_time:5552ms step_avg:135.42ms
step:52/1405 train_time:5687ms step_avg:135.41ms
step:53/1405 train_time:5824ms step_avg:135.44ms
step:54/1405 train_time:5958ms step_avg:135.41ms
step:55/1405 train_time:6094ms step_avg:135.42ms
step:56/1405 train_time:6229ms step_avg:135.42ms
step:57/1405 train_time:6365ms step_avg:135.43ms
step:58/1405 train_time:6500ms step_avg:135.42ms
step:59/1405 train_time:6636ms step_avg:135.44ms
step:60/1405 train_time:6770ms step_avg:135.41ms
step:61/1405 train_time:6905ms step_avg:135.40ms
step:62/1405 train_time:7042ms step_avg:135.42ms
step:63/1405 train_time:7178ms step_avg:135.43ms
step:64/1405 train_time:7311ms step_avg:135.39ms
step:65/1405 train_time:7448ms step_avg:135.41ms
step:66/1405 train_time:7583ms step_avg:135.41ms
step:67/1405 train_time:7719ms step_avg:135.42ms
step:68/1405 train_time:7854ms step_avg:135.42ms
step:69/1405 train_time:7992ms step_avg:135.46ms
step:70/1405 train_time:8128ms step_avg:135.47ms
step:71/1405 train_time:8264ms step_avg:135.47ms
step:72/1405 train_time:8400ms step_avg:135.48ms
step:73/1405 train_time:8535ms step_avg:135.47ms
step:74/1405 train_time:8669ms step_avg:135.45ms
step:75/1405 train_time:8805ms step_avg:135.46ms
step:76/1405 train_time:8941ms step_avg:135.46ms
step:77/1405 train_time:9074ms step_avg:135.43ms
step:78/1405 train_time:9209ms step_avg:135.43ms
step:79/1405 train_time:9346ms step_avg:135.45ms
step:80/1405 train_time:9483ms step_avg:135.47ms
step:81/1405 train_time:9618ms step_avg:135.47ms
step:82/1405 train_time:9753ms step_avg:135.46ms
step:83/1405 train_time:9887ms step_avg:135.44ms
step:84/1405 train_time:10024ms step_avg:135.46ms
step:85/1405 train_time:10161ms step_avg:135.47ms
step:86/1405 train_time:10298ms step_avg:135.50ms
step:87/1405 train_time:10432ms step_avg:135.48ms
step:88/1405 train_time:10567ms step_avg:135.47ms
step:89/1405 train_time:10703ms step_avg:135.48ms
step:90/1405 train_time:10840ms step_avg:135.50ms
step:91/1405 train_time:10974ms step_avg:135.48ms
step:92/1405 train_time:11110ms step_avg:135.49ms
step:93/1405 train_time:11247ms step_avg:135.50ms
step:94/1405 train_time:11382ms step_avg:135.51ms
step:95/1405 train_time:11519ms step_avg:135.52ms
step:96/1405 train_time:11655ms step_avg:135.52ms
step:97/1405 train_time:11791ms step_avg:135.53ms
step:98/1405 train_time:11928ms step_avg:135.55ms
step:99/1405 train_time:12063ms step_avg:135.54ms
step:100/1405 train_time:12199ms step_avg:135.54ms
step:101/1405 train_time:12334ms step_avg:135.54ms
step:102/1405 train_time:12471ms step_avg:135.55ms
step:103/1405 train_time:12607ms step_avg:135.56ms
step:104/1405 train_time:12744ms step_avg:135.58ms
step:105/1405 train_time:12880ms step_avg:135.58ms
step:106/1405 train_time:13017ms step_avg:135.59ms
step:107/1405 train_time:13155ms step_avg:135.62ms
step:108/1405 train_time:13293ms step_avg:135.64ms
step:109/1405 train_time:13430ms step_avg:135.65ms
step:110/1405 train_time:13568ms step_avg:135.68ms
step:111/1405 train_time:13705ms step_avg:135.70ms
step:112/1405 train_time:13845ms step_avg:135.73ms
step:113/1405 train_time:13981ms step_avg:135.74ms
step:114/1405 train_time:14118ms step_avg:135.75ms
step:115/1405 train_time:14255ms step_avg:135.76ms
step:116/1405 train_time:14392ms step_avg:135.78ms
step:117/1405 train_time:14529ms step_avg:135.79ms
step:118/1405 train_time:14666ms step_avg:135.80ms
step:119/1405 train_time:14805ms step_avg:135.82ms
step:120/1405 train_time:14943ms step_avg:135.85ms
step:121/1405 train_time:15081ms step_avg:135.87ms
step:122/1405 train_time:15218ms step_avg:135.87ms
step:123/1405 train_time:15354ms step_avg:135.88ms
step:124/1405 train_time:15493ms step_avg:135.91ms
step:125/1405 train_time:15631ms step_avg:135.92ms
step:125/1405 val_loss:4.3840 train_time:15698ms step_avg:136.50ms
step:126/1405 train_time:15771ms step_avg:135.95ms
step:127/1405 train_time:15913ms step_avg:136.01ms
step:128/1405 train_time:16052ms step_avg:136.03ms
step:129/1405 train_time:16188ms step_avg:136.04ms
step:130/1405 train_time:16325ms step_avg:136.04ms
step:131/1405 train_time:16461ms step_avg:136.04ms
step:132/1405 train_time:16598ms step_avg:136.05ms
step:133/1405 train_time:16738ms step_avg:136.08ms
step:134/1405 train_time:16876ms step_avg:136.09ms
step:135/1405 train_time:17013ms step_avg:136.10ms
step:136/1405 train_time:17151ms step_avg:136.12ms
step:137/1405 train_time:17289ms step_avg:136.13ms
step:138/1405 train_time:17425ms step_avg:136.13ms
step:139/1405 train_time:17562ms step_avg:136.14ms
step:140/1405 train_time:17701ms step_avg:136.17ms
step:141/1405 train_time:17841ms step_avg:136.19ms
step:142/1405 train_time:17980ms step_avg:136.21ms
step:143/1405 train_time:18116ms step_avg:136.21ms
step:144/1405 train_time:18256ms step_avg:136.24ms
step:145/1405 train_time:18391ms step_avg:136.23ms
step:146/1405 train_time:18529ms step_avg:136.24ms
step:147/1405 train_time:18667ms step_avg:136.26ms
step:148/1405 train_time:18806ms step_avg:136.27ms
step:149/1405 train_time:18944ms step_avg:136.29ms
step:150/1405 train_time:19084ms step_avg:136.31ms
step:151/1405 train_time:19222ms step_avg:136.33ms
step:152/1405 train_time:19359ms step_avg:136.33ms
step:153/1405 train_time:19497ms step_avg:136.34ms
step:154/1405 train_time:19635ms step_avg:136.35ms
step:155/1405 train_time:19772ms step_avg:136.36ms
step:156/1405 train_time:19911ms step_avg:136.38ms
step:157/1405 train_time:20050ms step_avg:136.39ms
step:158/1405 train_time:20190ms step_avg:136.42ms
step:159/1405 train_time:20328ms step_avg:136.43ms
step:160/1405 train_time:20464ms step_avg:136.43ms
step:161/1405 train_time:20602ms step_avg:136.44ms
step:162/1405 train_time:20741ms step_avg:136.45ms
step:163/1405 train_time:20879ms step_avg:136.47ms
step:164/1405 train_time:21018ms step_avg:136.48ms
step:165/1405 train_time:21157ms step_avg:136.50ms
step:166/1405 train_time:21296ms step_avg:136.51ms
step:167/1405 train_time:21432ms step_avg:136.51ms
step:168/1405 train_time:21570ms step_avg:136.52ms
step:169/1405 train_time:21709ms step_avg:136.54ms
step:170/1405 train_time:21848ms step_avg:136.55ms
step:171/1405 train_time:21986ms step_avg:136.56ms
step:172/1405 train_time:22125ms step_avg:136.57ms
step:173/1405 train_time:22263ms step_avg:136.58ms
step:174/1405 train_time:22402ms step_avg:136.60ms
step:175/1405 train_time:22540ms step_avg:136.61ms
step:176/1405 train_time:22680ms step_avg:136.63ms
step:177/1405 train_time:22818ms step_avg:136.63ms
step:178/1405 train_time:22957ms step_avg:136.65ms
step:179/1405 train_time:23094ms step_avg:136.65ms
step:180/1405 train_time:23232ms step_avg:136.66ms
step:181/1405 train_time:23367ms step_avg:136.65ms
step:182/1405 train_time:23505ms step_avg:136.66ms
step:183/1405 train_time:23643ms step_avg:136.66ms
step:184/1405 train_time:23782ms step_avg:136.68ms
step:185/1405 train_time:23920ms step_avg:136.68ms
step:186/1405 train_time:24058ms step_avg:136.70ms
step:187/1405 train_time:24198ms step_avg:136.71ms
step:188/1405 train_time:24334ms step_avg:136.71ms
step:189/1405 train_time:24471ms step_avg:136.71ms
step:190/1405 train_time:24611ms step_avg:136.73ms
step:191/1405 train_time:24783ms step_avg:136.92ms
step:192/1405 train_time:24919ms step_avg:136.92ms
step:193/1405 train_time:25056ms step_avg:136.92ms
step:194/1405 train_time:25193ms step_avg:136.92ms
step:195/1405 train_time:25329ms step_avg:136.92ms
step:196/1405 train_time:25465ms step_avg:136.91ms
step:197/1405 train_time:25602ms step_avg:136.91ms
step:198/1405 train_time:25745ms step_avg:136.94ms
step:199/1405 train_time:25885ms step_avg:136.96ms
step:200/1405 train_time:26022ms step_avg:136.96ms
step:201/1405 train_time:26160ms step_avg:136.96ms
step:202/1405 train_time:26300ms step_avg:136.98ms
step:203/1405 train_time:26437ms step_avg:136.98ms
step:204/1405 train_time:26575ms step_avg:136.98ms
step:205/1405 train_time:26714ms step_avg:137.00ms
step:206/1405 train_time:26854ms step_avg:137.01ms
step:207/1405 train_time:26993ms step_avg:137.02ms
step:208/1405 train_time:27129ms step_avg:137.02ms
step:209/1405 train_time:27266ms step_avg:137.01ms
step:210/1405 train_time:27403ms step_avg:137.02ms
step:211/1405 train_time:27542ms step_avg:137.03ms
step:212/1405 train_time:27681ms step_avg:137.03ms
step:213/1405 train_time:27821ms step_avg:137.05ms
step:214/1405 train_time:27962ms step_avg:137.07ms
step:215/1405 train_time:28100ms step_avg:137.07ms
step:216/1405 train_time:28239ms step_avg:137.08ms
step:217/1405 train_time:28378ms step_avg:137.09ms
step:218/1405 train_time:28516ms step_avg:137.10ms
step:219/1405 train_time:28656ms step_avg:137.11ms
step:220/1405 train_time:28796ms step_avg:137.12ms
step:221/1405 train_time:28935ms step_avg:137.13ms
step:222/1405 train_time:29073ms step_avg:137.14ms
step:223/1405 train_time:29211ms step_avg:137.14ms
step:224/1405 train_time:29351ms step_avg:137.15ms
step:225/1405 train_time:29488ms step_avg:137.15ms
step:226/1405 train_time:29627ms step_avg:137.16ms
step:227/1405 train_time:29768ms step_avg:137.18ms
step:228/1405 train_time:29906ms step_avg:137.18ms
step:229/1405 train_time:30045ms step_avg:137.19ms
step:230/1405 train_time:30184ms step_avg:137.20ms
step:231/1405 train_time:30323ms step_avg:137.21ms
step:232/1405 train_time:30462ms step_avg:137.22ms
step:233/1405 train_time:30601ms step_avg:137.22ms
step:234/1405 train_time:30741ms step_avg:137.23ms
step:235/1405 train_time:30881ms step_avg:137.25ms
step:236/1405 train_time:31022ms step_avg:137.27ms
step:237/1405 train_time:31161ms step_avg:137.27ms
step:238/1405 train_time:31301ms step_avg:137.28ms
step:239/1405 train_time:31439ms step_avg:137.29ms
step:240/1405 train_time:31578ms step_avg:137.30ms
step:241/1405 train_time:31716ms step_avg:137.30ms
step:242/1405 train_time:31855ms step_avg:137.31ms
step:243/1405 train_time:31995ms step_avg:137.32ms
step:244/1405 train_time:32134ms step_avg:137.32ms
step:245/1405 train_time:32273ms step_avg:137.33ms
step:246/1405 train_time:32411ms step_avg:137.34ms
step:247/1405 train_time:32550ms step_avg:137.34ms
step:248/1405 train_time:32688ms step_avg:137.35ms
step:249/1405 train_time:32827ms step_avg:137.35ms
step:250/1405 train_time:32967ms step_avg:137.36ms
step:250/1405 val_loss:3.9657 train_time:33034ms step_avg:137.64ms
step:251/1405 train_time:33108ms step_avg:137.38ms
step:252/1405 train_time:33250ms step_avg:137.39ms
step:253/1405 train_time:33391ms step_avg:137.41ms
step:254/1405 train_time:33530ms step_avg:137.42ms
step:255/1405 train_time:33667ms step_avg:137.42ms
step:256/1405 train_time:33804ms step_avg:137.41ms
step:257/1405 train_time:33942ms step_avg:137.42ms
step:258/1405 train_time:34084ms step_avg:137.44ms
step:259/1405 train_time:34224ms step_avg:137.45ms
step:260/1405 train_time:34365ms step_avg:137.46ms
step:261/1405 train_time:34503ms step_avg:137.46ms
step:262/1405 train_time:34643ms step_avg:137.47ms
step:263/1405 train_time:34783ms step_avg:137.48ms
step:264/1405 train_time:34921ms step_avg:137.48ms
step:265/1405 train_time:35060ms step_avg:137.49ms
step:266/1405 train_time:35199ms step_avg:137.50ms
step:267/1405 train_time:35340ms step_avg:137.51ms
step:268/1405 train_time:35481ms step_avg:137.52ms
step:269/1405 train_time:35621ms step_avg:137.53ms
step:270/1405 train_time:35760ms step_avg:137.54ms
step:271/1405 train_time:35899ms step_avg:137.54ms
step:272/1405 train_time:36038ms step_avg:137.55ms
step:273/1405 train_time:36177ms step_avg:137.56ms
step:274/1405 train_time:36318ms step_avg:137.57ms
step:275/1405 train_time:36458ms step_avg:137.58ms
step:276/1405 train_time:36597ms step_avg:137.58ms
step:277/1405 train_time:36736ms step_avg:137.59ms
step:278/1405 train_time:36876ms step_avg:137.60ms
step:279/1405 train_time:37016ms step_avg:137.61ms
step:280/1405 train_time:37154ms step_avg:137.61ms
step:281/1405 train_time:37294ms step_avg:137.62ms
step:282/1405 train_time:37435ms step_avg:137.63ms
step:283/1405 train_time:37574ms step_avg:137.63ms
step:284/1405 train_time:37714ms step_avg:137.64ms
step:285/1405 train_time:37852ms step_avg:137.64ms
step:286/1405 train_time:37992ms step_avg:137.65ms
step:287/1405 train_time:38132ms step_avg:137.66ms
step:288/1405 train_time:38271ms step_avg:137.67ms
step:289/1405 train_time:38412ms step_avg:137.68ms
step:290/1405 train_time:38552ms step_avg:137.68ms
step:291/1405 train_time:38692ms step_avg:137.69ms
step:292/1405 train_time:38831ms step_avg:137.70ms
step:293/1405 train_time:38971ms step_avg:137.71ms
step:294/1405 train_time:39110ms step_avg:137.71ms
step:295/1405 train_time:39248ms step_avg:137.71ms
step:296/1405 train_time:39388ms step_avg:137.72ms
step:297/1405 train_time:39528ms step_avg:137.73ms
step:298/1405 train_time:39667ms step_avg:137.73ms
step:299/1405 train_time:39806ms step_avg:137.74ms
step:300/1405 train_time:39945ms step_avg:137.74ms
step:301/1405 train_time:40086ms step_avg:137.75ms
step:302/1405 train_time:40223ms step_avg:137.75ms
step:303/1405 train_time:40361ms step_avg:137.75ms
step:304/1405 train_time:40500ms step_avg:137.76ms
step:305/1405 train_time:40641ms step_avg:137.77ms
step:306/1405 train_time:40781ms step_avg:137.77ms
step:307/1405 train_time:40923ms step_avg:137.79ms
step:308/1405 train_time:41062ms step_avg:137.79ms
step:309/1405 train_time:41201ms step_avg:137.79ms
step:310/1405 train_time:41340ms step_avg:137.80ms
step:311/1405 train_time:41479ms step_avg:137.80ms
step:312/1405 train_time:41617ms step_avg:137.81ms
step:313/1405 train_time:41757ms step_avg:137.81ms
step:314/1405 train_time:41897ms step_avg:137.82ms
step:315/1405 train_time:42041ms step_avg:137.84ms
step:316/1405 train_time:42184ms step_avg:137.86ms
step:317/1405 train_time:42326ms step_avg:137.87ms
step:318/1405 train_time:42468ms step_avg:137.88ms
step:319/1405 train_time:42608ms step_avg:137.89ms
step:320/1405 train_time:42749ms step_avg:137.90ms
step:321/1405 train_time:42893ms step_avg:137.92ms
step:322/1405 train_time:43036ms step_avg:137.94ms
step:323/1405 train_time:43178ms step_avg:137.95ms
step:324/1405 train_time:43319ms step_avg:137.96ms
step:325/1405 train_time:43461ms step_avg:137.97ms
step:326/1405 train_time:43603ms step_avg:137.98ms
step:327/1405 train_time:43744ms step_avg:137.99ms
step:328/1405 train_time:43886ms step_avg:138.01ms
step:329/1405 train_time:44028ms step_avg:138.02ms
step:330/1405 train_time:44169ms step_avg:138.03ms
step:331/1405 train_time:44310ms step_avg:138.04ms
step:332/1405 train_time:44453ms step_avg:138.05ms
step:333/1405 train_time:44595ms step_avg:138.07ms
step:334/1405 train_time:44737ms step_avg:138.08ms
step:335/1405 train_time:44880ms step_avg:138.09ms
step:336/1405 train_time:45022ms step_avg:138.10ms
step:337/1405 train_time:45165ms step_avg:138.12ms
step:338/1405 train_time:45307ms step_avg:138.13ms
step:339/1405 train_time:45448ms step_avg:138.14ms
step:340/1405 train_time:45591ms step_avg:138.16ms
step:341/1405 train_time:45734ms step_avg:138.17ms
step:342/1405 train_time:45876ms step_avg:138.18ms
step:343/1405 train_time:46016ms step_avg:138.19ms
step:344/1405 train_time:46159ms step_avg:138.20ms
step:345/1405 train_time:46301ms step_avg:138.21ms
step:346/1405 train_time:46442ms step_avg:138.22ms
step:347/1405 train_time:46584ms step_avg:138.23ms
step:348/1405 train_time:46726ms step_avg:138.24ms
step:349/1405 train_time:46868ms step_avg:138.25ms
step:350/1405 train_time:47009ms step_avg:138.26ms
step:351/1405 train_time:47151ms step_avg:138.27ms
step:352/1405 train_time:47292ms step_avg:138.28ms
step:353/1405 train_time:47435ms step_avg:138.29ms
step:354/1405 train_time:47577ms step_avg:138.30ms
step:355/1405 train_time:47720ms step_avg:138.32ms
step:356/1405 train_time:47861ms step_avg:138.33ms
step:357/1405 train_time:48002ms step_avg:138.34ms
step:358/1405 train_time:48145ms step_avg:138.35ms
step:359/1405 train_time:48288ms step_avg:138.36ms
step:360/1405 train_time:48431ms step_avg:138.37ms
step:361/1405 train_time:48571ms step_avg:138.38ms
step:362/1405 train_time:48712ms step_avg:138.39ms
step:363/1405 train_time:48854ms step_avg:138.40ms
step:364/1405 train_time:48997ms step_avg:138.41ms
step:365/1405 train_time:49140ms step_avg:138.42ms
step:366/1405 train_time:49282ms step_avg:138.43ms
step:367/1405 train_time:49423ms step_avg:138.44ms
step:368/1405 train_time:49565ms step_avg:138.45ms
step:369/1405 train_time:49708ms step_avg:138.46ms
step:370/1405 train_time:49849ms step_avg:138.47ms
step:371/1405 train_time:49991ms step_avg:138.48ms
step:372/1405 train_time:50134ms step_avg:138.49ms
step:373/1405 train_time:50277ms step_avg:138.50ms
step:374/1405 train_time:50419ms step_avg:138.51ms
step:375/1405 train_time:50561ms step_avg:138.52ms
step:375/1405 val_loss:3.7790 train_time:50629ms step_avg:138.71ms
step:376/1405 train_time:50703ms step_avg:138.53ms
step:377/1405 train_time:50849ms step_avg:138.55ms
step:378/1405 train_time:50991ms step_avg:138.56ms
step:379/1405 train_time:51132ms step_avg:138.57ms
step:380/1405 train_time:51273ms step_avg:138.58ms
step:381/1405 train_time:51454ms step_avg:138.69ms
step:382/1405 train_time:51594ms step_avg:138.69ms
step:383/1405 train_time:51734ms step_avg:138.70ms
step:384/1405 train_time:51874ms step_avg:138.70ms
step:385/1405 train_time:52014ms step_avg:138.71ms
step:386/1405 train_time:52155ms step_avg:138.71ms
step:387/1405 train_time:52299ms step_avg:138.73ms
step:388/1405 train_time:52444ms step_avg:138.74ms
step:389/1405 train_time:52586ms step_avg:138.75ms
step:390/1405 train_time:52729ms step_avg:138.76ms
step:391/1405 train_time:52870ms step_avg:138.77ms
step:392/1405 train_time:53010ms step_avg:138.77ms
step:393/1405 train_time:53152ms step_avg:138.78ms
step:394/1405 train_time:53295ms step_avg:138.79ms
step:395/1405 train_time:53437ms step_avg:138.80ms
step:396/1405 train_time:53580ms step_avg:138.81ms
step:397/1405 train_time:53724ms step_avg:138.82ms
step:398/1405 train_time:53866ms step_avg:138.83ms
step:399/1405 train_time:54008ms step_avg:138.84ms
step:400/1405 train_time:54150ms step_avg:138.85ms
step:401/1405 train_time:54292ms step_avg:138.85ms
step:402/1405 train_time:54434ms step_avg:138.86ms
step:403/1405 train_time:54576ms step_avg:138.87ms
step:404/1405 train_time:54719ms step_avg:138.88ms
step:405/1405 train_time:54861ms step_avg:138.89ms
step:406/1405 train_time:55004ms step_avg:138.90ms
step:407/1405 train_time:55147ms step_avg:138.91ms
step:408/1405 train_time:55290ms step_avg:138.92ms
step:409/1405 train_time:55432ms step_avg:138.93ms
step:410/1405 train_time:55572ms step_avg:138.93ms
step:411/1405 train_time:55714ms step_avg:138.94ms
step:412/1405 train_time:55856ms step_avg:138.95ms
step:413/1405 train_time:56000ms step_avg:138.96ms
step:414/1405 train_time:56142ms step_avg:138.96ms
step:415/1405 train_time:56284ms step_avg:138.97ms
step:416/1405 train_time:56426ms step_avg:138.98ms
step:417/1405 train_time:56568ms step_avg:138.99ms
step:418/1405 train_time:56711ms step_avg:139.00ms
step:419/1405 train_time:56853ms step_avg:139.00ms
step:420/1405 train_time:56996ms step_avg:139.02ms
step:421/1405 train_time:57139ms step_avg:139.02ms
step:422/1405 train_time:57281ms step_avg:139.03ms
step:423/1405 train_time:57424ms step_avg:139.04ms
step:424/1405 train_time:57569ms step_avg:139.06ms
step:425/1405 train_time:57712ms step_avg:139.06ms
step:426/1405 train_time:57854ms step_avg:139.07ms
step:427/1405 train_time:57998ms step_avg:139.08ms
step:428/1405 train_time:58140ms step_avg:139.09ms
step:429/1405 train_time:58282ms step_avg:139.10ms
step:430/1405 train_time:58425ms step_avg:139.11ms
step:431/1405 train_time:58569ms step_avg:139.12ms
step:432/1405 train_time:58711ms step_avg:139.12ms
step:433/1405 train_time:58854ms step_avg:139.13ms
step:434/1405 train_time:58998ms step_avg:139.15ms
step:435/1405 train_time:59140ms step_avg:139.15ms
step:436/1405 train_time:59283ms step_avg:139.16ms
step:437/1405 train_time:59426ms step_avg:139.17ms
step:438/1405 train_time:59569ms step_avg:139.18ms
step:439/1405 train_time:59712ms step_avg:139.19ms
step:440/1405 train_time:59854ms step_avg:139.20ms
step:441/1405 train_time:59998ms step_avg:139.21ms
step:442/1405 train_time:60139ms step_avg:139.21ms
step:443/1405 train_time:60281ms step_avg:139.22ms
step:444/1405 train_time:60424ms step_avg:139.23ms
step:445/1405 train_time:60568ms step_avg:139.24ms
step:446/1405 train_time:60712ms step_avg:139.25ms
step:447/1405 train_time:60854ms step_avg:139.25ms
step:448/1405 train_time:60996ms step_avg:139.26ms
step:449/1405 train_time:61139ms step_avg:139.27ms
step:450/1405 train_time:61281ms step_avg:139.28ms
step:451/1405 train_time:61425ms step_avg:139.29ms
step:452/1405 train_time:61569ms step_avg:139.30ms
step:453/1405 train_time:61712ms step_avg:139.30ms
step:454/1405 train_time:61855ms step_avg:139.31ms
step:455/1405 train_time:62000ms step_avg:139.32ms
step:456/1405 train_time:62143ms step_avg:139.34ms
step:457/1405 train_time:62287ms step_avg:139.34ms
step:458/1405 train_time:62429ms step_avg:139.35ms
step:459/1405 train_time:62574ms step_avg:139.36ms
step:460/1405 train_time:62717ms step_avg:139.37ms
step:461/1405 train_time:62858ms step_avg:139.38ms
step:462/1405 train_time:63002ms step_avg:139.39ms
step:463/1405 train_time:63146ms step_avg:139.39ms
step:464/1405 train_time:63288ms step_avg:139.40ms
step:465/1405 train_time:63430ms step_avg:139.41ms
step:466/1405 train_time:63573ms step_avg:139.41ms
step:467/1405 train_time:63717ms step_avg:139.42ms
step:468/1405 train_time:63859ms step_avg:139.43ms
step:469/1405 train_time:64002ms step_avg:139.44ms
step:470/1405 train_time:64146ms step_avg:139.45ms
step:471/1405 train_time:64290ms step_avg:139.46ms
step:472/1405 train_time:64432ms step_avg:139.46ms
step:473/1405 train_time:64574ms step_avg:139.47ms
step:474/1405 train_time:64717ms step_avg:139.48ms
step:475/1405 train_time:64860ms step_avg:139.48ms
step:476/1405 train_time:65004ms step_avg:139.49ms
step:477/1405 train_time:65148ms step_avg:139.50ms
step:478/1405 train_time:65291ms step_avg:139.51ms
step:479/1405 train_time:65434ms step_avg:139.52ms
step:480/1405 train_time:65575ms step_avg:139.52ms
step:481/1405 train_time:65720ms step_avg:139.53ms
step:482/1405 train_time:65862ms step_avg:139.54ms
step:483/1405 train_time:66007ms step_avg:139.55ms
step:484/1405 train_time:66150ms step_avg:139.56ms
step:485/1405 train_time:66292ms step_avg:139.56ms
step:486/1405 train_time:66434ms step_avg:139.57ms
step:487/1405 train_time:66577ms step_avg:139.57ms
step:488/1405 train_time:66720ms step_avg:139.58ms
step:489/1405 train_time:66863ms step_avg:139.59ms
step:490/1405 train_time:67009ms step_avg:139.60ms
step:491/1405 train_time:67153ms step_avg:139.61ms
step:492/1405 train_time:67295ms step_avg:139.62ms
step:493/1405 train_time:67438ms step_avg:139.62ms
step:494/1405 train_time:67579ms step_avg:139.63ms
step:495/1405 train_time:67722ms step_avg:139.63ms
step:496/1405 train_time:67865ms step_avg:139.64ms
step:497/1405 train_time:68009ms step_avg:139.65ms
step:498/1405 train_time:68153ms step_avg:139.66ms
step:499/1405 train_time:68295ms step_avg:139.66ms
step:500/1405 train_time:68439ms step_avg:139.67ms
step:500/1405 val_loss:3.6605 train_time:68505ms step_avg:139.81ms
step:501/1405 train_time:68579ms step_avg:139.67ms
step:502/1405 train_time:68725ms step_avg:139.69ms
step:503/1405 train_time:68870ms step_avg:139.70ms
step:504/1405 train_time:69012ms step_avg:139.70ms
step:505/1405 train_time:69156ms step_avg:139.71ms
step:506/1405 train_time:69298ms step_avg:139.71ms
step:507/1405 train_time:69442ms step_avg:139.72ms
step:508/1405 train_time:69585ms step_avg:139.73ms
step:509/1405 train_time:69729ms step_avg:139.74ms
step:510/1405 train_time:69871ms step_avg:139.74ms
step:511/1405 train_time:70015ms step_avg:139.75ms
step:512/1405 train_time:70159ms step_avg:139.76ms
step:513/1405 train_time:70302ms step_avg:139.76ms
step:514/1405 train_time:70443ms step_avg:139.77ms
step:515/1405 train_time:70585ms step_avg:139.77ms
step:516/1405 train_time:70730ms step_avg:139.78ms
step:517/1405 train_time:70872ms step_avg:139.79ms
step:518/1405 train_time:71016ms step_avg:139.80ms
step:519/1405 train_time:71161ms step_avg:139.80ms
step:520/1405 train_time:71304ms step_avg:139.81ms
step:521/1405 train_time:71446ms step_avg:139.82ms
step:522/1405 train_time:71589ms step_avg:139.82ms
step:523/1405 train_time:71734ms step_avg:139.83ms
step:524/1405 train_time:71880ms step_avg:139.84ms
step:525/1405 train_time:72027ms step_avg:139.86ms
step:526/1405 train_time:72172ms step_avg:139.87ms
step:527/1405 train_time:72317ms step_avg:139.88ms
step:528/1405 train_time:72461ms step_avg:139.89ms
step:529/1405 train_time:72606ms step_avg:139.90ms
step:530/1405 train_time:72752ms step_avg:139.91ms
step:531/1405 train_time:72896ms step_avg:139.92ms
step:532/1405 train_time:73043ms step_avg:139.93ms
step:533/1405 train_time:73189ms step_avg:139.94ms
step:534/1405 train_time:73333ms step_avg:139.95ms
step:535/1405 train_time:73478ms step_avg:139.96ms
step:536/1405 train_time:73623ms step_avg:139.97ms
step:537/1405 train_time:73768ms step_avg:139.98ms
step:538/1405 train_time:73913ms step_avg:139.99ms
step:539/1405 train_time:74060ms step_avg:140.00ms
step:540/1405 train_time:74205ms step_avg:140.01ms
step:541/1405 train_time:74350ms step_avg:140.02ms
step:542/1405 train_time:74494ms step_avg:140.03ms
step:543/1405 train_time:74639ms step_avg:140.04ms
step:544/1405 train_time:74785ms step_avg:140.05ms
step:545/1405 train_time:74930ms step_avg:140.06ms
step:546/1405 train_time:75074ms step_avg:140.06ms
step:547/1405 train_time:75220ms step_avg:140.07ms
step:548/1405 train_time:75366ms step_avg:140.09ms
step:549/1405 train_time:75512ms step_avg:140.10ms
step:550/1405 train_time:75655ms step_avg:140.10ms
step:551/1405 train_time:75801ms step_avg:140.11ms
step:552/1405 train_time:75948ms step_avg:140.12ms
step:553/1405 train_time:76092ms step_avg:140.13ms
step:554/1405 train_time:76236ms step_avg:140.14ms
step:555/1405 train_time:76382ms step_avg:140.15ms
step:556/1405 train_time:76526ms step_avg:140.16ms
step:557/1405 train_time:76670ms step_avg:140.17ms
step:558/1405 train_time:76815ms step_avg:140.17ms
step:559/1405 train_time:76961ms step_avg:140.18ms
step:560/1405 train_time:77107ms step_avg:140.19ms
step:561/1405 train_time:77252ms step_avg:140.20ms
step:562/1405 train_time:77397ms step_avg:140.21ms
step:563/1405 train_time:77542ms step_avg:140.22ms
step:564/1405 train_time:77688ms step_avg:140.23ms
step:565/1405 train_time:77832ms step_avg:140.24ms
step:566/1405 train_time:77977ms step_avg:140.25ms
step:567/1405 train_time:78124ms step_avg:140.26ms
step:568/1405 train_time:78269ms step_avg:140.27ms
step:569/1405 train_time:78413ms step_avg:140.27ms
step:570/1405 train_time:78558ms step_avg:140.28ms
step:571/1405 train_time:78743ms step_avg:140.36ms
step:572/1405 train_time:78885ms step_avg:140.37ms
step:573/1405 train_time:79028ms step_avg:140.37ms
step:574/1405 train_time:79174ms step_avg:140.38ms
step:575/1405 train_time:79317ms step_avg:140.38ms
step:576/1405 train_time:79462ms step_avg:140.39ms
step:577/1405 train_time:79608ms step_avg:140.40ms
step:578/1405 train_time:79753ms step_avg:140.41ms
step:579/1405 train_time:79898ms step_avg:140.42ms
step:580/1405 train_time:80043ms step_avg:140.43ms
step:581/1405 train_time:80188ms step_avg:140.44ms
step:582/1405 train_time:80333ms step_avg:140.44ms
step:583/1405 train_time:80479ms step_avg:140.45ms
step:584/1405 train_time:80624ms step_avg:140.46ms
step:585/1405 train_time:80770ms step_avg:140.47ms
step:586/1405 train_time:80916ms step_avg:140.48ms
step:587/1405 train_time:81061ms step_avg:140.49ms
step:588/1405 train_time:81207ms step_avg:140.50ms
step:589/1405 train_time:81353ms step_avg:140.51ms
step:590/1405 train_time:81499ms step_avg:140.52ms
step:591/1405 train_time:81644ms step_avg:140.52ms
step:592/1405 train_time:81790ms step_avg:140.53ms
step:593/1405 train_time:81935ms step_avg:140.54ms
step:594/1405 train_time:82080ms step_avg:140.55ms
step:595/1405 train_time:82226ms step_avg:140.56ms
step:596/1405 train_time:82370ms step_avg:140.56ms
step:597/1405 train_time:82514ms step_avg:140.57ms
step:598/1405 train_time:82659ms step_avg:140.58ms
step:599/1405 train_time:82805ms step_avg:140.59ms
step:600/1405 train_time:82951ms step_avg:140.59ms
step:601/1405 train_time:83096ms step_avg:140.60ms
step:602/1405 train_time:83242ms step_avg:140.61ms
step:603/1405 train_time:83388ms step_avg:140.62ms
step:604/1405 train_time:83532ms step_avg:140.63ms
step:605/1405 train_time:83678ms step_avg:140.64ms
step:606/1405 train_time:83825ms step_avg:140.65ms
step:607/1405 train_time:83970ms step_avg:140.65ms
step:608/1405 train_time:84117ms step_avg:140.66ms
step:609/1405 train_time:84262ms step_avg:140.67ms
step:610/1405 train_time:84408ms step_avg:140.68ms
step:611/1405 train_time:84552ms step_avg:140.69ms
step:612/1405 train_time:84697ms step_avg:140.69ms
step:613/1405 train_time:84843ms step_avg:140.70ms
step:614/1405 train_time:84987ms step_avg:140.71ms
step:615/1405 train_time:85133ms step_avg:140.72ms
step:616/1405 train_time:85278ms step_avg:140.72ms
step:617/1405 train_time:85423ms step_avg:140.73ms
step:618/1405 train_time:85569ms step_avg:140.74ms
step:619/1405 train_time:85714ms step_avg:140.75ms
step:620/1405 train_time:85861ms step_avg:140.76ms
step:621/1405 train_time:86007ms step_avg:140.76ms
step:622/1405 train_time:86151ms step_avg:140.77ms
step:623/1405 train_time:86299ms step_avg:140.78ms
step:624/1405 train_time:86444ms step_avg:140.79ms
step:625/1405 train_time:86589ms step_avg:140.79ms
step:625/1405 val_loss:3.5805 train_time:86659ms step_avg:140.91ms
step:626/1405 train_time:86736ms step_avg:140.81ms
step:627/1405 train_time:86880ms step_avg:140.81ms
step:628/1405 train_time:87026ms step_avg:140.82ms
step:629/1405 train_time:87172ms step_avg:140.83ms
step:630/1405 train_time:87316ms step_avg:140.83ms
step:631/1405 train_time:87460ms step_avg:140.84ms
step:632/1405 train_time:87606ms step_avg:140.85ms
step:633/1405 train_time:87756ms step_avg:140.86ms
step:634/1405 train_time:87902ms step_avg:140.87ms
step:635/1405 train_time:88048ms step_avg:140.88ms
step:636/1405 train_time:88195ms step_avg:140.89ms
step:637/1405 train_time:88340ms step_avg:140.89ms
step:638/1405 train_time:88484ms step_avg:140.90ms
step:639/1405 train_time:88633ms step_avg:140.91ms
step:640/1405 train_time:88780ms step_avg:140.92ms
step:641/1405 train_time:88925ms step_avg:140.93ms
step:642/1405 train_time:89073ms step_avg:140.94ms
step:643/1405 train_time:89217ms step_avg:140.94ms
step:644/1405 train_time:89362ms step_avg:140.95ms
step:645/1405 train_time:89509ms step_avg:140.96ms
step:646/1405 train_time:89656ms step_avg:140.97ms
step:647/1405 train_time:89801ms step_avg:140.98ms
step:648/1405 train_time:89950ms step_avg:140.99ms
step:649/1405 train_time:90096ms step_avg:141.00ms
step:650/1405 train_time:90241ms step_avg:141.00ms
step:651/1405 train_time:90385ms step_avg:141.01ms
step:652/1405 train_time:90532ms step_avg:141.02ms
step:653/1405 train_time:90679ms step_avg:141.02ms
step:654/1405 train_time:90824ms step_avg:141.03ms
step:655/1405 train_time:90971ms step_avg:141.04ms
step:656/1405 train_time:91116ms step_avg:141.05ms
step:657/1405 train_time:91261ms step_avg:141.05ms
step:658/1405 train_time:91407ms step_avg:141.06ms
step:659/1405 train_time:91554ms step_avg:141.07ms
step:660/1405 train_time:91700ms step_avg:141.08ms
step:661/1405 train_time:91848ms step_avg:141.09ms
step:662/1405 train_time:91994ms step_avg:141.09ms
step:663/1405 train_time:92138ms step_avg:141.10ms
step:664/1405 train_time:92284ms step_avg:141.11ms
step:665/1405 train_time:92430ms step_avg:141.12ms
step:666/1405 train_time:92575ms step_avg:141.12ms
step:667/1405 train_time:92721ms step_avg:141.13ms
step:668/1405 train_time:92870ms step_avg:141.14ms
step:669/1405 train_time:93016ms step_avg:141.15ms
step:670/1405 train_time:93162ms step_avg:141.15ms
step:671/1405 train_time:93308ms step_avg:141.16ms
step:672/1405 train_time:93453ms step_avg:141.17ms
step:673/1405 train_time:93599ms step_avg:141.18ms
step:674/1405 train_time:93744ms step_avg:141.18ms
step:675/1405 train_time:93893ms step_avg:141.19ms
step:676/1405 train_time:94041ms step_avg:141.20ms
step:677/1405 train_time:94187ms step_avg:141.21ms
step:678/1405 train_time:94334ms step_avg:141.22ms
step:679/1405 train_time:94480ms step_avg:141.23ms
step:680/1405 train_time:94625ms step_avg:141.23ms
step:681/1405 train_time:94771ms step_avg:141.24ms
step:682/1405 train_time:94918ms step_avg:141.25ms
step:683/1405 train_time:95063ms step_avg:141.25ms
step:684/1405 train_time:95210ms step_avg:141.26ms
step:685/1405 train_time:95356ms step_avg:141.27ms
step:686/1405 train_time:95501ms step_avg:141.27ms
step:687/1405 train_time:95648ms step_avg:141.28ms
step:688/1405 train_time:95795ms step_avg:141.29ms
step:689/1405 train_time:95941ms step_avg:141.30ms
step:690/1405 train_time:96088ms step_avg:141.31ms
step:691/1405 train_time:96234ms step_avg:141.31ms
step:692/1405 train_time:96379ms step_avg:141.32ms
step:693/1405 train_time:96523ms step_avg:141.32ms
step:694/1405 train_time:96669ms step_avg:141.33ms
step:695/1405 train_time:96815ms step_avg:141.34ms
step:696/1405 train_time:96961ms step_avg:141.34ms
step:697/1405 train_time:97107ms step_avg:141.35ms
step:698/1405 train_time:97254ms step_avg:141.36ms
step:699/1405 train_time:97401ms step_avg:141.37ms
step:700/1405 train_time:97548ms step_avg:141.37ms
step:701/1405 train_time:97694ms step_avg:141.38ms
step:702/1405 train_time:97840ms step_avg:141.39ms
step:703/1405 train_time:97985ms step_avg:141.39ms
step:704/1405 train_time:98133ms step_avg:141.40ms
step:705/1405 train_time:98280ms step_avg:141.41ms
step:706/1405 train_time:98428ms step_avg:141.42ms
step:707/1405 train_time:98576ms step_avg:141.43ms
step:708/1405 train_time:98722ms step_avg:141.43ms
step:709/1405 train_time:98867ms step_avg:141.44ms
step:710/1405 train_time:99014ms step_avg:141.45ms
step:711/1405 train_time:99160ms step_avg:141.46ms
step:712/1405 train_time:99308ms step_avg:141.46ms
step:713/1405 train_time:99456ms step_avg:141.47ms
step:714/1405 train_time:99601ms step_avg:141.48ms
step:715/1405 train_time:99747ms step_avg:141.49ms
step:716/1405 train_time:99894ms step_avg:141.49ms
step:717/1405 train_time:100040ms step_avg:141.50ms
step:718/1405 train_time:100186ms step_avg:141.51ms
step:719/1405 train_time:100332ms step_avg:141.51ms
step:720/1405 train_time:100478ms step_avg:141.52ms
step:721/1405 train_time:100624ms step_avg:141.52ms
step:722/1405 train_time:100772ms step_avg:141.53ms
step:723/1405 train_time:100919ms step_avg:141.54ms
step:724/1405 train_time:101063ms step_avg:141.54ms
step:725/1405 train_time:101210ms step_avg:141.55ms
step:726/1405 train_time:101355ms step_avg:141.56ms
step:727/1405 train_time:101502ms step_avg:141.56ms
step:728/1405 train_time:101649ms step_avg:141.57ms
step:729/1405 train_time:101796ms step_avg:141.58ms
step:730/1405 train_time:101941ms step_avg:141.59ms
step:731/1405 train_time:102089ms step_avg:141.59ms
step:732/1405 train_time:102236ms step_avg:141.60ms
step:733/1405 train_time:102383ms step_avg:141.61ms
step:734/1405 train_time:102531ms step_avg:141.62ms
step:735/1405 train_time:102679ms step_avg:141.63ms
step:736/1405 train_time:102825ms step_avg:141.63ms
step:737/1405 train_time:102974ms step_avg:141.64ms
step:738/1405 train_time:103121ms step_avg:141.65ms
step:739/1405 train_time:103271ms step_avg:141.66ms
step:740/1405 train_time:103419ms step_avg:141.67ms
step:741/1405 train_time:103565ms step_avg:141.68ms
step:742/1405 train_time:103713ms step_avg:141.68ms
step:743/1405 train_time:103860ms step_avg:141.69ms
step:744/1405 train_time:104007ms step_avg:141.70ms
step:745/1405 train_time:104156ms step_avg:141.71ms
step:746/1405 train_time:104303ms step_avg:141.72ms
step:747/1405 train_time:104452ms step_avg:141.73ms
step:748/1405 train_time:104600ms step_avg:141.73ms
step:749/1405 train_time:104748ms step_avg:141.74ms
step:750/1405 train_time:104895ms step_avg:141.75ms
step:750/1405 val_loss:3.5250 train_time:104966ms step_avg:141.85ms
step:751/1405 train_time:105042ms step_avg:141.76ms
step:752/1405 train_time:105193ms step_avg:141.77ms
step:753/1405 train_time:105340ms step_avg:141.78ms
step:754/1405 train_time:105486ms step_avg:141.78ms
step:755/1405 train_time:105633ms step_avg:141.79ms
step:756/1405 train_time:105781ms step_avg:141.80ms
step:757/1405 train_time:105929ms step_avg:141.81ms
step:758/1405 train_time:106079ms step_avg:141.82ms
step:759/1405 train_time:106225ms step_avg:141.82ms
step:760/1405 train_time:106373ms step_avg:141.83ms
step:761/1405 train_time:106561ms step_avg:141.89ms
step:762/1405 train_time:106706ms step_avg:141.90ms
step:763/1405 train_time:106852ms step_avg:141.90ms
step:764/1405 train_time:107000ms step_avg:141.91ms
step:765/1405 train_time:107145ms step_avg:141.91ms
step:766/1405 train_time:107295ms step_avg:141.92ms
step:767/1405 train_time:107442ms step_avg:141.93ms
step:768/1405 train_time:107592ms step_avg:141.94ms
step:769/1405 train_time:107741ms step_avg:141.95ms
step:770/1405 train_time:107887ms step_avg:141.96ms
step:771/1405 train_time:108035ms step_avg:141.96ms
step:772/1405 train_time:108182ms step_avg:141.97ms
step:773/1405 train_time:108329ms step_avg:141.98ms
step:774/1405 train_time:108478ms step_avg:141.99ms
step:775/1405 train_time:108627ms step_avg:142.00ms
step:776/1405 train_time:108777ms step_avg:142.01ms
step:777/1405 train_time:108924ms step_avg:142.01ms
step:778/1405 train_time:109070ms step_avg:142.02ms
step:779/1405 train_time:109217ms step_avg:142.02ms
step:780/1405 train_time:109365ms step_avg:142.03ms
step:781/1405 train_time:109514ms step_avg:142.04ms
step:782/1405 train_time:109662ms step_avg:142.05ms
step:783/1405 train_time:109810ms step_avg:142.06ms
step:784/1405 train_time:109958ms step_avg:142.06ms
step:785/1405 train_time:110105ms step_avg:142.07ms
step:786/1405 train_time:110254ms step_avg:142.08ms
step:787/1405 train_time:110402ms step_avg:142.09ms
step:788/1405 train_time:110548ms step_avg:142.09ms
step:789/1405 train_time:110696ms step_avg:142.10ms
step:790/1405 train_time:110842ms step_avg:142.11ms
step:791/1405 train_time:110991ms step_avg:142.11ms
step:792/1405 train_time:111139ms step_avg:142.12ms
step:793/1405 train_time:111286ms step_avg:142.13ms
step:794/1405 train_time:111435ms step_avg:142.14ms
step:795/1405 train_time:111583ms step_avg:142.14ms
step:796/1405 train_time:111729ms step_avg:142.15ms
step:797/1405 train_time:111877ms step_avg:142.16ms
step:798/1405 train_time:112026ms step_avg:142.17ms
step:799/1405 train_time:112177ms step_avg:142.18ms
step:800/1405 train_time:112324ms step_avg:142.18ms
step:801/1405 train_time:112470ms step_avg:142.19ms
step:802/1405 train_time:112618ms step_avg:142.19ms
step:803/1405 train_time:112764ms step_avg:142.20ms
step:804/1405 train_time:112911ms step_avg:142.21ms
step:805/1405 train_time:113061ms step_avg:142.22ms
step:806/1405 train_time:113209ms step_avg:142.22ms
step:807/1405 train_time:113358ms step_avg:142.23ms
step:808/1405 train_time:113504ms step_avg:142.24ms
step:809/1405 train_time:113651ms step_avg:142.24ms
step:810/1405 train_time:113799ms step_avg:142.25ms
step:811/1405 train_time:113945ms step_avg:142.25ms
step:812/1405 train_time:114094ms step_avg:142.26ms
step:813/1405 train_time:114241ms step_avg:142.27ms
step:814/1405 train_time:114389ms step_avg:142.28ms
step:815/1405 train_time:114537ms step_avg:142.28ms
step:816/1405 train_time:114683ms step_avg:142.29ms
step:817/1405 train_time:114830ms step_avg:142.29ms
step:818/1405 train_time:114978ms step_avg:142.30ms
step:819/1405 train_time:115125ms step_avg:142.31ms
step:820/1405 train_time:115275ms step_avg:142.31ms
step:821/1405 train_time:115423ms step_avg:142.32ms
step:822/1405 train_time:115569ms step_avg:142.33ms
step:823/1405 train_time:115719ms step_avg:142.34ms
step:824/1405 train_time:115864ms step_avg:142.34ms
step:825/1405 train_time:116012ms step_avg:142.35ms
step:826/1405 train_time:116161ms step_avg:142.35ms
step:827/1405 train_time:116307ms step_avg:142.36ms
step:828/1405 train_time:116458ms step_avg:142.37ms
step:829/1405 train_time:116604ms step_avg:142.37ms
step:830/1405 train_time:116751ms step_avg:142.38ms
step:831/1405 train_time:116899ms step_avg:142.39ms
step:832/1405 train_time:117045ms step_avg:142.39ms
step:833/1405 train_time:117194ms step_avg:142.40ms
step:834/1405 train_time:117342ms step_avg:142.41ms
step:835/1405 train_time:117492ms step_avg:142.41ms
step:836/1405 train_time:117640ms step_avg:142.42ms
step:837/1405 train_time:117786ms step_avg:142.43ms
step:838/1405 train_time:117936ms step_avg:142.43ms
step:839/1405 train_time:118083ms step_avg:142.44ms
step:840/1405 train_time:118229ms step_avg:142.44ms
step:841/1405 train_time:118377ms step_avg:142.45ms
step:842/1405 train_time:118525ms step_avg:142.46ms
step:843/1405 train_time:118674ms step_avg:142.47ms
step:844/1405 train_time:118823ms step_avg:142.47ms
step:845/1405 train_time:118970ms step_avg:142.48ms
step:846/1405 train_time:119119ms step_avg:142.49ms
step:847/1405 train_time:119265ms step_avg:142.49ms
step:848/1405 train_time:119414ms step_avg:142.50ms
step:849/1405 train_time:119562ms step_avg:142.51ms
step:850/1405 train_time:119711ms step_avg:142.51ms
step:851/1405 train_time:119860ms step_avg:142.52ms
step:852/1405 train_time:120007ms step_avg:142.53ms
step:853/1405 train_time:120158ms step_avg:142.54ms
step:854/1405 train_time:120304ms step_avg:142.54ms
step:855/1405 train_time:120452ms step_avg:142.55ms
step:856/1405 train_time:120600ms step_avg:142.55ms
step:857/1405 train_time:120748ms step_avg:142.56ms
step:858/1405 train_time:120899ms step_avg:142.57ms
step:859/1405 train_time:121047ms step_avg:142.58ms
step:860/1405 train_time:121198ms step_avg:142.59ms
step:861/1405 train_time:121344ms step_avg:142.59ms
step:862/1405 train_time:121492ms step_avg:142.60ms
step:863/1405 train_time:121639ms step_avg:142.60ms
step:864/1405 train_time:121788ms step_avg:142.61ms
step:865/1405 train_time:121938ms step_avg:142.62ms
step:866/1405 train_time:122088ms step_avg:142.63ms
step:867/1405 train_time:122238ms step_avg:142.63ms
step:868/1405 train_time:122384ms step_avg:142.64ms
step:869/1405 train_time:122533ms step_avg:142.65ms
step:870/1405 train_time:122683ms step_avg:142.65ms
step:871/1405 train_time:122829ms step_avg:142.66ms
step:872/1405 train_time:122978ms step_avg:142.67ms
step:873/1405 train_time:123126ms step_avg:142.67ms
step:874/1405 train_time:123276ms step_avg:142.68ms
step:875/1405 train_time:123423ms step_avg:142.69ms
step:875/1405 val_loss:3.4761 train_time:123496ms step_avg:142.77ms
step:876/1405 train_time:123572ms step_avg:142.69ms
step:877/1405 train_time:123719ms step_avg:142.70ms
step:878/1405 train_time:123868ms step_avg:142.71ms
step:879/1405 train_time:124015ms step_avg:142.71ms
step:880/1405 train_time:124162ms step_avg:142.72ms
step:881/1405 train_time:124310ms step_avg:142.72ms
step:882/1405 train_time:124460ms step_avg:142.73ms
step:883/1405 train_time:124611ms step_avg:142.74ms
step:884/1405 train_time:124758ms step_avg:142.74ms
step:885/1405 train_time:124908ms step_avg:142.75ms
step:886/1405 train_time:125056ms step_avg:142.76ms
step:887/1405 train_time:125204ms step_avg:142.76ms
step:888/1405 train_time:125352ms step_avg:142.77ms
step:889/1405 train_time:125502ms step_avg:142.78ms
step:890/1405 train_time:125649ms step_avg:142.78ms
step:891/1405 train_time:125798ms step_avg:142.79ms
step:892/1405 train_time:125947ms step_avg:142.80ms
step:893/1405 train_time:126094ms step_avg:142.80ms
step:894/1405 train_time:126241ms step_avg:142.81ms
step:895/1405 train_time:126391ms step_avg:142.81ms
step:896/1405 train_time:126537ms step_avg:142.82ms
step:897/1405 train_time:126687ms step_avg:142.83ms
step:898/1405 train_time:126834ms step_avg:142.83ms
step:899/1405 train_time:126983ms step_avg:142.84ms
step:900/1405 train_time:127131ms step_avg:142.84ms
step:901/1405 train_time:127279ms step_avg:142.85ms
step:902/1405 train_time:127426ms step_avg:142.85ms
step:903/1405 train_time:127575ms step_avg:142.86ms
step:904/1405 train_time:127724ms step_avg:142.87ms
step:905/1405 train_time:127873ms step_avg:142.87ms
step:906/1405 train_time:128021ms step_avg:142.88ms
step:907/1405 train_time:128172ms step_avg:142.89ms
step:908/1405 train_time:128318ms step_avg:142.89ms
step:909/1405 train_time:128470ms step_avg:142.90ms
step:910/1405 train_time:128620ms step_avg:142.91ms
step:911/1405 train_time:128769ms step_avg:142.92ms
step:912/1405 train_time:128916ms step_avg:142.92ms
step:913/1405 train_time:129067ms step_avg:142.93ms
step:914/1405 train_time:129213ms step_avg:142.93ms
step:915/1405 train_time:129360ms step_avg:142.94ms
step:916/1405 train_time:129509ms step_avg:142.95ms
step:917/1405 train_time:129658ms step_avg:142.95ms
step:918/1405 train_time:129807ms step_avg:142.96ms
step:919/1405 train_time:129956ms step_avg:142.97ms
step:920/1405 train_time:130103ms step_avg:142.97ms
step:921/1405 train_time:130252ms step_avg:142.98ms
step:922/1405 train_time:130400ms step_avg:142.98ms
step:923/1405 train_time:130548ms step_avg:142.99ms
step:924/1405 train_time:130696ms step_avg:142.99ms
step:925/1405 train_time:130845ms step_avg:143.00ms
step:926/1405 train_time:130995ms step_avg:143.01ms
step:927/1405 train_time:131144ms step_avg:143.01ms
step:928/1405 train_time:131293ms step_avg:143.02ms
step:929/1405 train_time:131440ms step_avg:143.03ms
step:930/1405 train_time:131591ms step_avg:143.03ms
step:931/1405 train_time:131736ms step_avg:143.04ms
step:932/1405 train_time:131885ms step_avg:143.04ms
step:933/1405 train_time:132033ms step_avg:143.05ms
step:934/1405 train_time:132181ms step_avg:143.05ms
step:935/1405 train_time:132330ms step_avg:143.06ms
step:936/1405 train_time:132478ms step_avg:143.06ms
step:937/1405 train_time:132629ms step_avg:143.07ms
step:938/1405 train_time:132775ms step_avg:143.08ms
step:939/1405 train_time:132926ms step_avg:143.09ms
step:940/1405 train_time:133075ms step_avg:143.09ms
step:941/1405 train_time:133228ms step_avg:143.10ms
step:942/1405 train_time:133375ms step_avg:143.11ms
step:943/1405 train_time:133527ms step_avg:143.12ms
step:944/1405 train_time:133678ms step_avg:143.12ms
step:945/1405 train_time:133829ms step_avg:143.13ms
step:946/1405 train_time:133978ms step_avg:143.14ms
step:947/1405 train_time:134128ms step_avg:143.15ms
step:948/1405 train_time:134276ms step_avg:143.15ms
step:949/1405 train_time:134427ms step_avg:143.16ms
step:950/1405 train_time:134576ms step_avg:143.17ms
step:951/1405 train_time:134761ms step_avg:143.21ms
step:952/1405 train_time:134909ms step_avg:143.22ms
step:953/1405 train_time:135060ms step_avg:143.22ms
step:954/1405 train_time:135210ms step_avg:143.23ms
step:955/1405 train_time:135358ms step_avg:143.24ms
step:956/1405 train_time:135507ms step_avg:143.24ms
step:957/1405 train_time:135657ms step_avg:143.25ms
step:958/1405 train_time:135811ms step_avg:143.26ms
step:959/1405 train_time:135962ms step_avg:143.27ms
step:960/1405 train_time:136113ms step_avg:143.28ms
step:961/1405 train_time:136261ms step_avg:143.28ms
step:962/1405 train_time:136410ms step_avg:143.29ms
step:963/1405 train_time:136562ms step_avg:143.30ms
step:964/1405 train_time:136712ms step_avg:143.30ms
step:965/1405 train_time:136862ms step_avg:143.31ms
step:966/1405 train_time:137012ms step_avg:143.32ms
step:967/1405 train_time:137160ms step_avg:143.32ms
step:968/1405 train_time:137309ms step_avg:143.33ms
step:969/1405 train_time:137459ms step_avg:143.34ms
step:970/1405 train_time:137608ms step_avg:143.34ms
step:971/1405 train_time:137760ms step_avg:143.35ms
step:972/1405 train_time:137909ms step_avg:143.36ms
step:973/1405 train_time:138057ms step_avg:143.36ms
step:974/1405 train_time:138207ms step_avg:143.37ms
step:975/1405 train_time:138357ms step_avg:143.38ms
step:976/1405 train_time:138508ms step_avg:143.38ms
step:977/1405 train_time:138656ms step_avg:143.39ms
step:978/1405 train_time:138806ms step_avg:143.39ms
step:979/1405 train_time:138955ms step_avg:143.40ms
step:980/1405 train_time:139104ms step_avg:143.41ms
step:981/1405 train_time:139254ms step_avg:143.41ms
step:982/1405 train_time:139401ms step_avg:143.42ms
step:983/1405 train_time:139552ms step_avg:143.42ms
step:984/1405 train_time:139701ms step_avg:143.43ms
step:985/1405 train_time:139851ms step_avg:143.44ms
step:986/1405 train_time:140000ms step_avg:143.44ms
step:987/1405 train_time:140150ms step_avg:143.45ms
step:988/1405 train_time:140298ms step_avg:143.45ms
step:989/1405 train_time:140448ms step_avg:143.46ms
step:990/1405 train_time:140597ms step_avg:143.47ms
step:991/1405 train_time:140747ms step_avg:143.47ms
step:992/1405 train_time:140898ms step_avg:143.48ms
step:993/1405 train_time:141054ms step_avg:143.49ms
step:994/1405 train_time:141205ms step_avg:143.50ms
step:995/1405 train_time:141354ms step_avg:143.51ms
step:996/1405 train_time:141504ms step_avg:143.51ms
step:997/1405 train_time:141653ms step_avg:143.52ms
step:998/1405 train_time:141803ms step_avg:143.53ms
step:999/1405 train_time:141953ms step_avg:143.53ms
step:1000/1405 train_time:142103ms step_avg:143.54ms
step:1000/1405 val_loss:3.4115 train_time:142175ms step_avg:143.61ms
step:1001/1405 train_time:142251ms step_avg:143.54ms
step:1002/1405 train_time:142401ms step_avg:143.55ms
step:1003/1405 train_time:142552ms step_avg:143.56ms
step:1004/1405 train_time:142701ms step_avg:143.56ms
step:1005/1405 train_time:142852ms step_avg:143.57ms
step:1006/1405 train_time:142999ms step_avg:143.57ms
step:1007/1405 train_time:143150ms step_avg:143.58ms
step:1008/1405 train_time:143301ms step_avg:143.59ms
step:1009/1405 train_time:143458ms step_avg:143.60ms
step:1010/1405 train_time:143605ms step_avg:143.60ms
step:1011/1405 train_time:143755ms step_avg:143.61ms
step:1012/1405 train_time:143902ms step_avg:143.62ms
step:1013/1405 train_time:144053ms step_avg:143.62ms
step:1014/1405 train_time:144201ms step_avg:143.63ms
step:1015/1405 train_time:144353ms step_avg:143.63ms
step:1016/1405 train_time:144504ms step_avg:143.64ms
step:1017/1405 train_time:144656ms step_avg:143.65ms
step:1018/1405 train_time:144802ms step_avg:143.65ms
step:1019/1405 train_time:144954ms step_avg:143.66ms
step:1020/1405 train_time:145102ms step_avg:143.67ms
step:1021/1405 train_time:145255ms step_avg:143.67ms
step:1022/1405 train_time:145402ms step_avg:143.68ms
step:1023/1405 train_time:145555ms step_avg:143.69ms
step:1024/1405 train_time:145703ms step_avg:143.69ms
step:1025/1405 train_time:145855ms step_avg:143.70ms
step:1026/1405 train_time:146001ms step_avg:143.70ms
step:1027/1405 train_time:146152ms step_avg:143.71ms
step:1028/1405 train_time:146301ms step_avg:143.71ms
step:1029/1405 train_time:146451ms step_avg:143.72ms
step:1030/1405 train_time:146601ms step_avg:143.73ms
step:1031/1405 train_time:146752ms step_avg:143.73ms
step:1032/1405 train_time:146900ms step_avg:143.74ms
step:1033/1405 train_time:147050ms step_avg:143.74ms
step:1034/1405 train_time:147199ms step_avg:143.75ms
step:1035/1405 train_time:147350ms step_avg:143.76ms
step:1036/1405 train_time:147500ms step_avg:143.76ms
step:1037/1405 train_time:147650ms step_avg:143.77ms
step:1038/1405 train_time:147799ms step_avg:143.77ms
step:1039/1405 train_time:147948ms step_avg:143.78ms
step:1040/1405 train_time:148097ms step_avg:143.78ms
step:1041/1405 train_time:148247ms step_avg:143.79ms
step:1042/1405 train_time:148396ms step_avg:143.79ms
step:1043/1405 train_time:148543ms step_avg:143.80ms
step:1044/1405 train_time:148696ms step_avg:143.81ms
step:1045/1405 train_time:148845ms step_avg:143.81ms
step:1046/1405 train_time:148996ms step_avg:143.82ms
step:1047/1405 train_time:149145ms step_avg:143.82ms
step:1048/1405 train_time:149297ms step_avg:143.83ms
step:1049/1405 train_time:149446ms step_avg:143.84ms
step:1050/1405 train_time:149597ms step_avg:143.84ms
step:1051/1405 train_time:149748ms step_avg:143.85ms
step:1052/1405 train_time:149898ms step_avg:143.86ms
step:1053/1405 train_time:150046ms step_avg:143.86ms
step:1054/1405 train_time:150198ms step_avg:143.87ms
step:1055/1405 train_time:150347ms step_avg:143.87ms
step:1056/1405 train_time:150498ms step_avg:143.88ms
step:1057/1405 train_time:150652ms step_avg:143.89ms
step:1058/1405 train_time:150803ms step_avg:143.90ms
step:1059/1405 train_time:150957ms step_avg:143.91ms
step:1060/1405 train_time:151104ms step_avg:143.91ms
step:1061/1405 train_time:151254ms step_avg:143.91ms
step:1062/1405 train_time:151405ms step_avg:143.92ms
step:1063/1405 train_time:151557ms step_avg:143.93ms
step:1064/1405 train_time:151704ms step_avg:143.93ms
step:1065/1405 train_time:151856ms step_avg:143.94ms
step:1066/1405 train_time:152008ms step_avg:143.95ms
step:1067/1405 train_time:152158ms step_avg:143.95ms
step:1068/1405 train_time:152307ms step_avg:143.96ms
step:1069/1405 train_time:152460ms step_avg:143.97ms
step:1070/1405 train_time:152610ms step_avg:143.97ms
step:1071/1405 train_time:152759ms step_avg:143.98ms
step:1072/1405 train_time:152908ms step_avg:143.98ms
step:1073/1405 train_time:153058ms step_avg:143.99ms
step:1074/1405 train_time:153206ms step_avg:143.99ms
step:1075/1405 train_time:153357ms step_avg:144.00ms
step:1076/1405 train_time:153506ms step_avg:144.00ms
step:1077/1405 train_time:153657ms step_avg:144.01ms
step:1078/1405 train_time:153809ms step_avg:144.02ms
step:1079/1405 train_time:153960ms step_avg:144.02ms
step:1080/1405 train_time:154111ms step_avg:144.03ms
step:1081/1405 train_time:154260ms step_avg:144.03ms
step:1082/1405 train_time:154411ms step_avg:144.04ms
step:1083/1405 train_time:154562ms step_avg:144.05ms
step:1084/1405 train_time:154715ms step_avg:144.05ms
step:1085/1405 train_time:154863ms step_avg:144.06ms
step:1086/1405 train_time:155016ms step_avg:144.07ms
step:1087/1405 train_time:155166ms step_avg:144.07ms
step:1088/1405 train_time:155317ms step_avg:144.08ms
step:1089/1405 train_time:155468ms step_avg:144.09ms
step:1090/1405 train_time:155622ms step_avg:144.09ms
step:1091/1405 train_time:155773ms step_avg:144.10ms
step:1092/1405 train_time:155921ms step_avg:144.10ms
step:1093/1405 train_time:156074ms step_avg:144.11ms
step:1094/1405 train_time:156222ms step_avg:144.12ms
step:1095/1405 train_time:156375ms step_avg:144.12ms
step:1096/1405 train_time:156527ms step_avg:144.13ms
step:1097/1405 train_time:156677ms step_avg:144.14ms
step:1098/1405 train_time:156826ms step_avg:144.14ms
step:1099/1405 train_time:156976ms step_avg:144.15ms
step:1100/1405 train_time:157126ms step_avg:144.15ms
step:1101/1405 train_time:157277ms step_avg:144.16ms
step:1102/1405 train_time:157428ms step_avg:144.16ms
step:1103/1405 train_time:157579ms step_avg:144.17ms
step:1104/1405 train_time:157729ms step_avg:144.18ms
step:1105/1405 train_time:157881ms step_avg:144.18ms
step:1106/1405 train_time:158031ms step_avg:144.19ms
step:1107/1405 train_time:158179ms step_avg:144.19ms
step:1108/1405 train_time:158332ms step_avg:144.20ms
step:1109/1405 train_time:158481ms step_avg:144.20ms
step:1110/1405 train_time:158633ms step_avg:144.21ms
step:1111/1405 train_time:158783ms step_avg:144.22ms
step:1112/1405 train_time:158936ms step_avg:144.23ms
step:1113/1405 train_time:159085ms step_avg:144.23ms
step:1114/1405 train_time:159237ms step_avg:144.24ms
step:1115/1405 train_time:159387ms step_avg:144.24ms
step:1116/1405 train_time:159536ms step_avg:144.25ms
step:1117/1405 train_time:159687ms step_avg:144.25ms
step:1118/1405 train_time:159839ms step_avg:144.26ms
step:1119/1405 train_time:159991ms step_avg:144.27ms
step:1120/1405 train_time:160141ms step_avg:144.27ms
step:1121/1405 train_time:160293ms step_avg:144.28ms
step:1122/1405 train_time:160441ms step_avg:144.28ms
step:1123/1405 train_time:160591ms step_avg:144.29ms
step:1124/1405 train_time:160741ms step_avg:144.29ms
step:1125/1405 train_time:160893ms step_avg:144.30ms
step:1125/1405 val_loss:3.3589 train_time:160967ms step_avg:144.36ms
step:1126/1405 train_time:161044ms step_avg:144.30ms
step:1127/1405 train_time:161197ms step_avg:144.31ms
step:1128/1405 train_time:161345ms step_avg:144.32ms
step:1129/1405 train_time:161497ms step_avg:144.32ms
step:1130/1405 train_time:161645ms step_avg:144.33ms
step:1131/1405 train_time:161797ms step_avg:144.33ms
step:1132/1405 train_time:161945ms step_avg:144.34ms
step:1133/1405 train_time:162097ms step_avg:144.34ms
step:1134/1405 train_time:162244ms step_avg:144.35ms
step:1135/1405 train_time:162396ms step_avg:144.35ms
step:1136/1405 train_time:162548ms step_avg:144.36ms
step:1137/1405 train_time:162698ms step_avg:144.36ms
step:1138/1405 train_time:162847ms step_avg:144.37ms
step:1139/1405 train_time:163000ms step_avg:144.38ms
step:1140/1405 train_time:163148ms step_avg:144.38ms
step:1141/1405 train_time:163339ms step_avg:144.42ms
step:1142/1405 train_time:163485ms step_avg:144.42ms
step:1143/1405 train_time:163638ms step_avg:144.43ms
step:1144/1405 train_time:163789ms step_avg:144.44ms
step:1145/1405 train_time:163937ms step_avg:144.44ms
step:1146/1405 train_time:164087ms step_avg:144.44ms
step:1147/1405 train_time:164241ms step_avg:144.45ms
step:1148/1405 train_time:164394ms step_avg:144.46ms
step:1149/1405 train_time:164545ms step_avg:144.46ms
step:1150/1405 train_time:164695ms step_avg:144.47ms
step:1151/1405 train_time:164847ms step_avg:144.48ms
step:1152/1405 train_time:165000ms step_avg:144.48ms
step:1153/1405 train_time:165151ms step_avg:144.49ms
step:1154/1405 train_time:165302ms step_avg:144.49ms
step:1155/1405 train_time:165454ms step_avg:144.50ms
step:1156/1405 train_time:165607ms step_avg:144.51ms
step:1157/1405 train_time:165762ms step_avg:144.52ms
step:1158/1405 train_time:165914ms step_avg:144.52ms
step:1159/1405 train_time:166064ms step_avg:144.53ms
step:1160/1405 train_time:166217ms step_avg:144.54ms
step:1161/1405 train_time:166368ms step_avg:144.54ms
step:1162/1405 train_time:166521ms step_avg:144.55ms
step:1163/1405 train_time:166673ms step_avg:144.56ms
step:1164/1405 train_time:166824ms step_avg:144.56ms
step:1165/1405 train_time:166975ms step_avg:144.57ms
step:1166/1405 train_time:167126ms step_avg:144.57ms
step:1167/1405 train_time:167276ms step_avg:144.58ms
step:1168/1405 train_time:167427ms step_avg:144.58ms
step:1169/1405 train_time:167581ms step_avg:144.59ms
step:1170/1405 train_time:167731ms step_avg:144.60ms
step:1171/1405 train_time:167884ms step_avg:144.60ms
step:1172/1405 train_time:168037ms step_avg:144.61ms
step:1173/1405 train_time:168188ms step_avg:144.62ms
step:1174/1405 train_time:168344ms step_avg:144.63ms
step:1175/1405 train_time:168500ms step_avg:144.63ms
step:1176/1405 train_time:168652ms step_avg:144.64ms
step:1177/1405 train_time:168807ms step_avg:144.65ms
step:1178/1405 train_time:168960ms step_avg:144.66ms
step:1179/1405 train_time:169109ms step_avg:144.66ms
step:1180/1405 train_time:169263ms step_avg:144.67ms
step:1181/1405 train_time:169416ms step_avg:144.68ms
step:1182/1405 train_time:169565ms step_avg:144.68ms
step:1183/1405 train_time:169719ms step_avg:144.69ms
step:1184/1405 train_time:169868ms step_avg:144.69ms
step:1185/1405 train_time:170022ms step_avg:144.70ms
step:1186/1405 train_time:170173ms step_avg:144.70ms
step:1187/1405 train_time:170328ms step_avg:144.71ms
step:1188/1405 train_time:170478ms step_avg:144.72ms
step:1189/1405 train_time:170630ms step_avg:144.72ms
step:1190/1405 train_time:170782ms step_avg:144.73ms
step:1191/1405 train_time:170935ms step_avg:144.74ms
step:1192/1405 train_time:171087ms step_avg:144.74ms
step:1193/1405 train_time:171239ms step_avg:144.75ms
step:1194/1405 train_time:171389ms step_avg:144.75ms
step:1195/1405 train_time:171540ms step_avg:144.76ms
step:1196/1405 train_time:171692ms step_avg:144.77ms
step:1197/1405 train_time:171844ms step_avg:144.77ms
step:1198/1405 train_time:171999ms step_avg:144.78ms
step:1199/1405 train_time:172149ms step_avg:144.78ms
step:1200/1405 train_time:172301ms step_avg:144.79ms
step:1201/1405 train_time:172453ms step_avg:144.80ms
step:1202/1405 train_time:172611ms step_avg:144.81ms
step:1203/1405 train_time:172763ms step_avg:144.81ms
step:1204/1405 train_time:172916ms step_avg:144.82ms
step:1205/1405 train_time:173065ms step_avg:144.82ms
step:1206/1405 train_time:173219ms step_avg:144.83ms
step:1207/1405 train_time:173368ms step_avg:144.84ms
step:1208/1405 train_time:173521ms step_avg:144.84ms
step:1209/1405 train_time:173672ms step_avg:144.85ms
step:1210/1405 train_time:173827ms step_avg:144.86ms
step:1211/1405 train_time:173979ms step_avg:144.86ms
step:1212/1405 train_time:174129ms step_avg:144.87ms
step:1213/1405 train_time:174281ms step_avg:144.87ms
step:1214/1405 train_time:174434ms step_avg:144.88ms
step:1215/1405 train_time:174583ms step_avg:144.88ms
step:1216/1405 train_time:174735ms step_avg:144.89ms
step:1217/1405 train_time:174886ms step_avg:144.89ms
step:1218/1405 train_time:175037ms step_avg:144.90ms
step:1219/1405 train_time:175187ms step_avg:144.90ms
step:1220/1405 train_time:175338ms step_avg:144.91ms
step:1221/1405 train_time:175489ms step_avg:144.91ms
step:1222/1405 train_time:175640ms step_avg:144.92ms
step:1223/1405 train_time:175791ms step_avg:144.92ms
step:1224/1405 train_time:175944ms step_avg:144.93ms
step:1225/1405 train_time:176096ms step_avg:144.94ms
step:1226/1405 train_time:176248ms step_avg:144.94ms
step:1227/1405 train_time:176402ms step_avg:144.95ms
step:1228/1405 train_time:176553ms step_avg:144.95ms
step:1229/1405 train_time:176703ms step_avg:144.96ms
step:1230/1405 train_time:176856ms step_avg:144.96ms
step:1231/1405 train_time:177008ms step_avg:144.97ms
step:1232/1405 train_time:177161ms step_avg:144.98ms
step:1233/1405 train_time:177313ms step_avg:144.98ms
step:1234/1405 train_time:177463ms step_avg:144.99ms
step:1235/1405 train_time:177616ms step_avg:144.99ms
step:1236/1405 train_time:177767ms step_avg:145.00ms
step:1237/1405 train_time:177919ms step_avg:145.00ms
step:1238/1405 train_time:178074ms step_avg:145.01ms
step:1239/1405 train_time:178224ms step_avg:145.02ms
step:1240/1405 train_time:178378ms step_avg:145.02ms
step:1241/1405 train_time:178534ms step_avg:145.03ms
step:1242/1405 train_time:178684ms step_avg:145.04ms
step:1243/1405 train_time:178837ms step_avg:145.04ms
step:1244/1405 train_time:178988ms step_avg:145.05ms
step:1245/1405 train_time:179140ms step_avg:145.05ms
step:1246/1405 train_time:179291ms step_avg:145.06ms
step:1247/1405 train_time:179443ms step_avg:145.06ms
step:1248/1405 train_time:179595ms step_avg:145.07ms
step:1249/1405 train_time:179744ms step_avg:145.07ms
step:1250/1405 train_time:179898ms step_avg:145.08ms
step:1250/1405 val_loss:3.3116 train_time:179973ms step_avg:145.14ms
step:1251/1405 train_time:180052ms step_avg:145.09ms
step:1252/1405 train_time:180200ms step_avg:145.09ms
step:1253/1405 train_time:180352ms step_avg:145.09ms
step:1254/1405 train_time:180500ms step_avg:145.10ms
step:1255/1405 train_time:180658ms step_avg:145.11ms
step:1256/1405 train_time:180810ms step_avg:145.11ms
step:1257/1405 train_time:180961ms step_avg:145.12ms
step:1258/1405 train_time:181117ms step_avg:145.13ms
step:1259/1405 train_time:181270ms step_avg:145.13ms
step:1260/1405 train_time:181420ms step_avg:145.14ms
step:1261/1405 train_time:181574ms step_avg:145.14ms
step:1262/1405 train_time:181726ms step_avg:145.15ms
step:1263/1405 train_time:181876ms step_avg:145.15ms
step:1264/1405 train_time:182027ms step_avg:145.16ms
step:1265/1405 train_time:182178ms step_avg:145.16ms
step:1266/1405 train_time:182331ms step_avg:145.17ms
step:1267/1405 train_time:182483ms step_avg:145.17ms
step:1268/1405 train_time:182636ms step_avg:145.18ms
step:1269/1405 train_time:182790ms step_avg:145.19ms
step:1270/1405 train_time:182942ms step_avg:145.19ms
step:1271/1405 train_time:183093ms step_avg:145.20ms
step:1272/1405 train_time:183245ms step_avg:145.20ms
step:1273/1405 train_time:183396ms step_avg:145.21ms
step:1274/1405 train_time:183548ms step_avg:145.21ms
step:1275/1405 train_time:183697ms step_avg:145.22ms
step:1276/1405 train_time:183849ms step_avg:145.22ms
step:1277/1405 train_time:184000ms step_avg:145.23ms
step:1278/1405 train_time:184153ms step_avg:145.23ms
step:1279/1405 train_time:184304ms step_avg:145.24ms
step:1280/1405 train_time:184459ms step_avg:145.24ms
step:1281/1405 train_time:184612ms step_avg:145.25ms
step:1282/1405 train_time:184762ms step_avg:145.25ms
step:1283/1405 train_time:184915ms step_avg:145.26ms
step:1284/1405 train_time:185067ms step_avg:145.26ms
step:1285/1405 train_time:185219ms step_avg:145.27ms
step:1286/1405 train_time:185373ms step_avg:145.28ms
step:1287/1405 train_time:185523ms step_avg:145.28ms
step:1288/1405 train_time:185675ms step_avg:145.29ms
step:1289/1405 train_time:185829ms step_avg:145.29ms
step:1290/1405 train_time:185982ms step_avg:145.30ms
step:1291/1405 train_time:186136ms step_avg:145.31ms
step:1292/1405 train_time:186287ms step_avg:145.31ms
step:1293/1405 train_time:186438ms step_avg:145.31ms
step:1294/1405 train_time:186591ms step_avg:145.32ms
step:1295/1405 train_time:186741ms step_avg:145.32ms
step:1296/1405 train_time:186895ms step_avg:145.33ms
step:1297/1405 train_time:187049ms step_avg:145.34ms
step:1298/1405 train_time:187200ms step_avg:145.34ms
step:1299/1405 train_time:187353ms step_avg:145.35ms
step:1300/1405 train_time:187504ms step_avg:145.35ms
step:1301/1405 train_time:187655ms step_avg:145.36ms
step:1302/1405 train_time:187809ms step_avg:145.36ms
step:1303/1405 train_time:187960ms step_avg:145.37ms
step:1304/1405 train_time:188116ms step_avg:145.38ms
step:1305/1405 train_time:188267ms step_avg:145.38ms
step:1306/1405 train_time:188419ms step_avg:145.39ms
step:1307/1405 train_time:188571ms step_avg:145.39ms
step:1308/1405 train_time:188723ms step_avg:145.40ms
step:1309/1405 train_time:188874ms step_avg:145.40ms
step:1310/1405 train_time:189024ms step_avg:145.40ms
step:1311/1405 train_time:189175ms step_avg:145.41ms
step:1312/1405 train_time:189326ms step_avg:145.41ms
step:1313/1405 train_time:189476ms step_avg:145.42ms
step:1314/1405 train_time:189629ms step_avg:145.42ms
step:1315/1405 train_time:189781ms step_avg:145.43ms
step:1316/1405 train_time:189933ms step_avg:145.43ms
step:1317/1405 train_time:190082ms step_avg:145.43ms
step:1318/1405 train_time:190238ms step_avg:145.44ms
step:1319/1405 train_time:190389ms step_avg:145.45ms
step:1320/1405 train_time:190541ms step_avg:145.45ms
step:1321/1405 train_time:190694ms step_avg:145.46ms
step:1322/1405 train_time:190849ms step_avg:145.46ms
step:1323/1405 train_time:190999ms step_avg:145.47ms
step:1324/1405 train_time:191151ms step_avg:145.47ms
step:1325/1405 train_time:191302ms step_avg:145.48ms
step:1326/1405 train_time:191456ms step_avg:145.48ms
step:1327/1405 train_time:191607ms step_avg:145.49ms
step:1328/1405 train_time:191758ms step_avg:145.49ms
step:1329/1405 train_time:191921ms step_avg:145.50ms
step:1330/1405 train_time:192075ms step_avg:145.51ms
step:1331/1405 train_time:192266ms step_avg:145.55ms
step:1332/1405 train_time:192419ms step_avg:145.55ms
step:1333/1405 train_time:192569ms step_avg:145.56ms
step:1334/1405 train_time:192719ms step_avg:145.56ms
step:1335/1405 train_time:192870ms step_avg:145.56ms
step:1336/1405 train_time:193024ms step_avg:145.57ms
step:1337/1405 train_time:193178ms step_avg:145.58ms
step:1338/1405 train_time:193333ms step_avg:145.58ms
step:1339/1405 train_time:193485ms step_avg:145.59ms
step:1340/1405 train_time:193636ms step_avg:145.59ms
step:1341/1405 train_time:193787ms step_avg:145.60ms
step:1342/1405 train_time:193938ms step_avg:145.60ms
step:1343/1405 train_time:194090ms step_avg:145.60ms
step:1344/1405 train_time:194241ms step_avg:145.61ms
step:1345/1405 train_time:194394ms step_avg:145.61ms
step:1346/1405 train_time:194546ms step_avg:145.62ms
step:1347/1405 train_time:194698ms step_avg:145.62ms
step:1348/1405 train_time:194850ms step_avg:145.63ms
step:1349/1405 train_time:195002ms step_avg:145.63ms
step:1350/1405 train_time:195154ms step_avg:145.64ms
step:1351/1405 train_time:195304ms step_avg:145.64ms
step:1352/1405 train_time:195456ms step_avg:145.65ms
step:1353/1405 train_time:195611ms step_avg:145.65ms
step:1354/1405 train_time:195763ms step_avg:145.66ms
step:1355/1405 train_time:195917ms step_avg:145.66ms
step:1356/1405 train_time:196069ms step_avg:145.67ms
step:1357/1405 train_time:196222ms step_avg:145.67ms
step:1358/1405 train_time:196376ms step_avg:145.68ms
step:1359/1405 train_time:196532ms step_avg:145.69ms
step:1360/1405 train_time:196686ms step_avg:145.69ms
step:1361/1405 train_time:196839ms step_avg:145.70ms
step:1362/1405 train_time:196990ms step_avg:145.70ms
step:1363/1405 train_time:197147ms step_avg:145.71ms
step:1364/1405 train_time:197299ms step_avg:145.72ms
step:1365/1405 train_time:197449ms step_avg:145.72ms
step:1366/1405 train_time:197602ms step_avg:145.72ms
step:1367/1405 train_time:197755ms step_avg:145.73ms
step:1368/1405 train_time:197908ms step_avg:145.74ms
step:1369/1405 train_time:198065ms step_avg:145.74ms
step:1370/1405 train_time:198218ms step_avg:145.75ms
step:1371/1405 train_time:198372ms step_avg:145.75ms
step:1372/1405 train_time:198526ms step_avg:145.76ms
step:1373/1405 train_time:198679ms step_avg:145.77ms
step:1374/1405 train_time:198833ms step_avg:145.77ms
step:1375/1405 train_time:198985ms step_avg:145.78ms
step:1375/1405 val_loss:3.2809 train_time:199059ms step_avg:145.83ms
step:1376/1405 train_time:199136ms step_avg:145.78ms
step:1377/1405 train_time:199289ms step_avg:145.79ms
step:1378/1405 train_time:199440ms step_avg:145.79ms
step:1379/1405 train_time:199595ms step_avg:145.80ms
step:1380/1405 train_time:199745ms step_avg:145.80ms
step:1381/1405 train_time:199900ms step_avg:145.81ms
step:1382/1405 train_time:200054ms step_avg:145.81ms
step:1383/1405 train_time:200206ms step_avg:145.82ms
step:1384/1405 train_time:200363ms step_avg:145.82ms
step:1385/1405 train_time:200518ms step_avg:145.83ms
step:1386/1405 train_time:200668ms step_avg:145.83ms
step:1387/1405 train_time:200823ms step_avg:145.84ms
step:1388/1405 train_time:200977ms step_avg:145.85ms
step:1389/1405 train_time:201131ms step_avg:145.85ms
step:1390/1405 train_time:201283ms step_avg:145.86ms
step:1391/1405 train_time:201435ms step_avg:145.86ms
step:1392/1405 train_time:201590ms step_avg:145.87ms
step:1393/1405 train_time:201742ms step_avg:145.87ms
step:1394/1405 train_time:201895ms step_avg:145.88ms
step:1395/1405 train_time:202047ms step_avg:145.88ms
step:1396/1405 train_time:202201ms step_avg:145.89ms
step:1397/1405 train_time:202352ms step_avg:145.89ms
step:1398/1405 train_time:202503ms step_avg:145.90ms
step:1399/1405 train_time:202656ms step_avg:145.90ms
step:1400/1405 train_time:202814ms step_avg:145.91ms
step:1401/1405 train_time:202965ms step_avg:145.91ms
step:1402/1405 train_time:203118ms step_avg:145.92ms
step:1403/1405 train_time:203274ms step_avg:145.93ms
step:1404/1405 train_time:203424ms step_avg:145.93ms
step:1405/1405 train_time:203579ms step_avg:145.93ms
step:1405/1405 val_loss:3.2783 train_time:203654ms step_avg:145.99ms
peak memory consumption: 31569 MiB
