# Debug Configuration - Small model for testing
# Usage: python train.py --yaml_path experiments/debug.yaml --token YOUR_TOKEN --log_name debug_run

save_path: "Synthyra/debug_test"

# Small model architecture for fast testing
hidden_size: 128
num_attention_heads: 2
num_hidden_layers: 2
num_att_tokens: 128
expansion_ratio: 2.0
soft_logit_cap: 16.0
p_attention: false
tie_embeddings: false
unet: true

# MHMoE Configuration for debugging
use_mhmoe: true
moe_num_heads: 2
moe_num_experts: 4
topk: 2
load_balancing_loss_weight: 0.01

# Small training configuration
batch_size: 2048
grad_accum: 1
num_steps: 100
cooldown_steps: 10
max_length: 512
lr_warmup_steps: 10

# Optimizer settings
use_muon: true
lr_embed: 0.01
lr_head: 0.001
lr_scalar: 0.01
lr_hidden: 0.01
muon_momentum_warmup_steps: 10

# Fast evaluation
eval_every: 50

# Simple dataloader
num_workers: 2
prefetch_factor: 1 